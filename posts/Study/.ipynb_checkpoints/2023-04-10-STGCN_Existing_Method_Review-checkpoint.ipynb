{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0d5e8969-31a5-4725-9686-98e8577f904c",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"STGCN Existing Method Review\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-04-10\"\n",
    "categories:\n",
    "  - ITSTGCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd18ee-8856-4674-9fe2-03d406080b0d",
   "metadata": {},
   "source": [
    "> Existing Method Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df90c90-1b8e-45d7-97a8-0303888b9154",
   "metadata": {},
   "source": [
    "RELU의 핵심; 그레이언트 소실 문제 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91573b0e-c2de-456c-8aa0-1d2969beb094",
   "metadata": {},
   "source": [
    "- 노드를 임베딩한다는 것은, 각 노드를 고정된 크기의 벡터로 변환하는 것을 말합니다. 이러한 노드 임베딩은 각 노드의 특성을 벡터 공간에서 나타내기 때문에, 노드 간의 유사성이나 관계를 계산하기 쉬워집니다. 노드 임베딩을 사용하면, 예를 들어 노드 간의 유사성을 측정하거나, 그래프 분류 및 예측 문제를 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb835d-df20-4c86-b96a-1f44f101321a",
   "metadata": {},
   "source": [
    "# 1. GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda8337-f903-48a7-b30f-fcb5ec6a456f",
   "metadata": {},
   "source": [
    "GCN(Graph Convolutional Network): 그래프를 표현하는 인접 행렬을 이용하여 노드 간 상호작용을 모델링하는 신경망 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da2aa0-fac5-4e0c-b7b4-b24f33d056ee",
   "metadata": {},
   "source": [
    "1. 그래프 표현\n",
    "\n",
    "그래프 데이터를 인접 행렬(adjacency matrix)로 표현합니다.\n",
    "\n",
    "인접 행렬은 노드들 간의 연결 정보를 나타내며, 행렬의 (i, j) 요소는 노드 i와 노드 j가 연결되어 있으면 1, 아니면 0으로 표현됩니다.\n",
    "\n",
    "그래프 데이터를 인접 행렬(adjacency matrix) A로 표현합니다.\n",
    "\n",
    "A는 n x n 크기의 행렬이며, A[i,j]는 노드 i와 노드 j가 연결되어 있으면 1, 아니면 0으로 표현됩니다.\n",
    "\n",
    "\n",
    "2. GCN 레이어 구성\n",
    "\n",
    "입력으로 인접 행렬과 노드 특성 행렬(feature matrix)을 받습니다.\n",
    "\n",
    "노드 특성 행렬은 각 노드의 특성을 행렬로 나타낸 것입니다.\n",
    "\n",
    "GCN 레이어는 인접 행렬과 노드 특성 행렬을 이용하여 노드 임베딩(node embedding)을 학습합니다.\n",
    "\n",
    "노드 임베딩은 각 노드의 특성을 저차원 벡터로 나타낸 것입니다.\n",
    "\n",
    "입력으로 인접 행렬 A와 노드 특성 행렬 X을 받습니다.\n",
    "\n",
    "노드 특성 행렬 X는 n x d 크기의 행렬이며, X[i,:]는 노드 i의 d차원 특성 벡터입니다.\n",
    "\n",
    "GCN 레이어는 아래와 같이 정의됩니다.\n",
    "\n",
    "$H^{(l+1)} = \\sigma (\\bar{A} H^{(l)} W^{(l)})$\n",
    "\n",
    "여기서 $H^{(l)}$는 l번째 레이어의 출력으로 $n x d_l$ 크기의 행렬입니다.\n",
    "\n",
    "$W^{(l)}$는 l번째 레이어의 가중치 행렬로, $d_l x d_{l+1}$ 크기입니다.\n",
    "\n",
    "$\\tilde{A} = D^{-\\frac{1}{2}}(A+I)n^{\\frac{1}{2}}D^{-\\frac{1}{2}}$는 A에 정규화 과정을 거친 행렬입니다.\n",
    "\n",
    "여기서 D는 A의 차수(degree) 행렬로, D[i,i]는 노드 i의 차수(연결된 간선의 수)입니다.\n",
    "\n",
    "$\\sigma$는 활성화 함수로, ReLU 함수 등을 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "3. 활성화 함수\n",
    "\n",
    "GCN 레이어의 출력에 활성화 함수를 적용합니다.\n",
    "\n",
    "대표적인 활성화 함수로는 ReLU 함수가 있습니다.\n",
    "\n",
    "\n",
    "4. 풀링\n",
    "\n",
    "GCN 레이어를 여러 개 쌓아서 그래프의 전체 구조를 반영하는 더 깊은 모델을 만들 수 있습니다.\n",
    "\n",
    "더 깊은 모델에서는 각 레이어의 출력을 풀링(pooling) 연산을 통해 전체 구조를 보존하면서 임베딩의 크기를 줄입니다.\n",
    "\n",
    "GCN 레이어를 여러 개 쌓아서 그래프의 전체 구조를 반영하는 더 깊은 모델을 만들 수 있습니다.\n",
    "\n",
    "더 깊은 모델에서는 각 레이어의 출력을 풀링(pooling) 연산을 통해 전체 구조를 보존하면서 임베딩의 크기를 줄입니다.\n",
    "\n",
    "대표적인 풀링 연산으로는 최대 풀링(max pooling)이 있습니다.\n",
    "\n",
    "5. 손실 함수\n",
    "\n",
    "GCN 모델의 출력을 이용하여 예측 값을 구하고, 이를 실제 값과 비교하여 손실 함수를 계산합니다.\n",
    "\n",
    "대표적인 손실 함수로는 크로스 엔트로피(Cross-entropy) 손실 함수가 있습니다.\n",
    "\n",
    "GCN 모델의 출력을 이용하여 예측 값을 구하고, 이를 실제 값과 비교하여 손실 함수를 계산합니다.\n",
    "\n",
    "예측 값을 구하는 방법에는 softmax 함수 등을 사용할 수 있습니다.\n",
    "\n",
    "대표적인 손실 함수로는 크로스 엔트로피(Cross-entropy) 손실 함수가 있습니다.\n",
    "\n",
    "6. 최적화\n",
    "\n",
    "손실 함수를 최소화하기 위해 역전파(backpropagation) 알고리즘을 이용하여 모델의 파라미터를 업데이트합니다.\n",
    "\n",
    "7. 학습\n",
    "\n",
    "손실 함수를 최소화하는 가중치 행렬 $W^{(l)}$를 찾기 위해 역전파(backpropagation) 알고리즘을 사용하여 모델을 학습합니다.\n",
    "\n",
    "일반적인 최적화 알고리즘으로는 경사 하강법(Gradient Descent)이 사용됩니다.\n",
    "\n",
    "8. 예측\n",
    "\n",
    "학습이 완료된 GCN 모델을 사용하여 새로운 그래프에 대한 예측 값을 구할 수 있습니다.\n",
    "\n",
    "입력 그래프의 인접 행렬 A와 노드 특성 행렬 X를 모델에 입력하고, 출력 값을 구합니다.\n",
    "\n",
    "출력 값은 보통 각 노드의 클래스에 대한 확률 값으로 나타내어지며, 분류 문제에서는 이를 이용하여 예측 클래스를 결정합니다.\n",
    "\n",
    "9. GCN의 활용\n",
    "\n",
    "GCN은 그래프 데이터를 다루는 다양한 문제에 활용됩니다.\n",
    "\n",
    "대표적으로는 노드 분류(node classification), 링크 예측(link prediction), 그래프 분류(graph classification) 등이 있습니다.\n",
    "\n",
    "또한 GCN은 컴퓨터 비전 분야에서의 CNN(Convolutional Neural Network)과 같은 역할을 수행하여, 그래프 데이터에 대한 특성 추출에 활용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be21488-9d5b-4e9d-88c1-45c29d4c7095",
   "metadata": {},
   "source": [
    "논문\n",
    "\n",
    "- [\"Semi-Supervised Classification with Graph Convolutional Networks\" by Thomas N. Kipf and Max Welling, ICLR 2017.](https://arxiv.org/pdf/1609.02907.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69897c-64a8-4f23-be06-7756fbf9a25d",
   "metadata": {},
   "source": [
    "# 2. GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739d702-5c42-4602-bdb7-39f8d2a054cb",
   "metadata": {},
   "source": [
    "GAT(Graph Attention Network): 노드 간 상호작용을 모델링할 때, 중요한 노드에 더 많은 가중치를 주어 상호작용을 모델링하는 신경망 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fb956-c441-4296-ba42-f20cfa982fb0",
   "metadata": {},
   "source": [
    "입력: 그래프 $\\mathcal{G=(V, E)}$, 각 노드 #v_i#의 특성 벡터 $h_i∈ℝ^d$, 이웃 노드 집합 $N(i)∈V (v_i)$에 연결된 노드들의 집합), 가중치 행렬 $W \\in ℝ^{d(d)}$, Attention 매개 변수 $W_a∈ℝ^{(2d)}×1$\n",
    "\n",
    "노드 i와 이웃 노드 j 간의 Attention 점수 계산:\n",
    "\n",
    "$a_{ij} = softmax(LeakyReLU(a([Wh_i, Wh_j])))$\n",
    "\n",
    "여기서 a는 하나의 Dense layer를 나타내며, LeakyReLU는 Leaky Rectified Linear Unit 함수입니다.\n",
    "\n",
    "노드 i의 새로운 표현 계산:\n",
    "\n",
    "$h_i' = σ(Σ_j a_ijWh_j)$\n",
    "\n",
    "여기서 σ는 활성화 함수로, 일반적으로 ReLU 함수가 사용됩니다.\n",
    "\n",
    "출력: 새로운 노드 표현 $h'_i$\n",
    "\n",
    "위의 알고리즘에서, 노드 i와 이웃 노드 j 간의 Attention 점수 a_ij는 각 노드 쌍 사이에서 얼마나 중요한 정보를 교환하는지를 나타냅니다. 이를 계산할 때, 입력 특성 벡터 h_i와 h_j를 각각 가중치 행렬 W를 이용하여 변환한 후, Attention 매개 변수 W_a를 사용하여 조정합니다. 이를 통해 중요한 노드에 더 많은 가중치를 부여하고, 이를 바탕으로 각 노드 간의 상호작용을 모델링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8047ca7-7ea4-416e-bbe1-e6b027656ada",
   "metadata": {},
   "source": [
    "- LeakyReLU\n",
    "\n",
    "LeakyReLU(Leaky Rectified Linear Unit)는 ReLU(Rectified Linear Unit) 함수의 변형으로, 입력 값이 음수일 때 작은 기울기를 가지는 선형 함수입니다.\n",
    "\n",
    "ReLU 함수는 입력 값이 0 이상일 경우, 0을 출력하고, 음수인 경우에는 기울기가 0이 되어 해당 노드의 기능을 강제로 제한하는 문제가 있습니다. 이를 해결하기 위해 LeakyReLU는 입력 값이 음수일 때, 작은 기울기를 가지도록 하여 제한을 완화합니다.\n",
    "\n",
    "따라서 GAT에서 사용되는 LeakyReLU는 양수 값에 대해서는 ReLU와 같은 함수를 수행하고, 음수 값에 대해서는 작은 기울기를 가지는 선형 함수를 수행합니다. 이를 통해 입력 값이 음수일 때도 노드의 기능이 유지되어, 더욱 효과적인 모델링을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62075a2-94a8-4f3b-987f-614fa1989d15",
   "metadata": {},
   "source": [
    "- Attention 매개 변수 W_a\n",
    "\n",
    "Attention 매개 변수 W_a는 모델이 학습을 통해 자동으로 결정됩니다. 즉, 모델이 훈련 데이터를 통해 최적의 가중치 값을 찾아가는 과정에서, W_a도 함께 학습됩니다.\n",
    "\n",
    "일반적으로 모델의 손실 함수에는 W와 같은 가중치 행렬들과 함께 Attention 매개 변수 W_a를 고려하는 항이 포함됩니다. 이 항은 모델이 Attention 매개 변수를 학습하는 동안 중요한 역할을 합니다. 모델은 이 항을 최소화하면서 W와 W_a를 조절하여 입력 그래프에서 노드 간의 상호작용을 잘 모델링할 수 있는 최적의 파라미터 값을 찾아갑니다.\n",
    "\n",
    "따라서, 모델이 학습을 통해 훈련 데이터를 학습하면서 최적의 가중치 행렬과 Attention 매개 변수를 찾아내며, 이를 통해 입력 그래프에서 노드 간의 상호작용을 잘 모델링할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e7efb-300c-4085-8b79-ee5830229bd1",
   "metadata": {},
   "source": [
    "논문\n",
    "\n",
    "- [Graph Attention Networks](https://arxiv.org/pdf/1710.10903.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac86e1-5509-4d89-ae49-187d5d8e55f7",
   "metadata": {},
   "source": [
    "# 3. TGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d5f84-f172-42a9-8dab-137fae0f0fa0",
   "metadata": {},
   "source": [
    "TGCN(Temporal Graph Convolutional Network): 시계열 데이터와 그래프를 동시에 고려하여 모델링하는 신경망 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edaa563-e16d-4c4c-8bef-47c6d26921cf",
   "metadata": {},
   "source": [
    "1. 입력 데이터를 받아 각 노드와 엣지에 대한 특성을 임베딩합니다.\n",
    "\n",
    "노드 임베딩: $H^{(0)} = [h_1^{(0)}, h_2^{(0)}, ..., h_N^{(0)}] \\in \\mathbb{R}^{N \\times F^{(0)}}$\n",
    "\n",
    "엣지 임베딩: $E^{(0)} = [e_1^{(0)}, e_2^{(0)}, ..., e_M^{(0)}] \\in \\mathbb{R}^{M \\times F_e^{(0)}}$\n",
    "\n",
    "2. 시계열 데이터를 입력으로 받아 각 시간 단계별로 특성을 임베딩합니다.\n",
    "\n",
    "시계열 임베딩: $X^{(t)} \\in \\mathbb{R}^{N \\times F_x}$, $t=1,...,T$\n",
    "\n",
    "3. TGCN 레이어를 여러 개 쌓아서 그래프와 시계열 정보를 모두 고려한 특성을 추출합니다.\n",
    "\n",
    "TGCN 레이어: $H^{(l)}, E^{(l)}, X^{(t)}, A \\rightarrow H^{(l+1)}$\n",
    "\n",
    "$H^{(l)}$: 이전 레이어에서의 노드 특성\n",
    "\n",
    "$E^{(l)}$: 이전 레이어에서의 엣지 특성\n",
    "\n",
    "$X^{(t)}$: 현재 시간 단계의 시계열 특성\n",
    "\n",
    "$A$: 인접 행렬\n",
    "\n",
    "4. TGCN 레이어를 모두 거친 후, 각 시간 단계별로 예측 값을 출력합니다.\n",
    "\n",
    "출력: $\\hat{Y}^{(t)} \\in \\mathbb{R}^{N \\times F_y}$, $t=1,...,T$\n",
    "\n",
    "위의 식에서 A는 인접 행렬이며, D는 A의 차수 행렬(diagonal degree matrix)입니다. A의 i번째 행은 i번째 노드와 연결된 모든 노드의 정보를 담고 있으며, D의 i번째 대각선 원소는 i번째 노드와 연결된 모든 노드의 차수의 합을 나타냅니다.\n",
    "\n",
    "첫 번째 레이어에서는 인접 행렬 A와 입력 특성 행렬 X를 곱하여 히든 상태 행렬 H(1)을 생성합니다. 이때, 히든 상태 행렬의 크기는 (N, F(1))이며, N은 노드의 개수, F(1)은 첫 번째 레이어에서의 히든 유닛 수입니다.\n",
    "\n",
    "두 번째 레이어에서는 첫 번째 레이어에서 생성된 히든 상태 행렬 H(1)와 인접 행렬 A를 곱하여 두 번째 히든 상태 행렬 H(2)를 생성합니다. 이때, 두 번째 히든 상태 행렬의 크기는 (N, F(2))이며, F(2)는 두 번째 레이어에서의 히든 유닛 수입니다.\n",
    "\n",
    "마지막 레이어에서는 두 번째 히든 상태 행렬 H(2)를 사용하여 그래프 분류, 노드 분류 또는 링크 예측과 같은 다양한 그래프 기반 작업을 수행할 수 있습니다. 예를 들어, 그래프 분류에서는 H(2)를 사용하여 소프트맥스 함수를 통해 분류 결과를 계산할 수 있습니다.\n",
    "\n",
    "TGCN에서는 또한 시계열 데이터를 고려하기 위해, GCN의 입력 특성 행렬 X 대신 시계열 데이터를 입력으로 사용합니다. 따라서 입력은 시간 축을 가지는 3D 텐서 형태이며, (N, T, F)의 크기를 가집니다. T는 시간 스텝 수이며, F는 각 시간 스텝에서의 특성 수입니다. 이러한 입력과 인접 행렬을 사용하여 TGCN은 시계열 데이터와 그래프를 동시에 고려하여 모델링할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6477-0786-4118-954e-ed7b1832c6a1",
   "metadata": {},
   "source": [
    "$N$: 노드 수\n",
    "\n",
    "$F$: 입력 피쳐의 수\n",
    "\n",
    "$K$: 인접 행렬의 차수 (degree)\n",
    "\n",
    "$T$: 시간 단계 수\n",
    "\n",
    "$C$: 출력 피쳐의 수\n",
    "\n",
    "$H$: hidden state의 크기\n",
    "\n",
    "$W_{in} \\in \\mathbb{R}^{F \\times H}$: 입력 피쳐에 대한 가중치 행렬\n",
    "\n",
    "$W_{out} \\in \\mathbb{R}^{H \\times C}$: 출력 피쳐에 대한 가중치 행렬\n",
    "\n",
    "$\\boldsymbol{W} \\in \\mathbb{R}^{H \\times H \\times K}$: 인접 행렬에 대한 가중치 텐서\n",
    "\n",
    "$\\boldsymbol{U} \\in \\mathbb{R}^{H \\times H}$: 시간 축에 대한 가중치 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069adc1-af71-44a1-8e16-8b617d0c06a2",
   "metadata": {},
   "source": [
    "논문\n",
    "\n",
    "- [T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction](https://arxiv.org/pdf/1811.05320.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224f2a7-24de-4e27-a751-c88d4f40737a",
   "metadata": {},
   "source": [
    "# 4. [MTGNN](https://github.com/nnzhan/MTGNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5b309-5528-4c2b-ab0a-53b034d820cd",
   "metadata": {},
   "source": [
    "MTGNN(Multi-Temporal Graph Neural Network): 여러 개의 그래프와 시계열 데이터를 모두 고려하여 모델링하는 신경망 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4823385-3367-476e-a557-7969c7231377",
   "metadata": {},
   "source": [
    "MTGNN은 여러 개의 그래프와 시계열 데이터를 동시에 고려하여 모델링하는 신경망 모델입니다. MTGNN은 크게 두 가지 단계로 구성됩니다.\n",
    "\n",
    "공간 변환 (Spatial Transformation): 먼저, 모델은 각 시간 스텝에서의 그래프 정보를 공간 상의 정보로 변환합니다. 이를 위해 각 그래프는 노드 임베딩 벡터를 생성하는데, 이 벡터는 해당 노드와 인접한 노드들의 정보를 이용해 구성됩니다. 또한, 각 그래프는 그래프 임베딩 벡터를 생성하는데, 이 벡터는 해당 그래프와 유사한 다른 그래프들의 정보를 이용해 구성됩니다.\n",
    "\n",
    "시간 변환 (Temporal Transformation): 다음으로, 모델은 공간 정보를 시간적인 정보로 변환합니다. 이를 위해 모델은 시계열 데이터와 공간 정보를 함께 입력으로 받아, 시간에 따라 정보가 어떻게 변화하는지 학습합니다. 이 단계에서는 여러 개의 MTGNN 레이어가 사용됩니다. 각 레이어에서는 이전 스텝에서 생성된 그래프와 노드 임베딩 벡터, 그리고 현재 스텝에서의 시계열 데이터가 입력으로 사용됩니다. 각 레이어에서는 이전 정보를 기억하고 새로운 정보를 추가하는 방식으로 학습이 이루어집니다. 이 단계에서도, 그래프 임베딩 벡터는 현재 스텝에서의 그래프와 유사한 다른 그래프들의 정보를 이용해 업데이트됩니다.\n",
    "\n",
    "MTGNN은 이러한 방식으로 여러 개의 그래프와 시계열 데이터를 동시에 고려하여 모델링할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d290e3-1319-43b9-bc34-58cb4f22aa48",
   "metadata": {},
   "source": [
    "입력:\n",
    "\n",
    "입력 데이터 X : T x N x F 크기의 3차원 텐서, T는 시간 단계, N은 노드 개수, F는 각 노드의 특징 벡터 크기입니다.\n",
    "\n",
    "인접 행렬 A : N x N 크기의 인접 행렬, 각 노드 사이의 관계를 나타냅니다.\n",
    "\n",
    "시계열 길이 L : 모델이 고려하는 시계열 데이터의 길이입니다.\n",
    "\n",
    "hidden state의 크기 H : LSTM 레이어에서 사용되는 은닉 상태의 크기입니다.\n",
    "\n",
    "출력의 크기 C : 예측하고자 하는 클래스의 개수입니다.\n",
    "\n",
    "출력:\n",
    "\n",
    "예측값 Y : T x C 크기의 2차원 텐서, T는 시간 단계, C는 출력 클래스의 개수입니다.\n",
    "\n",
    "1. 인접 행렬 A를 정규화합니다.\n",
    "\n",
    "D : N x N 크기의 노드의 차수(diagonal degree matrix)를 대각선에 위치한 행렬로 나타냅니다.\n",
    "\n",
    "$A_hat : (D + I)^(-1/2) x A x (D + I)^(-1/2)$로 정규화된 인접 행렬을 계산합니다.\n",
    "\n",
    "여기서 I는 N x N 크기의 단위 행렬입니다.\n",
    "\n",
    "2. 입력 데이터 X를 처리하기 위해 1D convolutional layer를 적용합니다.\n",
    "\n",
    "1D convolutional layer의 출력은 T x N x H 크기의 3차원 텐서입니다.\n",
    "\n",
    "3. GCLSTM 레이어를 적용합니다.\n",
    "\n",
    "각 시간 단계 t마다 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "- $X_t : T x N x F$ 크기의 입력 데이터 X에서 시간 단계 t의 데이터를 가져옵니다.\n",
    "    -  데이터 X_t와 이전 시간 단계의 은닉 상태 H_t-1을 이용하여, 각 노드의 hidden state $h_t^l$과 cell state $c_t^l$을 계산합니다.\n",
    "    - $h_t^l, c_t^l = LSTM(X_t, h_t-1^l, c_t-1^l)$\n",
    "    - 이전 시간 단계에서의 hidden state $H_{t-1}$과 현재 시간 단계에서 계산된 hidden state $h_t^l$을 이용하여, attention score s_t^l을 계산합니다.\n",
    "    - $s_t^l = softmax(a([H_{t-1}, h_t^l]))$\n",
    "    - 여기서 a는 fully connected layer입니다.\n",
    "    - 계산된 attention score $s_t^l$을 이용하여, GCLSTM의 출력 $H_t^l$을 계산합니다.\n",
    "    - $H_t^l = s_t^l * h_t^l + (1-s_t^l) * H$\n",
    "    \n",
    "식에서 $\\mathcal{A}$는 각 노드 간의 연결 관계를 나타내는 그래프의 인접 행렬(adjacency matrix)이고, $\\mathcal{D}$는 노드의 차수(degree)를 대각 원소로 갖는 대각 행렬(diagonal matrix)입니다.\n",
    "\n",
    "$\\mathbf{X}$는 입력 데이터로, $n \\times d$ 크기의 행렬입니다. 이는 $n$개의 시계열 데이터 샘플을 나타내는데, 각 샘플은 $d$개의 변수를 가지고 있습니다. $\\mathbf{X}$는 첫 번째 레이어의 입력으로 사용됩니다.\n",
    "\n",
    "$\\mathbf{H}^{(0)}$는 레이어 0의 출력으로, 이전 시간 단계에서의 입력 데이터 $\\mathbf{X}$로 초기화됩니다.\n",
    "\n",
    "$\\mathbf{H}^{(l)}$는 레이어 $l$의 출력입니다. $l$번째 레이어의 입력은 이전 레이어의 출력 $\\mathbf{H}^{(l-1)}$과 이전 시간 단계에서의 레이어 $l-1$의 출력인 $\\mathbf{Z}^{(l-1)}$의 결합입니다.\n",
    "\n",
    "$\\mathbf{Z}^{(l)}$는 레이어 $l$에서의 중간 표현으로, 이전 시간 단계에서의 레이어 $l$의 출력인 $\\mathbf{Z}^{(l-1)}$와 이번 시간 단계에서의 레이어 $l$의 입력 $\\mathbf{H}^{(l)}$을 기반으로 계산됩니다.\n",
    "\n",
    "레이어 $l$에서의 출력 $\\mathbf{H}^{(l)}$은 $\\mathbf{Z}^{(l)}$에서 특정 행만 선택하여 구성되는데, 이는 특정 시계열 변수만 사용하고자 할 때 유용합니다.\n",
    "\n",
    "$\\sigma(\\cdot)$는 활성화 함수로, 일반적으로 ReLU 또는 Sigmoid 함수가 사용됩니다. $\\mathbf{W}$와 $\\mathbf{U}$는 레이어에서 사용되는 가중치 행렬입니다. $\\circ$는 element-wise 곱셈을 나타냅니다.\n",
    "\n",
    "마지막 레이어에서는 softmax 함수를 사용하여 각 클래스에 대한 확률 분포를 출력합니다. 이를 통해 다중 클래스 분류 문제를 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4f242-9ece-4b38-af6c-919d9249a9fe",
   "metadata": {},
   "source": [
    "- 네, 인접한 노드와의 관계를 레이어마다 고려합니다. GNN은 그래프의 구조를 이용해 노드 간 상호작용을 모델링하는데, 인접한 노드끼리의 상호작용은 그래프의 연결관계에 의해 정의됩니다. 따라서 인접한 노드끼리의 정보를 이용해 노드의 임베딩을 갱신합니다. 이를 위해서는 인접한 노드의 특성을 수집하고, 해당 정보를 이용해 노드의 새로운 임베딩을 계산해야 합니다. 이 과정을 여러 레이어에서 반복하여 노드의 임베딩을 점점 더 복잡하게 구성해 나가는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e86fa3-3a56-4664-b9ae-169a55ddd85a",
   "metadata": {},
   "source": [
    "논문\n",
    "\n",
    "- [Connecting the Dots: Multivariate Time Series Forecasting with\n",
    "Graph Neural Networks](https://arxiv.org/pdf/2005.11650.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a95aa-dc73-4f5c-8082-adae38d3cef7",
   "metadata": {},
   "source": [
    "# 5. STGAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752f1b9-7b54-49a4-a1e4-f59cf259651e",
   "metadata": {},
   "source": [
    "STGAT(Spatio-Temporal Graph Attention Network): STGCN과 유사한 방식으로, 그래프와 시계열 데이터를 고려하여 모델링하되, GAT과 유사한 가중치를 사용하여 모델링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b5ca1-befc-42d2-a1a0-d3df2a5a1b15",
   "metadata": {},
   "source": [
    "STGAT는 먼저 교통 네트워크를 시공간 그래프로 표현합니다. 이 그래프는 노드(node)와 엣지(edge)로 이루어져 있으며, 각 노드는 교차로나 도로의 일부 구간을 나타내고, 각 엣지는 구간 간의 연결을 나타냅니다. 또한, 시간 축을 추가하여 각 구간의 트래픽 데이터를 시간에 따라 그래프의 각 노드에 매핑합니다.\n",
    "\n",
    "그 다음, STGAT는 그래프 내의 각 노드에 대한 특징을 추출합니다. 이를 위해 STGAT는 그래프 어텐션(graph attention) 메커니즘을 사용합니다. 이 메커니즘은 각 노드의 특징을 다른 노드의 특징과 조합하여 더 유의미한 특징을 추출합니다.\n",
    "\n",
    "마지막으로, STGAT는 추출된 특징을 사용하여 교통 예측 모델을 학습합니다. 이 모델은 시간에 따른 각 노드의 트래픽을 예측합니다. 이를 위해 STGAT는 순환 신경망(recurrent neural network)을 사용합니다. 이 신경망은 과거 시간의 데이터를 사용하여 현재 시간의 데이터를 예측합니다.\n",
    "\n",
    "따라서, STGAT는 교통 네트워크의 시공간 정보를 효과적으로 활용하여 높은 예측 성능을 달성하는 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16acb22-3bc7-450e-a3bc-647ab31c1f9e",
   "metadata": {},
   "source": [
    "1. 그래프 생성\n",
    "\n",
    "각 교차로나 도로 구간을 노드로 표현\n",
    "\n",
    "각 구간 간의 연결을 엣지로 표현\n",
    "\n",
    "각 노드에 시간 축 추가하여 시공간 그래프 생성\n",
    "\n",
    "2. 그래프 어텐션\n",
    "\n",
    "그래프 내의 각 노드에 대해 인접한 노드의 특징을 조합하여 새로운 특징을 추출하는 과정\n",
    "\n",
    "노드 i의 새로운 특징 h_i를 계산하는 식은 다음과 같음:\n",
    "\n",
    "$h_i = σ(Σ_j(α_ij * W * h_j))$\n",
    "\n",
    "여기서, $h_j$는 j번째 노드의 특징, W는 가중치 행렬, $α_{ij}$는 노드 i와 j 간의 어텐션 가중치, σ는 활성화 함수\n",
    "\n",
    "3. 시간 예측\n",
    "\n",
    "RNN을 사용하여 예측 모델 학습\n",
    "\n",
    "입력으로는 각 노드의 특징을 사용\n",
    "\n",
    "출력으로는 다음 시간대의 각 노드의 트래픽 예측 값을 사용\n",
    "\n",
    "RNN의 출력 식은 다음과 같음:\n",
    "\n",
    "$h_t = σ(W_h * h_t-1 + W_x * x_t + b)$\n",
    "\n",
    "여기서, h_t는 현재 시간대의 은닉 상태(hidden state), x_t는 입력 데이터, W_h와 W_x는 가중치 행렬, b는 편향"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8a6e1-ac21-4f8d-bc4d-cdadd7fd47ca",
   "metadata": {},
   "source": [
    "논문\n",
    "- [Spatial-temporal Graph Attention Networks for Traffic Flow Forecasting](https://iopscience.iop.org/article/10.1088/1755-1315/587/1/012065/pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f392e58-384f-4e48-ade4-f4383e4a3a4c",
   "metadata": {},
   "source": [
    "**STGCN과 STGAT 차이점**\n",
    "\n",
    "1. 그래프 생성 방법\n",
    "\n",
    "STGAT는 시간 축을 추가하여 각 노드에 매핑하는 방식으로 시공간 그래프를 생성합니다.\n",
    "\n",
    "STGCN은 인접 행렬(adjacency matrix)을 사용하여 시공간 그래프를 생성합니다.\n",
    "\n",
    "2. 그래프 어텐션 방법\n",
    "\n",
    "STGAT는 인접한 노드의 특징을 조합하여 새로운 특징을 추출하는 그래프 어텐션 메커니즘을 사용합니다.\n",
    "\n",
    "STGCN은 그래프 컨볼루션 연산(graph convolution operation)을 사용하여 새로운 특징을 추출합니다.\n",
    "\n",
    "3. 모델 구조\n",
    "\n",
    "STGAT는 그래프 어텐션과 RNN을 결합한 구조를 사용합니다.\n",
    "\n",
    "STGCN은 그래프 컨볼루션 연산과 1D 컨볼루션(convolution)을 결합한 구조를 사용합니다.\n",
    "\n",
    "4. 성능\n",
    "\n",
    "STGAT와 STGCN은 각각 다른 데이터셋에서 평가되었으며, 성능은 데이터셋에 따라 다릅니다. 일반적으로 STGCN은 STGAT보다 더 높은 예측 성능을 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b3da0-783e-4224-9d77-69b3db464bab",
   "metadata": {},
   "source": [
    "- STGAT는 시간 축을 추가하여 각 노드에 매핑하는 방식으로 시공간 그래프를 생성합니다.\n",
    "\n",
    "STGAT에서는 교통 데이터의 시간 축을 고려하여 시공간 그래프를 생성합니다. 이를 위해, 각 노드는 시간 정보를 포함한 특징 벡터를 가지고 있으며, 시간 정보는 시간 축으로 매핑됩니다.\n",
    "\n",
    "예를 들어, 교차로를 노드로 표현하는 경우, 각 교차로에 대해 다양한 특징(예: 교차로의 위치, 크기, 인구 밀도 등)을 수집할 수 있습니다. 그리고 교차로 간의 연결을 엣지로 표현하여 시공간 그래프를 생성할 수 있습니다. 그러나 이 경우 각 교차로의 특징 벡터에는 시간 정보가 포함되어 있지 않습니다.\n",
    "\n",
    "따라서, STGAT에서는 각 교차로의 특징 벡터에 시간 정보를 추가하여 시간 축으로 매핑합니다. 예를 들어, 하루를 24개의 시간 구간으로 분할하여 각 교차로의 특징 벡터에 현재 시간대의 교통 데이터를 추가할 수 있습니다. 이렇게 시간 정보가 추가된 특징 벡터를 이용하여 시공간 그래프를 생성하면, 시간 축을 고려한 교통 예측이 가능해집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56f4db-5d62-4f45-b7b3-c8bc0926719d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

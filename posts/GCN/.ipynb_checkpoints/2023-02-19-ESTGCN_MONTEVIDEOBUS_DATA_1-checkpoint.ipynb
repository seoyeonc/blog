{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8e90f49b-a002-4301-9656-147f3e4b8c46",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"MontevideoBus lag 4 Randomly Missing comparison Table\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-02-19\"\n",
    "categories:\n",
    "  - ST-GCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf50ae2-58ec-4c6e-9cc8-393c473767eb",
   "metadata": {},
   "source": [
    "> ST-GCN Dataset MontevideoBus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42435a96-b11a-4191-854f-889fdd8e7338",
   "metadata": {},
   "source": [
    "# MontevideoBusDatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ac8cd-211f-4e85-ae58-1c97e5a0f294",
   "metadata": {},
   "source": [
    "https://www.fing.edu.uy/~renzom/msc/uploads/msc-thesis.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a5b0f-0649-49ae-8982-56fddade088f",
   "metadata": {},
   "source": [
    "\n",
    "A dataset of inflow passenger at bus stop level from Montevideo city. This dataset comprises hourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay). The bus lines selected are the ones that carry people to the center of the city and they load more than 25% of the total daily inflow traffic. Vertices are bus stops, edges are links between bus stops when a bus line connects them and the weight represent the road distance. The target is the passenger inflow. This is a curated dataset made from different data sources of the Metropolitan Transportation System (STM) of Montevideo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01a222-fa36-4851-afe3-41b0b82b2ca1",
   "metadata": {},
   "source": [
    "데이터정리 \n",
    "\n",
    "- T = 739\n",
    "- V = 버스정류장 \n",
    "- N = 675 # number of nodes \n",
    "- E = 101761 = N^2 # edges \n",
    "- $f(v,t)$의 차원? (1,) # passenger inflow \n",
    "- 시간에 따라서 Number of nodes가 변하는지? False\n",
    "- 시간에 따라서 Number of nodes가 변하는지? False\n",
    "- X: (675,4) (N,4), $f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)$\n",
    "- y: (675,,) (N,), $f(v,t_4)$\n",
    "- 예제코드적용가능여부: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500dbf1-e2c4-4062-a57b-d654962d1c8d",
   "metadata": {},
   "source": [
    "`-` Nodes : `675`\n",
    "\n",
    "- vertices are bus stops\n",
    "\n",
    "`-`Edges : `690`\n",
    "\n",
    "- edges are links between bus stops when a bus line connects them and the weight represent the road distance\n",
    "\n",
    "`-` Time : `739`\n",
    "\n",
    "-  hourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463f6e7-0b6c-490d-b7ee-4022ce4345a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90af573-4bc0-4c9e-ad94-e9739160055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "# scipy \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import copy\n",
    "\n",
    "import rpy2.robjects.numpy2ri as rpyn\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbe91df-66c9-46da-abf9-379f37061d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f9f9-20fb-489c-9a8d-0f47cf681b1e",
   "metadata": {},
   "source": [
    "# my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227faf0a-4609-4fb1-bb57-f72308e2b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'rb') as outfile:\n",
    "        data_dict = pickle.load(outfile)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a159f970-32cf-4719-b3b7-d16eeb939f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict,fname):\n",
    "    with open(fname,'wb') as outfile:\n",
    "        pickle.dump(data_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b2f8de-d7db-4a8a-8b56-68987ea54c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f,*args,t=None,h=2.5,**kwargs):\n",
    "    T,N = f.shape\n",
    "    if t == None: t = range(T)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots(N,1)\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "        ax[n].set_title('node='+str(n))\n",
    "    fig.set_figheight(N*h)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd30cd2-1daf-474d-b132-7b41af02e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_add(fig,f,*args,t=None,**kwargs):\n",
    "    T = f.shape[0]\n",
    "    N = f.shape[1] \n",
    "    if t == None: t = range(T)   \n",
    "    ax = fig.get_axes()\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5422d968-a917-483b-8e82-4ab2bf569bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Psi(T):\n",
    "    W = np.zeros((T,T))\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            if i==j :\n",
    "                W[i,j] = 0\n",
    "            elif np.abs(i-j) <= 1 : \n",
    "                W[i,j] = 1\n",
    "    d = np.array(W.sum(axis=1))\n",
    "    D = np.diag(d)\n",
    "    L = np.array(np.diag(1/np.sqrt(d)) @ (D-W) @ np.diag(1/np.sqrt(d)))\n",
    "    lamb, Psi = np.linalg.eigh(L)\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdbd67c-4d90-4d7f-9a4f-2f73dac5485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da0eb4f-5518-4e35-b392-9762da230d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(f):\n",
    "    f = np.array(f)\n",
    "    if len(f.shape)==1: f = f.reshape(-1,1)\n",
    "    T,N = f.shape\n",
    "    Psi = make_Psi(T)\n",
    "    fbar = Psi.T @ f # apply dft \n",
    "    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n",
    "    fhat = Psi @ fbar_threshed # inverse dft \n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3036d47a-8211-4f46-9cd3-c316e01e5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_freq_domain(signal, missing_index):\n",
    "    signal = np.array(signal)\n",
    "    T,N = signal.shape \n",
    "    signal_trimed = trim(signal)\n",
    "    for i in range(N):\n",
    "        signal[missing_index[i],i] = signal_trimed[missing_index[i],i]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7494a4-48fb-4615-8278-92c167349a86",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5df260d-2d15-4aad-aa43-6a007338235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import  MontevideoBusDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c0532a-4145-444b-b21c-cd2527ac9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MontevideoBusDatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a769d9e-6673-45a9-af2d-d2f468eb4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.get_dataset(lags=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fa5d05-33c4-4a1e-a35e-165a199bb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7bfb4-afc6-4dbe-8214-74c3ab5b54e8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6636dc51-0b08-46c3-a085-e393a97aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    data_train.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5966c5-a39b-4b70-9028-a61dfd1de3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675, 4]),\n",
       " torch.Size([675]),\n",
       " torch.Size([2, 690]),\n",
       " torch.Size([690]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a07c500-5603-47c3-bdbf-2263bce42ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f10135-8c29-4ebf-81d0-be0757442889",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = time\n",
    "N = len(data_train[0][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa85896-7946-4953-8ee3-b26fd94acd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data_train[0][1].edge_index\n",
    "edge_attr = data_train[0][1].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b676bbb5-3b7f-4124-bc07-b76bbb3ef55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(time):\n",
    "    x_train.append(data_train[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133c53ec-f888-4692-8ec2-1190210ea234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([591, 675, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_train = data_tensor.reshape(time,N,-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0e2332-9332-457c-838f-913c746c357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(time):\n",
    "    y_train.append(data_train[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77b6591-a226-48e1-ad80-c80c450a0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([591, 675])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_train = data_tensor.reshape(time,N)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a982424-a5d6-4f00-b9f9-99148e4e71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([591, 675, 4]), torch.Size([591, 675]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d821f1b-bddd-4df4-91f1-f80f0d34492d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85c19483-c755-45dd-9a3f-1998c4088d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    data_test.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "620a37fb-0ac2-4550-8c66-5e788cdfa0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675, 4]),\n",
       " torch.Size([675]),\n",
       " torch.Size([2, 690]),\n",
       " torch.Size([690]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c43585-3bf3-43ad-a84b-26edcc809058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80140e76-d286-4fc9-b94a-d93de15e70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_test = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cedea55-bc18-45ac-b61a-676002cf8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(time):\n",
    "    x_test.append(data_test[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b775a13-ed2c-44ef-9d53-b53a475be2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147, 675, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_test = data_tensor.reshape(time,N,-1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a6a387a-f862-423c-b29f-e636c8ef507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for i in range(time):\n",
    "    y_test.append(data_test[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d2c5d2c-1b76-4022-b699-39cd13649f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147, 675])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_test = data_tensor.reshape(time,N)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf275097-975f-4812-a385-290f49d83136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147, 675, 4]), torch.Size([147, 675]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c101-5cff-4aec-9f7b-fe41c9c16b47",
   "metadata": {},
   "source": [
    "# data 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4e297-0e68-4b57-adc2-2abafc28cc03",
   "metadata": {},
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a16a8e01-944a-4b32-aba4-519372d25976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 591, 675)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_test,T_train,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c27e81db-e176-44d4-aef7-b978e6e8fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ..., 671, 672, 673],\n",
       "        [  1,   2,   3,  ..., 672, 673, 170]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = edge_index;E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8bbe9e3-5bb9-4fce-b8d0-4501388c620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "307602a2-61d2-40cd-b331-f498a8539e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 172.2000,  280.2000,  770.3000,  271.1000,  447.6000,  340.3000,\n",
       "         364.5000,  414.4000,  516.6000,  554.6000,  623.4000,  392.1000,\n",
       "         629.6000,  448.6000,  399.0000,  344.9000,  809.8000,  319.0000,\n",
       "         410.5000,  416.3000,  441.1000,  485.3000,  334.6000,  297.7000,\n",
       "         170.6000,  300.6000,  219.5000,  296.9000,  275.1000,  138.7000,\n",
       "         145.8000,  296.2000,  191.6000,  144.4000,  298.3000,  276.9000,\n",
       "         207.5000,  230.6000,  238.7000,  198.0000,  414.2000,  432.6000,\n",
       "         474.2000,  161.1000,  374.6000,  604.7000,  230.1000,  193.7000,\n",
       "         214.4000,  290.9000,  198.2000,  360.8000,  201.5000,  247.3000,\n",
       "         233.4000,  307.9000,  233.5000,  414.7000,  182.9000,  198.6000,\n",
       "         296.1000,  304.6000,  332.3000,  920.9000,  431.7000,  434.5000,\n",
       "         404.8000,  437.4000,  405.3000,  408.2000,  408.8000,  637.3000,\n",
       "         734.2000,  154.7000,  174.6000,  176.3000,  205.4000,  220.5000,\n",
       "         201.3000,  447.0000,  231.8000,  167.2000,  301.9000,  211.6000,\n",
       "         610.2000,  255.3000,  395.6000,  213.6000,  329.7000,  429.5000,\n",
       "         768.5000,  377.0000,  315.9000,  421.3000,  412.1000,  315.3000,\n",
       "         493.5000,  458.0000,  425.6000,  371.1000,  391.3000,  453.9000,\n",
       "         519.2000,  694.3000,  812.5000,  230.7000,  267.7000,  764.9000,\n",
       "         874.7000,  474.3000,  292.3000,  232.3000,  248.0000,  402.8000,\n",
       "         147.3000,  243.2000,  451.8000,  226.5000,  272.8000,  327.4000,\n",
       "         458.6000,  220.6000,  328.5000,  197.0000,  480.0000,  489.1000,\n",
       "         188.0000,  277.7000,  283.7000,  176.0000,  231.4000,  340.5000,\n",
       "         229.6000,  307.6000,  400.7000,  213.2000,  337.0000,  437.8000,\n",
       "         228.7000,  263.4000,  310.2000,  299.7000,  188.1000,  240.0000,\n",
       "         177.7000,  251.0000,  199.8000,  260.9000,  297.7000,  348.4000,\n",
       "         216.2000,  151.7000,  377.2000,  320.9000,  255.8000,  175.9000,\n",
       "         179.6000,  278.1000,  140.5000,  224.3000,  169.3000,  303.8000,\n",
       "         228.3000,  217.4000,  167.0000,  180.1000,  276.0000,  463.1000,\n",
       "         404.5000,  470.3000,  343.3000,  342.6000,  712.2000,  173.4000,\n",
       "         331.6000,  293.4000,  253.3000,  215.6000,  154.9000,  337.9000,\n",
       "         228.3000,  303.3000,  310.2000,  289.8000,  332.5000,  327.2000,\n",
       "         338.2000,  269.9000,  258.7000,  391.1000,  260.0000,  290.1000,\n",
       "         242.0000,  259.4000,  219.7000,  418.6000,  230.1000,  237.1000,\n",
       "         401.3000,  327.0000,  403.7000,  341.5000,  229.9000,  146.0000,\n",
       "         280.7000,  430.8000,  179.9000,  270.6000,  201.2000,  248.8000,\n",
       "         367.3000,  399.3000,  316.0000,  274.5000,  299.7000,  221.3000,\n",
       "         274.3000,  522.5000,  305.4000,  251.8000,  324.6000,  223.9000,\n",
       "         149.8000,  169.4000,  308.7000,  198.4000,  298.4000,  197.1000,\n",
       "         202.2000,  194.9000,  200.8000,  210.1000,  200.2000,  196.9000,\n",
       "         182.5000,  206.7000,  191.3000,  117.4000,  451.9000,  228.0000,\n",
       "        1025.9000,  192.2000,  200.2000,  215.6000,  207.3000,  224.3000,\n",
       "         207.8000,  187.2000,  225.9000,  168.8000,  246.6000,  242.2000,\n",
       "         343.2000,  330.5000,  193.0000,  195.8000,  265.6000,  175.9000,\n",
       "         256.2000,  255.2000,  219.3000,  327.7000,  352.3000,  402.1000,\n",
       "         340.5000,  342.7000,  343.6000,  313.3000,  347.1000,  243.9000,\n",
       "         331.1000,  274.1000,  335.2000,  220.2000,  240.0000,  297.7000,\n",
       "         285.2000,  342.8000,  386.0000,  411.6000,  249.2000,  590.4000,\n",
       "         178.5000,  204.5000,  224.1000,  256.1000,  201.1000,  283.8000,\n",
       "         324.8000,  491.0000,  430.6000,  261.3000,  301.2000,  360.6000,\n",
       "         302.4000,  194.2000,  287.0000,  288.6000,  284.6000,  202.4000,\n",
       "          99.6000,  183.4000,  214.8000,  204.3000,  195.4000,  195.1000,\n",
       "         281.6000,  184.5000,  131.0000,  446.3000,  454.3000,  328.5000,\n",
       "         262.9000,  471.6000,  593.2000,  238.2000,  254.8000,  129.0000,\n",
       "         312.5000,  209.8000,  347.7000,  210.0000,  307.5000,  226.6000,\n",
       "         217.9000,  256.0000,  190.5000,  268.9000,  282.1000,  215.5000,\n",
       "         579.9000,  342.9000,  176.4000,  381.2000,  277.4000,  274.7000,\n",
       "         226.8000,  847.3000,  438.6000,  305.4000,  258.9000,  199.7000,\n",
       "         291.3000,  220.5000,  418.7000,  299.1000,  385.1000,  236.4000,\n",
       "         547.3000,  209.0000,  220.4000,  433.8000,  237.4000,  220.2000,\n",
       "         249.2000,  163.6000,  368.6000,  280.2000,  439.4000,  348.5000,\n",
       "         147.8000,  396.4000,  256.3000,  324.3000,  374.4000, 1034.0000,\n",
       "        1864.1000,  252.5000,  615.6000,  157.9000,  139.5000,  227.8000,\n",
       "         238.5000,  226.2000,  788.5000,  669.9000,  105.8000,  195.9000,\n",
       "         368.7000,  356.4000,  305.6000,  276.9000,   23.8000, 1239.8000,\n",
       "         331.6000,  317.9000,  292.7000,  302.9000,  190.6000,  330.5000,\n",
       "         293.1000,  365.8000,  528.4000,  283.9000,  208.0000,  396.0000,\n",
       "         477.4000,  247.4000,  206.2000,  373.7000,  234.8000,  408.8000,\n",
       "         268.4000,  244.3000,  379.4000,  324.7000,  380.4000,  373.7000,\n",
       "         434.4000,  318.6000,  273.4000,  292.6000,  207.7000,  308.4000,\n",
       "         240.2000,  351.9000,  208.4000,  370.7000,  242.9000,  304.0000,\n",
       "         328.3000,  193.4000,  271.0000,  268.3000,  204.6000,  352.3000,\n",
       "         203.8000,  438.9000,  277.6000,  190.7000,  390.7000,  358.9000,\n",
       "         237.7000,  205.2000,  157.2000,  410.3000,  214.0000,  259.6000,\n",
       "         229.0000,  283.2000,  321.3000,  174.8000,  197.3000,  248.7000,\n",
       "         329.3000,  206.8000,  170.0000,  223.1000,  380.5000,  339.3000,\n",
       "         317.4000,  318.4000,  209.3000,  288.0000,  434.7000,  292.0000,\n",
       "         281.4000,  798.7000,  821.4000,  268.5000,  190.3000,  566.7000,\n",
       "         307.0000,  205.9000,  219.5000,  523.8000,  317.4000,  267.9000,\n",
       "         192.1000,  240.0000,  165.2000,  402.9000,  340.3000,  521.4000,\n",
       "         352.1000,  221.8000,  408.0000,  373.7000,  209.3000,  191.0000,\n",
       "         325.7000,  214.1000,  208.3000,  187.6000,  210.7000,  218.5000,\n",
       "         204.1000,  195.9000,  115.5000,  300.6000,  250.6000,  164.6000,\n",
       "         261.3000,  116.5000,  315.5000,  128.0000,  281.3000,  208.7000,\n",
       "         587.9000,  222.2000,  195.6000,  249.8000,  187.0000,  198.0000,\n",
       "         260.9000,  154.8000,  259.6000,  282.9000,  200.8000,  202.1000,\n",
       "         183.5000,  173.8000,  192.0000,  302.4000,  205.6000,  187.3000,\n",
       "         198.4000,  207.4000,  465.6000,  232.2000,  196.7000,  256.9000,\n",
       "         452.0000,  269.7000,  628.0000,  322.4000,  615.2000,  393.3000,\n",
       "         336.2000,  206.5000,   75.8000,  146.4000,  198.3000,  210.9000,\n",
       "         288.3000,  219.1000,  378.4000,  190.2000,  240.6000,  152.5000,\n",
       "         148.2000,  208.6000,  206.4000,  161.7000,  326.5000,  325.7000,\n",
       "         232.2000,  216.9000,  206.5000,  308.3000,  200.0000,  201.8000,\n",
       "        1250.2000,  235.9000,  301.6000,  195.1000,  204.5000,  296.7000,\n",
       "         265.8000,  206.4000,  622.3000,  250.6000,  282.7000,  271.0000,\n",
       "         185.1000,  378.6000,  172.8000,  305.9000,  346.8000,  321.1000,\n",
       "         312.4000,  326.2000,  380.5000,  313.6000,  288.5000,  304.5000,\n",
       "         293.9000,  346.9000,  315.4000,  322.5000,  243.9000,  189.0000,\n",
       "         335.7000,  204.7000,  576.5000,  183.3000,  231.8000,  211.9000,\n",
       "         347.3000,  193.1000,  370.0000,  235.9000,  187.2000,  222.6000,\n",
       "         245.3000,  280.5000,  316.5000,  206.7000,  446.4000,  242.9000,\n",
       "         483.2000,  270.4000,  397.3000,  265.0000,  262.0000,  376.3000,\n",
       "         354.1000,  204.1000,  181.4000,  520.8000,  214.4000,  203.1000,\n",
       "         216.3000,  353.2000,  564.9000, 1531.9000,  509.6000, 1991.3000,\n",
       "         816.2000,  461.7000,  217.1000,  703.1000,  384.4000,  329.3000,\n",
       "         321.6000,  210.2000,  321.2000,  194.6000,  139.5000,  374.0000,\n",
       "         481.7000,  451.8000,  218.0000,  500.6000,  412.8000,  335.0000,\n",
       "         347.7000,  257.2000,  335.2000,  235.6000,  222.7000,  233.7000,\n",
       "         186.8000,  290.0000,  350.8000,  397.0000,  316.2000,  374.9000,\n",
       "         199.9000,  220.9000,  199.5000,  667.0000,  530.8000,  341.5000,\n",
       "         320.6000,  222.1000,  214.0000,  329.6000,  270.5000,  185.0000,\n",
       "         128.9000,  185.2000,  262.5000,  253.8000,  223.4000,  214.3000,\n",
       "         467.1000,  227.2000,  204.2000,  487.2000,  272.5000,  284.6000,\n",
       "         168.2000,  471.6000,  341.3000,  198.0000,  282.4000,  206.4000,\n",
       "         200.5000,  234.8000,  305.3000,  179.6000,  313.7000,  288.7000,\n",
       "         251.8000,  132.4000,  212.9000,  193.6000,  507.5000,  173.0000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed58fa-3cd6-428b-a6d0-52e3460d9e1f",
   "metadata": {},
   "source": [
    "`-` train / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829a2c68-3ed8-4c46-909e-fae75875f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f = torch.concat([x_train[:-1,:,0], x_train[-1,:,:].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15c3eae0-fc4e-4b51-aefd-b78e067d9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_f = torch.concat([x_test[:-1,:,0], x_train[-1,:,:].T])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ecff-ebeb-4d3f-97de-297aa69aa487",
   "metadata": {},
   "source": [
    "# Random Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9c2d697-7649-4ed0-a0c7-e4b66c4fd45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Missing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.N = N\n",
    "        self.number = []\n",
    "    def miss(self,percent=0.5):\n",
    "        self.missing = copy.deepcopy(self.df)\n",
    "        self.percent = percent\n",
    "        for i in range(self.N):\n",
    "            #self.seed = np.random.choice(1000,1,replace=False)\n",
    "            #np.random.seed(self.seed)\n",
    "            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n",
    "            self.missing[self.number[i],i] = float('nan')\n",
    "    def first_mean(self):\n",
    "        self.train_mean = np.array(copy.deepcopy(self.missing))\n",
    "        for i in range(self.N):\n",
    "            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n",
    "    def second_linear(self):\n",
    "        self.train_linear = pd.DataFrame(self.missing.tolist())\n",
    "        self.train_linear.interpolate(method='linear', inplace=True)\n",
    "        self.train_linear = self.train_linear.fillna(0)\n",
    "        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25ad1659-237e-4130-aaa6-1bd75a841e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n",
    "\n",
    "rate = [i/10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9d407-a7b9-4d9c-90cf-390558a2a54d",
   "metadata": {},
   "source": [
    "# Class code by Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a576f-5751-460a-a374-8bf2f81d3e1c",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b18f97f-1fff-4d70-8d46-39416d954b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[j:(len(interpolated_signal) - self.lag + 1 +j),:] for j in range(self.lag)],axis = -1)).float()\n",
    "            y = torch.tensor(interpolated_signal[self.lag:,:]).float()\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            for epoch in range(50):\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):\n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_stgcn = (((self.real_y-yhat.squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_stgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "    \n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08d9a7-1069-4489-9ba2-fcc79361f45c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64c6ba31-a25e-405c-a410-4292d11a6da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESTGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            signal = interpolated_signal.copy()\n",
    "            for epoch in range(50):\n",
    "                signal = update_from_freq_domain(signal,missing_index)\n",
    "                X = torch.tensor(np.stack([signal[i:(T_train+epoch+i),:] for i in range(self.lag)],axis = -1)).reshape(-1,N,self.lag).float()\n",
    "                y = torch.tensor(signal).reshape(-1,N,1).float()[self.lag:,:,:]\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):        \n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_estgcn = (((self.real_y-yhat[:T_train,:].squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_estgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a30f7a-7435-4a8a-8685-a672b75e5764",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2768a07-6c2e-4232-8019-e94bd7dc2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63fcce33-58b6-4554-a297-aa4e6d3de83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: igraph\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: wordcloud\n",
      "\n",
      "R[write to console]: Loading required package: RColorBrewer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(GNAR)\n",
    "library(igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14d0be46-6771-456f-8631-63b040a834b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNAR = importr('GNAR') # import GNAR \n",
    "igraph = importr('igraph') # import igraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75b50b1f-e8bf-49d2-a2c5-a790edb0cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.zeros((N,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "037ccd50-0c8e-4594-9a84-caef6a766b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(edge_index[0])):\n",
    "    w[edge_index[0][k],edge_index[1][k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc149481-7248-4d81-8346-29365afc9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = robjects.r.matrix(FloatVector(w), nrow = N, ncol = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec363634-a385-4630-bd95-6c5dc578d4ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNAR_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.yy = torch.tensor(y_test).float()\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[i:(T_train+i),:] for i in range(self.lag)],axis = -1)).float()\n",
    "\n",
    "            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = T_train, ncol = N),net = GNAR.matrixtoGNAR(m), alphaOrder = 4, betaOrder = FloatVector([1, 1, 1, 1]))             \n",
    "            predict = GNAR.predict_GNARfit(answer,n_ahead=T_test)\n",
    "\n",
    "\n",
    "            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,N))**2).mean()\n",
    "            test_mse_total_gnar = ((self.yy - pd.DataFrame(predict).values.reshape(-1,N))**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423800d-629b-4e4a-8452-3285f5caecd8",
   "metadata": {},
   "source": [
    "## STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8e2d68b-4e7d-4b53-9250-94b3188a13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'MontevideoBus'\n",
    "Method = 'stgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4b9f59e-358d-4d64-997b-47040420bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stgcn= pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410de529-e1ec-4315-b250-c76f0f1437ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    stgcn.iter()\n",
    "    df_add = stgcn.df.copy()\n",
    "    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a4cd8-8420-4e85-a3ba-2ea115046627",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_stgcn, './data/EnglandCovid_stgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b0839-0ce0-4e9c-9117-55edbfb8b56e",
   "metadata": {},
   "source": [
    "## Enhencement of STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cde8e-4610-475d-bbb6-657161d373b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'MontevideoBus'\n",
    "Method = 'estgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bbfa2c-414d-407f-ad16-ca376bea8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estgcn = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b1708-bd3b-4ee2-8fec-0c38f39ba967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    estgcn.iter()\n",
    "    df_add = estgcn.df.copy()\n",
    "    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94d4fe-824e-44be-a336-30a87ea90ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_estgcn, './data/EnglandCovid_estgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f435b52-7a28-4f9c-8876-92532e600406",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc596277-a478-452d-8562-a63da5917aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'MontevideoBus'\n",
    "Method = 'gnar' # 'stgcn','estgcn','gnar'  \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = None # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196555b-5466-447f-a3be-97c575467f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnar = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199d167-0bc0-4e31-9852-27a57dbabde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    gnar = GNAR_Missing(Dataset, df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    gnar.iter()\n",
    "    df_add = gnar.df.copy()\n",
    "    df_gnar = pd.concat([df_gnar,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d81f39-8c51-473f-b9c1-431372106038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_gnar, './data/EnglandCovid_gnar_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1c4f7-cb66-4d83-8f83-848a634ae702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

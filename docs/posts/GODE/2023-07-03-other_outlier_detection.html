<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.527">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2023-07-03">

<title>Seoyeon’s Blog for study - Other Outlier Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for study</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/blog/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Posts</li><li class="breadcrumb-item"><a href="../../posts/GODE/index.html">GODE</a></li><li class="breadcrumb-item"><a href="../../posts/GODE/2023-07-03-other_outlier_detection.html">Other Outlier Detection</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">CAM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-08-28-HCAM_random_old.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>HCAM random</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-09-15-CAM-Original_rst.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>Original CAM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-09-16-Grad_CAM_rst.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>Grad CAM(Original, Randombox)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-09-19-HCAM_original.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>HCAM original</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-09-21-CAM_chest_xray.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>chest xray</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-09-23-HCAM_hy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>HCAM_ebayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-10-18-CAM_Other_Methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>Other Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-10-31-HCAM_Other_Methods_chest_xray.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>other methods chest xray</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-11-09-CAM_Scorecam_rst.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>Score CAM(Original, Randombox)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/CAM/2023-11-29-HCAM_Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[CAM]</strong>HCAM Tutorial</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">FRAUD</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/FRAUD/2023-07-10-fraud_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fraud data</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GCN/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GCN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-07-torchgcn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TORCH_GEOMETRIC.NN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-21-ST-GCN_Dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PyTorch ST-GCN Dataset</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-28-gcn_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation of geometric-temporal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-29-STGCN-tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[IT-STGCN]</strong> STGCN 튜토리얼</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-05-GNAR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GNAR data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-11-Algorithm_EX_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GCN Algorithm Example 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-18-Algorithm_traintest_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2nd ST-GCN Example dividing train and test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-20-Algorithm_traintest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1st ST-GCN Example dividing train and test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-21-Class.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method(GNAR) lag 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method(WikiMath) lag 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-guebin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method(GNAR) lag 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method(GNAR) lag 1 80% Missing repeat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class of Method(WikiMath) lag 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1st ITSTGCN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2nd ITSTGCN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SY 1st ITSTGCN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-17-ITSTGCN-Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ITSTGCN-Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-20-data load, data save as pickle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">data load, data save as pickle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation_boxplot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-06-METRLADatasetLoader.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">METRLADatasetLoader-Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-25-note_matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Note_weight amatrix</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-simulation_table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation Tables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toy Example Note</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-29-pedalme_GSO_st.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Padalme GSO_st</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Questions of PyTorch Geometric Temporal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-06-article_refer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ITSTGCN Article Refernece</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-CPUvsGPU.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PyG Geometric Temporal CPU vs GPU</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-PyGGeometricTemporalEx.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PyG Geometric Temporal Examples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GConvGRU_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GConvGRU and GNAR_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GConvGRU_Simulation Boxplot_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Adding the RecurrentGCN models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GConvLSTM_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GConvLSTM_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GCLSTM_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GCLSTM_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DCRNN_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DCRNN_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LRGCN_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LRGCN_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TGCN_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TGCN_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EvolveGCNO_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EvolveGCNO_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DYGRENCODER_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape (SEOYEON CHOI's conflicted copy 2023-09-27).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DYGRENCODER_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DYGRENCODER_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EvolveGCNH_Simulation_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EvolveGCNH_Simulation Tables_reshape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-04-toy_example_figure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toy Example Figure(Intro)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-08-toy_example_using_gnar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toy example using GNAR</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-17-toy_example_guebin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toy example using GNAR</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-18-EbayesThresh toy ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EbayesThresh Toy ex</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-18-Self Consistency toy ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Self Consistency Toy ex</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-08-25-batch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SimualtionPlanner-Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-22-Baseline_SimulationPlanner-Tutorial_test_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SimualtionPlanner-Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-05-31-Other Method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ITSTGCN add Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-07-05-ITSTGCN_data_management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data management for ITSTGCN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-07-20-ITSTGCN_data_magement_figure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data management Figure for ITSTGCN</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GODE/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GODE</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-09-02-paper_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-10-02-Earthquake_real.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Earthquake</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-11-19-class_code_for_paper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Class code for Comparison Study</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-01-graph_code_guebin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph code</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-16-linspace.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">linspace</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-27-DFT_study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discrete Fourier Transform</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-22-comparison_earthquake.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comparison Results on Real Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-27-Linear_graph_code_for_paper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Graph code for Paper</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-07-03-other_outlier_detection.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Other Outlier Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-08-05-semifinal_simulation_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semifinal_Other Outlier Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-08-16-final GODE code(paper).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">final GODE code(paper)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-08-16-options.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The options of Outlier Detection method</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-10-20-final_GODE_code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong><a href="#gode">GODE</a></strong>final GODE code</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-11-03-final_graph_code_for_paper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><a href="#gode">GODE</a>Final Graph code for GODE Paper</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-11-27-GODE_Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong><a href="#gode">GODE</a></strong>Package Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-11-29-PR_Other Methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong><a href="#gode">GODE</a></strong>GODE Other Methods</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/RESEARCHES/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RESEARCHES</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-07-07-Stock_Crawling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stock Crawling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-07-08-stock_on_graph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stock on Graph</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-07-22-ls2.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PyG lesson2: 벤치마크 데이터셋 (train/test분리)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-08-26-zero-shot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[LLM]</strong>Zeroshot</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-09-07-ANOMALOUS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[ANOMALOUS]</strong>Graph</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-09-08-llama2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[LLM]</strong>LLAMA2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RESEARCHES/2023-10-26-pygod.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[ANOMALOUS]</strong>PYGOD</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a>
  <ul class="collapse">
  <li><a href="#class-code" id="toc-class-code" class="nav-link" data-scroll-target="#class-code">Class Code</a></li>
  <li><a href="#linear-ebayesthresh" id="toc-linear-ebayesthresh" class="nav-link" data-scroll-target="#linear-ebayesthresh">Linear EbayesThresh</a></li>
  <li><a href="#linear" id="toc-linear" class="nav-link" data-scroll-target="#linear">Linear</a>
  <ul class="collapse">
  <li><a href="#gode" id="toc-gode" class="nav-link" data-scroll-target="#gode">GODE</a></li>
  <li><a href="#lofbreunig2000lofstar" id="toc-lofbreunig2000lofstar" class="nav-link" data-scroll-target="#lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(Breunig et al. 2000)</span><span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">KNN</a></li>
  <li><a href="#cblof오류" id="toc-cblof오류" class="nav-link" data-scroll-target="#cblof오류">CBLOF(오류)</a></li>
  <li><a href="#ocsvm" id="toc-ocsvm" class="nav-link" data-scroll-target="#ocsvm">OCSVM</a></li>
  <li><a href="#mcdstar" id="toc-mcdstar" class="nav-link" data-scroll-target="#mcdstar">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar" id="toc-feature-baggingstar" class="nav-link" data-scroll-target="#feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar" id="toc-abodstar" class="nav-link" data-scroll-target="#abodstar">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar" id="toc-iforeststar" class="nav-link" data-scroll-target="#iforeststar">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar" id="toc-hbosstar" class="nav-link" data-scroll-target="#hbosstar">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar" id="toc-sosstar" class="nav-link" data-scroll-target="#sosstar">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaal" id="toc-so_gaal" class="nav-link" data-scroll-target="#so_gaal">SO_GAAL</a></li>
  <li><a href="#mo_gaalstar" id="toc-mo_gaalstar" class="nav-link" data-scroll-target="#mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar" id="toc-lscpstar" class="nav-link" data-scroll-target="#lscpstar">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#linear-result" id="toc-linear-result" class="nav-link" data-scroll-target="#linear-result">Linear Result</a></li>
  <li><a href="#orbit-ebayesthresh" id="toc-orbit-ebayesthresh" class="nav-link" data-scroll-target="#orbit-ebayesthresh">Orbit EbayesThresh</a></li>
  <li><a href="#orbit" id="toc-orbit" class="nav-link" data-scroll-target="#orbit">Orbit</a>
  <ul class="collapse">
  <li><a href="#gode-1" id="toc-gode-1" class="nav-link" data-scroll-target="#gode-1">GODE</a></li>
  <li><a href="#lofstar" id="toc-lofstar" class="nav-link" data-scroll-target="#lofstar">LOF<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn-1" id="toc-knn-1" class="nav-link" data-scroll-target="#knn-1">KNN</a></li>
  <li><a href="#cblof" id="toc-cblof" class="nav-link" data-scroll-target="#cblof">CBLOF</a></li>
  <li><a href="#ocsvm-1" id="toc-ocsvm-1" class="nav-link" data-scroll-target="#ocsvm-1">OCSVM</a></li>
  <li><a href="#mcdstar-1" id="toc-mcdstar-1" class="nav-link" data-scroll-target="#mcdstar-1">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar-1" id="toc-feature-baggingstar-1" class="nav-link" data-scroll-target="#feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar-1" id="toc-abodstar-1" class="nav-link" data-scroll-target="#abodstar-1">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar-1" id="toc-iforeststar-1" class="nav-link" data-scroll-target="#iforeststar-1">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar-1" id="toc-hbosstar-1" class="nav-link" data-scroll-target="#hbosstar-1">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar-1" id="toc-sosstar-1" class="nav-link" data-scroll-target="#sosstar-1">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaalstar" id="toc-so_gaalstar" class="nav-link" data-scroll-target="#so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#mo_gaalstar-1" id="toc-mo_gaalstar-1" class="nav-link" data-scroll-target="#mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar-1" id="toc-lscpstar-1" class="nav-link" data-scroll-target="#lscpstar-1">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#orbit-result" id="toc-orbit-result" class="nav-link" data-scroll-target="#orbit-result">Orbit Result</a></li>
  <li><a href="#bunny" id="toc-bunny" class="nav-link" data-scroll-target="#bunny">Bunny</a>
  <ul class="collapse">
  <li><a href="#bunny-저장용" id="toc-bunny-저장용" class="nav-link" data-scroll-target="#bunny-저장용">bunny 저장용</a></li>
  <li><a href="#gode-2" id="toc-gode-2" class="nav-link" data-scroll-target="#gode-2">GODE</a></li>
  <li><a href="#lof" id="toc-lof" class="nav-link" data-scroll-target="#lof">LOF</a></li>
  <li><a href="#knn-2" id="toc-knn-2" class="nav-link" data-scroll-target="#knn-2">KNN</a></li>
  <li><a href="#cblof-1" id="toc-cblof-1" class="nav-link" data-scroll-target="#cblof-1">CBLOF</a></li>
  <li><a href="#ocsvm-2" id="toc-ocsvm-2" class="nav-link" data-scroll-target="#ocsvm-2">OCSVM</a></li>
  <li><a href="#mcd" id="toc-mcd" class="nav-link" data-scroll-target="#mcd">MCD</a></li>
  <li><a href="#feature-bagging" id="toc-feature-bagging" class="nav-link" data-scroll-target="#feature-bagging">Feature Bagging</a></li>
  <li><a href="#abod" id="toc-abod" class="nav-link" data-scroll-target="#abod">ABOD</a></li>
  <li><a href="#iforest" id="toc-iforest" class="nav-link" data-scroll-target="#iforest">IForest</a></li>
  <li><a href="#hbos" id="toc-hbos" class="nav-link" data-scroll-target="#hbos">HBOS</a></li>
  <li><a href="#sos" id="toc-sos" class="nav-link" data-scroll-target="#sos">SOS</a></li>
  <li><a href="#so_gaal-1" id="toc-so_gaal-1" class="nav-link" data-scroll-target="#so_gaal-1">SO_GAAL</a></li>
  <li><a href="#mo_gaal" id="toc-mo_gaal" class="nav-link" data-scroll-target="#mo_gaal">MO_GAAL</a></li>
  <li><a href="#lscp" id="toc-lscp" class="nav-link" data-scroll-target="#lscp">LSCP</a></li>
  </ul></li>
  <li><a href="#bunny-result" id="toc-bunny-result" class="nav-link" data-scroll-target="#bunny-result">Bunny Result</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2023-07-03-other_outlier_detection.out.ipynb" download="2023-07-03-other_outlier_detection.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Posts</li><li class="breadcrumb-item"><a href="../../posts/GODE/index.html">GODE</a></li><li class="breadcrumb-item"><a href="../../posts/GODE/2023-07-03-other_outlier_detection.html">Other Outlier Detection</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Other Outlier Detection</h1>
  <div class="quarto-categories">
    <div class="quarto-category">GODE</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>SEOYEON CHOI </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 3, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>knn, cblof, ocsvm 을 제외한 이상치 탐지 기법들에 데이터 집합에서 이상치 비율을 지정할 수 있는 옵션이 존재하였음.</p>
<p>default값은 10%인데, ABOD 방법에서는 5로 지정해주었고, 다른 방법들은 default인 10%가 들어갔다.</p>
<p>일단 우리 방법이랑 비교해서 좋은지 보기</p>
</div>
</div>
<p>iter</p>
<ul>
<li>LOF, CBLOF, OCSVM, MCD</li>
</ul>
<p>iter x - kNN, Feature Bagging, ABOD, Isolation, HBOS, SOS, SO-GAAL, MO-GAAL, LSCP</p>
<ul>
<li>Simple Linear</li>
</ul>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(5,7)\)</span> and <span class="math inline">\(U(-7,-5)\)</span>.</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.930</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;"><strong>0.988</strong></td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.889</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.883</td>
<td style="text-align: center;">0.938</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.896</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
</tbody>
</table>
<div id="f3b9cff9-e91b-4031-ab9c-106952e7220e" class="cell" data-execution_count="1628">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1628">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.998</td>
<td>0.999</td>
<td>0.999</td>
<td>0.999</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.926</td>
<td>0.961</td>
<td>0.961</td>
<td>0.961</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.950</td>
<td>1.000</td>
<td>0.947</td>
<td>0.973</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.935</td>
<td>0.991</td>
<td>0.940</td>
<td>0.965</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.998</td>
<td>0.999</td>
<td>0.999</td>
<td>0.999</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.986</td>
<td>0.993</td>
<td>0.993</td>
<td>0.993</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.868</td>
<td>0.999</td>
<td>0.862</td>
<td>0.925</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.960</td>
<td>0.978</td>
<td>0.980</td>
<td>0.979</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.916</td>
<td>0.956</td>
<td>0.956</td>
<td>0.956</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.936</td>
<td>0.966</td>
<td>0.966</td>
<td>0.966</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.940</td>
<td>0.965</td>
<td>0.972</td>
<td>0.969</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>Orbit</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.997</strong></td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.998</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.886</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.892</td>
<td style="text-align: center;">0.937</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.918</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.958</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.866</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.903</td>
<td style="text-align: center;">0.928</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.979</td>
<td style="text-align: center;">0.927</td>
<td style="text-align: center;">0.952</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.378</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.514</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.876</td>
<td style="text-align: center;">0.959</td>
<td style="text-align: center;">0.908</td>
<td style="text-align: center;">0.933</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
</tbody>
</table>
<div id="f5afa463-2d56-4ec1-8121-8ae312930909" class="cell" data-execution_count="1739">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1739">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.998</td>
<td>0.999</td>
<td>0.999</td>
<td>0.999</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.954</td>
<td>0.976</td>
<td>0.976</td>
<td>0.976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.948</td>
<td>0.999</td>
<td>0.946</td>
<td>0.972</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.908</td>
<td>0.977</td>
<td>0.925</td>
<td>0.950</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.916</td>
<td>0.956</td>
<td>0.956</td>
<td>0.956</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.942</td>
<td>0.969</td>
<td>0.969</td>
<td>0.969</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.443</td>
<td>0.992</td>
<td>0.417</td>
<td>0.587</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.935</td>
<td>0.960</td>
<td>0.973</td>
<td>0.966</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.950</td>
<td>0.974</td>
<td>0.974</td>
<td>0.974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.950</td>
<td>0.950</td>
<td>1.000</td>
<td>0.974</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.950</td>
<td>0.950</td>
<td>1.000</td>
<td>0.974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>Stanford Bunny</li>
</ul>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(3,7)\)</span> and <span class="math inline">\(U(-7,-3)\)</span>.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Stanford Bunny 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.995</strong></td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.997</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.869</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.932</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.937</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.938</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.915</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.794</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.788</td>
<td style="text-align: center;">0.879</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.967</td>
</tr>
</tbody>
</table>
<div id="68beb353-ff7c-4105-8978-23ca30d5499b" class="cell" data-execution_count="1852">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1852">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.988</td>
<td>0.995</td>
<td>0.993</td>
<td>0.994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.913</td>
<td>0.955</td>
<td>0.953</td>
<td>0.954</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.942</td>
<td>0.997</td>
<td>0.942</td>
<td>0.969</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.935</td>
<td>0.992</td>
<td>0.939</td>
<td>0.965</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.982</td>
<td>0.992</td>
<td>0.989</td>
<td>0.990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.954</td>
<td>0.977</td>
<td>0.974</td>
<td>0.976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.979</td>
<td>0.990</td>
<td>0.988</td>
<td>0.989</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.827</td>
<td>0.995</td>
<td>0.822</td>
<td>0.900</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.919</td>
<td>0.958</td>
<td>0.956</td>
<td>0.957</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.912</td>
<td>0.955</td>
<td>0.953</td>
<td>0.954</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.952</td>
<td>0.952</td>
<td>1.000</td>
<td>0.975</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.952</td>
<td>0.952</td>
<td>1.000</td>
<td>0.975</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.978</td>
<td>0.990</td>
<td>0.987</td>
<td>0.989</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="import" class="level1 page-columns page-full">
<h1>Import</h1>
<div id="a07a0afa-2fcf-4a07-8718-27c1cf142a89" class="cell" data-execution_count="397">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDOneClassSVM</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> Nystroem</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2.robjects <span class="im">as</span> ro </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.vectors <span class="im">import</span> FloatVector </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.packages <span class="im">import</span> importr</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_kddcup99, fetch_covtype, fetch_openml</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tqdm</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score, accuracy_score</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.covariance <span class="im">import</span> EmpiricalCovariance, MinCovDet</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> alibi_detect.od <span class="im">import</span> IForest</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># from pyod.models.iforest import IForest</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.abod <span class="im">import</span> ABOD</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.cblof <span class="im">import</span> CBLOF</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PyNomaly <span class="im">import</span> loop</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lscp <span class="im">import</span> LSCP</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.hbos <span class="im">import</span> HBOS</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.so_gaal <span class="im">import</span> SO_GAAL</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mcd <span class="im">import</span> MCD</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mo_gaal <span class="im">import</span> MO_GAAL</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lof <span class="im">import</span> LOF</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.ocsvm <span class="im">import</span> OCSVM</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.feature_bagging <span class="im">import</span> FeatureBagging</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.sos <span class="im">import</span> SOS</span></code></pre></div>
</div>
<section id="class-code" class="level2">
<h2 class="anchored" data-anchor-id="class-code">Class Code</h2>
<div id="0c35d527-37f6-4039-b78c-4d65798813d2" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tab_linear <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>tab_orbit <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>tab_bunny <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span></code></pre></div>
</div>
<div id="2cb1b7a4-4f6e-4b6d-b403-06bec5dd20ab" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conf_matrx:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,original,compare,tab):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original <span class="op">=</span> original</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compare <span class="op">=</span> compare</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> tab</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> conf(<span class="va">self</span>,name):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conf_matrix <span class="op">=</span> confusion_matrix(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        ax.matshow(<span class="va">self</span>.conf_matrix, cmap<span class="op">=</span>plt.cm.Oranges, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span><span class="va">self</span>.conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Confusion Matrix'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.acc <span class="op">=</span> accuracy_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pre <span class="op">=</span> precision_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rec <span class="op">=</span> recall_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f1 <span class="op">=</span> f1_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.acc)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Precision: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.pre)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Recall: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.rec)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'F1 Score: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.f1)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> <span class="va">self</span>.tab.append(pd.DataFrame({<span class="st">"Accuracy"</span>:[<span class="va">self</span>.acc],<span class="st">"Precision"</span>:[<span class="va">self</span>.pre],<span class="st">"Recall"</span>:[<span class="va">self</span>.rec],<span class="st">"F1"</span>:[<span class="va">self</span>.f1]},index <span class="op">=</span> [name]))</span></code></pre></div>
</div>
<div id="007f4445-30e5-4ccf-89c5-83dccb2c560e" class="cell" data-execution_count="255">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.y1 = df.y1.to_numpy()</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> w</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)      </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.y <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.ybar,<span class="dv">0</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.yhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.ybar_threshed</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(yHat <span class="op">=</span> <span class="va">self</span>.yhat)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.y<span class="op">-</span> <span class="va">self</span>.df.yHat)</span></code></pre></div>
</div>
<div id="88737d98-ef51-41dc-b9e1-31a466c6814d" class="cell" data-execution_count="256">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Orbit:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_distance(<span class="va">self</span>):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> np.zeros([<span class="va">self</span>.n,<span class="va">self</span>.n])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        locations <span class="op">=</span> np.stack([<span class="va">self</span>.x, <span class="va">self</span>.y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm.tqdm(<span class="bu">range</span>(<span class="va">self</span>.n)):</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i,<span class="va">self</span>.n):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.D[i,j]<span class="op">=</span>np.linalg.norm(locations[i]<span class="op">-</span>locations[j])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> <span class="va">self</span>.D <span class="op">+</span> <span class="va">self</span>.D.T</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_weightmatrix(<span class="va">self</span>,theta<span class="op">=</span><span class="dv">1</span>,beta<span class="op">=</span><span class="fl">0.5</span>,kappa<span class="op">=</span><span class="dv">4000</span>):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta <span class="op">=</span> theta</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.where(<span class="va">self</span>.D <span class="op">&lt;</span> kappa,<span class="va">self</span>.D,<span class="dv">0</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.exp(<span class="op">-</span>(dist<span class="op">/</span><span class="va">self</span>.theta)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.f <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f<span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
<div id="202a6bb4-a393-40f5-9676-e166da4d1ded" class="cell" data-execution_count="257">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BUNNY:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z <span class="op">=</span> df.z.to_numpy()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.noise <span class="op">=</span> df.noise.to_numpy()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fnoise <span class="op">=</span> <span class="va">self</span>.f <span class="op">+</span> <span class="va">self</span>.noise</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> _W</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">6</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.fnoise <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fnoise <span class="op">=</span> <span class="va">self</span>.fnoise)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f <span class="op">+</span> <span class="va">self</span>.df.noise <span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
</section>
<section id="linear-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="linear-ebayesthresh">Linear EbayesThresh</h2>
<div id="8723a99b-d883-4931-8f29-ae98d8a78dcd" class="cell" data-execution_count="1882">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div id="d56587a6-64e0-4338-97d1-44aed703dba7" class="cell" data-execution_count="1883">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>signal_1 <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1 <span class="op">=</span> which(signal_1<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>x_1<span class="op">=</span>signal_1<span class="op">+</span>epsilon</span></code></pre></div>
</div>
<div id="c3b52e47-035c-4ead-896a-8467adda9f9a" class="cell" data-execution_count="1884">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x_1</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier_1</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal_1</span></code></pre></div>
</div>
<div id="00bf68c1-6fec-40c7-bc4a-3b955f2f60c9" class="cell" data-execution_count="1885">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div id="029a7685-5203-4911-a567-c2205c3c751e" class="cell" data-execution_count="1886">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index_1 <span class="op">=</span> index_of_trueoutlier_1</span></code></pre></div>
</div>
<div id="bdd6638f-8444-42b9-80ad-dfc2e7ce1268" class="cell" data-execution_count="1887">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value_1 <span class="op">=</span> x_1[index_of_trueoutlier_1]</span></code></pre></div>
</div>
<div id="2622fdf0-cb3e-4487-b5d5-4db08354039a" class="cell" data-execution_count="1888">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> signal_1.copy()</span></code></pre></div>
</div>
<div id="a542fa4f-6e9d-4167-9dd8-fca561d38960" class="cell" data-execution_count="1889">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_1))</span></code></pre></div>
</div>
</section>
<section id="linear" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="linear">Linear</h2>
<div id="0ab3daba-7732-43de-95d0-cf390fa26bf7" class="cell" data-tags="[]" data-execution_count="1890">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>_x_1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1000</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>_y1_1 <span class="op">=</span> <span class="dv">5</span><span class="op">*</span>_x_1</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>_y_1 <span class="op">=</span> _y1_1 <span class="op">+</span> x_1 <span class="co"># x is epsilon</span></span></code></pre></div>
</div>
<div id="723b062b-1b12-4dcc-b634-9d0457053c2b" class="cell" data-execution_count="1891">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>_df<span class="op">=</span>pd.DataFrame({<span class="st">'x'</span>:_x_1, <span class="st">'y'</span>:_y_1})</span></code></pre></div>
</div>
<div id="3b1a946c-1d7b-415e-bcf0-4540c9834e4a" class="cell" data-execution_count="1892">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<div id="2654bd5f-6389-4d40-88cf-cc9bcd8e7b06" class="cell" data-execution_count="1897">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># _df.to_csv('simple_linear_df.csv')</span></span></code></pre></div>
</div>
<div id="c6aefff0-4c70-4b36-bce2-0338ba357aac" class="cell" data-execution_count="1898">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one_1).to_csv('simple_linear_outlier.csv')</span></span></code></pre></div>
</div>
<section id="gode" class="level3">
<h3 class="anchored" data-anchor-id="gode">GODE</h3>
<div id="7941c63b-c687-4105-9a58-0e9e4fe9b80c" class="cell" data-execution_count="1490">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span>np.zeros((<span class="dv">1000</span>,<span class="dv">1000</span>))</span></code></pre></div>
</div>
<div id="86c5a64b-e933-418d-aa36-5b5eaeba094a" class="cell" data-execution_count="1491">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">==</span>j :</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> np.<span class="bu">abs</span>(i<span class="op">-</span>j) <span class="op">&lt;=</span> <span class="dv">1</span> : </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="0c811c7c-e92f-4d98-b2d2-e9d8bc89b5e5" class="cell" data-execution_count="1492">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>_Linear <span class="op">=</span> Linear(_df)</span></code></pre></div>
</div>
<div id="be777422-6e80-486a-b4fb-1aec996f1ef4" class="cell" data-execution_count="1499">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>_Linear.fit(sd<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div id="0f0261aa-12e2-4d78-aef5-1fc5f3c9d64d" class="cell" data-execution_count="1543">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Linear.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div id="89e033da-7ca4-48c0-aeea-98df1e82cd34" class="cell" data-execution_count="1544">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">9.8</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div id="5585f4d5-8157-4d59-b931-8fa930e8e8bd" class="cell" data-execution_count="1545">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)</span></code></pre></div>
</div>
<div id="ca39799f-e6c7-449f-8a31-78ffd9136ed8" class="cell" data-execution_count="1546">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1546">
<pre><code>950</code></pre>
</div>
</div>
<div id="ae3f2231-bc8a-48c0-a831-a521b324ab81" class="cell" data-execution_count="1547">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1547">
<pre><code>50</code></pre>
</div>
</div>
<div id="6834ed16-9cc9-46ee-9949-1fa7a7dcff7b" class="cell" data-execution_count="1548">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-33-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="6a4b0623-12d3-4c67-9b10-d8c6ddb36010" class="cell" data-execution_count="1549">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lofbreunig2000lofstar" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(<a href="#ref-breunig2000lof" role="doc-biblioref">Breunig et al. 2000</a>)</span><span class="math inline">\(\star\)</span></h3>
<div class="no-row-height column-margin column-container"><div id="ref-breunig2000lof" class="csl-entry" role="listitem">
Breunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. <span>“LOF: Identifying Density-Based Local Outliers.”</span> In <em>Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</em>, 93–104.
</div></div><div id="fbf65c36-3752-42e4-bccd-0721cacc7da0" class="cell" data-execution_count="1550">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<p>Lof 논문 원문에 따라 LOF를 계산하고, min-max 범위를 넘으면 이상치</p>
<div class="img-fluid quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figs/lof.png" class="img-fluid figure-img"></p>
<figcaption>Figure: LOF’s outliers detection method</figcaption>
</figure>
</div>
<div id="1f6e9245-d4b7-4602-b0cd-2018ca69ea0d" class="cell" data-execution_count="1551">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)</span></code></pre></div>
</div>
<div id="e87d2126-1ab0-46b6-b190-1f7aa2643797" class="cell" data-execution_count="1552">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-37-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.926
Precision: 0.961
Recall: 0.961
F1 Score: 0.961</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="b6d50d23-85eb-45bc-b95a-e364fe4220ac" class="cell" data-execution_count="1553">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn" class="level3">
<h3 class="anchored" data-anchor-id="knn">KNN</h3>
<div id="2f0a2af8-4d53-4fa8-afa8-fb4ddf29cfee" class="cell" data-execution_count="1554">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span></code></pre></div>
</div>
<div id="3b8ecf2f-957d-4ab8-9031-348171423c54" class="cell" data-tags="[]" data-execution_count="1555">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p>k번째 이상은 outlier로 본다.</p>
<p><strong>이상치 비율 정하지 않음</strong></p>
<p>Three kNN detectors are supported:</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the outlier score</li>
</ul>
<div id="ed8b8fc2-d1d9-49c0-8ba2-bd942a31423d" class="cell" data-execution_count="1556">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="086bb2c4-8073-4cac-994f-996ae06657d0" class="cell" data-execution_count="1557">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div id="e6faebfe-7548-4d8f-8549-2d2d1b3530eb" class="cell" data-execution_count="1558">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)</span></code></pre></div>
</div>
<div id="046c293d-1ea8-46ef-a729-cf261f659807" class="cell" data-execution_count="1559">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-44-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 1.000
Recall: 0.947
F1 Score: 0.973</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="4132e0a6-02df-40d6-be56-99d0c9e2ad0a" class="cell" data-execution_count="1560">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof오류" class="level3">
<h3 class="anchored" data-anchor-id="cblof오류">CBLOF(오류)</h3>
<div id="90662a03-66a3-40c9-b638-3a8747b352f3" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div id="153172e0-038d-4fc9-a7af-f481661a786d" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span>  pd.read_csv(<span class="st">'simple_linear_df.csv'</span>)</span></code></pre></div>
</div>
<div id="cc05f817-077c-46d9-8e4d-0dc7e4198b45" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> pd.read_csv(<span class="st">'simple_linear_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].tolist()</span></code></pre></div>
</div>
<div id="b9dc9a67-d497-43b8-a645-ecadd1e933cc" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div id="5c678214-8b07-478b-afbe-a36b18e4e3fc" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div id="43315436-c387-40ec-8044-637a9b5ce503" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-51-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.972
Precision: 0.985
Recall: 0.985
F1 Score: 0.985</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<div id="11577e1e-178e-41bc-a935-0231159518dd" class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
</div>
<ul>
<li>Accuracy: 0.972</li>
<li>Precision: 0.985</li>
<li>Recall: 0.985</li>
<li>F1 Score: 0.985</li>
</ul>
</section>
<section id="ocsvm" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm">OCSVM</h3>
<p>default=10%</p>
<div id="92a9370a-0a6d-48d0-a7dd-7d861a54a965" class="cell" data-execution_count="1562">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div id="f1b6ba1d-acd4-47e8-afb9-f3596f8a594c" class="cell" data-execution_count="1563">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1563">
<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div id="b045b365-2a1e-4864-933d-0627ebb1e284" class="cell" data-execution_count="1564">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div id="42be82d2-be59-4a39-a1b8-bb2740eb4cc1" class="cell" data-execution_count="1565">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)</span></code></pre></div>
</div>
<div id="d1fa5c0e-ca21-48d6-a236-61228979cd4d" class="cell" data-execution_count="1566">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-57-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.991
Recall: 0.940
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="b6d6abf2-3136-4015-9caa-933a0b8a0e91" class="cell" data-execution_count="1567">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcdstar" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar">MCD<span class="math inline">\(\star\)</span></h3>
<div id="752671f8-a722-4246-8b27-7d4656f44e38" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1568">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="b18b17b4-3cf9-4cb1-8d31-2a9ef92d44b7" class="cell" data-execution_count="1569">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="f36beccd-824e-438f-b2d7-47bd8c62438e" class="cell" data-execution_count="1570">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div id="42c5b9f5-6e96-4b9d-8a6e-e2b2deee33f7" class="cell" data-execution_count="1571">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)</span></code></pre></div>
</div>
<div id="7f6e8752-b7a7-4f14-81e7-64f3ec1a638f" class="cell" data-execution_count="1572">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-63-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="4cdd361e-8e0b-4151-8a03-82f116f6604f" class="cell" data-execution_count="1573">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-baggingstar" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<p>default값은 10%로 설정되어 있었고, 5%로 지정한 결과, 평가지표값이 전반적으로 1%이상 낮아졌다.</p>
<div id="6b6f574b-efb7-4166-b3a0-ecbe7180837d" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1574">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="d1fcff2f-f3cf-4224-84b4-1af9cbd95c58" class="cell" data-execution_count="1575">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="cb6af11e-b54c-469e-8958-e54bf8775935" class="cell" data-execution_count="1576">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div id="e078354e-30de-45b2-a62c-467c162c2408" class="cell" data-execution_count="1577">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)</span></code></pre></div>
</div>
<div id="5b4274c8-ed10-4a9a-b0c7-971c00a63052" class="cell" data-execution_count="1578">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-69-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.986
Precision: 0.993
Recall: 0.993
F1 Score: 0.993</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="4c090c99-a516-4d65-8054-1d9b8af3c2be" class="cell" data-execution_count="1579">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abodstar" class="level3">
<h3 class="anchored" data-anchor-id="abodstar">ABOD<span class="math inline">\(\star\)</span></h3>
<p>default 값이 5%이며, 이미 지정된 채려 시뮬레이션 돌림</p>
<div id="fe44106d-3f42-4d2d-8247-aac18a9d6b53" class="cell" data-execution_count="1580">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p><strong>contamination</strong> : float in (0., 0.5), optional (default=0.1)</p>
<ul>
<li>The amount of contamination of the data set, i.e.</li>
<li>the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.</li>
</ul>
<div id="718bd8c6-ad4c-4b10-bf7d-d15f49159ff1" class="cell" data-execution_count="1581">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="9430c793-c89e-4274-9622-13d04ed7406c" class="cell" data-execution_count="1582">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div id="36be755d-a7e9-4855-bc93-f30e6088df5e" class="cell" data-execution_count="1583">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)</span></code></pre></div>
</div>
<div id="7bc8f40d-a585-40ab-a8ce-b7e10263c7a7" class="cell" data-execution_count="1584">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-75-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="cb79803f-1bf1-4294-81e1-db2cd98f4af6" class="cell" data-execution_count="1585">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="iforeststar" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar">IForest<span class="math inline">\(\star\)</span></h3>
<p>n_estimators Number of base estimators in the ensemble.</p>
<ul>
<li>n이 총 1000개니까 5%인 50 지정해줄 수 있음</li>
</ul>
<div id="acf903c6-90e1-40ba-b85d-01c351628038" class="cell" data-execution_count="1586">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="3efe5b39-8954-4db6-86e1-24c2bca88223" class="cell" data-execution_count="1587">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span></code></pre></div>
</div>
<div id="6b02a0ac-ee37-4ff7-b1b6-3e2ac4de39ba" class="cell" data-execution_count="1588">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>]],</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="58fa6202-ba82-45dd-9607-eb69680a0de3" class="cell" data-execution_count="1589">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div id="4983467a-e00e-4e70-bba7-3038346fe3b3" class="cell" data-execution_count="1590">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div id="47855d84-4ddb-40f5-a850-0f8bad57a52f" class="cell" data-execution_count="1591">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div id="6e1dacb7-3e8f-439f-9da6-38db8622bce7" class="cell" data-execution_count="1592">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)</span></code></pre></div>
</div>
<div id="a91ec2b8-3d1a-4f62-aa65-6b6172971c35" class="cell" data-execution_count="1593">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-84-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.868
Precision: 0.999
Recall: 0.862
F1 Score: 0.925</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="5d54172f-7626-4392-a336-33e9799c7d21" class="cell" data-execution_count="1594">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbosstar" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar">HBOS<span class="math inline">\(\star\)</span></h3>
<p>default값은 이상치값을 10%로 지정하였으며, 5%로 지정한 결과 값 다 작아짐</p>
<div id="56d6c47d-ffab-4d66-b645-f2ccc2bd287f" class="cell" data-execution_count="1595">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="b454d8d5-49e4-4a93-b274-9f9f51b3b72a" class="cell" data-execution_count="1596">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="0c26e28d-417f-44d2-bc45-9a7f1d87a7ba" class="cell" data-execution_count="1597">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div id="98ce6a88-fc1b-4a11-9fd1-994e174741e5" class="cell" data-execution_count="1598">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)</span></code></pre></div>
</div>
<div id="9eeacd94-89e8-49f0-a51a-63edefde43df" class="cell" data-execution_count="1599">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-90-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.960
Precision: 0.978
Recall: 0.980
F1 Score: 0.979</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="f6aa48af-70a4-42b4-bdbb-7e7db4e590f6" class="cell" data-execution_count="1600">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sosstar" class="level3">
<h3 class="anchored" data-anchor-id="sosstar">SOS<span class="math inline">\(\star\)</span></h3>
<p>default 는 10%</p>
<div id="3cbfd4f3-2e9c-4639-a441-b9a266b7c2c8" class="cell" data-execution_count="1601">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="860d1fa3-8b82-42b6-930a-f7f79ef633fe" class="cell" data-execution_count="1602">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="920f0102-efce-4f5a-96d1-ae06ef2f1b83" class="cell" data-execution_count="1603">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div id="71368535-c659-42e7-9d44-92c437591ca5" class="cell" data-execution_count="1604">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)</span></code></pre></div>
</div>
<div id="d09f9eb5-9451-4a4f-83ed-49d4427901d0" class="cell" data-execution_count="1605">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-96-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="3732bcc6-24a8-43a8-8f98-d596c35a524f" class="cell" data-execution_count="1606">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaal" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal">SO_GAAL</h3>
<div id="98428fce-c7d8-4c30-8c61-0a3ea25bf597" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1607">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3130

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.3524
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3562

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3857
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3845

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3516
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3861

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4008
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3870

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4348
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.3913

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4431
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4510

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4427
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.4704

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4752
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4794

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4972
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4998

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.5168
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5228

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.5560
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5677

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.4929
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5675

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5508
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5679

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5563
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5806

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.5637
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5749

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6370
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6088

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6408
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6699

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5958
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5661

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.6471
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.6815

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6419
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6967

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7016
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6348

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 5ms/step - loss: 1.6519
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6470

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6582
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6890

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7197
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7613

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7085
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6933

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7013
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7330

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7275
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7635

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7682
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.8321

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7557
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.7231

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7787
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.7553

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7782
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7678

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8069
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.7798

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8038
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.8120

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7591
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.8204

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8033
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8414

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.7215
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8414

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8143
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.8406

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.8562
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8167

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8597
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
</div>
<div id="5179dd6c-fb20-4362-ab41-6339408e8827" class="cell" data-execution_count="1608">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="1f5d0584-9632-447d-a5d3-2529b3c41b49" class="cell" data-execution_count="1609">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div id="639307be-7900-4259-816a-fe6da25ed1dc" class="cell" data-execution_count="1610">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div id="c3ffdbfe-2f54-4717-b1be-1fa38eb69e2f" class="cell" data-execution_count="1611">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-102-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.936
Precision: 0.966
Recall: 0.966
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="95415640-8335-414b-9a35-2825561281c0" class="cell" data-execution_count="1612">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div id="a8cb0a21-0444-4613-8b92-1d069d9b3575" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1613">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 658us/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 865us/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 597us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 623us/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 597us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 605us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 810us/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 613us/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 610us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 624us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 597us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 833us/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 600us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 614us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 635us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 619us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 610us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 610us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 613us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 616us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 627us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 614us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 846us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 623us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 915us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 836us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 829us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 860us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 832us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 870us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3802
16/16 [==============================] - 0s 992us/step - loss: 0.7194
16/16 [==============================] - 0s 1ms/step - loss: 0.9382
16/16 [==============================] - 0s 2ms/step - loss: 1.1679
16/16 [==============================] - 0s 1ms/step - loss: 1.2953
16/16 [==============================] - 0s 982us/step - loss: 1.3707
16/16 [==============================] - 0s 1ms/step - loss: 1.4090
16/16 [==============================] - 0s 1ms/step - loss: 1.4370
16/16 [==============================] - 0s 1ms/step - loss: 1.4481
16/16 [==============================] - 0s 1ms/step - loss: 1.4524
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3784
16/16 [==============================] - 0s 3ms/step - loss: 0.7280
16/16 [==============================] - 0s 1ms/step - loss: 0.9713
16/16 [==============================] - 0s 2ms/step - loss: 1.2091
16/16 [==============================] - 0s 1ms/step - loss: 1.3341
16/16 [==============================] - 0s 2ms/step - loss: 1.4019
16/16 [==============================] - 0s 2ms/step - loss: 1.4333
16/16 [==============================] - 0s 1ms/step - loss: 1.4551
16/16 [==============================] - 0s 1ms/step - loss: 1.4629
16/16 [==============================] - 0s 1ms/step - loss: 1.4656

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 913us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3866
16/16 [==============================] - 0s 1ms/step - loss: 0.7327
16/16 [==============================] - 0s 2ms/step - loss: 0.9839
16/16 [==============================] - 0s 5ms/step - loss: 1.2335
16/16 [==============================] - 0s 1ms/step - loss: 1.3481
16/16 [==============================] - 0s 3ms/step - loss: 1.4093
16/16 [==============================] - 0s 1ms/step - loss: 1.4348
16/16 [==============================] - 0s 2ms/step - loss: 1.4506
16/16 [==============================] - 0s 1ms/step - loss: 1.4559
16/16 [==============================] - 0s 2ms/step - loss: 1.4576
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.3956
16/16 [==============================] - 0s 1ms/step - loss: 0.7406
16/16 [==============================] - 0s 1ms/step - loss: 0.9936
16/16 [==============================] - 0s 2ms/step - loss: 1.2356
16/16 [==============================] - 0s 2ms/step - loss: 1.3418
16/16 [==============================] - 0s 1ms/step - loss: 1.3928
16/16 [==============================] - 0s 2ms/step - loss: 1.4131
16/16 [==============================] - 0s 1ms/step - loss: 1.4239
16/16 [==============================] - 0s 1ms/step - loss: 1.4275
16/16 [==============================] - 0s 1ms/step - loss: 1.4283

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 5ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3925
16/16 [==============================] - 0s 1ms/step - loss: 0.7523
16/16 [==============================] - 0s 1ms/step - loss: 1.0367
16/16 [==============================] - 0s 1ms/step - loss: 1.2950
16/16 [==============================] - 0s 2ms/step - loss: 1.3968
16/16 [==============================] - 0s 2ms/step - loss: 1.4439
16/16 [==============================] - 0s 2ms/step - loss: 1.4623
16/16 [==============================] - 0s 1ms/step - loss: 1.4710
16/16 [==============================] - 0s 2ms/step - loss: 1.4735
16/16 [==============================] - 0s 2ms/step - loss: 1.4740
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4051
16/16 [==============================] - 0s 2ms/step - loss: 0.7528
16/16 [==============================] - 0s 2ms/step - loss: 1.0473
16/16 [==============================] - 0s 1ms/step - loss: 1.2922
16/16 [==============================] - 0s 1ms/step - loss: 1.3798
16/16 [==============================] - 0s 2ms/step - loss: 1.4177
16/16 [==============================] - 0s 2ms/step - loss: 1.4316
16/16 [==============================] - 0s 2ms/step - loss: 1.4376
16/16 [==============================] - 0s 1ms/step - loss: 1.4391
16/16 [==============================] - 0s 2ms/step - loss: 1.4393

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 897us/step
16/16 [==============================] - 0s 3ms/step - loss: 0.4123
16/16 [==============================] - 0s 2ms/step - loss: 0.7576
16/16 [==============================] - 0s 2ms/step - loss: 1.0566
16/16 [==============================] - 0s 2ms/step - loss: 1.2987
16/16 [==============================] - 0s 2ms/step - loss: 1.3765
16/16 [==============================] - 0s 4ms/step - loss: 1.4095
16/16 [==============================] - 0s 2ms/step - loss: 1.4206
16/16 [==============================] - 0s 2ms/step - loss: 1.4250
16/16 [==============================] - 0s 2ms/step - loss: 1.4259
16/16 [==============================] - 0s 1ms/step - loss: 1.4259
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4149
16/16 [==============================] - 0s 2ms/step - loss: 0.7675
16/16 [==============================] - 0s 1ms/step - loss: 1.0765
16/16 [==============================] - 0s 2ms/step - loss: 1.3167
16/16 [==============================] - 0s 1ms/step - loss: 1.3880
16/16 [==============================] - 0s 1ms/step - loss: 1.4164
16/16 [==============================] - 0s 2ms/step - loss: 1.4257
16/16 [==============================] - 0s 1ms/step - loss: 1.4288
16/16 [==============================] - 0s 1ms/step - loss: 1.4294
16/16 [==============================] - 0s 1ms/step - loss: 1.4293

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 899us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4172
16/16 [==============================] - 0s 1ms/step - loss: 0.7677
16/16 [==============================] - 0s 1ms/step - loss: 1.0818
16/16 [==============================] - 0s 1ms/step - loss: 1.3143
16/16 [==============================] - 0s 1ms/step - loss: 1.3797
16/16 [==============================] - 0s 1ms/step - loss: 1.4048
16/16 [==============================] - 0s 1ms/step - loss: 1.4123
16/16 [==============================] - 0s 1ms/step - loss: 1.4147
16/16 [==============================] - 0s 2ms/step - loss: 1.4150
16/16 [==============================] - 0s 2ms/step - loss: 1.4148
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 754us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4148
16/16 [==============================] - 0s 2ms/step - loss: 0.7766
16/16 [==============================] - 0s 4ms/step - loss: 1.1064
16/16 [==============================] - 0s 2ms/step - loss: 1.3376
16/16 [==============================] - 0s 1ms/step - loss: 1.4002
16/16 [==============================] - 0s 1ms/step - loss: 1.4228
16/16 [==============================] - 0s 1ms/step - loss: 1.4290
16/16 [==============================] - 0s 1ms/step - loss: 1.4308
16/16 [==============================] - 0s 1ms/step - loss: 1.4309
16/16 [==============================] - 0s 1ms/step - loss: 1.4307

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 842us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4190
16/16 [==============================] - 0s 1ms/step - loss: 0.7761
16/16 [==============================] - 0s 2ms/step - loss: 1.1055
16/16 [==============================] - 0s 1ms/step - loss: 1.3282
16/16 [==============================] - 0s 2ms/step - loss: 1.3846
16/16 [==============================] - 0s 1ms/step - loss: 1.4044
16/16 [==============================] - 0s 2ms/step - loss: 1.4095
16/16 [==============================] - 0s 1ms/step - loss: 1.4108
16/16 [==============================] - 0s 2ms/step - loss: 1.4108
16/16 [==============================] - 0s 2ms/step - loss: 1.4105
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4225
16/16 [==============================] - 0s 1ms/step - loss: 0.7746
16/16 [==============================] - 0s 1ms/step - loss: 1.1026
16/16 [==============================] - 0s 1ms/step - loss: 1.3159
16/16 [==============================] - 0s 1ms/step - loss: 1.3665
16/16 [==============================] - 0s 2ms/step - loss: 1.3838
16/16 [==============================] - 0s 972us/step - loss: 1.3880
16/16 [==============================] - 0s 1ms/step - loss: 1.3888
16/16 [==============================] - 0s 1ms/step - loss: 1.3887
16/16 [==============================] - 0s 2ms/step - loss: 1.3884

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4196
16/16 [==============================] - 0s 1ms/step - loss: 0.7825
16/16 [==============================] - 0s 2ms/step - loss: 1.1245
16/16 [==============================] - 0s 1ms/step - loss: 1.3411
16/16 [==============================] - 0s 2ms/step - loss: 1.3905
16/16 [==============================] - 0s 1ms/step - loss: 1.4071
16/16 [==============================] - 0s 2ms/step - loss: 1.4109
16/16 [==============================] - 0s 2ms/step - loss: 1.4116
16/16 [==============================] - 0s 1ms/step - loss: 1.4115
16/16 [==============================] - 0s 3ms/step - loss: 1.4112
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4124
16/16 [==============================] - 0s 2ms/step - loss: 0.7896
16/16 [==============================] - 0s 2ms/step - loss: 1.1481
16/16 [==============================] - 0s 2ms/step - loss: 1.3684
16/16 [==============================] - 0s 2ms/step - loss: 1.4180
16/16 [==============================] - 0s 2ms/step - loss: 1.4340
16/16 [==============================] - 0s 2ms/step - loss: 1.4374
16/16 [==============================] - 0s 1ms/step - loss: 1.4380
16/16 [==============================] - 0s 1ms/step - loss: 1.4378
16/16 [==============================] - 0s 1ms/step - loss: 1.4375

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4173
16/16 [==============================] - 0s 2ms/step - loss: 0.7865
16/16 [==============================] - 0s 2ms/step - loss: 1.1353
16/16 [==============================] - 0s 1ms/step - loss: 1.3465
16/16 [==============================] - 0s 1ms/step - loss: 1.3927
16/16 [==============================] - 0s 1ms/step - loss: 1.4072
16/16 [==============================] - 0s 2ms/step - loss: 1.4101
16/16 [==============================] - 0s 1ms/step - loss: 1.4105
16/16 [==============================] - 0s 1ms/step - loss: 1.4102
16/16 [==============================] - 0s 1ms/step - loss: 1.4099
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4145
16/16 [==============================] - 0s 1ms/step - loss: 0.7933
16/16 [==============================] - 0s 1ms/step - loss: 1.1517
16/16 [==============================] - 0s 1ms/step - loss: 1.3656
16/16 [==============================] - 0s 5ms/step - loss: 1.4111
16/16 [==============================] - 0s 4ms/step - loss: 1.4251
16/16 [==============================] - 0s 4ms/step - loss: 1.4278
16/16 [==============================] - 0s 2ms/step - loss: 1.4281
16/16 [==============================] - 0s 2ms/step - loss: 1.4278
16/16 [==============================] - 0s 2ms/step - loss: 1.4275

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4111
16/16 [==============================] - 0s 1ms/step - loss: 0.7909
16/16 [==============================] - 0s 1ms/step - loss: 1.1516
16/16 [==============================] - 0s 2ms/step - loss: 1.3647
16/16 [==============================] - 0s 1ms/step - loss: 1.4090
16/16 [==============================] - 0s 1ms/step - loss: 1.4224
16/16 [==============================] - 0s 2ms/step - loss: 1.4249
16/16 [==============================] - 0s 2ms/step - loss: 1.4250
16/16 [==============================] - 0s 2ms/step - loss: 1.4247
16/16 [==============================] - 0s 2ms/step - loss: 1.4244
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 869us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4107
16/16 [==============================] - 0s 1ms/step - loss: 0.7938
16/16 [==============================] - 0s 1ms/step - loss: 1.1611
16/16 [==============================] - 0s 2ms/step - loss: 1.3750
16/16 [==============================] - 0s 994us/step - loss: 1.4188
16/16 [==============================] - 0s 903us/step - loss: 1.4319
16/16 [==============================] - 0s 916us/step - loss: 1.4343
16/16 [==============================] - 0s 997us/step - loss: 1.4344
16/16 [==============================] - 0s 4ms/step - loss: 1.4341
16/16 [==============================] - 0s 1ms/step - loss: 1.4338

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4054
16/16 [==============================] - 0s 4ms/step - loss: 0.7927
16/16 [==============================] - 0s 3ms/step - loss: 1.1646
16/16 [==============================] - 0s 2ms/step - loss: 1.3805
16/16 [==============================] - 0s 4ms/step - loss: 1.4241
16/16 [==============================] - 0s 2ms/step - loss: 1.4369
16/16 [==============================] - 0s 2ms/step - loss: 1.4391
16/16 [==============================] - 0s 1ms/step - loss: 1.4391
16/16 [==============================] - 0s 1ms/step - loss: 1.4388
16/16 [==============================] - 0s 1ms/step - loss: 1.4384
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3962
16/16 [==============================] - 0s 2ms/step - loss: 0.7984
16/16 [==============================] - 0s 1ms/step - loss: 1.1888
16/16 [==============================] - 0s 5ms/step - loss: 1.4144
16/16 [==============================] - 0s 3ms/step - loss: 1.4594
16/16 [==============================] - 0s 2ms/step - loss: 1.4726
16/16 [==============================] - 0s 4ms/step - loss: 1.4748
16/16 [==============================] - 0s 2ms/step - loss: 1.4749
16/16 [==============================] - 0s 1ms/step - loss: 1.4745
16/16 [==============================] - 0s 1ms/step - loss: 1.4742

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 898us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3984
16/16 [==============================] - 0s 1ms/step - loss: 0.7936
16/16 [==============================] - 0s 1ms/step - loss: 1.1789
16/16 [==============================] - 0s 3ms/step - loss: 1.4023
16/16 [==============================] - 0s 2ms/step - loss: 1.4465
16/16 [==============================] - 0s 1ms/step - loss: 1.4593
16/16 [==============================] - 0s 954us/step - loss: 1.4615
16/16 [==============================] - 0s 1ms/step - loss: 1.4616
16/16 [==============================] - 0s 998us/step - loss: 1.4612
16/16 [==============================] - 0s 2ms/step - loss: 1.4608
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3891
16/16 [==============================] - 0s 1ms/step - loss: 0.7938
16/16 [==============================] - 0s 1ms/step - loss: 1.1911
16/16 [==============================] - 0s 1ms/step - loss: 1.4219
16/16 [==============================] - 0s 3ms/step - loss: 1.4666
16/16 [==============================] - 0s 2ms/step - loss: 1.4796
16/16 [==============================] - 0s 2ms/step - loss: 1.4818
16/16 [==============================] - 0s 1ms/step - loss: 1.4818
16/16 [==============================] - 0s 1ms/step - loss: 1.4815
16/16 [==============================] - 0s 1ms/step - loss: 1.4811

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 913us/step
16/16 [==============================] - 0s 3ms/step - loss: 0.3883
16/16 [==============================] - 0s 3ms/step - loss: 0.7919
16/16 [==============================] - 0s 2ms/step - loss: 1.1930
16/16 [==============================] - 0s 1ms/step - loss: 1.4285
16/16 [==============================] - 0s 2ms/step - loss: 1.4721
16/16 [==============================] - 0s 1ms/step - loss: 1.4852
16/16 [==============================] - 0s 2ms/step - loss: 1.4875
16/16 [==============================] - 0s 1ms/step - loss: 1.4875
16/16 [==============================] - 0s 1ms/step - loss: 1.4871
16/16 [==============================] - 0s 3ms/step - loss: 1.4867
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3772
16/16 [==============================] - 0s 1ms/step - loss: 0.7929
16/16 [==============================] - 0s 2ms/step - loss: 1.2122
16/16 [==============================] - 0s 1ms/step - loss: 1.4584
16/16 [==============================] - 0s 3ms/step - loss: 1.5041
16/16 [==============================] - 0s 3ms/step - loss: 1.5178
16/16 [==============================] - 0s 1ms/step - loss: 1.5201
16/16 [==============================] - 0s 1ms/step - loss: 1.5202
16/16 [==============================] - 0s 1ms/step - loss: 1.5198
16/16 [==============================] - 0s 973us/step - loss: 1.5194

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3685
16/16 [==============================] - 0s 2ms/step - loss: 0.7940
16/16 [==============================] - 0s 1ms/step - loss: 1.2262
16/16 [==============================] - 0s 2ms/step - loss: 1.4829
16/16 [==============================] - 0s 2ms/step - loss: 1.5311
16/16 [==============================] - 0s 1ms/step - loss: 1.5455
16/16 [==============================] - 0s 2ms/step - loss: 1.5481
16/16 [==============================] - 0s 4ms/step - loss: 1.5482
16/16 [==============================] - 0s 2ms/step - loss: 1.5478
16/16 [==============================] - 0s 3ms/step - loss: 1.5474
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.3693
16/16 [==============================] - 0s 1ms/step - loss: 0.7909
16/16 [==============================] - 0s 1ms/step - loss: 1.2196
16/16 [==============================] - 0s 1ms/step - loss: 1.4752
16/16 [==============================] - 0s 2ms/step - loss: 1.5233
16/16 [==============================] - 0s 2ms/step - loss: 1.5375
16/16 [==============================] - 0s 1ms/step - loss: 1.5400
16/16 [==============================] - 0s 1ms/step - loss: 1.5400
16/16 [==============================] - 0s 2ms/step - loss: 1.5396
16/16 [==============================] - 0s 3ms/step - loss: 1.5392

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3592
16/16 [==============================] - 0s 1ms/step - loss: 0.7936
16/16 [==============================] - 0s 2ms/step - loss: 1.2413
16/16 [==============================] - 0s 2ms/step - loss: 1.5117
16/16 [==============================] - 0s 2ms/step - loss: 1.5633
16/16 [==============================] - 0s 2ms/step - loss: 1.5786
16/16 [==============================] - 0s 4ms/step - loss: 1.5814
16/16 [==============================] - 0s 2ms/step - loss: 1.5816
16/16 [==============================] - 0s 2ms/step - loss: 1.5812
16/16 [==============================] - 0s 1ms/step - loss: 1.5808
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 923us/step - loss: 0.3582
16/16 [==============================] - 0s 1ms/step - loss: 0.7895
16/16 [==============================] - 0s 1ms/step - loss: 1.2360
16/16 [==============================] - 0s 1ms/step - loss: 1.5072
16/16 [==============================] - 0s 952us/step - loss: 1.5584
16/16 [==============================] - 0s 2ms/step - loss: 1.5735
16/16 [==============================] - 0s 2ms/step - loss: 1.5763
16/16 [==============================] - 0s 1ms/step - loss: 1.5764
16/16 [==============================] - 0s 2ms/step - loss: 1.5760
16/16 [==============================] - 0s 1ms/step - loss: 1.5756

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3488
16/16 [==============================] - 0s 2ms/step - loss: 0.7942
16/16 [==============================] - 0s 1ms/step - loss: 1.2601
16/16 [==============================] - 0s 1ms/step - loss: 1.5469
16/16 [==============================] - 0s 1ms/step - loss: 1.6015
16/16 [==============================] - 0s 1ms/step - loss: 1.6177
16/16 [==============================] - 0s 1ms/step - loss: 1.6207
16/16 [==============================] - 0s 2ms/step - loss: 1.6210
16/16 [==============================] - 0s 2ms/step - loss: 1.6206
16/16 [==============================] - 0s 1ms/step - loss: 1.6202
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 829us/step
16/16 [==============================] - 0s 980us/step - loss: 0.3512
16/16 [==============================] - 0s 943us/step - loss: 0.7854
16/16 [==============================] - 0s 842us/step - loss: 1.2413
16/16 [==============================] - 0s 816us/step - loss: 1.5228
16/16 [==============================] - 0s 1ms/step - loss: 1.5761
16/16 [==============================] - 0s 829us/step - loss: 1.5918
16/16 [==============================] - 0s 819us/step - loss: 1.5947
16/16 [==============================] - 0s 801us/step - loss: 1.5949
16/16 [==============================] - 0s 852us/step - loss: 1.5945
16/16 [==============================] - 0s 874us/step - loss: 1.5940

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 637us/step
16/16 [==============================] - 0s 798us/step - loss: 0.3437
16/16 [==============================] - 0s 798us/step - loss: 0.7857
16/16 [==============================] - 0s 793us/step - loss: 1.2551
16/16 [==============================] - 0s 784us/step - loss: 1.5475
16/16 [==============================] - 0s 778us/step - loss: 1.6036
16/16 [==============================] - 0s 789us/step - loss: 1.6201
16/16 [==============================] - 0s 800us/step - loss: 1.6232
16/16 [==============================] - 0s 786us/step - loss: 1.6234
16/16 [==============================] - 0s 804us/step - loss: 1.6230
16/16 [==============================] - 0s 771us/step - loss: 1.6226
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 837us/step
16/16 [==============================] - 0s 906us/step - loss: 0.3392
16/16 [==============================] - 0s 772us/step - loss: 0.7786
16/16 [==============================] - 0s 1ms/step - loss: 1.2518
16/16 [==============================] - 0s 1ms/step - loss: 1.5415
16/16 [==============================] - 0s 1ms/step - loss: 1.5975
16/16 [==============================] - 0s 1ms/step - loss: 1.6140
16/16 [==============================] - 0s 836us/step - loss: 1.6171
16/16 [==============================] - 0s 781us/step - loss: 1.6173
16/16 [==============================] - 0s 805us/step - loss: 1.6169
16/16 [==============================] - 0s 802us/step - loss: 1.6165

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 831us/step - loss: 0.3362
16/16 [==============================] - 0s 795us/step - loss: 0.7794
16/16 [==============================] - 0s 806us/step - loss: 1.2570
16/16 [==============================] - 0s 780us/step - loss: 1.5521
16/16 [==============================] - 0s 821us/step - loss: 1.6094
16/16 [==============================] - 0s 778us/step - loss: 1.6265
16/16 [==============================] - 0s 835us/step - loss: 1.6298
16/16 [==============================] - 0s 774us/step - loss: 1.6300
16/16 [==============================] - 0s 773us/step - loss: 1.6296
16/16 [==============================] - 0s 782us/step - loss: 1.6291
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 821us/step - loss: 0.3350
16/16 [==============================] - 0s 780us/step - loss: 0.7829
16/16 [==============================] - 0s 807us/step - loss: 1.2628
16/16 [==============================] - 0s 798us/step - loss: 1.5617
16/16 [==============================] - 0s 790us/step - loss: 1.6196
16/16 [==============================] - 0s 810us/step - loss: 1.6369
16/16 [==============================] - 0s 814us/step - loss: 1.6402
16/16 [==============================] - 0s 784us/step - loss: 1.6404
16/16 [==============================] - 0s 812us/step - loss: 1.6400
16/16 [==============================] - 0s 808us/step - loss: 1.6395

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 854us/step - loss: 0.3207
16/16 [==============================] - 0s 771us/step - loss: 0.7883
16/16 [==============================] - 0s 791us/step - loss: 1.2870
16/16 [==============================] - 0s 762us/step - loss: 1.6028
16/16 [==============================] - 0s 770us/step - loss: 1.6645
16/16 [==============================] - 0s 770us/step - loss: 1.6830
16/16 [==============================] - 0s 792us/step - loss: 1.6866
16/16 [==============================] - 0s 788us/step - loss: 1.6869
16/16 [==============================] - 0s 827us/step - loss: 1.6865
16/16 [==============================] - 0s 758us/step - loss: 1.6861
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 807us/step - loss: 0.3234
16/16 [==============================] - 0s 771us/step - loss: 0.7890
16/16 [==============================] - 0s 777us/step - loss: 1.2822
16/16 [==============================] - 0s 780us/step - loss: 1.5961
16/16 [==============================] - 0s 807us/step - loss: 1.6572
16/16 [==============================] - 0s 795us/step - loss: 1.6753
16/16 [==============================] - 0s 803us/step - loss: 1.6788
16/16 [==============================] - 0s 1ms/step - loss: 1.6791
16/16 [==============================] - 0s 682us/step - loss: 1.6786
16/16 [==============================] - 0s 750us/step - loss: 1.6782

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 660us/step - loss: 0.3169
16/16 [==============================] - 0s 1ms/step - loss: 0.7846
16/16 [==============================] - 0s 664us/step - loss: 1.2831
16/16 [==============================] - 0s 655us/step - loss: 1.6025
16/16 [==============================] - 0s 771us/step - loss: 1.6649
16/16 [==============================] - 0s 675us/step - loss: 1.6836
16/16 [==============================] - 0s 677us/step - loss: 1.6870
16/16 [==============================] - 0s 815us/step - loss: 1.6873
16/16 [==============================] - 0s 791us/step - loss: 1.6868
16/16 [==============================] - 0s 785us/step - loss: 1.6863
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 798us/step - loss: 0.3223
16/16 [==============================] - 0s 769us/step - loss: 0.7759
16/16 [==============================] - 0s 774us/step - loss: 1.2607
16/16 [==============================] - 0s 769us/step - loss: 1.5701
16/16 [==============================] - 0s 806us/step - loss: 1.6300
16/16 [==============================] - 0s 781us/step - loss: 1.6478
16/16 [==============================] - 0s 791us/step - loss: 1.6509
16/16 [==============================] - 0s 779us/step - loss: 1.6511
16/16 [==============================] - 0s 1ms/step - loss: 1.6506
16/16 [==============================] - 0s 779us/step - loss: 1.6501

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 779us/step - loss: 0.3189
16/16 [==============================] - 0s 824us/step - loss: 0.7810
16/16 [==============================] - 0s 808us/step - loss: 1.2802
16/16 [==============================] - 0s 809us/step - loss: 1.6001
16/16 [==============================] - 0s 777us/step - loss: 1.6622
16/16 [==============================] - 0s 785us/step - loss: 1.6807
16/16 [==============================] - 0s 780us/step - loss: 1.6840
16/16 [==============================] - 0s 805us/step - loss: 1.6842
16/16 [==============================] - 0s 783us/step - loss: 1.6838
16/16 [==============================] - 0s 818us/step - loss: 1.6833
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 797us/step - loss: 0.3072
16/16 [==============================] - 0s 828us/step - loss: 0.7912
16/16 [==============================] - 0s 783us/step - loss: 1.3176
16/16 [==============================] - 0s 819us/step - loss: 1.6547
16/16 [==============================] - 0s 783us/step - loss: 1.7199
16/16 [==============================] - 0s 810us/step - loss: 1.7392
16/16 [==============================] - 0s 818us/step - loss: 1.7426
16/16 [==============================] - 0s 773us/step - loss: 1.7428
16/16 [==============================] - 0s 769us/step - loss: 1.7424
16/16 [==============================] - 0s 772us/step - loss: 1.7419

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 783us/step - loss: 0.3088
16/16 [==============================] - 0s 818us/step - loss: 0.7812
16/16 [==============================] - 0s 804us/step - loss: 1.2987
16/16 [==============================] - 0s 774us/step - loss: 1.6308
16/16 [==============================] - 0s 770us/step - loss: 1.6949
16/16 [==============================] - 0s 772us/step - loss: 1.7138
16/16 [==============================] - 0s 803us/step - loss: 1.7172
16/16 [==============================] - 0s 773us/step - loss: 1.7174
16/16 [==============================] - 0s 789us/step - loss: 1.7170
16/16 [==============================] - 0s 771us/step - loss: 1.7165
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 788us/step - loss: 0.3021
16/16 [==============================] - 0s 792us/step - loss: 0.7873
16/16 [==============================] - 0s 673us/step - loss: 1.3203
16/16 [==============================] - 0s 786us/step - loss: 1.6612
16/16 [==============================] - 0s 2ms/step - loss: 1.7264
16/16 [==============================] - 0s 2ms/step - loss: 1.7454
16/16 [==============================] - 0s 2ms/step - loss: 1.7487
16/16 [==============================] - 0s 767us/step - loss: 1.7489
16/16 [==============================] - 0s 2ms/step - loss: 1.7484
16/16 [==============================] - 0s 844us/step - loss: 1.7479

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2994
16/16 [==============================] - 0s 655us/step - loss: 0.7933
16/16 [==============================] - 0s 1ms/step - loss: 1.3330
16/16 [==============================] - 0s 818us/step - loss: 1.6811
16/16 [==============================] - 0s 1ms/step - loss: 1.7477
16/16 [==============================] - 0s 806us/step - loss: 1.7671
16/16 [==============================] - 0s 825us/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.7707
16/16 [==============================] - 0s 1ms/step - loss: 1.7702
16/16 [==============================] - 0s 2ms/step - loss: 1.7697
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3054
16/16 [==============================] - 0s 2ms/step - loss: 0.7894
16/16 [==============================] - 0s 2ms/step - loss: 1.3140
16/16 [==============================] - 0s 799us/step - loss: 1.6513
16/16 [==============================] - 0s 1ms/step - loss: 1.7147
16/16 [==============================] - 0s 894us/step - loss: 1.7329
16/16 [==============================] - 0s 2ms/step - loss: 1.7359
16/16 [==============================] - 0s 896us/step - loss: 1.7360
16/16 [==============================] - 0s 1ms/step - loss: 1.7355
16/16 [==============================] - 0s 2ms/step - loss: 1.7350

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 551us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2985
16/16 [==============================] - 0s 2ms/step - loss: 0.7894
16/16 [==============================] - 0s 2ms/step - loss: 1.3189
16/16 [==============================] - 0s 2ms/step - loss: 1.6614
16/16 [==============================] - 0s 803us/step - loss: 1.7256
16/16 [==============================] - 0s 2ms/step - loss: 1.7439
16/16 [==============================] - 0s 2ms/step - loss: 1.7470
16/16 [==============================] - 0s 2ms/step - loss: 1.7471
16/16 [==============================] - 0s 2ms/step - loss: 1.7465
16/16 [==============================] - 0s 2ms/step - loss: 1.7460
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2929
16/16 [==============================] - 0s 773us/step - loss: 0.7969
16/16 [==============================] - 0s 1ms/step - loss: 1.3407
16/16 [==============================] - 0s 2ms/step - loss: 1.6916
16/16 [==============================] - 0s 2ms/step - loss: 1.7567
16/16 [==============================] - 0s 819us/step - loss: 1.7749
16/16 [==============================] - 0s 2ms/step - loss: 1.7779
16/16 [==============================] - 0s 2ms/step - loss: 1.7780
16/16 [==============================] - 0s 2ms/step - loss: 1.7775
16/16 [==============================] - 0s 2ms/step - loss: 1.7769

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 796us/step - loss: 0.2909
16/16 [==============================] - 0s 772us/step - loss: 0.7933
16/16 [==============================] - 0s 823us/step - loss: 1.3388
16/16 [==============================] - 0s 2ms/step - loss: 1.6890
16/16 [==============================] - 0s 951us/step - loss: 1.7538
16/16 [==============================] - 0s 831us/step - loss: 1.7717
16/16 [==============================] - 0s 1ms/step - loss: 1.7746
16/16 [==============================] - 0s 2ms/step - loss: 1.7747
16/16 [==============================] - 0s 796us/step - loss: 1.7741
16/16 [==============================] - 0s 2ms/step - loss: 1.7736
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 791us/step - loss: 0.2946
16/16 [==============================] - 0s 786us/step - loss: 0.7951
16/16 [==============================] - 0s 823us/step - loss: 1.3410
16/16 [==============================] - 0s 1ms/step - loss: 1.6875
16/16 [==============================] - 0s 1ms/step - loss: 1.7506
16/16 [==============================] - 0s 812us/step - loss: 1.7678
16/16 [==============================] - 0s 1ms/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.7705
16/16 [==============================] - 0s 1ms/step - loss: 1.7700
16/16 [==============================] - 0s 2ms/step - loss: 1.7694

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2911
16/16 [==============================] - 0s 789us/step - loss: 0.7943
16/16 [==============================] - 0s 817us/step - loss: 1.3485
16/16 [==============================] - 0s 2ms/step - loss: 1.6968
16/16 [==============================] - 0s 934us/step - loss: 1.7600
16/16 [==============================] - 0s 2ms/step - loss: 1.7771
16/16 [==============================] - 0s 816us/step - loss: 1.7797
16/16 [==============================] - 0s 807us/step - loss: 1.7796
16/16 [==============================] - 0s 820us/step - loss: 1.7791
16/16 [==============================] - 0s 932us/step - loss: 1.7785
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 804us/step - loss: 0.2932
16/16 [==============================] - 0s 2ms/step - loss: 0.7938
16/16 [==============================] - 0s 2ms/step - loss: 1.3487
16/16 [==============================] - 0s 942us/step - loss: 1.6919
16/16 [==============================] - 0s 984us/step - loss: 1.7534
16/16 [==============================] - 0s 828us/step - loss: 1.7699
16/16 [==============================] - 0s 2ms/step - loss: 1.7723
16/16 [==============================] - 0s 839us/step - loss: 1.7722
16/16 [==============================] - 0s 801us/step - loss: 1.7717
16/16 [==============================] - 0s 796us/step - loss: 1.7711

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 805us/step - loss: 0.2842
16/16 [==============================] - 0s 2ms/step - loss: 0.8012
16/16 [==============================] - 0s 2ms/step - loss: 1.3785
16/16 [==============================] - 0s 809us/step - loss: 1.7329
16/16 [==============================] - 0s 853us/step - loss: 1.7961
16/16 [==============================] - 0s 2ms/step - loss: 1.8129
16/16 [==============================] - 0s 812us/step - loss: 1.8153
16/16 [==============================] - 0s 1ms/step - loss: 1.8152
16/16 [==============================] - 0s 760us/step - loss: 1.8146
16/16 [==============================] - 0s 794us/step - loss: 1.8141
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 831us/step - loss: 0.2767
16/16 [==============================] - 0s 805us/step - loss: 0.8072
16/16 [==============================] - 0s 1ms/step - loss: 1.4037
16/16 [==============================] - 0s 869us/step - loss: 1.7654
16/16 [==============================] - 0s 843us/step - loss: 1.8289
16/16 [==============================] - 0s 814us/step - loss: 1.8455
16/16 [==============================] - 0s 837us/step - loss: 1.8479
16/16 [==============================] - 0s 827us/step - loss: 1.8477
16/16 [==============================] - 0s 2ms/step - loss: 1.8471
16/16 [==============================] - 0s 2ms/step - loss: 1.8466

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 582us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2830
16/16 [==============================] - 0s 2ms/step - loss: 0.8001
16/16 [==============================] - 0s 2ms/step - loss: 1.3796
16/16 [==============================] - 0s 799us/step - loss: 1.7297
16/16 [==============================] - 0s 822us/step - loss: 1.7904
16/16 [==============================] - 0s 2ms/step - loss: 1.8061
16/16 [==============================] - 0s 830us/step - loss: 1.8082
16/16 [==============================] - 0s 2ms/step - loss: 1.8080
16/16 [==============================] - 0s 805us/step - loss: 1.8074
16/16 [==============================] - 0s 842us/step - loss: 1.8069
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 671us/step
16/16 [==============================] - 0s 763us/step - loss: 0.2810
16/16 [==============================] - 0s 786us/step - loss: 0.8040
16/16 [==============================] - 0s 770us/step - loss: 1.3884
16/16 [==============================] - 0s 764us/step - loss: 1.7378
16/16 [==============================] - 0s 757us/step - loss: 1.7973
16/16 [==============================] - 0s 769us/step - loss: 1.8124
16/16 [==============================] - 0s 773us/step - loss: 1.8144
16/16 [==============================] - 0s 1ms/step - loss: 1.8141
16/16 [==============================] - 0s 1ms/step - loss: 1.8134
16/16 [==============================] - 0s 1ms/step - loss: 1.8129

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2789
16/16 [==============================] - 0s 783us/step - loss: 0.8059
16/16 [==============================] - 0s 779us/step - loss: 1.3913
16/16 [==============================] - 0s 762us/step - loss: 1.7401
16/16 [==============================] - 0s 762us/step - loss: 1.7989
16/16 [==============================] - 0s 846us/step - loss: 1.8136
16/16 [==============================] - 0s 857us/step - loss: 1.8155
16/16 [==============================] - 0s 839us/step - loss: 1.8151
16/16 [==============================] - 0s 860us/step - loss: 1.8145
16/16 [==============================] - 0s 877us/step - loss: 1.8139
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2754
16/16 [==============================] - 0s 800us/step - loss: 0.8119
16/16 [==============================] - 0s 791us/step - loss: 1.4077
16/16 [==============================] - 0s 786us/step - loss: 1.7589
16/16 [==============================] - 0s 1ms/step - loss: 1.8171
16/16 [==============================] - 0s 801us/step - loss: 1.8315
16/16 [==============================] - 0s 886us/step - loss: 1.8332
16/16 [==============================] - 0s 1ms/step - loss: 1.8328
16/16 [==============================] - 0s 875us/step - loss: 1.8322
16/16 [==============================] - 0s 861us/step - loss: 1.8316

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 789us/step - loss: 0.2707
16/16 [==============================] - 0s 784us/step - loss: 0.8127
16/16 [==============================] - 0s 817us/step - loss: 1.4127
16/16 [==============================] - 0s 815us/step - loss: 1.7644
16/16 [==============================] - 0s 792us/step - loss: 1.8221
16/16 [==============================] - 0s 817us/step - loss: 1.8361
16/16 [==============================] - 0s 800us/step - loss: 1.8377
16/16 [==============================] - 0s 800us/step - loss: 1.8373
16/16 [==============================] - 0s 812us/step - loss: 1.8366
16/16 [==============================] - 0s 856us/step - loss: 1.8360
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 809us/step - loss: 0.2747
16/16 [==============================] - 0s 783us/step - loss: 0.8236
16/16 [==============================] - 0s 793us/step - loss: 1.4341
16/16 [==============================] - 0s 1ms/step - loss: 1.7868
16/16 [==============================] - 0s 904us/step - loss: 1.8438
16/16 [==============================] - 0s 877us/step - loss: 1.8574
16/16 [==============================] - 0s 811us/step - loss: 1.8589
16/16 [==============================] - 0s 807us/step - loss: 1.8584
16/16 [==============================] - 0s 791us/step - loss: 1.8578
16/16 [==============================] - 0s 820us/step - loss: 1.8572

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2854
16/16 [==============================] - 0s 818us/step - loss: 0.8126
16/16 [==============================] - 0s 790us/step - loss: 1.3992
16/16 [==============================] - 0s 837us/step - loss: 1.7342
16/16 [==============================] - 0s 789us/step - loss: 1.7876
16/16 [==============================] - 0s 781us/step - loss: 1.8000
16/16 [==============================] - 0s 785us/step - loss: 1.8013
16/16 [==============================] - 0s 779us/step - loss: 1.8007
16/16 [==============================] - 0s 781us/step - loss: 1.8000
16/16 [==============================] - 0s 806us/step - loss: 1.7995
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2657
16/16 [==============================] - 0s 813us/step - loss: 0.8298
16/16 [==============================] - 0s 787us/step - loss: 1.4637
16/16 [==============================] - 0s 791us/step - loss: 1.8214
16/16 [==============================] - 0s 790us/step - loss: 1.8778
16/16 [==============================] - 0s 780us/step - loss: 1.8907
16/16 [==============================] - 0s 803us/step - loss: 1.8920
16/16 [==============================] - 0s 817us/step - loss: 1.8915
16/16 [==============================] - 0s 779us/step - loss: 1.8908
16/16 [==============================] - 0s 777us/step - loss: 1.8902

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 594us/step
16/16 [==============================] - 0s 818us/step - loss: 0.2715
16/16 [==============================] - 0s 1ms/step - loss: 0.8213
16/16 [==============================] - 0s 1ms/step - loss: 1.4421
16/16 [==============================] - 0s 1ms/step - loss: 1.7886
16/16 [==============================] - 0s 1ms/step - loss: 1.8427
16/16 [==============================] - 0s 787us/step - loss: 1.8549
16/16 [==============================] - 0s 1ms/step - loss: 1.8561
16/16 [==============================] - 0s 1ms/step - loss: 1.8555
16/16 [==============================] - 0s 1ms/step - loss: 1.8549
16/16 [==============================] - 0s 796us/step - loss: 1.8543
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 821us/step - loss: 0.2673
16/16 [==============================] - 0s 799us/step - loss: 0.8241
16/16 [==============================] - 0s 780us/step - loss: 1.4541
16/16 [==============================] - 0s 796us/step - loss: 1.8011
16/16 [==============================] - 0s 811us/step - loss: 1.8543
16/16 [==============================] - 0s 779us/step - loss: 1.8660
16/16 [==============================] - 0s 791us/step - loss: 1.8671
16/16 [==============================] - 0s 771us/step - loss: 1.8665
16/16 [==============================] - 0s 823us/step - loss: 1.8658
16/16 [==============================] - 0s 774us/step - loss: 1.8652

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 801us/step - loss: 0.2792
16/16 [==============================] - 0s 780us/step - loss: 0.8209
16/16 [==============================] - 0s 825us/step - loss: 1.4352
16/16 [==============================] - 0s 812us/step - loss: 1.7676
16/16 [==============================] - 0s 821us/step - loss: 1.8181
16/16 [==============================] - 0s 814us/step - loss: 1.8289
16/16 [==============================] - 0s 1ms/step - loss: 1.8298
16/16 [==============================] - 0s 1ms/step - loss: 1.8291
16/16 [==============================] - 0s 802us/step - loss: 1.8284
16/16 [==============================] - 0s 797us/step - loss: 1.8278
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 859us/step - loss: 0.2657
16/16 [==============================] - 0s 817us/step - loss: 0.8274
16/16 [==============================] - 0s 799us/step - loss: 1.4711
16/16 [==============================] - 0s 898us/step - loss: 1.8159
16/16 [==============================] - 0s 791us/step - loss: 1.8675
16/16 [==============================] - 0s 821us/step - loss: 1.8786
16/16 [==============================] - 0s 802us/step - loss: 1.8795
16/16 [==============================] - 0s 823us/step - loss: 1.8789
16/16 [==============================] - 0s 779us/step - loss: 1.8782
16/16 [==============================] - 0s 797us/step - loss: 1.8776

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 792us/step - loss: 0.2711
16/16 [==============================] - 0s 779us/step - loss: 0.8247
16/16 [==============================] - 0s 798us/step - loss: 1.4613
16/16 [==============================] - 0s 772us/step - loss: 1.7968
16/16 [==============================] - 0s 780us/step - loss: 1.8466
16/16 [==============================] - 0s 797us/step - loss: 1.8571
16/16 [==============================] - 0s 811us/step - loss: 1.8579
16/16 [==============================] - 0s 801us/step - loss: 1.8572
16/16 [==============================] - 0s 776us/step - loss: 1.8565
16/16 [==============================] - 0s 774us/step - loss: 1.8559
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2669
16/16 [==============================] - 0s 830us/step - loss: 0.8337
16/16 [==============================] - 0s 782us/step - loss: 1.4889
16/16 [==============================] - 0s 901us/step - loss: 1.8301
16/16 [==============================] - 0s 812us/step - loss: 1.8797
16/16 [==============================] - 0s 816us/step - loss: 1.8901
16/16 [==============================] - 0s 775us/step - loss: 1.8908
16/16 [==============================] - 0s 778us/step - loss: 1.8901
16/16 [==============================] - 0s 797us/step - loss: 1.8894
16/16 [==============================] - 0s 784us/step - loss: 1.8888

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 811us/step - loss: 0.2687
16/16 [==============================] - 0s 800us/step - loss: 0.8254
16/16 [==============================] - 0s 794us/step - loss: 1.4729
16/16 [==============================] - 0s 777us/step - loss: 1.8040
16/16 [==============================] - 0s 775us/step - loss: 1.8518
16/16 [==============================] - 0s 790us/step - loss: 1.8616
16/16 [==============================] - 0s 806us/step - loss: 1.8622
16/16 [==============================] - 0s 781us/step - loss: 1.8615
16/16 [==============================] - 0s 804us/step - loss: 1.8608
16/16 [==============================] - 0s 782us/step - loss: 1.8602
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2630
16/16 [==============================] - 0s 1ms/step - loss: 0.8345
16/16 [==============================] - 0s 1ms/step - loss: 1.5023
16/16 [==============================] - 0s 1ms/step - loss: 1.8396
16/16 [==============================] - 0s 1ms/step - loss: 1.8872
16/16 [==============================] - 0s 769us/step - loss: 1.8970
16/16 [==============================] - 0s 822us/step - loss: 1.8976
16/16 [==============================] - 0s 778us/step - loss: 1.8968
16/16 [==============================] - 0s 778us/step - loss: 1.8961
16/16 [==============================] - 0s 804us/step - loss: 1.8955

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 787us/step - loss: 0.2649
16/16 [==============================] - 0s 825us/step - loss: 0.8307
16/16 [==============================] - 0s 785us/step - loss: 1.4969
16/16 [==============================] - 0s 799us/step - loss: 1.8271
16/16 [==============================] - 0s 800us/step - loss: 1.8735
16/16 [==============================] - 0s 1ms/step - loss: 1.8829
16/16 [==============================] - 0s 1ms/step - loss: 1.8834
16/16 [==============================] - 0s 1ms/step - loss: 1.8826
16/16 [==============================] - 0s 1ms/step - loss: 1.8818
16/16 [==============================] - 0s 1ms/step - loss: 1.8813
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 845us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2646
16/16 [==============================] - 0s 1ms/step - loss: 0.8302
16/16 [==============================] - 0s 1ms/step - loss: 1.4973
16/16 [==============================] - 0s 780us/step - loss: 1.8229
16/16 [==============================] - 0s 773us/step - loss: 1.8679
16/16 [==============================] - 0s 794us/step - loss: 1.8768
16/16 [==============================] - 0s 1ms/step - loss: 1.8772
16/16 [==============================] - 0s 1ms/step - loss: 1.8763
16/16 [==============================] - 0s 804us/step - loss: 1.8756
16/16 [==============================] - 0s 806us/step - loss: 1.8750

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 844us/step - loss: 0.2654
16/16 [==============================] - 0s 777us/step - loss: 0.8271
16/16 [==============================] - 0s 797us/step - loss: 1.4953
16/16 [==============================] - 0s 781us/step - loss: 1.8151
16/16 [==============================] - 0s 797us/step - loss: 1.8594
16/16 [==============================] - 0s 774us/step - loss: 1.8680
16/16 [==============================] - 0s 811us/step - loss: 1.8683
16/16 [==============================] - 0s 808us/step - loss: 1.8674
16/16 [==============================] - 0s 782us/step - loss: 1.8667
16/16 [==============================] - 0s 785us/step - loss: 1.8661
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 626us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2603
16/16 [==============================] - 0s 797us/step - loss: 0.8334
16/16 [==============================] - 0s 781us/step - loss: 1.5190
16/16 [==============================] - 0s 775us/step - loss: 1.8422
16/16 [==============================] - 0s 772us/step - loss: 1.8866
16/16 [==============================] - 0s 819us/step - loss: 1.8950
16/16 [==============================] - 0s 814us/step - loss: 1.8952
16/16 [==============================] - 0s 790us/step - loss: 1.8943
16/16 [==============================] - 0s 798us/step - loss: 1.8935
16/16 [==============================] - 0s 802us/step - loss: 1.8930

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2586
16/16 [==============================] - 0s 775us/step - loss: 0.8385
16/16 [==============================] - 0s 784us/step - loss: 1.5405
16/16 [==============================] - 0s 786us/step - loss: 1.8654
16/16 [==============================] - 0s 784us/step - loss: 1.9105
16/16 [==============================] - 0s 787us/step - loss: 1.9188
16/16 [==============================] - 0s 787us/step - loss: 1.9191
16/16 [==============================] - 0s 825us/step - loss: 1.9182
16/16 [==============================] - 0s 796us/step - loss: 1.9175
16/16 [==============================] - 0s 790us/step - loss: 1.9169
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 896us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2664
16/16 [==============================] - 0s 887us/step - loss: 0.8317
16/16 [==============================] - 0s 789us/step - loss: 1.5162
16/16 [==============================] - 0s 1ms/step - loss: 1.8275
16/16 [==============================] - 0s 807us/step - loss: 1.8701
16/16 [==============================] - 0s 780us/step - loss: 1.8777
16/16 [==============================] - 0s 782us/step - loss: 1.8779
16/16 [==============================] - 0s 782us/step - loss: 1.8769
16/16 [==============================] - 0s 778us/step - loss: 1.8762
16/16 [==============================] - 0s 801us/step - loss: 1.8756

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2565
16/16 [==============================] - 0s 790us/step - loss: 0.8364
16/16 [==============================] - 0s 832us/step - loss: 1.5469
16/16 [==============================] - 0s 782us/step - loss: 1.8653
16/16 [==============================] - 0s 796us/step - loss: 1.9092
16/16 [==============================] - 0s 783us/step - loss: 1.9169
16/16 [==============================] - 0s 790us/step - loss: 1.9171
16/16 [==============================] - 0s 785us/step - loss: 1.9162
16/16 [==============================] - 0s 799us/step - loss: 1.9154
16/16 [==============================] - 0s 822us/step - loss: 1.9149
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 843us/step - loss: 0.2551
16/16 [==============================] - 0s 823us/step - loss: 0.8408
16/16 [==============================] - 0s 1ms/step - loss: 1.5610
16/16 [==============================] - 0s 804us/step - loss: 1.8795
16/16 [==============================] - 0s 1ms/step - loss: 1.9230
16/16 [==============================] - 0s 832us/step - loss: 1.9304
16/16 [==============================] - 0s 1ms/step - loss: 1.9306
16/16 [==============================] - 0s 1ms/step - loss: 1.9296
16/16 [==============================] - 0s 875us/step - loss: 1.9289
16/16 [==============================] - 0s 825us/step - loss: 1.9283

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 794us/step
16/16 [==============================] - 0s 827us/step - loss: 0.2557
16/16 [==============================] - 0s 812us/step - loss: 0.8404
16/16 [==============================] - 0s 1ms/step - loss: 1.5661
16/16 [==============================] - 0s 1ms/step - loss: 1.8818
16/16 [==============================] - 0s 1ms/step - loss: 1.9253
16/16 [==============================] - 0s 1ms/step - loss: 1.9326
16/16 [==============================] - 0s 820us/step - loss: 1.9327
16/16 [==============================] - 0s 1ms/step - loss: 1.9318
16/16 [==============================] - 0s 1ms/step - loss: 1.9311
16/16 [==============================] - 0s 1ms/step - loss: 1.9305
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2626
16/16 [==============================] - 0s 1ms/step - loss: 0.8359
16/16 [==============================] - 0s 1ms/step - loss: 1.5479
16/16 [==============================] - 0s 1ms/step - loss: 1.8518
16/16 [==============================] - 0s 1ms/step - loss: 1.8930
16/16 [==============================] - 0s 1ms/step - loss: 1.8996
16/16 [==============================] - 0s 853us/step - loss: 1.8996
16/16 [==============================] - 0s 825us/step - loss: 1.8986
16/16 [==============================] - 0s 819us/step - loss: 1.8979
16/16 [==============================] - 0s 857us/step - loss: 1.8973

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 645us/step
16/16 [==============================] - 0s 813us/step - loss: 0.2643
16/16 [==============================] - 0s 836us/step - loss: 0.8245
16/16 [==============================] - 0s 851us/step - loss: 1.5218
16/16 [==============================] - 0s 854us/step - loss: 1.8173
16/16 [==============================] - 0s 807us/step - loss: 1.8571
16/16 [==============================] - 0s 829us/step - loss: 1.8634
16/16 [==============================] - 0s 803us/step - loss: 1.8633
16/16 [==============================] - 0s 814us/step - loss: 1.8623
16/16 [==============================] - 0s 811us/step - loss: 1.8615
16/16 [==============================] - 0s 828us/step - loss: 1.8609
32/32 [==============================] - 0s 634us/step</code></pre>
</div>
</div>
<div id="41e07567-3f8f-4aec-a6fd-98643c82ee86" class="cell" data-execution_count="1614">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="b553dad5-5575-45db-8644-3681cd99172e" class="cell" data-execution_count="1615">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div id="2e5c7ff0-81be-4590-8cb3-63ea6e664f10" class="cell" data-execution_count="1616">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div id="8ec4ef5d-e581-4dbe-89a1-330588fb810b" class="cell" data-execution_count="1617">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-108-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.940
Precision: 0.965
Recall: 0.972
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="527637da-b760-4ef9-a554-457a8a35b4f2" class="cell" data-execution_count="1618">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>therteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  therteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscpstar" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar">LSCP<span class="math inline">\(\star\)</span></h3>
<p>default=10%</p>
<div id="10d0ca96-59ca-4737-88fc-08186c6d269a" class="cell" data-execution_count="1619">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div id="c33ecb34-c02a-4df2-9063-a361ae2e3196" class="cell" data-execution_count="1620">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="92f6faa7-86b7-4d57-a0d8-2d75accdf3f9" class="cell" data-execution_count="1621">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div id="6b4f4315-cfeb-4266-9e83-6663db679eea" class="cell" data-execution_count="1622">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)</span></code></pre></div>
</div>
<div id="848f3ca5-55b5-4260-bc39-190d3f728a57" class="cell" data-execution_count="1623">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-114-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="8bd744a7-e603-4591-bd44-768ee279f720" class="cell" data-execution_count="1624">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> therteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = therteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="linear-result" class="level2">
<h2 class="anchored" data-anchor-id="linear-result">Linear Result</h2>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(5,7)\)</span> and <span class="math inline">\(U(-7,-5)\)</span>.</p>
<div id="c8f598bf-a61f-4ed3-8a7e-800fc753c59e" class="cell" data-execution_count="1625">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>fourteen</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1625">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.998</td>
<td>0.998947</td>
<td>0.998947</td>
<td>0.998947</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.926</td>
<td>0.961053</td>
<td>0.961053</td>
<td>0.961053</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.950</td>
<td>1.000000</td>
<td>0.947368</td>
<td>0.972973</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.935</td>
<td>0.991121</td>
<td>0.940000</td>
<td>0.964884</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.998</td>
<td>0.998947</td>
<td>0.998947</td>
<td>0.998947</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.986</td>
<td>0.992632</td>
<td>0.992632</td>
<td>0.992632</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.988</td>
<td>0.993684</td>
<td>0.993684</td>
<td>0.993684</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.868</td>
<td>0.998780</td>
<td>0.862105</td>
<td>0.925424</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.960</td>
<td>0.977941</td>
<td>0.980000</td>
<td>0.978970</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.916</td>
<td>0.955789</td>
<td>0.955789</td>
<td>0.955789</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.936</td>
<td>0.966316</td>
<td>0.966316</td>
<td>0.966316</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.940</td>
<td>0.965481</td>
<td>0.971579</td>
<td>0.968520</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.988</td>
<td>0.993684</td>
<td>0.993684</td>
<td>0.993684</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="orbit-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="orbit-ebayesthresh">Orbit EbayesThresh</h2>
<div id="29744f1d-f562-4222-8078-30df600c8efa" class="cell" data-execution_count="1899">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div id="b45730b6-a154-44c4-a6db-7769d36e4688" class="cell" data-execution_count="1900">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier <span class="op">=</span> which(signal<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier</span>
<span id="cb168-8"><a href="#cb168-8" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>signal<span class="op">+</span>epsilon</span>
<span id="cb168-9"><a href="#cb168-9" aria-hidden="true" tabindex="-1"></a>plot(<span class="dv">1</span>:<span class="dv">1000</span>,x)</span>
<span id="cb168-10"><a href="#cb168-10" aria-hidden="true" tabindex="-1"></a>points(index_of_trueoutlier,x[index_of_trueoutlier],col<span class="op">=</span><span class="dv">2</span>,cex<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb168-11"><a href="#cb168-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-12"><a href="#cb168-12" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(x,type='l')</span></span>
<span id="cb168-13"><a href="#cb168-13" aria-hidden="true" tabindex="-1"></a><span class="co">#mu &lt;- EbayesThresh::ebayesthresh(x,sdev=2)</span></span>
<span id="cb168-14"><a href="#cb168-14" aria-hidden="true" tabindex="-1"></a><span class="co">#lines(mu,col=2,lty=2,lwd=2)</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-118-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="580e6cfa-7793-4288-94a3-095abdb1156f" class="cell" data-execution_count="1901">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier</span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal</span></code></pre></div>
</div>
<div id="dd034f9d-045b-48e8-be51-d384e84f51fa" class="cell" data-execution_count="1902">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div id="b61b9b71-6b90-4be5-80ac-673e54b00499" class="cell" data-execution_count="1903">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>xhat <span class="op">=</span> np.array(ebayesthresh(FloatVector(x)))</span></code></pre></div>
</div>
<div id="d7318a01-f445-4252-a644-6a6dfd68c823" class="cell" data-execution_count="1904">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(x)</span></span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(xhat)</span></span></code></pre></div>
</div>
<div id="446fcf0e-494e-43c7-a7c2-500a603a9287" class="cell" data-execution_count="1905">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index <span class="op">=</span> index_of_trueoutlier</span></code></pre></div>
</div>
<div id="af764b91-96ff-4bce-b405-d54f826984ae" class="cell" data-execution_count="1906">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value <span class="op">=</span> x[index_of_trueoutlier]</span></code></pre></div>
</div>
<p>package와 비교를 위해 outlier는 -1, inlier는 1로 표시</p>
<div id="916ae7e6-970c-47c9-a09b-077196a38e1f" class="cell" data-execution_count="1907">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> signal.copy()</span></code></pre></div>
</div>
<div id="cbba111b-c439-4cf6-8921-a66d05580eff" class="cell" data-execution_count="1908">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one))</span></code></pre></div>
</div>
<div id="18e5f62d-05c7-4028-a959-369a520bc0f1" class="cell" data-execution_count="1909">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one).to_csv('orbit_outlier.csv')</span></span></code></pre></div>
</div>
</section>
<section id="orbit" class="level2">
<h2 class="anchored" data-anchor-id="orbit">Orbit</h2>
<div id="656ba8c0-418e-4f45-b437-a154771935d5" class="cell" data-execution_count="1877">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">777</span>)</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>pi<span class="op">=</span>np.pi</span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a>ang<span class="op">=</span>np.linspace(<span class="op">-</span>pi,pi<span class="op">-</span><span class="dv">2</span><span class="op">*</span>pi<span class="op">/</span>n,n)</span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a>r<span class="op">=</span><span class="dv">5</span><span class="op">+</span>np.cos(np.linspace(<span class="dv">0</span>,<span class="dv">12</span><span class="op">*</span>pi,n))</span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a>vx<span class="op">=</span>r<span class="op">*</span>np.cos(ang)</span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a>vy<span class="op">=</span>r<span class="op">*</span>np.sin(ang)</span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span><span class="dv">10</span><span class="op">*</span>np.sin(np.linspace(<span class="dv">0</span>,<span class="dv">6</span><span class="op">*</span>pi,n))</span>
<span id="cb178-9"><a href="#cb178-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f1 <span class="op">+</span> x</span></code></pre></div>
</div>
<div id="7dcf2069-e2ac-4651-a1b2-2810efc95f6c" class="cell" data-execution_count="1878">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span> : vx, <span class="st">'y'</span> : vy, <span class="st">'f'</span> : f})</span></code></pre></div>
</div>
<div id="3844ac9c-d2b2-4737-be43-8b89b32ea9f5" class="cell" data-execution_count="1879">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<div id="6cf4bc0a-4c70-400b-a78c-9fc196f0f478" class="cell" data-execution_count="1642">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save_data(_df,'Orbit.pkl')</span></span></code></pre></div>
</div>
<section id="gode-1" class="level3">
<h3 class="anchored" data-anchor-id="gode-1">GODE</h3>
<div id="d315067c-e1e8-4b7d-8278-f74243a577bc" class="cell" data-execution_count="1643">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>_Orbit <span class="op">=</span> Orbit(_df)</span></code></pre></div>
</div>
<div id="91f557c8-fb5b-4244-98d2-b4f57a3d45f5" class="cell" data-execution_count="1644">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_distance()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1000/1000 [00:02&lt;00:00, 340.03it/s]</code></pre>
</div>
</div>
<div id="41ac2f03-b0d5-4700-a5fd-bbba91aa8d13" class="cell" data-execution_count="1645">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_weightmatrix(theta<span class="op">=</span>(_Orbit.D[_Orbit.D<span class="op">&gt;</span><span class="dv">0</span>].mean()),kappa<span class="op">=</span><span class="dv">2500</span>) </span></code></pre></div>
</div>
<div id="e2d1731f-fa9d-4aec-8e58-61a3c818233f" class="cell" data-execution_count="1646">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>_Orbit.fit(sd<span class="op">=</span><span class="dv">15</span>,ref<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div id="7e64c9c6-f23e-4bf0-9169-b1487f9c8f58" class="cell" data-execution_count="1647">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Orbit.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div id="abc11caa-9761-4df1-becc-c886f8755e66" class="cell" data-execution_count="1648">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">13</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div id="668d41f2-a3d1-4f59-b15a-050b2fc01547" class="cell" data-execution_count="1649">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1649">
<pre><code>950</code></pre>
</div>
</div>
<div id="bdfad597-5998-4890-9c20-35dacfb7ea93" class="cell" data-execution_count="1650">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1650">
<pre><code>50</code></pre>
</div>
</div>
<div id="229422f2-34e8-4799-b48d-e550619ca19d" class="cell" data-execution_count="1651">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)</span></code></pre></div>
</div>
<div id="9102ccf8-756d-4b65-beb1-c2e6d786b1a7" class="cell" data-execution_count="1652">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-141-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="fde23476-8180-4424-b3b5-bec72f306068" class="cell" data-execution_count="1653">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofstar">LOF<span class="math inline">\(\star\)</span></h3>
<div id="12377f40-3a51-43e0-a29e-590623436746" class="cell" data-execution_count="1654">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div id="186c8c2b-e7a8-4fee-8454-3c93242a35db" class="cell" data-execution_count="1655">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)</span></code></pre></div>
</div>
<div id="9850dc82-ff5a-4999-b13a-881f27ade039" class="cell" data-execution_count="1656">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-145-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.976
Recall: 0.976
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="0199bf2a-ae7c-4b28-89b3-73d3ebf9432f" class="cell" data-execution_count="1658">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn-1" class="level3">
<h3 class="anchored" data-anchor-id="knn-1">KNN</h3>
<div id="f71aa118-032d-4372-8f1d-c6b9970a4bce" class="cell" data-tags="[]" data-execution_count="1659">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb205-3"><a href="#cb205-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="1e1c46cc-46b1-48b6-bcb6-9ddf940cc7c1" class="cell" data-execution_count="1660">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="bd687849-666b-4755-8aef-69695d3c5866" class="cell" data-execution_count="1661">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div id="8fbdc407-4c81-4c9b-946f-087e7a47e43b" class="cell" data-execution_count="1662">
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)</span></code></pre></div>
</div>
<div id="e5a301b2-5883-47d0-a6b2-dc3ac8dfe49f" class="cell" data-execution_count="1663">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-151-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.948
Precision: 0.999
Recall: 0.946
F1 Score: 0.972</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="cb846126-3f1c-4e2b-b367-8aad708d5827" class="cell" data-execution_count="1664">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof" class="level3">
<h3 class="anchored" data-anchor-id="cblof">CBLOF</h3>
<div id="9c89fbe5-0f4f-4003-b7ae-530469c85fc5" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div id="1b32de36-142f-40a2-aab8-da5478218184" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> load_data(<span class="st">'Orbit.pkl'</span>)</span></code></pre></div>
</div>
<div id="de267107-c7ca-4b1b-8b9f-d89f290084e9" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> pd.read_csv(<span class="st">'orbit_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].tolist()</span></code></pre></div>
</div>
<div id="da9bc1df-30fc-4649-a640-59a3d14c2ae9" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div id="62472305-4ac9-48ab-8d79-9071fa3879ac" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span>
<span id="cb219-6"><a href="#cb219-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-7"><a href="#cb219-7" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span>
<span id="cb219-8"><a href="#cb219-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-9"><a href="#cb219-9" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)</span>
<span id="cb219-10"><a href="#cb219-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-11"><a href="#cb219-11" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span>
<span id="cb219-12"><a href="#cb219-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-13"><a href="#cb219-13" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-157-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<ul>
<li>Accuracy: 0.916</li>
<li>Precision: 0.956</li>
<li>Recall: 0.956</li>
<li>F1 Score: 0.956</li>
</ul>
</section>
<section id="ocsvm-1" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-1">OCSVM</h3>
<div id="14b23a33-1e1d-43c3-8091-1f71e0318b85" class="cell" data-execution_count="1668">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div id="95ca92ce-5af0-4878-af44-d2fad4a10e32" class="cell" data-execution_count="1669">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1669">
<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked=""><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div id="dc5ff2fc-8e7c-499b-a245-1c9d6abee8e8" class="cell" data-execution_count="1670">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div id="b06dcfef-bf08-4a51-bdda-cd1a10b2f5cf" class="cell" data-execution_count="1671">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)</span></code></pre></div>
</div>
<div id="045fe8fa-9e0d-4d54-8883-537a4d1f09b1" class="cell" data-execution_count="1672">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-162-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.908
Precision: 0.977
Recall: 0.925
F1 Score: 0.950</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="ec716e6c-db7a-4e0d-a441-33836e393fdd" class="cell" data-execution_count="1674">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcdstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar-1">MCD<span class="math inline">\(\star\)</span></h3>
<div id="53cc633b-e6ca-4dc0-8bcc-a9b6f06adc6f" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1675">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="bcd938bc-7c0e-4499-a6f4-3c8214da5575" class="cell" data-execution_count="1676">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="b4a4b5b0-42f8-4a4e-b660-b300927eb81f" class="cell" data-execution_count="1677">
<div class="sourceCode cell-code" id="cb234"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div id="a459eaab-8873-4f2f-a09a-56f9e8c5f410" class="cell" data-execution_count="1678">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)</span></code></pre></div>
</div>
<div id="7e930280-027d-4b1c-aaae-f5002ca10749" class="cell" data-execution_count="1679">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-168-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="d4dd7b34-e9b5-4c49-b139-50cef0ff0e5c" class="cell" data-execution_count="1682">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-baggingstar-1" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<div id="bd85c63c-6ef6-4aa6-9e08-70f3481e5db0" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1683">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb241-2"><a href="#cb241-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb241-3"><a href="#cb241-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="a726f1d3-920c-4bb8-bd93-1aff062dd9a5" class="cell" data-execution_count="1684">
<div class="sourceCode cell-code" id="cb242"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="73a3b889-2091-4d2c-9b34-90cb1650f42f" class="cell" data-execution_count="1685">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div id="5c600842-003a-4e91-b27b-12ee3792e2ff" class="cell" data-execution_count="1686">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)</span></code></pre></div>
</div>
<div id="ace3a587-b15d-4ddd-a826-fc1aa5b32d19" class="cell" data-execution_count="1687">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-174-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.969
Recall: 0.969
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="ab454db9-f894-4603-90ba-001ad2f2478b" class="cell" data-execution_count="1688">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abodstar-1" class="level3">
<h3 class="anchored" data-anchor-id="abodstar-1">ABOD<span class="math inline">\(\star\)</span></h3>
<div id="c5bdf15b-597c-4fb5-aaf0-6c833bd87266" class="cell" data-execution_count="1689">
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb250-2"><a href="#cb250-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb250-3"><a href="#cb250-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="3bd7e84f-771a-4fef-b561-1878765c34f9" class="cell" data-execution_count="1690">
<div class="sourceCode cell-code" id="cb251"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="524750aa-1413-4178-809a-4492cc1afafb" class="cell" data-execution_count="1691">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div id="cc107a56-e734-4f2d-9a82-f10894fd89a5" class="cell" data-execution_count="1692">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)</span></code></pre></div>
</div>
<div id="c253da3c-3cdf-45db-be17-d2f5c19057cd" class="cell" data-execution_count="1693">
<div class="sourceCode cell-code" id="cb254"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-180-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="79091c09-ad9e-44ed-a9bb-e82afa419d9f" class="cell" data-execution_count="1695">
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="iforeststar-1" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar-1">IForest<span class="math inline">\(\star\)</span></h3>
<div id="077d39f8-8b2e-472b-aa0b-6e05badb7021" class="cell" data-execution_count="1696">
<div class="sourceCode cell-code" id="cb259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb259-2"><a href="#cb259-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb259-3"><a href="#cb259-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb259-4"><a href="#cb259-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="4dfc599f-6e3e-4ec3-9d5b-c3c829e17407" class="cell" data-execution_count="1697">
<div class="sourceCode cell-code" id="cb260"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span></code></pre></div>
</div>
<div id="770e9351-cd55-48bb-b071-57f899a91542" class="cell" data-execution_count="1698">
<div class="sourceCode cell-code" id="cb261"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb261-2"><a href="#cb261-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]],</span>
<span id="cb261-3"><a href="#cb261-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb261-4"><a href="#cb261-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="da9b2ec8-d952-4eb0-8e46-a2bd92afd05c" class="cell" data-execution_count="1699">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div id="e1993201-f06b-4389-a8be-cc78d3c1a3cf" class="cell" data-execution_count="1700">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div id="0c726c96-6fbc-46e1-81d2-59df41a0e7fc" class="cell" data-execution_count="1701">
<div class="sourceCode cell-code" id="cb264"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div id="acc010b6-e817-43dc-b3eb-17a26dc83cc9" class="cell" data-execution_count="1702">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)</span></code></pre></div>
</div>
<div id="07b00e57-350f-4f93-9652-f809d6906a3a" class="cell" data-execution_count="1703">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-189-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.443
Precision: 0.992
Recall: 0.417
F1 Score: 0.587</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="3eddb2a6-9437-4187-b433-3aeefcb7ed57" class="cell" data-execution_count="1704">
<div class="sourceCode cell-code" id="cb269"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar-1">HBOS<span class="math inline">\(\star\)</span></h3>
<div id="9aa34dc5-2b99-40a9-8b2b-c099eec1a60b" class="cell" data-execution_count="1705">
<div class="sourceCode cell-code" id="cb271"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb271-1"><a href="#cb271-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb271-2"><a href="#cb271-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb271-3"><a href="#cb271-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="030f3caa-fd90-487f-bc66-75757943ac60" class="cell" data-execution_count="1706">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="f427f0e1-cc6c-4315-87bf-369d25c10932" class="cell" data-execution_count="1707">
<div class="sourceCode cell-code" id="cb273"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div id="70ceff0e-4e36-4590-996b-9dda2a9c834d" class="cell" data-execution_count="1708">
<div class="sourceCode cell-code" id="cb274"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)</span></code></pre></div>
</div>
<div id="bf019ea9-ad6f-4993-851c-b7a80683a2df" class="cell" data-execution_count="1709">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-195-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.960
Recall: 0.973
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="2a9914e9-c586-4749-a73b-2919c841bcc2" class="cell" data-execution_count="1711">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="sosstar-1">SOS<span class="math inline">\(\star\)</span></h3>
<div id="cbb972a5-d763-45d6-a70e-a6b2b5865bb6" class="cell" data-execution_count="1712">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="d663fd08-5b3d-4e6c-ab2a-ac9f15cfcda5" class="cell" data-execution_count="1713">
<div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="ffe47d4c-2ee7-4b5a-95b2-5308a121ad58" class="cell" data-execution_count="1714">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div id="41c63cd6-cc2d-42b8-b340-1de3d7ce0fef" class="cell" data-execution_count="1715">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)</span></code></pre></div>
</div>
<div id="c10ea94c-56a0-4f8a-a4e0-afa9b21a0b41" class="cell" data-execution_count="1716">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-201-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.974
Recall: 0.974
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="ad063163-c8da-4cee-9d19-f9897be12896" class="cell" data-execution_count="1718">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></h3>
<div id="7c6036be-ed6b-4162-ba2d-02c6a956394b" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1719">
<div class="sourceCode cell-code" id="cb289"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb289-1"><a href="#cb289-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb289-2"><a href="#cb289-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb289-3"><a href="#cb289-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 969us/step - loss: 1.3463

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3506
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3586

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3721
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3866

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3800
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4006

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4023
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4122

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.4314
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4473

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.4588
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4734

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4913
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5128

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5221
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5512

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5569
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5717

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5833
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5991

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6237
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.6486

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6528
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6775

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6728
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6961

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7114
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7382

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7361
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7442

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7632
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7813

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7997
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8135

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8074
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8185

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.8404
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.8432

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8590
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8644

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8872
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9012

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.9049
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9139

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9184
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.9365

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9581
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9824

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.9639
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0122

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0024
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0080

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.0230
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0424

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0419
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0648

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0705
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0983

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1023
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1145

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.1403
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1403

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1572
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1621

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.1594
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1776

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1913
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.2041

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2355
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2292

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2431
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2475

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2408
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2696

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2748
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3000

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.3168
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
</div>
<div id="f0eea7c8-4808-456b-8d5e-2ec504abb94c" class="cell" data-execution_count="1720">
<div class="sourceCode cell-code" id="cb292"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="0a0a0e1a-c30a-4d94-b758-c7d7821abb0f" class="cell" data-execution_count="1721">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div id="7b8ebf0e-0a69-4684-896c-c39b873a6350" class="cell" data-execution_count="1722">
<div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div id="cd41ad40-82eb-4f90-8435-655bc878f489" class="cell" data-execution_count="1723">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-207-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="10c8c438-18f9-4086-b5db-58b286cac0bd" class="cell" data-execution_count="1724">
<div class="sourceCode cell-code" id="cb298"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaalstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div id="dcbc8402-10f2-45bc-9681-cef54890a997" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1725">
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb300-3"><a href="#cb300-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 3ms/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 3ms/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 992us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 782us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 680us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 801us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 642us/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 617us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 801us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 894us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4662
16/16 [==============================] - 0s 1ms/step - loss: 1.1250
16/16 [==============================] - 0s 1ms/step - loss: 1.1652
16/16 [==============================] - 0s 1ms/step - loss: 1.1668
16/16 [==============================] - 0s 997us/step - loss: 1.1673
16/16 [==============================] - 0s 965us/step - loss: 1.1677
16/16 [==============================] - 0s 1ms/step - loss: 1.1681
16/16 [==============================] - 0s 1ms/step - loss: 1.1688
16/16 [==============================] - 0s 971us/step - loss: 1.1690
16/16 [==============================] - 0s 2ms/step - loss: 1.1690
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 858us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4861
16/16 [==============================] - 0s 2ms/step - loss: 1.1078
16/16 [==============================] - 0s 1ms/step - loss: 1.1395
16/16 [==============================] - 0s 1ms/step - loss: 1.1408
16/16 [==============================] - 0s 1ms/step - loss: 1.1412
16/16 [==============================] - 0s 1ms/step - loss: 1.1417
16/16 [==============================] - 0s 2ms/step - loss: 1.1423
16/16 [==============================] - 0s 2ms/step - loss: 1.1430
16/16 [==============================] - 0s 1ms/step - loss: 1.1433
16/16 [==============================] - 0s 1ms/step - loss: 1.1433

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4978
16/16 [==============================] - 0s 2ms/step - loss: 1.1226
16/16 [==============================] - 0s 1ms/step - loss: 1.1496
16/16 [==============================] - 0s 2ms/step - loss: 1.1507
16/16 [==============================] - 0s 1ms/step - loss: 1.1512
16/16 [==============================] - 0s 4ms/step - loss: 1.1516
16/16 [==============================] - 0s 3ms/step - loss: 1.1520
16/16 [==============================] - 0s 2ms/step - loss: 1.1527
16/16 [==============================] - 0s 2ms/step - loss: 1.1529
16/16 [==============================] - 0s 1ms/step - loss: 1.1529
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 900us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5048
16/16 [==============================] - 0s 1ms/step - loss: 1.1336
16/16 [==============================] - 0s 2ms/step - loss: 1.1607
16/16 [==============================] - 0s 1ms/step - loss: 1.1618
16/16 [==============================] - 0s 2ms/step - loss: 1.1622
16/16 [==============================] - 0s 4ms/step - loss: 1.1625
16/16 [==============================] - 0s 2ms/step - loss: 1.1630
16/16 [==============================] - 0s 1ms/step - loss: 1.1636
16/16 [==============================] - 0s 1ms/step - loss: 1.1638
16/16 [==============================] - 0s 2ms/step - loss: 1.1638

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5183
16/16 [==============================] - 0s 2ms/step - loss: 1.1345
16/16 [==============================] - 0s 2ms/step - loss: 1.1583
16/16 [==============================] - 0s 2ms/step - loss: 1.1593
16/16 [==============================] - 0s 2ms/step - loss: 1.1597
16/16 [==============================] - 0s 2ms/step - loss: 1.1601
16/16 [==============================] - 0s 1ms/step - loss: 1.1606
16/16 [==============================] - 0s 1ms/step - loss: 1.1612
16/16 [==============================] - 0s 2ms/step - loss: 1.1614
16/16 [==============================] - 0s 2ms/step - loss: 1.1614
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5228
16/16 [==============================] - 0s 1ms/step - loss: 1.1392
16/16 [==============================] - 0s 1ms/step - loss: 1.1615
16/16 [==============================] - 0s 977us/step - loss: 1.1623
16/16 [==============================] - 0s 1ms/step - loss: 1.1628
16/16 [==============================] - 0s 1ms/step - loss: 1.1633
16/16 [==============================] - 0s 1ms/step - loss: 1.1639
16/16 [==============================] - 0s 2ms/step - loss: 1.1646
16/16 [==============================] - 0s 1ms/step - loss: 1.1649
16/16 [==============================] - 0s 1ms/step - loss: 1.1649

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5259
16/16 [==============================] - 0s 1ms/step - loss: 1.1609
16/16 [==============================] - 0s 1ms/step - loss: 1.1832
16/16 [==============================] - 0s 1ms/step - loss: 1.1841
16/16 [==============================] - 0s 2ms/step - loss: 1.1845
16/16 [==============================] - 0s 2ms/step - loss: 1.1848
16/16 [==============================] - 0s 2ms/step - loss: 1.1853
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1861
16/16 [==============================] - 0s 2ms/step - loss: 1.1861
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5249
16/16 [==============================] - 0s 2ms/step - loss: 1.1680
16/16 [==============================] - 0s 2ms/step - loss: 1.1921
16/16 [==============================] - 0s 1ms/step - loss: 1.1930
16/16 [==============================] - 0s 1ms/step - loss: 1.1933
16/16 [==============================] - 0s 1ms/step - loss: 1.1937
16/16 [==============================] - 0s 959us/step - loss: 1.1941
16/16 [==============================] - 0s 3ms/step - loss: 1.1947
16/16 [==============================] - 0s 1ms/step - loss: 1.1949
16/16 [==============================] - 0s 1ms/step - loss: 1.1949

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5256
16/16 [==============================] - 0s 4ms/step - loss: 1.1816
16/16 [==============================] - 0s 1ms/step - loss: 1.2066
16/16 [==============================] - 0s 1ms/step - loss: 1.2075
16/16 [==============================] - 0s 1ms/step - loss: 1.2079
16/16 [==============================] - 0s 2ms/step - loss: 1.2082
16/16 [==============================] - 0s 1ms/step - loss: 1.2087
16/16 [==============================] - 0s 1ms/step - loss: 1.2092
16/16 [==============================] - 0s 1ms/step - loss: 1.2095
16/16 [==============================] - 0s 2ms/step - loss: 1.2095
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5199
16/16 [==============================] - 0s 1ms/step - loss: 1.1842
16/16 [==============================] - 0s 1ms/step - loss: 1.2109
16/16 [==============================] - 0s 2ms/step - loss: 1.2118
16/16 [==============================] - 0s 2ms/step - loss: 1.2122
16/16 [==============================] - 0s 1ms/step - loss: 1.2126
16/16 [==============================] - 0s 1ms/step - loss: 1.2131
16/16 [==============================] - 0s 4ms/step - loss: 1.2137
16/16 [==============================] - 0s 2ms/step - loss: 1.2140
16/16 [==============================] - 0s 878us/step - loss: 1.2140

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 656us/step
16/16 [==============================] - 0s 831us/step - loss: 0.5174
16/16 [==============================] - 0s 864us/step - loss: 1.1946
16/16 [==============================] - 0s 732us/step - loss: 1.2231
16/16 [==============================] - 0s 767us/step - loss: 1.2241
16/16 [==============================] - 0s 810us/step - loss: 1.2245
16/16 [==============================] - 0s 822us/step - loss: 1.2248
16/16 [==============================] - 0s 808us/step - loss: 1.2252
16/16 [==============================] - 0s 788us/step - loss: 1.2257
16/16 [==============================] - 0s 821us/step - loss: 1.2259
16/16 [==============================] - 0s 810us/step - loss: 1.2260
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 796us/step - loss: 0.5052
16/16 [==============================] - 0s 812us/step - loss: 1.2202
16/16 [==============================] - 0s 814us/step - loss: 1.2513
16/16 [==============================] - 0s 778us/step - loss: 1.2525
16/16 [==============================] - 0s 782us/step - loss: 1.2529
16/16 [==============================] - 0s 804us/step - loss: 1.2532
16/16 [==============================] - 0s 777us/step - loss: 1.2536
16/16 [==============================] - 0s 785us/step - loss: 1.2541
16/16 [==============================] - 0s 795us/step - loss: 1.2544
16/16 [==============================] - 0s 797us/step - loss: 1.2544

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 837us/step - loss: 0.5002
16/16 [==============================] - 0s 831us/step - loss: 1.2353
16/16 [==============================] - 0s 827us/step - loss: 1.2665
16/16 [==============================] - 0s 780us/step - loss: 1.2678
16/16 [==============================] - 0s 798us/step - loss: 1.2682
16/16 [==============================] - 0s 771us/step - loss: 1.2685
16/16 [==============================] - 0s 778us/step - loss: 1.2690
16/16 [==============================] - 0s 809us/step - loss: 1.2696
16/16 [==============================] - 0s 818us/step - loss: 1.2698
16/16 [==============================] - 0s 784us/step - loss: 1.2698
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 792us/step - loss: 0.4877
16/16 [==============================] - 0s 796us/step - loss: 1.2490
16/16 [==============================] - 0s 816us/step - loss: 1.2845
16/16 [==============================] - 0s 825us/step - loss: 1.2858
16/16 [==============================] - 0s 782us/step - loss: 1.2862
16/16 [==============================] - 0s 824us/step - loss: 1.2866
16/16 [==============================] - 0s 812us/step - loss: 1.2870
16/16 [==============================] - 0s 799us/step - loss: 1.2875
16/16 [==============================] - 0s 792us/step - loss: 1.2877
16/16 [==============================] - 0s 811us/step - loss: 1.2877

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 782us/step - loss: 0.4795
16/16 [==============================] - 0s 819us/step - loss: 1.2762
16/16 [==============================] - 0s 807us/step - loss: 1.3130
16/16 [==============================] - 0s 810us/step - loss: 1.3144
16/16 [==============================] - 0s 812us/step - loss: 1.3148
16/16 [==============================] - 0s 816us/step - loss: 1.3151
16/16 [==============================] - 0s 774us/step - loss: 1.3156
16/16 [==============================] - 0s 780us/step - loss: 1.3161
16/16 [==============================] - 0s 805us/step - loss: 1.3163
16/16 [==============================] - 0s 775us/step - loss: 1.3163
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 791us/step - loss: 0.4700
16/16 [==============================] - 0s 815us/step - loss: 1.2786
16/16 [==============================] - 0s 795us/step - loss: 1.3164
16/16 [==============================] - 0s 800us/step - loss: 1.3177
16/16 [==============================] - 0s 781us/step - loss: 1.3182
16/16 [==============================] - 0s 768us/step - loss: 1.3186
16/16 [==============================] - 0s 775us/step - loss: 1.3191
16/16 [==============================] - 0s 795us/step - loss: 1.3197
16/16 [==============================] - 0s 799us/step - loss: 1.3199
16/16 [==============================] - 0s 775us/step - loss: 1.3199

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 790us/step - loss: 0.4639
16/16 [==============================] - 0s 816us/step - loss: 1.2951
16/16 [==============================] - 0s 784us/step - loss: 1.3344
16/16 [==============================] - 0s 821us/step - loss: 1.3358
16/16 [==============================] - 0s 769us/step - loss: 1.3362
16/16 [==============================] - 0s 798us/step - loss: 1.3366
16/16 [==============================] - 0s 773us/step - loss: 1.3371
16/16 [==============================] - 0s 781us/step - loss: 1.3376
16/16 [==============================] - 0s 803us/step - loss: 1.3379
16/16 [==============================] - 0s 795us/step - loss: 1.3379
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 629us/step
16/16 [==============================] - 0s 792us/step - loss: 0.4496
16/16 [==============================] - 0s 777us/step - loss: 1.3229
16/16 [==============================] - 0s 782us/step - loss: 1.3686
16/16 [==============================] - 0s 793us/step - loss: 1.3703
16/16 [==============================] - 0s 798us/step - loss: 1.3707
16/16 [==============================] - 0s 792us/step - loss: 1.3710
16/16 [==============================] - 0s 784us/step - loss: 1.3714
16/16 [==============================] - 0s 780us/step - loss: 1.3719
16/16 [==============================] - 0s 803us/step - loss: 1.3720
16/16 [==============================] - 0s 773us/step - loss: 1.3721

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 780us/step - loss: 0.4461
16/16 [==============================] - 0s 772us/step - loss: 1.3343
16/16 [==============================] - 0s 771us/step - loss: 1.3836
16/16 [==============================] - 0s 777us/step - loss: 1.3853
16/16 [==============================] - 0s 823us/step - loss: 1.3857
16/16 [==============================] - 0s 797us/step - loss: 1.3861
16/16 [==============================] - 0s 783us/step - loss: 1.3865
16/16 [==============================] - 0s 770us/step - loss: 1.3870
16/16 [==============================] - 0s 769us/step - loss: 1.3871
16/16 [==============================] - 0s 791us/step - loss: 1.3872
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 793us/step - loss: 0.4388
16/16 [==============================] - 0s 803us/step - loss: 1.3348
16/16 [==============================] - 0s 785us/step - loss: 1.3881
16/16 [==============================] - 0s 795us/step - loss: 1.3898
16/16 [==============================] - 0s 784us/step - loss: 1.3903
16/16 [==============================] - 0s 814us/step - loss: 1.3906
16/16 [==============================] - 0s 764us/step - loss: 1.3910
16/16 [==============================] - 0s 769us/step - loss: 1.3915
16/16 [==============================] - 0s 766us/step - loss: 1.3917
16/16 [==============================] - 0s 770us/step - loss: 1.3917

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 785us/step - loss: 0.4335
16/16 [==============================] - 0s 778us/step - loss: 1.3689
16/16 [==============================] - 0s 776us/step - loss: 1.4249
16/16 [==============================] - 0s 794us/step - loss: 1.4268
16/16 [==============================] - 0s 773us/step - loss: 1.4272
16/16 [==============================] - 0s 770us/step - loss: 1.4275
16/16 [==============================] - 0s 770us/step - loss: 1.4279
16/16 [==============================] - 0s 788us/step - loss: 1.4283
16/16 [==============================] - 0s 792us/step - loss: 1.4285
16/16 [==============================] - 0s 802us/step - loss: 1.4285
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 797us/step - loss: 0.4265
16/16 [==============================] - 0s 805us/step - loss: 1.3817
16/16 [==============================] - 0s 815us/step - loss: 1.4402
16/16 [==============================] - 0s 784us/step - loss: 1.4422
16/16 [==============================] - 0s 785us/step - loss: 1.4426
16/16 [==============================] - 0s 791us/step - loss: 1.4429
16/16 [==============================] - 0s 811us/step - loss: 1.4432
16/16 [==============================] - 0s 791us/step - loss: 1.4435
16/16 [==============================] - 0s 809us/step - loss: 1.4437
16/16 [==============================] - 0s 777us/step - loss: 1.4437

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 622us/step
16/16 [==============================] - 0s 819us/step - loss: 0.4303
16/16 [==============================] - 0s 794us/step - loss: 1.3806
16/16 [==============================] - 0s 809us/step - loss: 1.4368
16/16 [==============================] - 0s 791us/step - loss: 1.4388
16/16 [==============================] - 0s 781us/step - loss: 1.4392
16/16 [==============================] - 0s 797us/step - loss: 1.4396
16/16 [==============================] - 0s 784us/step - loss: 1.4399
16/16 [==============================] - 0s 786us/step - loss: 1.4404
16/16 [==============================] - 0s 808us/step - loss: 1.4406
16/16 [==============================] - 0s 809us/step - loss: 1.4406
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.4255
16/16 [==============================] - 0s 2ms/step - loss: 1.3957
16/16 [==============================] - 0s 2ms/step - loss: 1.4540
16/16 [==============================] - 0s 2ms/step - loss: 1.4562
16/16 [==============================] - 0s 1ms/step - loss: 1.4566
16/16 [==============================] - 0s 2ms/step - loss: 1.4569
16/16 [==============================] - 0s 1ms/step - loss: 1.4573
16/16 [==============================] - 0s 2ms/step - loss: 1.4577
16/16 [==============================] - 0s 2ms/step - loss: 1.4579
16/16 [==============================] - 0s 4ms/step - loss: 1.4579

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4288
16/16 [==============================] - 0s 1ms/step - loss: 1.4084
16/16 [==============================] - 0s 1ms/step - loss: 1.4660
16/16 [==============================] - 0s 1ms/step - loss: 1.4681
16/16 [==============================] - 0s 2ms/step - loss: 1.4686
16/16 [==============================] - 0s 2ms/step - loss: 1.4689
16/16 [==============================] - 0s 1ms/step - loss: 1.4692
16/16 [==============================] - 0s 1ms/step - loss: 1.4696
16/16 [==============================] - 0s 1ms/step - loss: 1.4698
16/16 [==============================] - 0s 1ms/step - loss: 1.4698
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4279
16/16 [==============================] - 0s 1ms/step - loss: 1.4181
16/16 [==============================] - 0s 1ms/step - loss: 1.4764
16/16 [==============================] - 0s 5ms/step - loss: 1.4786
16/16 [==============================] - 0s 4ms/step - loss: 1.4790
16/16 [==============================] - 0s 2ms/step - loss: 1.4793
16/16 [==============================] - 0s 2ms/step - loss: 1.4796
16/16 [==============================] - 0s 1ms/step - loss: 1.4800
16/16 [==============================] - 0s 1ms/step - loss: 1.4802
16/16 [==============================] - 0s 1ms/step - loss: 1.4802

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.4335
16/16 [==============================] - 0s 1ms/step - loss: 1.4360
16/16 [==============================] - 0s 2ms/step - loss: 1.4928
16/16 [==============================] - 0s 3ms/step - loss: 1.4949
16/16 [==============================] - 0s 1ms/step - loss: 1.4954
16/16 [==============================] - 0s 1ms/step - loss: 1.4957
16/16 [==============================] - 0s 938us/step - loss: 1.4960
16/16 [==============================] - 0s 3ms/step - loss: 1.4964
16/16 [==============================] - 0s 4ms/step - loss: 1.4966
16/16 [==============================] - 0s 2ms/step - loss: 1.4966
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4357
16/16 [==============================] - 0s 1ms/step - loss: 1.4423
16/16 [==============================] - 0s 1ms/step - loss: 1.4991
16/16 [==============================] - 0s 1ms/step - loss: 1.5013
16/16 [==============================] - 0s 987us/step - loss: 1.5017
16/16 [==============================] - 0s 2ms/step - loss: 1.5019
16/16 [==============================] - 0s 2ms/step - loss: 1.5022
16/16 [==============================] - 0s 1ms/step - loss: 1.5026
16/16 [==============================] - 0s 1ms/step - loss: 1.5028
16/16 [==============================] - 0s 2ms/step - loss: 1.5028

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 4ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4458
16/16 [==============================] - 0s 3ms/step - loss: 1.4532
16/16 [==============================] - 0s 1ms/step - loss: 1.5074
16/16 [==============================] - 0s 1ms/step - loss: 1.5094
16/16 [==============================] - 0s 1ms/step - loss: 1.5098
16/16 [==============================] - 0s 1ms/step - loss: 1.5100
16/16 [==============================] - 0s 1ms/step - loss: 1.5103
16/16 [==============================] - 0s 1ms/step - loss: 1.5106
16/16 [==============================] - 0s 1ms/step - loss: 1.5107
16/16 [==============================] - 0s 2ms/step - loss: 1.5107
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4508
16/16 [==============================] - 0s 2ms/step - loss: 1.4504
16/16 [==============================] - 0s 2ms/step - loss: 1.5026
16/16 [==============================] - 0s 1ms/step - loss: 1.5046
16/16 [==============================] - 0s 1ms/step - loss: 1.5050
16/16 [==============================] - 0s 1ms/step - loss: 1.5053
16/16 [==============================] - 0s 1ms/step - loss: 1.5056
16/16 [==============================] - 0s 1ms/step - loss: 1.5060
16/16 [==============================] - 0s 1ms/step - loss: 1.5062
16/16 [==============================] - 0s 1ms/step - loss: 1.5062

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 988us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4614
16/16 [==============================] - 0s 1ms/step - loss: 1.4690
16/16 [==============================] - 0s 1ms/step - loss: 1.5199
16/16 [==============================] - 0s 1ms/step - loss: 1.5217
16/16 [==============================] - 0s 1ms/step - loss: 1.5222
16/16 [==============================] - 0s 1ms/step - loss: 1.5225
16/16 [==============================] - 0s 2ms/step - loss: 1.5228
16/16 [==============================] - 0s 891us/step - loss: 1.5233
16/16 [==============================] - 0s 1ms/step - loss: 1.5235
16/16 [==============================] - 0s 1ms/step - loss: 1.5235
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4674
16/16 [==============================] - 0s 1ms/step - loss: 1.4703
16/16 [==============================] - 0s 3ms/step - loss: 1.5202
16/16 [==============================] - 0s 1ms/step - loss: 1.5220
16/16 [==============================] - 0s 1ms/step - loss: 1.5224
16/16 [==============================] - 0s 1ms/step - loss: 1.5226
16/16 [==============================] - 0s 1ms/step - loss: 1.5229
16/16 [==============================] - 0s 1ms/step - loss: 1.5232
16/16 [==============================] - 0s 1ms/step - loss: 1.5233
16/16 [==============================] - 0s 1ms/step - loss: 1.5233

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4817
16/16 [==============================] - 0s 2ms/step - loss: 1.4794
16/16 [==============================] - 0s 2ms/step - loss: 1.5276
16/16 [==============================] - 0s 2ms/step - loss: 1.5293
16/16 [==============================] - 0s 1ms/step - loss: 1.5296
16/16 [==============================] - 0s 1ms/step - loss: 1.5299
16/16 [==============================] - 0s 2ms/step - loss: 1.5301
16/16 [==============================] - 0s 2ms/step - loss: 1.5304
16/16 [==============================] - 0s 2ms/step - loss: 1.5305
16/16 [==============================] - 0s 2ms/step - loss: 1.5305
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4878
16/16 [==============================] - 0s 1ms/step - loss: 1.4939
16/16 [==============================] - 0s 1ms/step - loss: 1.5415
16/16 [==============================] - 0s 2ms/step - loss: 1.5431
16/16 [==============================] - 0s 2ms/step - loss: 1.5435
16/16 [==============================] - 0s 1ms/step - loss: 1.5437
16/16 [==============================] - 0s 2ms/step - loss: 1.5439
16/16 [==============================] - 0s 2ms/step - loss: 1.5442
16/16 [==============================] - 0s 2ms/step - loss: 1.5443
16/16 [==============================] - 0s 2ms/step - loss: 1.5443

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5035
16/16 [==============================] - 0s 1ms/step - loss: 1.4905
16/16 [==============================] - 0s 1ms/step - loss: 1.5351
16/16 [==============================] - 0s 1ms/step - loss: 1.5365
16/16 [==============================] - 0s 1ms/step - loss: 1.5370
16/16 [==============================] - 0s 1ms/step - loss: 1.5373
16/16 [==============================] - 0s 988us/step - loss: 1.5376
16/16 [==============================] - 0s 2ms/step - loss: 1.5381
16/16 [==============================] - 0s 2ms/step - loss: 1.5382
16/16 [==============================] - 0s 2ms/step - loss: 1.5383
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5103
16/16 [==============================] - 0s 1ms/step - loss: 1.5127
16/16 [==============================] - 0s 1ms/step - loss: 1.5577
16/16 [==============================] - 0s 1ms/step - loss: 1.5592
16/16 [==============================] - 0s 4ms/step - loss: 1.5596
16/16 [==============================] - 0s 4ms/step - loss: 1.5598
16/16 [==============================] - 0s 1ms/step - loss: 1.5601
16/16 [==============================] - 0s 3ms/step - loss: 1.5604
16/16 [==============================] - 0s 1ms/step - loss: 1.5605
16/16 [==============================] - 0s 1ms/step - loss: 1.5605

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5264
16/16 [==============================] - 0s 1ms/step - loss: 1.5167
16/16 [==============================] - 0s 3ms/step - loss: 1.5597
16/16 [==============================] - 0s 2ms/step - loss: 1.5612
16/16 [==============================] - 0s 1ms/step - loss: 1.5615
16/16 [==============================] - 0s 1ms/step - loss: 1.5617
16/16 [==============================] - 0s 1ms/step - loss: 1.5620
16/16 [==============================] - 0s 1ms/step - loss: 1.5622
16/16 [==============================] - 0s 1ms/step - loss: 1.5623
16/16 [==============================] - 0s 1ms/step - loss: 1.5623
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5342
16/16 [==============================] - 0s 2ms/step - loss: 1.5283
16/16 [==============================] - 0s 2ms/step - loss: 1.5709
16/16 [==============================] - 0s 1ms/step - loss: 1.5724
16/16 [==============================] - 0s 1ms/step - loss: 1.5727
16/16 [==============================] - 0s 1ms/step - loss: 1.5729
16/16 [==============================] - 0s 2ms/step - loss: 1.5732
16/16 [==============================] - 0s 1ms/step - loss: 1.5734
16/16 [==============================] - 0s 1ms/step - loss: 1.5735
16/16 [==============================] - 0s 1ms/step - loss: 1.5735

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5499
16/16 [==============================] - 0s 2ms/step - loss: 1.5318
16/16 [==============================] - 0s 2ms/step - loss: 1.5719
16/16 [==============================] - 0s 1ms/step - loss: 1.5733
16/16 [==============================] - 0s 1ms/step - loss: 1.5736
16/16 [==============================] - 0s 2ms/step - loss: 1.5738
16/16 [==============================] - 0s 2ms/step - loss: 1.5740
16/16 [==============================] - 0s 2ms/step - loss: 1.5743
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5570
16/16 [==============================] - 0s 1ms/step - loss: 1.5475
16/16 [==============================] - 0s 1ms/step - loss: 1.5874
16/16 [==============================] - 0s 1ms/step - loss: 1.5888
16/16 [==============================] - 0s 2ms/step - loss: 1.5891
16/16 [==============================] - 0s 2ms/step - loss: 1.5892
16/16 [==============================] - 0s 2ms/step - loss: 1.5893
16/16 [==============================] - 0s 1ms/step - loss: 1.5895
16/16 [==============================] - 0s 1ms/step - loss: 1.5896
16/16 [==============================] - 0s 2ms/step - loss: 1.5896

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5733
16/16 [==============================] - 0s 1ms/step - loss: 1.5531
16/16 [==============================] - 0s 1ms/step - loss: 1.5914
16/16 [==============================] - 0s 1ms/step - loss: 1.5927
16/16 [==============================] - 0s 2ms/step - loss: 1.5931
16/16 [==============================] - 0s 2ms/step - loss: 1.5932
16/16 [==============================] - 0s 2ms/step - loss: 1.5934
16/16 [==============================] - 0s 1ms/step - loss: 1.5937
16/16 [==============================] - 0s 1ms/step - loss: 1.5938
16/16 [==============================] - 0s 1ms/step - loss: 1.5938
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 830us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5804
16/16 [==============================] - 0s 2ms/step - loss: 1.5605
16/16 [==============================] - 0s 1ms/step - loss: 1.5989
16/16 [==============================] - 0s 2ms/step - loss: 1.6002
16/16 [==============================] - 0s 1ms/step - loss: 1.6005
16/16 [==============================] - 0s 1ms/step - loss: 1.6007
16/16 [==============================] - 0s 2ms/step - loss: 1.6010
16/16 [==============================] - 0s 2ms/step - loss: 1.6013
16/16 [==============================] - 0s 1ms/step - loss: 1.6014
16/16 [==============================] - 0s 2ms/step - loss: 1.6014

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 770us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5964
16/16 [==============================] - 0s 3ms/step - loss: 1.5755
16/16 [==============================] - 0s 2ms/step - loss: 1.6137
16/16 [==============================] - 0s 2ms/step - loss: 1.6149
16/16 [==============================] - 0s 1ms/step - loss: 1.6153
16/16 [==============================] - 0s 1ms/step - loss: 1.6155
16/16 [==============================] - 0s 1ms/step - loss: 1.6157
16/16 [==============================] - 0s 2ms/step - loss: 1.6160
16/16 [==============================] - 0s 2ms/step - loss: 1.6161
16/16 [==============================] - 0s 3ms/step - loss: 1.6161
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6020
16/16 [==============================] - 0s 2ms/step - loss: 1.5861
16/16 [==============================] - 0s 4ms/step - loss: 1.6247
16/16 [==============================] - 0s 2ms/step - loss: 1.6259
16/16 [==============================] - 0s 2ms/step - loss: 1.6263
16/16 [==============================] - 0s 2ms/step - loss: 1.6264
16/16 [==============================] - 0s 1ms/step - loss: 1.6266
16/16 [==============================] - 0s 2ms/step - loss: 1.6268
16/16 [==============================] - 0s 2ms/step - loss: 1.6269
16/16 [==============================] - 0s 2ms/step - loss: 1.6269

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 896us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6162
16/16 [==============================] - 0s 1ms/step - loss: 1.5924
16/16 [==============================] - 0s 988us/step - loss: 1.6302
16/16 [==============================] - 0s 2ms/step - loss: 1.6314
16/16 [==============================] - 0s 2ms/step - loss: 1.6318
16/16 [==============================] - 0s 1ms/step - loss: 1.6319
16/16 [==============================] - 0s 1ms/step - loss: 1.6321
16/16 [==============================] - 0s 1ms/step - loss: 1.6323
16/16 [==============================] - 0s 2ms/step - loss: 1.6324
16/16 [==============================] - 0s 2ms/step - loss: 1.6324
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.6208
16/16 [==============================] - 0s 3ms/step - loss: 1.6042
16/16 [==============================] - 0s 2ms/step - loss: 1.6422
16/16 [==============================] - 0s 1ms/step - loss: 1.6435
16/16 [==============================] - 0s 2ms/step - loss: 1.6438
16/16 [==============================] - 0s 2ms/step - loss: 1.6440
16/16 [==============================] - 0s 2ms/step - loss: 1.6442
16/16 [==============================] - 0s 1ms/step - loss: 1.6444
16/16 [==============================] - 0s 1ms/step - loss: 1.6445
16/16 [==============================] - 0s 1ms/step - loss: 1.6445

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 855us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6333
16/16 [==============================] - 0s 1ms/step - loss: 1.6115
16/16 [==============================] - 0s 2ms/step - loss: 1.6493
16/16 [==============================] - 0s 2ms/step - loss: 1.6505
16/16 [==============================] - 0s 1ms/step - loss: 1.6508
16/16 [==============================] - 0s 1ms/step - loss: 1.6510
16/16 [==============================] - 0s 2ms/step - loss: 1.6512
16/16 [==============================] - 0s 2ms/step - loss: 1.6515
16/16 [==============================] - 0s 1ms/step - loss: 1.6516
16/16 [==============================] - 0s 2ms/step - loss: 1.6516
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 836us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6363
16/16 [==============================] - 0s 2ms/step - loss: 1.6203
16/16 [==============================] - 0s 1ms/step - loss: 1.6589
16/16 [==============================] - 0s 1ms/step - loss: 1.6601
16/16 [==============================] - 0s 1ms/step - loss: 1.6604
16/16 [==============================] - 0s 1ms/step - loss: 1.6606
16/16 [==============================] - 0s 771us/step - loss: 1.6608
16/16 [==============================] - 0s 1ms/step - loss: 1.6610
16/16 [==============================] - 0s 954us/step - loss: 1.6611
16/16 [==============================] - 0s 943us/step - loss: 1.6611

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6489
16/16 [==============================] - 0s 1ms/step - loss: 1.6337
16/16 [==============================] - 0s 1ms/step - loss: 1.6729
16/16 [==============================] - 0s 1ms/step - loss: 1.6741
16/16 [==============================] - 0s 1ms/step - loss: 1.6744
16/16 [==============================] - 0s 1ms/step - loss: 1.6746
16/16 [==============================] - 0s 2ms/step - loss: 1.6747
16/16 [==============================] - 0s 2ms/step - loss: 1.6749
16/16 [==============================] - 0s 1ms/step - loss: 1.6749
16/16 [==============================] - 0s 2ms/step - loss: 1.6750
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6501
16/16 [==============================] - 0s 1ms/step - loss: 1.6367
16/16 [==============================] - 0s 1ms/step - loss: 1.6765
16/16 [==============================] - 0s 3ms/step - loss: 1.6777
16/16 [==============================] - 0s 2ms/step - loss: 1.6780
16/16 [==============================] - 0s 2ms/step - loss: 1.6781
16/16 [==============================] - 0s 2ms/step - loss: 1.6783
16/16 [==============================] - 0s 1ms/step - loss: 1.6784
16/16 [==============================] - 0s 2ms/step - loss: 1.6785
16/16 [==============================] - 0s 1ms/step - loss: 1.6785

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 819us/step - loss: 0.6612
16/16 [==============================] - 0s 804us/step - loss: 1.6441
16/16 [==============================] - 0s 1ms/step - loss: 1.6840
16/16 [==============================] - 0s 785us/step - loss: 1.6852
16/16 [==============================] - 0s 1ms/step - loss: 1.6855
16/16 [==============================] - 0s 1ms/step - loss: 1.6856
16/16 [==============================] - 0s 1ms/step - loss: 1.6857
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 835us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6626
16/16 [==============================] - 0s 1ms/step - loss: 1.6545
16/16 [==============================] - 0s 805us/step - loss: 1.6944
16/16 [==============================] - 0s 804us/step - loss: 1.6957
16/16 [==============================] - 0s 1ms/step - loss: 1.6960
16/16 [==============================] - 0s 1ms/step - loss: 1.6961
16/16 [==============================] - 0s 1ms/step - loss: 1.6961
16/16 [==============================] - 0s 1ms/step - loss: 1.6962
16/16 [==============================] - 0s 778us/step - loss: 1.6962
16/16 [==============================] - 0s 792us/step - loss: 1.6962

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 791us/step - loss: 0.6744
16/16 [==============================] - 0s 976us/step - loss: 1.6678
16/16 [==============================] - 0s 1ms/step - loss: 1.7065
16/16 [==============================] - 0s 804us/step - loss: 1.7078
16/16 [==============================] - 0s 1ms/step - loss: 1.7081
16/16 [==============================] - 0s 1ms/step - loss: 1.7083
16/16 [==============================] - 0s 1ms/step - loss: 1.7085
16/16 [==============================] - 0s 777us/step - loss: 1.7087
16/16 [==============================] - 0s 800us/step - loss: 1.7088
16/16 [==============================] - 0s 789us/step - loss: 1.7088
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 618us/step
16/16 [==============================] - 0s 829us/step - loss: 0.6775
16/16 [==============================] - 0s 800us/step - loss: 1.6875
16/16 [==============================] - 0s 1ms/step - loss: 1.7276
16/16 [==============================] - 0s 1ms/step - loss: 1.7289
16/16 [==============================] - 0s 808us/step - loss: 1.7292
16/16 [==============================] - 0s 776us/step - loss: 1.7293
16/16 [==============================] - 0s 792us/step - loss: 1.7294
16/16 [==============================] - 0s 1ms/step - loss: 1.7295
16/16 [==============================] - 0s 1ms/step - loss: 1.7296
16/16 [==============================] - 0s 1ms/step - loss: 1.7296

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 831us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6904
16/16 [==============================] - 0s 1ms/step - loss: 1.7060
16/16 [==============================] - 0s 1ms/step - loss: 1.7464
16/16 [==============================] - 0s 1ms/step - loss: 1.7477
16/16 [==============================] - 0s 1ms/step - loss: 1.7480
16/16 [==============================] - 0s 1ms/step - loss: 1.7481
16/16 [==============================] - 0s 1ms/step - loss: 1.7482
16/16 [==============================] - 0s 1ms/step - loss: 1.7484
16/16 [==============================] - 0s 813us/step - loss: 1.7485
16/16 [==============================] - 0s 1ms/step - loss: 1.7485
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 779us/step - loss: 0.6923
16/16 [==============================] - 0s 771us/step - loss: 1.7161
16/16 [==============================] - 0s 799us/step - loss: 1.7569
16/16 [==============================] - 0s 819us/step - loss: 1.7583
16/16 [==============================] - 0s 1ms/step - loss: 1.7586
16/16 [==============================] - 0s 1ms/step - loss: 1.7587
16/16 [==============================] - 0s 1ms/step - loss: 1.7589
16/16 [==============================] - 0s 1ms/step - loss: 1.7591
16/16 [==============================] - 0s 1ms/step - loss: 1.7592
16/16 [==============================] - 0s 1ms/step - loss: 1.7592

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 779us/step - loss: 0.7016
16/16 [==============================] - 0s 782us/step - loss: 1.7163
16/16 [==============================] - 0s 798us/step - loss: 1.7574
16/16 [==============================] - 0s 790us/step - loss: 1.7587
16/16 [==============================] - 0s 796us/step - loss: 1.7589
16/16 [==============================] - 0s 778us/step - loss: 1.7590
16/16 [==============================] - 0s 770us/step - loss: 1.7591
16/16 [==============================] - 0s 799us/step - loss: 1.7591
16/16 [==============================] - 0s 810us/step - loss: 1.7591
16/16 [==============================] - 0s 779us/step - loss: 1.7591
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 792us/step - loss: 0.7041
16/16 [==============================] - 0s 787us/step - loss: 1.7274
16/16 [==============================] - 0s 833us/step - loss: 1.7685
16/16 [==============================] - 0s 826us/step - loss: 1.7698
16/16 [==============================] - 0s 792us/step - loss: 1.7702
16/16 [==============================] - 0s 818us/step - loss: 1.7703
16/16 [==============================] - 0s 778us/step - loss: 1.7705
16/16 [==============================] - 0s 841us/step - loss: 1.7707
16/16 [==============================] - 0s 805us/step - loss: 1.7708
16/16 [==============================] - 0s 838us/step - loss: 1.7708

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 824us/step - loss: 0.7152
16/16 [==============================] - 0s 796us/step - loss: 1.7311
16/16 [==============================] - 0s 817us/step - loss: 1.7720
16/16 [==============================] - 0s 781us/step - loss: 1.7732
16/16 [==============================] - 0s 1ms/step - loss: 1.7736
16/16 [==============================] - 0s 1ms/step - loss: 1.7737
16/16 [==============================] - 0s 1ms/step - loss: 1.7739
16/16 [==============================] - 0s 895us/step - loss: 1.7741
16/16 [==============================] - 0s 776us/step - loss: 1.7742
16/16 [==============================] - 0s 804us/step - loss: 1.7742
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 813us/step - loss: 0.7194
16/16 [==============================] - 0s 799us/step - loss: 1.7544
16/16 [==============================] - 0s 796us/step - loss: 1.7966
16/16 [==============================] - 0s 790us/step - loss: 1.7980
16/16 [==============================] - 0s 810us/step - loss: 1.7983
16/16 [==============================] - 0s 804us/step - loss: 1.7984
16/16 [==============================] - 0s 821us/step - loss: 1.7985
16/16 [==============================] - 0s 791us/step - loss: 1.7987
16/16 [==============================] - 0s 781us/step - loss: 1.7987
16/16 [==============================] - 0s 789us/step - loss: 1.7987

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 789us/step - loss: 0.7322
16/16 [==============================] - 0s 802us/step - loss: 1.7637
16/16 [==============================] - 0s 793us/step - loss: 1.8060
16/16 [==============================] - 0s 795us/step - loss: 1.8073
16/16 [==============================] - 0s 783us/step - loss: 1.8076
16/16 [==============================] - 0s 776us/step - loss: 1.8077
16/16 [==============================] - 0s 770us/step - loss: 1.8079
16/16 [==============================] - 0s 779us/step - loss: 1.8080
16/16 [==============================] - 0s 787us/step - loss: 1.8081
16/16 [==============================] - 0s 805us/step - loss: 1.8081
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 809us/step - loss: 0.7334
16/16 [==============================] - 0s 807us/step - loss: 1.7648
16/16 [==============================] - 0s 785us/step - loss: 1.8070
16/16 [==============================] - 0s 789us/step - loss: 1.8083
16/16 [==============================] - 0s 788us/step - loss: 1.8086
16/16 [==============================] - 0s 825us/step - loss: 1.8088
16/16 [==============================] - 0s 794us/step - loss: 1.8089
16/16 [==============================] - 0s 839us/step - loss: 1.8091
16/16 [==============================] - 0s 827us/step - loss: 1.8092
16/16 [==============================] - 0s 832us/step - loss: 1.8092

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 953us/step - loss: 0.7473
16/16 [==============================] - 0s 1ms/step - loss: 1.7771
16/16 [==============================] - 0s 1ms/step - loss: 1.8202
16/16 [==============================] - 0s 782us/step - loss: 1.8215
16/16 [==============================] - 0s 806us/step - loss: 1.8217
16/16 [==============================] - 0s 789us/step - loss: 1.8217
16/16 [==============================] - 0s 821us/step - loss: 1.8217
16/16 [==============================] - 0s 810us/step - loss: 1.8217
16/16 [==============================] - 0s 706us/step - loss: 1.8217
16/16 [==============================] - 0s 675us/step - loss: 1.8217
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 543us/step
16/16 [==============================] - 0s 815us/step - loss: 0.7534
16/16 [==============================] - 0s 798us/step - loss: 1.7954
16/16 [==============================] - 0s 682us/step - loss: 1.8386
16/16 [==============================] - 0s 821us/step - loss: 1.8399
16/16 [==============================] - 0s 786us/step - loss: 1.8402
16/16 [==============================] - 0s 788us/step - loss: 1.8403
16/16 [==============================] - 0s 801us/step - loss: 1.8404
16/16 [==============================] - 0s 864us/step - loss: 1.8405
16/16 [==============================] - 0s 866us/step - loss: 1.8405
16/16 [==============================] - 0s 861us/step - loss: 1.8405

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 821us/step
16/16 [==============================] - 0s 901us/step - loss: 0.7658
16/16 [==============================] - 0s 876us/step - loss: 1.7944
16/16 [==============================] - 0s 904us/step - loss: 1.8367
16/16 [==============================] - 0s 923us/step - loss: 1.8380
16/16 [==============================] - 0s 863us/step - loss: 1.8382
16/16 [==============================] - 0s 888us/step - loss: 1.8383
16/16 [==============================] - 0s 892us/step - loss: 1.8384
16/16 [==============================] - 0s 872us/step - loss: 1.8385
16/16 [==============================] - 0s 874us/step - loss: 1.8385
16/16 [==============================] - 0s 1ms/step - loss: 1.8385
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 675us/step
16/16 [==============================] - 0s 837us/step - loss: 0.7743
16/16 [==============================] - 0s 878us/step - loss: 1.8193
16/16 [==============================] - 0s 800us/step - loss: 1.8622
16/16 [==============================] - 0s 791us/step - loss: 1.8635
16/16 [==============================] - 0s 786us/step - loss: 1.8638
16/16 [==============================] - 0s 794us/step - loss: 1.8639
16/16 [==============================] - 0s 798us/step - loss: 1.8640
16/16 [==============================] - 0s 828us/step - loss: 1.8641
16/16 [==============================] - 0s 797us/step - loss: 1.8642
16/16 [==============================] - 0s 812us/step - loss: 1.8642

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 818us/step - loss: 0.7864
16/16 [==============================] - 0s 822us/step - loss: 1.8117
16/16 [==============================] - 0s 809us/step - loss: 1.8535
16/16 [==============================] - 0s 794us/step - loss: 1.8547
16/16 [==============================] - 0s 811us/step - loss: 1.8550
16/16 [==============================] - 0s 806us/step - loss: 1.8551
16/16 [==============================] - 0s 844us/step - loss: 1.8552
16/16 [==============================] - 0s 794us/step - loss: 1.8553
16/16 [==============================] - 0s 784us/step - loss: 1.8554
16/16 [==============================] - 0s 802us/step - loss: 1.8554
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 873us/step - loss: 0.7953
16/16 [==============================] - 0s 873us/step - loss: 1.8319
16/16 [==============================] - 0s 808us/step - loss: 1.8741
16/16 [==============================] - 0s 859us/step - loss: 1.8754
16/16 [==============================] - 0s 809us/step - loss: 1.8757
16/16 [==============================] - 0s 847us/step - loss: 1.8758
16/16 [==============================] - 0s 827us/step - loss: 1.8758
16/16 [==============================] - 0s 860us/step - loss: 1.8759
16/16 [==============================] - 0s 804us/step - loss: 1.8760
16/16 [==============================] - 0s 876us/step - loss: 1.8760

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 643us/step
16/16 [==============================] - 0s 808us/step - loss: 0.8131
16/16 [==============================] - 0s 893us/step - loss: 1.8454
16/16 [==============================] - 0s 809us/step - loss: 1.8876
16/16 [==============================] - 0s 907us/step - loss: 1.8889
16/16 [==============================] - 0s 873us/step - loss: 1.8891
16/16 [==============================] - 0s 886us/step - loss: 1.8892
16/16 [==============================] - 0s 869us/step - loss: 1.8892
16/16 [==============================] - 0s 876us/step - loss: 1.8892
16/16 [==============================] - 0s 808us/step - loss: 1.8892
16/16 [==============================] - 0s 796us/step - loss: 1.8892
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 694us/step - loss: 0.8154
16/16 [==============================] - 0s 812us/step - loss: 1.8371
16/16 [==============================] - 0s 815us/step - loss: 1.8781
16/16 [==============================] - 0s 796us/step - loss: 1.8793
16/16 [==============================] - 0s 867us/step - loss: 1.8796
16/16 [==============================] - 0s 798us/step - loss: 1.8797
16/16 [==============================] - 0s 791us/step - loss: 1.8798
16/16 [==============================] - 0s 878us/step - loss: 1.8799
16/16 [==============================] - 0s 872us/step - loss: 1.8800
16/16 [==============================] - 0s 799us/step - loss: 1.8800

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 830us/step - loss: 0.8363
16/16 [==============================] - 0s 883us/step - loss: 1.8623
16/16 [==============================] - 0s 873us/step - loss: 1.9037
16/16 [==============================] - 0s 817us/step - loss: 1.9049
16/16 [==============================] - 0s 837us/step - loss: 1.9052
16/16 [==============================] - 0s 811us/step - loss: 1.9052
16/16 [==============================] - 0s 862us/step - loss: 1.9053
16/16 [==============================] - 0s 859us/step - loss: 1.9054
16/16 [==============================] - 0s 839us/step - loss: 1.9054
16/16 [==============================] - 0s 809us/step - loss: 1.9054
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 860us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.8392
16/16 [==============================] - 0s 866us/step - loss: 1.8604
16/16 [==============================] - 0s 854us/step - loss: 1.9012
16/16 [==============================] - 0s 1ms/step - loss: 1.9024
16/16 [==============================] - 0s 1ms/step - loss: 1.9027
16/16 [==============================] - 0s 853us/step - loss: 1.9028
16/16 [==============================] - 0s 892us/step - loss: 1.9029
16/16 [==============================] - 0s 901us/step - loss: 1.9030
16/16 [==============================] - 0s 666us/step - loss: 1.9031
16/16 [==============================] - 0s 2ms/step - loss: 1.9031

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 570us/step
16/16 [==============================] - 0s 875us/step - loss: 0.8581
16/16 [==============================] - 0s 839us/step - loss: 1.8764
16/16 [==============================] - 0s 1ms/step - loss: 1.9169
16/16 [==============================] - 0s 793us/step - loss: 1.9180
16/16 [==============================] - 0s 829us/step - loss: 1.9183
16/16 [==============================] - 0s 852us/step - loss: 1.9184
16/16 [==============================] - 0s 2ms/step - loss: 1.9185
16/16 [==============================] - 0s 786us/step - loss: 1.9186
16/16 [==============================] - 0s 890us/step - loss: 1.9187
16/16 [==============================] - 0s 2ms/step - loss: 1.9187
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 549us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.8680
16/16 [==============================] - 0s 922us/step - loss: 1.8985
16/16 [==============================] - 0s 765us/step - loss: 1.9394
16/16 [==============================] - 0s 781us/step - loss: 1.9405
16/16 [==============================] - 0s 820us/step - loss: 1.9408
16/16 [==============================] - 0s 1ms/step - loss: 1.9409
16/16 [==============================] - 0s 781us/step - loss: 1.9410
16/16 [==============================] - 0s 755us/step - loss: 1.9411
16/16 [==============================] - 0s 811us/step - loss: 1.9412
16/16 [==============================] - 0s 2ms/step - loss: 1.9412

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 863us/step - loss: 0.8825
16/16 [==============================] - 0s 2ms/step - loss: 1.9008
16/16 [==============================] - 0s 799us/step - loss: 1.9412
16/16 [==============================] - 0s 2ms/step - loss: 1.9423
16/16 [==============================] - 0s 2ms/step - loss: 1.9425
16/16 [==============================] - 0s 2ms/step - loss: 1.9426
16/16 [==============================] - 0s 791us/step - loss: 1.9427
16/16 [==============================] - 0s 851us/step - loss: 1.9427
16/16 [==============================] - 0s 2ms/step - loss: 1.9427
16/16 [==============================] - 0s 2ms/step - loss: 1.9427
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 818us/step - loss: 0.8879
16/16 [==============================] - 0s 803us/step - loss: 1.9056
16/16 [==============================] - 0s 2ms/step - loss: 1.9456
16/16 [==============================] - 0s 1ms/step - loss: 1.9468
16/16 [==============================] - 0s 962us/step - loss: 1.9470
16/16 [==============================] - 0s 794us/step - loss: 1.9470
16/16 [==============================] - 0s 800us/step - loss: 1.9471
16/16 [==============================] - 0s 2ms/step - loss: 1.9471
16/16 [==============================] - 0s 2ms/step - loss: 1.9471
16/16 [==============================] - 0s 1ms/step - loss: 1.9471

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 830us/step - loss: 0.9059
16/16 [==============================] - 0s 1ms/step - loss: 1.9160
16/16 [==============================] - 0s 838us/step - loss: 1.9552
16/16 [==============================] - 0s 788us/step - loss: 1.9563
16/16 [==============================] - 0s 2ms/step - loss: 1.9566
16/16 [==============================] - 0s 761us/step - loss: 1.9567
16/16 [==============================] - 0s 808us/step - loss: 1.9569
16/16 [==============================] - 0s 2ms/step - loss: 1.9571
16/16 [==============================] - 0s 2ms/step - loss: 1.9571
16/16 [==============================] - 0s 1ms/step - loss: 1.9571
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 561us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.9083
16/16 [==============================] - 0s 2ms/step - loss: 1.9140
16/16 [==============================] - 0s 800us/step - loss: 1.9538
16/16 [==============================] - 0s 793us/step - loss: 1.9549
16/16 [==============================] - 0s 877us/step - loss: 1.9551
16/16 [==============================] - 0s 783us/step - loss: 1.9551
16/16 [==============================] - 0s 1ms/step - loss: 1.9551
16/16 [==============================] - 0s 1ms/step - loss: 1.9552
16/16 [==============================] - 0s 884us/step - loss: 1.9552
16/16 [==============================] - 0s 2ms/step - loss: 1.9552

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.9274
16/16 [==============================] - 0s 2ms/step - loss: 1.9310
16/16 [==============================] - 0s 2ms/step - loss: 1.9710
16/16 [==============================] - 0s 775us/step - loss: 1.9721
16/16 [==============================] - 0s 960us/step - loss: 1.9723
16/16 [==============================] - 0s 2ms/step - loss: 1.9723
16/16 [==============================] - 0s 794us/step - loss: 1.9722
16/16 [==============================] - 0s 1ms/step - loss: 1.9721
16/16 [==============================] - 0s 2ms/step - loss: 1.9721
16/16 [==============================] - 0s 2ms/step - loss: 1.9721
32/32 [==============================] - 0s 1ms/step</code></pre>
</div>
</div>
<div id="72483fdf-6840-4cf6-9822-487feeb18144" class="cell" data-execution_count="1726">
<div class="sourceCode cell-code" id="cb303"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="ffcadab2-86ee-4f93-b9af-1f7c35486ae9" class="cell" data-execution_count="1727">
<div class="sourceCode cell-code" id="cb304"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div id="b2633c01-1b6e-4bce-8896-1d3fcda3dbca" class="cell" data-execution_count="1728">
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div id="e4edd0f0-044a-4cf8-975b-cdec5be55862" class="cell" data-execution_count="1729">
<div class="sourceCode cell-code" id="cb306"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb306-1"><a href="#cb306-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-213-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="4fd8555c-1030-4ca9-8168-2a8559779308" class="cell" data-execution_count="1731">
<div class="sourceCode cell-code" id="cb309"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a>thirteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  thirteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscpstar-1" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar-1">LSCP<span class="math inline">\(\star\)</span></h3>
<div id="15095b9e-d7ea-417f-8a87-14757ecb3699" class="cell" data-execution_count="1732">
<div class="sourceCode cell-code" id="cb311"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb311-2"><a href="#cb311-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb311-3"><a href="#cb311-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb311-4"><a href="#cb311-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div id="0d823726-6c89-4165-a180-cc284f2c48e1" class="cell" data-execution_count="1733">
<div class="sourceCode cell-code" id="cb313"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="d5d59236-ad68-4abe-a1b6-91ddc62bfa17" class="cell" data-execution_count="1734">
<div class="sourceCode cell-code" id="cb314"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div id="da4d4c0c-64c3-45bb-b7fa-5eaa46369d02" class="cell" data-execution_count="1735">
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)</span></code></pre></div>
</div>
<div id="bec6647d-c517-4d62-9d50-fd9fd74912ca" class="cell" data-execution_count="1736">
<div class="sourceCode cell-code" id="cb316"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-219-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="1b6ad748-340d-4dc1-9d31-53581fd3c162" class="cell" data-execution_count="1737">
<div class="sourceCode cell-code" id="cb319"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> thirteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = thirteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="orbit-result" class="level2">
<h2 class="anchored" data-anchor-id="orbit-result">Orbit Result</h2>
<div id="ac394b08-c8d5-42dc-8e52-81e713b476fa" class="cell" data-execution_count="1738">
<div class="sourceCode cell-code" id="cb321"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen,<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1738">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.998</td>
<td>0.999</td>
<td>0.999</td>
<td>0.999</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.954</td>
<td>0.976</td>
<td>0.976</td>
<td>0.976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.948</td>
<td>0.999</td>
<td>0.946</td>
<td>0.972</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.908</td>
<td>0.977</td>
<td>0.925</td>
<td>0.950</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.916</td>
<td>0.956</td>
<td>0.956</td>
<td>0.956</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.942</td>
<td>0.969</td>
<td>0.969</td>
<td>0.969</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.443</td>
<td>0.992</td>
<td>0.417</td>
<td>0.587</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.935</td>
<td>0.960</td>
<td>0.973</td>
<td>0.966</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.950</td>
<td>0.974</td>
<td>0.974</td>
<td>0.974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.950</td>
<td>0.950</td>
<td>1.000</td>
<td>0.974</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.950</td>
<td>0.950</td>
<td>1.000</td>
<td>0.974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.988</td>
<td>0.994</td>
<td>0.994</td>
<td>0.994</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
</section>
<section id="bunny" class="level2">
<h2 class="anchored" data-anchor-id="bunny">Bunny</h2>
<hr>
<section id="bunny-저장용" class="level3">
<h3 class="anchored" data-anchor-id="bunny-저장용">bunny 저장용</h3>
<div id="d13311ab-5a96-4585-ac3e-79720ed5548b" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb322"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<div id="7fdf4bd7-e077-442f-800d-5980ebcb6fd0" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb323"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_data(data_dict,fname):</span>
<span id="cb323-2"><a href="#cb323-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname,<span class="st">'wb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb323-3"><a href="#cb323-3" aria-hidden="true" tabindex="-1"></a>        pickle.dump(data_dict,outfile)</span></code></pre></div>
</div>
<div id="3dba4947-bdbe-429c-b00a-a3e5b0eaf79a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div id="49bf6104-1809-41e3-8800-47fcb54a6461" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb325"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> graphs.Bunny()</span>
<span id="cb325-2"><a href="#cb325-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> G.N</span></code></pre></div>
</div>
<div id="85657b04-6741-4217-bd9e-6df2f3cb0e9e" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> filters.Heat(G, tau<span class="op">=</span><span class="dv">75</span>) </span></code></pre></div>
</div>
<div id="53a206a0-fc08-4621-9cdb-4a62f2514b7e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb327"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">2503</span></span></code></pre></div>
</div>
<div id="3e0b1f11-a121-41c7-9fde-0872ee600983" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb328"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a>normal <span class="op">=</span> np.random.randn(n)</span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> np.concatenate([np.random.uniform(low<span class="op">=</span><span class="dv">3</span>,high<span class="op">=</span><span class="dv">7</span>,size<span class="op">=</span><span class="dv">60</span>), np.random.uniform(low<span class="op">=-</span><span class="dv">7</span>,high<span class="op">=-</span><span class="dv">3</span>,size<span class="op">=</span><span class="dv">60</span>),np.zeros(n<span class="op">-</span><span class="dv">120</span>)])<span class="op">;</span> np.random.shuffle(unif)</span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> normal <span class="op">+</span> unif</span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier2 <span class="op">=</span> np.where(unif<span class="op">!=</span><span class="dv">0</span>)</span></code></pre></div>
</div>
<div id="aa42d5c1-0a67-42ae-8ece-361b6dd03fab" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb329"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb329-1"><a href="#cb329-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.zeros(n)</span>
<span id="cb329-2"><a href="#cb329-2" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">1000</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3234</span></span>
<span id="cb329-3"><a href="#cb329-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> g.<span class="bu">filter</span>(f, method<span class="op">=</span><span class="st">'chebyshev'</span>) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-07-04 17:37:32,017:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.</code></pre>
</div>
</div>
<div id="a8e671b0-b36d-49a7-9d48-24d42155eb52" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb331"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb331-1"><a href="#cb331-1" aria-hidden="true" tabindex="-1"></a>G.coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(2503, 3)</code></pre>
</div>
</div>
<div id="a0ece8f8-0c72-47a7-8458-03a69c361af9" class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb333"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> G.W.toarray()</span>
<span id="cb333-2"><a href="#cb333-2" aria-hidden="true" tabindex="-1"></a>_x <span class="op">=</span> G.coords[:,<span class="dv">0</span>]</span>
<span id="cb333-3"><a href="#cb333-3" aria-hidden="true" tabindex="-1"></a>_y <span class="op">=</span> G.coords[:,<span class="dv">1</span>]</span>
<span id="cb333-4"><a href="#cb333-4" aria-hidden="true" tabindex="-1"></a>_z <span class="op">=</span> <span class="op">-</span>G.coords[:,<span class="dv">2</span>]</span></code></pre></div>
</div>
<div id="35bc2079-1f33-4c64-8b79-e590c3d086bc" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb334"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb334-1"><a href="#cb334-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
</div>
<div id="4387a99f-3d0f-44b3-afb6-7f966322a085" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb335"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb335-1"><a href="#cb335-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z})</span></code></pre></div>
</div>
<div id="5aeef0f4-0d90-4315-a713-f0a836c78b68" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb336"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div id="616db851-cb98-4698-9396-1dc3c3f81df4" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb337"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> {<span class="st">'W'</span>:_W,<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z, <span class="st">'fnoise'</span>:f<span class="op">+</span>noise,<span class="st">'f'</span> : f, <span class="st">'noise'</span>: noise,<span class="st">'unif'</span>:unif,<span class="st">'index_of_trueoutlier2'</span>:index_of_trueoutlier2}</span></code></pre></div>
</div>
<div id="21342948-f1ce-4fbf-afbc-c5c43d9e900b" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb338"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a>save_data(_df,<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div id="bdb6b5e7-8ee9-47d8-8823-fb9ee6800353" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>_df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'W': array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]),
 'x': array([ 0.26815193, -0.58456893, -0.02730755, ...,  0.15397547,
        -0.45056488, -0.29405249]),
 'y': array([ 0.39314334,  0.63468595,  0.33280949, ...,  0.80205526,
         0.6207154 , -0.40187451]),
 'z': array([-0.13834514, -0.22438843,  0.08658215, ...,  0.33698514,
         0.58353051, -0.08647485]),
 'fnoise': array([-1.63569131,  0.49423926, -1.04026277, ..., -1.0694093 ,
        -0.24395499,  0.41729667]),
 'f': array([-1.54422488, -0.03596483, -0.93972715, ..., -0.01924028,
        -0.02470869, -0.26266752]),
 'noise': array([-0.09146643,  0.53020409, -0.10053563, ..., -1.05016902,
        -0.2192463 ,  0.67996419]),
 'unif': array([0., 0., 0., ..., 0., 0., 0.]),
 'index_of_trueoutlier2': (array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
          240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
          397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
          569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
          858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
         1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
         1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
         1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
         1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
         2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
         2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)}</code></pre>
</div>
</div>
<hr>
<div id="99f6ac1a-d20e-46df-af95-2d50f2126ffd" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb341"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb341-1"><a href="#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname):</span>
<span id="cb341-2"><a href="#cb341-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname, <span class="st">'rb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb341-3"><a href="#cb341-3" aria-hidden="true" tabindex="-1"></a>        data_dict <span class="op">=</span> pickle.load(outfile)</span>
<span id="cb341-4"><a href="#cb341-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_dict</span></code></pre></div>
</div>
<div id="bcc8c077-095e-4eb0-a5df-ba6b57e0460e" class="cell" data-execution_count="1911">
<div class="sourceCode cell-code" id="cb342"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a>_df1 <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div id="3cf62caa-e458-4d1f-9e9a-97fab84ff6b1" class="cell" data-execution_count="1912">
<div class="sourceCode cell-code" id="cb343"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: _df1[<span class="st">'x'</span>],<span class="st">'y'</span>:_df1[<span class="st">'y'</span>],<span class="st">'z'</span>:_df1[<span class="st">'z'</span>],<span class="st">'fnoise'</span>:_df1[<span class="st">'fnoise'</span>],<span class="st">'f'</span>:_df1[<span class="st">'f'</span>],<span class="st">'noise'</span>:_df1[<span class="st">'noise'</span>]})</span></code></pre></div>
</div>
<div id="90c54b8c-653d-4c44-a154-f4930c4286de" class="cell" data-execution_count="1913">
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> _df1[<span class="st">'unif'</span>]</span></code></pre></div>
</div>
<div id="3002dc84-c02f-4aa9-a289-3251a66cf767" class="cell" data-execution_count="1914">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a>_df1[<span class="st">'index_of_trueoutlier2'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1914">
<pre><code>(array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
         240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
         397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
         569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
         858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
        1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
        1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
        1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
        1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
        2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
        2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)</code></pre>
</div>
</div>
<div id="462a928e-6f2c-4883-81c0-79cc81a98e0f" class="cell" data-execution_count="1915">
<div class="sourceCode cell-code" id="cb347"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="co"># _df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})</span></span></code></pre></div>
</div>
<div id="edcc5751-f5ab-438d-8eab-e769d8f98424" class="cell" data-execution_count="1916">
<div class="sourceCode cell-code" id="cb348"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> unif.copy()</span></code></pre></div>
</div>
<div id="d84b0c37-7b6d-4a6f-8f8f-15ac6746d82a" class="cell" data-execution_count="1917">
<div class="sourceCode cell-code" id="cb349"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">!=</span><span class="dv">0</span>  <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_2))</span></code></pre></div>
</div>
<div id="c3ab3425-3bbe-416b-9517-02faea8ec49b" class="cell" data-execution_count="1920">
<div class="sourceCode cell-code" id="cb350"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one_2).to_csv('bunny_outlier.csv')</span></span></code></pre></div>
</div>
<div id="58484f48-53fc-4bfe-a363-2226222b30be" class="cell" data-execution_count="1748">
<div class="sourceCode cell-code" id="cb351"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)[:,:<span class="dv">4</span>]</span></code></pre></div>
</div>
</section>
<section id="gode-2" class="level3">
<h3 class="anchored" data-anchor-id="gode-2">GODE</h3>
<div id="356dc7bb-1003-4fb1-9ca2-df0ceb8ce18e" class="cell" data-execution_count="1749">
<div class="sourceCode cell-code" id="cb352"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> _df1[<span class="st">'W'</span>]</span></code></pre></div>
</div>
<div id="1c61a42a-2378-4c8b-9a93-c1b53656550c" class="cell" data-execution_count="1750">
<div class="sourceCode cell-code" id="cb353"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb353-1"><a href="#cb353-1" aria-hidden="true" tabindex="-1"></a>_BUNNY <span class="op">=</span> BUNNY(_df)</span></code></pre></div>
</div>
<div id="0f7b7ce9-041c-4572-be2f-30a1594182c1" class="cell" data-execution_count="1751">
<div class="sourceCode cell-code" id="cb354"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a>_BUNNY.fit(sd<span class="op">=</span><span class="dv">20</span>,ref<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div>
</div>
<div id="fbbcd8c0-c4ac-4982-9ad5-084cdc1e0a59" class="cell" data-execution_count="1752">
<div class="sourceCode cell-code" id="cb355"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(_BUNNY.f)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1752">
<pre><code>2503</code></pre>
</div>
</div>
<div id="207679e3-6f20-49d4-b36f-a59ceaf64967" class="cell" data-execution_count="1753">
<div class="sourceCode cell-code" id="cb357"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb357-1"><a href="#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2503</span><span class="op">*</span><span class="fl">0.05</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1753">
<pre><code>125.15</code></pre>
</div>
</div>
<div id="24276e3d-0800-46e5-9567-6d17ed00f0d5" class="cell" data-execution_count="1754">
<div class="sourceCode cell-code" id="cb359"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb359-1"><a href="#cb359-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_BUNNY.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div id="ef0e8856-0fac-4b87-a5b7-c43dd1255df0" class="cell" data-execution_count="1755">
<div class="sourceCode cell-code" id="cb360"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a><span class="co"># outlier_simul_one = list(map(lambda x: -1 if x &gt; 8.7 else 1,outlier_simul_one))</span></span></code></pre></div>
</div>
<div id="6a2deeae-d5da-4d56-98e3-b136ef041026" class="cell" data-execution_count="1756">
<div class="sourceCode cell-code" id="cb361"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb361-1"><a href="#cb361-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">8.05</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div id="d9532b5b-59f2-4454-85a5-56e06aa01b07" class="cell" data-execution_count="1757">
<div class="sourceCode cell-code" id="cb362"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1757">
<pre><code>2378</code></pre>
</div>
</div>
<div id="51a161c8-d7b9-400f-be1b-9525e475b75b" class="cell" data-execution_count="1758">
<div class="sourceCode cell-code" id="cb364"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb364-1"><a href="#cb364-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1758">
<pre><code>125</code></pre>
</div>
</div>
<div id="4b14ca94-f4d4-4ba9-98fd-08cb1d711ffc" class="cell" data-execution_count="1759">
<div class="sourceCode cell-code" id="cb366"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)</span></code></pre></div>
</div>
<div id="879123b3-96fd-4801-96d1-58f65ed1c2aa" class="cell" data-execution_count="1760">
<div class="sourceCode cell-code" id="cb367"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb367-1"><a href="#cb367-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-259-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.995
Recall: 0.993
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="fd294420-ea7e-4644-9e02-792b94e824b5" class="cell" data-execution_count="1761">
<div class="sourceCode cell-code" id="cb370"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lof" class="level3">
<h3 class="anchored" data-anchor-id="lof">LOF</h3>
<div id="6ebaa979-a6a5-4791-bdc2-8da2b796107f" class="cell" data-execution_count="1762">
<div class="sourceCode cell-code" id="cb371"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb371-1"><a href="#cb371-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div id="a14d512f-0ba1-4611-b902-9208d4981e3a" class="cell" data-execution_count="1763">
<div class="sourceCode cell-code" id="cb372"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)</span></code></pre></div>
</div>
<div id="5f319d00-a9c7-4ff0-a4fa-81f70c3594fc" class="cell" data-execution_count="1764">
<div class="sourceCode cell-code" id="cb373"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb373-1"><a href="#cb373-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-263-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.913
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="9dc634b9-d4c1-4dbd-afd4-d1df5d9bcead" class="cell" data-execution_count="1766">
<div class="sourceCode cell-code" id="cb376"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb376-1"><a href="#cb376-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn-2" class="level3">
<h3 class="anchored" data-anchor-id="knn-2">KNN</h3>
<div id="ebd94da5-66c7-477e-8269-c61c1b139bdd" class="cell" data-tags="[]" data-execution_count="1767">
<div class="sourceCode cell-code" id="cb378"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb378-1"><a href="#cb378-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb378-2"><a href="#cb378-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb378-3"><a href="#cb378-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="ebcb1883-348b-40b8-b534-655018b1b537" class="cell" data-execution_count="1768">
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="d957a8f6-7f3f-4879-957f-2aa2df478972" class="cell" data-execution_count="1769">
<div class="sourceCode cell-code" id="cb380"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb380-1"><a href="#cb380-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div id="bbee32e4-3b9b-441c-ae12-69a9a07e14d5" class="cell" data-execution_count="1770">
<div class="sourceCode cell-code" id="cb381"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)</span></code></pre></div>
</div>
<div id="996818d7-ef9e-4fbe-8d84-0c830d347cf4" class="cell" data-execution_count="1771">
<div class="sourceCode cell-code" id="cb382"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-269-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.997
Recall: 0.942
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="9c58d956-d981-4e53-b68d-15461cfa8530" class="cell" data-execution_count="1772">
<div class="sourceCode cell-code" id="cb385"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof-1" class="level3">
<h3 class="anchored" data-anchor-id="cblof-1">CBLOF</h3>
<div id="9c44344f-c9f7-43a3-b1d5-2ffa4553af04" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb387"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb387-1"><a href="#cb387-1" aria-hidden="true" tabindex="-1"></a>_df1 <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div id="3983b934-32a2-4619-852d-588e5c67e5ec" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb388"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> pd.read_csv(<span class="st">'bunny_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].to_list()</span></code></pre></div>
</div>
<div id="228ba848-c512-412c-89dc-91a211aa4826" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb389"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: _df1[<span class="st">'x'</span>],<span class="st">'y'</span>:_df1[<span class="st">'y'</span>],<span class="st">'z'</span>:_df1[<span class="st">'z'</span>],<span class="st">'fnoise'</span>:_df1[<span class="st">'fnoise'</span>],<span class="st">'f'</span>:_df1[<span class="st">'f'</span>],<span class="st">'noise'</span>:_df1[<span class="st">'noise'</span>]})</span></code></pre></div>
</div>
<div id="8b00c51e-8a34-4ab8-8706-3d4e44d940cb" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb390"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb390-2"><a href="#cb390-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb390-3"><a href="#cb390-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div id="a8fbe55e-6a19-4c03-9775-230053eca6d2" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb392"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="5429a0a8-163b-4a78-827e-fd87c67dcd44" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb393"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div id="3848b658-a40e-40dc-a797-bf4c18c6bad3" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)</span></code></pre></div>
</div>
<div id="2b1041db-84eb-4d99-90d2-6471cc20f266" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb395"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-278-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.974
Precision: 0.988
Recall: 0.985
F1 Score: 0.987</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<div id="7e54059b-9766-4ab8-80f7-ea2a795ca81b" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb398"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb398-1"><a href="#cb398-1" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
</div>
<ul>
<li>Accuracy: 0.974</li>
<li>Precision: 0.988</li>
<li>Recall: 0.985</li>
<li>F1 Score: 0.987</li>
</ul>
</section>
<section id="ocsvm-2" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-2">OCSVM</h3>
<div id="7bd8b236-4653-4131-aa04-41111d185483" class="cell" data-execution_count="1774">
<div class="sourceCode cell-code" id="cb399"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb399-1"><a href="#cb399-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="9ce01aaf-fe0e-49ca-b600-5492a7386b11" class="cell" data-execution_count="1775">
<div class="sourceCode cell-code" id="cb400"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1775">
<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-9" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.1, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" checked=""><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.1, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div id="a55376ec-404b-476e-9a89-1a028f4d6921" class="cell" data-execution_count="1776">
<div class="sourceCode cell-code" id="cb401"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb401-1"><a href="#cb401-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div id="73ce90c4-2288-40e9-a7c1-13761112a507" class="cell" data-execution_count="1777">
<div class="sourceCode cell-code" id="cb402"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb402-1"><a href="#cb402-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)</span></code></pre></div>
</div>
<div id="4ff333b9-31f8-41ba-8d42-4483fcd14260" class="cell" data-execution_count="1778">
<div class="sourceCode cell-code" id="cb403"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb403-1"><a href="#cb403-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-284-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.992
Recall: 0.939
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="d2506ff8-caea-4678-9ff1-55942ab8b105" class="cell" data-execution_count="1779">
<div class="sourceCode cell-code" id="cb406"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb406-1"><a href="#cb406-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcd" class="level3">
<h3 class="anchored" data-anchor-id="mcd">MCD</h3>
<div id="dac94df3-372e-4e42-99f2-f5e70e548ea3" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1791">
<div class="sourceCode cell-code" id="cb408"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb408-1"><a href="#cb408-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb408-2"><a href="#cb408-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb408-3"><a href="#cb408-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="b9cf263d-6922-454c-80e5-459747a0c2eb" class="cell" data-execution_count="1792">
<div class="sourceCode cell-code" id="cb409"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb409-1"><a href="#cb409-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="dfcb2a3b-0064-4b46-a006-c3904b90226f" class="cell" data-execution_count="1793">
<div class="sourceCode cell-code" id="cb410"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb410-1"><a href="#cb410-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div id="15f7bc37-12e7-44a5-b711-c2b04ff3484b" class="cell" data-execution_count="1794">
<div class="sourceCode cell-code" id="cb411"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)</span></code></pre></div>
</div>
<div id="c8ccea94-09c5-4f91-8db5-61fb0f6d76a9" class="cell" data-execution_count="1795">
<div class="sourceCode cell-code" id="cb412"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb412-1"><a href="#cb412-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-290-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.982
Precision: 0.992
Recall: 0.989
F1 Score: 0.990</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="233983cd-aa09-453f-98af-9601371f33f5" class="cell" data-execution_count="1796">
<div class="sourceCode cell-code" id="cb415"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb415-1"><a href="#cb415-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-bagging" class="level3">
<h3 class="anchored" data-anchor-id="feature-bagging">Feature Bagging</h3>
<div id="26f70fde-9cae-4c7e-95d7-80ac029fadae" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1797">
<div class="sourceCode cell-code" id="cb417"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb417-1"><a href="#cb417-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb417-2"><a href="#cb417-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb417-3"><a href="#cb417-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="c936dde6-37c3-4b26-9e81-943261332725" class="cell" data-execution_count="1798">
<div class="sourceCode cell-code" id="cb418"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="71cfbd17-a36c-4c26-8b29-d85cce17c6e1" class="cell" data-execution_count="1799">
<div class="sourceCode cell-code" id="cb419"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb419-1"><a href="#cb419-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div id="75460ac3-26fd-4dc8-a076-ff127b396550" class="cell" data-execution_count="1800">
<div class="sourceCode cell-code" id="cb420"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb420-1"><a href="#cb420-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)</span></code></pre></div>
</div>
<div id="943c9107-52f7-4e11-8510-9695af300aa4" class="cell" data-execution_count="1801">
<div class="sourceCode cell-code" id="cb421"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb421-1"><a href="#cb421-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-296-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.977
Recall: 0.974
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="1ac245ea-8029-4909-88cb-bc5c35b7c54c" class="cell" data-execution_count="1802">
<div class="sourceCode cell-code" id="cb424"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb424-1"><a href="#cb424-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abod" class="level3">
<h3 class="anchored" data-anchor-id="abod">ABOD</h3>
<div id="2fa20a90-e548-4588-b82f-a022fcdc7480" class="cell" data-execution_count="1803">
<div class="sourceCode cell-code" id="cb426"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb426-1"><a href="#cb426-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb426-2"><a href="#cb426-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb426-3"><a href="#cb426-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="68710435-f76d-4ca4-a1eb-80876bde4b18" class="cell" data-execution_count="1804">
<div class="sourceCode cell-code" id="cb427"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb427-1"><a href="#cb427-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="a7adc46e-e635-4965-81e7-fad16ee4ca47" class="cell" data-execution_count="1805">
<div class="sourceCode cell-code" id="cb428"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb428-1"><a href="#cb428-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div id="0ac2625c-b2cc-4c30-a5fd-e6b65dcac8f1" class="cell" data-execution_count="1806">
<div class="sourceCode cell-code" id="cb429"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb429-1"><a href="#cb429-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)</span></code></pre></div>
</div>
<div id="c838d238-03aa-4509-9ef6-6bd22fd0b632" class="cell" data-execution_count="1807">
<div class="sourceCode cell-code" id="cb430"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb430-1"><a href="#cb430-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-302-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.979
Precision: 0.990
Recall: 0.988
F1 Score: 0.989</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="8ad8dbb6-c607-49d4-ba03-da9188b183a6" class="cell" data-execution_count="1809">
<div class="sourceCode cell-code" id="cb433"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb433-1"><a href="#cb433-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
<p>normal fix 안 해줘서 좀 다른듯</p>
</section>
<section id="iforest" class="level3">
<h3 class="anchored" data-anchor-id="iforest">IForest</h3>
<div id="7ba5fe34-e7ae-42c7-abd9-f78f10e87617" class="cell" data-execution_count="1810">
<div class="sourceCode cell-code" id="cb435"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb435-1"><a href="#cb435-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb435-2"><a href="#cb435-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb435-3"><a href="#cb435-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">125</span></span>
<span id="cb435-4"><a href="#cb435-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="8bbcd696-cff0-411a-9233-293dd09c1485" class="cell" data-execution_count="1811">
<div class="sourceCode cell-code" id="cb436"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb436-1"><a href="#cb436-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span></code></pre></div>
</div>
<div id="09a50b58-8ef5-4732-b136-4a79d0cbe851" class="cell" data-execution_count="1812">
<div class="sourceCode cell-code" id="cb437"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb437-1"><a href="#cb437-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb437-2"><a href="#cb437-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]],</span>
<span id="cb437-3"><a href="#cb437-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb437-4"><a href="#cb437-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="2ccc3405-d9b0-4699-893b-a5784a88af9c" class="cell" data-execution_count="1813">
<div class="sourceCode cell-code" id="cb438"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb438-1"><a href="#cb438-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div id="32e1236f-7fc8-428f-a884-36fac3974cf2" class="cell" data-execution_count="1814">
<div class="sourceCode cell-code" id="cb439"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb439-1"><a href="#cb439-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div id="876318ab-934d-4c61-9da5-3fbe66051fb7" class="cell" data-execution_count="1815">
<div class="sourceCode cell-code" id="cb440"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb440-1"><a href="#cb440-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div id="237b4a33-06cc-4793-87a7-d667f45dba0d" class="cell" data-execution_count="1816">
<div class="sourceCode cell-code" id="cb441"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb441-1"><a href="#cb441-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)</span></code></pre></div>
</div>
<div id="409c10da-3ef0-4ba7-aea1-2a75fc71fed1" class="cell" data-execution_count="1817">
<div class="sourceCode cell-code" id="cb442"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb442-1"><a href="#cb442-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-311-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.827
Precision: 0.995
Recall: 0.822
F1 Score: 0.900</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="79810773-8d57-4372-ba48-ebd28ffaad16" class="cell" data-execution_count="1818">
<div class="sourceCode cell-code" id="cb445"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb445-1"><a href="#cb445-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbos" class="level3">
<h3 class="anchored" data-anchor-id="hbos">HBOS</h3>
<div id="731a662b-f20b-48f8-a3ae-5440ec8e6c4c" class="cell" data-execution_count="1819">
<div class="sourceCode cell-code" id="cb447"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb447-1"><a href="#cb447-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb447-2"><a href="#cb447-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb447-3"><a href="#cb447-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="9df21c57-05fa-4055-94f2-e5c2e94f15cf" class="cell" data-execution_count="1820">
<div class="sourceCode cell-code" id="cb448"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb448-1"><a href="#cb448-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="9699ee9a-6f2d-4eae-abc4-8fb612c5ff57" class="cell" data-execution_count="1821">
<div class="sourceCode cell-code" id="cb449"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb449-1"><a href="#cb449-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div id="4ef67898-a67e-44f5-b220-9ce2091415e0" class="cell" data-execution_count="1822">
<div class="sourceCode cell-code" id="cb450"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb450-1"><a href="#cb450-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)</span></code></pre></div>
</div>
<div id="fc947c63-29f7-409b-9f31-a835261bdead" class="cell" data-execution_count="1823">
<div class="sourceCode cell-code" id="cb451"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb451-1"><a href="#cb451-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-317-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.919
Precision: 0.958
Recall: 0.956
F1 Score: 0.957</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="2373685e-b4d4-4c04-9dd2-02a3cdf54775" class="cell" data-execution_count="1825">
<div class="sourceCode cell-code" id="cb454"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb454-1"><a href="#cb454-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sos" class="level3">
<h3 class="anchored" data-anchor-id="sos">SOS</h3>
<div id="243d69d7-4a99-4032-9589-8e624c53faf0" class="cell" data-execution_count="1826">
<div class="sourceCode cell-code" id="cb456"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb456-1"><a href="#cb456-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb456-2"><a href="#cb456-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb456-3"><a href="#cb456-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div id="b8c7e25d-d691-4661-8977-f01b4008ca1a" class="cell" data-execution_count="1827">
<div class="sourceCode cell-code" id="cb457"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb457-1"><a href="#cb457-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="435842a5-e178-4f61-a786-2ff7a7a7b3b3" class="cell" data-execution_count="1828">
<div class="sourceCode cell-code" id="cb458"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb458-1"><a href="#cb458-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div id="ede1254d-731d-4257-b921-ae7b56339a05" class="cell" data-execution_count="1829">
<div class="sourceCode cell-code" id="cb459"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb459-1"><a href="#cb459-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)</span></code></pre></div>
</div>
<div id="8905cac1-5f7a-4268-8727-e54a6b285d77" class="cell" data-execution_count="1830">
<div class="sourceCode cell-code" id="cb460"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb460-1"><a href="#cb460-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-323-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.912
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="a3384720-d660-461f-8431-5fe8063c64fd" class="cell" data-execution_count="1832">
<div class="sourceCode cell-code" id="cb463"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb463-1"><a href="#cb463-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaal-1" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal-1">SO_GAAL</h3>
<div id="498d6a54-7758-473b-828b-7c3aad9b1ba9" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1833">
<div class="sourceCode cell-code" id="cb465"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb465-1"><a href="#cb465-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb465-2"><a href="#cb465-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb465-3"><a href="#cb465-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:

Testing for epoch 1 index 3:

Testing for epoch 1 index 4:

Testing for epoch 1 index 5:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:

Testing for epoch 2 index 3:

Testing for epoch 2 index 4:

Testing for epoch 2 index 5:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:

Testing for epoch 3 index 3:

Testing for epoch 3 index 4:

Testing for epoch 3 index 5:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:

Testing for epoch 4 index 3:

Testing for epoch 4 index 4:

Testing for epoch 4 index 5:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:

Testing for epoch 5 index 3:

Testing for epoch 5 index 4:

Testing for epoch 5 index 5:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:

Testing for epoch 6 index 3:

Testing for epoch 6 index 4:

Testing for epoch 6 index 5:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:

Testing for epoch 7 index 3:

Testing for epoch 7 index 4:

Testing for epoch 7 index 5:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:

Testing for epoch 8 index 3:

Testing for epoch 8 index 4:

Testing for epoch 8 index 5:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:

Testing for epoch 9 index 3:

Testing for epoch 9 index 4:

Testing for epoch 9 index 5:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:

Testing for epoch 10 index 3:

Testing for epoch 10 index 4:

Testing for epoch 10 index 5:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:

Testing for epoch 11 index 3:

Testing for epoch 11 index 4:

Testing for epoch 11 index 5:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:

Testing for epoch 12 index 3:

Testing for epoch 12 index 4:

Testing for epoch 12 index 5:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:

Testing for epoch 13 index 3:

Testing for epoch 13 index 4:

Testing for epoch 13 index 5:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:

Testing for epoch 14 index 3:

Testing for epoch 14 index 4:

Testing for epoch 14 index 5:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:

Testing for epoch 15 index 3:

Testing for epoch 15 index 4:

Testing for epoch 15 index 5:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:

Testing for epoch 16 index 3:

Testing for epoch 16 index 4:

Testing for epoch 16 index 5:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:

Testing for epoch 17 index 3:

Testing for epoch 17 index 4:

Testing for epoch 17 index 5:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:

Testing for epoch 18 index 3:

Testing for epoch 18 index 4:

Testing for epoch 18 index 5:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:

Testing for epoch 19 index 3:

Testing for epoch 19 index 4:

Testing for epoch 19 index 5:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:

Testing for epoch 20 index 3:

Testing for epoch 20 index 4:

Testing for epoch 20 index 5:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:

Testing for epoch 21 index 3:

Testing for epoch 21 index 4:

Testing for epoch 21 index 5:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7853

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 5ms/step - loss: 1.8346

Testing for epoch 22 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 1.8320

Testing for epoch 22 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.8046

Testing for epoch 22 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 1.8184
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8771

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8672

Testing for epoch 23 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 1.8837

Testing for epoch 23 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.8886

Testing for epoch 23 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 1.9140
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8837

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9102

Testing for epoch 24 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9125

Testing for epoch 24 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0084

Testing for epoch 24 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 1.9376
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9044

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9835

Testing for epoch 25 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9699

Testing for epoch 25 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.9834

Testing for epoch 25 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.0290
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9765

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9838

Testing for epoch 26 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9822

Testing for epoch 26 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0609

Testing for epoch 26 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.0396
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0832

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0676

Testing for epoch 27 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.0518

Testing for epoch 27 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0792

Testing for epoch 27 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1063
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1162

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0633

Testing for epoch 28 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.0415

Testing for epoch 28 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.1830

Testing for epoch 28 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.1030
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0691

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.1029

Testing for epoch 29 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.0695

Testing for epoch 29 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.1422

Testing for epoch 29 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.1041
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1561

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1334

Testing for epoch 30 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1333

Testing for epoch 30 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.0868

Testing for epoch 30 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.0846
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1405

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1730

Testing for epoch 31 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1575

Testing for epoch 31 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.1294

Testing for epoch 31 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1989
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1998

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1295

Testing for epoch 32 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2162

Testing for epoch 32 index 4:
16/16 [==============================] - 0s 3ms/step - loss: 2.2034

Testing for epoch 32 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1361
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2382

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2261

Testing for epoch 33 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1818

Testing for epoch 33 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2120

Testing for epoch 33 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2132
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2494

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2255

Testing for epoch 34 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2671

Testing for epoch 34 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2116

Testing for epoch 34 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.2581
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.2491

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2208

Testing for epoch 35 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.2014

Testing for epoch 35 index 4:
16/16 [==============================] - 0s 3ms/step - loss: 2.2550

Testing for epoch 35 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2830
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2405

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.3333

Testing for epoch 36 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.2521

Testing for epoch 36 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.2896

Testing for epoch 36 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3155
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3146

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2681

Testing for epoch 37 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.2337

Testing for epoch 37 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2561

Testing for epoch 37 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2611
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.3340

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2951

Testing for epoch 38 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2973

Testing for epoch 38 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3241

Testing for epoch 38 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.3202
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2970

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2818

Testing for epoch 39 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2771

Testing for epoch 39 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.3100

Testing for epoch 39 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.2902
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3639

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2836

Testing for epoch 40 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4120

Testing for epoch 40 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.3052

Testing for epoch 40 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.2881
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3652

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.3530

Testing for epoch 41 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3983

Testing for epoch 41 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3804

Testing for epoch 41 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.3145
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3505

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.3759

Testing for epoch 42 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3779

Testing for epoch 42 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4360

Testing for epoch 42 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3967
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.4442

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.3817

Testing for epoch 43 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4227

Testing for epoch 43 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3354

Testing for epoch 43 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3362
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3727

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4077

Testing for epoch 44 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.4266

Testing for epoch 44 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4087

Testing for epoch 44 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3740
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4019

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4554

Testing for epoch 45 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4162

Testing for epoch 45 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4631

Testing for epoch 45 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.4390
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3997

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4826

Testing for epoch 46 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3973

Testing for epoch 46 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4596

Testing for epoch 46 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.4296
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.4578

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5058

Testing for epoch 47 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4464

Testing for epoch 47 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4684

Testing for epoch 47 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.4405
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4991

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4709

Testing for epoch 48 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4676

Testing for epoch 48 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4131

Testing for epoch 48 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.4753
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5160

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4963

Testing for epoch 49 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.4678

Testing for epoch 49 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4248

Testing for epoch 49 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.5513
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.4780

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4913

Testing for epoch 50 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4956

Testing for epoch 50 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4918

Testing for epoch 50 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.4777
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5556

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4938

Testing for epoch 51 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.4807

Testing for epoch 51 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5070

Testing for epoch 51 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.5431
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4874

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5284

Testing for epoch 52 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5150

Testing for epoch 52 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5187

Testing for epoch 52 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.5245
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5878

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5331

Testing for epoch 53 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5031

Testing for epoch 53 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5649

Testing for epoch 53 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.5189
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5311

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5879

Testing for epoch 54 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5670

Testing for epoch 54 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5522

Testing for epoch 54 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.5572
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5563

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5327

Testing for epoch 55 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5742

Testing for epoch 55 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4747

Testing for epoch 55 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.5711
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5344

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5182

Testing for epoch 56 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4722

Testing for epoch 56 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5704

Testing for epoch 56 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6122
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.5826

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5456

Testing for epoch 57 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5821

Testing for epoch 57 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5895

Testing for epoch 57 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.6114
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5628

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5592

Testing for epoch 58 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.6494

Testing for epoch 58 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5955

Testing for epoch 58 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6131
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.6084

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5200

Testing for epoch 59 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.5612

Testing for epoch 59 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5473

Testing for epoch 59 index 5:
16/16 [==============================] - 0s 5ms/step - loss: 2.6558
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.6821

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5944

Testing for epoch 60 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.6211

Testing for epoch 60 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5937

Testing for epoch 60 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6623
79/79 [==============================] - 0s 1ms/step</code></pre>
</div>
</div>
<div id="fbc0891d-3399-4639-afd6-208bf453338b" class="cell" data-execution_count="1834">
<div class="sourceCode cell-code" id="cb468"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb468-1"><a href="#cb468-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="c3353c2b-9347-44d2-ba71-3c8cced3bfca" class="cell" data-execution_count="1835">
<div class="sourceCode cell-code" id="cb469"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb469-1"><a href="#cb469-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div id="9c8b9234-7ff7-4b80-a3f2-7b5cd9da860d" class="cell" data-execution_count="1836">
<div class="sourceCode cell-code" id="cb470"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb470-1"><a href="#cb470-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div id="dad4dc36-d6a8-4d5e-98a6-67f79e14c056" class="cell" data-execution_count="1837">
<div class="sourceCode cell-code" id="cb471"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb471-1"><a href="#cb471-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-329-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="261e9c52-7eb6-4f90-93d9-567f8943da85" class="cell" data-execution_count="1838">
<div class="sourceCode cell-code" id="cb474"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb474-1"><a href="#cb474-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaal" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaal">MO_GAAL</h3>
<div id="7adfa27d-2cc5-41e5-90a1-3945e71192fb" class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1839">
<div class="sourceCode cell-code" id="cb476"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb476-1"><a href="#cb476-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb476-2"><a href="#cb476-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb476-3"><a href="#cb476-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 2 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 3 index 3:
79/79 [==============================] - 0s 664us/step

Testing for epoch 3 index 4:
79/79 [==============================] - 0s 875us/step

Testing for epoch 3 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 4 of 60

Testing for epoch 4 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 4 index 2:
79/79 [==============================] - 0s 820us/step

Testing for epoch 4 index 3:
79/79 [==============================] - 0s 609us/step

Testing for epoch 4 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 4 index 5:
79/79 [==============================] - 0s 512us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 5 index 2:
79/79 [==============================] - 0s 684us/step

Testing for epoch 5 index 3:
79/79 [==============================] - 0s 589us/step

Testing for epoch 5 index 4:
79/79 [==============================] - 0s 742us/step

Testing for epoch 5 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 6 of 60

Testing for epoch 6 index 1:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 6 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 6 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 6 index 4:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 6 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 7 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 7 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 7 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 7 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 8 of 60

Testing for epoch 8 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 8 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 8 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 8 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 8 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 9 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 9 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 9 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 9 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 10 of 60

Testing for epoch 10 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 10 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 11 of 60

Testing for epoch 11 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 11 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 12 of 60

Testing for epoch 12 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 12 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 13 of 60

Testing for epoch 13 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 14 of 60

Testing for epoch 14 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 15 of 60

Testing for epoch 15 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 5:
79/79 [==============================] - 0s 976us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 16 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 17 of 60

Testing for epoch 17 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 17 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 18 of 60

Testing for epoch 18 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 18 index 2:
79/79 [==============================] - 0s 891us/step

Testing for epoch 18 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 19 of 60

Testing for epoch 19 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 20 of 60

Testing for epoch 20 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 20 index 2:
79/79 [==============================] - 0s 978us/step

Testing for epoch 20 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 20 index 4:
79/79 [==============================] - 0s 969us/step

Testing for epoch 20 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 21 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2249
16/16 [==============================] - 0s 1ms/step - loss: 1.3848
16/16 [==============================] - 0s 2ms/step - loss: 1.5898
16/16 [==============================] - 1s 2ms/step - loss: 1.6900
16/16 [==============================] - 0s 1ms/step - loss: 1.7373
16/16 [==============================] - 0s 2ms/step - loss: 1.7695
16/16 [==============================] - 0s 1ms/step - loss: 1.7774
16/16 [==============================] - 0s 1ms/step - loss: 1.7766
16/16 [==============================] - 0s 1ms/step - loss: 1.7754
16/16 [==============================] - 0s 1ms/step - loss: 1.7754

Testing for epoch 21 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2249
16/16 [==============================] - 0s 2ms/step - loss: 1.4195
16/16 [==============================] - 0s 3ms/step - loss: 1.6365
16/16 [==============================] - 0s 2ms/step - loss: 1.7426
16/16 [==============================] - 0s 2ms/step - loss: 1.7927
16/16 [==============================] - 0s 2ms/step - loss: 1.8275
16/16 [==============================] - 0s 1ms/step - loss: 1.8359
16/16 [==============================] - 0s 1ms/step - loss: 1.8351
16/16 [==============================] - 0s 2ms/step - loss: 1.8338
16/16 [==============================] - 0s 2ms/step - loss: 1.8338

Testing for epoch 21 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.2255
16/16 [==============================] - 0s 2ms/step - loss: 1.4083
16/16 [==============================] - 0s 2ms/step - loss: 1.6229
16/16 [==============================] - 0s 1ms/step - loss: 1.7262
16/16 [==============================] - 0s 1ms/step - loss: 1.7739
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8141
16/16 [==============================] - 0s 1ms/step - loss: 1.8131
16/16 [==============================] - 0s 2ms/step - loss: 1.8118
16/16 [==============================] - 0s 2ms/step - loss: 1.8117

Testing for epoch 21 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2193
16/16 [==============================] - 0s 2ms/step - loss: 1.4150
16/16 [==============================] - 0s 2ms/step - loss: 1.6347
16/16 [==============================] - 0s 2ms/step - loss: 1.7387
16/16 [==============================] - 0s 1ms/step - loss: 1.7855
16/16 [==============================] - 0s 2ms/step - loss: 1.8169
16/16 [==============================] - 0s 2ms/step - loss: 1.8234
16/16 [==============================] - 0s 2ms/step - loss: 1.8219
16/16 [==============================] - 0s 2ms/step - loss: 1.8205
16/16 [==============================] - 0s 2ms/step - loss: 1.8205
Epoch 22 of 60

Testing for epoch 22 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2173
16/16 [==============================] - 0s 2ms/step - loss: 1.4357
16/16 [==============================] - 0s 2ms/step - loss: 1.6634
16/16 [==============================] - 0s 5ms/step - loss: 1.7700
16/16 [==============================] - 0s 2ms/step - loss: 1.8171
16/16 [==============================] - 0s 3ms/step - loss: 1.8488
16/16 [==============================] - 0s 5ms/step - loss: 1.8558
16/16 [==============================] - 0s 2ms/step - loss: 1.8544
16/16 [==============================] - 0s 2ms/step - loss: 1.8529
16/16 [==============================] - 0s 3ms/step - loss: 1.8529

Testing for epoch 22 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2139
16/16 [==============================] - 0s 2ms/step - loss: 1.4286
16/16 [==============================] - 0s 2ms/step - loss: 1.6561
16/16 [==============================] - 0s 1ms/step - loss: 1.7609
16/16 [==============================] - 0s 4ms/step - loss: 1.8068
16/16 [==============================] - 0s 2ms/step - loss: 1.8372
16/16 [==============================] - 0s 6ms/step - loss: 1.8438
16/16 [==============================] - 0s 2ms/step - loss: 1.8422
16/16 [==============================] - 0s 2ms/step - loss: 1.8407
16/16 [==============================] - 0s 2ms/step - loss: 1.8407

Testing for epoch 22 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.2148
16/16 [==============================] - 0s 1ms/step - loss: 1.4293
16/16 [==============================] - 0s 2ms/step - loss: 1.6578
16/16 [==============================] - 0s 4ms/step - loss: 1.7632
16/16 [==============================] - 0s 2ms/step - loss: 1.8090
16/16 [==============================] - 0s 2ms/step - loss: 1.8394
16/16 [==============================] - 0s 2ms/step - loss: 1.8454
16/16 [==============================] - 0s 5ms/step - loss: 1.8437
16/16 [==============================] - 0s 2ms/step - loss: 1.8423
16/16 [==============================] - 0s 2ms/step - loss: 1.8423

Testing for epoch 22 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2181
16/16 [==============================] - 0s 3ms/step - loss: 1.3837
16/16 [==============================] - 0s 2ms/step - loss: 1.6049
16/16 [==============================] - 0s 2ms/step - loss: 1.7082
16/16 [==============================] - 0s 2ms/step - loss: 1.7544
16/16 [==============================] - 0s 4ms/step - loss: 1.7860
16/16 [==============================] - 0s 3ms/step - loss: 1.7928
16/16 [==============================] - 0s 2ms/step - loss: 1.7913
16/16 [==============================] - 0s 3ms/step - loss: 1.7897
16/16 [==============================] - 0s 2ms/step - loss: 1.7897

Testing for epoch 22 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2083
16/16 [==============================] - 0s 991us/step - loss: 1.4684
16/16 [==============================] - 0s 873us/step - loss: 1.7111
16/16 [==============================] - 0s 2ms/step - loss: 1.8243
16/16 [==============================] - 0s 820us/step - loss: 1.8730
16/16 [==============================] - 0s 947us/step - loss: 1.9051
16/16 [==============================] - 0s 771us/step - loss: 1.9109
16/16 [==============================] - 0s 1ms/step - loss: 1.9087
16/16 [==============================] - 0s 1ms/step - loss: 1.9069
16/16 [==============================] - 0s 839us/step - loss: 1.9069
Epoch 23 of 60

Testing for epoch 23 index 1:
79/79 [==============================] - 0s 564us/step
16/16 [==============================] - 0s 872us/step - loss: 0.2068
16/16 [==============================] - 0s 929us/step - loss: 1.4438
16/16 [==============================] - 0s 859us/step - loss: 1.6817
16/16 [==============================] - 0s 829us/step - loss: 1.7917
16/16 [==============================] - 0s 1ms/step - loss: 1.8384
16/16 [==============================] - 0s 672us/step - loss: 1.8677
16/16 [==============================] - 0s 2ms/step - loss: 1.8721
16/16 [==============================] - 0s 3ms/step - loss: 1.8696
16/16 [==============================] - 0s 1ms/step - loss: 1.8677
16/16 [==============================] - 0s 942us/step - loss: 1.8676

Testing for epoch 23 index 2:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 827us/step - loss: 0.2075
16/16 [==============================] - 0s 724us/step - loss: 1.4278
16/16 [==============================] - 0s 781us/step - loss: 1.6611
16/16 [==============================] - 0s 855us/step - loss: 1.7673
16/16 [==============================] - 0s 1ms/step - loss: 1.8137
16/16 [==============================] - 0s 689us/step - loss: 1.8419
16/16 [==============================] - 0s 846us/step - loss: 1.8465
16/16 [==============================] - 0s 826us/step - loss: 1.8442
16/16 [==============================] - 0s 818us/step - loss: 1.8425
16/16 [==============================] - 0s 818us/step - loss: 1.8425

Testing for epoch 23 index 3:
79/79 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2072
16/16 [==============================] - 0s 1ms/step - loss: 1.4404
16/16 [==============================] - 0s 2ms/step - loss: 1.6810
16/16 [==============================] - 0s 5ms/step - loss: 1.7908
16/16 [==============================] - 0s 1ms/step - loss: 1.8406
16/16 [==============================] - 0s 1ms/step - loss: 1.8710
16/16 [==============================] - 0s 1ms/step - loss: 1.8762
16/16 [==============================] - 0s 2ms/step - loss: 1.8739
16/16 [==============================] - 0s 2ms/step - loss: 1.8721
16/16 [==============================] - 0s 1ms/step - loss: 1.8720

Testing for epoch 23 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2005
16/16 [==============================] - 0s 4ms/step - loss: 1.4690
16/16 [==============================] - 0s 2ms/step - loss: 1.7149
16/16 [==============================] - 0s 1ms/step - loss: 1.8240
16/16 [==============================] - 0s 1ms/step - loss: 1.8711
16/16 [==============================] - 0s 2ms/step - loss: 1.8977
16/16 [==============================] - 0s 2ms/step - loss: 1.9010
16/16 [==============================] - 0s 2ms/step - loss: 1.8979
16/16 [==============================] - 0s 2ms/step - loss: 1.8961
16/16 [==============================] - 0s 2ms/step - loss: 1.8960

Testing for epoch 23 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1965
16/16 [==============================] - 0s 933us/step - loss: 1.4857
16/16 [==============================] - 0s 2ms/step - loss: 1.7374
16/16 [==============================] - 0s 1ms/step - loss: 1.8489
16/16 [==============================] - 0s 1ms/step - loss: 1.8958
16/16 [==============================] - 0s 1ms/step - loss: 1.9208
16/16 [==============================] - 0s 2ms/step - loss: 1.9232
16/16 [==============================] - 0s 1ms/step - loss: 1.9199
16/16 [==============================] - 0s 2ms/step - loss: 1.9179
16/16 [==============================] - 0s 2ms/step - loss: 1.9179
Epoch 24 of 60

Testing for epoch 24 index 1:
79/79 [==============================] - 0s 934us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1949
16/16 [==============================] - 0s 2ms/step - loss: 1.5125
16/16 [==============================] - 0s 1ms/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.8843
16/16 [==============================] - 0s 1ms/step - loss: 1.9321
16/16 [==============================] - 0s 1ms/step - loss: 1.9573
16/16 [==============================] - 0s 934us/step - loss: 1.9592
16/16 [==============================] - 0s 2ms/step - loss: 1.9558
16/16 [==============================] - 0s 2ms/step - loss: 1.9537
16/16 [==============================] - 0s 1ms/step - loss: 1.9537

Testing for epoch 24 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1959
16/16 [==============================] - 0s 1ms/step - loss: 1.4640
16/16 [==============================] - 0s 2ms/step - loss: 1.7067
16/16 [==============================] - 0s 2ms/step - loss: 1.8128
16/16 [==============================] - 0s 2ms/step - loss: 1.8585
16/16 [==============================] - 0s 2ms/step - loss: 1.8822
16/16 [==============================] - 0s 970us/step - loss: 1.8835
16/16 [==============================] - 0s 1ms/step - loss: 1.8799
16/16 [==============================] - 0s 2ms/step - loss: 1.8778
16/16 [==============================] - 0s 1ms/step - loss: 1.8777

Testing for epoch 24 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1986
16/16 [==============================] - 0s 1ms/step - loss: 1.4867
16/16 [==============================] - 0s 4ms/step - loss: 1.7359
16/16 [==============================] - 0s 3ms/step - loss: 1.8473
16/16 [==============================] - 0s 2ms/step - loss: 1.8954
16/16 [==============================] - 0s 2ms/step - loss: 1.9193
16/16 [==============================] - 0s 2ms/step - loss: 1.9209
16/16 [==============================] - 0s 1ms/step - loss: 1.9173
16/16 [==============================] - 0s 2ms/step - loss: 1.9152
16/16 [==============================] - 0s 1ms/step - loss: 1.9151

Testing for epoch 24 index 4:
79/79 [==============================] - 0s 862us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1967
16/16 [==============================] - 0s 1ms/step - loss: 1.4806
16/16 [==============================] - 0s 2ms/step - loss: 1.7273
16/16 [==============================] - 0s 1ms/step - loss: 1.8367
16/16 [==============================] - 0s 2ms/step - loss: 1.8844
16/16 [==============================] - 0s 2ms/step - loss: 1.9072
16/16 [==============================] - 0s 1ms/step - loss: 1.9083
16/16 [==============================] - 0s 1ms/step - loss: 1.9047
16/16 [==============================] - 0s 2ms/step - loss: 1.9027
16/16 [==============================] - 0s 2ms/step - loss: 1.9027

Testing for epoch 24 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1922
16/16 [==============================] - 0s 1ms/step - loss: 1.5153
16/16 [==============================] - 0s 1ms/step - loss: 1.7681
16/16 [==============================] - 0s 1ms/step - loss: 1.8780
16/16 [==============================] - 0s 1ms/step - loss: 1.9241
16/16 [==============================] - 0s 1ms/step - loss: 1.9447
16/16 [==============================] - 0s 2ms/step - loss: 1.9445
16/16 [==============================] - 0s 1ms/step - loss: 1.9402
16/16 [==============================] - 0s 954us/step - loss: 1.9381
16/16 [==============================] - 0s 1ms/step - loss: 1.9380
Epoch 25 of 60

Testing for epoch 25 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.1929
16/16 [==============================] - 0s 1ms/step - loss: 1.4627
16/16 [==============================] - 0s 1ms/step - loss: 1.7036
16/16 [==============================] - 0s 953us/step - loss: 1.8077
16/16 [==============================] - 0s 1000us/step - loss: 1.8516
16/16 [==============================] - 0s 2ms/step - loss: 1.8687
16/16 [==============================] - 0s 1ms/step - loss: 1.8670
16/16 [==============================] - 0s 4ms/step - loss: 1.8625
16/16 [==============================] - 0s 3ms/step - loss: 1.8602
16/16 [==============================] - 0s 2ms/step - loss: 1.8602

Testing for epoch 25 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1918
16/16 [==============================] - 0s 1ms/step - loss: 1.5117
16/16 [==============================] - 0s 2ms/step - loss: 1.7683
16/16 [==============================] - 0s 1ms/step - loss: 1.8769
16/16 [==============================] - 0s 2ms/step - loss: 1.9240
16/16 [==============================] - 0s 2ms/step - loss: 1.9418
16/16 [==============================] - 0s 1ms/step - loss: 1.9400
16/16 [==============================] - 0s 1ms/step - loss: 1.9352
16/16 [==============================] - 0s 2ms/step - loss: 1.9327
16/16 [==============================] - 0s 2ms/step - loss: 1.9326

Testing for epoch 25 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1905
16/16 [==============================] - 0s 1ms/step - loss: 1.5434
16/16 [==============================] - 0s 1ms/step - loss: 1.8096
16/16 [==============================] - 0s 1ms/step - loss: 1.9206
16/16 [==============================] - 0s 1ms/step - loss: 1.9683
16/16 [==============================] - 0s 5ms/step - loss: 1.9856
16/16 [==============================] - 0s 2ms/step - loss: 1.9832
16/16 [==============================] - 0s 2ms/step - loss: 1.9781
16/16 [==============================] - 0s 4ms/step - loss: 1.9756
16/16 [==============================] - 0s 2ms/step - loss: 1.9755

Testing for epoch 25 index 4:
79/79 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 856us/step - loss: 0.1849
16/16 [==============================] - 0s 898us/step - loss: 1.5488
16/16 [==============================] - 0s 842us/step - loss: 1.8135
16/16 [==============================] - 0s 817us/step - loss: 1.9221
16/16 [==============================] - 0s 797us/step - loss: 1.9682
16/16 [==============================] - 0s 795us/step - loss: 1.9825
16/16 [==============================] - 0s 833us/step - loss: 1.9783
16/16 [==============================] - 0s 813us/step - loss: 1.9727
16/16 [==============================] - 0s 792us/step - loss: 1.9702
16/16 [==============================] - 0s 794us/step - loss: 1.9701

Testing for epoch 25 index 5:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 817us/step - loss: 0.1847
16/16 [==============================] - 0s 809us/step - loss: 1.5567
16/16 [==============================] - 0s 778us/step - loss: 1.8307
16/16 [==============================] - 0s 778us/step - loss: 1.9453
16/16 [==============================] - 0s 771us/step - loss: 1.9954
16/16 [==============================] - 0s 826us/step - loss: 2.0152
16/16 [==============================] - 0s 802us/step - loss: 2.0137
16/16 [==============================] - 0s 813us/step - loss: 2.0085
16/16 [==============================] - 0s 779us/step - loss: 2.0058
16/16 [==============================] - 0s 769us/step - loss: 2.0056
Epoch 26 of 60

Testing for epoch 26 index 1:
79/79 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1844
16/16 [==============================] - 0s 807us/step - loss: 1.5198
16/16 [==============================] - 0s 785us/step - loss: 1.7813
16/16 [==============================] - 0s 804us/step - loss: 1.8883
16/16 [==============================] - 0s 778us/step - loss: 1.9336
16/16 [==============================] - 0s 799us/step - loss: 1.9494
16/16 [==============================] - 0s 789us/step - loss: 1.9453
16/16 [==============================] - 0s 816us/step - loss: 1.9398
16/16 [==============================] - 0s 785us/step - loss: 1.9373
16/16 [==============================] - 0s 785us/step - loss: 1.9372

Testing for epoch 26 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 806us/step - loss: 0.1859
16/16 [==============================] - 0s 815us/step - loss: 1.5434
16/16 [==============================] - 0s 803us/step - loss: 1.8104
16/16 [==============================] - 0s 770us/step - loss: 1.9219
16/16 [==============================] - 0s 847us/step - loss: 1.9699
16/16 [==============================] - 0s 794us/step - loss: 1.9883
16/16 [==============================] - 0s 779us/step - loss: 1.9855
16/16 [==============================] - 0s 801us/step - loss: 1.9802
16/16 [==============================] - 0s 835us/step - loss: 1.9775
16/16 [==============================] - 0s 1ms/step - loss: 1.9773

Testing for epoch 26 index 3:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1817
16/16 [==============================] - 0s 1ms/step - loss: 1.5762
16/16 [==============================] - 0s 1ms/step - loss: 1.8483
16/16 [==============================] - 0s 1ms/step - loss: 1.9610
16/16 [==============================] - 0s 781us/step - loss: 2.0079
16/16 [==============================] - 0s 1ms/step - loss: 2.0228
16/16 [==============================] - 0s 1ms/step - loss: 2.0191
16/16 [==============================] - 0s 1ms/step - loss: 2.0135
16/16 [==============================] - 0s 771us/step - loss: 2.0108
16/16 [==============================] - 0s 785us/step - loss: 2.0106

Testing for epoch 26 index 4:
79/79 [==============================] - 0s 749us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1829
16/16 [==============================] - 0s 1ms/step - loss: 1.5509
16/16 [==============================] - 0s 808us/step - loss: 1.8163
16/16 [==============================] - 0s 782us/step - loss: 1.9243
16/16 [==============================] - 0s 783us/step - loss: 1.9681
16/16 [==============================] - 0s 782us/step - loss: 1.9796
16/16 [==============================] - 0s 785us/step - loss: 1.9733
16/16 [==============================] - 0s 789us/step - loss: 1.9671
16/16 [==============================] - 0s 795us/step - loss: 1.9644
16/16 [==============================] - 0s 797us/step - loss: 1.9643

Testing for epoch 26 index 5:
79/79 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 834us/step - loss: 0.1804
16/16 [==============================] - 0s 785us/step - loss: 1.5986
16/16 [==============================] - 0s 791us/step - loss: 1.8789
16/16 [==============================] - 0s 810us/step - loss: 1.9937
16/16 [==============================] - 0s 786us/step - loss: 2.0401
16/16 [==============================] - 0s 775us/step - loss: 2.0543
16/16 [==============================] - 0s 813us/step - loss: 2.0491
16/16 [==============================] - 0s 841us/step - loss: 2.0430
16/16 [==============================] - 0s 787us/step - loss: 2.0402
16/16 [==============================] - 0s 802us/step - loss: 2.0401
Epoch 27 of 60

Testing for epoch 27 index 1:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 980us/step - loss: 0.1780
16/16 [==============================] - 0s 1ms/step - loss: 1.5897
16/16 [==============================] - 0s 1ms/step - loss: 1.8713
16/16 [==============================] - 0s 1ms/step - loss: 1.9847
16/16 [==============================] - 0s 785us/step - loss: 2.0309
16/16 [==============================] - 0s 800us/step - loss: 2.0444
16/16 [==============================] - 0s 801us/step - loss: 2.0382
16/16 [==============================] - 0s 800us/step - loss: 2.0316
16/16 [==============================] - 0s 775us/step - loss: 2.0287
16/16 [==============================] - 0s 772us/step - loss: 2.0286

Testing for epoch 27 index 2:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1847
16/16 [==============================] - 0s 776us/step - loss: 1.5399
16/16 [==============================] - 0s 808us/step - loss: 1.8078
16/16 [==============================] - 0s 805us/step - loss: 1.9151
16/16 [==============================] - 0s 1ms/step - loss: 1.9593
16/16 [==============================] - 0s 774us/step - loss: 1.9706
16/16 [==============================] - 0s 922us/step - loss: 1.9641
16/16 [==============================] - 0s 1ms/step - loss: 1.9579
16/16 [==============================] - 0s 1ms/step - loss: 1.9552
16/16 [==============================] - 0s 1ms/step - loss: 1.9551

Testing for epoch 27 index 3:
79/79 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1802
16/16 [==============================] - 0s 1ms/step - loss: 1.5996
16/16 [==============================] - 0s 840us/step - loss: 1.8825
16/16 [==============================] - 0s 865us/step - loss: 1.9942
16/16 [==============================] - 0s 893us/step - loss: 2.0396
16/16 [==============================] - 0s 707us/step - loss: 2.0499
16/16 [==============================] - 0s 796us/step - loss: 2.0429
16/16 [==============================] - 0s 686us/step - loss: 2.0363
16/16 [==============================] - 0s 703us/step - loss: 2.0335
16/16 [==============================] - 0s 713us/step - loss: 2.0335

Testing for epoch 27 index 4:
79/79 [==============================] - 0s 763us/step
16/16 [==============================] - 0s 845us/step - loss: 0.1746
16/16 [==============================] - 0s 1ms/step - loss: 1.6245
16/16 [==============================] - 0s 1ms/step - loss: 1.9167
16/16 [==============================] - 0s 796us/step - loss: 2.0309
16/16 [==============================] - 0s 813us/step - loss: 2.0769
16/16 [==============================] - 0s 803us/step - loss: 2.0875
16/16 [==============================] - 0s 811us/step - loss: 2.0801
16/16 [==============================] - 0s 796us/step - loss: 2.0733
16/16 [==============================] - 0s 815us/step - loss: 2.0704
16/16 [==============================] - 0s 790us/step - loss: 2.0703

Testing for epoch 27 index 5:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 831us/step - loss: 0.1721
16/16 [==============================] - 0s 817us/step - loss: 1.6490
16/16 [==============================] - 0s 829us/step - loss: 1.9488
16/16 [==============================] - 0s 804us/step - loss: 2.0650
16/16 [==============================] - 0s 814us/step - loss: 2.1109
16/16 [==============================] - 0s 828us/step - loss: 2.1218
16/16 [==============================] - 0s 836us/step - loss: 2.1139
16/16 [==============================] - 0s 2ms/step - loss: 2.1069
16/16 [==============================] - 0s 2ms/step - loss: 2.1038
16/16 [==============================] - 0s 2ms/step - loss: 2.1037
Epoch 28 of 60

Testing for epoch 28 index 1:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 842us/step - loss: 0.1745
16/16 [==============================] - 0s 841us/step - loss: 1.6265
16/16 [==============================] - 0s 856us/step - loss: 1.9218
16/16 [==============================] - 0s 844us/step - loss: 2.0351
16/16 [==============================] - 0s 870us/step - loss: 2.0786
16/16 [==============================] - 0s 884us/step - loss: 2.0882
16/16 [==============================] - 0s 929us/step - loss: 2.0794
16/16 [==============================] - 0s 911us/step - loss: 2.0722
16/16 [==============================] - 0s 983us/step - loss: 2.0691
16/16 [==============================] - 0s 924us/step - loss: 2.0690

Testing for epoch 28 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1718
16/16 [==============================] - 0s 4ms/step - loss: 1.6199
16/16 [==============================] - 0s 2ms/step - loss: 1.9153
16/16 [==============================] - 0s 1ms/step - loss: 2.0279
16/16 [==============================] - 0s 2ms/step - loss: 2.0710
16/16 [==============================] - 0s 2ms/step - loss: 2.0805
16/16 [==============================] - 0s 1ms/step - loss: 2.0718
16/16 [==============================] - 0s 2ms/step - loss: 2.0644
16/16 [==============================] - 0s 2ms/step - loss: 2.0613
16/16 [==============================] - 0s 2ms/step - loss: 2.0612

Testing for epoch 28 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1764
16/16 [==============================] - 0s 2ms/step - loss: 1.5756
16/16 [==============================] - 0s 992us/step - loss: 1.8577
16/16 [==============================] - 0s 1ms/step - loss: 1.9628
16/16 [==============================] - 0s 4ms/step - loss: 2.0023
16/16 [==============================] - 0s 1ms/step - loss: 2.0074
16/16 [==============================] - 0s 2ms/step - loss: 1.9974
16/16 [==============================] - 0s 2ms/step - loss: 1.9900
16/16 [==============================] - 0s 2ms/step - loss: 1.9869
16/16 [==============================] - 0s 2ms/step - loss: 1.9867

Testing for epoch 28 index 4:
79/79 [==============================] - 0s 897us/step
16/16 [==============================] - 0s 991us/step - loss: 0.1714
16/16 [==============================] - 0s 2ms/step - loss: 1.5748
16/16 [==============================] - 0s 2ms/step - loss: 1.8565
16/16 [==============================] - 0s 1ms/step - loss: 1.9601
16/16 [==============================] - 0s 2ms/step - loss: 1.9993
16/16 [==============================] - 0s 2ms/step - loss: 2.0048
16/16 [==============================] - 0s 2ms/step - loss: 1.9951
16/16 [==============================] - 0s 1ms/step - loss: 1.9878
16/16 [==============================] - 0s 1ms/step - loss: 1.9850
16/16 [==============================] - 0s 2ms/step - loss: 1.9849

Testing for epoch 28 index 5:
79/79 [==============================] - 0s 947us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1700
16/16 [==============================] - 0s 1ms/step - loss: 1.6374
16/16 [==============================] - 0s 1ms/step - loss: 1.9381
16/16 [==============================] - 0s 1ms/step - loss: 2.0497
16/16 [==============================] - 0s 1ms/step - loss: 2.0926
16/16 [==============================] - 0s 1ms/step - loss: 2.0984
16/16 [==============================] - 0s 1ms/step - loss: 2.0886
16/16 [==============================] - 0s 1ms/step - loss: 2.0809
16/16 [==============================] - 0s 1ms/step - loss: 2.0778
16/16 [==============================] - 0s 2ms/step - loss: 2.0776
Epoch 29 of 60

Testing for epoch 29 index 1:
79/79 [==============================] - 0s 878us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1688
16/16 [==============================] - 0s 2ms/step - loss: 1.6160
16/16 [==============================] - 0s 2ms/step - loss: 1.9106
16/16 [==============================] - 0s 1ms/step - loss: 2.0177
16/16 [==============================] - 0s 1ms/step - loss: 2.0581
16/16 [==============================] - 0s 1ms/step - loss: 2.0626
16/16 [==============================] - 0s 2ms/step - loss: 2.0522
16/16 [==============================] - 0s 1ms/step - loss: 2.0446
16/16 [==============================] - 0s 1ms/step - loss: 2.0417
16/16 [==============================] - 0s 3ms/step - loss: 2.0417

Testing for epoch 29 index 2:
79/79 [==============================] - 0s 967us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1690
16/16 [==============================] - 0s 1ms/step - loss: 1.6719
16/16 [==============================] - 0s 1ms/step - loss: 1.9800
16/16 [==============================] - 0s 2ms/step - loss: 2.0915
16/16 [==============================] - 0s 1ms/step - loss: 2.1340
16/16 [==============================] - 0s 1ms/step - loss: 2.1376
16/16 [==============================] - 0s 1ms/step - loss: 2.1260
16/16 [==============================] - 0s 1ms/step - loss: 2.1178
16/16 [==============================] - 0s 964us/step - loss: 2.1145
16/16 [==============================] - 0s 1ms/step - loss: 2.1144

Testing for epoch 29 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1690
16/16 [==============================] - 0s 2ms/step - loss: 1.5813
16/16 [==============================] - 0s 1ms/step - loss: 1.8637
16/16 [==============================] - 0s 1ms/step - loss: 1.9638
16/16 [==============================] - 0s 2ms/step - loss: 2.0025
16/16 [==============================] - 0s 2ms/step - loss: 2.0058
16/16 [==============================] - 0s 2ms/step - loss: 1.9953
16/16 [==============================] - 0s 2ms/step - loss: 1.9879
16/16 [==============================] - 0s 2ms/step - loss: 1.9850
16/16 [==============================] - 0s 1ms/step - loss: 1.9849

Testing for epoch 29 index 4:
79/79 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1653
16/16 [==============================] - 0s 2ms/step - loss: 1.7200
16/16 [==============================] - 0s 2ms/step - loss: 2.0423
16/16 [==============================] - 0s 1ms/step - loss: 2.1567
16/16 [==============================] - 0s 1ms/step - loss: 2.2005
16/16 [==============================] - 0s 1ms/step - loss: 2.2035
16/16 [==============================] - 0s 1ms/step - loss: 2.1900
16/16 [==============================] - 0s 1ms/step - loss: 2.1809
16/16 [==============================] - 0s 2ms/step - loss: 2.1772
16/16 [==============================] - 0s 3ms/step - loss: 2.1770

Testing for epoch 29 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1656
16/16 [==============================] - 0s 2ms/step - loss: 1.6312
16/16 [==============================] - 0s 1ms/step - loss: 1.9296
16/16 [==============================] - 0s 1ms/step - loss: 2.0334
16/16 [==============================] - 0s 1ms/step - loss: 2.0736
16/16 [==============================] - 0s 1ms/step - loss: 2.0773
16/16 [==============================] - 0s 1ms/step - loss: 2.0655
16/16 [==============================] - 0s 2ms/step - loss: 2.0575
16/16 [==============================] - 0s 2ms/step - loss: 2.0543
16/16 [==============================] - 0s 2ms/step - loss: 2.0542
Epoch 30 of 60

Testing for epoch 30 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1641
16/16 [==============================] - 0s 1ms/step - loss: 1.6943
16/16 [==============================] - 0s 1ms/step - loss: 2.0115
16/16 [==============================] - 0s 1ms/step - loss: 2.1206
16/16 [==============================] - 0s 2ms/step - loss: 2.1614
16/16 [==============================] - 0s 1ms/step - loss: 2.1623
16/16 [==============================] - 0s 933us/step - loss: 2.1487
16/16 [==============================] - 0s 2ms/step - loss: 2.1400
16/16 [==============================] - 0s 2ms/step - loss: 2.1366
16/16 [==============================] - 0s 1ms/step - loss: 2.1364

Testing for epoch 30 index 2:
79/79 [==============================] - 0s 864us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1658
16/16 [==============================] - 0s 1ms/step - loss: 1.6611
16/16 [==============================] - 0s 1ms/step - loss: 1.9702
16/16 [==============================] - 0s 1ms/step - loss: 2.0763
16/16 [==============================] - 0s 1ms/step - loss: 2.1169
16/16 [==============================] - 0s 1ms/step - loss: 2.1173
16/16 [==============================] - 0s 1ms/step - loss: 2.1036
16/16 [==============================] - 0s 1ms/step - loss: 2.0951
16/16 [==============================] - 0s 1ms/step - loss: 2.0918
16/16 [==============================] - 0s 2ms/step - loss: 2.0917

Testing for epoch 30 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1678
16/16 [==============================] - 0s 2ms/step - loss: 1.6270
16/16 [==============================] - 0s 2ms/step - loss: 1.9300
16/16 [==============================] - 0s 2ms/step - loss: 2.0320
16/16 [==============================] - 0s 2ms/step - loss: 2.0718
16/16 [==============================] - 0s 2ms/step - loss: 2.0723
16/16 [==============================] - 0s 1ms/step - loss: 2.0596
16/16 [==============================] - 0s 2ms/step - loss: 2.0514
16/16 [==============================] - 0s 2ms/step - loss: 2.0481
16/16 [==============================] - 0s 2ms/step - loss: 2.0479

Testing for epoch 30 index 4:
79/79 [==============================] - 0s 932us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1629
16/16 [==============================] - 0s 2ms/step - loss: 1.6611
16/16 [==============================] - 0s 2ms/step - loss: 1.9644
16/16 [==============================] - 0s 2ms/step - loss: 2.0613
16/16 [==============================] - 0s 1ms/step - loss: 2.0966
16/16 [==============================] - 0s 3ms/step - loss: 2.0905
16/16 [==============================] - 0s 2ms/step - loss: 2.0735
16/16 [==============================] - 0s 1ms/step - loss: 2.0643
16/16 [==============================] - 0s 2ms/step - loss: 2.0611
16/16 [==============================] - 0s 1ms/step - loss: 2.0611

Testing for epoch 30 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1580
16/16 [==============================] - 0s 1ms/step - loss: 1.7343
16/16 [==============================] - 0s 926us/step - loss: 2.0589
16/16 [==============================] - 0s 3ms/step - loss: 2.1636
16/16 [==============================] - 0s 2ms/step - loss: 2.2026
16/16 [==============================] - 0s 960us/step - loss: 2.1988
16/16 [==============================] - 0s 2ms/step - loss: 2.1826
16/16 [==============================] - 0s 2ms/step - loss: 2.1732
16/16 [==============================] - 0s 2ms/step - loss: 2.1697
16/16 [==============================] - 0s 2ms/step - loss: 2.1695
Epoch 31 of 60

Testing for epoch 31 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1629
16/16 [==============================] - 0s 2ms/step - loss: 1.6340
16/16 [==============================] - 0s 2ms/step - loss: 1.9369
16/16 [==============================] - 0s 4ms/step - loss: 2.0366
16/16 [==============================] - 0s 1ms/step - loss: 2.0749
16/16 [==============================] - 0s 2ms/step - loss: 2.0736
16/16 [==============================] - 0s 1ms/step - loss: 2.0595
16/16 [==============================] - 0s 2ms/step - loss: 2.0507
16/16 [==============================] - 0s 1ms/step - loss: 2.0472
16/16 [==============================] - 0s 2ms/step - loss: 2.0470

Testing for epoch 31 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1602
16/16 [==============================] - 0s 2ms/step - loss: 1.6604
16/16 [==============================] - 0s 1ms/step - loss: 1.9645
16/16 [==============================] - 0s 2ms/step - loss: 2.0619
16/16 [==============================] - 0s 1ms/step - loss: 2.0977
16/16 [==============================] - 0s 2ms/step - loss: 2.0922
16/16 [==============================] - 0s 1ms/step - loss: 2.0766
16/16 [==============================] - 0s 2ms/step - loss: 2.0677
16/16 [==============================] - 0s 2ms/step - loss: 2.0645
16/16 [==============================] - 0s 2ms/step - loss: 2.0644

Testing for epoch 31 index 3:
79/79 [==============================] - 0s 814us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1592
16/16 [==============================] - 0s 3ms/step - loss: 1.7109
16/16 [==============================] - 0s 2ms/step - loss: 2.0223
16/16 [==============================] - 0s 1ms/step - loss: 2.1224
16/16 [==============================] - 0s 1ms/step - loss: 2.1597
16/16 [==============================] - 0s 977us/step - loss: 2.1517
16/16 [==============================] - 0s 961us/step - loss: 2.1344
16/16 [==============================] - 0s 2ms/step - loss: 2.1248
16/16 [==============================] - 0s 1ms/step - loss: 2.1212
16/16 [==============================] - 0s 1ms/step - loss: 2.1210

Testing for epoch 31 index 4:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 975us/step - loss: 0.1591
16/16 [==============================] - 0s 1ms/step - loss: 1.7203
16/16 [==============================] - 0s 1ms/step - loss: 2.0343
16/16 [==============================] - 0s 4ms/step - loss: 2.1337
16/16 [==============================] - 0s 1ms/step - loss: 2.1707
16/16 [==============================] - 0s 2ms/step - loss: 2.1621
16/16 [==============================] - 0s 2ms/step - loss: 2.1441
16/16 [==============================] - 0s 2ms/step - loss: 2.1342
16/16 [==============================] - 0s 1ms/step - loss: 2.1305
16/16 [==============================] - 0s 1ms/step - loss: 2.1303

Testing for epoch 31 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1568
16/16 [==============================] - 0s 2ms/step - loss: 1.7400
16/16 [==============================] - 0s 2ms/step - loss: 2.0591
16/16 [==============================] - 0s 2ms/step - loss: 2.1605
16/16 [==============================] - 0s 2ms/step - loss: 2.1977
16/16 [==============================] - 0s 2ms/step - loss: 2.1903
16/16 [==============================] - 0s 1ms/step - loss: 2.1724
16/16 [==============================] - 0s 2ms/step - loss: 2.1626
16/16 [==============================] - 0s 2ms/step - loss: 2.1590
16/16 [==============================] - 0s 1ms/step - loss: 2.1589
Epoch 32 of 60

Testing for epoch 32 index 1:
79/79 [==============================] - 0s 870us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1585
16/16 [==============================] - 0s 2ms/step - loss: 1.7001
16/16 [==============================] - 0s 1ms/step - loss: 2.0088
16/16 [==============================] - 0s 2ms/step - loss: 2.1060
16/16 [==============================] - 0s 2ms/step - loss: 2.1420
16/16 [==============================] - 0s 2ms/step - loss: 2.1348
16/16 [==============================] - 0s 2ms/step - loss: 2.1169
16/16 [==============================] - 0s 2ms/step - loss: 2.1072
16/16 [==============================] - 0s 4ms/step - loss: 2.1037
16/16 [==============================] - 0s 2ms/step - loss: 2.1035

Testing for epoch 32 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 899us/step - loss: 0.1574
16/16 [==============================] - 0s 1ms/step - loss: 1.7923
16/16 [==============================] - 0s 1ms/step - loss: 2.1196
16/16 [==============================] - 0s 2ms/step - loss: 2.2226
16/16 [==============================] - 0s 990us/step - loss: 2.2597
16/16 [==============================] - 0s 1ms/step - loss: 2.2503
16/16 [==============================] - 0s 1ms/step - loss: 2.2299
16/16 [==============================] - 0s 962us/step - loss: 2.2193
16/16 [==============================] - 0s 1ms/step - loss: 2.2156
16/16 [==============================] - 0s 996us/step - loss: 2.2155

Testing for epoch 32 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 7ms/step - loss: 0.1557
16/16 [==============================] - 0s 2ms/step - loss: 1.7954
16/16 [==============================] - 0s 2ms/step - loss: 2.1247
16/16 [==============================] - 0s 2ms/step - loss: 2.2272
16/16 [==============================] - 0s 2ms/step - loss: 2.2635
16/16 [==============================] - 0s 2ms/step - loss: 2.2531
16/16 [==============================] - 0s 2ms/step - loss: 2.2322
16/16 [==============================] - 0s 2ms/step - loss: 2.2215
16/16 [==============================] - 0s 2ms/step - loss: 2.2178
16/16 [==============================] - 0s 2ms/step - loss: 2.2177

Testing for epoch 32 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1537
16/16 [==============================] - 0s 1ms/step - loss: 1.7869
16/16 [==============================] - 0s 1ms/step - loss: 2.1168
16/16 [==============================] - 0s 1ms/step - loss: 2.2210
16/16 [==============================] - 0s 1ms/step - loss: 2.2596
16/16 [==============================] - 0s 1ms/step - loss: 2.2526
16/16 [==============================] - 0s 992us/step - loss: 2.2329
16/16 [==============================] - 0s 969us/step - loss: 2.2226
16/16 [==============================] - 0s 1ms/step - loss: 2.2187
16/16 [==============================] - 0s 1ms/step - loss: 2.2184

Testing for epoch 32 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1510
16/16 [==============================] - 0s 2ms/step - loss: 1.7654
16/16 [==============================] - 0s 1ms/step - loss: 2.0879
16/16 [==============================] - 0s 2ms/step - loss: 2.1879
16/16 [==============================] - 0s 1ms/step - loss: 2.2230
16/16 [==============================] - 0s 1ms/step - loss: 2.2123
16/16 [==============================] - 0s 1ms/step - loss: 2.1914
16/16 [==============================] - 0s 1ms/step - loss: 2.1809
16/16 [==============================] - 0s 1ms/step - loss: 2.1770
16/16 [==============================] - 0s 1ms/step - loss: 2.1768
Epoch 33 of 60

Testing for epoch 33 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1555
16/16 [==============================] - 0s 1ms/step - loss: 1.7559
16/16 [==============================] - 0s 2ms/step - loss: 2.0784
16/16 [==============================] - 0s 2ms/step - loss: 2.1784
16/16 [==============================] - 0s 4ms/step - loss: 2.2136
16/16 [==============================] - 0s 2ms/step - loss: 2.2035
16/16 [==============================] - 0s 2ms/step - loss: 2.1825
16/16 [==============================] - 0s 1ms/step - loss: 2.1721
16/16 [==============================] - 0s 3ms/step - loss: 2.1683
16/16 [==============================] - 0s 2ms/step - loss: 2.1681

Testing for epoch 33 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1507
16/16 [==============================] - 0s 932us/step - loss: 1.7736
16/16 [==============================] - 0s 877us/step - loss: 2.0996
16/16 [==============================] - 0s 821us/step - loss: 2.2003
16/16 [==============================] - 0s 801us/step - loss: 2.2338
16/16 [==============================] - 0s 821us/step - loss: 2.2216
16/16 [==============================] - 0s 842us/step - loss: 2.2004
16/16 [==============================] - 0s 791us/step - loss: 2.1900
16/16 [==============================] - 0s 787us/step - loss: 2.1864
16/16 [==============================] - 0s 816us/step - loss: 2.1863

Testing for epoch 33 index 3:
79/79 [==============================] - 0s 589us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1522
16/16 [==============================] - 0s 829us/step - loss: 1.7884
16/16 [==============================] - 0s 806us/step - loss: 2.1161
16/16 [==============================] - 0s 793us/step - loss: 2.2152
16/16 [==============================] - 0s 777us/step - loss: 2.2465
16/16 [==============================] - 0s 780us/step - loss: 2.2315
16/16 [==============================] - 0s 794us/step - loss: 2.2087
16/16 [==============================] - 0s 783us/step - loss: 2.1979
16/16 [==============================] - 0s 824us/step - loss: 2.1942
16/16 [==============================] - 0s 1ms/step - loss: 2.1941

Testing for epoch 33 index 4:
79/79 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1512
16/16 [==============================] - 0s 838us/step - loss: 1.7421
16/16 [==============================] - 0s 848us/step - loss: 2.0614
16/16 [==============================] - 0s 818us/step - loss: 2.1598
16/16 [==============================] - 0s 791us/step - loss: 2.1919
16/16 [==============================] - 0s 785us/step - loss: 2.1795
16/16 [==============================] - 0s 815us/step - loss: 2.1576
16/16 [==============================] - 0s 800us/step - loss: 2.1471
16/16 [==============================] - 0s 835us/step - loss: 2.1433
16/16 [==============================] - 0s 804us/step - loss: 2.1431

Testing for epoch 33 index 5:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 850us/step - loss: 0.1533
16/16 [==============================] - 0s 823us/step - loss: 1.7343
16/16 [==============================] - 0s 841us/step - loss: 2.0496
16/16 [==============================] - 0s 819us/step - loss: 2.1449
16/16 [==============================] - 0s 840us/step - loss: 2.1741
16/16 [==============================] - 0s 829us/step - loss: 2.1592
16/16 [==============================] - 0s 810us/step - loss: 2.1358
16/16 [==============================] - 0s 784us/step - loss: 2.1250
16/16 [==============================] - 0s 834us/step - loss: 2.1212
16/16 [==============================] - 0s 850us/step - loss: 2.1210
Epoch 34 of 60

Testing for epoch 34 index 1:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1524
16/16 [==============================] - 0s 1ms/step - loss: 1.7155
16/16 [==============================] - 0s 1ms/step - loss: 2.0298
16/16 [==============================] - 0s 1ms/step - loss: 2.1247
16/16 [==============================] - 0s 816us/step - loss: 2.1539
16/16 [==============================] - 0s 845us/step - loss: 2.1409
16/16 [==============================] - 0s 784us/step - loss: 2.1187
16/16 [==============================] - 0s 1ms/step - loss: 2.1082
16/16 [==============================] - 0s 1ms/step - loss: 2.1044
16/16 [==============================] - 0s 970us/step - loss: 2.1041

Testing for epoch 34 index 2:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1485
16/16 [==============================] - 0s 826us/step - loss: 1.7384
16/16 [==============================] - 0s 794us/step - loss: 2.0580
16/16 [==============================] - 0s 786us/step - loss: 2.1532
16/16 [==============================] - 0s 782us/step - loss: 2.1809
16/16 [==============================] - 0s 782us/step - loss: 2.1669
16/16 [==============================] - 0s 792us/step - loss: 2.1444
16/16 [==============================] - 0s 779us/step - loss: 2.1341
16/16 [==============================] - 0s 782us/step - loss: 2.1306
16/16 [==============================] - 0s 828us/step - loss: 2.1305

Testing for epoch 34 index 3:
79/79 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 809us/step - loss: 0.1477
16/16 [==============================] - 0s 1ms/step - loss: 1.7757
16/16 [==============================] - 0s 1ms/step - loss: 2.1041
16/16 [==============================] - 0s 820us/step - loss: 2.1998
16/16 [==============================] - 0s 783us/step - loss: 2.2271
16/16 [==============================] - 0s 774us/step - loss: 2.2111
16/16 [==============================] - 0s 783us/step - loss: 2.1877
16/16 [==============================] - 0s 1ms/step - loss: 2.1770
16/16 [==============================] - 0s 772us/step - loss: 2.1732
16/16 [==============================] - 0s 817us/step - loss: 2.1731

Testing for epoch 34 index 4:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 807us/step - loss: 0.1443
16/16 [==============================] - 0s 797us/step - loss: 1.8313
16/16 [==============================] - 0s 766us/step - loss: 2.1753
16/16 [==============================] - 0s 775us/step - loss: 2.2750
16/16 [==============================] - 0s 775us/step - loss: 2.3028
16/16 [==============================] - 0s 782us/step - loss: 2.2844
16/16 [==============================] - 0s 778us/step - loss: 2.2581
16/16 [==============================] - 0s 780us/step - loss: 2.2464
16/16 [==============================] - 0s 793us/step - loss: 2.2425
16/16 [==============================] - 0s 798us/step - loss: 2.2424

Testing for epoch 34 index 5:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 779us/step - loss: 0.1507
16/16 [==============================] - 0s 1ms/step - loss: 1.7991
16/16 [==============================] - 0s 1ms/step - loss: 2.1385
16/16 [==============================] - 0s 805us/step - loss: 2.2388
16/16 [==============================] - 0s 777us/step - loss: 2.2689
16/16 [==============================] - 0s 769us/step - loss: 2.2553
16/16 [==============================] - 0s 770us/step - loss: 2.2330
16/16 [==============================] - 0s 766us/step - loss: 2.2225
16/16 [==============================] - 0s 796us/step - loss: 2.2189
16/16 [==============================] - 0s 802us/step - loss: 2.2187
Epoch 35 of 60

Testing for epoch 35 index 1:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 810us/step - loss: 0.1468
16/16 [==============================] - 0s 1000us/step - loss: 1.8167
16/16 [==============================] - 0s 1ms/step - loss: 2.1570
16/16 [==============================] - 0s 783us/step - loss: 2.2540
16/16 [==============================] - 0s 816us/step - loss: 2.2807
16/16 [==============================] - 0s 980us/step - loss: 2.2621
16/16 [==============================] - 0s 787us/step - loss: 2.2360
16/16 [==============================] - 0s 814us/step - loss: 2.2244
16/16 [==============================] - 0s 805us/step - loss: 2.2204
16/16 [==============================] - 0s 832us/step - loss: 2.2203

Testing for epoch 35 index 2:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1469
16/16 [==============================] - 0s 791us/step - loss: 1.8178
16/16 [==============================] - 0s 775us/step - loss: 2.1558
16/16 [==============================] - 0s 784us/step - loss: 2.2515
16/16 [==============================] - 0s 796us/step - loss: 2.2769
16/16 [==============================] - 0s 783us/step - loss: 2.2571
16/16 [==============================] - 0s 802us/step - loss: 2.2299
16/16 [==============================] - 0s 779us/step - loss: 2.2181
16/16 [==============================] - 0s 811us/step - loss: 2.2141
16/16 [==============================] - 0s 798us/step - loss: 2.2140

Testing for epoch 35 index 3:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1499
16/16 [==============================] - 0s 823us/step - loss: 1.7804
16/16 [==============================] - 0s 814us/step - loss: 2.1084
16/16 [==============================] - 0s 789us/step - loss: 2.1988
16/16 [==============================] - 0s 779us/step - loss: 2.2227
16/16 [==============================] - 0s 772us/step - loss: 2.2030
16/16 [==============================] - 0s 794us/step - loss: 2.1772
16/16 [==============================] - 0s 787us/step - loss: 2.1661
16/16 [==============================] - 0s 822us/step - loss: 2.1624
16/16 [==============================] - 0s 797us/step - loss: 2.1623

Testing for epoch 35 index 4:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1474
16/16 [==============================] - 0s 804us/step - loss: 1.7882
16/16 [==============================] - 0s 816us/step - loss: 2.1206
16/16 [==============================] - 0s 826us/step - loss: 2.2126
16/16 [==============================] - 0s 844us/step - loss: 2.2362
16/16 [==============================] - 0s 804us/step - loss: 2.2145
16/16 [==============================] - 0s 1ms/step - loss: 2.1867
16/16 [==============================] - 0s 881us/step - loss: 2.1749
16/16 [==============================] - 0s 852us/step - loss: 2.1709
16/16 [==============================] - 0s 785us/step - loss: 2.1708

Testing for epoch 35 index 5:
79/79 [==============================] - 0s 585us/step
16/16 [==============================] - 0s 861us/step - loss: 0.1426
16/16 [==============================] - 0s 1ms/step - loss: 1.8107
16/16 [==============================] - 0s 762us/step - loss: 2.1481
16/16 [==============================] - 0s 757us/step - loss: 2.2402
16/16 [==============================] - 0s 771us/step - loss: 2.2636
16/16 [==============================] - 0s 772us/step - loss: 2.2406
16/16 [==============================] - 0s 768us/step - loss: 2.2119
16/16 [==============================] - 0s 766us/step - loss: 2.1997
16/16 [==============================] - 0s 765us/step - loss: 2.1956
16/16 [==============================] - 0s 771us/step - loss: 2.1955
Epoch 36 of 60

Testing for epoch 36 index 1:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 782us/step - loss: 0.1440
16/16 [==============================] - 0s 780us/step - loss: 1.8571
16/16 [==============================] - 0s 775us/step - loss: 2.2097
16/16 [==============================] - 0s 779us/step - loss: 2.3070
16/16 [==============================] - 0s 776us/step - loss: 2.3319
16/16 [==============================] - 0s 788us/step - loss: 2.3098
16/16 [==============================] - 0s 1ms/step - loss: 2.2808
16/16 [==============================] - 0s 1ms/step - loss: 2.2685
16/16 [==============================] - 0s 800us/step - loss: 2.2645
16/16 [==============================] - 0s 891us/step - loss: 2.2644

Testing for epoch 36 index 2:
79/79 [==============================] - 0s 693us/step
16/16 [==============================] - 0s 833us/step - loss: 0.1417
16/16 [==============================] - 0s 814us/step - loss: 1.8655
16/16 [==============================] - 0s 906us/step - loss: 2.2205
16/16 [==============================] - 0s 829us/step - loss: 2.3178
16/16 [==============================] - 0s 872us/step - loss: 2.3425
16/16 [==============================] - 0s 864us/step - loss: 2.3198
16/16 [==============================] - 0s 792us/step - loss: 2.2908
16/16 [==============================] - 0s 803us/step - loss: 2.2784
16/16 [==============================] - 0s 796us/step - loss: 2.2743
16/16 [==============================] - 0s 821us/step - loss: 2.2743

Testing for epoch 36 index 3:
79/79 [==============================] - 0s 620us/step
16/16 [==============================] - 0s 820us/step - loss: 0.1445
16/16 [==============================] - 0s 830us/step - loss: 1.8152
16/16 [==============================] - 0s 800us/step - loss: 2.1608
16/16 [==============================] - 0s 826us/step - loss: 2.2564
16/16 [==============================] - 0s 814us/step - loss: 2.2806
16/16 [==============================] - 0s 806us/step - loss: 2.2592
16/16 [==============================] - 0s 792us/step - loss: 2.2315
16/16 [==============================] - 0s 823us/step - loss: 2.2197
16/16 [==============================] - 0s 819us/step - loss: 2.2156
16/16 [==============================] - 0s 807us/step - loss: 2.2155

Testing for epoch 36 index 4:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1423
16/16 [==============================] - 0s 803us/step - loss: 1.8472
16/16 [==============================] - 0s 782us/step - loss: 2.1950
16/16 [==============================] - 0s 816us/step - loss: 2.2881
16/16 [==============================] - 0s 794us/step - loss: 2.3102
16/16 [==============================] - 0s 786us/step - loss: 2.2857
16/16 [==============================] - 0s 786us/step - loss: 2.2565
16/16 [==============================] - 0s 794us/step - loss: 2.2442
16/16 [==============================] - 0s 788us/step - loss: 2.2402
16/16 [==============================] - 0s 792us/step - loss: 2.2401

Testing for epoch 36 index 5:
79/79 [==============================] - 0s 659us/step
16/16 [==============================] - 0s 872us/step - loss: 0.1383
16/16 [==============================] - 0s 805us/step - loss: 1.8481
16/16 [==============================] - 0s 806us/step - loss: 2.2002
16/16 [==============================] - 0s 807us/step - loss: 2.2955
16/16 [==============================] - 0s 810us/step - loss: 2.3191
16/16 [==============================] - 0s 818us/step - loss: 2.2953
16/16 [==============================] - 0s 846us/step - loss: 2.2663
16/16 [==============================] - 0s 817us/step - loss: 2.2540
16/16 [==============================] - 0s 842us/step - loss: 2.2498
16/16 [==============================] - 0s 808us/step - loss: 2.2496
Epoch 37 of 60

Testing for epoch 37 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1396
16/16 [==============================] - 0s 800us/step - loss: 1.8411
16/16 [==============================] - 0s 794us/step - loss: 2.1902
16/16 [==============================] - 0s 789us/step - loss: 2.2840
16/16 [==============================] - 0s 805us/step - loss: 2.3066
16/16 [==============================] - 0s 794us/step - loss: 2.2821
16/16 [==============================] - 0s 787us/step - loss: 2.2532
16/16 [==============================] - 0s 790us/step - loss: 2.2411
16/16 [==============================] - 0s 814us/step - loss: 2.2372
16/16 [==============================] - 0s 796us/step - loss: 2.2371

Testing for epoch 37 index 2:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1395
16/16 [==============================] - 0s 832us/step - loss: 1.8573
16/16 [==============================] - 0s 835us/step - loss: 2.2095
16/16 [==============================] - 0s 826us/step - loss: 2.3029
16/16 [==============================] - 0s 804us/step - loss: 2.3241
16/16 [==============================] - 0s 805us/step - loss: 2.2983
16/16 [==============================] - 0s 796us/step - loss: 2.2682
16/16 [==============================] - 0s 807us/step - loss: 2.2556
16/16 [==============================] - 0s 1ms/step - loss: 2.2513
16/16 [==============================] - 0s 1ms/step - loss: 2.2511

Testing for epoch 37 index 3:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1401
16/16 [==============================] - 0s 796us/step - loss: 1.8239
16/16 [==============================] - 0s 798us/step - loss: 2.1752
16/16 [==============================] - 0s 804us/step - loss: 2.2721
16/16 [==============================] - 0s 838us/step - loss: 2.2980
16/16 [==============================] - 0s 841us/step - loss: 2.2774
16/16 [==============================] - 0s 820us/step - loss: 2.2510
16/16 [==============================] - 0s 694us/step - loss: 2.2395
16/16 [==============================] - 0s 737us/step - loss: 2.2355
16/16 [==============================] - 0s 689us/step - loss: 2.2353

Testing for epoch 37 index 4:
79/79 [==============================] - 0s 668us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1385
16/16 [==============================] - 0s 2ms/step - loss: 1.8566
16/16 [==============================] - 0s 2ms/step - loss: 2.2037
16/16 [==============================] - 0s 2ms/step - loss: 2.2918
16/16 [==============================] - 0s 2ms/step - loss: 2.3097
16/16 [==============================] - 0s 844us/step - loss: 2.2792
16/16 [==============================] - 0s 855us/step - loss: 2.2463
16/16 [==============================] - 0s 2ms/step - loss: 2.2331
16/16 [==============================] - 0s 2ms/step - loss: 2.2290
16/16 [==============================] - 0s 769us/step - loss: 2.2290

Testing for epoch 37 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 876us/step - loss: 0.1371
16/16 [==============================] - 0s 2ms/step - loss: 1.8841
16/16 [==============================] - 0s 781us/step - loss: 2.2415
16/16 [==============================] - 0s 754us/step - loss: 2.3349
16/16 [==============================] - 0s 831us/step - loss: 2.3552
16/16 [==============================] - 0s 788us/step - loss: 2.3269
16/16 [==============================] - 0s 832us/step - loss: 2.2956
16/16 [==============================] - 0s 797us/step - loss: 2.2825
16/16 [==============================] - 0s 2ms/step - loss: 2.2780
16/16 [==============================] - 0s 2ms/step - loss: 2.2778
Epoch 38 of 60

Testing for epoch 38 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1392
16/16 [==============================] - 0s 846us/step - loss: 1.9016
16/16 [==============================] - 0s 2ms/step - loss: 2.2615
16/16 [==============================] - 0s 2ms/step - loss: 2.3548
16/16 [==============================] - 0s 2ms/step - loss: 2.3744
16/16 [==============================] - 0s 783us/step - loss: 2.3445
16/16 [==============================] - 0s 1ms/step - loss: 2.3121
16/16 [==============================] - 0s 2ms/step - loss: 2.2989
16/16 [==============================] - 0s 2ms/step - loss: 2.2947
16/16 [==============================] - 0s 1ms/step - loss: 2.2946

Testing for epoch 38 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 804us/step - loss: 0.1370
16/16 [==============================] - 0s 2ms/step - loss: 1.8808
16/16 [==============================] - 0s 2ms/step - loss: 2.2309
16/16 [==============================] - 0s 803us/step - loss: 2.3252
16/16 [==============================] - 0s 2ms/step - loss: 2.3458
16/16 [==============================] - 0s 2ms/step - loss: 2.3187
16/16 [==============================] - 0s 2ms/step - loss: 2.2874
16/16 [==============================] - 0s 840us/step - loss: 2.2746
16/16 [==============================] - 0s 2ms/step - loss: 2.2703
16/16 [==============================] - 0s 805us/step - loss: 2.2702

Testing for epoch 38 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1335
16/16 [==============================] - 0s 2ms/step - loss: 1.9326
16/16 [==============================] - 0s 2ms/step - loss: 2.2893
16/16 [==============================] - 0s 804us/step - loss: 2.3820
16/16 [==============================] - 0s 2ms/step - loss: 2.3984
16/16 [==============================] - 0s 817us/step - loss: 2.3647
16/16 [==============================] - 0s 2ms/step - loss: 2.3292
16/16 [==============================] - 0s 2ms/step - loss: 2.3153
16/16 [==============================] - 0s 883us/step - loss: 2.3110
16/16 [==============================] - 0s 2ms/step - loss: 2.3111

Testing for epoch 38 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 849us/step - loss: 0.1333
16/16 [==============================] - 0s 805us/step - loss: 1.9265
16/16 [==============================] - 0s 793us/step - loss: 2.2845
16/16 [==============================] - 0s 815us/step - loss: 2.3802
16/16 [==============================] - 0s 808us/step - loss: 2.3993
16/16 [==============================] - 0s 818us/step - loss: 2.3696
16/16 [==============================] - 0s 2ms/step - loss: 2.3358
16/16 [==============================] - 0s 800us/step - loss: 2.3221
16/16 [==============================] - 0s 792us/step - loss: 2.3175
16/16 [==============================] - 0s 2ms/step - loss: 2.3173

Testing for epoch 38 index 5:
79/79 [==============================] - 0s 759us/step
16/16 [==============================] - 0s 844us/step - loss: 0.1361
16/16 [==============================] - 0s 833us/step - loss: 1.9262
16/16 [==============================] - 0s 799us/step - loss: 2.2858
16/16 [==============================] - 0s 2ms/step - loss: 2.3821
16/16 [==============================] - 0s 814us/step - loss: 2.4018
16/16 [==============================] - 0s 2ms/step - loss: 2.3724
16/16 [==============================] - 0s 2ms/step - loss: 2.3391
16/16 [==============================] - 0s 833us/step - loss: 2.3258
16/16 [==============================] - 0s 814us/step - loss: 2.3215
16/16 [==============================] - 0s 823us/step - loss: 2.3214
Epoch 39 of 60

Testing for epoch 39 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 833us/step - loss: 0.1330
16/16 [==============================] - 0s 1ms/step - loss: 1.8945
16/16 [==============================] - 0s 2ms/step - loss: 2.2436
16/16 [==============================] - 0s 1ms/step - loss: 2.3363
16/16 [==============================] - 0s 911us/step - loss: 2.3546
16/16 [==============================] - 0s 808us/step - loss: 2.3242
16/16 [==============================] - 0s 2ms/step - loss: 2.2909
16/16 [==============================] - 0s 2ms/step - loss: 2.2776
16/16 [==============================] - 0s 2ms/step - loss: 2.2733
16/16 [==============================] - 0s 791us/step - loss: 2.2731

Testing for epoch 39 index 2:
79/79 [==============================] - 0s 929us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1358
16/16 [==============================] - 0s 2ms/step - loss: 1.8447
16/16 [==============================] - 0s 832us/step - loss: 2.1816
16/16 [==============================] - 0s 795us/step - loss: 2.2687
16/16 [==============================] - 0s 807us/step - loss: 2.2848
16/16 [==============================] - 0s 2ms/step - loss: 2.2549
16/16 [==============================] - 0s 1ms/step - loss: 2.2232
16/16 [==============================] - 0s 919us/step - loss: 2.2103
16/16 [==============================] - 0s 2ms/step - loss: 2.2061
16/16 [==============================] - 0s 787us/step - loss: 2.2059

Testing for epoch 39 index 3:
79/79 [==============================] - 0s 533us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1353
16/16 [==============================] - 0s 1ms/step - loss: 1.9032
16/16 [==============================] - 0s 2ms/step - loss: 2.2511
16/16 [==============================] - 0s 2ms/step - loss: 2.3409
16/16 [==============================] - 0s 780us/step - loss: 2.3580
16/16 [==============================] - 0s 891us/step - loss: 2.3288
16/16 [==============================] - 0s 863us/step - loss: 2.2962
16/16 [==============================] - 0s 876us/step - loss: 2.2830
16/16 [==============================] - 0s 1ms/step - loss: 2.2787
16/16 [==============================] - 0s 937us/step - loss: 2.2786

Testing for epoch 39 index 4:
79/79 [==============================] - 0s 781us/step
16/16 [==============================] - 0s 835us/step - loss: 0.1367
16/16 [==============================] - 0s 2ms/step - loss: 1.9084
16/16 [==============================] - 0s 990us/step - loss: 2.2575
16/16 [==============================] - 0s 814us/step - loss: 2.3489
16/16 [==============================] - 0s 777us/step - loss: 2.3668
16/16 [==============================] - 0s 782us/step - loss: 2.3375
16/16 [==============================] - 0s 714us/step - loss: 2.3043
16/16 [==============================] - 0s 1ms/step - loss: 2.2911
16/16 [==============================] - 0s 649us/step - loss: 2.2868
16/16 [==============================] - 0s 790us/step - loss: 2.2867

Testing for epoch 39 index 5:
79/79 [==============================] - 0s 661us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1330
16/16 [==============================] - 0s 780us/step - loss: 1.9413
16/16 [==============================] - 0s 778us/step - loss: 2.3006
16/16 [==============================] - 0s 786us/step - loss: 2.3940
16/16 [==============================] - 0s 804us/step - loss: 2.4106
16/16 [==============================] - 0s 791us/step - loss: 2.3794
16/16 [==============================] - 0s 780us/step - loss: 2.3453
16/16 [==============================] - 0s 779us/step - loss: 2.3317
16/16 [==============================] - 0s 815us/step - loss: 2.3272
16/16 [==============================] - 0s 790us/step - loss: 2.3271
Epoch 40 of 60

Testing for epoch 40 index 1:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1342
16/16 [==============================] - 0s 1ms/step - loss: 1.9180
16/16 [==============================] - 0s 1ms/step - loss: 2.2724
16/16 [==============================] - 0s 1ms/step - loss: 2.3660
16/16 [==============================] - 0s 1ms/step - loss: 2.3839
16/16 [==============================] - 0s 781us/step - loss: 2.3552
16/16 [==============================] - 0s 1ms/step - loss: 2.3228
16/16 [==============================] - 0s 788us/step - loss: 2.3097
16/16 [==============================] - 0s 800us/step - loss: 2.3054
16/16 [==============================] - 0s 800us/step - loss: 2.3052

Testing for epoch 40 index 2:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1336
16/16 [==============================] - 0s 806us/step - loss: 1.8845
16/16 [==============================] - 0s 785us/step - loss: 2.2270
16/16 [==============================] - 0s 789us/step - loss: 2.3128
16/16 [==============================] - 0s 803us/step - loss: 2.3252
16/16 [==============================] - 0s 807us/step - loss: 2.2901
16/16 [==============================] - 0s 789us/step - loss: 2.2552
16/16 [==============================] - 0s 803us/step - loss: 2.2418
16/16 [==============================] - 0s 903us/step - loss: 2.2374
16/16 [==============================] - 0s 860us/step - loss: 2.2373

Testing for epoch 40 index 3:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1321
16/16 [==============================] - 0s 817us/step - loss: 1.9400
16/16 [==============================] - 0s 819us/step - loss: 2.2933
16/16 [==============================] - 0s 825us/step - loss: 2.3799
16/16 [==============================] - 0s 819us/step - loss: 2.3924
16/16 [==============================] - 0s 885us/step - loss: 2.3564
16/16 [==============================] - 0s 882us/step - loss: 2.3207
16/16 [==============================] - 0s 823us/step - loss: 2.3070
16/16 [==============================] - 0s 865us/step - loss: 2.3027
16/16 [==============================] - 0s 803us/step - loss: 2.3027

Testing for epoch 40 index 4:
79/79 [==============================] - 0s 669us/step
16/16 [==============================] - 0s 815us/step - loss: 0.1334
16/16 [==============================] - 0s 833us/step - loss: 1.9022
16/16 [==============================] - 0s 806us/step - loss: 2.2463
16/16 [==============================] - 0s 796us/step - loss: 2.3297
16/16 [==============================] - 0s 790us/step - loss: 2.3413
16/16 [==============================] - 0s 790us/step - loss: 2.3067
16/16 [==============================] - 0s 791us/step - loss: 2.2727
16/16 [==============================] - 0s 828us/step - loss: 2.2595
16/16 [==============================] - 0s 819us/step - loss: 2.2552
16/16 [==============================] - 0s 798us/step - loss: 2.2550

Testing for epoch 40 index 5:
79/79 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 790us/step - loss: 0.1269
16/16 [==============================] - 0s 804us/step - loss: 1.9772
16/16 [==============================] - 0s 796us/step - loss: 2.3427
16/16 [==============================] - 0s 779us/step - loss: 2.4319
16/16 [==============================] - 0s 792us/step - loss: 2.4454
16/16 [==============================] - 0s 806us/step - loss: 2.4078
16/16 [==============================] - 0s 804us/step - loss: 2.3714
16/16 [==============================] - 0s 817us/step - loss: 2.3572
16/16 [==============================] - 0s 854us/step - loss: 2.3526
16/16 [==============================] - 0s 889us/step - loss: 2.3524
Epoch 41 of 60

Testing for epoch 41 index 1:
79/79 [==============================] - 0s 862us/step
16/16 [==============================] - 0s 846us/step - loss: 0.1301
16/16 [==============================] - 0s 833us/step - loss: 1.9242
16/16 [==============================] - 0s 1ms/step - loss: 2.2728
16/16 [==============================] - 0s 814us/step - loss: 2.3565
16/16 [==============================] - 0s 834us/step - loss: 2.3696
16/16 [==============================] - 0s 832us/step - loss: 2.3336
16/16 [==============================] - 0s 849us/step - loss: 2.2979
16/16 [==============================] - 0s 895us/step - loss: 2.2839
16/16 [==============================] - 0s 835us/step - loss: 2.2793
16/16 [==============================] - 0s 842us/step - loss: 2.2791

Testing for epoch 41 index 2:
79/79 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 832us/step - loss: 0.1314
16/16 [==============================] - 0s 845us/step - loss: 1.9663
16/16 [==============================] - 0s 874us/step - loss: 2.3249
16/16 [==============================] - 0s 816us/step - loss: 2.4099
16/16 [==============================] - 0s 824us/step - loss: 2.4224
16/16 [==============================] - 0s 826us/step - loss: 2.3848
16/16 [==============================] - 0s 849us/step - loss: 2.3482
16/16 [==============================] - 0s 800us/step - loss: 2.3341
16/16 [==============================] - 0s 856us/step - loss: 2.3296
16/16 [==============================] - 0s 797us/step - loss: 2.3295

Testing for epoch 41 index 3:
79/79 [==============================] - 0s 719us/step
16/16 [==============================] - 0s 843us/step - loss: 0.1290
16/16 [==============================] - 0s 858us/step - loss: 2.0148
16/16 [==============================] - 0s 784us/step - loss: 2.3873
16/16 [==============================] - 0s 856us/step - loss: 2.4746
16/16 [==============================] - 0s 835us/step - loss: 2.4879
16/16 [==============================] - 0s 810us/step - loss: 2.4474
16/16 [==============================] - 0s 865us/step - loss: 2.4088
16/16 [==============================] - 0s 884us/step - loss: 2.3940
16/16 [==============================] - 0s 869us/step - loss: 2.3894
16/16 [==============================] - 0s 785us/step - loss: 2.3893

Testing for epoch 41 index 4:
79/79 [==============================] - 0s 618us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1312
16/16 [==============================] - 0s 807us/step - loss: 1.9137
16/16 [==============================] - 0s 1ms/step - loss: 2.2591
16/16 [==============================] - 0s 798us/step - loss: 2.3380
16/16 [==============================] - 0s 1ms/step - loss: 2.3479
16/16 [==============================] - 0s 1ms/step - loss: 2.3084
16/16 [==============================] - 0s 830us/step - loss: 2.2720
16/16 [==============================] - 0s 788us/step - loss: 2.2582
16/16 [==============================] - 0s 795us/step - loss: 2.2539
16/16 [==============================] - 0s 855us/step - loss: 2.2538

Testing for epoch 41 index 5:
79/79 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 857us/step - loss: 0.1289
16/16 [==============================] - 0s 817us/step - loss: 1.9509
16/16 [==============================] - 0s 905us/step - loss: 2.3031
16/16 [==============================] - 0s 799us/step - loss: 2.3834
16/16 [==============================] - 0s 915us/step - loss: 2.3938
16/16 [==============================] - 0s 1ms/step - loss: 2.3538
16/16 [==============================] - 0s 911us/step - loss: 2.3167
16/16 [==============================] - 0s 934us/step - loss: 2.3026
16/16 [==============================] - 0s 891us/step - loss: 2.2981
16/16 [==============================] - 0s 866us/step - loss: 2.2980
Epoch 42 of 60

Testing for epoch 42 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1312
16/16 [==============================] - 0s 3ms/step - loss: 1.9436
16/16 [==============================] - 0s 1ms/step - loss: 2.2942
16/16 [==============================] - 0s 1ms/step - loss: 2.3728
16/16 [==============================] - 0s 801us/step - loss: 2.3809
16/16 [==============================] - 0s 1ms/step - loss: 2.3390
16/16 [==============================] - 0s 881us/step - loss: 2.3013
16/16 [==============================] - 0s 818us/step - loss: 2.2872
16/16 [==============================] - 0s 807us/step - loss: 2.2829
16/16 [==============================] - 0s 794us/step - loss: 2.2830

Testing for epoch 42 index 2:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 830us/step - loss: 0.1277
16/16 [==============================] - 0s 825us/step - loss: 1.9867
16/16 [==============================] - 0s 818us/step - loss: 2.3500
16/16 [==============================] - 0s 797us/step - loss: 2.4348
16/16 [==============================] - 0s 795us/step - loss: 2.4465
16/16 [==============================] - 0s 798us/step - loss: 2.4073
16/16 [==============================] - 0s 790us/step - loss: 2.3709
16/16 [==============================] - 0s 803us/step - loss: 2.3569
16/16 [==============================] - 0s 799us/step - loss: 2.3525
16/16 [==============================] - 0s 796us/step - loss: 2.3524

Testing for epoch 42 index 3:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1334
16/16 [==============================] - 0s 821us/step - loss: 1.9570
16/16 [==============================] - 0s 806us/step - loss: 2.3121
16/16 [==============================] - 0s 808us/step - loss: 2.3937
16/16 [==============================] - 0s 805us/step - loss: 2.4031
16/16 [==============================] - 0s 824us/step - loss: 2.3619
16/16 [==============================] - 0s 808us/step - loss: 2.3245
16/16 [==============================] - 0s 827us/step - loss: 2.3104
16/16 [==============================] - 0s 827us/step - loss: 2.3060
16/16 [==============================] - 0s 813us/step - loss: 2.3059

Testing for epoch 42 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1268
16/16 [==============================] - 0s 794us/step - loss: 1.9501
16/16 [==============================] - 0s 868us/step - loss: 2.3015
16/16 [==============================] - 0s 822us/step - loss: 2.3798
16/16 [==============================] - 0s 828us/step - loss: 2.3880
16/16 [==============================] - 0s 789us/step - loss: 2.3466
16/16 [==============================] - 0s 802us/step - loss: 2.3094
16/16 [==============================] - 0s 821us/step - loss: 2.2953
16/16 [==============================] - 0s 815us/step - loss: 2.2908
16/16 [==============================] - 0s 839us/step - loss: 2.2906

Testing for epoch 42 index 5:
79/79 [==============================] - 0s 730us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1280
16/16 [==============================] - 0s 1ms/step - loss: 1.9975
16/16 [==============================] - 0s 805us/step - loss: 2.3589
16/16 [==============================] - 0s 798us/step - loss: 2.4382
16/16 [==============================] - 0s 829us/step - loss: 2.4454
16/16 [==============================] - 0s 821us/step - loss: 2.4015
16/16 [==============================] - 0s 797us/step - loss: 2.3619
16/16 [==============================] - 0s 1ms/step - loss: 2.3472
16/16 [==============================] - 0s 815us/step - loss: 2.3427
16/16 [==============================] - 0s 813us/step - loss: 2.3427
Epoch 43 of 60

Testing for epoch 43 index 1:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1275
16/16 [==============================] - 0s 1ms/step - loss: 2.0014
16/16 [==============================] - 0s 773us/step - loss: 2.3669
16/16 [==============================] - 0s 771us/step - loss: 2.4493
16/16 [==============================] - 0s 1ms/step - loss: 2.4593
16/16 [==============================] - 0s 1ms/step - loss: 2.4179
16/16 [==============================] - 0s 1ms/step - loss: 2.3796
16/16 [==============================] - 0s 1ms/step - loss: 2.3652
16/16 [==============================] - 0s 1ms/step - loss: 2.3606
16/16 [==============================] - 0s 787us/step - loss: 2.3604

Testing for epoch 43 index 2:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1274
16/16 [==============================] - 0s 800us/step - loss: 1.9885
16/16 [==============================] - 0s 800us/step - loss: 2.3486
16/16 [==============================] - 0s 793us/step - loss: 2.4281
16/16 [==============================] - 0s 810us/step - loss: 2.4365
16/16 [==============================] - 0s 805us/step - loss: 2.3939
16/16 [==============================] - 0s 806us/step - loss: 2.3558
16/16 [==============================] - 0s 830us/step - loss: 2.3415
16/16 [==============================] - 0s 830us/step - loss: 2.3370
16/16 [==============================] - 0s 812us/step - loss: 2.3370

Testing for epoch 43 index 3:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 810us/step - loss: 0.1306
16/16 [==============================] - 0s 811us/step - loss: 1.9621
16/16 [==============================] - 0s 817us/step - loss: 2.3132
16/16 [==============================] - 0s 805us/step - loss: 2.3880
16/16 [==============================] - 0s 784us/step - loss: 2.3952
16/16 [==============================] - 0s 820us/step - loss: 2.3532
16/16 [==============================] - 0s 793us/step - loss: 2.3157
16/16 [==============================] - 0s 778us/step - loss: 2.3018
16/16 [==============================] - 0s 786us/step - loss: 2.2976
16/16 [==============================] - 0s 785us/step - loss: 2.2976

Testing for epoch 43 index 4:
79/79 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1253
16/16 [==============================] - 0s 825us/step - loss: 2.0501
16/16 [==============================] - 0s 816us/step - loss: 2.4197
16/16 [==============================] - 0s 851us/step - loss: 2.4972
16/16 [==============================] - 0s 822us/step - loss: 2.5028
16/16 [==============================] - 0s 876us/step - loss: 2.4551
16/16 [==============================] - 0s 910us/step - loss: 2.4127
16/16 [==============================] - 0s 879us/step - loss: 2.3973
16/16 [==============================] - 0s 871us/step - loss: 2.3927
16/16 [==============================] - 0s 818us/step - loss: 2.3928

Testing for epoch 43 index 5:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 828us/step - loss: 0.1265
16/16 [==============================] - 0s 801us/step - loss: 2.0007
16/16 [==============================] - 0s 796us/step - loss: 2.3614
16/16 [==============================] - 0s 798us/step - loss: 2.4380
16/16 [==============================] - 0s 812us/step - loss: 2.4449
16/16 [==============================] - 0s 809us/step - loss: 2.4011
16/16 [==============================] - 0s 821us/step - loss: 2.3625
16/16 [==============================] - 0s 811us/step - loss: 2.3483
16/16 [==============================] - 0s 815us/step - loss: 2.3439
16/16 [==============================] - 0s 808us/step - loss: 2.3438
Epoch 44 of 60

Testing for epoch 44 index 1:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1299
16/16 [==============================] - 0s 803us/step - loss: 1.9974
16/16 [==============================] - 0s 782us/step - loss: 2.3529
16/16 [==============================] - 0s 792us/step - loss: 2.4269
16/16 [==============================] - 0s 795us/step - loss: 2.4322
16/16 [==============================] - 0s 797us/step - loss: 2.3865
16/16 [==============================] - 0s 805us/step - loss: 2.3467
16/16 [==============================] - 0s 805us/step - loss: 2.3323
16/16 [==============================] - 0s 795us/step - loss: 2.3279
16/16 [==============================] - 0s 793us/step - loss: 2.3279

Testing for epoch 44 index 2:
79/79 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1263
16/16 [==============================] - 0s 809us/step - loss: 2.0233
16/16 [==============================] - 0s 809us/step - loss: 2.3927
16/16 [==============================] - 0s 835us/step - loss: 2.4734
16/16 [==============================] - 0s 809us/step - loss: 2.4828
16/16 [==============================] - 0s 835us/step - loss: 2.4407
16/16 [==============================] - 0s 810us/step - loss: 2.4019
16/16 [==============================] - 0s 906us/step - loss: 2.3872
16/16 [==============================] - 0s 824us/step - loss: 2.3824
16/16 [==============================] - 0s 789us/step - loss: 2.3822

Testing for epoch 44 index 3:
79/79 [==============================] - 0s 595us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1234
16/16 [==============================] - 0s 929us/step - loss: 2.0523
16/16 [==============================] - 0s 784us/step - loss: 2.4219
16/16 [==============================] - 0s 829us/step - loss: 2.4981
16/16 [==============================] - 0s 831us/step - loss: 2.5027
16/16 [==============================] - 0s 805us/step - loss: 2.4546
16/16 [==============================] - 0s 1ms/step - loss: 2.4132
16/16 [==============================] - 0s 1ms/step - loss: 2.3981
16/16 [==============================] - 0s 1ms/step - loss: 2.3935
16/16 [==============================] - 0s 1ms/step - loss: 2.3934

Testing for epoch 44 index 4:
79/79 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1256
16/16 [==============================] - 0s 787us/step - loss: 1.9662
16/16 [==============================] - 0s 788us/step - loss: 2.3195
16/16 [==============================] - 0s 787us/step - loss: 2.3944
16/16 [==============================] - 0s 790us/step - loss: 2.4012
16/16 [==============================] - 0s 790us/step - loss: 2.3588
16/16 [==============================] - 0s 795us/step - loss: 2.3210
16/16 [==============================] - 0s 790us/step - loss: 2.3069
16/16 [==============================] - 0s 788us/step - loss: 2.3024
16/16 [==============================] - 0s 801us/step - loss: 2.3022

Testing for epoch 44 index 5:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1243
16/16 [==============================] - 0s 807us/step - loss: 2.0090
16/16 [==============================] - 0s 838us/step - loss: 2.3705
16/16 [==============================] - 0s 823us/step - loss: 2.4464
16/16 [==============================] - 0s 817us/step - loss: 2.4520
16/16 [==============================] - 0s 803us/step - loss: 2.4062
16/16 [==============================] - 0s 809us/step - loss: 2.3657
16/16 [==============================] - 0s 829us/step - loss: 2.3510
16/16 [==============================] - 0s 824us/step - loss: 2.3466
16/16 [==============================] - 0s 796us/step - loss: 2.3466
Epoch 45 of 60

Testing for epoch 45 index 1:
79/79 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1223
16/16 [==============================] - 0s 1ms/step - loss: 2.0306
16/16 [==============================] - 0s 1ms/step - loss: 2.3982
16/16 [==============================] - 0s 1ms/step - loss: 2.4740
16/16 [==============================] - 0s 806us/step - loss: 2.4773
16/16 [==============================] - 0s 825us/step - loss: 2.4287
16/16 [==============================] - 0s 821us/step - loss: 2.3869
16/16 [==============================] - 0s 791us/step - loss: 2.3718
16/16 [==============================] - 0s 1ms/step - loss: 2.3672
16/16 [==============================] - 0s 791us/step - loss: 2.3671

Testing for epoch 45 index 2:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1210
16/16 [==============================] - 0s 791us/step - loss: 2.0704
16/16 [==============================] - 0s 1ms/step - loss: 2.4462
16/16 [==============================] - 0s 1ms/step - loss: 2.5242
16/16 [==============================] - 0s 1ms/step - loss: 2.5296
16/16 [==============================] - 0s 1ms/step - loss: 2.4812
16/16 [==============================] - 0s 1ms/step - loss: 2.4387
16/16 [==============================] - 0s 1ms/step - loss: 2.4232
16/16 [==============================] - 0s 1ms/step - loss: 2.4184
16/16 [==============================] - 0s 786us/step - loss: 2.4183

Testing for epoch 45 index 3:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1213
16/16 [==============================] - 0s 1ms/step - loss: 2.0630
16/16 [==============================] - 0s 1ms/step - loss: 2.4339
16/16 [==============================] - 0s 791us/step - loss: 2.5090
16/16 [==============================] - 0s 1ms/step - loss: 2.5119
16/16 [==============================] - 0s 1ms/step - loss: 2.4617
16/16 [==============================] - 0s 796us/step - loss: 2.4184
16/16 [==============================] - 0s 790us/step - loss: 2.4027
16/16 [==============================] - 0s 787us/step - loss: 2.3979
16/16 [==============================] - 0s 1ms/step - loss: 2.3979

Testing for epoch 45 index 4:
79/79 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1207
16/16 [==============================] - 0s 1ms/step - loss: 2.0925
16/16 [==============================] - 0s 916us/step - loss: 2.4711
16/16 [==============================] - 0s 783us/step - loss: 2.5501
16/16 [==============================] - 0s 783us/step - loss: 2.5549
16/16 [==============================] - 0s 826us/step - loss: 2.5060
16/16 [==============================] - 0s 813us/step - loss: 2.4629
16/16 [==============================] - 0s 857us/step - loss: 2.4472
16/16 [==============================] - 0s 1ms/step - loss: 2.4425
16/16 [==============================] - 0s 1ms/step - loss: 2.4424

Testing for epoch 45 index 5:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1209
16/16 [==============================] - 0s 794us/step - loss: 2.0450
16/16 [==============================] - 0s 781us/step - loss: 2.4120
16/16 [==============================] - 0s 811us/step - loss: 2.4853
16/16 [==============================] - 0s 1ms/step - loss: 2.4875
16/16 [==============================] - 0s 1ms/step - loss: 2.4384
16/16 [==============================] - 0s 1ms/step - loss: 2.3963
16/16 [==============================] - 0s 1ms/step - loss: 2.3811
16/16 [==============================] - 0s 807us/step - loss: 2.3765
16/16 [==============================] - 0s 797us/step - loss: 2.3764
Epoch 46 of 60

Testing for epoch 46 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1157
16/16 [==============================] - 0s 803us/step - loss: 2.0892
16/16 [==============================] - 0s 783us/step - loss: 2.4688
16/16 [==============================] - 0s 779us/step - loss: 2.5448
16/16 [==============================] - 0s 790us/step - loss: 2.5463
16/16 [==============================] - 0s 791us/step - loss: 2.4953
16/16 [==============================] - 0s 788us/step - loss: 2.4526
16/16 [==============================] - 0s 786us/step - loss: 2.4370
16/16 [==============================] - 0s 788us/step - loss: 2.4322
16/16 [==============================] - 0s 792us/step - loss: 2.4321

Testing for epoch 46 index 2:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 784us/step - loss: 0.1203
16/16 [==============================] - 0s 786us/step - loss: 2.0153
16/16 [==============================] - 0s 774us/step - loss: 2.3790
16/16 [==============================] - 0s 782us/step - loss: 2.4528
16/16 [==============================] - 0s 786us/step - loss: 2.4549
16/16 [==============================] - 0s 791us/step - loss: 2.4069
16/16 [==============================] - 0s 776us/step - loss: 2.3664
16/16 [==============================] - 0s 778us/step - loss: 2.3517
16/16 [==============================] - 0s 772us/step - loss: 2.3471
16/16 [==============================] - 0s 782us/step - loss: 2.3469

Testing for epoch 46 index 3:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1176
16/16 [==============================] - 0s 784us/step - loss: 2.0705
16/16 [==============================] - 0s 780us/step - loss: 2.4423
16/16 [==============================] - 0s 778us/step - loss: 2.5156
16/16 [==============================] - 0s 787us/step - loss: 2.5160
16/16 [==============================] - 0s 775us/step - loss: 2.4639
16/16 [==============================] - 0s 780us/step - loss: 2.4200
16/16 [==============================] - 0s 783us/step - loss: 2.4040
16/16 [==============================] - 0s 779us/step - loss: 2.3992
16/16 [==============================] - 0s 780us/step - loss: 2.3991

Testing for epoch 46 index 4:
79/79 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1199
16/16 [==============================] - 0s 796us/step - loss: 2.0859
16/16 [==============================] - 0s 808us/step - loss: 2.4654
16/16 [==============================] - 0s 790us/step - loss: 2.5423
16/16 [==============================] - 0s 787us/step - loss: 2.5441
16/16 [==============================] - 0s 1ms/step - loss: 2.4922
16/16 [==============================] - 0s 781us/step - loss: 2.4480
16/16 [==============================] - 0s 794us/step - loss: 2.4320
16/16 [==============================] - 0s 800us/step - loss: 2.4271
16/16 [==============================] - 0s 783us/step - loss: 2.4269

Testing for epoch 46 index 5:
79/79 [==============================] - 0s 594us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1187
16/16 [==============================] - 0s 794us/step - loss: 2.0720
16/16 [==============================] - 0s 787us/step - loss: 2.4514
16/16 [==============================] - 0s 784us/step - loss: 2.5300
16/16 [==============================] - 0s 806us/step - loss: 2.5335
16/16 [==============================] - 0s 798us/step - loss: 2.4858
16/16 [==============================] - 0s 802us/step - loss: 2.4440
16/16 [==============================] - 0s 798us/step - loss: 2.4288
16/16 [==============================] - 0s 794us/step - loss: 2.4241
16/16 [==============================] - 0s 794us/step - loss: 2.4240
Epoch 47 of 60

Testing for epoch 47 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1168
16/16 [==============================] - 0s 779us/step - loss: 2.0878
16/16 [==============================] - 0s 786us/step - loss: 2.4644
16/16 [==============================] - 0s 803us/step - loss: 2.5367
16/16 [==============================] - 0s 800us/step - loss: 2.5353
16/16 [==============================] - 0s 821us/step - loss: 2.4811
16/16 [==============================] - 0s 796us/step - loss: 2.4357
16/16 [==============================] - 0s 793us/step - loss: 2.4197
16/16 [==============================] - 0s 784us/step - loss: 2.4149
16/16 [==============================] - 0s 793us/step - loss: 2.4149

Testing for epoch 47 index 2:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1129
16/16 [==============================] - 0s 863us/step - loss: 2.1291
16/16 [==============================] - 0s 866us/step - loss: 2.5159
16/16 [==============================] - 0s 877us/step - loss: 2.5921
16/16 [==============================] - 0s 791us/step - loss: 2.5924
16/16 [==============================] - 0s 785us/step - loss: 2.5399
16/16 [==============================] - 0s 793us/step - loss: 2.4954
16/16 [==============================] - 0s 794us/step - loss: 2.4795
16/16 [==============================] - 0s 808us/step - loss: 2.4746
16/16 [==============================] - 0s 813us/step - loss: 2.4745

Testing for epoch 47 index 3:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1157
16/16 [==============================] - 0s 801us/step - loss: 2.0875
16/16 [==============================] - 0s 797us/step - loss: 2.4622
16/16 [==============================] - 0s 793us/step - loss: 2.5350
16/16 [==============================] - 0s 793us/step - loss: 2.5349
16/16 [==============================] - 0s 802us/step - loss: 2.4821
16/16 [==============================] - 0s 803us/step - loss: 2.4374
16/16 [==============================] - 0s 803us/step - loss: 2.4214
16/16 [==============================] - 0s 790us/step - loss: 2.4166
16/16 [==============================] - 0s 784us/step - loss: 2.4165

Testing for epoch 47 index 4:
79/79 [==============================] - 0s 619us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1148
16/16 [==============================] - 0s 780us/step - loss: 2.1379
16/16 [==============================] - 0s 809us/step - loss: 2.5248
16/16 [==============================] - 0s 780us/step - loss: 2.5999
16/16 [==============================] - 0s 872us/step - loss: 2.5989
16/16 [==============================] - 0s 866us/step - loss: 2.5435
16/16 [==============================] - 0s 863us/step - loss: 2.4969
16/16 [==============================] - 0s 863us/step - loss: 2.4802
16/16 [==============================] - 0s 787us/step - loss: 2.4751
16/16 [==============================] - 0s 859us/step - loss: 2.4750

Testing for epoch 47 index 5:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 790us/step - loss: 0.1154
16/16 [==============================] - 0s 786us/step - loss: 2.0392
16/16 [==============================] - 0s 788us/step - loss: 2.4002
16/16 [==============================] - 0s 784us/step - loss: 2.4684
16/16 [==============================] - 0s 795us/step - loss: 2.4659
16/16 [==============================] - 0s 801us/step - loss: 2.4131
16/16 [==============================] - 0s 824us/step - loss: 2.3696
16/16 [==============================] - 0s 790us/step - loss: 2.3543
16/16 [==============================] - 0s 812us/step - loss: 2.3497
16/16 [==============================] - 0s 795us/step - loss: 2.3497
Epoch 48 of 60

Testing for epoch 48 index 1:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 876us/step - loss: 0.1150
16/16 [==============================] - 0s 864us/step - loss: 2.1081
16/16 [==============================] - 0s 861us/step - loss: 2.4903
16/16 [==============================] - 0s 856us/step - loss: 2.5626
16/16 [==============================] - 0s 862us/step - loss: 2.5596
16/16 [==============================] - 0s 865us/step - loss: 2.5044
16/16 [==============================] - 0s 865us/step - loss: 2.4593
16/16 [==============================] - 0s 870us/step - loss: 2.4434
16/16 [==============================] - 0s 875us/step - loss: 2.4386
16/16 [==============================] - 0s 808us/step - loss: 2.4386

Testing for epoch 48 index 2:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1147
16/16 [==============================] - 0s 781us/step - loss: 2.1044
16/16 [==============================] - 0s 779us/step - loss: 2.4888
16/16 [==============================] - 0s 782us/step - loss: 2.5643
16/16 [==============================] - 0s 825us/step - loss: 2.5644
16/16 [==============================] - 0s 801us/step - loss: 2.5118
16/16 [==============================] - 0s 819us/step - loss: 2.4675
16/16 [==============================] - 0s 796us/step - loss: 2.4516
16/16 [==============================] - 0s 786us/step - loss: 2.4465
16/16 [==============================] - 0s 779us/step - loss: 2.4463

Testing for epoch 48 index 3:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1152
16/16 [==============================] - 0s 774us/step - loss: 2.0719
16/16 [==============================] - 0s 786us/step - loss: 2.4408
16/16 [==============================] - 0s 809us/step - loss: 2.5109
16/16 [==============================] - 0s 793us/step - loss: 2.5086
16/16 [==============================] - 0s 795us/step - loss: 2.4552
16/16 [==============================] - 0s 811us/step - loss: 2.4115
16/16 [==============================] - 0s 797us/step - loss: 2.3960
16/16 [==============================] - 0s 824us/step - loss: 2.3913
16/16 [==============================] - 0s 818us/step - loss: 2.3912

Testing for epoch 48 index 4:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1107
16/16 [==============================] - 0s 795us/step - loss: 2.1577
16/16 [==============================] - 0s 857us/step - loss: 2.5481
16/16 [==============================] - 0s 813us/step - loss: 2.6204
16/16 [==============================] - 0s 797us/step - loss: 2.6165
16/16 [==============================] - 0s 790us/step - loss: 2.5579
16/16 [==============================] - 0s 782us/step - loss: 2.5097
16/16 [==============================] - 0s 804us/step - loss: 2.4927
16/16 [==============================] - 0s 779us/step - loss: 2.4877
16/16 [==============================] - 0s 782us/step - loss: 2.4876

Testing for epoch 48 index 5:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1159
16/16 [==============================] - 0s 803us/step - loss: 2.0767
16/16 [==============================] - 0s 810us/step - loss: 2.4525
16/16 [==============================] - 0s 781us/step - loss: 2.5232
16/16 [==============================] - 0s 796us/step - loss: 2.5203
16/16 [==============================] - 0s 810us/step - loss: 2.4657
16/16 [==============================] - 0s 782us/step - loss: 2.4213
16/16 [==============================] - 0s 814us/step - loss: 2.4055
16/16 [==============================] - 0s 805us/step - loss: 2.4008
16/16 [==============================] - 0s 781us/step - loss: 2.4008
Epoch 49 of 60

Testing for epoch 49 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1130
16/16 [==============================] - 0s 806us/step - loss: 2.1188
16/16 [==============================] - 0s 784us/step - loss: 2.5027
16/16 [==============================] - 0s 783us/step - loss: 2.5749
16/16 [==============================] - 0s 777us/step - loss: 2.5720
16/16 [==============================] - 0s 790us/step - loss: 2.5164
16/16 [==============================] - 0s 787us/step - loss: 2.4706
16/16 [==============================] - 0s 823us/step - loss: 2.4543
16/16 [==============================] - 0s 811us/step - loss: 2.4493
16/16 [==============================] - 0s 819us/step - loss: 2.4491

Testing for epoch 49 index 2:
79/79 [==============================] - 0s 589us/step
16/16 [==============================] - 0s 806us/step - loss: 0.1130
16/16 [==============================] - 0s 798us/step - loss: 2.1207
16/16 [==============================] - 0s 791us/step - loss: 2.5027
16/16 [==============================] - 0s 807us/step - loss: 2.5732
16/16 [==============================] - 0s 794us/step - loss: 2.5696
16/16 [==============================] - 0s 795us/step - loss: 2.5133
16/16 [==============================] - 0s 790us/step - loss: 2.4675
16/16 [==============================] - 0s 787us/step - loss: 2.4516
16/16 [==============================] - 0s 790us/step - loss: 2.4468
16/16 [==============================] - 0s 789us/step - loss: 2.4468

Testing for epoch 49 index 3:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1157
16/16 [==============================] - 0s 771us/step - loss: 2.1044
16/16 [==============================] - 0s 773us/step - loss: 2.4790
16/16 [==============================] - 0s 775us/step - loss: 2.5455
16/16 [==============================] - 0s 783us/step - loss: 2.5407
16/16 [==============================] - 0s 848us/step - loss: 2.4851
16/16 [==============================] - 0s 846us/step - loss: 2.4397
16/16 [==============================] - 0s 861us/step - loss: 2.4239
16/16 [==============================] - 0s 847us/step - loss: 2.4191
16/16 [==============================] - 0s 868us/step - loss: 2.4191

Testing for epoch 49 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1159
16/16 [==============================] - 0s 797us/step - loss: 2.1415
16/16 [==============================] - 0s 792us/step - loss: 2.5249
16/16 [==============================] - 0s 821us/step - loss: 2.5930
16/16 [==============================] - 0s 888us/step - loss: 2.5871
16/16 [==============================] - 0s 879us/step - loss: 2.5281
16/16 [==============================] - 0s 867us/step - loss: 2.4804
16/16 [==============================] - 0s 893us/step - loss: 2.4640
16/16 [==============================] - 0s 804us/step - loss: 2.4592
16/16 [==============================] - 0s 808us/step - loss: 2.4592

Testing for epoch 49 index 5:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 821us/step - loss: 0.1108
16/16 [==============================] - 0s 839us/step - loss: 2.1666
16/16 [==============================] - 0s 802us/step - loss: 2.5501
16/16 [==============================] - 0s 670us/step - loss: 2.6150
16/16 [==============================] - 0s 783us/step - loss: 2.6061
16/16 [==============================] - 0s 2ms/step - loss: 2.5432
16/16 [==============================] - 0s 748us/step - loss: 2.4931
16/16 [==============================] - 0s 2ms/step - loss: 2.4759
16/16 [==============================] - 0s 746us/step - loss: 2.4708
16/16 [==============================] - 0s 2ms/step - loss: 2.4707
Epoch 50 of 60

Testing for epoch 50 index 1:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1092
16/16 [==============================] - 0s 2ms/step - loss: 2.1786
16/16 [==============================] - 0s 2ms/step - loss: 2.5691
16/16 [==============================] - 0s 783us/step - loss: 2.6374
16/16 [==============================] - 0s 1ms/step - loss: 2.6307
16/16 [==============================] - 0s 983us/step - loss: 2.5707
16/16 [==============================] - 0s 1ms/step - loss: 2.5218
16/16 [==============================] - 0s 2ms/step - loss: 2.5047
16/16 [==============================] - 0s 827us/step - loss: 2.4996
16/16 [==============================] - 0s 820us/step - loss: 2.4996

Testing for epoch 50 index 2:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1106
16/16 [==============================] - 0s 812us/step - loss: 2.1213
16/16 [==============================] - 0s 2ms/step - loss: 2.4972
16/16 [==============================] - 0s 805us/step - loss: 2.5617
16/16 [==============================] - 0s 2ms/step - loss: 2.5540
16/16 [==============================] - 0s 779us/step - loss: 2.4949
16/16 [==============================] - 0s 798us/step - loss: 2.4473
16/16 [==============================] - 0s 802us/step - loss: 2.4311
16/16 [==============================] - 0s 827us/step - loss: 2.4263
16/16 [==============================] - 0s 827us/step - loss: 2.4263

Testing for epoch 50 index 3:
79/79 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1134
16/16 [==============================] - 0s 833us/step - loss: 2.1640
16/16 [==============================] - 0s 831us/step - loss: 2.5466
16/16 [==============================] - 0s 806us/step - loss: 2.6094
16/16 [==============================] - 0s 2ms/step - loss: 2.5990
16/16 [==============================] - 0s 2ms/step - loss: 2.5356
16/16 [==============================] - 0s 2ms/step - loss: 2.4853
16/16 [==============================] - 0s 2ms/step - loss: 2.4681
16/16 [==============================] - 0s 830us/step - loss: 2.4631
16/16 [==============================] - 0s 2ms/step - loss: 2.4631

Testing for epoch 50 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1106
16/16 [==============================] - 0s 2ms/step - loss: 2.1669
16/16 [==============================] - 0s 2ms/step - loss: 2.5499
16/16 [==============================] - 0s 2ms/step - loss: 2.6154
16/16 [==============================] - 0s 919us/step - loss: 2.6077
16/16 [==============================] - 0s 1ms/step - loss: 2.5490
16/16 [==============================] - 0s 2ms/step - loss: 2.5020
16/16 [==============================] - 0s 2ms/step - loss: 2.4856
16/16 [==============================] - 0s 2ms/step - loss: 2.4805
16/16 [==============================] - 0s 1ms/step - loss: 2.4803

Testing for epoch 50 index 5:
79/79 [==============================] - 0s 853us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1134
16/16 [==============================] - 0s 1ms/step - loss: 2.1299
16/16 [==============================] - 0s 1ms/step - loss: 2.5127
16/16 [==============================] - 0s 1ms/step - loss: 2.5788
16/16 [==============================] - 0s 818us/step - loss: 2.5713
16/16 [==============================] - 0s 828us/step - loss: 2.5120
16/16 [==============================] - 0s 806us/step - loss: 2.4655
16/16 [==============================] - 0s 1ms/step - loss: 2.4496
16/16 [==============================] - 0s 825us/step - loss: 2.4450
16/16 [==============================] - 0s 851us/step - loss: 2.4451
Epoch 51 of 60

Testing for epoch 51 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 799us/step - loss: 0.1102
16/16 [==============================] - 0s 2ms/step - loss: 2.1080
16/16 [==============================] - 0s 1ms/step - loss: 2.4813
16/16 [==============================] - 0s 801us/step - loss: 2.5444
16/16 [==============================] - 0s 1ms/step - loss: 2.5367
16/16 [==============================] - 0s 1ms/step - loss: 2.4800
16/16 [==============================] - 0s 779us/step - loss: 2.4343
16/16 [==============================] - 0s 780us/step - loss: 2.4184
16/16 [==============================] - 0s 809us/step - loss: 2.4137
16/16 [==============================] - 0s 816us/step - loss: 2.4137

Testing for epoch 51 index 2:
79/79 [==============================] - 0s 544us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1094
16/16 [==============================] - 0s 2ms/step - loss: 2.1884
16/16 [==============================] - 0s 825us/step - loss: 2.5791
16/16 [==============================] - 0s 1ms/step - loss: 2.6449
16/16 [==============================] - 0s 837us/step - loss: 2.6358
16/16 [==============================] - 0s 1ms/step - loss: 2.5744
16/16 [==============================] - 0s 792us/step - loss: 2.5257
16/16 [==============================] - 0s 2ms/step - loss: 2.5088
16/16 [==============================] - 0s 807us/step - loss: 2.5036
16/16 [==============================] - 0s 2ms/step - loss: 2.5035

Testing for epoch 51 index 3:
79/79 [==============================] - 0s 575us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1135
16/16 [==============================] - 0s 918us/step - loss: 2.1417
16/16 [==============================] - 0s 778us/step - loss: 2.5163
16/16 [==============================] - 0s 839us/step - loss: 2.5775
16/16 [==============================] - 0s 1ms/step - loss: 2.5668
16/16 [==============================] - 0s 817us/step - loss: 2.5060
16/16 [==============================] - 0s 820us/step - loss: 2.4582
16/16 [==============================] - 0s 2ms/step - loss: 2.4420
16/16 [==============================] - 0s 2ms/step - loss: 2.4372
16/16 [==============================] - 0s 2ms/step - loss: 2.4371

Testing for epoch 51 index 4:
79/79 [==============================] - 0s 660us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1133
16/16 [==============================] - 0s 2ms/step - loss: 2.1446
16/16 [==============================] - 0s 780us/step - loss: 2.5259
16/16 [==============================] - 0s 2ms/step - loss: 2.5907
16/16 [==============================] - 0s 2ms/step - loss: 2.5826
16/16 [==============================] - 0s 2ms/step - loss: 2.5259
16/16 [==============================] - 0s 778us/step - loss: 2.4802
16/16 [==============================] - 0s 945us/step - loss: 2.4642
16/16 [==============================] - 0s 2ms/step - loss: 2.4593
16/16 [==============================] - 0s 937us/step - loss: 2.4592

Testing for epoch 51 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 867us/step - loss: 0.1097
16/16 [==============================] - 0s 2ms/step - loss: 2.1334
16/16 [==============================] - 0s 2ms/step - loss: 2.5077
16/16 [==============================] - 0s 1ms/step - loss: 2.5687
16/16 [==============================] - 0s 814us/step - loss: 2.5580
16/16 [==============================] - 0s 1ms/step - loss: 2.4978
16/16 [==============================] - 0s 1ms/step - loss: 2.4505
16/16 [==============================] - 0s 2ms/step - loss: 2.4342
16/16 [==============================] - 0s 804us/step - loss: 2.4293
16/16 [==============================] - 0s 831us/step - loss: 2.4292
Epoch 52 of 60

Testing for epoch 52 index 1:
79/79 [==============================] - 0s 964us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1128
16/16 [==============================] - 0s 2ms/step - loss: 2.1843
16/16 [==============================] - 0s 1ms/step - loss: 2.5731
16/16 [==============================] - 0s 992us/step - loss: 2.6381
16/16 [==============================] - 0s 2ms/step - loss: 2.6285
16/16 [==============================] - 0s 2ms/step - loss: 2.5692
16/16 [==============================] - 0s 815us/step - loss: 2.5219
16/16 [==============================] - 0s 944us/step - loss: 2.5053
16/16 [==============================] - 0s 740us/step - loss: 2.5000
16/16 [==============================] - 0s 799us/step - loss: 2.4998

Testing for epoch 52 index 2:
79/79 [==============================] - 0s 498us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1151
16/16 [==============================] - 0s 662us/step - loss: 2.1366
16/16 [==============================] - 0s 786us/step - loss: 2.5143
16/16 [==============================] - 0s 832us/step - loss: 2.5790
16/16 [==============================] - 0s 828us/step - loss: 2.5708
16/16 [==============================] - 0s 772us/step - loss: 2.5126
16/16 [==============================] - 0s 763us/step - loss: 2.4669
16/16 [==============================] - 0s 761us/step - loss: 2.4509
16/16 [==============================] - 0s 762us/step - loss: 2.4460
16/16 [==============================] - 0s 765us/step - loss: 2.4459

Testing for epoch 52 index 3:
79/79 [==============================] - 0s 651us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1137
16/16 [==============================] - 0s 776us/step - loss: 2.1214
16/16 [==============================] - 0s 777us/step - loss: 2.4961
16/16 [==============================] - 0s 810us/step - loss: 2.5559
16/16 [==============================] - 0s 1ms/step - loss: 2.5443
16/16 [==============================] - 0s 1ms/step - loss: 2.4830
16/16 [==============================] - 0s 1ms/step - loss: 2.4348
16/16 [==============================] - 0s 1ms/step - loss: 2.4184
16/16 [==============================] - 0s 823us/step - loss: 2.4137
16/16 [==============================] - 0s 786us/step - loss: 2.4137

Testing for epoch 52 index 4:
79/79 [==============================] - 0s 809us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1077
16/16 [==============================] - 0s 1ms/step - loss: 2.2251
16/16 [==============================] - 0s 765us/step - loss: 2.6189
16/16 [==============================] - 0s 1ms/step - loss: 2.6792
16/16 [==============================] - 0s 1ms/step - loss: 2.6652
16/16 [==============================] - 0s 1ms/step - loss: 2.5992
16/16 [==============================] - 0s 1ms/step - loss: 2.5479
16/16 [==============================] - 0s 787us/step - loss: 2.5304
16/16 [==============================] - 0s 1ms/step - loss: 2.5253
16/16 [==============================] - 0s 1ms/step - loss: 2.5253

Testing for epoch 52 index 5:
79/79 [==============================] - 0s 575us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1081
16/16 [==============================] - 0s 787us/step - loss: 2.1911
16/16 [==============================] - 0s 801us/step - loss: 2.5848
16/16 [==============================] - 0s 776us/step - loss: 2.6481
16/16 [==============================] - 0s 819us/step - loss: 2.6369
16/16 [==============================] - 0s 784us/step - loss: 2.5737
16/16 [==============================] - 0s 778us/step - loss: 2.5244
16/16 [==============================] - 0s 774us/step - loss: 2.5073
16/16 [==============================] - 0s 830us/step - loss: 2.5021
16/16 [==============================] - 0s 783us/step - loss: 2.5019
Epoch 53 of 60

Testing for epoch 53 index 1:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 783us/step - loss: 0.1105
16/16 [==============================] - 0s 798us/step - loss: 2.2424
16/16 [==============================] - 0s 801us/step - loss: 2.6434
16/16 [==============================] - 0s 782us/step - loss: 2.7071
16/16 [==============================] - 0s 809us/step - loss: 2.6960
16/16 [==============================] - 0s 781us/step - loss: 2.6329
16/16 [==============================] - 0s 796us/step - loss: 2.5825
16/16 [==============================] - 0s 785us/step - loss: 2.5653
16/16 [==============================] - 0s 779us/step - loss: 2.5603
16/16 [==============================] - 0s 780us/step - loss: 2.5603

Testing for epoch 53 index 2:
79/79 [==============================] - 0s 666us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1065
16/16 [==============================] - 0s 773us/step - loss: 2.2126
16/16 [==============================] - 0s 780us/step - loss: 2.5990
16/16 [==============================] - 0s 799us/step - loss: 2.6537
16/16 [==============================] - 0s 775us/step - loss: 2.6362
16/16 [==============================] - 0s 778us/step - loss: 2.5665
16/16 [==============================] - 0s 777us/step - loss: 2.5130
16/16 [==============================] - 0s 782us/step - loss: 2.4951
16/16 [==============================] - 0s 793us/step - loss: 2.4897
16/16 [==============================] - 0s 783us/step - loss: 2.4896

Testing for epoch 53 index 3:
79/79 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1109
16/16 [==============================] - 0s 783us/step - loss: 2.2409
16/16 [==============================] - 0s 826us/step - loss: 2.6359
16/16 [==============================] - 0s 802us/step - loss: 2.6951
16/16 [==============================] - 0s 784us/step - loss: 2.6803
16/16 [==============================] - 0s 818us/step - loss: 2.6154
16/16 [==============================] - 0s 854us/step - loss: 2.5654
16/16 [==============================] - 0s 824us/step - loss: 2.5480
16/16 [==============================] - 0s 878us/step - loss: 2.5427
16/16 [==============================] - 0s 823us/step - loss: 2.5425

Testing for epoch 53 index 4:
79/79 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 822us/step - loss: 0.1077
16/16 [==============================] - 0s 774us/step - loss: 2.1988
16/16 [==============================] - 0s 791us/step - loss: 2.5828
16/16 [==============================] - 0s 824us/step - loss: 2.6395
16/16 [==============================] - 0s 777us/step - loss: 2.6247
16/16 [==============================] - 0s 786us/step - loss: 2.5585
16/16 [==============================] - 0s 791us/step - loss: 2.5071
16/16 [==============================] - 0s 796us/step - loss: 2.4895
16/16 [==============================] - 0s 784us/step - loss: 2.4842
16/16 [==============================] - 0s 781us/step - loss: 2.4840

Testing for epoch 53 index 5:
79/79 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1101
16/16 [==============================] - 0s 823us/step - loss: 2.1742
16/16 [==============================] - 0s 806us/step - loss: 2.5541
16/16 [==============================] - 0s 815us/step - loss: 2.6106
16/16 [==============================] - 0s 786us/step - loss: 2.5974
16/16 [==============================] - 0s 779us/step - loss: 2.5359
16/16 [==============================] - 0s 777us/step - loss: 2.4884
16/16 [==============================] - 0s 821us/step - loss: 2.4719
16/16 [==============================] - 0s 831us/step - loss: 2.4668
16/16 [==============================] - 0s 794us/step - loss: 2.4666
Epoch 54 of 60

Testing for epoch 54 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 824us/step - loss: 0.1084
16/16 [==============================] - 0s 791us/step - loss: 2.1517
16/16 [==============================] - 0s 804us/step - loss: 2.5217
16/16 [==============================] - 0s 781us/step - loss: 2.5735
16/16 [==============================] - 0s 773us/step - loss: 2.5572
16/16 [==============================] - 0s 860us/step - loss: 2.4921
16/16 [==============================] - 0s 798us/step - loss: 2.4427
16/16 [==============================] - 0s 783us/step - loss: 2.4259
16/16 [==============================] - 0s 788us/step - loss: 2.4209
16/16 [==============================] - 0s 779us/step - loss: 2.4208

Testing for epoch 54 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 841us/step - loss: 0.1095
16/16 [==============================] - 0s 791us/step - loss: 2.1899
16/16 [==============================] - 0s 857us/step - loss: 2.5646
16/16 [==============================] - 0s 832us/step - loss: 2.6178
16/16 [==============================] - 0s 805us/step - loss: 2.5997
16/16 [==============================] - 0s 811us/step - loss: 2.5326
16/16 [==============================] - 0s 1ms/step - loss: 2.4819
16/16 [==============================] - 0s 799us/step - loss: 2.4647
16/16 [==============================] - 0s 810us/step - loss: 2.4596
16/16 [==============================] - 0s 818us/step - loss: 2.4596

Testing for epoch 54 index 3:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1083
16/16 [==============================] - 0s 802us/step - loss: 2.1131
16/16 [==============================] - 0s 796us/step - loss: 2.4631
16/16 [==============================] - 0s 776us/step - loss: 2.5087
16/16 [==============================] - 0s 791us/step - loss: 2.4890
16/16 [==============================] - 0s 833us/step - loss: 2.4226
16/16 [==============================] - 0s 784us/step - loss: 2.3731
16/16 [==============================] - 0s 772us/step - loss: 2.3567
16/16 [==============================] - 0s 772us/step - loss: 2.3520
16/16 [==============================] - 0s 798us/step - loss: 2.3520

Testing for epoch 54 index 4:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1097
16/16 [==============================] - 0s 820us/step - loss: 2.2147
16/16 [==============================] - 0s 790us/step - loss: 2.5931
16/16 [==============================] - 0s 786us/step - loss: 2.6463
16/16 [==============================] - 0s 793us/step - loss: 2.6278
16/16 [==============================] - 0s 815us/step - loss: 2.5607
16/16 [==============================] - 0s 786us/step - loss: 2.5099
16/16 [==============================] - 0s 800us/step - loss: 2.4930
16/16 [==============================] - 0s 804us/step - loss: 2.4882
16/16 [==============================] - 0s 803us/step - loss: 2.4882

Testing for epoch 54 index 5:
79/79 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 865us/step - loss: 0.1090
16/16 [==============================] - 0s 821us/step - loss: 2.2205
16/16 [==============================] - 0s 781us/step - loss: 2.5931
16/16 [==============================] - 0s 1ms/step - loss: 2.6411
16/16 [==============================] - 0s 1ms/step - loss: 2.6206
16/16 [==============================] - 0s 783us/step - loss: 2.5518
16/16 [==============================] - 0s 789us/step - loss: 2.5000
16/16 [==============================] - 0s 791us/step - loss: 2.4825
16/16 [==============================] - 0s 786us/step - loss: 2.4773
16/16 [==============================] - 0s 784us/step - loss: 2.4773
Epoch 55 of 60

Testing for epoch 55 index 1:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 788us/step - loss: 0.1066
16/16 [==============================] - 0s 821us/step - loss: 2.2507
16/16 [==============================] - 0s 780us/step - loss: 2.6376
16/16 [==============================] - 0s 776us/step - loss: 2.6928
16/16 [==============================] - 0s 775us/step - loss: 2.6741
16/16 [==============================] - 0s 780us/step - loss: 2.6065
16/16 [==============================] - 0s 778us/step - loss: 2.5550
16/16 [==============================] - 0s 908us/step - loss: 2.5376
16/16 [==============================] - 0s 1ms/step - loss: 2.5325
16/16 [==============================] - 0s 1ms/step - loss: 2.5324

Testing for epoch 55 index 2:
79/79 [==============================] - 0s 827us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1066
16/16 [==============================] - 0s 830us/step - loss: 2.2226
16/16 [==============================] - 0s 782us/step - loss: 2.5906
16/16 [==============================] - 0s 780us/step - loss: 2.6408
16/16 [==============================] - 0s 1ms/step - loss: 2.6207
16/16 [==============================] - 0s 1ms/step - loss: 2.5530
16/16 [==============================] - 0s 1ms/step - loss: 2.5026
16/16 [==============================] - 0s 1ms/step - loss: 2.4856
16/16 [==============================] - 0s 1ms/step - loss: 2.4805
16/16 [==============================] - 0s 1ms/step - loss: 2.4805

Testing for epoch 55 index 3:
79/79 [==============================] - 0s 733us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1096
16/16 [==============================] - 0s 1ms/step - loss: 2.2626
16/16 [==============================] - 0s 1ms/step - loss: 2.6387
16/16 [==============================] - 0s 1ms/step - loss: 2.6881
16/16 [==============================] - 0s 1ms/step - loss: 2.6669
16/16 [==============================] - 0s 1ms/step - loss: 2.5970
16/16 [==============================] - 0s 1ms/step - loss: 2.5450
16/16 [==============================] - 0s 1ms/step - loss: 2.5276
16/16 [==============================] - 0s 1ms/step - loss: 2.5226
16/16 [==============================] - 0s 799us/step - loss: 2.5226

Testing for epoch 55 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1016
16/16 [==============================] - 0s 783us/step - loss: 2.2888
16/16 [==============================] - 0s 782us/step - loss: 2.6711
16/16 [==============================] - 0s 815us/step - loss: 2.7212
16/16 [==============================] - 0s 1ms/step - loss: 2.6985
16/16 [==============================] - 0s 848us/step - loss: 2.6265
16/16 [==============================] - 0s 837us/step - loss: 2.5724
16/16 [==============================] - 0s 788us/step - loss: 2.5543
16/16 [==============================] - 0s 828us/step - loss: 2.5490
16/16 [==============================] - 0s 827us/step - loss: 2.5490

Testing for epoch 55 index 5:
79/79 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 924us/step - loss: 0.1076
16/16 [==============================] - 0s 874us/step - loss: 2.3363
16/16 [==============================] - 0s 793us/step - loss: 2.7287
16/16 [==============================] - 0s 798us/step - loss: 2.7820
16/16 [==============================] - 0s 796us/step - loss: 2.7605
16/16 [==============================] - 0s 836us/step - loss: 2.6894
16/16 [==============================] - 0s 801us/step - loss: 2.6356
16/16 [==============================] - 0s 797us/step - loss: 2.6175
16/16 [==============================] - 0s 791us/step - loss: 2.6122
16/16 [==============================] - 0s 794us/step - loss: 2.6122
Epoch 56 of 60

Testing for epoch 56 index 1:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1053
16/16 [==============================] - 0s 823us/step - loss: 2.2654
16/16 [==============================] - 0s 784us/step - loss: 2.6376
16/16 [==============================] - 0s 796us/step - loss: 2.6831
16/16 [==============================] - 0s 798us/step - loss: 2.6585
16/16 [==============================] - 0s 784us/step - loss: 2.5853
16/16 [==============================] - 0s 784us/step - loss: 2.5317
16/16 [==============================] - 0s 776us/step - loss: 2.5138
16/16 [==============================] - 0s 788us/step - loss: 2.5086
16/16 [==============================] - 0s 780us/step - loss: 2.5085

Testing for epoch 56 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1091
16/16 [==============================] - 0s 846us/step - loss: 2.2312
16/16 [==============================] - 0s 782us/step - loss: 2.6027
16/16 [==============================] - 0s 806us/step - loss: 2.6531
16/16 [==============================] - 0s 791us/step - loss: 2.6318
16/16 [==============================] - 0s 771us/step - loss: 2.5612
16/16 [==============================] - 0s 795us/step - loss: 2.5079
16/16 [==============================] - 0s 779us/step - loss: 2.4899
16/16 [==============================] - 0s 788us/step - loss: 2.4844
16/16 [==============================] - 0s 784us/step - loss: 2.4842

Testing for epoch 56 index 3:
79/79 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1080
16/16 [==============================] - 0s 804us/step - loss: 2.2179
16/16 [==============================] - 0s 792us/step - loss: 2.5805
16/16 [==============================] - 0s 778us/step - loss: 2.6276
16/16 [==============================] - 0s 777us/step - loss: 2.6063
16/16 [==============================] - 0s 784us/step - loss: 2.5380
16/16 [==============================] - 0s 779us/step - loss: 2.4867
16/16 [==============================] - 0s 795us/step - loss: 2.4695
16/16 [==============================] - 0s 798us/step - loss: 2.4644
16/16 [==============================] - 0s 791us/step - loss: 2.4644

Testing for epoch 56 index 4:
79/79 [==============================] - 0s 709us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1050
16/16 [==============================] - 0s 1ms/step - loss: 2.2906
16/16 [==============================] - 0s 1ms/step - loss: 2.6671
16/16 [==============================] - 0s 1ms/step - loss: 2.7144
16/16 [==============================] - 0s 1ms/step - loss: 2.6909
16/16 [==============================] - 0s 1ms/step - loss: 2.6183
16/16 [==============================] - 0s 787us/step - loss: 2.5653
16/16 [==============================] - 0s 783us/step - loss: 2.5474
16/16 [==============================] - 0s 800us/step - loss: 2.5423
16/16 [==============================] - 0s 1ms/step - loss: 2.5422

Testing for epoch 56 index 5:
79/79 [==============================] - 0s 823us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1082
16/16 [==============================] - 0s 831us/step - loss: 2.2431
16/16 [==============================] - 0s 843us/step - loss: 2.6105
16/16 [==============================] - 0s 781us/step - loss: 2.6582
16/16 [==============================] - 0s 786us/step - loss: 2.6367
16/16 [==============================] - 0s 790us/step - loss: 2.5673
16/16 [==============================] - 0s 809us/step - loss: 2.5156
16/16 [==============================] - 0s 805us/step - loss: 2.4986
16/16 [==============================] - 0s 807us/step - loss: 2.4937
16/16 [==============================] - 0s 804us/step - loss: 2.4937
Epoch 57 of 60

Testing for epoch 57 index 1:
79/79 [==============================] - 0s 582us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1051
16/16 [==============================] - 0s 794us/step - loss: 2.3166
16/16 [==============================] - 0s 852us/step - loss: 2.6952
16/16 [==============================] - 0s 812us/step - loss: 2.7417
16/16 [==============================] - 0s 788us/step - loss: 2.7163
16/16 [==============================] - 0s 781us/step - loss: 2.6402
16/16 [==============================] - 0s 775us/step - loss: 2.5838
16/16 [==============================] - 0s 787us/step - loss: 2.5650
16/16 [==============================] - 0s 783us/step - loss: 2.5596
16/16 [==============================] - 0s 808us/step - loss: 2.5596

Testing for epoch 57 index 2:
79/79 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1056
16/16 [==============================] - 0s 1ms/step - loss: 2.1999
16/16 [==============================] - 0s 1ms/step - loss: 2.5532
16/16 [==============================] - 0s 1ms/step - loss: 2.5957
16/16 [==============================] - 0s 1ms/step - loss: 2.5734
16/16 [==============================] - 0s 930us/step - loss: 2.5046
16/16 [==============================] - 0s 902us/step - loss: 2.4545
16/16 [==============================] - 0s 1ms/step - loss: 2.4380
16/16 [==============================] - 0s 1ms/step - loss: 2.4332
16/16 [==============================] - 0s 1ms/step - loss: 2.4332

Testing for epoch 57 index 3:
79/79 [==============================] - 0s 665us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1134
16/16 [==============================] - 0s 842us/step - loss: 2.1538
16/16 [==============================] - 0s 780us/step - loss: 2.5023
16/16 [==============================] - 0s 775us/step - loss: 2.5460
16/16 [==============================] - 0s 788us/step - loss: 2.5254
16/16 [==============================] - 0s 775us/step - loss: 2.4601
16/16 [==============================] - 0s 775us/step - loss: 2.4117
16/16 [==============================] - 0s 789us/step - loss: 2.3954
16/16 [==============================] - 0s 788us/step - loss: 2.3907
16/16 [==============================] - 0s 787us/step - loss: 2.3906

Testing for epoch 57 index 4:
79/79 [==============================] - 0s 909us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1055
16/16 [==============================] - 0s 809us/step - loss: 2.3141
16/16 [==============================] - 0s 817us/step - loss: 2.6890
16/16 [==============================] - 0s 861us/step - loss: 2.7333
16/16 [==============================] - 0s 789us/step - loss: 2.7077
16/16 [==============================] - 0s 777us/step - loss: 2.6323
16/16 [==============================] - 0s 780us/step - loss: 2.5774
16/16 [==============================] - 0s 780us/step - loss: 2.5593
16/16 [==============================] - 0s 802us/step - loss: 2.5541
16/16 [==============================] - 0s 790us/step - loss: 2.5541

Testing for epoch 57 index 5:
79/79 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1056
16/16 [==============================] - 0s 789us/step - loss: 2.2966
16/16 [==============================] - 0s 796us/step - loss: 2.6697
16/16 [==============================] - 0s 781us/step - loss: 2.7157
16/16 [==============================] - 0s 781us/step - loss: 2.6915
16/16 [==============================] - 0s 1ms/step - loss: 2.6184
16/16 [==============================] - 0s 1ms/step - loss: 2.5641
16/16 [==============================] - 0s 803us/step - loss: 2.5462
16/16 [==============================] - 0s 776us/step - loss: 2.5410
16/16 [==============================] - 0s 805us/step - loss: 2.5409
Epoch 58 of 60

Testing for epoch 58 index 1:
79/79 [==============================] - 0s 585us/step
16/16 [==============================] - 0s 781us/step - loss: 0.1061
16/16 [==============================] - 0s 785us/step - loss: 2.3267
16/16 [==============================] - 0s 777us/step - loss: 2.7069
16/16 [==============================] - 0s 784us/step - loss: 2.7544
16/16 [==============================] - 0s 782us/step - loss: 2.7306
16/16 [==============================] - 0s 1ms/step - loss: 2.6573
16/16 [==============================] - 0s 816us/step - loss: 2.6031
16/16 [==============================] - 0s 1ms/step - loss: 2.5850
16/16 [==============================] - 0s 1ms/step - loss: 2.5797
16/16 [==============================] - 0s 1ms/step - loss: 2.5796

Testing for epoch 58 index 2:
79/79 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1053
16/16 [==============================] - 0s 1ms/step - loss: 2.2433
16/16 [==============================] - 0s 778us/step - loss: 2.6007
16/16 [==============================] - 0s 778us/step - loss: 2.6389
16/16 [==============================] - 0s 782us/step - loss: 2.6116
16/16 [==============================] - 0s 784us/step - loss: 2.5366
16/16 [==============================] - 0s 777us/step - loss: 2.4824
16/16 [==============================] - 0s 773us/step - loss: 2.4647
16/16 [==============================] - 0s 780us/step - loss: 2.4596
16/16 [==============================] - 0s 792us/step - loss: 2.4596

Testing for epoch 58 index 3:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1060
16/16 [==============================] - 0s 813us/step - loss: 2.2387
16/16 [==============================] - 0s 788us/step - loss: 2.5997
16/16 [==============================] - 0s 780us/step - loss: 2.6431
16/16 [==============================] - 0s 827us/step - loss: 2.6195
16/16 [==============================] - 0s 818us/step - loss: 2.5483
16/16 [==============================] - 0s 820us/step - loss: 2.4955
16/16 [==============================] - 0s 774us/step - loss: 2.4780
16/16 [==============================] - 0s 791us/step - loss: 2.4729
16/16 [==============================] - 0s 801us/step - loss: 2.4729

Testing for epoch 58 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1044
16/16 [==============================] - 0s 792us/step - loss: 2.3186
16/16 [==============================] - 0s 778us/step - loss: 2.6976
16/16 [==============================] - 0s 779us/step - loss: 2.7451
16/16 [==============================] - 0s 783us/step - loss: 2.7220
16/16 [==============================] - 0s 795us/step - loss: 2.6492
16/16 [==============================] - 0s 787us/step - loss: 2.5949
16/16 [==============================] - 0s 792us/step - loss: 2.5768
16/16 [==============================] - 0s 1ms/step - loss: 2.5714
16/16 [==============================] - 0s 807us/step - loss: 2.5713

Testing for epoch 58 index 5:
79/79 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 783us/step - loss: 0.1039
16/16 [==============================] - 0s 794us/step - loss: 2.2733
16/16 [==============================] - 0s 768us/step - loss: 2.6396
16/16 [==============================] - 0s 790us/step - loss: 2.6824
16/16 [==============================] - 0s 774us/step - loss: 2.6577
16/16 [==============================] - 0s 780us/step - loss: 2.5860
16/16 [==============================] - 0s 1ms/step - loss: 2.5336
16/16 [==============================] - 0s 1ms/step - loss: 2.5162
16/16 [==============================] - 0s 1ms/step - loss: 2.5110
16/16 [==============================] - 0s 1ms/step - loss: 2.5109
Epoch 59 of 60

Testing for epoch 59 index 1:
79/79 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1015
16/16 [==============================] - 0s 799us/step - loss: 2.2663
16/16 [==============================] - 0s 786us/step - loss: 2.6320
16/16 [==============================] - 0s 785us/step - loss: 2.6746
16/16 [==============================] - 0s 782us/step - loss: 2.6500
16/16 [==============================] - 0s 779us/step - loss: 2.5779
16/16 [==============================] - 0s 776us/step - loss: 2.5255
16/16 [==============================] - 0s 781us/step - loss: 2.5079
16/16 [==============================] - 0s 780us/step - loss: 2.5025
16/16 [==============================] - 0s 807us/step - loss: 2.5023

Testing for epoch 59 index 2:
79/79 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1025
16/16 [==============================] - 0s 807us/step - loss: 2.3515
16/16 [==============================] - 0s 777us/step - loss: 2.7275
16/16 [==============================] - 0s 774us/step - loss: 2.7688
16/16 [==============================] - 0s 1ms/step - loss: 2.7405
16/16 [==============================] - 0s 1ms/step - loss: 2.6618
16/16 [==============================] - 0s 776us/step - loss: 2.6044
16/16 [==============================] - 0s 1ms/step - loss: 2.5857
16/16 [==============================] - 0s 780us/step - loss: 2.5804
16/16 [==============================] - 0s 786us/step - loss: 2.5804

Testing for epoch 59 index 3:
79/79 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1027
16/16 [==============================] - 0s 791us/step - loss: 2.2619
16/16 [==============================] - 0s 780us/step - loss: 2.6166
16/16 [==============================] - 0s 783us/step - loss: 2.6521
16/16 [==============================] - 0s 819us/step - loss: 2.6231
16/16 [==============================] - 0s 796us/step - loss: 2.5477
16/16 [==============================] - 0s 827us/step - loss: 2.4932
16/16 [==============================] - 0s 795us/step - loss: 2.4756
16/16 [==============================] - 0s 786us/step - loss: 2.4707
16/16 [==============================] - 0s 778us/step - loss: 2.4708

Testing for epoch 59 index 4:
79/79 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1013
16/16 [==============================] - 0s 800us/step - loss: 2.2814
16/16 [==============================] - 0s 797us/step - loss: 2.6450
16/16 [==============================] - 0s 797us/step - loss: 2.6843
16/16 [==============================] - 0s 797us/step - loss: 2.6560
16/16 [==============================] - 0s 801us/step - loss: 2.5800
16/16 [==============================] - 0s 792us/step - loss: 2.5259
16/16 [==============================] - 0s 796us/step - loss: 2.5080
16/16 [==============================] - 0s 814us/step - loss: 2.5027
16/16 [==============================] - 0s 820us/step - loss: 2.5026

Testing for epoch 59 index 5:
79/79 [==============================] - 0s 657us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1035
16/16 [==============================] - 0s 785us/step - loss: 2.3241
16/16 [==============================] - 0s 810us/step - loss: 2.7005
16/16 [==============================] - 0s 802us/step - loss: 2.7443
16/16 [==============================] - 0s 788us/step - loss: 2.7189
16/16 [==============================] - 0s 785us/step - loss: 2.6445
16/16 [==============================] - 0s 783us/step - loss: 2.5895
16/16 [==============================] - 0s 787us/step - loss: 2.5711
16/16 [==============================] - 0s 794us/step - loss: 2.5655
16/16 [==============================] - 0s 1ms/step - loss: 2.5654
Epoch 60 of 60

Testing for epoch 60 index 1:
79/79 [==============================] - 0s 828us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0991
16/16 [==============================] - 0s 797us/step - loss: 2.3587
16/16 [==============================] - 0s 1ms/step - loss: 2.7350
16/16 [==============================] - 0s 1ms/step - loss: 2.7747
16/16 [==============================] - 0s 1ms/step - loss: 2.7463
16/16 [==============================] - 0s 1ms/step - loss: 2.6678
16/16 [==============================] - 0s 1ms/step - loss: 2.6113
16/16 [==============================] - 0s 1ms/step - loss: 2.5929
16/16 [==============================] - 0s 1ms/step - loss: 2.5877
16/16 [==============================] - 0s 809us/step - loss: 2.5878

Testing for epoch 60 index 2:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 828us/step - loss: 0.1038
16/16 [==============================] - 0s 830us/step - loss: 2.2804
16/16 [==============================] - 0s 783us/step - loss: 2.6366
16/16 [==============================] - 0s 788us/step - loss: 2.6709
16/16 [==============================] - 0s 1ms/step - loss: 2.6408
16/16 [==============================] - 0s 1ms/step - loss: 2.5626
16/16 [==============================] - 0s 1ms/step - loss: 2.5067
16/16 [==============================] - 0s 1ms/step - loss: 2.4886
16/16 [==============================] - 0s 1ms/step - loss: 2.4834
16/16 [==============================] - 0s 803us/step - loss: 2.4834

Testing for epoch 60 index 3:
79/79 [==============================] - 0s 812us/step
16/16 [==============================] - 0s 788us/step - loss: 0.0991
16/16 [==============================] - 0s 1ms/step - loss: 2.3934
16/16 [==============================] - 0s 1ms/step - loss: 2.7744
16/16 [==============================] - 0s 1ms/step - loss: 2.8152
16/16 [==============================] - 0s 1ms/step - loss: 2.7874
16/16 [==============================] - 0s 1ms/step - loss: 2.7085
16/16 [==============================] - 0s 777us/step - loss: 2.6519
16/16 [==============================] - 0s 1ms/step - loss: 2.6333
16/16 [==============================] - 0s 778us/step - loss: 2.6279
16/16 [==============================] - 0s 1ms/step - loss: 2.6278

Testing for epoch 60 index 4:
79/79 [==============================] - 0s 579us/step
16/16 [==============================] - 0s 793us/step - loss: 0.0991
16/16 [==============================] - 0s 784us/step - loss: 2.3763
16/16 [==============================] - 0s 782us/step - loss: 2.7524
16/16 [==============================] - 0s 782us/step - loss: 2.7925
16/16 [==============================] - 0s 1ms/step - loss: 2.7641
16/16 [==============================] - 0s 1ms/step - loss: 2.6876
16/16 [==============================] - 0s 1ms/step - loss: 2.6322
16/16 [==============================] - 0s 1ms/step - loss: 2.6139
16/16 [==============================] - 0s 1ms/step - loss: 2.6085
16/16 [==============================] - 0s 1ms/step - loss: 2.6085

Testing for epoch 60 index 5:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1005
16/16 [==============================] - 0s 785us/step - loss: 2.3451
16/16 [==============================] - 0s 785us/step - loss: 2.7153
16/16 [==============================] - 0s 771us/step - loss: 2.7525
16/16 [==============================] - 0s 774us/step - loss: 2.7234
16/16 [==============================] - 0s 789us/step - loss: 2.6445
16/16 [==============================] - 0s 784us/step - loss: 2.5884
16/16 [==============================] - 0s 789us/step - loss: 2.5702
16/16 [==============================] - 0s 789us/step - loss: 2.5652
16/16 [==============================] - 0s 802us/step - loss: 2.5653
79/79 [==============================] - 0s 580us/step</code></pre>
</div>
</div>
<div id="0c306dbb-fcb8-48ab-9e0c-5ae0817b9067" class="cell" data-execution_count="1840">
<div class="sourceCode cell-code" id="cb479"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb479-1"><a href="#cb479-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="e13a03c9-074f-48f4-b580-2245e661ffd8" class="cell" data-execution_count="1841">
<div class="sourceCode cell-code" id="cb480"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb480-1"><a href="#cb480-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div id="07ed9d30-dff7-4f1a-9132-eb6909c00a8b" class="cell" data-execution_count="1842">
<div class="sourceCode cell-code" id="cb481"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb481-1"><a href="#cb481-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div id="b90d9cdf-9e91-46c3-b14d-3c8a9022f464" class="cell" data-execution_count="1843">
<div class="sourceCode cell-code" id="cb482"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb482-1"><a href="#cb482-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-335-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="8cce9fc8-8f58-4ab4-b683-1772f9aec70c" class="cell" data-execution_count="1844">
<div class="sourceCode cell-code" id="cb485"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb485-1"><a href="#cb485-1" aria-hidden="true" tabindex="-1"></a>thirteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  thirteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscp" class="level3">
<h3 class="anchored" data-anchor-id="lscp">LSCP</h3>
<div id="8dc964e7-1fa2-4e49-8c0d-bdc7064e359a" class="cell" data-execution_count="1845">
<div class="sourceCode cell-code" id="cb487"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb487-1"><a href="#cb487-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb487-2"><a href="#cb487-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb487-3"><a href="#cb487-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb487-4"><a href="#cb487-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div id="01d34ad9-c2dc-419b-8775-7910c792a67b" class="cell" data-execution_count="1846">
<div class="sourceCode cell-code" id="cb489"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb489-1"><a href="#cb489-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div id="addb3065-c030-4714-8578-46a0257a2256" class="cell" data-execution_count="1847">
<div class="sourceCode cell-code" id="cb490"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb490-1"><a href="#cb490-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div id="13d15c75-eef0-41ee-b064-a776bf869227" class="cell" data-execution_count="1848">
<div class="sourceCode cell-code" id="cb491"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb491-1"><a href="#cb491-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)</span></code></pre></div>
</div>
<div id="f701bbf2-92d6-4d32-af0b-cbd389f6f7ce" class="cell" data-execution_count="1849">
<div class="sourceCode cell-code" id="cb492"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb492-1"><a href="#cb492-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-341-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.978
Precision: 0.990
Recall: 0.987
F1 Score: 0.989</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div id="de19e271-d6cf-4e93-82ab-62fdcecce6df" class="cell" data-execution_count="1850">
<div class="sourceCode cell-code" id="cb495"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb495-1"><a href="#cb495-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> thirteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = thirteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="bunny-result" class="level2">
<h2 class="anchored" data-anchor-id="bunny-result">Bunny Result</h2>
<div id="a5d1ea92-fc89-4788-b81f-a6b86743d002" class="cell" data-execution_count="1851">
<div class="sourceCode cell-code" id="cb497"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb497-1"><a href="#cb497-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1851">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">GODE</td>
<td>0.988</td>
<td>0.995</td>
<td>0.993</td>
<td>0.994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">LOF (Breunig et al., 2000)</td>
<td>0.913</td>
<td>0.955</td>
<td>0.953</td>
<td>0.954</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">kNN (Ramaswamy et al., 2000)</td>
<td>0.942</td>
<td>0.997</td>
<td>0.942</td>
<td>0.969</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td>0.935</td>
<td>0.992</td>
<td>0.939</td>
<td>0.965</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MCD (Hardin and Rocke, 2004)</td>
<td>0.982</td>
<td>0.992</td>
<td>0.989</td>
<td>0.990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td>0.954</td>
<td>0.977</td>
<td>0.974</td>
<td>0.976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ABOD (Kriegel et al., 2008)</td>
<td>0.979</td>
<td>0.990</td>
<td>0.988</td>
<td>0.989</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Isolation Forest (Liu et al., 2008)</td>
<td>0.827</td>
<td>0.995</td>
<td>0.822</td>
<td>0.900</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">HBOS (Goldstein and Dengel, 2012)</td>
<td>0.919</td>
<td>0.958</td>
<td>0.956</td>
<td>0.957</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SOS (Janssens et al., 2012)</td>
<td>0.912</td>
<td>0.955</td>
<td>0.953</td>
<td>0.954</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SO-GAAL (Liu et al., 2019)</td>
<td>0.952</td>
<td>0.952</td>
<td>1.000</td>
<td>0.975</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MO-GAAL (Liu et al., 2019)</td>
<td>0.952</td>
<td>0.952</td>
<td>1.000</td>
<td>0.975</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">LSCP (Zhao et al., 2019)</td>
<td>0.978</td>
<td>0.990</td>
<td>0.987</td>
<td>0.989</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Bunny 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.913</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.990</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.884</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.958</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.989</td>
</tr>
</tbody>
</table>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="seoyeonc/blog" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>
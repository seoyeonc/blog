[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ":)",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2099\n\n\nITSTGCN add Model\n\n\nSEOYEON CHOI\n\n\n\n\nJul 20, 2023\n\n\nData management Figure for ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nJul 20, 2023\n\n\nLLM\n\n\nSEOYEON CHOI\n\n\n\n\nJul 18, 2023\n\n\nSelf Consistency Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nJul 18, 2023\n\n\nEbayesThresh Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nJul 10, 2023\n\n\nFraud data\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nToy example using GNAR\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nToy example using GNAR\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nStock on Graph\n\n\nSEOYEON CHOI\n\n\n\n\nJul 7, 2023\n\n\nStock Crawling\n\n\nSEOYEON CHOI\n\n\n\n\nJul 7, 2023\n\n\nPyG lesson2: 벤치마크 데이터셋 (train/test분리)\n\n\n신록예찬\n\n\n\n\nJul 5, 2023\n\n\nData management for ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nJul 5, 2023\n\n\nRESEARCHES\n\n\nSEOYEON CHOI\n\n\n\n\nJul 4, 2023\n\n\nToy Example Figure(Intro)\n\n\nSEOYEON CHOI\n\n\n\n\nJul 3, 2023\n\n\nOther Outlier Detection\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nEvolveGCNH_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJul 1, 2023\n\n\nEvolveGCNH_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 28, 2023\n\n\nDYGRENCODER_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 28, 2023\n\n\nDYGRENCODER_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 27, 2023\n\n\nLinear Graph code for Paper\n\n\nSEOYEON CHOI\n\n\n\n\nJun 25, 2023\n\n\nEvolveGCNO_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 25, 2023\n\n\nEvolveGCNO_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 22, 2023\n\n\nComparison Results on Real Data\n\n\nSEOYEON CHOI\n\n\n\n\nJun 20, 2023\n\n\nTGCN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 20, 2023\n\n\nTGCN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 13, 2023\n\n\nDCRNN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 13, 2023\n\n\nLRGCN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 13, 2023\n\n\nLRGCN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 13, 2023\n\n\nDCRNN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 6, 2023\n\n\nGCLSTM_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 6, 2023\n\n\nGCLSTM_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 30, 2023\n\n\nGConvLSTM_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 30, 2023\n\n\nGConvLSTM_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 27, 2023\n\n\nAdding the RecurrentGCN models\n\n\nSEOYEON CHOI\n\n\n\n\nMay 25, 2023\n\n\nGConvGRU_Simulation Boxplot_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 25, 2023\n\n\nGConvGRU_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 17, 2023\n\n\nGConvGRU and GNAR_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 11, 2023\n\n\nPyG Geometric Temporal CPU vs GPU\n\n\nSEOYEON CHOI\n\n\n\n\nMay 11, 2023\n\n\nPyG Geometric Temporal Examples\n\n\nSEOYEON CHOI\n\n\n\n\nMay 6, 2023\n\n\nITSTGCN Article Refernece\n\n\nSEOYEON CHOI\n\n\n\n\nMay 4, 2023\n\n\nQuestions of PyTorch Geometric Temporal\n\n\nSEOYEON CHOI\n\n\n\n\nApr 29, 2023\n\n\nPadalme GSO_st\n\n\nSEOYEON CHOI\n\n\n\n\n\nApr 27, 2023\n\n\nSimulation Tables\n\n\nSEOYEON CHOI\n\n\n\n\nApr 27, 2023\n\n\nToy Example Note\n\n\nGUEBIN CHOI\n\n\n\n\nApr 25, 2023\n\n\nNote_weight amatrix\n\n\nGUEBIN CHOI\n\n\n\n\nApr 6, 2023\n\n\nMETRLADatasetLoader-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nMar 22, 2023\n\n\nSimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 20, 2023\n\n\ndata load, data save as pickle\n\n\nSEOYEON CHOI\n\n\n\n\nMar 18, 2023\n\n\nSimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\nITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 3, 2023\n\n\nSY 1st ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 15, 2023\n\n\n2nd ITSTGCN\n\n\nGUEBIN CHOI\n\n\n\n\nFeb 15, 2023\n\n\n1st ITSTGCN\n\n\nGUEBIN CHOI\n\n\n\n\nFeb 7, 2023\n\n\nClass of Method(WikiMath) lag 1\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 6, 2023\n\n\nClass of Method(GNAR) lag 1 80% Missing repeat\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 6, 2023\n\n\nClass of Method(GNAR) lag 2\n\n\nSEOYEON CHOI\n\n\n\n\nJan 28, 2023\n\n\nClass of Method(GNAR) lag 1\n\n\nSEOYEON CHOI\n\n\n\n\nJan 28, 2023\n\n\nClass of Method(WikiMath) lag 4\n\n\nSEOYEON CHOI\n\n\n\n\nJan 26, 2023\n\n\nClass of Method\n\n\nGuebin Choi\n\n\n\n\nJan 21, 2023\n\n\nClass of Method\n\n\nSEOYEON CHOI\n\n\n\n\nJan 20, 2023\n\n\n1st ST-GCN Example dividing train and test\n\n\nSEOYEON CHOI\n\n\n\n\nJan 17, 2023\n\n\n2nd ST-GCN Example dividing train and test\n\n\nSEOYEON CHOI\n\n\n\n\nJan 11, 2023\n\n\nGCN Algorithm Example 1\n\n\nSEOYEON CHOI\n\n\n\n\nJan 5, 2023\n\n\nGNAR data\n\n\nSEOYEON CHOI\n\n\n\n\nDec 29, 2022\n\n\n[IT-STGCN] STGCN 튜토리얼\n\n\n신록예찬, SEOYEON CHOI\n\n\n\n\nDec 28, 2022\n\n\nSimulation of geometric-temporal\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2022\n\n\nDiscrete Fourier Transform\n\n\nSEOYEON CHOI\n\n\n\n\nDec 21, 2022\n\n\nPyTorch ST-GCN Dataset\n\n\nSEOYEON CHOI\n\n\n\n\nDec 5, 2022\n\n\nGCN\n\n\nSEOYEON CHOI\n\n\n\n\nDec 5, 2022\n\n\nTORCH_GEOMETRIC.NN\n\n\nSEOYEON CHOI\n\n\n\n\nDec 1, 2022\n\n\nGraph code\n\n\nSEOYEON CHOI\n\n\n\n\nNov 24, 2022\n\n\nClass code for Comparison Study\n\n\nSEOYEON CHOI\n\n\n\n\nNov 24, 2022\n\n\nEarthquake\n\n\nSEOYEON CHOI\n\n\n\n\nSep 2, 2022\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nSep 1, 2022\n\n\nGODE\n\n\nSEOYEON CHOI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/GCN/2023-07-18-Self Consistency toy ex.html",
    "href": "posts/GCN/2023-07-18-Self Consistency toy ex.html",
    "title": "Self Consistency Toy ex",
    "section": "",
    "text": "Self Consistency\nRef: Self Consistency: A General Recipe for Wavelet Estimation With Irregularly-spaced and/or Incomplete Data\n\\[\\mathbb{E}(\\hat{f}_{com} | f = \\hat{f}_{obs}) = \\hat{f}_{obs}\\]"
  },
  {
    "objectID": "posts/GCN/2023-07-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "href": "posts/GCN/2023-07-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "title": "Self Consistency Toy ex",
    "section": "2 Self Consistency: How Does It Work?",
    "text": "2 Self Consistency: How Does It Work?\n\n2.1 Self-consistency: An Intuitive Principle\n책에서의 가정\n\n\\(x = 0,1,2,3,\\dots,16\\)으로 fixed 되어 있음.\n\\(y_0,\\dots, y_{13}\\)까지의 값을 알고 있는데 \\(y_{14},y_{15},y_{16}\\)의 값은 모른다.\n\n\\(y_i=\\beta x_i + \\epsilon_i, i=1,\\dots,n, \\epsilon_i \\sim \\text{i.i.d.}F(0,\\sigma^2)\\)\n\n\\(\\beta\\)의 최소제곱추정치\n\n\\(\\hat{\\beta}_n = \\hat{\\beta}_n(y_1 ,\\dots,y_n) = \\frac{\\sum^n_{i=1} y_i x_i}{\\sum^n_{i=1} x_i^2}\\)\n\n단, \\(m<n\\) 이고, \\(\\sum ^n_{m+1} x_i^2 > 0\\) 일 때,\n\n\\(E(\\hat{\\beta}_n|y_a, \\dots,y_m,;\\beta = \\hat{\\beta}_m) = \\hat{\\beta}_m\\)\nthe least-squares estimator has a (Martingale-like property)1, and reaches a perfect equilibrium in its projective properties1 확률 과정 중 과거의 정보를 알고 있다면 미래의 기댓값이 현재값과 동일한 과정\n참고;(위키백과)[https://ko.wikipedia.org/wiki/%EB%A7%88%ED%8C%85%EA%B2%8C%EC%9D%BC]\n\n\\(\\beta_n\\)을 구한다.\n\\(\\beta_n \\times x\\) 를 구한다.\nmissing 값이 있는 index만 대체한다.\n다시 \\(\\beta_n\\)을 구한다.\n.. 반복\n\n\\(\\beta\\)의 선형성 때문에 가능한 이론\n아래 계산하면 맞아야 함\n\\(\\hat{\\beta}_n = \\frac{\\sum_{i=1}^m y_i x_i + \\hat{\\beta}_m \\sum_{i=m+1}^n x_i^2}{\\sum_{i=1}^n x_i^2}\\)\n\n\n2.2 A Self–consistent Regression Estimator\n목적은 최적의 \\(\\hat{f}_{com}\\) 찾는 것, 일단 이 paper는 웨이블릿에 중점을 두고 비모수, 준모수 회귀로 확장 가능 누적 분포 함수 CDF 찾는 것이 목적"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html",
    "title": "PyTorch ST-GCN Dataset",
    "section": "",
    "text": "PyTorch Geometric Temporal Dataset\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\n논문\n|Dataset|Signal|Graph|Frequency|𝑇|ㅣ𝑉ㅣ | |:–:|:–:||:–:||:–:| |Chickenpox Hungary|Temporal|Static|Weekly|522|20| |Windmill Large|Temporal|Static|Hourly|17,472|319| |Windmill Medium|Temporal|Static|Hourly|17,472|26| |Windmill Small|Temporal|Static|Hourly|17,472|11| |Pedal Me Deliveries|Temporal|Static|Weekly|36|15| |Wikipedia Math|Temporal|Static|Daily|731|1,068| |Twitter Tennis RG|Static|Dynamic|Hourly|120|1000| |Twitter Tennis UO|Static|Dynamic|Hourly|112|1000| |Covid19 England|Temporal|Dynamic|Daily|61|129| |Montevideo Buses|Temporal|Static|Hourly|744|675| |MTM-1 Hand Motions|Temporal|Static|1/24 Seconds|14,469|21|"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#chickenpoxdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#chickenpoxdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "ChickenpoxDatasetLoader",
    "text": "ChickenpoxDatasetLoader\nChickenpox Hungary\n\nA spatiotemporal dataset about the officially reported cases of chickenpox in Hungary. The nodes are counties and edges describe direct neighbourhood relationships. The dataset covers the weeks between 2005 and 2015 without missingness.\n\n데이터정리\n\nT = 519\nN = 20 # number of nodes\nE = 102 # edges\n\\(f(v,t)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n519\n\n\n\n(data[0][1]).x.type,(data[0][1]).edge_index.type,(data[0][1]).edge_attr.type,(data[0][1]).y.type\n\n(<function Tensor.type>,\n <function Tensor.type>,\n <function Tensor.type>,\n <function Tensor.type>)\n\n\n\nmax((data[4][1]).x[0])\n\ntensor(2.1339)\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(20)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[519, Data(x=[20, 1], edge_index=[2, 102], edge_attr=[102], y=[20])]\n\n\n\nlen(data[0][1].edge_index[0])\n\n102\n\n\n\nedge_list=[]\nfor i in range(519):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(20, 61)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  ChickenpoxDatasetLoader\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.0011,  0.0286,  0.3547,  0.2954]), tensor(0.7106))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0]\n\ntensor([0.0286, 0.3547, 0.2954, 0.7106])\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0]\n\ntensor([ 0.3547,  0.2954,  0.7106, -0.6831])\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 20개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{20}\\}, t=1,2,\\dots,519\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([20, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 102])\n\n\n\n_edge_attr.shape\n\ntorch.Size([102])\n\n\n\n_y.shape\n\ntorch.Size([20])\n\n\n\n_x.shape\n\ntorch.Size([20, 4])\n\n\nx\n\nVertex features are lagged weekly counts of the chickenpox cases (we included 4 lags). y\nThe target is the weekly number of cases for the upcoming week\n\n\n_x\n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n_y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pedalmedatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pedalmedatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "PedalMeDatasetLoader",
    "text": "PedalMeDatasetLoader\nPedal Me Deliveries\n\nA dataset about the number of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.\n\n데이터정리\n\nT = 33\nV = 지역의 집합\nN = 15 # number of nodes\nE = 225 # edges\n\\(f(v,t)\\)의 차원? (1,) # number of deliveries\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (15,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (15,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 15\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  PedalMeDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = PedalMeDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n33\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([15, 1]), torch.Size([2, 225]), torch.Size([225]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(15)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[33, Data(x=[15, 1], edge_index=[2, 225], edge_attr=[225], y=[15])]\n\n\n\nedge_list=[]\nfor i in range(33):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(15, 120)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  PedalMeDatasetLoader\nloader = PedalMeDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([ 3.0574, -0.0477, -0.3076,  0.2437]), tensor(-0.2710))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0], (data[1][1]).y[0]\n\n(tensor([-0.0477, -0.3076,  0.2437, -0.2710]), tensor(0.2490))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0], (data[2][1]).y[0]\n\n(tensor([-0.3076,  0.2437, -0.2710,  0.2490]), tensor(-0.0357))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 15개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{15}\\}, t=1,2,\\dots,33\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:03<00:00, 16.04it/s]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([15, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 225])\n\n\n\n_edge_attr.shape\n\ntorch.Size([225])\n\n\n\n_y.shape\n\ntorch.Size([15])\n\n\n\n_x.shape\n\ntorch.Size([15, 4])\n\n\nx\n\nVertex features are lagged weekly counts of the delivery demands (we included 4 lags).\n주마다 배달 수요의 수가 얼마나 될지 percentage로, t-4시점까지?\n\ny\n\nThe target is the weekly number of deliveries the upcoming week. Our dataset consist of more than 30 snapshots (weeks).\n그 다음주에 배달의 수가 몇 퍼센트로 발생할지?\n\n\n_x[0:3]\n\ntensor([[ 3.0574, -0.0477, -0.3076,  0.2437],\n        [ 3.2126,  0.1240,  0.0764,  0.5582],\n        [ 1.9071, -0.8883,  1.5280, -0.7184]])\n\n\n\n_y\n\ntensor([-0.2710,  0.0888,  0.4733,  0.0907, -0.3129,  0.1184,  0.5886, -0.6571,\n         0.2647,  0.2338,  0.1720,  0.5720, -0.9568, -0.4138, -0.5271])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#wikimathsdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#wikimathsdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WikiMathsDatasetLoader",
    "text": "WikiMathsDatasetLoader\nWikipedia Math\n\nContains Wikipedia pages about popular mathematics topics and edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.\n\n데이터정리\n\nT = 722\nV = 위키피디아 페이지\nN = 1068 # number of nodes\nE = 27079 # edges\n\\(f(v,t)\\)의 차원? (1,) # 해당페이지를 유저가 방문한 횟수\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (1068,8) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3),f(v,t_4),f(v,t_5),f(v,t_6),f(v,t_7)\\)\ny: (1068,) (N,), \\(f(v,t_8)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 1068\n\nvertices are Wikipedia pages\n\n-Edges : 27079\n\nedges are links between them\n\n- Time : 722\n\nWikipedia pages between March 16th 2019 and March 15th 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n722\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([1068, 8]), torch.Size([2, 27079]), torch.Size([27079]))\n\n\n\n(data[10][1]).x\n\ntensor([[ 0.4972,  0.6838,  0.7211,  ..., -0.8513,  0.1881,  1.3820],\n        [ 0.5457,  0.6016,  0.7071,  ..., -0.4599, -0.6089, -0.0626],\n        [ 0.6305,  1.1404,  0.8779,  ..., -0.5370,  0.7422,  0.3862],\n        ...,\n        [ 0.8699,  0.5451,  1.9254,  ..., -0.8351,  0.3828,  0.3828],\n        [ 0.2451,  0.9629,  1.0526,  ..., -0.9213,  0.8731, -0.1138],\n        [ 0.0200, -0.0871,  0.2342,  ..., -0.4712,  0.0717,  0.2859]])\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(1068)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(722):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(1068, 27079)\n\n\n\nnx.draw(G,node_color='green',node_size=100,width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nnp.where(data[11][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nnp.where(data[11][1].edge_index != data[20][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nhttps://www.kaggle.com/code/mapologo/loading-wikipedia-math-essentials\n\nfrom torch_geometric_temporal.dataset import  WikiMathsDatasetLoader\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=8)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.4323, -0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617]),\n tensor(-0.4067))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3,,x_4,x_5,x_6,x_7\\)\ny:= \\(x_9\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617, -0.4067]),\n tensor(0.3064))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8\\)\ny:= \\(x_9\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617, -0.4067,  0.3064]),\n tensor(0.4972))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9\\)\ny:=\\(x_{10}\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 1068개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7) \\to (x_8)\\)\n\\((x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8) \\to (x_9)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{1068}\\}, t=1,2,\\dots,722\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=8, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [09:28<00:00, 11.37s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 8])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n어떤 페이지에 refer가 되었는지\n\n_edge_index[0][:5],_edge_index[1][:5]\n\n(tensor([0, 0, 0, 0, 0]), tensor([1, 2, 3, 4, 5]))\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_edge_attr[:5]\n\ntensor([1., 4., 2., 2., 5.])\n\n\n\nWeights represent the number of links found at the source Wikipedia page linking to the target Wikipedia page.\n\n가중치는 엣지별 한 페이지에 refer되었는지, 몇 번 되었나 수 나옴\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n_x.shape\n\ntorch.Size([1068, 8])\n\n\nx\n\nlag 를 몇으로 지정하느냐에 따라 다르게 추출\n\ny\n\nThe target is the daily user visits to the Wikipedia pages between March 16th 2019 and March 15th 2021 which results in 731 periods.\n매일 위키피디아 해당 페이지에 몇 명의 유저가 방문하는지!\n음수가 왜 나오지..\n\n\n_x[0:3]\n\ntensor([[-0.4323, -0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617],\n        [-0.4041, -0.4165, -0.0751,  0.1484,  0.4153,  0.4464, -0.3916, -0.8137],\n        [-0.3892,  0.0634,  0.5913,  0.5370,  0.4646,  0.2776, -0.0724, -0.8116]])\n\n\n\n_y[:3]\n\ntensor([-0.4067, -0.1620, -0.4043])\n\n\n\ny_hat[:3].data\n\ntensor([[-0.0648],\n        [ 0.0314],\n        [-1.0724]])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputlargedatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputlargedatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputLargeDatasetLoader",
    "text": "WindmillOutputLargeDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 319 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n데이터정리\n\nT = 17470\nV = 풍력발전소\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 319\n\nvertices represent 319 windmills\n\n-Edges : 101761\n\nweighted edges describe the strength of relationships.\n\n- Time : 17470\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputLargeDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputLargeDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17470\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([319, 1]), torch.Size([2, 101761]), torch.Size([101761]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(319)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[17470, Data(x=[319, 1], edge_index=[2, 101761], edge_attr=[101761], y=[319])]\n\n\ntime이 너무 많아서 일부만 시각화함!!\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(319, 51040)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputLargeDatasetLoader\nloader = WindmillOutputLargeDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.5711, -0.7560,  2.6278, -0.8674]), tensor(-0.9877))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0], (data[1][1]).y[0]\n\n(tensor([-0.7560,  2.6278, -0.8674, -0.9877]), tensor(-0.8583))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 2.6278, -0.8674, -0.9877, -0.8583]), tensor(0.4282))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 319개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{319}\\}, t=1,2,\\dots,17470\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 5/5 [1:06:03<00:00, 792.70s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([319, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 101761])\n\n\n\n_edge_attr.shape\n\ntorch.Size([101761])\n\n\n\n_y.shape\n\ntorch.Size([319])\n\n\n\n_x.shape\n\ntorch.Size([319, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[-0.5711, -0.7560,  2.6278, -0.8674],\n        [-0.6936, -0.7264,  2.4113, -0.6052],\n        [-0.8666, -0.7785,  2.2759, -0.6759]])\n\n\n\n_y[0]\n\ntensor(-0.9877)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputmediumdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputmediumdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputMediumDatasetLoader",
    "text": "WindmillOutputMediumDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 26 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n데이터정리\n\nT = 17470\nV = 풍력발전소\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 26\n\nvertices represent 26 windmills\n\n-Edges : 225\n\nweighted edges describe the strength of relationships\n\n- Time : 676\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputMediumDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputMediumDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17470\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([26, 1]), torch.Size([2, 676]), torch.Size([676]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(26)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[17470, Data(x=[26, 1], edge_index=[2, 676], edge_attr=[676], y=[26])]\n\n\n\nedge_list=[]\nfor i in range(17463):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(26, 351)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputMediumDatasetLoader\nloader = WindmillOutputMediumDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.2170, -0.2055, -0.1587, -0.1930]), tensor(-0.2149))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.2055, -0.1587, -0.1930, -0.2149]), tensor(-0.2336))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-0.1587, -0.1930, -0.2149, -0.2336]), tensor(-0.1785))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 26개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{26}\\}, t=1,2,\\dots,177470\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 5/5 [03:23<00:00, 40.73s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([26, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 676])\n\n\n\n_edge_attr.shape\n\ntorch.Size([676])\n\n\n\n_y.shape\n\ntorch.Size([26])\n\n\n\n_x.shape\n\ntorch.Size([26, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[-0.2170, -0.2055, -0.1587, -0.1930],\n        [-0.1682, -0.2708, -0.1051,  1.1786],\n        [ 1.1540, -0.6707, -0.8291, -0.6823]])\n\n\n\n_y[0]\n\ntensor(-0.2149)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputsmalldatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputsmalldatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputSmallDatasetLoader",
    "text": "WindmillOutputSmallDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 11 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n데이터정리\n\nT = 17470\nV = 풍력발전소\nN = 11 # number of nodes\nE = 121 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (11,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (11,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 11\n\nvertices represent 11 windmills\n\n-Edges : 121\n\nweighted edges describe the strength of relationships\n\n- Time : 17470\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputSmallDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17463\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([11, 8]), torch.Size([2, 121]), torch.Size([121]))\n\n\n\ndata[-1]\n\n[17463, Data(x=[11, 8], edge_index=[2, 121], edge_attr=[121], y=[11])]\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(11)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(17463):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(11, 66)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader = WindmillOutputSmallDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([ 0.8199, -0.4972,  0.4923, -0.8299]), tensor(-0.6885))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4972,  0.4923, -0.8299, -0.6885]), tensor(0.7092))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 0.4923, -0.8299, -0.6885,  0.7092]), tensor(-0.9356))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 11개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{11}\\}, t=1,2,\\dots,17463\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 5/5 [02:55<00:00, 35.01s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([11, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 121])\n\n\n\n_edge_attr.shape\n\ntorch.Size([121])\n\n\n\n_y.shape\n\ntorch.Size([11])\n\n\n\n_x.shape\n\ntorch.Size([11, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[ 0.8199, -0.4972,  0.4923, -0.8299],\n        [ 1.1377, -0.3742,  0.3668, -0.8333],\n        [ 0.9979, -0.5643,  0.4070, -0.8918]])\n\n\n\n_y\n\ntensor([-0.6885, -0.6594, -0.6303, -0.6983, -0.5416, -0.6186, -0.6031, -0.7580,\n        -0.6659, -0.5948, -0.5088])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#metrladatasetloader_real-world-traffic-dataset",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#metrladatasetloader_real-world-traffic-dataset",
    "title": "PyTorch ST-GCN Dataset",
    "section": "METRLADatasetLoader_real world traffic dataset",
    "text": "METRLADatasetLoader_real world traffic dataset\nA traffic forecasting dataset based on Los Angeles Metropolitan traffic conditions. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County in aggregated 5 minute intervals for 4 months between March 2012 to June 2012.\n데이터정리\n\nT = 33\nV = 구역\nN = 207 # number of nodes\nE = 225\n\\(f(v,t)\\)의 차원? (3,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (207,4) (N,2,12), \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny: (207,) (N,), \\((x_{12})\\)\n예제코드적용가능여부: No\n\nhttps://arxiv.org/pdf/1707.01926.pdf\n- Nodes : 207\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = METRLADatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n34248\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([207, 2, 12]), torch.Size([2, 1722]), torch.Size([1722]))\n\n\n\ndata[-1]\n\n[34248,\n Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])]\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(20)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(207, 1520)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n논문 내용 중\n\n\n\nimage.png\n\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nloader = METRLADatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\n\n\n\n\n\nNote\n\n\n\nlags option 없어서 error 뜸 : get_dataset() got an unexpected keyword argument ‘lags’\n\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[ 0.5332,  0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,\n           0.7497,  0.4899,  0.5751,  0.4280],\n         [-1.7292, -1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448,\n          -1.6328, -1.6207, -1.6087, -1.5966]]),\n tensor([0.3724, 0.2452, 0.4961, 0.6521, 0.1126, 0.5311, 0.5091, 0.4713, 0.4218,\n         0.3909, 0.4761, 0.5641]))\n\n\n\\(t=0\\)에서 \\(X,Z\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\nZ:= \\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny:= \\(x_{12}\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[ 0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,  0.7497,\n           0.4899,  0.5751,  0.4280,  0.3724],\n         [-1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448, -1.6328,\n          -1.6207, -1.6087, -1.5966, -1.5846]]),\n tensor([ 0.2452,  0.4961,  0.6521,  0.1126,  0.5311,  0.5091,  0.4713,  0.4218,\n          0.3909,  0.4761,  0.5641, -0.0022]))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12}\\)\nZ:= \\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12}\\)\ny:= \\(x_{13}\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([[ 0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,  0.7497,  0.4899,\n           0.5751,  0.4280,  0.3724,  0.2452],\n         [-1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448, -1.6328, -1.6207,\n          -1.6087, -1.5966, -1.5846, -1.5725]]),\n tensor([ 0.4961,  0.6521,  0.1126,  0.5311,  0.5091,  0.4713,  0.4218,  0.3909,\n          0.4761,  0.5641, -0.0022,  0.4218]))\n\n\n\nX:= \\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},x_{13}\\)\nZ:= \\(z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12},z_{13}\\)\ny:= \\(x_{14}\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 207개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11} \\to (x_{12})\\)\n\\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12} \\to (x_{13})\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{207}\\}, t=1,2,\\dots,34248\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=1, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([207, 2, 12])\n\n\n\nnode 207개, traffic sensor 2개\n\n\n_edge_index.shape\n\ntorch.Size([2, 1722])\n\n\n\n_edge_attr.shape\n\ntorch.Size([1722])\n\n\n\n_y.shape\n\ntorch.Size([207, 12])\n\n\n\n_x.shape\n\ntorch.Size([207, 2, 12])\n\n\ny\n\ntraffic speed\n\n\n_x[0]\n\ntensor([[ 0.5332,  0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,\n          0.7497,  0.4899,  0.5751,  0.4280],\n        [-1.7292, -1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448,\n         -1.6328, -1.6207, -1.6087, -1.5966]])\n\n\n\n_y[0]\n\ntensor([0.3724, 0.2452, 0.4961, 0.6521, 0.1126, 0.5311, 0.5091, 0.4713, 0.4218,\n        0.3909, 0.4761, 0.5641])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pemsbaydatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pemsbaydatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "PemsBayDatasetLoader",
    "text": "PemsBayDatasetLoader\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12644\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nThis traffic dataset is collected by California Transportation Agencies (CalTrans) Performance Measurement System (PeMS). It is represented by a network of 325 traffic sensors in the Bay Area with 6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals.\n데이터정리\n\nT = 17470\nV = 풍력발전소\nN = 325 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (325,2,12) (N,2,12),\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\n\ny: (325,) (N,2,12),\n\n\\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n예제코드적용가능여부: No\n\n- Nodes : 325\n\nvertices are sensors\n\n-Edges : 2694\n\nweighted edges are between seonsor paris measured by the road nretwork distance\n\n- Time : 52081\n\n6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = PemsBayDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n52081\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([325, 2, 12]), torch.Size([2, 2694]), torch.Size([2694]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(325)).tolist()\n\n\ndata[-1]\n\n[52081,\n Data(x=[325, 2, 12], edge_index=[2, 2694], edge_attr=[2694], y=[325, 2, 12])]\n\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(325, 2404)\n\n\n\nnx.draw(G,node_color='green',node_size=50,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nloader = PemsBayDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[ 0.9821,  0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,\n           1.0143,  0.9928,  0.9498,  0.9821],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275,\n          -1.5153, -1.5032, -1.4910, -1.4788]]),\n tensor([[ 1.0143,  0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,\n           0.9928,  0.9928,  0.9498,  0.9928],\n         [-1.4667, -1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815,\n          -1.3694, -1.3572, -1.3450, -1.3329]]))\n\n\n\\(t=0\\)에서 \\(X,Z\\)와 \\(y,s\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\nZ:= \\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny:= \\(x_{12},x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23}\\)\ns:= \\(z_{12},z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23}\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[ 0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,  1.0143,\n           0.9928,  0.9498,  0.9821,  1.0143],\n         [-1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275, -1.5153,\n          -1.5032, -1.4910, -1.4788, -1.4667]]),\n tensor([[ 0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,  0.9928,\n           0.9928,  0.9498,  0.9928,  0.9821],\n         [-1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815, -1.3694,\n          -1.3572, -1.3450, -1.3329, -1.3207]]))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12}\\)\nZ:= \\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12}\\)\ny:= \\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\ns:= \\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([[ 1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,  1.0143,  0.9928,\n           0.9498,  0.9821,  1.0143,  0.9821],\n         [-1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275, -1.5153, -1.5032,\n          -1.4910, -1.4788, -1.4667, -1.4545]]),\n tensor([[ 0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,  0.9928,  0.9928,\n           0.9498,  0.9928,  0.9821,  1.0143],\n         [-1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815, -1.3694, -1.3572,\n          -1.3450, -1.3329, -1.3207, -1.3085]]))\n\n\n\nX:= \\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},x_{13}\\)\nZ:= \\(z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12},z_{13}\\)\ny:= \\(x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24},x_{25}\\)\ns:= \\(z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24},z_{25}\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 325개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11} \\to x_{12},x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11} \\to z_{12},z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23}\\)\n\\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12} \\to x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12} \\to z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{325}\\}, t=1,2,\\dots,52081\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([325, 2, 12])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 2694])\n\n\n\n_edge_attr.shape\n\ntorch.Size([2694])\n\n\n\n_y.shape\n\ntorch.Size([325, 2, 12])\n\n\n\n_x.shape\n\ntorch.Size([325, 2, 12])\n\n\nx\n\n.!\n\ny\n\ncapturing temporal dependencies..?\n\nedges connect sensors\nFor instance, the traffic conditions on one road on Wednesday at 3:00 p.m. are similar to the traffic conditions on Thursday at the same time.\n\n_x[0:3]\n\ntensor([[[ 0.9821,  0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,\n           1.0251,  1.0143,  0.9928,  0.9498,  0.9821],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]],\n\n        [[ 0.6054,  0.5839,  0.6592,  0.6269,  0.6808,  0.6377,  0.6700,\n           0.6054,  0.6162,  0.6162,  0.5839,  0.5947],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]],\n\n        [[ 0.9390,  0.9175,  0.8960,  0.9175,  0.9067,  0.9175,  0.9175,\n           0.8852,  0.9283,  0.8960,  0.9067,  0.8960],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]]])\n\n\n\n_y[0]\n\ntensor([[ 1.0143,  0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,\n          0.9928,  0.9928,  0.9498,  0.9928],\n        [-1.4667, -1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815,\n         -1.3694, -1.3572, -1.3450, -1.3329]])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#englandcoviddatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#englandcoviddatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "EnglandCovidDatasetLoader",
    "text": "EnglandCovidDatasetLoader\nCovid19 England\n\nA dataset about mass mobility between regions in England and the number of confirmed COVID-19 cases from March to May 2020 [38]. Each day contains a different mobility graph and node features corresponding to the number of cases in the previous days. Mobility stems from Facebook Data For Good 1 and cases from gov.uk 2\n\nhttps://arxiv.org/pdf/2009.08388.pdf\n데이터정리\n\nT = 52\nV = 지역\nN = 129 # number of nodes\nE = 2158\n\\(f(v,t)\\)의 차원? (1,) # 코로나확진자수\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 129\n\nvertices are correspond to the number of COVID-19 cases in the region in the past window days.\n\n-Edges : 2158\n\nthe spatial edges capture county-to-county movement at a specific date, and a county is connected to a number of past instances of itself with temporal edges.\n\n- Time : 52\n\nfrom 3 March to 12 of May\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = EnglandCovidDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n52\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([129, 8]), torch.Size([2, 2158]), torch.Size([2158]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(129)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[52, Data(x=[129, 8], edge_index=[2, 1424], edge_attr=[1424], y=[129])]\n\n\n\nlen(data[0][1].edge_index[0])\n\n2158\n\n\n\nedge_list=[]\nfor i in range(52):\n    for j in range(100):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(129, 1230)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[2][1].edge_index !=data[2][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nloader = EnglandCovidDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-1.4697, -1.9283, -1.6990, -1.8137]), tensor(-1.8137))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-1.9283, -1.6990, -1.8137, -1.8137]), tensor(-0.8965))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-1.6990, -1.8137, -1.8137, -0.8965]), tensor(-1.1258))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 129개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{129}\\}, t=1,2,\\dots,52\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:07<00:00,  6.30it/s]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([129, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 2158])\n\n\n\n_edge_attr.shape\n\ntorch.Size([2158])\n\n\n\n_y.shape\n\ntorch.Size([129])\n\n\n\ny_hat.shape\n\ntorch.Size([129, 1])\n\n\n\n_x.shape\n\ntorch.Size([129, 4])\n\n\nx\n\n\n\ny\n\n\n\nThe node features correspond to the number of COVID-19 cases in the region in the past window days.\nThe task is to predict the number of cases in each node after 1 day\n\n_x[0:3]\n\ntensor([[-1.4697, -1.9283, -1.6990, -1.8137],\n        [-1.2510, -1.1812, -1.3208, -1.1812],\n        [-1.0934, -1.0934, -1.0934, -1.0934]])\n\n\n\n_y[:3]\n\ntensor([-1.8137, -1.3208, -1.0934])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#montevideobusdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#montevideobusdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "MontevideoBusDatasetLoader",
    "text": "MontevideoBusDatasetLoader\nhttps://www.fing.edu.uy/~renzom/msc/uploads/msc-thesis.pdf\nMontevideo Buses\n\nA dataset about the hourly passenger inflow at bus stop level for eleven bus lines from the city of Montevideo. Nodes are bus stops and edges represent connections between the stops; the dataset covers a whole month of traffic patterns.\n\n데이터정리\n\nT = 739\nV = 버스정류장\nN = 675 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # passenger inflow\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\nX: (675,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (675,,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 675\n\nvertices are bus stops\n\n-Edges : 690\n\nedges are links between bus stops when a bus line connects them and the weight represent the road distance\n\n- Time : 739\n\nhourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay).\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = MontevideoBusDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n739\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([675, 4]), torch.Size([2, 690]), torch.Size([690]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(675)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(739):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(675, 690)\n\n\n\nnx.draw(G,node_color='green',node_size=50,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader = MontevideoBusDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\\(t=0\\)에서 \\(X\\)와 \\(y\\)를 정리하면 아래와 같음.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\n하나의 노드에 길이가 \\(T\\)인 시계열이 맵핑되어 있음. (노드는 총 675개)\n각 노드마다 아래와 같은 과정으로 예측이 됨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{675}\\}, t=1,2,\\dots,739\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:51<00:00,  2.23s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([675, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 690])\n\n\n\n_edge_attr.shape\n\ntorch.Size([690])\n\n\n\n_y.shape\n\ntorch.Size([675])\n\n\n\n_x.shape\n\ntorch.Size([675, 4])\n\n\nx\n\n\n\ny\n\nThe target is the passenger inflow.\nThis is a curated dataset made from different data sources of the Metropolitan Transportation System (STM) of Montevide\n\n\n_x[0:3]\n\ntensor([[-0.4200, -0.4200, -0.4200, -0.4200],\n        [-0.0367, -0.0367, -0.0367, -0.0367],\n        [-0.2655, -0.2655, -0.2655, -0.2655]])\n\n\n\n_y[:3]\n\ntensor([-0.4200, -0.0367, -0.2655])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#twittertennisdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#twittertennisdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "TwitterTennisDatasetLoader",
    "text": "TwitterTennisDatasetLoader\nhttps://appliednetsci.springeropen.com/articles/10.1007/s41109-018-0080-5?ref=https://githubhelp.com\nTwitter Tennis RG and UO\n\nTwitter mention graphs of major tennis tournaments from 2017. Each snapshot contains the graph of popular player or sport news accounts and mentions between them [5, 6]. Node labels encode the number of mentions received and vertex features are structural properties\n\n데이터정리\n\nT = 52081\nV = 트위터계정\n\nN = 1000 # number of nodes\nE = 119 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # passenger inflow\n시간에 따라서 N이 변하는지? ??\n시간에 따라서 E가 변하는지? True\nX: ?\ny: ?\n예제코드적용가능여부: No\n\n- Nodes : 1000\n\nvertices are Twitter accounts\n\n-Edges : 119\n\nedges are mentions between them\n\n- Time : 52081\n\nTwitter mention graphs related to major tennis tournaments from 2017\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = TwitterTennisDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n119\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([1000, 16]), torch.Size([2, 89]), torch.Size([89]))\n\n\n\ndata[0][1].x[0]\n\ntensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\ndata[0][1].edge_index[0]\n\ntensor([ 42, 909, 909, 909, 233, 233, 450, 256, 256, 256, 256, 256, 434, 434,\n        434, 233, 233, 233, 233, 233, 233, 233,   9,   9, 355,  84,  84,  84,\n         84, 140, 140, 140, 140,   0, 140, 238, 238, 238, 649, 875, 875, 234,\n         73,  73, 341, 341, 341, 341, 341, 417, 293, 991,  74, 581, 282, 162,\n        144, 383, 383, 135, 135, 910, 910, 910, 910, 910,  87,  87,  87,  87,\n          9,   9, 934, 934, 162, 225,  42, 911, 911, 911, 911, 911, 911, 911,\n        911, 498, 498,  64, 435])\n\n\n\ndata[0][1].edge_attr\n\ntensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 3., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 3.])\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(1000)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(119):\n    for j in range(40):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(1000, 2819)\n\n\n\nnx.draw(G,node_color='green',node_size=50,width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nlen(data[2][1].edge_index[0])\n\n67\n\n\n\nlen(data[0][1].edge_index[0])\n\n89\n\n\n다름..\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nloader = TwitterTennisDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(4.8363))\n\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(4.9200))\n\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(6.5539))\n\n\n\n(data[3][1]).x[0],(data[3][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(6.9651))\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1000, 16])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 89])\n\n\n\n_edge_attr.shape\n\ntorch.Size([89])\n\n\n\n_y.shape\n\ntorch.Size([1000])\n\n\n\n_x.shape\n\ntorch.Size([1000, 16])\n\n\nx\n\n\n\ny\n\n\n\n\n_x[0:3]\n\ntensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n_y[0]\n\ntensor(4.8363)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#mtmdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#mtmdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "MTMDatasetLoader",
    "text": "MTMDatasetLoader\nMTM-1 Hand Motions\n\nA temporal dataset of MethodsTime Measurement-1 [36] motions, signalled as consecutive graph frames of 21 3D hand key points that were acquired via MediaPipe Hands [64] from original RGB-Video material. Node features encode the normalized xyz-coordinates of each finger joint and the vertices are connected according to the human hand structure.\n\n데이터정리\n\nT = 14452\nV = 손의 shape에 대응하는 dot\n\nN = 325 # number of nodes\nE = 19 = N^2 # edges\n\\(f(v,t)\\)의 차원? (Grasp, Release, Move, Reach, Poision, -1)\n시간에 따라서 N이 변하는지? ??\n시간에 따라서 E가 변하는지? ??\nX: ?\ny: ?\n예제코드적용가능여부: No\n\n- Nodes : 325\n\nvertices are are the finger joints of the human hand\n\n-Edges : 19\n\nedges are the bones connecting them\n\n- Time : 14452\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = MTMDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n14452\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([3, 21, 16]), torch.Size([2, 19]), torch.Size([19]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(21)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(14452):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(21, 19)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntime별 같은 edge 정보를 가지고 있나 확인\n\nnp.where(data[0][1].edge_index != data[12][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nloader = MTMDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n tensor([0., 0., 1., 0., 0., 0.]))\n\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n tensor([0., 0., 1., 0., 0., 0.]))\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([3, 21, 16])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 19])\n\n\n\n_edge_attr.shape\n\ntorch.Size([19])\n\n\n\n_y.shape\n\ntorch.Size([16, 6])\n\n\n\n_x.shape\n\ntorch.Size([3, 21, 16])\n\n\nx\n\nThe data x is returned in shape (3, 21, T),\n\ny\n\nThe targets are manually labeled for each frame, according to one of the five MTM-1 motions (classes ): Grasp, Release, Move, Reach, Position plus a negative class for frames without graph signals (no hand present).\nthe target is returned one-hot-encoded in shape (T, 6).\n\n\n_x[0]\n\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n_y[0]\n\ntensor([0., 0., 1., 0., 0., 0.])"
  },
  {
    "objectID": "posts/GCN/index.html",
    "href": "posts/GCN/index.html",
    "title": "GCN",
    "section": "",
    "text": "About GCN Study"
  },
  {
    "objectID": "posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html",
    "href": "posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html",
    "title": "Adding the RecurrentGCN models",
    "section": "",
    "text": "RecurrentGCN\n\n\nImport\n\nimport itstgcntry\nimport torch\nimport itstgcntry.planner \n\nTry\n\nimport pandas as pd\n\n\npd.read_csv('./simulation_results/2023-05-29_11-18-32.csv').groupby(['RecurrentGCN','method','mrate'])['mse'].mean().reset_index()\n\n\n\n\n\n  \n    \n      \n      RecurrentGCN\n      method\n      mrate\n      mse\n    \n  \n  \n    \n      0\n      DCRNN\n      IT-STGCN\n      0.8\n      1.517346\n    \n    \n      1\n      DCRNN\n      STGCN\n      0.8\n      1.521906\n    \n    \n      2\n      EvolveGCNH\n      IT-STGCN\n      0.8\n      1.338225\n    \n    \n      3\n      EvolveGCNH\n      STGCN\n      0.8\n      1.337022\n    \n    \n      4\n      EvolveGCNO\n      IT-STGCN\n      0.8\n      1.370455\n    \n    \n      5\n      EvolveGCNO\n      STGCN\n      0.8\n      1.326990\n    \n    \n      6\n      GCLSTM\n      IT-STGCN\n      0.8\n      1.529536\n    \n    \n      7\n      GCLSTM\n      STGCN\n      0.8\n      1.600452\n    \n    \n      8\n      GConvGRU\n      IT-STGCN\n      0.8\n      1.567661\n    \n    \n      9\n      GConvGRU\n      STGCN\n      0.8\n      1.654162\n    \n    \n      10\n      GConvLSTM\n      IT-STGCN\n      0.8\n      1.494284\n    \n    \n      11\n      GConvLSTM\n      STGCN\n      0.8\n      1.633645\n    \n    \n      12\n      LRGCN\n      IT-STGCN\n      0.8\n      1.512042\n    \n    \n      13\n      LRGCN\n      STGCN\n      0.8\n      1.604186\n    \n    \n      14\n      MPNNLSTM\n      IT-STGCN\n      0.8\n      1.386678\n    \n    \n      15\n      MPNNLSTM\n      STGCN\n      0.8\n      1.351526\n    \n    \n      16\n      TGCN\n      IT-STGCN\n      0.8\n      1.279269\n    \n    \n      17\n      TGCN\n      STGCN\n      0.8\n      1.278411\n    \n  \n\n\n\n\n\npd.read_csv('./simulation_results/2023-05-29_12-31-06.csv').groupby(['RecurrentGCN','method','mrate'])['mse'].mean().reset_index()\n\n\n\n\n\n  \n    \n      \n      RecurrentGCN\n      method\n      mrate\n      mse\n    \n  \n  \n    \n      0\n      DCRNN\n      IT-STGCN\n      0.6\n      1.457874\n    \n    \n      1\n      DCRNN\n      STGCN\n      0.6\n      1.523312\n    \n    \n      2\n      EvolveGCNH\n      IT-STGCN\n      0.6\n      1.265695\n    \n    \n      3\n      EvolveGCNH\n      STGCN\n      0.6\n      1.290008\n    \n    \n      4\n      EvolveGCNO\n      IT-STGCN\n      0.6\n      1.288295\n    \n    \n      5\n      EvolveGCNO\n      STGCN\n      0.6\n      1.308886\n    \n    \n      6\n      GCLSTM\n      IT-STGCN\n      0.6\n      1.304539\n    \n    \n      7\n      GCLSTM\n      STGCN\n      0.6\n      1.537681\n    \n    \n      8\n      GConvGRU\n      IT-STGCN\n      0.6\n      1.402607\n    \n    \n      9\n      GConvGRU\n      STGCN\n      0.6\n      1.582745\n    \n    \n      10\n      GConvLSTM\n      IT-STGCN\n      0.6\n      1.299263\n    \n    \n      11\n      GConvLSTM\n      STGCN\n      0.6\n      1.534498\n    \n    \n      12\n      LRGCN\n      IT-STGCN\n      0.6\n      1.295239\n    \n    \n      13\n      LRGCN\n      STGCN\n      0.6\n      1.527917\n    \n    \n      14\n      MPNNLSTM\n      IT-STGCN\n      0.6\n      1.287649\n    \n    \n      15\n      MPNNLSTM\n      STGCN\n      0.6\n      1.307589\n    \n    \n      16\n      TGCN\n      IT-STGCN\n      0.6\n      1.276318\n    \n    \n      17\n      TGCN\n      STGCN\n      0.6\n      1.262256\n    \n  \n\n\n\n\n\n\nGConvGRU\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcntry/utils.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GConvGRU_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr.learn(model,epoch=5)\n\n5/5\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GConvGRU_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr1.learn(model1,epoch=5)\n\n5/5\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nDCRNN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.DCRNN_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.DCRNN_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nEvolveGCNH\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.EvolveGCNH_RecurrentGCN(train_dataset_padded)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.EvolveGCNH_RecurrentGCN(train_dataset_padded)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nEvolveGCNO\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.EvolveGCNO_RecurrentGCN(train_dataset_padded)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.EvolveGCNO_RecurrentGCN(train_dataset_padded)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nGCLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GCLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GCLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nGConvLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GConvLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GConvLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nLRGCN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.LRGCN_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.LRGCN_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nMPNNLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.MPNNLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.MPNNLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nTGCN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.TGCN_RecurrentGCN(train_dataset_padded, filters=32)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.TGCN_RecurrentGCN(train_dataset_padded, filters=32)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- 적합값\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html",
    "href": "posts/GCN/2023-01-26-guebin.html",
    "title": "Class of Method",
    "section": "",
    "text": "Class"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#시나리오1-baseline",
    "href": "posts/GCN/2023-01-26-guebin.html#시나리오1-baseline",
    "title": "Class of Method",
    "section": "시나리오1 (Baseline)",
    "text": "시나리오1 (Baseline)\n시나리오1\n\nmissing rate: 0%\n보간방법: None\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:39<00:00,  2.00s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR 으로 적합 + 예측\n-\n\n\n결과시각화\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}'.format(i,train_mse_eachnode[i],test_mse_eachnode[i]))\n    a.plot(range(1,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test[:,i],label='STCGCN (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n\".format(train_mse_total,test_mse_total),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#시나리오2",
    "href": "posts/GCN/2023-01-26-guebin.html#시나리오2",
    "title": "Class of Method",
    "section": "시나리오2",
    "text": "시나리오2\n시나리오2\n\nmissing rate: 50%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:31<00:00,  1.82s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [01:29<00:00,  1.80s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\n결과시각화\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#시나리오3",
    "href": "posts/GCN/2023-01-26-guebin.html#시나리오3",
    "title": "Class of Method",
    "section": "시나리오3",
    "text": "시나리오3\n시나리오3\n\nmissing rate: 80%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:27<00:00,  1.76s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [01:32<00:00,  1.86s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\n결과시각화\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html",
    "title": "Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='RecurrentGCN',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\n# df1 = pd.read_csv('./simulation_results/2023-04-30_13-00-12.csv')\n# df2 = pd.read_csv('./simulation_results/2023-04-30_13-31-32.csv')\n# df3 = pd.read_csv('./simulation_results/2023-04-30_14-01-49.csv')\n# df4 = pd.read_csv('./simulation_results/2023-04-30_14-31-56.csv')\n# df5 = pd.read_csv('./simulation_results/2023-04-30_15-02-23.csv')\n# df6 = pd.read_csv('./simulation_results/2023-04-30_15-33-03.csv')\n# df7 = pd.read_csv('./simulation_results/2023-04-30_16-07-43.csv')\n# df8 = pd.read_csv('./simulation_results/2023-04-30_16-41-35.csv')\n# df9 = pd.read_csv('./simulation_results/2023-04-30_17-14-51.csv')\n# df10 = pd.read_csv('./simulation_results/2023-04-30_17-49-34.csv')\n# df11 = pd.read_csv('./simulation_results/2023-04-30_18-21-29.csv')\n# df12 = pd.read_csv('./simulation_results/2023-04-30_18-50-24.csv')\n# df13 = pd.read_csv('./simulation_results/2023-04-30_20-33-28.csv')\n# df14 = pd.read_csv('./simulation_results/2023-05-04_16-40-05.csv')\n# df15 = pd.read_csv('./simulation_results/2023-05-04_17-34-00.csv')\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype!='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1000)\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-1",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-1",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-1",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-05-24_00-26-51.csv')\n# df2 = pd.read_csv('./simulation_results/2023-04-27_22-09-07.csv')\n# df3 = pd.read_csv('./simulation_results/2023-04-28_14-40-59.csv')\n# df4 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n# df5 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n\n\ndata = pd.concat([df1],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_block.csv')\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\n# df1 = pd.read_csv('./simulation_results/2023-04-29_03-57-07.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-04-29_20-15-46.csv') # STGCN IT-STGCN\n# df3 = pd.read_csv('./simulation_results/2023-04-30_16-19-58.csv') # STGCN IT-STGCN\n# # 60% 확인하고 다시 돌리기\n# df4 = pd.read_csv('./simulation_results/2023-05-05_04-21-57.csv') # STGCN IT-STGCN 60%\n# df5 = pd.read_csv('./simulation_results/2023-05-06_11-34-46.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-05-06_23-43-35.csv') # STGCN IT-STGCN\n# df7 = pd.read_csv('./simulation_results/2023-05-07_14-06-44.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-2",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata = pd.concat([df1,df2,df3,df4,df5,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,\n                 df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,\n                 df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,\n                 df51,df52,df53,df54,df55,df56,df57,df58,df59,df60,df61],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/windmillsmall.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/windmillsmall.csv')\n\n\ndata.query(\"method=='GNAR' and mrate ==0\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-2",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR' and mrate !=0\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-2",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\n# df1 = pd.read_csv('./simulation_results/2023-04-24_02-48-08.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-04-24_10-57-10.csv') # STGCN IT-STGCN\n# df3 = pd.read_csv('./simulation_results/2023-04-24_18-53-34.csv') # STGCN IT-STGCN\n# df4 = pd.read_csv('./simulation_results/2023-04-25_02-30-27.csv') # STGCN IT-STGCN\n# df5 = pd.read_csv('./simulation_results/2023-04-25_10-48-46.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-04-25_10-53-14.csv') # GNAR \n# df7 = pd.read_csv('./simulation_results/2023-04-25_18-40-53.csv') # STGCN IT-STGCN\n# df8 = pd.read_csv('./simulation_results/2023-04-25_23-30-08.csv') # STGCN IT-STGCN\n# df9 = pd.read_csv('./simulation_results/2023-04-26_04-15-00.csv') # STGCN IT-STGCN\n# df10 = pd.read_csv('./simulation_results/2023-04-27_07-59-36.csv') # STGCN IT-STGCN\n# df11 = pd.read_csv('./simulation_results/2023-04-27_15-29-00.csv') # STGCN IT-STGCN\n# df12 = pd.read_csv('./simulation_results/2023-04-27_23-37-18.csv') # STGCN IT-STGCN\n# df13 = pd.read_csv('./simulation_results/2023-04-28_08-21-54.csv') # STGCN IT-STGCN\n# df14 = pd.read_csv('./simulation_results/2023-04-28_16-06-55.csv') # STGCN IT-STGCN\n# df15 = pd.read_csv('./simulation_results/2023-04-28_21-19-37.csv') # STGCN IT-STGCN\n# df16 = pd.read_csv('./simulation_results/2023-04-29_03-07-03.csv') # STGCN IT-STGCN\n# df17 = pd.read_csv('./simulation_results/2023-04-29_09-00-42.csv') # STGCN IT-STGCN\n# df18 = pd.read_csv('./simulation_results/2023-04-29_19-07-49.csv') # STGCN IT-STGCN\n# df19 = pd.read_csv('./simulation_results/2023-04-30_05-14-07.csv') # STGCN IT-STGCN\n# df20 = pd.read_csv('./simulation_results/2023-04-30_15-23-16.csv') # STGCN IT-STGCN\n# df21 = pd.read_csv('./simulation_results/2023-05-01_00-16-37.csv') # STGCN IT-STGCN\n# df22 = pd.read_csv('./simulation_results/2023-05-01_07-41-52.csv') # STGCN IT-STGCN\n# df23 = pd.read_csv('./simulation_results/2023-05-01_16-21-41.csv') # STGCN IT-STGCN\n# df24 = pd.read_csv('./simulation_results/2023-05-01_23-38-23.csv') # STGCN IT-STGCN\n# df25 = pd.read_csv('./simulation_results/2023-05-02_13-51-13.csv') # STGCN IT-STGCN\n# df26 = pd.read_csv('./simulation_results/2023-05-02_21-43-26.csv') # STGCN IT-STGCN\n# df27 = pd.read_csv('./simulation_results/2023-05-03_06-04-32.csv') # STGCN IT-STGCN\n# df28 = pd.read_csv('./simulation_results/2023-05-03_13-43-11.csv') # STGCN IT-STGCN\n# df29 = pd.read_csv('./simulation_results/2023-05-03_21-58-04.csv') # STGCN IT-STGCN\n# df30 = pd.read_csv('./simulation_results/2023-05-04_04-39-00.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,\n                 df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/windmillsmall_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/windmillsmall_block.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-3",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-3",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.3 and mrate!=0.4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-3",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\n# df1 = pd.read_csv('./simulation_results/2023-05-04_21-03-21.csv')\n# df2 = pd.read_csv('./simulation_results/2023-05-05_12-10-44.csv')\n# df3 = pd.read_csv('./simulation_results/2023-05-06_12-42-22.csv')\n# df4 = pd.read_csv('./simulation_results/2023-05-06_15-40-47.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/monte_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/monte_block.csv')\n\n\ndata.query(\"mtype=='block' and method=='GNAR'\")['mse'].mean()\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-27_00-26-15.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-27_00-42-14.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-29_18-21-43.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-29_13-25-16.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-29_15-50-57.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-06-METRLADatasetLoader.html",
    "href": "posts/GCN/2023-04-06-METRLADatasetLoader.html",
    "title": "METRLADatasetLoader-Tutorial",
    "section": "",
    "text": "METRLADatasetLoader\n\n\nimport torch\nfrom IPython.display import clear_output\npt_version = torch.__version__\nprint(pt_version)\n\n1.10.1\n\n\n\nimport numpy as np\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import StaticGraphTemporalSignal\n\nloader = METRLADatasetLoader()\ndataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\n#print(\"Dataset type:  \", dataset)\n#print(\"Number of samples / sequences: \",  len(set(dataset)))\n\n\nimport seaborn as sns\n# Visualize traffic over time\nsensor_number = 1\nhours = 24\nsensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\nsns.lineplot(data=sensor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n#print(\"Number of train buckets: \", len(set(train_dataset)))\n#print(\"Number of test buckets: \", len(set(test_dataset)))\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import A3TGCN\n\nclass TemporalGNN(torch.nn.Module):\n    def __init__(self, node_features, periods):\n        super(TemporalGNN, self).__init__()\n        # Attention Temporal Graph Convolutional Cell\n        self.tgnn = A3TGCN(in_channels=node_features, \n                           out_channels=32, \n                           periods=periods)\n        # Equals single-shot prediction\n        self.linear = torch.nn.Linear(32, periods)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        x = Node features for T time steps\n        edge_index = Graph edge indices\n        \"\"\"\n        h = self.tgnn(x, edge_index)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\nTemporalGNN(node_features=2, periods=12)\n\nTemporalGNN(\n  (tgnn): A3TGCN(\n    (_base_tgcn): TGCN(\n      (conv_z): GCNConv(2, 32)\n      (linear_z): Linear(in_features=64, out_features=32, bias=True)\n      (conv_r): GCNConv(2, 32)\n      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n      (conv_h): GCNConv(2, 32)\n      (linear_h): Linear(in_features=64, out_features=32, bias=True)\n    )\n  )\n  (linear): Linear(in_features=32, out_features=12, bias=True)\n)\n\n\n\n# GPU support\ndevice = torch.device('cpu') # cuda\nsubset = 2000\n\n# Create model and optimizers\nmodel = TemporalGNN(node_features=2, periods=12).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nprint(\"Running training...\")\nfor epoch in range(10): \n    loss = 0\n    step = 0\n    for snapshot in train_dataset:\n        snapshot = snapshot.to(device)\n        # Get model predictions\n        y_hat = model(snapshot.x, snapshot.edge_index)\n        # Mean squared error\n        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n        step += 1\n        if step > subset:\n          break\n\n    loss = loss / (step + 1)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))\n\nRunning training...\nEpoch 0 train MSE: 0.7596\nEpoch 1 train MSE: 0.7398\nEpoch 2 train MSE: 0.7205\nEpoch 3 train MSE: 0.6996\nEpoch 4 train MSE: 0.6759\nEpoch 5 train MSE: 0.6495\nEpoch 6 train MSE: 0.6221\nEpoch 7 train MSE: 0.5963\nEpoch 8 train MSE: 0.5743\nEpoch 9 train MSE: 0.5573\n\n\n\nmodel.eval()\nloss = 0\nstep = 0\nhorizon = 288\n\n# Store for analysis\npredictions = []\nlabels = []\n\nfor snapshot in test_dataset:\n    snapshot = snapshot.to(device)\n    # Get predictions\n    y_hat = model(snapshot.x, snapshot.edge_index)\n    # Mean squared error\n    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n    # Store for analysis below\n    labels.append(snapshot.y)\n    predictions.append(y_hat)\n    step += 1\n    if step > horizon:\n          break\n\nloss = loss / (step+1)\nloss = loss.item()\nprint(\"Test MSE: {:.4f}\".format(loss))\n\nTest MSE: 0.6738"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html",
    "href": "posts/GCN/2023-04-27-simulation_table.html",
    "title": "Simulation Tables",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"dataset=='fivenodes' and mtype!='block'\")['mrate'].unique()\n\narray([0.7 , 0.75, 0.8 , 0.85, 0.  ])\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12.0\n      IT-STGCN\n      2\n      1.168\n      0.030\n    \n    \n      1\n      12.0\n      STGCN\n      2\n      1.173\n      0.036\n    \n    \n      2\n      16.0\n      IT-STGCN\n      2\n      1.166\n      0.039\n    \n    \n      3\n      16.0\n      STGCN\n      2\n      1.165\n      0.040\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].std().reset_index(),\n         on=['nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12.0\n      2\n      1.170\n      0.033\n    \n    \n      1\n      16.0\n      2\n      1.165\n      0.039\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].mean().reset_index(),\n         data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].std().reset_index(),\n         on=['nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      2\n      1.247\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='fivenodes' and mtype=='rand'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.407])\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.70\n      12.0\n      IT-STGCN\n      2\n      1.200\n      0.070\n    \n    \n      1\n      0.70\n      12.0\n      STGCN\n      2\n      1.213\n      0.083\n    \n    \n      4\n      0.75\n      12.0\n      IT-STGCN\n      2\n      1.188\n      0.060\n    \n    \n      5\n      0.75\n      12.0\n      STGCN\n      2\n      1.239\n      0.102\n    \n    \n      8\n      0.80\n      12.0\n      IT-STGCN\n      2\n      1.221\n      0.083\n    \n    \n      9\n      0.80\n      12.0\n      STGCN\n      2\n      1.226\n      0.105\n    \n    \n      12\n      0.85\n      12.0\n      IT-STGCN\n      2\n      1.227\n      0.085\n    \n    \n      13\n      0.85\n      12.0\n      STGCN\n      2\n      1.291\n      0.252\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters!=12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      2\n      0.70\n      16.0\n      IT-STGCN\n      2\n      1.201\n      0.068\n    \n    \n      3\n      0.70\n      16.0\n      STGCN\n      2\n      1.227\n      0.094\n    \n    \n      6\n      0.75\n      16.0\n      IT-STGCN\n      2\n      1.231\n      0.110\n    \n    \n      7\n      0.75\n      16.0\n      STGCN\n      2\n      1.201\n      0.072\n    \n    \n      10\n      0.80\n      16.0\n      IT-STGCN\n      2\n      1.232\n      0.092\n    \n    \n      11\n      0.80\n      16.0\n      STGCN\n      2\n      1.292\n      0.148\n    \n    \n      14\n      0.85\n      16.0\n      IT-STGCN\n      2\n      1.286\n      0.297\n    \n    \n      15\n      0.85\n      16.0\n      STGCN\n      2\n      1.362\n      0.239\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters!=12 and mrate!=0.3\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      2\n      0.8\n      16\n      IT-STGCN\n      2\n      1.478\n      1.245\n    \n    \n      3\n      0.8\n      16\n      STGCN\n      2\n      1.491\n      0.302"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\ndata.query(\"dataset=='fivenodes' and mtype=='block'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.407])\n\n\n\ndata.query(\"dataset=='fivenodes' and mtype=='block'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      600\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      601\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      linear\n      NaN\n      1.406830\n    \n    \n      602\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      603\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      linear\n      NaN\n      1.406830\n    \n    \n      604\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      967\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.135442\n    \n    \n      968\n      fivenodes\n      STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      12.0\n      linear\n      150.0\n      1.203593\n    \n    \n      969\n      fivenodes\n      STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.220799\n    \n    \n      970\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      12.0\n      linear\n      150.0\n      1.111655\n    \n    \n      971\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.197438\n    \n  \n\n372 rows × 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12.0\n      IT-STGCN\n      4.308\n      3.333\n    \n    \n      1\n      0.125\n      12.0\n      STGCN\n      6.722\n      5.755\n    \n    \n      2\n      0.125\n      16.0\n      IT-STGCN\n      4.633\n      3.737\n    \n    \n      3\n      0.125\n      16.0\n      STGCN\n      6.858\n      5.814\n    \n    \n      4\n      0.300\n      12.0\n      IT-STGCN\n      1.178\n      0.032\n    \n    \n      5\n      0.300\n      12.0\n      STGCN\n      1.232\n      0.040\n    \n    \n      6\n      0.300\n      16.0\n      IT-STGCN\n      1.163\n      0.050\n    \n    \n      7\n      0.300\n      16.0\n      STGCN\n      1.232\n      0.053\n    \n  \n\n\n\n\n\nepoch 별 보기\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch200.csv')\n\n\ndf_gnar = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_random.csv')\n\n\ndata_temp = pd.concat([df1,df2,df3,df4,df_gnar],axis=0)\n\nSTGCN은 nearest에서 mse가 낮았다.\n\ndata_temp.query(\"method=='STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].mean()\n\n1.182556539773941\n\n\n\ndata_temp.query(\"method=='STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].std()\n\n0.012169932740213692\n\n\n\ndata_temp.query(\"method=='IT-STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].mean()\n\n1.1747438261906304\n\n\n\ndata_temp.query(\"method=='IT-STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].std()\n\n0.007602895892378366"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-1",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16.0\n      IT-STGCN\n      1.008\n      0.010\n    \n    \n      1\n      16.0\n      STGCN\n      1.009\n      0.008\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.953\n      0.005\n    \n    \n      1\n      16\n      STGCN\n      0.953\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-1",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='chickenpox' and mtype=='rand'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.427])\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      cubic\n      16.0\n      IT-STGCN\n      1.019\n      0.011\n    \n    \n      1\n      0.3\n      cubic\n      16.0\n      STGCN\n      1.059\n      0.013\n    \n    \n      6\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      1.015\n      0.009\n    \n    \n      7\n      0.3\n      linear\n      16.0\n      STGCN\n      1.040\n      0.014\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      cubic\n      16\n      IT-STGCN\n      0.985\n      0.008\n    \n    \n      1\n      0.3\n      cubic\n      16\n      STGCN\n      1.053\n      0.008\n    \n    \n      2\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.983\n      0.007\n    \n    \n      3\n      0.3\n      linear\n      16\n      STGCN\n      1.028\n      0.012\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      0.4\n      cubic\n      16\n      IT-STGCN\n      0.995\n      0.009\n    \n    \n      5\n      0.4\n      cubic\n      16\n      STGCN\n      1.069\n      0.011\n    \n    \n      6\n      0.4\n      linear\n      16\n      IT-STGCN\n      0.994\n      0.008\n    \n    \n      7\n      0.4\n      linear\n      16\n      STGCN\n      1.038\n      0.011\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.4\n      cubic\n      16.0\n      IT-STGCN\n      1.021\n      0.009\n    \n    \n      13\n      0.4\n      cubic\n      16.0\n      STGCN\n      1.084\n      0.025\n    \n    \n      18\n      0.4\n      linear\n      16.0\n      IT-STGCN\n      1.020\n      0.009\n    \n    \n      19\n      0.4\n      linear\n      16.0\n      STGCN\n      1.051\n      0.014\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      24\n      0.5\n      cubic\n      16.0\n      IT-STGCN\n      1.027\n      0.012\n    \n    \n      25\n      0.5\n      cubic\n      16.0\n      STGCN\n      1.128\n      0.042\n    \n    \n      30\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.026\n      0.014\n    \n    \n      31\n      0.5\n      linear\n      16.0\n      STGCN\n      1.071\n      0.016\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      8\n      0.5\n      cubic\n      16\n      IT-STGCN\n      1.011\n      0.007\n    \n    \n      9\n      0.5\n      cubic\n      16\n      STGCN\n      1.080\n      0.019\n    \n    \n      10\n      0.5\n      linear\n      16\n      IT-STGCN\n      1.008\n      0.007\n    \n    \n      11\n      0.5\n      linear\n      16\n      STGCN\n      1.055\n      0.010\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      36\n      0.8\n      cubic\n      16.0\n      IT-STGCN\n      1.206\n      0.117\n    \n    \n      37\n      0.8\n      cubic\n      16.0\n      STGCN\n      1.266\n      0.152\n    \n    \n      42\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.101\n      0.034\n    \n    \n      43\n      0.8\n      linear\n      16.0\n      STGCN\n      1.166\n      0.059\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.8\n      cubic\n      16\n      IT-STGCN\n      1.181\n      0.142\n    \n    \n      13\n      0.8\n      cubic\n      16\n      STGCN\n      1.417\n      0.663\n    \n    \n      14\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.058\n      0.015\n    \n    \n      15\n      0.8\n      linear\n      16\n      STGCN\n      1.102\n      0.027\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.9 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      48\n      0.9\n      cubic\n      16.0\n      IT-STGCN\n      1.228\n      0.199\n    \n    \n      49\n      0.9\n      cubic\n      16.0\n      STGCN\n      1.283\n      0.222\n    \n    \n      54\n      0.9\n      linear\n      16.0\n      IT-STGCN\n      1.251\n      0.106\n    \n    \n      55\n      0.9\n      linear\n      16.0\n      STGCN\n      1.265\n      0.148\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.9 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      16\n      0.9\n      cubic\n      16\n      IT-STGCN\n      2.372\n      1.841\n    \n    \n      17\n      0.9\n      cubic\n      16\n      STGCN\n      1.596\n      0.648\n    \n    \n      18\n      0.9\n      linear\n      16\n      IT-STGCN\n      1.090\n      0.045\n    \n    \n      19\n      0.9\n      linear\n      16\n      STGCN\n      1.179\n      0.127"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-1",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\ndata.query(\"dataset=='chickenpox' and mtype=='block'and method=='GNAR'\")['mse'].unique()\n\narray([1.42749429])\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      cubic\n      0.288\n      16.0\n      IT-STGCN\n      1.052\n      0.028\n    \n    \n      1\n      cubic\n      0.288\n      16.0\n      STGCN\n      1.052\n      0.023\n    \n    \n      6\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      1.008\n      0.005\n    \n    \n      7\n      linear\n      0.288\n      16.0\n      STGCN\n      1.011\n      0.008"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-2",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12.0\n      IT-STGCN\n      1.241\n      0.04\n    \n    \n      1\n      4\n      12.0\n      STGCN\n      1.271\n      0.04\n    \n  \n\n\n\n\n\n(1.241+1.271)/2\n\n1.256\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.204\n      0.020\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.203\n      0.022\n    \n  \n\n\n\n\n\n(1.204+1.203)/2\n\n1.2035"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-2",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='pedalme' and method=='GNAR' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index().query(\" lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mse\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      1\n      0.3\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      2\n      0.4\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      3\n      0.4\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      4\n      0.5\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      5\n      0.5\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      6\n      0.6\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      7\n      0.6\n      4\n      linear\n      GNAR\n      1.302679\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      1\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.314\n      0.109\n    \n    \n      2\n      0.3\n      4\n      cubic\n      STGCN\n      1.363\n      0.115\n    \n    \n      3\n      0.3\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      4\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.323\n      0.094\n    \n    \n      5\n      0.3\n      4\n      linear\n      STGCN\n      1.380\n      0.127\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and  lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.223\n      0.031\n    \n    \n      1\n      0.3\n      4\n      cubic\n      STGCN\n      1.248\n      0.039\n    \n    \n      2\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.227\n      0.026\n    \n    \n      3\n      0.3\n      4\n      linear\n      STGCN\n      1.242\n      0.031\n    \n    \n      4\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.032\n    \n    \n      5\n      0.3\n      4\n      nearest\n      STGCN\n      1.229\n      0.032\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      10\n      0.4\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      11\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.331\n      0.112\n    \n    \n      12\n      0.4\n      4\n      cubic\n      STGCN\n      1.342\n      0.108\n    \n    \n      13\n      0.4\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      14\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.375\n      0.154\n    \n    \n      15\n      0.4\n      4\n      linear\n      STGCN\n      1.397\n      0.193\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\" mrate==0.4 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.230\n      0.030\n    \n    \n      7\n      0.4\n      4\n      cubic\n      STGCN\n      1.257\n      0.051\n    \n    \n      8\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.231\n      0.032\n    \n    \n      9\n      0.4\n      4\n      linear\n      STGCN\n      1.251\n      0.040\n    \n    \n      10\n      0.4\n      4\n      nearest\n      IT-STGCN\n      1.235\n      0.031\n    \n    \n      11\n      0.4\n      4\n      nearest\n      STGCN\n      1.241\n      0.033\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      20\n      0.5\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      21\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.328\n      0.108\n    \n    \n      22\n      0.5\n      4\n      cubic\n      STGCN\n      1.367\n      0.114\n    \n    \n      23\n      0.5\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      24\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.377\n      0.138\n    \n    \n      25\n      0.5\n      4\n      linear\n      STGCN\n      1.326\n      0.129\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\" mrate==0.5 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.251\n      0.034\n    \n    \n      13\n      0.5\n      4\n      cubic\n      STGCN\n      1.279\n      0.095\n    \n    \n      14\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.037\n    \n    \n      15\n      0.5\n      4\n      linear\n      STGCN\n      1.268\n      0.052\n    \n    \n      16\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.034\n    \n    \n      17\n      0.5\n      4\n      nearest\n      STGCN\n      1.256\n      0.043\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.6 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      30\n      0.6\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      31\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.300\n      0.063\n    \n    \n      32\n      0.6\n      4\n      cubic\n      STGCN\n      1.352\n      0.106\n    \n    \n      33\n      0.6\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      34\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.416\n      0.169\n    \n    \n      35\n      0.6\n      4\n      linear\n      STGCN\n      1.326\n      0.106\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.6 and  lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      18\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.259\n      0.052\n    \n    \n      19\n      0.6\n      4\n      cubic\n      STGCN\n      1.313\n      0.193\n    \n    \n      20\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.036\n    \n    \n      21\n      0.6\n      4\n      linear\n      STGCN\n      1.280\n      0.064\n    \n    \n      22\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.254\n      0.037\n    \n    \n      23\n      0.6\n      4\n      nearest\n      STGCN\n      1.271\n      0.050"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-2",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      0.143\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      5\n      0.143\n      4\n      cubic\n      IT-STGCN\n      1.284\n      0.053\n    \n    \n      6\n      0.143\n      4\n      cubic\n      STGCN\n      1.288\n      0.071\n    \n    \n      7\n      0.143\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      14\n      0.286\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      15\n      0.286\n      4\n      cubic\n      IT-STGCN\n      1.304\n      0.050\n    \n    \n      16\n      0.286\n      4\n      cubic\n      STGCN\n      1.377\n      0.061\n    \n    \n      17\n      0.286\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      18\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.335\n      0.062\n    \n    \n      19\n      0.286\n      4\n      linear\n      STGCN\n      1.350\n      0.056"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#w_st",
    "href": "posts/GCN/2023-04-27-simulation_table.html#w_st",
    "title": "Simulation Tables",
    "section": "W_st",
    "text": "W_st\n\ndata_pedalme_wst = pd.read_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv')\n\n\npd.merge(data_pedalme_wst.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedalme_wst.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.353\n      0.141\n    \n    \n      1\n      0.3\n      4\n      cubic\n      STGCN\n      1.360\n      0.131\n    \n    \n      2\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.337\n      0.122\n    \n    \n      3\n      0.3\n      4\n      linear\n      STGCN\n      1.353\n      0.117\n    \n    \n      4\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.316\n      0.122\n    \n    \n      5\n      0.3\n      4\n      nearest\n      STGCN\n      1.403\n      0.134\n    \n    \n      12\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.332\n      0.166\n    \n    \n      13\n      0.4\n      4\n      cubic\n      STGCN\n      1.344\n      0.123\n    \n    \n      14\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.355\n      0.139\n    \n    \n      15\n      0.4\n      4\n      linear\n      STGCN\n      1.393\n      0.168\n    \n    \n      16\n      0.4\n      4\n      nearest\n      IT-STGCN\n      1.386\n      0.128\n    \n    \n      17\n      0.4\n      4\n      nearest\n      STGCN\n      1.341\n      0.129\n    \n    \n      24\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.312\n      0.152\n    \n    \n      25\n      0.5\n      4\n      cubic\n      STGCN\n      1.362\n      0.129\n    \n    \n      26\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.344\n      0.177\n    \n    \n      27\n      0.5\n      4\n      linear\n      STGCN\n      1.335\n      0.117\n    \n    \n      28\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.335\n      0.153\n    \n    \n      29\n      0.5\n      4\n      nearest\n      STGCN\n      1.350\n      0.129\n    \n    \n      36\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.346\n      0.151\n    \n    \n      37\n      0.6\n      4\n      cubic\n      STGCN\n      1.398\n      0.103\n    \n    \n      38\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.365\n      0.177\n    \n    \n      39\n      0.6\n      4\n      linear\n      STGCN\n      1.353\n      0.087\n    \n    \n      40\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.402\n      0.269\n    \n    \n      41\n      0.6\n      4\n      nearest\n      STGCN\n      1.339\n      0.111\n    \n    \n      48\n      0.7\n      4\n      cubic\n      IT-STGCN\n      1.377\n      0.173\n    \n    \n      49\n      0.7\n      4\n      cubic\n      STGCN\n      1.363\n      0.097\n    \n    \n      50\n      0.7\n      4\n      linear\n      IT-STGCN\n      1.355\n      0.144\n    \n    \n      51\n      0.7\n      4\n      linear\n      STGCN\n      1.288\n      0.063\n    \n    \n      52\n      0.7\n      4\n      nearest\n      IT-STGCN\n      1.383\n      0.157\n    \n    \n      53\n      0.7\n      4\n      nearest\n      STGCN\n      1.334\n      0.124\n    \n  \n\n\n\n\n\npd.merge(data_pedalme_wst.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedalme_wst.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.286\n      4\n      cubic\n      IT-STGCN\n      1.260\n      0.063\n    \n    \n      7\n      0.286\n      4\n      cubic\n      STGCN\n      1.417\n      0.065\n    \n    \n      8\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.276\n      0.065\n    \n    \n      9\n      0.286\n      4\n      linear\n      STGCN\n      1.288\n      0.055\n    \n    \n      10\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.275\n      0.061\n    \n    \n      11\n      0.286\n      4\n      nearest\n      STGCN\n      1.312\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-3",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index().round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mse\n    \n  \n  \n    \n      4\n      8\n      12.0\n      IT-STGCN\n      0.771\n    \n    \n      5\n      8\n      12.0\n      STGCN\n      0.772\n    \n  \n\n\n\n\n\ndata_DCRNN_wikimath.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index().round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mse\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.778\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.759"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-3",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.3\n      8\n      IT-STGCN\n      0.781\n      0.012\n    \n    \n      7\n      0.3\n      8\n      STGCN\n      0.779\n      0.013\n    \n    \n      14\n      0.5\n      8\n      IT-STGCN\n      0.802\n      0.041\n    \n    \n      15\n      0.5\n      8\n      STGCN\n      0.806\n      0.020\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_wikimath.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_wikimath.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.759\n      0.021\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.774\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-3",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003841\n      2\n      IT-STGCN\n      0.810475\n      0.033897\n    \n    \n      1\n      0.003841\n      2\n      STGCN\n      0.801502\n      0.015510\n    \n    \n      2\n      0.003841\n      4\n      IT-STGCN\n      0.779852\n      0.013188\n    \n    \n      3\n      0.003841\n      4\n      STGCN\n      0.779816\n      0.019309"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-04-27-simulation_table.html#missing-values-on-the-same-nodes",
    "title": "Simulation Tables",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndata_wikimath_st = pd.read_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv')\n\n\npd.merge(data_wikimath_st.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wikimath_st.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.123\n      4\n      IT-STGCN\n      0.774\n      0.008\n    \n    \n      1\n      0.123\n      4\n      STGCN\n      0.766\n      0.010\n    \n    \n      2\n      0.738\n      4\n      IT-STGCN\n      0.851\n      0.029\n    \n    \n      3\n      0.738\n      4\n      STGCN\n      0.831\n      0.031"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-4",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      8\n      IT-STGCN\n      1.006\n      0.006\n    \n    \n      2\n      8\n      STGCN\n      1.001\n      0.003\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.000\n      NaN\n    \n    \n      1\n      8\n      STGCN\n      1.001\n      NaN"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-4",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='windmillsmall' and mtype=='rand'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      7097\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.436077\n    \n    \n      7098\n      windmillsmall\n      IT-STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.290896\n    \n    \n      7099\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.410098\n    \n    \n      7100\n      windmillsmall\n      IT-STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.176981\n    \n    \n      7101\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.447851\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7180\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7181\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7182\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7183\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7184\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n  \n\n88 rows × 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      0.7\n      8\n      IT-STGCN\n      1.178\n      0.054\n    \n    \n      2\n      0.7\n      8\n      STGCN\n      1.410\n      0.075\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-4",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.325\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      0.325\n      8\n      IT-STGCN\n      1.015\n      0.009\n    \n    \n      2\n      0.325\n      8\n      STGCN\n      1.017\n      0.008"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-5",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\nround(data.query(\"dataset=='monte' and mrate==0\")['mse'].mean(),3),round(data_monte.query(\"mrate==0\")['mse'].std(),3)\n\n(0.97, 0.024)"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-5",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='monte' and mtype=='rand'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      7307\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.972491\n    \n    \n      7308\n      monte\n      IT-STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.974410\n    \n    \n      7309\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.968628\n    \n    \n      7310\n      monte\n      IT-STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.976796\n    \n    \n      7311\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.973314\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7872\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.030140\n    \n    \n      7873\n      monte\n      STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.040731\n    \n    \n      7874\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.041819\n    \n    \n      7875\n      monte\n      STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.023531\n    \n    \n      7876\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.032515\n    \n  \n\n504 rows × 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      1\n      0.3\n      4\n      IT-STGCN\n      0.971925\n      0.001871\n    \n    \n      2\n      0.3\n      4\n      STGCN\n      0.965885\n      0.002552\n    \n    \n      3\n      0.3\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      4\n      0.3\n      8\n      IT-STGCN\n      0.974867\n      0.003233\n    \n    \n      5\n      0.3\n      8\n      STGCN\n      0.972051\n      0.002383\n    \n    \n      6\n      0.4\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      7\n      0.4\n      4\n      IT-STGCN\n      0.976348\n      0.001374\n    \n    \n      8\n      0.4\n      4\n      STGCN\n      0.967480\n      0.002974\n    \n    \n      9\n      0.4\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      10\n      0.4\n      8\n      IT-STGCN\n      0.978809\n      0.002110\n    \n    \n      11\n      0.4\n      8\n      STGCN\n      0.973098\n      0.002613\n    \n    \n      12\n      0.8\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      13\n      0.8\n      4\n      IT-STGCN\n      1.006583\n      0.003297\n    \n    \n      14\n      0.8\n      4\n      STGCN\n      0.999715\n      0.006909\n    \n    \n      15\n      0.8\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      16\n      0.8\n      8\n      IT-STGCN\n      1.004450\n      0.002953\n    \n    \n      17\n      0.8\n      8\n      STGCN\n      1.005238\n      0.005777\n    \n    \n      18\n      0.9\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      19\n      0.9\n      4\n      IT-STGCN\n      1.034162\n      0.005611\n    \n    \n      20\n      0.9\n      4\n      STGCN\n      1.034995\n      0.006551\n    \n    \n      21\n      0.9\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      22\n      0.9\n      8\n      IT-STGCN\n      1.030283\n      0.007979\n    \n    \n      23\n      0.9\n      8\n      STGCN\n      1.031538\n      0.009285"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-5",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      1\n      0.149142\n      4\n      IT-STGCN\n      0.963990\n      0.002194\n    \n    \n      2\n      0.149142\n      4\n      STGCN\n      0.965297\n      0.001611\n    \n    \n      3\n      0.149142\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      4\n      0.149142\n      8\n      IT-STGCN\n      0.971647\n      0.002860\n    \n    \n      5\n      0.149142\n      8\n      STGCN\n      0.971700\n      0.001672"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.113\n      0.037\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.115\n      0.038"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.258\n      0.069\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.494\n      0.133\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.322\n      0.070\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.508\n      0.137"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.126\n      0.033\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.154\n      0.040"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      0.910\n      0.042\n    \n    \n      1\n      12\n      STGCN\n      0.902\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      12\n      IT-STGCN\n      0.868\n      0.028\n    \n    \n      1\n      0.3\n      linear\n      12\n      STGCN\n      1.080\n      0.037\n    \n    \n      2\n      0.8\n      linear\n      12\n      IT-STGCN\n      1.399\n      0.063\n    \n    \n      3\n      0.8\n      linear\n      12\n      STGCN\n      2.127\n      0.240"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      12\n      IT-STGCN\n      0.898825\n      0.034600\n    \n    \n      1\n      linear\n      0.28777\n      12\n      STGCN\n      0.912353\n      0.043433\n    \n    \n      2\n      nearest\n      0.28777\n      12\n      IT-STGCN\n      0.908500\n      0.043167\n    \n    \n      3\n      nearest\n      0.28777\n      12\n      STGCN\n      0.930462\n      0.035268"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.197\n      0.052\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.182\n      0.041"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.207\n      0.046\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.279\n      0.061\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.205\n      0.075\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.289\n      0.096\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.294\n      0.056\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.526\n      0.078\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.285\n      0.051\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.083"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.167\n      0.040\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.222\n      0.054\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#w_st",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.222\n      0.083\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.276\n      0.058\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.091\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.281\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.305\n      0.131\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.073\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.204\n      0.063\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.563\n      0.030\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.560\n      0.029"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.578\n      0.031\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.562\n      0.016\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.606\n      0.017\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.770\n      0.045"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.008\n      0.044\n    \n    \n      1\n      4\n      STGCN\n      0.983\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.215692\n      0.117963\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.357897\n      0.148740"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.005486\n      0.046063\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.030326\n      0.044023"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html",
    "title": "DCRNN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random",
    "title": "DCRNN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block",
    "title": "DCRNN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "DCRNN_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-16_21-09-11.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-16_21-30-17.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/DCRNN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/DCRNN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "DCRNN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-19_15-43-50.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-19_18-35-04.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-19_22-00-09.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/DCRNN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/DCRNN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-07-02_07-01-12.csv')\ndf2 = pd.read_csv('./simulation_results/2023-07-02_07-19-21.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-07-03_13-39-23.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-07-03_16-17-40.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-07-03_19-00-05.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.174\n      0.074\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.175\n      0.062"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.197\n      0.057\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.217\n      0.064\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.210\n      0.060\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.217\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.170\n      0.055\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.189\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      32\n      IT-STGCN\n      0.996\n      0.019\n    \n    \n      1\n      32\n      STGCN\n      1.004\n      0.021"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      32\n      IT-STGCN\n      1.011\n      0.019\n    \n    \n      1\n      0.3\n      linear\n      32\n      STGCN\n      1.058\n      0.015\n    \n    \n      2\n      0.8\n      linear\n      32\n      IT-STGCN\n      1.140\n      0.042\n    \n    \n      3\n      0.8\n      linear\n      32\n      STGCN\n      1.203\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      32\n      IT-STGCN\n      1.007400\n      0.020847\n    \n    \n      1\n      linear\n      0.28777\n      32\n      STGCN\n      1.027340\n      0.022523\n    \n    \n      2\n      nearest\n      0.28777\n      32\n      IT-STGCN\n      1.011141\n      0.017937\n    \n    \n      3\n      nearest\n      0.28777\n      32\n      STGCN\n      1.030143\n      0.016657"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.223\n      0.053\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.204\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.245\n      0.069\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.273\n      0.057\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.238\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.244\n      0.054\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.279\n      0.057\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.301\n      0.061\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.091\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.284\n      0.066"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.259\n      0.085\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.246\n      0.073\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#w_st",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.218\n      0.058\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.237\n      0.051\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.068\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.237\n      0.058\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.246\n      0.067\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.291\n      0.063\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.037\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.240\n      0.062"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.784\n      0.027\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.771\n      0.028"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.775\n      0.021\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.787\n      0.024\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.877\n      0.045\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.915\n      0.063"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.775854\n      0.027860\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.773374\n      0.020599"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.794\n      0.031\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.818\n      0.031\n    \n  \n\n\n\n\n\n# WindmillOutputSmallDatasetLoader (lags=8)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.358\n      0.107\n    \n    \n      1\n      4\n      STGCN\n      1.006\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.845349\n      0.504113\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      2.158357\n      0.545361"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.391881\n      0.110351\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.612466\n      0.216224"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html",
    "href": "posts/GCN/2023-01-05-GNAR.html",
    "title": "GNAR data",
    "section": "",
    "text": "GNAR\nGNAR"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#gnar-network-example",
    "href": "posts/GCN/2023-01-05-GNAR.html#gnar-network-example",
    "title": "GNAR data",
    "section": "2.3 GNAR network example",
    "text": "2.3 GNAR network example\n\nedge(list)\ndist(list)\n\n\n%%R\nplot(fiveNet, vertex.label = c(\"A\", \"B\", \"C\", \"D\", \"E\"))\n\n\n\n\n\n%%R\nsummary(\"fiveNet\")\n\n   Length     Class      Mode \n        1 character character \n\n\nother examples\n\nigraphtoGNAR or GNARtoigraph쓰는 예제\n\n\n%%R\nfiveNet2 <- GNARtoigraph(net = fiveNet)\nsummary(fiveNet2)\n\nIGRAPH 2b4460d U-W- 5 5 -- \n+ attr: weight (e/n)\n\n\n\n%%R\nfiveNet3 <- igraphtoGNAR(fiveNet2)\nall.equal(fiveNet, fiveNet3)\n\n[1] TRUE\n\n\n\n%%R\nprint(igraphtoGNAR(fiveNet2))\n\nGNARnet with 5 nodes \nedges:1--4 1--5 2--3 2--4 3--2 3--4 4--1 4--2 4--3 5--1 \n     \n edges of each of length  1 \n\n\nedge들 보고 싶을 때\nwhereas the reverse conversion would be performed as\n\n%%R\ng <- make_ring(10)\nprint(igraphtoGNAR(g))\n\nGNARnet with 10 nodes \nedges:1--2 1--10 2--1 2--3 3--2 3--4 4--3 4--5 5--4 5--6 \n     6--5 6--7 7--6 7--8 8--7 8--9 9--8 9--10 10--1 10--9 \n     \n edges of each of length  1 \n\n\n\n%%R\nmake_ring(10)\n\nIGRAPH 22f6be5 U--- 10 10 -- Ring graph\n+ attr: name (g/c), mutual (g/l), circular (g/l)\n+ edges from 22f6be5:\n [1] 1-- 2 2-- 3 3-- 4 4-- 5 5-- 6 6-- 7 7-- 8 8-- 9 9--10 1--10\n\n\n이어진 방향으로 각각의 edge를 만들어주는 게 igrapphtoGNAR이다\nGNARtoigraph function으로 높은 수준의 이웃 구조를 포함한 그래프를 추출할 수 있다.\n\nas.matrix or matrixtoGNAR로 인접 행렬 구할 수 있음\n\nwe can prosucean adjacency matrix for the fiveNet obeject with\n\n%%R\nas.matrix(fiveNet)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\nand an example converting a weighted adjacency matrix to a GNARnet object is\n\n%%R\nadj <- matrix(runif(9), ncol = 3, nrow = 3)\nadj[adj < 0.3] <- 0\nprint(matrixtoGNAR(adj))\n\nWARNING: diagonal entries present in original matrix, these will be removed\nGNARnet with 3 nodes \nedges:1--2 1--3 2--1 2--3 3--1 3--2 \n edges of unequal lengths"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#example-gnar-model-fitting",
    "href": "posts/GCN/2023-01-05-GNAR.html#example-gnar-model-fitting",
    "title": "GNAR data",
    "section": "2.4. Example: GNAR model fitting",
    "text": "2.4. Example: GNAR model fitting\n\nGNAR로 fit과 predict 가능\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\n파라메터 4개 가지고 있음\n\n\n%%R\nlayout(matrix(c(1, 2), 2, 1))\nplot(fiveVTS[, 1], ylab = \"Node A Time Series\")\nlines(fitted(answer)[, 1], col = 2)\nplot(fiveVTS[, 2], ylab = \"Node B Time Series\")\nlines(fitted(answer)[, 2], col = 2)\n\n\n\n\n\n%%R\nlayout(matrix(c(1, 2), 2, 1))\nplot(fiveVTS[, 3], ylab = \"Node C Time Series\")\nlines(fitted(answer)[, 3], col = 2)\nplot(fiveVTS[, 4], ylab = \"Node D Time Series\")\nlines(fitted(answer)[, 4], col = 2)\n\n\n\n\n\n각 노드의 time series(검정), fitted values from ‘answer’ model overlaid in red\n\n\n%%R\nmyresiduals <- residuals(answer)[, 1]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 1], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 2]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 2], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 3]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 3], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 4]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 4], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\nresidual plots from ‘answer’ model fit. Top: time sereies, Bottom: Histogram"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#example-gnar-data-simulation-on-a-given-network",
    "href": "posts/GCN/2023-01-05-GNAR.html#example-gnar-data-simulation-on-a-given-network",
    "title": "GNAR data",
    "section": "2.5. Example: GNAR data simulation on a given network",
    "text": "2.5. Example: GNAR data simulation on a given network\n\nfiveNet 네트워크를 사용하여 네트워크 시계열 시뮬레이션 진행\n두 시뮬레이션 모두 sigma argument를 사용하여 표준 편차가 제어되는 표준 정규 노이즈를 사용하여 생성된다.\n\n\n%%R\nset.seed(10)\nfiveVTS2 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(c(0.4, 0, -0.6, 0, 0)), betaParams = list(c(0.3)))\n\n\nfiveVTS2 네트워크를 사용하여 시뮬레이션 된 것이다보니 파라메터 계수 비슷\n\n\n%%R\nprint(GNARfit(vts = fiveVTS2, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE))\n\nModel: \nGNAR(1,[1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\ndmatalpha1node1  dmatalpha1node2  dmatalpha1node3  dmatalpha1node4  \n        0.45902          0.13133         -0.49166          0.03828  \ndmatalpha1node5      dmatbeta1.1  \n        0.02249          0.24848  \n\n\n\n\n%%R\nset.seed(10)\nfiveVTS3 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(rep(0.2, 5), rep(0.3, 5)), betaParams = list(c(0.2, 0.3), c(0)))\nprint(GNARfit(vts = fiveVTS3, net = fiveNet, alphaOrder = 2, betaOrder = c(2,0)))\n\nModel: \nGNAR(2,[2,0]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1  dmatbeta1.2   dmatalpha2  \n     0.2537       0.1049       0.3146       0.2907  \n\n\n\n\n%%R\nfiveVTS4 <- simulate(GNARfit(vts = fiveVTS2, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE), n = 200)\nprint(GNARfit(vts = fiveVTS4, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE))\n\nModel: \nGNAR(1,[1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\ndmatalpha1node1  dmatalpha1node2  dmatalpha1node3  dmatalpha1node4  \n      0.4478300       -0.0008695       -0.4822675        0.0523652  \ndmatalpha1node5      dmatbeta1.1  \n     -0.0063702        0.2249530  \n\n\n\n\n위와 같이 GNAR 모델에 있는 시계열을 simulate하기 위해 GNARfit object에 대해 simulate S3 method 사용할 수 있다"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#missing-data-and-changing-connection-weights-with-gnar-models",
    "href": "posts/GCN/2023-01-05-GNAR.html#missing-data-and-changing-connection-weights-with-gnar-models",
    "title": "GNAR data",
    "section": "2.6 Missing data and changing connection weights with GNAR models",
    "text": "2.6 Missing data and changing connection weights with GNAR models\n\nThe flexibility of GNAR modelling이 의미하는 것은 연결 가중치를 바꾸지 않고 변하는 네트워크로 missing data 를 모델링 할 수 있다.\n한 노드가 missing data 구간이 생기면 그 구간에서만 네트워크를 변화하여 weight가 변경된다.\n\n\n%%R\nfiveVTS0 <- fiveVTS\nfiveVTS0[50:150, 3] <- NA\nnafit <- GNARfit(vts = fiveVTS0, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(fitted(nafit)[, 3]), ylab = \"Node C fitted values\")\nplot(ts(fitted(nafit)[, 4]), ylab = \"Node D fitted values\")\n\n\n\n\nA key advantage of our parsimonious GNAR model is that it models via neighborhoods across the entire data set. If a node is missing for a given time, then it does not contribute to the estimation of neighborhood parameters that the network structure suggests it should, and there are plenty of other nodes that do contribute, generally resulting in a high number of observations to estimate each coefficient. In GNAR models, missing data of this kind is not a problem.\n\n우리의 간결한 GNAR 모델의 주요 장점은 전체 데이터 세트에 걸쳐 이웃을 통해 모델링한다는 것입니다. 노드가 특정 시간 동안 누락되면 네트워크 구조가 제안하는 인접 매개 변수의 추정에 기여하지 않으며, 기여하는 다른 노드도 많아 일반적으로 각 계수를 추정하기 위한 관측치 수가 많습니다. GNAR 모델에서는 이런 종류의 데이터가 누락되는 것은 문제가 되지 않습니다."
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#stationary-conditions-for-a-gnar-process-with-fixed-network",
    "href": "posts/GCN/2023-01-05-GNAR.html#stationary-conditions-for-a-gnar-process-with-fixed-network",
    "title": "GNAR data",
    "section": "2.7. Stationary conditions for a GNAR process with fixed network",
    "text": "2.7. Stationary conditions for a GNAR process with fixed network\nTheorem 1\n\nGiven an unchanging network, \\(\\mathcal{G}\\) a sufficient condition for the GNAT model (1) to be stationary is\n\n\\[\\sum^p_{j=1}(|\\alpha_{i,j}| + \\sum^{C}_{c=1} \\sum^{s_j}_{r=1} |\\beta_{j,t,c}|)<1 , \\forall_i \\in 1,\\dots, N\\]\n위 조건을 GNARsim을 이용하여 확인 할 수 있다.\n\n%%R\nset.seed(10)\nfiveVTS4 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(rep(0.2, 5)), betaParams = list(c(0.85)))\nc(mean(fiveVTS4[1:50, ]), mean(fiveVTS4[51:100, ]), mean(fiveVTS4[101:150, ]), mean(fiveVTS4[151:200, ]))\n\n[1]    -120.511   -1370.216  -15725.884 -180319.140\n\n\n\nThe mean increases rapidly indicating nonstationarity.\n평균이 빠르게 증가하는 것으로 보아 정상성을 띄고 있지 않다."
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#benefits-of-our-model-and-comparisons-to-others",
    "href": "posts/GCN/2023-01-05-GNAR.html#benefits-of-our-model-and-comparisons-to-others",
    "title": "GNAR data",
    "section": "2.8. Benefits of our model and comparisons to others",
    "text": "2.8. Benefits of our model and comparisons to others"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#order-selection",
    "href": "posts/GCN/2023-01-05-GNAR.html#order-selection",
    "title": "GNAR data",
    "section": "3.1. Order selection",
    "text": "3.1. Order selection\nBayesian information criterion\n\\[BIC(p,s) = ln|\\sum^{\\hat{}}_{p,s}| + T^{-1} M ln(T)\\]\n\n%%R\nBIC(GNARfit())\n\n[1] -0.003953124\n\n\n\n%%R\nBIC(GNARfit(betaOrder = c(2, 1)))\n\n[1] 0.02251406\n\n\nAkaike information criterion\n\\[AIC(p,s) = ln|\\sum^{\\hat{}}_{p,s}| + 2T^{-1} M\\]\n\n%%R\nAIC(GNARfit())\n\n[1] -0.06991947\n\n\n\n%%R\nAIC(GNARfit(betaOrder = c(2, 1)))\n\n[1] -0.05994387"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#model-selection-on-a-wind-network-time-series",
    "href": "posts/GCN/2023-01-05-GNAR.html#model-selection-on-a-wind-network-time-series",
    "title": "GNAR data",
    "section": "3.2. Model selection on a wind network time series",
    "text": "3.2. Model selection on a wind network time series\nthe data suite vswind that contains a number of R objects pertaining to 721 wind speeds taken at each of 102 weather stations in England and Wales. The suite contains the vector time series vswindts, the associated network vswindnet, a character vector of the weather station location names in vswindnames and coordinates of the stations in the two column matrix vswindcoords. The data originate from the UK Met Office site http://wow.metoffice.gov.uk and full details can be found in the vswind help file in the GNAR package.\n\nnodes : 102\ntime step : 721\n\n\n%%R\noldpar <- par(cex = 0.75)\nwindnetplot()\npar(oldpar)\n\n\n\n\nPlot of the wind speed network\n\nblue numbers are relative distance between sites\nlabels are the site name\n\n\n%%R\nBIC(GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 1, betaOrder = 0))\n\n[1] -233.3848\n\n\n\n%%R \nfiveFit <- GNARfit(fiveVTS[1:160,],net=fiveNet, alphaOrder=2, betaOrder=c(2,0)) #learn \ndim(fitted(fiveFit))\n\n[1] 158   5\n\n\n\n%%R\ndummyFit <- GNARfit(fiveVTS,net=fiveNet, alphaOrder=2, betaOrder=c(2,0)) #learn \ndummyFit$mod$coefficients <- fiveFit$mod$coefficients\n\n\n%%R\nfitted(dummyFit)[161:200]\n\n [1]  0.01093152  0.07611113  0.50989356  0.84380803  0.90488185 -0.12703505\n [7] -0.57721780 -0.36681689 -0.26281975 -0.47712098 -0.62293008 -0.58121816\n[13] -0.81149078 -0.45403821 -0.60487041  0.28617606  0.20580455  0.19341988\n[19]  0.35296420  0.15628117  0.68350847  0.49043974  0.29627168 -0.35666858\n[25] -0.47565960  0.06692171 -0.14924170 -0.36616239 -0.49994894  0.22625500\n[31] -0.08023045  0.25371268 -0.47415540 -0.99390660 -1.16821429 -0.18438203\n[37] -1.10766872 -0.76969390  0.71828989  0.69737474\n\n\n\n%%R\nfitted(fiveFit)\n\n               [,1]         [,2]         [,3]          [,4]         [,5]\n  [1,]  0.300764573  0.731759572  0.645747192  0.6590441235  0.329408573\n  [2,]  0.584155581  0.709939766  0.504838042  0.4006542005  0.002404727\n  [3,]  0.248206643 -0.053672929  0.089912292  0.3569760840  0.886027241\n  [4,]  0.431422029 -0.596332784 -0.445500333 -0.1950437084  0.998677531\n  [5,]  0.369251545 -0.131646096 -0.151852774 -0.0307057532  0.602574799\n  [6,] -0.281163998  0.372761568  0.470612441  0.0640593261 -0.793452225\n  [7,] -0.629184394  0.122210560 -0.064188223  0.2614228537  0.027403171\n  [8,]  0.176102146  0.054605602  0.001654112 -0.0679337406 -0.041235943\n  [9,] -0.168610998 -0.212095723 -0.204125726 -0.2125261302 -0.010579734\n [10,] -0.161421278 -0.007465513  0.149274060 -0.0249484567 -0.327041759\n [11,]  0.359655447 -0.077039236 -0.039580520 -0.0457447866  0.112500734\n [12,] -0.015390804 -0.224700395 -0.236137628 -0.1566997305 -0.032236173\n [13,] -0.254595294 -0.052425427 -0.222029463 -0.1955623614 -0.090852345\n [14,] -0.133378083 -0.231175869 -0.262111004 -0.4557269171 -0.613390251\n [15,] -0.299492590 -1.329777415 -1.157380728 -0.7395871328  0.367735930\n [16,] -0.092939379 -0.649485715 -0.649077093 -0.5677985865  0.018220159\n [17,] -0.197734475  0.006055154  0.003767933  0.0142878952  0.017169293\n [18,] -0.593128663 -0.029057099  0.019930836 -0.1995170085 -0.699678586\n [19,] -0.406803183 -0.080878255 -0.076916012 -0.0142207300  0.084031465\n [20,]  0.195661742  0.636973567  0.514808183  0.1521298877 -0.565262518\n [21,] -0.646798007  0.034595763 -0.038468526 -0.2844049647 -1.200687294\n [22,] -0.858660467 -0.279197317 -0.100300563 -0.1774862659 -0.600631944\n [23,]  0.072500668  0.171516441  0.137895886  0.1253750409  0.109017776\n [24,]  0.361169443 -0.134591857 -0.172907391 -0.0276254736  0.454886946\n [25,] -0.555837928  0.021772877  0.086135588 -0.5401601843 -1.758757275\n [26,] -0.907025497 -0.516889787 -0.601369437 -0.4907248867 -0.518976355\n [27,] -0.577788165 -0.883706611 -0.990274375 -0.5655498386  0.219126828\n [28,] -0.381253476 -1.020667212 -0.974967606 -0.8163078225 -0.224880458\n [29,] -0.418889129 -1.136651964 -1.192973176 -0.8278078873  0.075705061\n [30,] -0.430848760 -0.711242749 -0.645456670 -0.7835485785 -0.902099485\n [31,] -0.408762558 -0.330133901 -0.313267801 -0.2950574688 -0.516672981\n [32,] -0.397456978 -0.177503203 -0.123190622  0.0851676997  0.175790185\n [33,] -0.321504797  0.137826136  0.185516044 -0.0469442492 -0.541534195\n [34,] -0.446890348  0.425984103  0.440639199  0.0859296090 -0.911239457\n [35,] -0.409664931  0.661582101  0.615592428  0.4648149587 -0.620671093\n [36,] -0.178853576  1.134703079  1.170584884  0.7788603566 -0.614547790\n [37,] -0.187107405  0.975055141  0.894986103  0.7556786981  0.299963760\n [38,] -0.421512891  0.230443777  0.311288224  0.3783662241  0.481463020\n [39,]  0.551866636  0.010017627 -0.031712684 -0.0291730137  0.299117468\n [40,] -0.415705371 -0.084974037 -0.102059950  0.0729357811 -0.004680301\n [41,] -0.596582277 -0.181138675 -0.037759798 -0.0710576429 -0.300907209\n [42,] -0.264388277  0.136784757  0.077185718  0.0270845136 -0.311590329\n [43,]  0.413516614  0.932841430  0.935079115  0.7161523403 -0.158898407\n [44,]  0.095801809  0.920995408  0.955252555  0.8459697803 -0.127453246\n [45,]  0.975373534  1.209886345  1.185240223  1.0015804496  0.169827608\n [46,]  0.618868253 -0.058442807 -0.058935046  0.2370795943  0.914954875\n [47,]  0.366854292  0.267881271  0.247344186  0.2400219950  0.479987689\n [48,] -0.150157867 -0.777932308 -0.717286974 -0.5794468369  0.195377648\n [49,]  0.075029321 -0.299959011 -0.355342761 -0.1920419709  0.334423437\n [50,]  0.386593451 -0.135877992 -0.072542184  0.2518678243  0.984484742\n [51,]  0.697822864 -0.311896474 -0.295669625 -0.2502382955  0.585030936\n [52,]  0.062654477 -0.191584061 -0.107314176  0.2208996954  1.056837103\n [53,]  0.728773427 -0.477836693 -0.494169917 -0.4843342717  0.451358938\n [54,]  0.585069845  0.665543312  0.719452401  0.5820396956  0.545931719\n [55,]  1.079661317  0.127297862  0.038038488  0.0677187351  0.907180658\n [56,]  0.651000271  0.443573833  0.461237609  0.2318123507  0.355931847\n [57,]  0.047340441  0.061483244 -0.142562719 -0.0074741198  0.203598849\n [58,]  0.020722674 -0.855956709 -0.772986200 -0.7280158105 -0.072139463\n [59,] -0.197216261 -0.894976325 -0.740954981 -0.7972459012 -0.237856418\n [60,] -0.335837112 -0.488349114 -0.651565734 -0.7163113371 -0.703717928\n [61,] -0.573434288 -1.566963776 -1.470953366 -0.9358838106  0.340002593\n [62,] -0.019967493 -1.006103326 -1.203028246 -0.7206978782  0.426166645\n [63,]  0.289165755 -0.676589963 -0.529091393 -0.3863962807  0.580747013\n [64,] -0.063683833 -0.320450285 -0.325613255 -0.2974046265 -0.105675029\n [65,] -0.112032969 -0.527479112 -0.523398055 -0.1590403400  0.496544412\n [66,] -0.286173235 -0.053400092  0.018863005 -0.0124208740 -0.118724115\n [67,] -0.499744957  0.041067235  0.076504951 -0.2048682261 -0.787362589\n [68,] -0.547870145 -0.732546310 -0.770409578 -0.7369449312 -0.331821251\n [69,] -0.905056316 -0.829491825 -0.850502405 -0.7607730212 -0.656264847\n [70,] -0.246440697 -0.279850678 -0.269853546 -0.5660758221 -1.111827018\n [71,] -0.186335645  0.010799425 -0.077495418  0.0601490253  0.102437820\n [72,]  0.010493539 -0.479453043 -0.453954591 -0.3426073144 -0.040090049\n [73,] -0.673580794 -0.734494634 -0.564315445 -0.8190023610 -1.019947630\n [74,] -0.640032299 -0.558498277 -0.596977420 -0.5456733025 -0.090276605\n [75,] -0.464960459 -0.529199551 -0.552331950 -0.8884973812 -1.066744453\n [76,] -0.887182659 -0.141258133 -0.110786546  0.0237603066  0.003998690\n [77,] -0.073105627 -0.207336194 -0.187193599 -0.6930066146 -1.105251019\n [78,] -0.689981040  0.027486354  0.151691133  0.2650861359 -0.203709649\n [79,]  0.258382277  0.652801148  0.545006830  0.3925781271 -0.249181067\n [80,]  0.751377138  0.239900459  0.276168396  0.6057405726  1.262601102\n [81,]  0.631390471  0.411822991  0.543334476  0.2438621480  0.112347717\n [82,] -0.034969641 -0.104184784 -0.097705561  0.1498464790  0.895833940\n [83,]  0.120113065  0.049356967  0.046034277 -0.0721309377  0.217972070\n [84,] -0.200386785 -0.203495710 -0.239586254 -0.1172887981  0.323191787\n [85,]  0.185644181 -0.395187380 -0.370733604 -0.5009300085 -0.211102667\n [86,] -0.237732516  0.276454796  0.287754635  0.2080093644 -0.223951494\n [87,]  0.216163467  0.192130141  0.177949800 -0.0753244143 -0.351364565\n [88,] -0.142649364 -0.186692214 -0.168987298 -0.1166303744  0.011404103\n [89,]  0.548618117  0.747707315  0.770581155  0.5221810333  0.172075628\n [90,]  0.028104354  0.688465275  0.636215214  0.5500772784  0.059464762\n [91,] -0.495363724 -0.071919605 -0.008154852 -0.4353087653 -1.271143508\n [92,] -1.107134875 -0.172815824 -0.303687490 -0.0844525666 -0.236711607\n [93,] -0.149354271  0.009431534  0.092873697 -0.4137230613 -1.079758945\n [94,] -0.480127162 -0.759207617 -0.733556252 -0.1155717520  0.856016011\n [95,] -0.068768871 -0.262250231 -0.276510238 -0.4068034977 -0.281317568\n [96,] -0.204766674 -0.466093264 -0.516820813 -0.4012743931 -0.036227691\n [97,]  0.450365055 -0.345449271 -0.277951368 -0.0735386028  0.626942400\n [98,]  0.825252322 -0.102070954  0.029346323  0.2224587296  0.891243876\n [99,]  0.918255191  0.974393754  0.785132509  0.9588950601  0.747082329\n[100,]  1.161471681  0.803193156  1.046464965  1.2474096963  1.536524225\n[101,]  0.796513581  0.943461644  0.698756745  0.5968311778  0.275247231\n[102,]  0.189772234  0.088167353  0.193522913 -0.1055246595 -0.205361362\n[103,] -0.486312684  0.528260131  0.609425778  0.4533837262 -0.448633125\n[104,] -0.780106474  0.619638040  0.487082196  0.2699333424 -1.074329863\n[105,]  0.001495171  0.043686101  0.071429149 -0.0068869393  0.109059794\n[106,]  0.412811020  0.589258087  0.534530373  0.1827023688 -0.169191222\n[107,]  0.230033356  0.369815780  0.441499631  0.4808802972  0.619074058\n[108,]  0.887957665  0.299276196  0.242694214  0.2120811348  0.437908215\n[109,] -0.003445154 -0.934051132 -0.730038077 -0.3220444395  0.707556500\n[110,] -0.138607950 -0.723059594 -0.801323554 -0.7383525593 -0.366013353\n[111,] -0.761794858 -0.776583246 -0.767390838 -0.6281202398 -0.286591883\n[112,] -0.143995206 -0.994654745 -0.891931956 -0.8145750541  0.194529857\n[113,] -0.158840376 -0.789802525 -0.720611341 -0.3434589195  0.705106074\n[114,]  0.213701938  0.094954893 -0.066337346 -0.1715778242 -0.301015012\n[115,]  0.353147878 -0.162438159 -0.035453134  0.2417453098  0.692188468\n[116,] -0.259026322 -0.062564122 -0.069539905  0.0494333669  0.016725122\n[117,]  0.439567933  0.334238798  0.123452083  0.2899531832  0.536404389\n[118,]  0.243694767 -0.136731679 -0.062368473 -0.0505163356  0.329751821\n[119,] -0.221760052 -0.034088224 -0.073079140 -0.0719693132  0.080492952\n[120,] -0.639870092 -0.346958117 -0.350162454 -0.6158933852 -1.052705642\n[121,]  0.191514800  0.198936857  0.188570749  0.0576140540 -0.098783032\n[122,]  0.497040376  0.104911046  0.183534206  0.3233013200  0.725368718\n[123,]  0.912741276  0.906110114  0.847102372  0.9050828507  0.840894148\n[124,]  0.761509505  0.486180954  0.657445208  0.6485641139  0.813518998\n[125,]  0.316821416 -0.083720193 -0.173493262 -0.1007134067  0.356082268\n[126,] -0.067185056 -0.753094489 -0.702750670 -0.2621385119  1.046954137\n[127,] -0.091228436 -0.675109353 -0.703565297 -0.5564405787  0.258988050\n[128,] -0.109253436 -0.444143304 -0.399640932 -0.3580561559 -0.035762392\n[129,] -0.232521560 -0.039990247 -0.095241200 -0.0443450553 -0.430664437\n[130,]  0.123446724  0.200420996  0.173518282  0.5184071044  0.313636742\n[131,]  0.285159008 -0.032242166  0.027550780  0.1048459050 -0.132334038\n[132,] -0.029094326  0.291860928  0.394652562  0.4297945912  0.077465921\n[133,]  0.607314455  0.854271821  0.946947611  0.7446008823  0.229008010\n[134,]  0.114274696  0.395094364  0.372741933  0.2933528915  0.073135295\n[135,]  0.058334948  0.020883512 -0.064495939 -0.0002935146  0.194116690\n[136,] -0.485203794  0.162128088  0.243616443  0.0173331790 -0.588154182\n[137,]  0.361414229  0.497203208  0.361158226  0.5018799742  0.573470360\n[138,]  0.819903948  0.366313425  0.363516294  0.3796662479  0.699684917\n[139,] -0.216165855 -0.335708047 -0.251520773 -0.2682301442  0.062768414\n[140,] -0.454294227 -0.359066363 -0.294969357 -0.4097376437 -0.479590775\n[141,] -0.062418172  0.009466708 -0.051169781  0.1398314442  0.275918751\n[142,]  0.546927988  0.424770686  0.388169659  0.1288546957 -0.347653081\n[143,] -0.311508529  0.345041027  0.500511866  0.3303953879 -0.189245985\n[144,]  0.156321321  0.623518356  0.518171727  0.4513620372  0.284295098\n[145,]  0.039622964  0.299954776  0.356381605  0.3469508290  0.326305082\n[146,]  0.579791654  0.695810253  0.652099702  0.5011115910  0.023065334\n[147,]  0.554655907  0.093490122  0.153079897  0.4182759318  0.767121199\n[148,]  0.384057236 -0.065678272 -0.023948715  0.0451867298  0.454508452\n[149,]  0.447874514  0.392017250  0.266888939  0.3039632644  0.540801889\n[150,]  0.497810670  0.980726335  1.014061377  0.9632510637  0.560362395\n[151,]  0.044270389  0.550595322  0.526083974  0.5090146051 -0.039702900\n[152,]  0.128989148  0.501717816  0.494582107  0.2658346703 -0.283886186\n[153,]  0.003640933  0.471547028  0.593579063  0.5105159483  0.179982706\n[154,]  0.207081614  0.420074580  0.265684904  0.2159979026 -0.161101019\n[155,] -0.478137997  0.240399554  0.349195339  0.3926704926 -0.290283502\n[156,] -0.368038032  0.588505317  0.539132547  0.2403574312 -0.831187194\n[157,] -0.452959327  0.212753187  0.402307299  0.1713284561 -0.415735323\n[158,]  0.013726373  0.132970935  0.077022243  0.0243587773 -0.211000744\n\n\n\n%%R \nfiveVTS\n#gdpVTSn2[52,]\n\n               [,1]         [,2]         [,3]         [,4]        [,5]\n  [1,] -0.106526553  1.077613724 -0.244694569  0.933710066  0.44443593\n  [2,]  0.664495737  0.935476457  1.402823610  0.826656526  0.02097885\n  [3,] -0.255977521 -1.478171940  2.160938890  1.746276180  0.80188586\n  [4,]  1.684436464  0.180662387  0.398879113 -0.418094544  0.28037722\n  [5,]  1.451205104  0.584157057 -1.700218367 -1.219724913  1.63810802\n  [6,]  0.728846398  0.536253148 -0.730310794 -0.297010221  1.04864255\n  [7,] -1.526780869  1.957817106 -0.506088728  0.470747730 -0.63167929\n  [8,]  1.269035583 -0.519870107  0.773038576 -0.176065931 -3.13354575\n  [9,] -0.403340381 -0.398760476  1.358212255 -0.755544421  1.58592625\n [10,] -0.057805476 -0.932876792  0.163580296 -0.299486667 -0.31232748\n [11,] -0.498505318  1.005323196 -0.762045202  0.136725053 -0.43412619\n [12,]  0.057551667  0.252414834 -1.585146661  0.892773199  0.64534882\n [13,] -0.235969810  0.168738145 -0.927906887 -0.201182245  0.28394360\n [14,] -0.574265201 -0.451671164  1.523378623 -1.466113999  0.88143283\n [15,] -1.120369546 -2.167955049 -0.290951250  0.951438750 -0.63430591\n [16,]  0.734315543 -1.074175821 -2.550164018 -1.843026440  0.16372069\n [17,] -0.300708705 -0.215965234 -1.251829204 -1.147084336  0.81200151\n [18,]  0.168111491  0.617846030 -0.067553835 -0.316813889 -0.57552628\n [19,] -1.130660662  1.049382642 -0.219923688 -0.838450813 -0.84289855\n [20,]  0.491603006  0.911202204 -0.037939755 -1.146905077 -0.70878526\n [21,] -1.282680651 -0.037695723  1.273889958  1.222120228  0.48792144\n [22,] -1.977860407 -1.476586870  0.618312041  0.541447907 -1.59494685\n [23,] -0.566157633  1.007129193 -0.421914435 -1.255494830 -1.57780757\n [24,]  0.427751755  0.446864227 -0.006556415  0.235046101 -0.13251371\n [25,]  0.588963964 -0.510977075 -0.208215798 -0.038859202  1.03505405\n [26,] -3.577108873  0.063814248 -0.764773488  0.750897963 -0.57677829\n [27,] -0.762998219 -0.715903539  0.070974165 -1.767866460 -0.85886671\n [28,]  1.154873570 -2.505711766 -0.235496918 -1.464120269 -1.74689908\n [29,] -0.272693870 -1.857460255 -1.012583601 -1.478438760 -0.20065611\n [30,]  0.395708110 -2.601309968 -1.102332663 -1.418525692 -0.67074519\n [31,] -1.632021790 -1.389226367 -1.406639927 -0.164463613 -0.57992151\n [32,] -0.593868925 -0.604746854 -0.889344852  0.170550009 -1.19152282\n [33,]  0.902385866  0.859337939 -0.216488189 -1.019066503 -1.20331830\n [34,] -0.755599082  1.205454399 -0.315142793 -0.182216870 -0.76219579\n [35,] -1.402617202  1.327218071  0.030109089  0.508358610 -1.19204930\n [36,] -0.248901260  0.835443000  0.673836075  1.249100802 -2.50681088\n [37,] -0.821889741  2.683690391  1.991361276  0.628557722 -0.63183483\n [38,]  0.509052231  2.387571425  3.198218488 -1.313720751  0.41614740\n [39,]  1.760264680  1.329747672  0.589082315 -0.959062662 -2.17248032\n [40,]  0.407692882 -0.494160904 -0.336544078  0.518871030  1.17098422\n [41,]  0.529542953 -0.109371157  0.276546799 -0.441917032 -1.77465267\n [42,]  0.071422121  1.390859571 -0.656166400 -1.112883997 -1.53889722\n [43,] -0.038685141  0.343631869 -0.121075284  0.189519172 -1.28519302\n [44,]  0.032507365  1.105775541  0.745569895  2.313785056 -0.54606867\n [45,]  0.326298291  1.672376452  0.867801558  1.596593083 -1.38530798\n [46,]  0.493735214  0.828445070  0.665517459  3.545540325  0.17892418\n [47,]  1.046193130  0.182022439  0.076358398 -0.564071723  2.31894117\n [48,]  0.487801423  0.402192928  0.660265277  0.160859127  0.85916399\n [49,]  0.012036883 -0.575802156 -1.375502706 -1.555497631  0.78253503\n [50,]  0.566249612 -0.679123506 -0.342116629 -0.293370938  0.16791547\n [51,]  1.983899460  0.325870466 -0.462247924 -0.144103964  0.20428669\n [52,]  0.082477869 -0.015707410 -0.827420937 -0.533338717  3.03848854\n [53,]  2.025321199  1.260059506 -0.667274520 -0.983423623 -0.25069462\n [54,] -0.182207953 -0.492329932 -1.572486971 -0.318050791  3.11590615\n [55,]  0.310016519  2.163157480  0.539075569  0.775034293  1.55599197\n [56,]  0.344219807 -0.289984010  0.019376746  0.352604618  3.88803701\n [57,] -0.628460347  0.908826573  0.839215153  0.387888048  2.79852674\n [58,]  0.219514752 -1.949662023  1.297952270  0.245509848 -0.10715958\n [59,] -0.703231049 -1.872499373 -0.948118550 -0.956147553  1.46327573\n [60,] -1.037484518 -0.353586885 -2.197040404 -1.022195776  1.03019923\n [61,] -1.671104120 -1.807816077 -0.456726722 -0.275561042  0.23349098\n [62,]  1.082454650 -2.163914674 -2.772699788 -1.867484810 -1.15276058\n [63,]  0.733526181 -2.901286567 -0.144692022 -1.533368920  0.64538823\n [64,]  0.607622782 -0.564034684 -1.024446572 -0.860302664  1.46464103\n [65,] -0.249447697 -0.622497600 -0.860157861  0.059602510 -0.28629810\n [66,]  1.242991882 -0.553213122 -0.784868076 -0.866755329 -0.50726271\n [67,]  0.025808026  1.134045937 -0.194833475 -0.766397319 -0.66714031\n [68,] -1.280038469  0.969797971 -0.529341149 -0.274648131 -0.88451275\n [69,] -0.899437152 -0.455454165 -0.889218336 -2.081201461  0.63782940\n [70,] -0.485225451 -1.579881065 -1.542956678 -0.728773133 -2.63529295\n [71,] -2.232840088 -0.666470900 -0.802215707  0.306471316  0.36000506\n [72,]  0.263283350 -0.473210196  0.858443996 -0.330691066 -0.23528971\n [73,]  0.194868023 -1.673792947 -1.157081284  0.464290012 -0.67196384\n [74,] -2.374209088  0.746939110 -1.641811447 -1.805924541  0.66216561\n [75,] -0.319164807  0.368646446 -0.675529010 -2.103798682  0.06414596\n [76,] -2.347006749 -0.926133386 -1.280596322 -0.435692565  0.21824222\n [77,]  0.446994651  1.473521493  0.734103122 -2.231131628 -1.36931119\n [78,] -2.402766578 -0.673636271 -1.514644362  0.766704957  0.57180703\n [79,]  0.591165442  1.638210347 -0.954659887  0.008337226 -2.90507678\n [80,] -0.284550885  0.812008860  0.745209777  1.099796776  0.12632330\n [81,]  2.404372924  0.494780967 -0.137672593  0.738809147  0.71597343\n [82,] -0.732204526  2.210038243 -0.355431422  0.339909653  2.46725315\n [83,]  1.437145004  1.547713162 -0.345952409 -1.578834604  0.52850356\n [84,] -0.084957358  1.234464257 -0.032386550 -0.956802127  1.29018233\n [85,]  0.630013261  0.172600953 -0.127816246 -1.056826347 -0.23795324\n [86,] -0.893457396 -0.660542921 -1.265061454  0.015612038  1.27234265\n [87,] -0.287301062  0.963686285  0.359594848  0.203580641 -0.80393259\n [88,] -1.133229025  0.151632482 -0.040554491  0.515841576  1.28839412\n [89,] -0.023953670 -0.117144878 -0.537169309 -0.192949617 -0.19885872\n [90,] -0.238994400  1.725878556  1.063475592  0.828811176  1.72692730\n [91,]  0.299232378  0.799624873  1.181753039  0.831726730 -0.84857446\n [92,] -2.481179710  0.113529319 -0.650053446  0.011672273 -0.33558946\n [93,]  0.312713660 -0.079515578  1.502108851 -2.180229770 -2.24161884\n [94,] -1.996496328 -0.407588562 -0.652585366  0.923280995 -0.15832811\n [95,]  2.250167112 -0.220512659 -0.805730284 -2.066199413 -1.28057608\n [96,] -0.763689773 -0.031020794 -0.208759418 -0.867474784  0.72626616\n [97,]  0.014431435 -1.336163148 -0.640654650 -0.333381100 -0.44435745\n [98,]  0.957691513 -0.361694475 -0.967050395  0.060214711  1.10246612\n [99,]  1.469745730  0.554733531 -1.990318074  1.277950650  0.91469843\n[100,]  1.356192755  0.363980993  1.646543813  2.153855538  0.49502358\n[101,]  3.001712443  2.666746291 -0.368684582  1.849950555  0.63675201\n[102,] -0.281234965  0.456235005  2.292473984  0.854928226  2.22619190\n[103,] -1.140727890  0.202030354 -0.219402824  0.310787559  1.38376301\n[104,] -0.101523413  1.693526806  0.088496042  0.849098718 -2.58113447\n[105,] -1.122014513  0.674017745  1.696074464  0.065284585 -2.46042966\n[106,] -0.050503692  0.476461163  0.741019471 -1.033544711  1.30742678\n[107,] -0.977589842  0.119899249  1.188456997  1.081889577  1.41965239\n[108,]  0.909422801  1.255343375  0.842509208 -0.192153747  0.71392520\n[109,]  0.441028047 -0.896440332 -0.270300473  1.985698469  1.24604331\n[110,]  1.237351903  0.285784091 -2.573210003 -1.364613642  0.30715435\n[111,] -0.812621272 -1.216797535 -1.946208168 -0.293442424  0.01613793\n[112,] -0.569590223 -0.000629766 -0.657769831 -2.422099355 -0.23850071\n[113,]  0.013135413 -0.269047393 -2.386679520 -1.612243344  1.04220642\n[114,]  1.497050345  0.473005141 -2.121414725 -1.449151157 -0.36453856\n[115,] -0.826489548 -0.635578799  0.160746530  0.588310936  0.64139235\n[116,]  1.714414681 -0.069917852 -1.565924860  1.120471391 -0.78042307\n[117,]  0.090005879  1.200734542  0.270198304 -1.404710351 -0.03628579\n[118,]  1.236752409 -1.518803758  1.237344754  1.129076932 -0.20967169\n[119,] -0.087766705  0.109758177  0.830463404 -1.215657793  2.10369911\n[120,]  0.171155851 -0.458798255  0.673636072 -0.491339577 -0.55057403\n[121,] -2.015292503 -0.870762059 -0.029309395 -0.793820162 -0.46857349\n[122,] -0.362231614 -0.364385616  0.389845581  0.862317056  0.58137591\n[123,]  1.134908449  0.528983153 -0.215140490  0.381732812  0.95051905\n[124,]  1.457741194  0.847372382  1.281677103  1.882417946  0.73169697\n[125,]  1.108355891  2.153722703 -0.310021511  0.663789759  1.50520899\n[126,]  0.071438586 -0.058006918 -0.325876606 -0.374044712  1.44845100\n[127,]  1.793527240  0.106114670 -0.893934806 -2.276541783  0.63834022\n[128,]  0.315117203 -0.717323756 -0.955019446 -1.370627155  0.39051426\n[129,] -0.043340209 -0.312945747 -1.197591049 -0.317055511 -0.20153262\n[130,] -0.102618844 -0.880170227 -0.604543790  1.138606188 -2.06784587\n[131,]  1.740909147 -0.637353850 -0.010562729  1.561563247 -2.32157478\n[132,]  0.188345255 -0.469433386 -0.998242748  1.333047029 -0.61688863\n[133,]  0.478267920  1.814870921 -0.214383410  0.211463195 -0.68793981\n[134,]  0.520210151  2.448452650 -0.463708150  1.952197392  0.18188706\n[135,] -0.269362229  1.911952464  0.242272223 -0.444547682  1.07677467\n[136,]  0.423190923 -0.410880998 -0.195993929  0.257239829 -0.28741994\n[137,] -1.026903990  1.526871656  0.360358335 -0.772639199 -0.55385790\n[138,]  1.450078506 -0.349330702  1.034884543  1.105119122 -0.44915787\n[139,]  0.550436921  0.247527774  1.257978907  0.192344787  2.62949378\n[140,] -0.191655801  0.134136826 -0.521197521 -1.048113725  0.16877213\n[141,] -0.791900380  0.321889000 -1.170523314 -0.640876817 -0.67475039\n[142,]  0.971146450  0.021298110 -0.039896748  0.046666821 -0.88362522\n[143,] -0.982608481 -0.377262589  0.171316614  1.854723760  0.99834845\n[144,] -0.495627812  2.483176264  0.354246741 -0.684488580 -0.02501307\n[145,]  0.561938527  0.993967044  1.211151634  0.257789007  0.12399797\n[146,]  0.709311790  1.260796758  0.500729309 -0.317030392 -0.10472747\n[147,]  0.242781056  0.024085820  0.200161589  2.499565048 -0.35615091\n[148,]  1.391448147  0.433674956 -0.406153463  0.535043661  0.73457838\n[149,]  0.412636662  0.657392857 -0.602350630 -0.222007914  1.28589205\n[150,]  0.464724442  0.241309629  1.384164088 -0.007823340  1.51425328\n[151,]  1.387500492  1.166650199  1.425112356  1.867514447 -0.82096695\n[152,]  0.324362289  0.546923900  1.123115609  0.598062895 -0.86820404\n[153,] -0.642847662  0.488927474  1.005998211  0.623605903  0.36832761\n[154,]  0.580613501  1.826643913  0.215912542  0.360628058 -0.61370894\n[155,] -0.144307876 -0.646151661  0.724633376  1.186826797 -0.31028196\n[156,]  0.546715317  0.754951418 -0.046634000  0.644574743 -3.02529497\n[157,] -1.292512590  1.254904828  1.493495999 -0.128867226 -0.51111891\n[158,] -0.178360098  1.914596966 -0.981080025  0.228541535 -1.75337640\n[159,] -0.292207540  0.598820101 -0.516651587  0.274304089  0.03373131\n[160,] -2.308524149  0.208852278  1.461230272 -0.500911249 -2.27810147\n[161,] -1.379791032  0.145882158  0.915799429  1.484776097 -3.50041126\n[162,] -0.687780533 -0.916656103  1.270414228  1.016692379 -0.33067553\n[163,]  0.719998169  2.802816864  1.671148575 -0.623046401  0.58186844\n[164,]  0.720895216 -0.441022235  1.355521153  0.169312739  1.37392204\n[165,]  1.255917246  1.237433250 -1.261445845  1.156903886  1.34803048\n[166,]  1.705742677 -2.082080117  1.178644006  0.035092003  2.31810280\n[167,] -1.241297515 -1.810899663  0.429577096 -1.605573403  1.82238571\n[168,] -1.733594362 -1.512615033 -0.660630798 -0.541034771 -0.51548359\n[169,]  0.792480615  1.111823458 -0.087410649 -0.471304848 -1.46894677\n[170,] -1.308490289 -0.820921717 -1.060340478 -0.848828375  0.61581232\n[171,] -0.151371781 -1.755296255 -2.178401224 -1.133293893 -0.73148664\n[172,] -1.440949271 -1.701461336  0.086620787 -0.574783622 -0.96759066\n[173,] -0.602659336  0.088764382 -1.505800731 -1.165425847 -0.71480221\n[174,]  1.275259704 -0.410086120  0.494580410 -2.991666233 -1.27793672\n[175,] -1.404478046 -0.271241519  0.442854733 -0.222198583 -0.71844124\n[176,] -0.656202533  1.203821570  0.978017687  0.126331498 -1.96978752\n[177,] -0.394150009 -0.161910841  2.176312978  0.695232617  0.89852498\n[178,]  0.942635640  0.627373149  1.433906899 -0.365531957  0.60603188\n[179,] -0.023229999  1.377273430 -0.409007667  1.061813530 -0.29478037\n[180,]  0.365704922  1.211613739 -1.923486162  0.212759987  0.96275639\n[181,] -0.005420862 -0.765759383 -1.517079711  0.902219156 -0.34235656\n[182,]  0.024961781  0.098786009 -0.242548348  0.230247435  2.58670863\n[183,]  0.827409379 -0.019279260  1.645100501 -0.517327835  1.97867114\n[184,]  0.446528306 -0.641671765  0.183926490  0.194955794  0.61934460\n[185,] -0.852794309 -0.150650614 -1.175556623 -0.749290811 -0.16935739\n[186,]  0.545053341 -0.164000579 -0.705192833 -2.243859141 -0.09017822\n[187,] -1.237547900  0.639970678 -0.071693146  0.802596589  0.36885061\n[188,] -0.400597906 -0.490175656  1.285472941  0.566619402 -0.76045074\n[189,] -0.346030030 -0.031140831  0.468958960 -0.626935003 -0.58954715\n[190,] -0.242598074 -0.643482354  0.637618122  0.729482578 -2.59565491\n[191,]  1.906927330  1.295421628 -0.473359922  0.009433931 -0.45087521\n[192,]  0.247556013  0.380624945  0.511373051 -0.303734068 -0.35216521\n[193,]  0.109182478 -1.095266046 -1.117244679  0.260695357  0.63022764\n[194,] -0.428068355  0.957493744  1.147709215 -1.806721502  0.20508136\n[195,] -2.391696093  1.006982896  0.469035946 -1.029263987 -1.23612823\n[196,] -2.210774865 -1.403493412  0.556772208 -0.600485513 -2.42048578\n[197,] -0.722601932 -0.414053540  0.988636770 -0.610321642  0.58772892\n[198,] -2.938590715 -0.559749691  0.078615069  0.010633188 -2.36841490\n[199,] -0.985951916  0.215394351 -0.119048423  0.779733910 -2.98799845\n[200,]  0.447242609  0.404155027  0.719959458 -0.442525233 -1.78159592\n\n\n\n%%R\nBIC(GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 1, betaOrder = 0, globalalpha = FALSE))\n\n[1] -233.1697\n\n\n\n%%R\nBIC.Alpha2.Beta <- matrix(0, ncol = 15, nrow = 15)\nfor(b1 in 0:14)\n    for(b2 in 0:14)\n        BIC.Alpha2.Beta[b1 + 1, b2 + 1] <- BIC(GNARfit(vts = vswindts,\n                    net = vswindnet, alphaOrder = 2, betaOrder = c(b1, b2)))\ncontour(0:14, 0:14, log(251 + BIC.Alpha2.Beta), xlab = \"Lag 1 Neighbour Order\", ylab = \"Lag 2 Neighbour Order\")\n\nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \n\n\n\na set of GNAR(2,[b1,b2]) models with b1, b2 ranging from zero to 14\nContour plot of BIC values for the two-lag autoregressive model incorporating b1-stage and b2-stage neighbours at time lags one and two. Values shown are log(251 + BIC) to display clearer contours.\n\n이해 덜 됨..\n\nincreasing the lag two neighbour sets beyond first stage neighbours would appear to increase the BIC for those lag one neighbour stages greater than five\n\nchatGPT\n이 문장을 조금 더 자세히 설명하면, BIC(Bayesian Information Criterion)는 모델을 선택할 때 사용하는 지표로서, 우리가 선택한 모델이 얼마나 적합한지를 측정합니다. 이 문장에서는, 이웃 집합의 대기 시간이 증가할수록 BIC 값이 증가할 것이라고 언급하고 있습니다. 이는 우리가 선택한 모델이 적합하지 않을 가능성이 있다는 의미입니다. 그래프를 보고 있을 때, 수평 윤곽선은 BIC 값이 0인 스테이지를 의미합니다. 이는 우리가 선택한 모델이 완벽하게 적합한다는 의미입니다.\n\n%%R\ngoodmod <- GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 2, betaOrder = c(5, 1))\ngoodmod\n\nModel: \nGNAR(2,[5,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1  dmatbeta1.2  dmatbeta1.3  dmatbeta1.4  dmatbeta1.5  \n    0.56911      0.10932      0.03680      0.02332      0.02937      0.04709  \n dmatalpha2  dmatbeta2.1  \n    0.23424     -0.04872"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#constructing-a-network-to-aid-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#constructing-a-network-to-aid-prediction",
    "title": "GNAR data",
    "section": "3.3. Constructing a network to aid prediction",
    "text": "3.3. Constructing a network to aid prediction\nWe propose a network construction method that uses prediction error, but note here that our scope is not to estimate an underlying network, but merely to find a structure that is useful in the task of prediction.\nwe use a prediction error measure, understood as the sum of squared differences between the observations and the estimates:\n\\[\\sum^N_{i=1} (X_{i,t} - \\hat{X}_{i,t})^2\\]\n\n%%R\nprediction <- predict(GNARfit(vts = fiveVTS[1:199,], net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1)))\nprediction\n\nTime Series:\nStart = 1 \nEnd = 1 \nFrequency = 1 \n    Series 1  Series 2  Series 3  Series 4   Series 5\n1 -0.6427718 0.2060671 0.2525534 0.1228404 -0.8231921"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#oecd-gdp-network-structure-aids-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#oecd-gdp-network-structure-aids-prediction",
    "title": "GNAR data",
    "section": "4. OECD GDP: Network structure aids prediction",
    "text": "4. OECD GDP: Network structure aids prediction\nGOP growth rate time series\n\n35 countries from the OECD website\ntime series : 1961 - 2013\nT = 52\nNodes = 35\nIn this data set 20.8% (379 out of 1820) of the observations were missing due to some nodes not being included from the start.\nwe do not uese covariate information, so C=1\n\n\n%%R\nlibrary(\"fields\")\nlayout(matrix(c(1, 2), nrow = 1, ncol = 2), widths = c(4.5, 1))\nimage(t(apply(gdpVTS, 1, rev)), xaxt = \"n\", yaxt = \"n\", col = gray.colors(14), xlab = \"Year\", ylab = \"Country\")\naxis(side = 1, at = seq(from = 0, to = 1, length = 52), labels = FALSE, col.ticks = \"grey\")\naxis(side = 1, at = seq(from = 0, to = 1, length = 52)[5*(1:11)], labels = (1:52)[5*(1:11)])\naxis(side = 2, at = seq(from = 1, to = 0, length = 35), labels = colnames(gdpVTS), las = 1, cex = 0.8)\nlayout(matrix(1))\nimage.plot(zlim = range(gdpVTS, na.rm = TRUE), legend.only = TRUE, col = gray.colors(14))\n\nR[write to console]: Loading required package: spam\n\nR[write to console]: Spam version 2.8-0 (2022-01-05) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\nR[write to console]: \nAttaching package: ‘spam’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    backsolve, forwardsolve\n\n\nR[write to console]: Loading required package: viridis\n\nR[write to console]: Loading required package: viridisLite\n\nR[write to console]: \nTry help(fields) to get started.\n\n\n\n\n\n\nHeat plot(grey scale) of the differenced time series,\n\nwhite space indicates missing time series observations"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#finding-a-network-to-aid-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#finding-a-network-to-aid-prediction",
    "title": "GNAR data",
    "section": "4.1. Finding a network to aid prediction",
    "text": "4.1. Finding a network to aid prediction\n\n%%R\nnet1 <- seedToNet(seed.no = seed.nos[1], nnodes = 35, graph.prob = 0.15)\nnet2 <- seedToNet(seed.no = seed.nos[2], nnodes = 35, graph.prob = 0.15)\n\n\n%%R\nlayout(matrix(c(2, 1), 1, 2))\npar(mar=c(0,1,0,1))\nplot(net1, vertex.label = colnames(gdpVTS), vertex.size = 0)\nplot(net2, vertex.label = colnames(gdpVTS), vertex.size = 0)\n\n\n\n\n\nErdos-Renyi random graphs xonstructed from the first two elements of the seed.nos variable with 35 nodes and connection probability 0.15.\n자기회귀 모델인 GNAR 모델을 예측에 사용할 때, 어떤 네트워크가 가장 적합한지 조사해야 함.\n이때 각 노드의 자기 상관 함수를 이용한 초기 분석 결과, 2차 자기회귀 구성 요소가 충분할 것으로 예상되어 p = 2까지의 GNAR 모델을 시험함.\n각 시간 지연에서 최대 2개의 이웃 집합을 포함함.\n이에 따라 아래와 같은 GNAR 모델이 시험됨.\n\nGNAR(1, [0]), GNAR(1, [1]), GNAR(2, [0, 0]), GNAR(2, [1, 0]), GNAR(2, [1, 1]), GNAR(2, [2, 0]), GNAR(2, [2, 1]), 그리고 GNAR(2, [2, 2])가 시험되며, 각각 individual-\\(\\alpha\\)와 global-\\(\\alpha\\) GNAR 모델로 적합함.\n총 16개의 모델이 생성됨.\n이 중에서 전체 GDP 예측에 사용할 GNAR 모델을 선택할 것.\n연결 확률이 0.15인 10,000개의 임의의 양방향 네트워크를 생성하고, 위에서 언급한 GNAR 모델을 이용해 예측할 것.\n그래서 이 예제는 상당한 계산 시간이 필요(데스크탑 PC에서 약 90분).\n이를 위해 아래 코드에는 일부 분석만 포함.\n계산 상의 이유로, 우선 각 노드에서 표준 편차로 나눠서 잔차가 각 노드에서 동일한 분산을 가지게 함.\nseedSim 함수는 예측값과 원래 값의 제곱 차이의 합을 출력하고, 이를 예측 정확도의 측정 기준으로 사용\n\n\n\n%%R\ngdpVTSn <- apply(gdpVTS, 2, function(x){x / sd(x[1:50], na.rm = TRUE)})\nalphas <- c(rep(1, 2), rep(2, 6))\nbetas <- list(c(0), c(1), c(0, 0), c(1, 0), c(1, 1), c(2, 0), c(2, 1), c(2, 2))\nseedSim <- function(seedNo, modelNo, globalalpha){\n    net1 <- seedToNet(seed.no = seedNo, nnodes = 35, graph.prob = 0.15)\n    gdpPred <- predict(GNARfit(vts = gdpVTSn[1:50, ], net = net1,\n                               alphaOrder = alphas[modelNo], betaOrder = betas[[modelNo]],\n                               globalalpha = globalalpha))\n    return(sum((gdpPred - gdpVTSn[51, ])^2))\n    }\n\n\n%%R\nseedSim(seedNo = seed.nos[1], modelNo = 1, globalalpha = TRUE)\n\n[1] 23.36913\n\n\n\n%%R\nseedSim(seed.nos[1], modelNo = 3, globalalpha = TRUE)\n\n[1] 11.50739\n\n\n\n%%R\nseedSim(seed.nos[1], modelNo = 3, globalalpha = FALSE)\n\n[1] 18.96766\n\n\n\n\n\nimage.png\n\n\n\n10,000개의 임의의 네트워크와 16개의 모델로부터 시뮬레이션한 예측 오류의 박스 그래프\n(계산 시간이 길어(90분) 코드는 생략).\n일반적으로 global-α 모델은 더 낮은 예측 오류를 일으킴.\n그래서 이 버전의 GNAR 모델을 사용할 것.\n그림 9에서 첫 번째 모델인 GNAR(1, [0])과 세 번째 모델인 GNAR(2, [0, 0])의 경우, “박스 그래프”는 인접한 매개변수가 적합되지 않아 결과가 전부 동일해 짧은 수평선으로 표시됨.\n다른 global-α 모델들은 이 안에 포함되어 있기 때문에, global-α GNAR(2, [2, 2])의 예측 오류가 최소가 되는 임의의 그래프를 선택할 것.\n이는 seed.nos[921]에서 생성된 네트워크가 선택되게 됩니다.\n\n\n%%R\nnet921 <- seedToNet(seed.no = seed.nos[921], nnodes = 35, graph.prob = 0.15)\nlayout(matrix(c(1), 1, 1))\nplot(net921, vertex.label = colnames(gdpVTS), vertex.size = 0)\n\n\n\n\nRandomly generated un-weighted and un-directed graph over the OECD ountries that minimises the prediction error at t = 51 using GNAR(2, [2, 2]).\n\nseed.nos[921]에서 생성된 네트워크\n네트워크에는 전부 2개 이상의 이웃을 가지고 있는 countries들이 있고, 총 97개의 edges이 있음.\n이 “921” 네트워크는 GDP 예측을 위해 생성되었기 때문에, 찾은 네트워크에 인식 가능한 구조가 있지 않을 것이라고 예상할 수 있음\n그러나 미국, 멕시코, 캐나다는 각각 8개, 8개, 6개의 edge을 가지고 있어 매우 잘 연결되어 있음.\n스웨덴과 칠레도 잘 연결되어 있으며, 각각 8개와 7개의 edge을 가지고 있습니다.\n예측 성능이 유사한 적은 개수의 edge를 가진 네트워크를 찾기 위해 테스트 될 수 있지만, 여기서는 전체 선택된 네트워크를 그대로 사용.\n이 네트워크를 사용하면 BIC를 이용해 최적의 GNAR 순서를 선택할 수 있음.\n\n\n%%R\nres <- rep(NA, 8)\nfor(i in 1:8){\n    res[i] <- BIC(GNARfit(gdpVTSn[1:50, ],\n                          net = seedToNet(seed.nos[921], nnodes = 35, graph.prob = 0.15),\n                          alphaOrder = alphas[i], betaOrder = betas[[i]]))}\norder(res)\n\n[1] 6 3 4 7 8 5 1 2\n\n\n\n%%R\nsort(res)\n\n[1] -64.44811 -64.32155 -64.18751 -64.12683 -64.09656 -63.86919 -60.67858\n[8] -60.54207"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#results-and-comparisons",
    "href": "posts/GCN/2023-01-05-GNAR.html#results-and-comparisons",
    "title": "GNAR data",
    "section": "4.2. Results and comparisons",
    "text": "4.2. Results and comparisons\n\n이전 섹션의 모델을 사용해 t=52일 때의 값을 예측\n이 예측 오류를 표준 AR과 VAR 모델을 사용해 찾은 예측 오류와 비교\nGNAR 예측은 선택된 네트워크(seed.nos[921]에 해당)를 가진 GNAR(2, [2, 0]) 모델을 t=51까지의 데이터에 적합시키고, t=52일 때의 값을 예측\n우선 series를 정규화한 다음, 모델 적합으로부터 SSE를 계산합니다.\n\n\n%%R\ngdpVTSn2 <- apply(gdpVTS, 2, function(x){x / sd(x[1:51], na.rm = TRUE)})\ngdpFit <- GNARfit(gdpVTSn2[1:51,], net = net921, alphaOrder = 2, betaOrder = c(2, 0))\nsummary(gdpFit)\n\n\nCall:\nlm(formula = yvec2 ~ dmat2 + 0)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4806 -0.5491 -0.0121  0.5013  3.1208 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \ndmat2alpha1  -0.41693    0.03154 -13.221  < 2e-16 ***\ndmat2beta1.1 -0.12662    0.05464  -2.317   0.0206 *  \ndmat2beta1.2  0.28044    0.06233   4.500  7.4e-06 ***\ndmat2alpha2  -0.33282    0.02548 -13.064  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8926 on 1332 degrees of freedom\n  (23 observations deleted due to missingness)\nMultiple R-squared:  0.1859,    Adjusted R-squared:  0.1834 \nF-statistic: 76.02 on 4 and 1332 DF,  p-value: < 2.2e-16\n\nGNAR BIC: -62.86003\n\n\n\n%%R\nsum((predict(gdpFit) - gdpVTSn2[52, ])^2)\n\n[1] 5.737203\n\n\n이 GNAR 모델의 적합된 매개변수는 \\(\\alpha^1 = - 0.42, \\beta^1,1 = - 0.13, \\beta^1,2 = 0.28\\), 그리고 \\(\\alpha^2 = - 0.33\\)입니다.\n\n\n\nModel\nparameters\nprediction error\n\n\n\n\nGNAR(2,[2,0])\n4\n5.7\n\n\nIndividual AR(2)\n38\n8.1\n\n\nVAR(1)\n199\n26.2\n\n\n\nEstimated prediction error of differenced real GDP change at t = 52 for all 35 countries.\n우리의 방법과 CRAN forecast 패키지의 버전 8.0에서의 forecast.ar()과 auto.arima() 함수를 사용해 각 노드별로 AR 모델을 적합한 결과를 비교\n\n섹션 4.1의 자기상관 분석을 고려해 각각 35개의 개별 모델의 최대 AR 순서를 p=2로 설정\n\n\n%%R\nlibrary(\"forecast\")\narforecast <- apply(gdpVTSn2[1:51, ], 2, function(x){\n            forecast(auto.arima(x[!is.na(x)], d= ,D=0,max.p = 2,max.q=0,\n                                max.P=0,max.Q = 0,stationary = TRUE, seasonal = FALSE), ic = \"bic\",\n                     allowmean = FALSE, allowdraft = FALSE, trace = FALSE, h=1)$mean\n})\nsum((arforecast - gdpVTSn2[52, ])^2)\n\nR[write to console]: Registered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\n\n[1] 7.8974\n\n\nWe fit the model using the VAR function and then use the restrict function to reduce dimensionality further, by setting to zero any coefficient whose associated absolute t-statistic value is less than two.\n\n%%R\nlibrary(\"vars\")\ngdpVTSn2.0 <- gdpVTSn2\ngdpVTSn2.0[is.na(gdpVTSn2.0)] <- 0\nvarforecast <- predict(restrict(VAR(gdpVTSn2.0[1:51, ], p = 1, type = \"none\")), n.ahead = 1)\n\ncompute the prediction error\n\n%%R\ngetfcst <- function(x){return(x[1])}\nvarforecastpt <- unlist(lapply(varforecast$fcst, getfcst))\nsum((varforecastpt - gdpVTSn2.0[52, ])^2)\n\n[1] 26.19805\n\n\nGNAR 모델은 AR과 VAR 결과보다 적은 예측 오류를 제공합니다. 이는 AR과 비교했을 때 29%가 줄어들고, VAR과 비교했을 때 78%가 줄어듭니다.\n위 절차를 반복해 2단계 앞으로의 예측을 기반으로 분석을 수행합니다.\n이 경우 다른 네트워크가 GNAR(2,[2,2]) 모델의 예측 오류를 최소화합니다.\n그러나 BIC 단계에서 GNAR(2,[0,0]) 모델이 최적으로 적합된 것을 식별하였고, 이는 네트워크 회귀 매개변수를 포함하지 않는 모델입니다.\n\n%%R\nlibrary(\"vars\")\ngdpVTSn2.0 <- gdpVTSn2\ngdpVTSn2.0[is.na(gdpVTSn2.0)] <- 0\nvarforecast <- predict(restrict(VAR(gdpVTSn2.0[1:51, ], p = 1, type = \"none\")), n.ahead = 40)"
  },
  {
    "objectID": "posts/GCN/2023-05-06-article_refer.html",
    "href": "posts/GCN/2023-05-06-article_refer.html",
    "title": "ITSTGCN Article Refernece",
    "section": "",
    "text": "summerizing it\n\n\n\n\n\n\n\nNote\n\n\n\n\n글이 진행되는 순서로 작성함.\n\n\n\n\nIntroduction\nlittle1989analysis\n\nThe analysis of social science data with missing values\n\nLittle, Roderick JA and Rubin, Donald B\n\n\n위 논문은 구하지 못했고, 아래 논문에서 refer 건 것 보고 작성\nEvaluating the Influence of Missing Data on Classification Algorithms in Data Mining Applications by Luciano C. Blomberg\n내용\n\nFurthermore, distribution of missing data is another aspect that may influence the effectiveness of classification algorithms. Litle and Rubin [1987] presented three different mechanisms by which the missing data are distributed:\n\nli2018missing\n\nMissing value imputation for traffic-related time series data based on a multi-view learning method\n\nLi, Linchao and Zhang, Jian and Wang, Yonggang and Ran, Bin\n\n\n내용\n\nIn this circumstance, the difficulty of imputation is increased as we may not be able to find stable inputs for a model.\n\nSpatiotemporal Data\natluri2018spatio\n\nSpatio-temporal data mining: A survey of problems and methods\n\nAtluri, Gowtham and Karpatne, Anuj and Kumar, Vipin\n\n\n내용\n\n3.2. Data type 내용\n\nwang2020deep\n\nDeep learning for spatio-temporal data mining: A survey\n\nWang, Senzhang and Cao, Jiannong and Yu, Philip\n\n\n내용\n\n2.1. Spatio-Temporal Data Types 항목 내용에서 STData 종류\n\nyu2017spatio\n\nSpatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting\n\nYu, Bing and Yin, Haoteng and Zhu, Zhanxing\n\n\n내용\n\nThe linear interpolation method is used to fill missing values after data cleaning.\n\nguo2019attention\n\nAttention based spatial-temporal graph convolutional networks for traffic flow forecasting\n\nGuo, Shengnan and Lin, Youfang and Feng, Ning and Song, Chao and Wan, Huaiyu\n\n\n내용\n\nThe missing values are filled by the linear interpolation.\n\nbai2020adaptive\n\nAdaptive graph convolutional recurrent network for traffic forecasting\n\nBai, Lei and Yao, Lina and Li, Can and Wang, Xianzhi and Wang, Can\n\n\n내용\n\nThe missing values in the datasets are filled by linear interpolation.\n\nli2019predicting\n\nPredicting path failure in time-evolving graphs\n\nLi, Jia and Han, Zhichao and Cheng, Hong and Su, Jiao and Wang, Pengyun and Zhang, Jianfeng and Pan, Lujia\n\n\n내용\n\nWe replace missing values with 0, and normalize the features to the range\n\nzhao2019t\n\nT-GCN: A Temporal Graph Convol- utional Network for Traffic Prediction\n\nZhao, Ling and Song, Yujiao and Zhang, Chao and Liu, Yu and Wang, Pu and Lin, Tao and Deng, Min and Li, Haifeng\n\n\n내용\n\nwe used the linear interpolation method to fill missing values.\n\nbaraldi2010introduction\n\nAn introduction to modern missing data analyses\n\nBaraldi, Amanda N and Enders, Craig K\n\n\n내용\n\nAn overview of traditional missing data techniques 항목\n\nshi2022air\n\nAir Quality Prediction Model Based on Spatio-temporal Graph Convolution Neural Networks\n\nShi, Weidi and Song, Anjun\n\n\n내용\n\nDue to weather reasons and corrosion or damage of some sensors, some data were lost and abnormal. Therefore, the data needs to be cleaned. We used the average imputation method to fill some lost data and deleted the data which lost too many values.\n\nbatista2003analysis\n\nAn analysis of four missing data treatment methods for supervised learning\n\nBatista, Gustavo EAPA and Monard, Maria Carolina\n\n\n내용\n\nIMPUTATION METHODS\nImputation methods involve replacing missing values with estimated ones based on information available in the data set. There are many options varying from naive methods, such as mean imputation, to some more robust methods based on relationships among attributes. A description of some widely used imputation methods follows:\n\nblomberg2013evaluating\n\nEvaluating the performance of regression algorithms on datasets with missing data\n\nBlomberg, Luciano Costa and Hemerich, Daiane and Ruiz, Duncan Dubugras Alcoba\n\n\n내용\n\nfor example, replaces the missing values with means or modes.\n\ndonders2006gentle\n\nReview: A gentle introduction to imputation of missing values\n\nDonders, A Rogier T and Van Der Heijden, Geert JMG and Stijnen, Theo and Moons, Karel GM\n\n\n내용\n\nthe indicator method and overall mean imputation, give biased results.\nThe mean of the standard errors is a measure for the uncertainty in the estimated associations caused by sampling the study subjects from a source popu- lation. Additionally, the standard deviation of the multiple estimated associations (e.g., regression coefficients) reflects the differences between the imputed data sets, i.e., the un- certainty in the estimated underlying distributions of the variables with missing values.\n\nbaraldi2010introduction\n\nAn introduction to modern missing data analyses\n\nBaraldi, Amanda N and Enders, Craig K\n\n\n내용\n\nTo illustrate the bias that can result from the use of traditional missing data methods, we use the artificial math performance data set found in Table 1.\n\n\n\nProposed Methods\nSelf-Consistent Estimator"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html",
    "title": "Class of Method(GNAR) lag 1",
    "section": "",
    "text": "GNAR fiveNet,fivenodes"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오1-baseline",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오1-baseline",
    "title": "Class of Method(GNAR) lag 1",
    "section": "시나리오1 (Baseline)",
    "text": "시나리오1 (Baseline)\n시나리오1\n\nmissing rate: 0%\n보간방법: None\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:34<00:00,  1.43it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR 으로 적합 + 예측\n-\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\nlibrary(tidyverse)\n\n\n%R -i fiveVTS_train\n\n\n%%R\nanswer <- GNARfit(vts = fiveVTS_train, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean(axis=0)\ntest_mse_total_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.9994323113693153, 1.2692101967317866)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(1,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),gnar_train.reshape(-1,5)[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(161,201),gnar_test.reshape(-1,5)[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오2",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오2",
    "title": "Class of Method(GNAR) lag 1",
    "section": "시나리오2",
    "text": "시나리오2\n시나리오2\n\nmissing rate: 50%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:35<00:00,  1.41it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:37<00:00,  1.33it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7473098322871093, 1.3231643342748722)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(161,201),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오3",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오3",
    "title": "Class of Method(GNAR) lag 1",
    "section": "시나리오3",
    "text": "시나리오3\n시나리오3\n\nmissing rate: 80%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:35<00:00,  1.39it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:37<00:00,  1.33it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.38358787816283946, 1.3239931193379793)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(161,201),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오4",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#시나리오4",
    "title": "Class of Method(GNAR) lag 1",
    "section": "시나리오4",
    "text": "시나리오4\n시나리오4\n\nmissing rate: 30%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:27<00:00,  1.79it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7978462123549198, 1.3146463350699074)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(160,200),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-07-08-toy_example_using_gnar.html",
    "href": "posts/GCN/2023-07-08-toy_example_using_gnar.html",
    "title": "Toy example using GNAR",
    "section": "",
    "text": "Import\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nimport torch\nimport itstgcn\nimport random\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\n\nGNAR Data copy\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\n\nedge(list)\ndist(list)\n\n\n%%R\nplot(fiveNet, vertex.label = c(\"A\", \"B\", \"C\", \"D\", \"E\"))\n\n\n\n\n\n%%R\nas.matrix(fiveNet)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\\[X_{i,t} = \\sum^p_{j=1}\\big( \\alpha_{i,j} X_{i,t-j} + \\sum^C_{c=1} \\sum^{s_j}_{r=1} \\beta_{j,r,c} \\sum_{1 \\in \\cal{N}^{(r)}_t (i)} \\omega^{(t)}_{i,q,c} X_{q,t-j} \\big) + u_{i,t}\\]\n\n\\(p \\in \\mathbb{N}\\) is the maximum time lag\n\\([s] = (s_1, \\dots , s_p)\\) and \\(s_j \\in \\mathbb{N}_0\\) is the maximum stage of neighbor dependence for time lag \\(j\\), with \\(\\mathbb{N}_0 = \\mathbb{N} \\cup \\{ 0\\}\\)\n\\(\\cal{N}^{(r)}_t (i)\\) is the \\(r\\)th stage neighbour set of node \\(i\\) at time \\(t\\)\n\\(\\omega^{(t)}_{i,q,c} \\in [0,1]\\) is the connection weight between node \\(i\\) and node \\(q\\) at time \\(t\\) if the path corresponds to covariate \\(c\\)\n\n\\[X_{A,t} = 0.206 X_{A,t−1}+0.503 (X_{E,t−1}+X_{D,t−1})/2+0.021 X_{A,t−2}−0.095(X_{E,t−2}+X_{D,t−2})/2+u_{A,t}\\]\n\\[X_{B,t} = 0.206 X_{B,t−1}+0.503 (X_{C,t−1}+X_{D,t−1})/2+0.021 X_{B,t−2}−0.095(X_{C,t−2}+X_{D,t−2})/2+u_{B,t}\\]\n\\[X_{C,t} = 0.206 X_{C,t−1}+0.503 (X_{B,t−1}+X_{D,t−1})/2+0.021 X_{C,t−2}−0.095(X_{B,t−2}+X_{D,t−2})/2+u_{C,t}\\]\n\\[X_{D,t} = 0.206 X_{D,t−1}+0.503 (X_{A,t−1}+X_{B,t−1}+X_{C,t−1})/3+0.021 X_{D,t−2}−0.095(X_{A,t−1}+X_{B,t−1}+X_{C,t−1})/3+u_{D,t}\\]\n\\[X_{E,t} = 0.206 X_{E,t−1}+0.503 (X_{A,t−1})+0.021 X_{E,t−2}−0.095(X_{A,t−1})+u_{E,t}\\]\n\nfrom statsmodels.tsa.arima.model import ARIMA\n\nhttps://communities.sas.com/t5/SAS-Tech-Tip/SAS-%ED%99%9C%EC%9A%A9-%EB%85%B8%ED%95%98%EC%9A%B0-%EC%8B%9C%EA%B3%84%EC%97%B4-AR-1-%EA%B3%BC-AR-2/ta-p/792106\n\na_ylag1 = np.random.normal(size=1)\na_ylag2 = np.random.normal(size=1)\n\n\nb_ylag1 = np.random.normal(size=1)\nb_ylag2 = np.random.normal(size=1)\n\n\n# alpha1 = 0.15\nalpha1 = 0.4\nalpha2 = 0.2\n# alpha2 = 0.01\n# beta1 = 0.503\nbeta1 = 0.01\nbeta2 = - 0.1\na_ar_values = []\na_ar_values_true = []\nb_ar_values = []\nb_ar_values_true = []\n\n\nfor i in range(500):\n    a_e = np.random.normal(size=1) * 0.2\n    b_e = np.random.normal(size=1)  * 0.2\n    \n    # a_y = alpha1 * a_ylag1 + alpha2 * a_ylag2 + a_e + beta1 * (e_ylag1 + d_ylag1) / 2 + beta2 * (e_ylag2 + d_ylag2) / 2\n    # b_y = alpha1 * b_ylag1 + alpha2 * b_ylag2 + b_e + beta1 * (c_ylag1 + d_ylag1) / 2 + beta2 * (c_ylag2 + d_ylag2) / 2\n    # c_y = alpha1 * c_ylag1 + alpha2 * c_ylag2 + c_e + beta1 * (b_ylag1 + d_ylag1) / 2 + beta2 * (b_ylag2 + d_ylag2) / 2\n    # d_y = alpha1 * d_ylag1 + alpha2 * d_ylag2 + d_e + beta1 * (a_ylag1 + b_ylag1 + c_ylag1) / 3 + beta2 * (a_ylag2 + b_ylag2 + c_ylag2) / 3\n    # e_y = alpha1 * e_ylag1 + alpha2 * e_ylag2 + e_e + beta1 * a_ylag1 + beta2 * a_ylag2\n    a_y_true = alpha1 * a_ylag1 + alpha2 * a_ylag2 + beta1 * (b_ylag1) + beta2 * (a_ylag2)\n    a_y = a_y_true + a_e\n    b_y_true = alpha1 * b_ylag1 + alpha2 * b_ylag2 + beta1 * (a_ylag1) + beta2 * (b_ylag2)\n    b_y = b_y_true + b_e\n    \n    a_ar_values_true.append(a_y_true[0])\n    a_ar_values.append(a_y[0])\n    b_ar_values_true.append(b_y_true[0])\n    b_ar_values.append(b_y[0])\n    \n    a_ylag2 = a_ylag1\n    b_ylag2 = b_ylag1\n    \n    a_ylag1 = a_y\n    b_ylag1 = b_y\n\n\nnp.sum(a_ar_values)\n\n0.6513402621576372\n\n\n\nnp.sum(b_ar_values)\n\n11.796436691361254\n\n\n\nplt.plot(a_ar_values_true)\n\n\n\n\n\nplt.plot(a_ar_values)\n\n\n\n\n\nplt.plot(b_ar_values_true)\n\n\n\n\n\nplt.plot(b_ar_values)\n\n\n\n\n\ndf = {'A' : a_ar_values, 'B' : b_ar_values}\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_edges = torch.tensor([[0,1],[1,0]]).tolist()\n\n\n_FX1 = np.stack([a_ar_values,b_ar_values],axis=1).tolist()\n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX1}\n\n\nsave_data(data_dict,'toy_ex_dataset.pkl')\n\n\n\nRandom\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_rand = itstgcn.rand_mindex(train_dataset,mrate=0.7)\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\ntrain_dataset_miss_rand = itstgcn.miss(train_dataset,mindex_rand,mtype='rand')\n\n\ntrain_dataset_padded_rand = itstgcn.padding(train_dataset_miss_rand) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr_rand = itstgcn.StgcnLearner(train_dataset_padded_rand)\n\n\nlrnr_rand.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_rand_it = itstgcn.ITStgcnLearner(train_dataset_padded_rand)\n\n\nlrnr_rand_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- 모형 평가 및 시각화\n\nevtor_rand = itstgcn.Evaluator(lrnr_rand,train_dataset_padded_rand,test_dataset)\n\n\nfig = evtor_rand.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rand_it = itstgcn.Evaluator(lrnr_rand_it,train_dataset_padded_rand,test_dataset)\n\n\nfig = evtor_rand_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rand.mse\n\n{'train': {'each_node': [0.014082524925470352, 0.015163550153374672],\n  'total': 0.014623038470745087},\n 'test': {'each_node': [0.07657670229673386, 0.06272050738334656],\n  'total': 0.0696486085653305},\n 'test(base)': {'each_node': [0.05262065306305885, 0.05082978680729866],\n  'total': 0.05172521993517876}}\n\n\n\nevtor_rand_it.mse\n\n{'train': {'each_node': [0.013057202100753784, 0.014180357567965984],\n  'total': 0.013618779368698597},\n 'test': {'each_node': [0.06001878157258034, 0.04732104390859604],\n  'total': 0.05366990715265274},\n 'test(base)': {'each_node': [0.05262065306305885, 0.05082978680729866],\n  'total': 0.05172521993517876}}\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_rand.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:400,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rand.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rand_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rand.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rand_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rand.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rand_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rand.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rand_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\n\nBlock\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_block = [list(range(80,180)),list(range(100,190))]\n\n\ntrain_dataset_miss_block = itstgcn.miss(train_dataset,mindex_block,mtype='block')\n\n\ntrain_dataset_padded_block = itstgcn.padding(train_dataset_miss_block) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr_block = itstgcn.StgcnLearner(train_dataset_padded_block)\n\n\nlrnr_block.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_block_it = itstgcn.ITStgcnLearner(train_dataset_padded_block)\n\n\nlrnr_block_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- 모형 평가 및 시각화\n\nevtor_block = itstgcn.Evaluator(lrnr_block,train_dataset_padded_block,test_dataset)\n\n\nfig = evtor_block.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_block_it = itstgcn.Evaluator(lrnr_block_it,train_dataset_padded_block,test_dataset)\n\n\nfig = evtor_block_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_block.mse\n\n\nevtor_block_it.mse\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_block.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_block.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_block.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_block_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_block.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_block_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='TrGround Truthue')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_block.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_block.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_block.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_block_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_block.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_block_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\n\nRandom & Block\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_rdbl = [random.sample(range(0, 400), int(400*0.7)),[np.array(list(range(150,220)))]]\n\n\ntrain_dataset_miss_rdbl = itstgcn.miss(train_dataset,mindex_rdbl,mtype='block')\n\n\ntrain_dataset_padded_rdbl = itstgcn.padding(train_dataset_miss_rdbl) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr_rdbl = itstgcn.StgcnLearner(train_dataset_padded_rdbl)\n\n\nlrnr_rdbl.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_rdbl_it = itstgcn.ITStgcnLearner(train_dataset_padded_rdbl)\n\n\nlrnr_rdbl_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- 모형 평가 및 시각화\n\nevtor_rdbl = itstgcn.Evaluator(lrnr_rdbl,train_dataset_padded_rdbl,test_dataset)\n\n\nfig = evtor_rdbl.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rdbl_it = itstgcn.Evaluator(lrnr_rdbl_it,train_dataset_padded_rdbl,test_dataset)\n\n\nfig = evtor_rdbl_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\nevtor_rdbl.mse\n\n\nevtor_rdbl_it.mse\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_rdbl.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_rdbl.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rdbl.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rdbl_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rdbl.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rdbl_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_rdbl.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:400,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rdbl.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rdbl_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[399:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rdbl.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rdbl_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "",
    "text": "Try to divide train and test(GNAR fivenet)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nmean_f_fiveVTS_train = torch.tensor(fiveVTS_train_mean).reshape(160,5,1).float()\n\n\nmean_X_fiveVTS = mean_f_fiveVTS_train[:159,:,:]\nmean_y_fiveVTS = mean_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n\n\n\nmean_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nxt_test = torch.tensor(fiveVTS_test.reshape(40,5,1)[:-1,:,:]).float()\n\n\nmean_fhat_fiveVTS_forecast = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_fiveVTS_forecast);\n\n\n\n\n\nvis2(fiveVTS_train_mean,mean_fhat_fiveVTS);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n# np.fft(mean_fhat_fiveVTS[:,0,0])\n\n\n# mean_fhat_fiveVTS.shape\n\n\n# fft_result =np.stack([np.fft.fft(mean_fhat_fiveVTS[:,n,0]) for n in range(N)]).T\n\n\n# plt.plot(abs(fft_result[:,0])**2)\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_fiveVTS.reshape(159*N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n\nvis2(mean_fhat_fiveVTS,fhatbarhat_mean_spatio_temporal.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:26<00:00,  1.88it/s]\n\n\n\nmean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal,mean_fhat_spatio_temporal);\n\n\n\n\n\n\nfor i in tqdm(range(50)):\n    ## GFT \n    fhatbar = Psi.T @ mean_fhat_fiveVTS.reshape(159*N,1)\n\n    ## Ebayes\n    ebayesthresh = importr('EbayesThresh').ebayesthresh\n    fhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n    #plt.plot(fhatbar)\n    #plt.plot(fhatbar_threshed)\n\n    ## inverse GFT \n    fhatbarhat = Psi @ fhatbar_threshed\n    fhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n    #vis2(mean_fhat_fiveVTS,fhatbarhat_mean_spatio_temporal.reshape(159,5));\n\n    ## STGCN \n    fiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\n    fiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number1,1,0]\n    fiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number1,2,0]\n    fiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number1,3,0]\n    fiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number1,4,0]\n    #vis(fiveVTS_train_mean);\n\n    #model = RecurrentGCN(node_features=1, filters=4)\n\n    #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n    #model.train()\n    for epoch in range(1):\n        for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n            y_hat = model(xt, edge_index, edge_attr)\n            cost = torch.mean((y_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    mean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n    mean_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n    #vis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test);\n    #vis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);\n\n100%|██████████| 50/50 [00:55<00:00,  1.10s/it]\n\n\n\nvis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);\n\n\n\n\n\nvis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_spatio_temporal.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\n\n\n\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal2 = fhatbarhat.reshape(159,N,1)\n\n\nvis2(mean_fhat_spatio_temporal,fhatbarhat_mean_spatio_temporal2.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n\n\n\nmean_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test2 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test2);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal2,mean_fhat_spatio_temporal2);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "10) Fourier transform",
    "text": "10) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_spatio_temporal.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "11) Ebayes",
    "text": "11) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "12) Inverse Fourier transform",
    "text": "12) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal3 = fhatbarhat.reshape(159,N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "13) ST-GCN",
    "text": "13) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n\n\n\nmean_fhat_spatio_temporal3 = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test3 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test3);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal3,mean_fhat_spatio_temporal3);\n\n\n\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\nfour = []\nfor i in range(N):\n    four.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test3.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three,'four':four})\n\n\n\n\n\n  \n    \n      \n      one\n      two\n      three\n      four\n    \n  \n  \n    \n      0\n      -0.196310\n      -0.189000\n      -0.173563\n      -0.200559\n    \n    \n      1\n      -0.161632\n      -0.135003\n      -0.142250\n      -0.159892\n    \n    \n      2\n      0.079347\n      0.106893\n      0.108179\n      0.079011\n    \n    \n      3\n      -0.267653\n      -0.244438\n      -0.248220\n      -0.269292\n    \n    \n      4\n      -0.162464\n      -0.135709\n      -0.130221\n      -0.167336"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nlinear_f_fiveVTS_train = torch.tensor(linear_fiveVTS_train).reshape(160,5,1).float()\n\n\nlinear_X_fiveVTS = linear_f_fiveVTS_train[:159,:,:]\nlinear_y_fiveVTS = linear_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_fiveVTS,linear_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_fiveVTS]).detach().numpy()\n\n\nxt_test = torch.tensor(fiveVTS_test.reshape(40,5,1)[:-1,:,:]).float()\n\n\nlinear_fhat_fiveVTS_forecast = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_fiveVTS_forecast);\n\n\nvis2(linear_fiveVTS_train,linear_f_fiveVTS_train);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_fiveVTS.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nplt.plot(fhatbar.reshape(159,5)[:,0]**2)\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n\nvis2(linear_fhat_fiveVTS,fhatbarhat_linear_spatio_temporal.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nlinear_spatio_temporal = torch.tensor(fhatbarhat_linear_spatio_temporal).reshape(159,5,1).float()\n\n\nlinear_X_spatio_temporal = linear_spatio_temporal[:158,:,:]\nlinear_y_spatio_temporal = linear_spatio_temporal[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal,linear_y_spatio_temporal)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test);\n\n\nvis2(fhatbarhat_linear_spatio_temporal,linear_fhat_spatio_temporal);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nw=np.zeros((158*N,158*N))\n\n\nfor i in range(158*N):\n    for j in range(158*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_spatio_temporal.reshape(158*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal2 = fhatbarhat.reshape(158,N,1)\n\n\nvis2(linear_fhat_spatio_temporal,fhatbarhat_linear_spatio_temporal2.reshape(158,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-6",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-6",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nlinear_spatio_temporal2 = torch.tensor(fhatbarhat_linear_spatio_temporal2).reshape(158,5,1).float()\n\n\nlinear_X_spatio_temporal2 = linear_spatio_temporal2[:157,:,:]\nlinear_y_spatio_temporal2 = linear_spatio_temporal2[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal2,linear_y_spatio_temporal2)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal2]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test2 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test2);\n\n\nvis2(fhatbarhat_linear_spatio_temporal2,linear_fhat_spatio_temporal2);\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three})"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "10) Fourier transform",
    "text": "10) Fourier transform\n\nw=np.zeros((157*N,157*N))\n\n\nfor i in range(157*N):\n    for j in range(157*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_spatio_temporal2.reshape(157*N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "11) Ebayes",
    "text": "11) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "12) Inverse Fourier transform",
    "text": "12) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal3 = fhatbarhat.reshape(157,N,1)\n\n\nvis2(linear_fhat_spatio_temporal2,fhatbarhat_linear_spatio_temporal3.reshape(157,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-7",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-7",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "13) ST-GCN",
    "text": "13) ST-GCN\n\nlinear_spatio_temporal3 = torch.tensor(fhatbarhat_linear_spatio_temporal3).reshape(157,5,1).float()\n\n\nlinear_X_spatio_temporal3 = linear_spatio_temporal3[:156,:,:]\nlinear_y_spatio_temporal3 = linear_spatio_temporal3[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal3,linear_y_spatio_temporal3)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal3 = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal3]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test3 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test3);\n\n\nvis2(fhatbarhat_linear_spatio_temporal3,linear_fhat_spatio_temporal3);\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\nfour = []\nfor i in range(N):\n    four.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test3.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three,'four':four})"
  },
  {
    "objectID": "posts/GCN/2023-03-17-ITSTGCN-Tutorial.html",
    "href": "posts/GCN/2023-03-17-ITSTGCN-Tutorial.html",
    "title": "ITSTGCN-Tutorial",
    "section": "",
    "text": "edit\n\n\nimport\n\nimport itstgcn \nimport torch\n\n\n\n예제1: vanilla STGCN\n- 데이터\n\ndata_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset,dataset_name='five_nodes')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/learners.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) \nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제2: padding missing values\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 임의로 결측치 발생\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex=mindex,mtype='rand')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n- 적절한 method로 결측치를 채움 (default 는 linear)\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n다른 method로 결측치를 채울수도 있음. 사용할 수 있는 방법들은 아래에 정리되어 있음\n\nref: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='nearest')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='quadratic')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='cubic')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.utils.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n- 블락으로 결측치 발생\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n예제3: vanilla STGCN with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.learners.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제4: vanilla STGCN with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제5: threshold example (random)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.utils.plot(f_miss,'o')\nitstgcn.utils.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n예제6: threshold example (block)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.plot(f_miss,'o')\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n예제7: iterative thresholded STGCN (IT-STGCN) with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제8: iterative thresholded STGCN (IT-STGCN) with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제9: GNAR (random missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n예제10: GNAR (block missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html",
    "title": "Data management for ITSTGCN",
    "section": "",
    "text": "순환형 구조를 가진 모델(Models with recurrent structures):"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\ndf.query(\"model=='GNAR' and dataset=='fivenodes'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n      model\n    \n  \n  \n    \n      23326\n      fivenodes\n      GNAR\n      0.0\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      1.40683\n      0.021981\n      GNAR\n    \n    \n      23327\n      fivenodes\n      GNAR\n      0.0\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      1.40683\n      0.017151\n      GNAR\n    \n    \n      23328\n      fivenodes\n      GNAR\n      0.7\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.084960\n      GNAR\n    \n    \n      23329\n      fivenodes\n      GNAR\n      0.7\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.010853\n      GNAR\n    \n    \n      23330\n      fivenodes\n      GNAR\n      0.8\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.012061\n      GNAR\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23594\n      fivenodes\n      GNAR\n      0.3\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.008497\n      GNAR\n    \n    \n      23595\n      fivenodes\n      GNAR\n      0.5\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.010377\n      GNAR\n    \n    \n      23596\n      fivenodes\n      GNAR\n      0.5\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.018586\n      GNAR\n    \n    \n      23597\n      fivenodes\n      GNAR\n      0.6\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.007493\n      GNAR\n    \n    \n      23598\n      fivenodes\n      GNAR\n      0.6\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.008042\n      GNAR\n    \n  \n\n204 rows × 11 columns\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','nof_filters','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      nof_filters\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      2.0\n      2\n      50.0\n      1.229\n      0.041\n    \n    \n      1\n      DyGrEncoder\n      12.0\n      2\n      50.0\n      1.114\n      0.037\n    \n    \n      2\n      EvolveGCNH\n      12.0\n      2\n      50.0\n      1.175\n      0.068\n    \n    \n      3\n      EvolveGCNO\n      12.0\n      2\n      50.0\n      1.168\n      0.065\n    \n    \n      4\n      GCLSTM\n      4.0\n      2\n      50.0\n      1.209\n      0.023\n    \n    \n      5\n      GConvGRU\n      12.0\n      2\n      50.0\n      0.732\n      0.005\n    \n    \n      6\n      GConvLSTM\n      12.0\n      2\n      50.0\n      1.131\n      0.041\n    \n    \n      7\n      LRGCN\n      4.0\n      2\n      50.0\n      1.212\n      0.024\n    \n    \n      8\n      TGCN\n      12.0\n      2\n      50.0\n      1.085\n      0.016"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\nhttps://matplotlib.org/stable/gallery/statistics/boxplot.html#sphx-glr-gallery-statistics-boxplot-py\n\n# with plt.style.context('cyberpunk'):\n#     plt.rcParams['figure.figsize'] = [40,20]\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='GConvGRU' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='GConvLSTM' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==2 and epoch==50 and model=='GCLSTM' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==2 and epoch==50 and model=='LRGCN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='DyGrEncoder' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and lags==2 and epoch==50 and model=='EvolveGCNH' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and lags==2 and epoch==50 and model=='EvolveGCNO' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='TGCN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==2 and lags==2 and epoch==50 and model=='DCRNN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.7 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      12\n      DCRNN\n      0.7\n      2.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.247\n      0.044\n    \n    \n      13\n      DCRNN\n      0.7\n      2.0\n      linear\n      STGCN\n      2\n      50.0\n      1.271\n      0.066\n    \n    \n      32\n      DyGrEncoder\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.252\n      0.060\n    \n    \n      33\n      DyGrEncoder\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.548\n      0.158\n    \n    \n      52\n      EvolveGCNH\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.188\n      0.049\n    \n    \n      53\n      EvolveGCNH\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.228\n      0.064\n    \n    \n      72\n      EvolveGCNO\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.162\n      0.052\n    \n    \n      73\n      EvolveGCNO\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.198\n      0.045\n    \n    \n      92\n      GCLSTM\n      0.7\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.228\n      0.034\n    \n    \n      93\n      GCLSTM\n      0.7\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.245\n      0.033\n    \n    \n      112\n      GConvGRU\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.180\n      0.060\n    \n    \n      113\n      GConvGRU\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.858\n      0.139\n    \n    \n      132\n      GConvLSTM\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.287\n      0.075\n    \n    \n      133\n      GConvLSTM\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.472\n      0.125\n    \n    \n      152\n      LRGCN\n      0.7\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.244\n      0.041\n    \n    \n      153\n      LRGCN\n      0.7\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.261\n      0.047\n    \n    \n      172\n      TGCN\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.110\n      0.037\n    \n    \n      173\n      TGCN\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.184\n      0.057\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      16\n      DCRNN\n      0.8\n      2.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.257\n      0.057\n    \n    \n      17\n      DCRNN\n      0.8\n      2.0\n      linear\n      STGCN\n      2\n      50.0\n      1.255\n      0.040\n    \n    \n      18\n      DCRNN\n      0.8\n      2.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.246\n      0.034\n    \n    \n      19\n      DCRNN\n      0.8\n      2.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.253\n      0.043\n    \n    \n      36\n      DyGrEncoder\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.333\n      0.080\n    \n    \n      37\n      DyGrEncoder\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.496\n      0.146\n    \n    \n      38\n      DyGrEncoder\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.311\n      0.057\n    \n    \n      39\n      DyGrEncoder\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.519\n      0.129\n    \n    \n      56\n      EvolveGCNH\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.212\n      0.065\n    \n    \n      57\n      EvolveGCNH\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.217\n      0.061\n    \n    \n      58\n      EvolveGCNH\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.207\n      0.057\n    \n    \n      59\n      EvolveGCNH\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.217\n      0.059\n    \n    \n      76\n      EvolveGCNO\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.194\n      0.065\n    \n    \n      77\n      EvolveGCNO\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.220\n      0.063\n    \n    \n      78\n      EvolveGCNO\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.224\n      0.079\n    \n    \n      79\n      EvolveGCNO\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.212\n      0.053\n    \n    \n      96\n      GCLSTM\n      0.8\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.235\n      0.027\n    \n    \n      97\n      GCLSTM\n      0.8\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.263\n      0.050\n    \n    \n      98\n      GCLSTM\n      0.8\n      4.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.237\n      0.029\n    \n    \n      99\n      GCLSTM\n      0.8\n      4.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.258\n      0.046\n    \n    \n      116\n      GConvGRU\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.383\n      0.108\n    \n    \n      117\n      GConvGRU\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      2.224\n      0.192\n    \n    \n      118\n      GConvGRU\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.360\n      0.084\n    \n    \n      119\n      GConvGRU\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      2.641\n      0.117\n    \n    \n      136\n      GConvLSTM\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.298\n      0.060\n    \n    \n      137\n      GConvLSTM\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.442\n      0.111\n    \n    \n      138\n      GConvLSTM\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.312\n      0.065\n    \n    \n      139\n      GConvLSTM\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.436\n      0.098\n    \n    \n      156\n      LRGCN\n      0.8\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.233\n      0.041\n    \n    \n      157\n      LRGCN\n      0.8\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.250\n      0.038\n    \n    \n      158\n      LRGCN\n      0.8\n      4.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.230\n      0.036\n    \n    \n      159\n      LRGCN\n      0.8\n      4.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.250\n      0.046\n    \n    \n      176\n      TGCN\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.125\n      0.047\n    \n    \n      177\n      TGCN\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.199\n      0.070\n    \n    \n      178\n      TGCN\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.139\n      0.054\n    \n    \n      179\n      TGCN\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.140\n      0.044"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.125\n      2.0\n      linear\n      IT-STGCN\n      50.0\n      1.232\n      0.033\n    \n    \n      1\n      DCRNN\n      0.125\n      2.0\n      linear\n      STGCN\n      50.0\n      1.260\n      0.051\n    \n    \n      2\n      DCRNN\n      0.125\n      2.0\n      nearest\n      IT-STGCN\n      50.0\n      1.222\n      0.025\n    \n    \n      3\n      DCRNN\n      0.125\n      2.0\n      nearest\n      STGCN\n      50.0\n      1.248\n      0.039\n    \n    \n      4\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.124\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.173\n      0.037\n    \n    \n      6\n      DyGrEncoder\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.128\n      0.031\n    \n    \n      7\n      DyGrEncoder\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.135\n      0.033\n    \n    \n      8\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.181\n      0.055\n    \n    \n      9\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.197\n      0.076\n    \n    \n      10\n      EvolveGCNH\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.159\n      0.053\n    \n    \n      11\n      EvolveGCNH\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.181\n      0.037\n    \n    \n      12\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.162\n      0.040\n    \n    \n      13\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.176\n      0.056\n    \n    \n      14\n      EvolveGCNO\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.167\n      0.061\n    \n    \n      15\n      EvolveGCNO\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.195\n      0.065\n    \n    \n      16\n      GCLSTM\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.219\n      0.025\n    \n    \n      17\n      GCLSTM\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.244\n      0.033\n    \n    \n      18\n      GCLSTM\n      0.125\n      4.0\n      nearest\n      IT-STGCN\n      50.0\n      1.215\n      0.022\n    \n    \n      19\n      GCLSTM\n      0.125\n      4.0\n      nearest\n      STGCN\n      50.0\n      1.248\n      0.040\n    \n    \n      20\n      GConvGRU\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.165\n      0.043\n    \n    \n      21\n      GConvGRU\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.210\n      0.039\n    \n    \n      22\n      GConvGRU\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.156\n      0.042\n    \n    \n      23\n      GConvGRU\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.220\n      0.032\n    \n    \n      24\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.140\n      0.038\n    \n    \n      25\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.172\n      0.055\n    \n    \n      26\n      GConvLSTM\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.121\n      0.027\n    \n    \n      27\n      GConvLSTM\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.140\n      0.058\n    \n    \n      28\n      LRGCN\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.220\n      0.020\n    \n    \n      29\n      LRGCN\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.251\n      0.037\n    \n    \n      30\n      LRGCN\n      0.125\n      4.0\n      nearest\n      IT-STGCN\n      50.0\n      1.216\n      0.030\n    \n    \n      31\n      LRGCN\n      0.125\n      4.0\n      nearest\n      STGCN\n      50.0\n      1.239\n      0.034\n    \n    \n      32\n      TGCN\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.090\n      0.015\n    \n    \n      33\n      TGCN\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.107\n      0.020\n    \n    \n      34\n      TGCN\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.091\n      0.015\n    \n    \n      35\n      TGCN\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.091\n      0.011\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.125\n      2.0\n      linear\n      IT-STGCN\n      50.0\n      1.232\n      0.033\n    \n    \n      1\n      DCRNN\n      0.125\n      2.0\n      linear\n      STGCN\n      50.0\n      1.260\n      0.051\n    \n    \n      4\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.124\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.173\n      0.037\n    \n    \n      8\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.181\n      0.055\n    \n    \n      9\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.197\n      0.076\n    \n    \n      12\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.162\n      0.040\n    \n    \n      13\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.176\n      0.056\n    \n    \n      16\n      GCLSTM\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.219\n      0.025\n    \n    \n      17\n      GCLSTM\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.244\n      0.033\n    \n    \n      20\n      GConvGRU\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.165\n      0.043\n    \n    \n      21\n      GConvGRU\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.210\n      0.039\n    \n    \n      24\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.140\n      0.038\n    \n    \n      25\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.172\n      0.055\n    \n    \n      28\n      LRGCN\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.220\n      0.020\n    \n    \n      29\n      LRGCN\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.251\n      0.037\n    \n    \n      32\n      TGCN\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.090\n      0.015\n    \n    \n      33\n      TGCN\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.107\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-1",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters'])['mse'].std().reset_index(),\n         on=['model','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      nof_filters\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      16.0\n      0.727\n      0.009\n    \n    \n      1\n      DyGrEncoder\n      12.0\n      0.906\n      0.051\n    \n    \n      2\n      EvolveGCNH\n      32.0\n      1.000\n      0.020\n    \n    \n      3\n      EvolveGCNO\n      32.0\n      0.986\n      0.018\n    \n    \n      4\n      GCLSTM\n      16.0\n      0.885\n      0.051\n    \n    \n      5\n      GConvGRU\n      16.0\n      0.752\n      0.013\n    \n    \n      6\n      GConvLSTM\n      32.0\n      0.959\n      0.088\n    \n    \n      7\n      LRGCN\n      8.0\n      0.868\n      0.047\n    \n    \n      8\n      TGCN\n      12.0\n      1.090\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-1",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='GConvGRU' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==32 and lags==4 and epoch==50 and model=='GConvLSTM' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='GCLSTM' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='LRGCN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='DyGrEncoder' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNH' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNO' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='TGCN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='DCRNN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.797\n      0.010\n    \n    \n      1\n      DCRNN\n      0.3\n      linear\n      16.0\n      STGCN\n      1.032\n      0.039\n    \n    \n      8\n      DyGrEncoder\n      0.3\n      linear\n      12.0\n      IT-STGCN\n      0.868\n      0.028\n    \n    \n      9\n      DyGrEncoder\n      0.3\n      linear\n      12.0\n      STGCN\n      1.080\n      0.037\n    \n    \n      16\n      EvolveGCNH\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      1.011\n      0.019\n    \n    \n      17\n      EvolveGCNH\n      0.3\n      linear\n      32.0\n      STGCN\n      1.058\n      0.015\n    \n    \n      24\n      EvolveGCNO\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      0.998\n      0.019\n    \n    \n      25\n      EvolveGCNO\n      0.3\n      linear\n      32.0\n      STGCN\n      1.054\n      0.011\n    \n    \n      32\n      GCLSTM\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.850\n      0.022\n    \n    \n      33\n      GCLSTM\n      0.3\n      linear\n      16.0\n      STGCN\n      1.050\n      0.036\n    \n    \n      40\n      GConvGRU\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      41\n      GConvGRU\n      0.3\n      linear\n      16.0\n      STGCN\n      1.087\n      0.046\n    \n    \n      48\n      GConvLSTM\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      0.872\n      0.035\n    \n    \n      49\n      GConvLSTM\n      0.3\n      linear\n      32.0\n      STGCN\n      1.114\n      0.057\n    \n    \n      56\n      LRGCN\n      0.3\n      linear\n      8.0\n      IT-STGCN\n      0.870\n      0.035\n    \n    \n      57\n      LRGCN\n      0.3\n      linear\n      8.0\n      STGCN\n      1.086\n      0.029\n    \n    \n      64\n      TGCN\n      0.3\n      linear\n      12.0\n      IT-STGCN\n      1.042\n      0.020\n    \n    \n      65\n      TGCN\n      0.3\n      linear\n      12.0\n      STGCN\n      1.054\n      0.015\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate!=0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.869\n      0.018\n    \n    \n      3\n      DCRNN\n      0.5\n      linear\n      16.0\n      STGCN\n      1.473\n      0.058\n    \n    \n      4\n      DCRNN\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      0.973\n      0.032\n    \n    \n      5\n      DCRNN\n      0.6\n      linear\n      16.0\n      STGCN\n      1.848\n      0.072\n    \n    \n      6\n      DCRNN\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.467\n      0.076\n    \n    \n      7\n      DCRNN\n      0.8\n      linear\n      16.0\n      STGCN\n      2.287\n      0.074\n    \n    \n      10\n      DyGrEncoder\n      0.5\n      linear\n      12.0\n      IT-STGCN\n      0.915\n      0.029\n    \n    \n      11\n      DyGrEncoder\n      0.5\n      linear\n      12.0\n      STGCN\n      1.540\n      0.045\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      linear\n      12.0\n      IT-STGCN\n      1.013\n      0.035\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      linear\n      12.0\n      STGCN\n      1.807\n      0.068\n    \n    \n      14\n      DyGrEncoder\n      0.8\n      linear\n      12.0\n      IT-STGCN\n      1.399\n      0.063\n    \n    \n      15\n      DyGrEncoder\n      0.8\n      linear\n      12.0\n      STGCN\n      2.127\n      0.240\n    \n    \n      18\n      EvolveGCNH\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.026\n      0.017\n    \n    \n      19\n      EvolveGCNH\n      0.5\n      linear\n      16.0\n      STGCN\n      1.122\n      0.035\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.054\n      0.024\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      linear\n      16.0\n      STGCN\n      1.162\n      0.044\n    \n    \n      22\n      EvolveGCNH\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.140\n      0.042\n    \n    \n      23\n      EvolveGCNH\n      0.8\n      linear\n      32.0\n      STGCN\n      1.203\n      0.061\n    \n    \n      26\n      EvolveGCNO\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.020\n      0.014\n    \n    \n      27\n      EvolveGCNO\n      0.5\n      linear\n      16.0\n      STGCN\n      1.145\n      0.027\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.050\n      0.018\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      linear\n      16.0\n      STGCN\n      1.205\n      0.055\n    \n    \n      30\n      EvolveGCNO\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.161\n      0.054\n    \n    \n      31\n      EvolveGCNO\n      0.8\n      linear\n      32.0\n      STGCN\n      1.234\n      0.096\n    \n    \n      34\n      GCLSTM\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.899\n      0.023\n    \n    \n      35\n      GCLSTM\n      0.5\n      linear\n      16.0\n      STGCN\n      1.514\n      0.050\n    \n    \n      36\n      GCLSTM\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.003\n      0.030\n    \n    \n      37\n      GCLSTM\n      0.6\n      linear\n      16.0\n      STGCN\n      1.808\n      0.069\n    \n    \n      38\n      GCLSTM\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.371\n      0.072\n    \n    \n      39\n      GCLSTM\n      0.8\n      linear\n      16.0\n      STGCN\n      2.172\n      0.186\n    \n    \n      42\n      GConvGRU\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.958\n      0.072\n    \n    \n      43\n      GConvGRU\n      0.5\n      linear\n      16.0\n      STGCN\n      1.530\n      0.106\n    \n    \n      44\n      GConvGRU\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.120\n      0.072\n    \n    \n      45\n      GConvGRU\n      0.6\n      linear\n      16.0\n      STGCN\n      1.753\n      0.181\n    \n    \n      46\n      GConvGRU\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      47\n      GConvGRU\n      0.8\n      linear\n      16.0\n      STGCN\n      2.529\n      0.292\n    \n    \n      50\n      GConvLSTM\n      0.5\n      linear\n      32.0\n      IT-STGCN\n      0.901\n      0.024\n    \n    \n      51\n      GConvLSTM\n      0.5\n      linear\n      32.0\n      STGCN\n      1.518\n      0.063\n    \n    \n      52\n      GConvLSTM\n      0.6\n      linear\n      32.0\n      IT-STGCN\n      1.004\n      0.038\n    \n    \n      53\n      GConvLSTM\n      0.6\n      linear\n      32.0\n      STGCN\n      1.787\n      0.055\n    \n    \n      54\n      GConvLSTM\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.433\n      0.080\n    \n    \n      55\n      GConvLSTM\n      0.8\n      linear\n      32.0\n      STGCN\n      2.522\n      0.111\n    \n    \n      58\n      LRGCN\n      0.5\n      linear\n      8.0\n      IT-STGCN\n      0.931\n      0.034\n    \n    \n      59\n      LRGCN\n      0.5\n      linear\n      8.0\n      STGCN\n      1.458\n      0.068\n    \n    \n      60\n      LRGCN\n      0.6\n      linear\n      8.0\n      IT-STGCN\n      1.017\n      0.029\n    \n    \n      61\n      LRGCN\n      0.6\n      linear\n      8.0\n      STGCN\n      1.615\n      0.134\n    \n    \n      62\n      LRGCN\n      0.8\n      linear\n      8.0\n      IT-STGCN\n      1.334\n      0.071\n    \n    \n      63\n      LRGCN\n      0.8\n      linear\n      8.0\n      STGCN\n      1.632\n      0.156\n    \n    \n      66\n      TGCN\n      0.5\n      linear\n      12.0\n      IT-STGCN\n      1.032\n      0.012\n    \n    \n      67\n      TGCN\n      0.5\n      linear\n      12.0\n      STGCN\n      1.167\n      0.018\n    \n    \n      68\n      TGCN\n      0.6\n      linear\n      12.0\n      IT-STGCN\n      1.054\n      0.014\n    \n    \n      69\n      TGCN\n      0.6\n      linear\n      12.0\n      STGCN\n      1.242\n      0.021\n    \n    \n      70\n      TGCN\n      0.8\n      linear\n      12.0\n      IT-STGCN\n      1.183\n      0.028\n    \n    \n      71\n      TGCN\n      0.8\n      linear\n      12.0\n      STGCN\n      1.466\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-1",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.740\n      0.007\n    \n    \n      1\n      DCRNN\n      linear\n      0.288\n      16.0\n      STGCN\n      0.812\n      0.006\n    \n    \n      2\n      DCRNN\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.738\n      0.007\n    \n    \n      3\n      DCRNN\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.832\n      0.009\n    \n    \n      4\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      0.899\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      STGCN\n      0.912\n      0.043\n    \n    \n      6\n      DyGrEncoder\n      nearest\n      0.288\n      12.0\n      IT-STGCN\n      0.909\n      0.043\n    \n    \n      7\n      DyGrEncoder\n      nearest\n      0.288\n      12.0\n      STGCN\n      0.930\n      0.035\n    \n    \n      8\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.007\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      STGCN\n      1.027\n      0.023\n    \n    \n      10\n      EvolveGCNH\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      1.011\n      0.018\n    \n    \n      11\n      EvolveGCNH\n      nearest\n      0.288\n      32.0\n      STGCN\n      1.030\n      0.017\n    \n    \n      12\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.002\n      0.015\n    \n    \n      13\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      STGCN\n      1.028\n      0.016\n    \n    \n      14\n      EvolveGCNO\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      0.999\n      0.022\n    \n    \n      15\n      EvolveGCNO\n      nearest\n      0.288\n      32.0\n      STGCN\n      1.026\n      0.015\n    \n    \n      16\n      GCLSTM\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.883\n      0.045\n    \n    \n      17\n      GCLSTM\n      linear\n      0.288\n      16.0\n      STGCN\n      0.890\n      0.033\n    \n    \n      18\n      GCLSTM\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.901\n      0.054\n    \n    \n      19\n      GCLSTM\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.885\n      0.042\n    \n    \n      20\n      GConvGRU\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.807\n      0.016\n    \n    \n      21\n      GConvGRU\n      linear\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      22\n      GConvGRU\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.824\n      0.023\n    \n    \n      23\n      GConvGRU\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      24\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      25\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      STGCN\n      0.900\n      0.049\n    \n    \n      26\n      GConvLSTM\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      0.885\n      0.040\n    \n    \n      27\n      GConvLSTM\n      nearest\n      0.288\n      32.0\n      STGCN\n      0.896\n      0.054\n    \n    \n      28\n      LRGCN\n      linear\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.035\n    \n    \n      29\n      LRGCN\n      linear\n      0.288\n      8.0\n      STGCN\n      0.911\n      0.047\n    \n    \n      30\n      LRGCN\n      nearest\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.041\n    \n    \n      31\n      LRGCN\n      nearest\n      0.288\n      8.0\n      STGCN\n      0.902\n      0.039\n    \n    \n      32\n      TGCN\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      1.065\n      0.031\n    \n    \n      33\n      TGCN\n      linear\n      0.288\n      12.0\n      STGCN\n      1.082\n      0.028\n    \n    \n      34\n      TGCN\n      nearest\n      0.288\n      12.0\n      IT-STGCN\n      1.070\n      0.028\n    \n    \n      35\n      TGCN\n      nearest\n      0.288\n      12.0\n      STGCN\n      1.079\n      0.027\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.740\n      0.007\n    \n    \n      1\n      DCRNN\n      linear\n      0.288\n      16.0\n      STGCN\n      0.812\n      0.006\n    \n    \n      4\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      0.899\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      STGCN\n      0.912\n      0.043\n    \n    \n      8\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.007\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      STGCN\n      1.027\n      0.023\n    \n    \n      12\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.002\n      0.015\n    \n    \n      13\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      STGCN\n      1.028\n      0.016\n    \n    \n      16\n      GCLSTM\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.883\n      0.045\n    \n    \n      17\n      GCLSTM\n      linear\n      0.288\n      16.0\n      STGCN\n      0.890\n      0.033\n    \n    \n      20\n      GConvGRU\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.807\n      0.016\n    \n    \n      21\n      GConvGRU\n      linear\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      24\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      25\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      STGCN\n      0.900\n      0.049\n    \n    \n      28\n      LRGCN\n      linear\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.035\n    \n    \n      29\n      LRGCN\n      linear\n      0.288\n      8.0\n      STGCN\n      0.911\n      0.047\n    \n    \n      32\n      TGCN\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      1.065\n      0.031\n    \n    \n      33\n      TGCN\n      linear\n      0.288\n      12.0\n      STGCN\n      1.082\n      0.028"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-2",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['model','lags','nof_filters'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['model','lags','nof_filters'])['mse'].std().reset_index(),\n         on=['model','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      nof_filters\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      4\n      8.0\n      1.131\n      0.015\n    \n    \n      1\n      DyGrEncoder\n      4\n      12.0\n      1.190\n      0.047\n    \n    \n      2\n      EvolveGCNH\n      4\n      2.0\n      1.213\n      0.057\n    \n    \n      3\n      EvolveGCNO\n      4\n      2.0\n      1.223\n      0.051\n    \n    \n      4\n      GCLSTM\n      4\n      4.0\n      1.181\n      0.040\n    \n    \n      5\n      GConvGRU\n      4\n      12.0\n      1.233\n      0.107\n    \n    \n      6\n      GConvLSTM\n      4\n      2.0\n      1.214\n      0.055\n    \n    \n      7\n      LRGCN\n      4\n      8.0\n      1.191\n      0.054\n    \n    \n      8\n      TGCN\n      4\n      12.0\n      1.307\n      0.075"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-2",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='GConvGRU' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==2 and lags==4 and epoch==50 and model=='GConvLSTM' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==4 and epoch==50 and model=='GCLSTM' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='LRGCN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='DyGrEncoder' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNH' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNO' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='TGCN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='DCRNN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate == 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.190\n      0.029\n    \n    \n      1\n      DCRNN\n      0.3\n      4\n      8.0\n      linear\n      STGCN\n      1.277\n      0.064\n    \n    \n      2\n      DCRNN\n      0.3\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.179\n      0.035\n    \n    \n      3\n      DCRNN\n      0.3\n      4\n      8.0\n      nearest\n      STGCN\n      1.278\n      0.060\n    \n    \n      16\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.207\n      0.046\n    \n    \n      17\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.279\n      0.061\n    \n    \n      18\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.205\n      0.075\n    \n    \n      19\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.289\n      0.096\n    \n    \n      32\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.245\n      0.069\n    \n    \n      33\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.273\n      0.057\n    \n    \n      34\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.238\n      0.046\n    \n    \n      35\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.244\n      0.054\n    \n    \n      48\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.251\n      0.072\n    \n    \n      49\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.267\n      0.072\n    \n    \n      50\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.251\n      0.057\n    \n    \n      51\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.265\n      0.056\n    \n    \n      64\n      GCLSTM\n      0.3\n      4\n      4.0\n      linear\n      IT-STGCN\n      1.202\n      0.029\n    \n    \n      65\n      GCLSTM\n      0.3\n      4\n      4.0\n      linear\n      STGCN\n      1.267\n      0.041\n    \n    \n      66\n      GCLSTM\n      0.3\n      4\n      4.0\n      nearest\n      IT-STGCN\n      1.211\n      0.039\n    \n    \n      67\n      GCLSTM\n      0.3\n      4\n      4.0\n      nearest\n      STGCN\n      1.256\n      0.038\n    \n    \n      80\n      GConvGRU\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      81\n      GConvGRU\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      82\n      GConvGRU\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      83\n      GConvGRU\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      96\n      GConvLSTM\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.227\n      0.056\n    \n    \n      97\n      GConvLSTM\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.244\n      0.041\n    \n    \n      98\n      GConvLSTM\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.224\n      0.035\n    \n    \n      99\n      GConvLSTM\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.266\n      0.068\n    \n    \n      112\n      LRGCN\n      0.3\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.210\n      0.039\n    \n    \n      113\n      LRGCN\n      0.3\n      4\n      8.0\n      linear\n      STGCN\n      1.274\n      0.045\n    \n    \n      114\n      LRGCN\n      0.3\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.220\n      0.046\n    \n    \n      115\n      LRGCN\n      0.3\n      4\n      8.0\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      128\n      TGCN\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.280\n      0.070\n    \n    \n      129\n      TGCN\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.302\n      0.112\n    \n    \n      130\n      TGCN\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.248\n      0.074\n    \n    \n      131\n      TGCN\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.291\n      0.111\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.5\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.238\n      0.080\n    \n    \n      5\n      DCRNN\n      0.5\n      4\n      8.0\n      linear\n      STGCN\n      1.451\n      0.061\n    \n    \n      6\n      DCRNN\n      0.5\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.232\n      0.061\n    \n    \n      7\n      DCRNN\n      0.5\n      4\n      8.0\n      nearest\n      STGCN\n      1.447\n      0.073\n    \n    \n      8\n      DCRNN\n      0.6\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      139\n      TGCN\n      0.6\n      4\n      12.0\n      nearest\n      STGCN\n      1.301\n      0.090\n    \n    \n      140\n      TGCN\n      0.8\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.294\n      0.063\n    \n    \n      141\n      TGCN\n      0.8\n      4\n      12.0\n      linear\n      STGCN\n      1.289\n      0.065\n    \n    \n      142\n      TGCN\n      0.8\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.258\n      0.053\n    \n    \n      143\n      TGCN\n      0.8\n      4\n      12.0\n      nearest\n      STGCN\n      1.277\n      0.080\n    \n  \n\n108 rows × 8 columns\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\").\\\nquery(\"inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      DCRNN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.232\n      0.061\n    \n    \n      7\n      DCRNN\n      0.5\n      4\n      nearest\n      STGCN\n      1.447\n      0.073\n    \n    \n      10\n      DCRNN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.303\n      0.078\n    \n    \n      11\n      DCRNN\n      0.6\n      4\n      nearest\n      STGCN\n      1.509\n      0.068\n    \n    \n      14\n      DCRNN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.527\n      0.079\n    \n    \n      15\n      DCRNN\n      0.8\n      4\n      nearest\n      STGCN\n      1.616\n      0.075\n    \n    \n      22\n      DyGrEncoder\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.236\n      0.059\n    \n    \n      23\n      DyGrEncoder\n      0.5\n      4\n      nearest\n      STGCN\n      1.427\n      0.076\n    \n    \n      26\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.285\n      0.051\n    \n    \n      27\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.083\n    \n    \n      30\n      DyGrEncoder\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.476\n      0.098\n    \n    \n      31\n      DyGrEncoder\n      0.8\n      4\n      nearest\n      STGCN\n      1.614\n      0.096\n    \n    \n      38\n      EvolveGCNH\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.242\n      0.058\n    \n    \n      39\n      EvolveGCNH\n      0.5\n      4\n      nearest\n      STGCN\n      1.285\n      0.049\n    \n    \n      42\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.091\n    \n    \n      43\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      STGCN\n      1.284\n      0.066\n    \n    \n      46\n      EvolveGCNH\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.299\n      0.082\n    \n    \n      47\n      EvolveGCNH\n      0.8\n      4\n      nearest\n      STGCN\n      1.292\n      0.074\n    \n    \n      54\n      EvolveGCNO\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.254\n      0.037\n    \n    \n      55\n      EvolveGCNO\n      0.5\n      4\n      nearest\n      STGCN\n      1.274\n      0.080\n    \n    \n      58\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.267\n      0.067\n    \n    \n      59\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      STGCN\n      1.292\n      0.075\n    \n    \n      62\n      EvolveGCNO\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.312\n      0.073\n    \n    \n      63\n      EvolveGCNO\n      0.8\n      4\n      nearest\n      STGCN\n      1.334\n      0.144\n    \n    \n      70\n      GCLSTM\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.221\n      0.042\n    \n    \n      71\n      GCLSTM\n      0.5\n      4\n      nearest\n      STGCN\n      1.333\n      0.066\n    \n    \n      74\n      GCLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.042\n    \n    \n      75\n      GCLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.365\n      0.064\n    \n    \n      78\n      GCLSTM\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.352\n      0.050\n    \n    \n      79\n      GCLSTM\n      0.8\n      4\n      nearest\n      STGCN\n      1.396\n      0.079\n    \n    \n      86\n      GConvGRU\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.507\n      0.235\n    \n    \n      87\n      GConvGRU\n      0.5\n      4\n      nearest\n      STGCN\n      1.673\n      0.223\n    \n    \n      90\n      GConvGRU\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      91\n      GConvGRU\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254\n    \n    \n      94\n      GConvGRU\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.608\n      0.243\n    \n    \n      95\n      GConvGRU\n      0.8\n      4\n      nearest\n      STGCN\n      1.871\n      0.214\n    \n    \n      102\n      GConvLSTM\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.235\n      0.042\n    \n    \n      103\n      GConvLSTM\n      0.5\n      4\n      nearest\n      STGCN\n      1.283\n      0.071\n    \n    \n      106\n      GConvLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.045\n    \n    \n      107\n      GConvLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.274\n      0.078\n    \n    \n      110\n      GConvLSTM\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.287\n      0.065\n    \n    \n      111\n      GConvLSTM\n      0.8\n      4\n      nearest\n      STGCN\n      1.364\n      0.069\n    \n    \n      115\n      GNAR\n      0.5\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      117\n      GNAR\n      0.6\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      119\n      GNAR\n      0.8\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      126\n      LRGCN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.240\n      0.036\n    \n    \n      127\n      LRGCN\n      0.5\n      4\n      nearest\n      STGCN\n      1.379\n      0.079\n    \n    \n      130\n      LRGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.286\n      0.033\n    \n    \n      131\n      LRGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.462\n      0.084\n    \n    \n      134\n      LRGCN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.436\n      0.091\n    \n    \n      135\n      LRGCN\n      0.8\n      4\n      nearest\n      STGCN\n      1.529\n      0.071\n    \n    \n      142\n      TGCN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.066\n    \n    \n      143\n      TGCN\n      0.5\n      4\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      146\n      TGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.072\n    \n    \n      147\n      TGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.301\n      0.090\n    \n    \n      150\n      TGCN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.258\n      0.053\n    \n    \n      151\n      TGCN\n      0.8\n      4\n      nearest\n      STGCN\n      1.277\n      0.080"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-2",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.154\n      0.014\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.248\n      0.019\n    \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.167\n      0.040\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.222\n      0.054\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.259\n      0.085\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.246\n      0.073\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.246\n      0.034\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.031\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.211\n      0.023\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.069\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.223\n      0.042\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046\n    \n    \n      28\n      GNAR\n      0.286\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      29\n      GNAR\n      0.286\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      30\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.169\n      0.040\n    \n    \n      31\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.204\n      0.032\n    \n    \n      32\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      33\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033\n    \n    \n      34\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.056\n    \n    \n      35\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.244\n      0.071\n    \n    \n      36\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      37\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).\\\nquery(\"lags==4 and inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046\n    \n    \n      29\n      GNAR\n      0.286\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      32\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      33\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033\n    \n    \n      36\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      37\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#w_st",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#w_st",
    "title": "Data management for ITSTGCN",
    "section": "W_st",
    "text": "W_st\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate==0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.153\n      0.036\n    \n    \n      1\n      DCRNN\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.053\n    \n    \n      2\n      DCRNN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.154\n      0.038\n    \n    \n      3\n      DCRNN\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.068\n    \n    \n      8\n      DyGrEncoder\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.222\n      0.083\n    \n    \n      9\n      DyGrEncoder\n      0.3\n      4\n      linear\n      STGCN\n      1.276\n      0.058\n    \n    \n      10\n      DyGrEncoder\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.091\n    \n    \n      11\n      DyGrEncoder\n      0.3\n      4\n      nearest\n      STGCN\n      1.281\n      0.068\n    \n    \n      16\n      EvolveGCNH\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.218\n      0.058\n    \n    \n      17\n      EvolveGCNH\n      0.3\n      4\n      linear\n      STGCN\n      1.237\n      0.051\n    \n    \n      18\n      EvolveGCNH\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.068\n    \n    \n      19\n      EvolveGCNH\n      0.3\n      4\n      nearest\n      STGCN\n      1.237\n      0.058\n    \n    \n      24\n      EvolveGCNO\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.223\n      0.041\n    \n    \n      25\n      EvolveGCNO\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.048\n    \n    \n      26\n      EvolveGCNO\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.234\n      0.046\n    \n    \n      27\n      EvolveGCNO\n      0.3\n      4\n      nearest\n      STGCN\n      1.252\n      0.071\n    \n    \n      32\n      GCLSTM\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.191\n      0.041\n    \n    \n      33\n      GCLSTM\n      0.3\n      4\n      linear\n      STGCN\n      1.264\n      0.041\n    \n    \n      34\n      GCLSTM\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.193\n      0.033\n    \n    \n      35\n      GCLSTM\n      0.3\n      4\n      nearest\n      STGCN\n      1.250\n      0.049\n    \n    \n      40\n      GConvGRU\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      41\n      GConvGRU\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      42\n      GConvGRU\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      43\n      GConvGRU\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      48\n      GConvLSTM\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.340\n      0.166\n    \n    \n      49\n      GConvLSTM\n      0.3\n      4\n      linear\n      STGCN\n      1.392\n      0.109\n    \n    \n      50\n      GConvLSTM\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.368\n      0.158\n    \n    \n      51\n      GConvLSTM\n      0.3\n      4\n      nearest\n      STGCN\n      1.338\n      0.118\n    \n    \n      56\n      LRGCN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.299\n      0.147\n    \n    \n      57\n      LRGCN\n      0.3\n      4\n      linear\n      STGCN\n      1.325\n      0.086\n    \n    \n      58\n      LRGCN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.117\n    \n    \n      59\n      LRGCN\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.087\n    \n    \n      64\n      TGCN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.320\n      0.164\n    \n    \n      65\n      TGCN\n      0.3\n      4\n      linear\n      STGCN\n      1.287\n      0.126\n    \n    \n      66\n      TGCN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.276\n      0.105\n    \n    \n      67\n      TGCN\n      0.3\n      4\n      nearest\n      STGCN\n      1.313\n      0.101\n    \n  \n\n\n\n\n\n테이블 정리용\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      DCRNN\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      37\n      GCLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      45\n      GConvGRU\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      53\n      GConvLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      61\n      LRGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      69\n      TGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"method !='STGCN' and lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"method !='STGCN' and lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      8\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      24\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.294\n      0.056\n    \n    \n      40\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.279\n      0.057\n    \n    \n      56\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.065\n    \n    \n      72\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.040\n    \n    \n      88\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      104\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.255\n      0.049\n    \n    \n      116\n      GNAR\n      0.6\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      128\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.286\n      0.053\n    \n    \n      144\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.257\n      0.048\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate == 0.6\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      DCRNN\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      6\n      DCRNN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.079\n    \n    \n      7\n      DCRNN\n      0.6\n      4\n      nearest\n      STGCN\n      1.552\n      0.087\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      14\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.305\n      0.131\n    \n    \n      15\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.073\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      22\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.246\n      0.067\n    \n    \n      23\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      STGCN\n      1.291\n      0.063\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      30\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.072\n    \n    \n      31\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      STGCN\n      1.321\n      0.094\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      37\n      GCLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      38\n      GCLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.044\n    \n    \n      39\n      GCLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.355\n      0.068\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      45\n      GConvGRU\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      46\n      GConvGRU\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      47\n      GConvGRU\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      53\n      GConvLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      54\n      GConvLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.313\n      0.205\n    \n    \n      55\n      GConvLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.503\n      0.101\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      61\n      LRGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      62\n      LRGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.331\n      0.120\n    \n    \n      63\n      LRGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.453\n      0.115\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      69\n      TGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n    \n      70\n      TGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.338\n      0.202\n    \n    \n      71\n      TGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.297\n      0.093\n    \n  \n\n\n\n\n\nconclusion table\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      28\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      29\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      32\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      33\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.143\n      0.011\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.310\n      0.019\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.204\n      0.063\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.043\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.037\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.240\n      0.062\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.033\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.241\n      0.095\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.185\n      0.035\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.249\n      0.027\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.310\n      0.151\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.459\n      0.153\n    \n    \n      28\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      29\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      30\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.106\n    \n    \n      31\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.347\n      0.117\n    \n    \n      32\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      33\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n    \n      34\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.237\n      0.083\n    \n    \n      35\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.258\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-3",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='wikimath' and mrate==0\").groupby(['model','lags','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mrate==0\").groupby(['model','lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      8\n      12.0\n      IT-STGCN\n      0.582\n      0.006\n    \n    \n      1\n      DCRNN\n      8\n      12.0\n      STGCN\n      0.580\n      0.006\n    \n    \n      2\n      DyGrEncoder\n      8\n      12.0\n      IT-STGCN\n      0.563\n      0.030\n    \n    \n      3\n      DyGrEncoder\n      8\n      12.0\n      STGCN\n      0.560\n      0.029\n    \n    \n      4\n      EvolveGCNH\n      8\n      12.0\n      IT-STGCN\n      0.784\n      0.027\n    \n    \n      5\n      EvolveGCNH\n      8\n      12.0\n      STGCN\n      0.771\n      0.028\n    \n    \n      6\n      EvolveGCNO\n      8\n      12.0\n      IT-STGCN\n      0.735\n      0.023\n    \n    \n      7\n      EvolveGCNO\n      8\n      12.0\n      STGCN\n      0.734\n      0.025\n    \n    \n      8\n      GCLSTM\n      8\n      64.0\n      IT-STGCN\n      0.643\n      0.024\n    \n    \n      9\n      GCLSTM\n      8\n      64.0\n      STGCN\n      0.645\n      0.018\n    \n    \n      10\n      GConvGRU\n      8\n      12.0\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      11\n      GConvGRU\n      8\n      12.0\n      STGCN\n      0.528\n      0.003\n    \n    \n      12\n      GConvLSTM\n      8\n      64.0\n      IT-STGCN\n      0.626\n      0.015\n    \n    \n      13\n      GConvLSTM\n      8\n      64.0\n      STGCN\n      0.640\n      0.031\n    \n    \n      14\n      LRGCN\n      8\n      32.0\n      IT-STGCN\n      0.610\n      0.017\n    \n    \n      15\n      LRGCN\n      8\n      32.0\n      STGCN\n      0.608\n      0.014\n    \n    \n      16\n      TGCN\n      8\n      12.0\n      IT-STGCN\n      0.730\n      0.030\n    \n    \n      17\n      TGCN\n      8\n      12.0\n      STGCN\n      0.732\n      0.035"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-3",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='GConvGRU'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==64 and lags==8 and epoch==50 and model=='GConvLSTM'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==64 and lags==8 and epoch==50 and model=='GCLSTM'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==32 and lags==8 and epoch==50 and model=='LRGCN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='DyGrEncoder'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50 and model=='EvolveGCNH'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50 and model=='EvolveGCNO'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='TGCN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='DCRNN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    # ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate == 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.588\n      0.007\n    \n    \n      1\n      DCRNN\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.603\n      0.010\n    \n    \n      4\n      DyGrEncoder\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.578\n      0.031\n    \n    \n      5\n      DyGrEncoder\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.562\n      0.016\n    \n    \n      8\n      EvolveGCNH\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.775\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.787\n      0.024\n    \n    \n      12\n      EvolveGCNO\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.738\n      0.018\n    \n    \n      13\n      EvolveGCNO\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.743\n      0.024\n    \n    \n      16\n      GCLSTM\n      0.3\n      8\n      64.0\n      linear\n      IT-STGCN\n      0.628\n      0.020\n    \n    \n      17\n      GCLSTM\n      0.3\n      8\n      64.0\n      linear\n      STGCN\n      0.674\n      0.020\n    \n    \n      20\n      GConvGRU\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      21\n      GConvGRU\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.570\n      0.006\n    \n    \n      28\n      GConvLSTM\n      0.3\n      8\n      64.0\n      linear\n      IT-STGCN\n      0.631\n      0.019\n    \n    \n      29\n      GConvLSTM\n      0.3\n      8\n      64.0\n      linear\n      STGCN\n      0.764\n      0.057\n    \n    \n      32\n      LRGCN\n      0.3\n      8\n      32.0\n      linear\n      IT-STGCN\n      0.619\n      0.019\n    \n    \n      33\n      LRGCN\n      0.3\n      8\n      32.0\n      linear\n      STGCN\n      0.689\n      0.032\n    \n    \n      36\n      TGCN\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.739\n      0.040\n    \n    \n      37\n      TGCN\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.734\n      0.027\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.672\n      0.007\n    \n    \n      3\n      DCRNN\n      0.8\n      8\n      linear\n      STGCN\n      0.846\n      0.031\n    \n    \n      6\n      DyGrEncoder\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.606\n      0.017\n    \n    \n      7\n      DyGrEncoder\n      0.8\n      8\n      linear\n      STGCN\n      0.770\n      0.045\n    \n    \n      10\n      EvolveGCNH\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.877\n      0.045\n    \n    \n      11\n      EvolveGCNH\n      0.8\n      8\n      linear\n      STGCN\n      0.915\n      0.063\n    \n    \n      14\n      EvolveGCNO\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.780\n      0.027\n    \n    \n      15\n      EvolveGCNO\n      0.8\n      8\n      linear\n      STGCN\n      0.863\n      0.038\n    \n    \n      18\n      GCLSTM\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.815\n      0.058\n    \n    \n      19\n      GCLSTM\n      0.8\n      8\n      linear\n      STGCN\n      1.407\n      0.117\n    \n    \n      22\n      GConvGRU\n      0.5\n      8\n      linear\n      IT-STGCN\n      0.524\n      0.003\n    \n    \n      23\n      GConvGRU\n      0.5\n      8\n      linear\n      STGCN\n      0.658\n      0.010\n    \n    \n      24\n      GConvGRU\n      0.6\n      8\n      linear\n      IT-STGCN\n      0.539\n      0.004\n    \n    \n      25\n      GConvGRU\n      0.6\n      8\n      linear\n      STGCN\n      0.731\n      0.015\n    \n    \n      26\n      GConvGRU\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      27\n      GConvGRU\n      0.8\n      8\n      linear\n      STGCN\n      0.932\n      0.043\n    \n    \n      30\n      GConvLSTM\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.920\n      0.069\n    \n    \n      31\n      GConvLSTM\n      0.8\n      8\n      linear\n      STGCN\n      1.423\n      0.121\n    \n    \n      33\n      GNAR\n      0.8\n      8\n      linear\n      GNAR\n      1.354\n      0.000\n    \n    \n      36\n      LRGCN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.769\n      0.045\n    \n    \n      37\n      LRGCN\n      0.8\n      8\n      linear\n      STGCN\n      1.105\n      0.099\n    \n    \n      40\n      TGCN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.771\n      0.020\n    \n    \n      41\n      TGCN\n      0.8\n      8\n      linear\n      STGCN\n      0.827\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-3",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.583\n      0.006\n    \n    \n      1\n      DCRNN\n      0.120\n      8\n      linear\n      STGCN\n      0.578\n      0.005\n    \n    \n      2\n      DyGrEncoder\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.563\n      0.025\n    \n    \n      3\n      DyGrEncoder\n      0.120\n      8\n      linear\n      STGCN\n      0.546\n      0.016\n    \n    \n      4\n      EvolveGCNH\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.776\n      0.028\n    \n    \n      5\n      EvolveGCNH\n      0.120\n      8\n      linear\n      STGCN\n      0.773\n      0.021\n    \n    \n      6\n      EvolveGCNO\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.732\n      0.025\n    \n    \n      7\n      EvolveGCNO\n      0.120\n      8\n      linear\n      STGCN\n      0.735\n      0.022\n    \n    \n      8\n      GCLSTM\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.640\n      0.019\n    \n    \n      9\n      GCLSTM\n      0.120\n      8\n      linear\n      STGCN\n      0.638\n      0.013\n    \n    \n      10\n      GConvGRU\n      0.004\n      8\n      linear\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      11\n      GConvGRU\n      0.004\n      8\n      linear\n      STGCN\n      0.528\n      0.003\n    \n    \n      12\n      GConvGRU\n      0.096\n      8\n      linear\n      IT-STGCN\n      0.529\n      0.004\n    \n    \n      13\n      GConvGRU\n      0.096\n      8\n      linear\n      STGCN\n      0.544\n      0.011\n    \n    \n      14\n      GConvGRU\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.523\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.120\n      8\n      linear\n      STGCN\n      0.531\n      0.002\n    \n    \n      16\n      GConvLSTM\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.627\n      0.014\n    \n    \n      17\n      GConvLSTM\n      0.120\n      8\n      linear\n      STGCN\n      0.660\n      0.034\n    \n    \n      18\n      GNAR\n      0.120\n      8\n      linear\n      GNAR\n      1.354\n      0.000\n    \n    \n      19\n      LRGCN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.608\n      0.012\n    \n    \n      20\n      LRGCN\n      0.120\n      8\n      linear\n      STGCN\n      0.624\n      0.024\n    \n    \n      21\n      TGCN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.748\n      0.046\n    \n    \n      22\n      TGCN\n      0.120\n      8\n      linear\n      STGCN\n      0.741\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#missing-values-on-the-same-nodes",
    "title": "Data management for ITSTGCN",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(df2.query(\"dataset=='wikimath'\").groupby(['model','mrate','lags','method'])['mse'].mean().reset_index(),\n        df2.query(\"dataset=='wikimath'\").groupby(['model','mrate','lags','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.512\n      8\n      IT-STGCN\n      0.592\n      0.005\n    \n    \n      1\n      DCRNN\n      0.512\n      8\n      STGCN\n      0.665\n      0.015\n    \n    \n      2\n      DyGrEncoder\n      0.512\n      8\n      IT-STGCN\n      0.561\n      0.031\n    \n    \n      3\n      DyGrEncoder\n      0.512\n      8\n      STGCN\n      0.626\n      0.027\n    \n    \n      4\n      EvolveGCNH\n      0.512\n      8\n      IT-STGCN\n      0.794\n      0.031\n    \n    \n      5\n      EvolveGCNH\n      0.512\n      8\n      STGCN\n      0.818\n      0.031\n    \n    \n      6\n      EvolveGCNO\n      0.512\n      8\n      IT-STGCN\n      0.745\n      0.017\n    \n    \n      7\n      EvolveGCNO\n      0.512\n      8\n      STGCN\n      0.753\n      0.026\n    \n    \n      8\n      GCLSTM\n      0.512\n      8\n      IT-STGCN\n      0.617\n      0.011\n    \n    \n      9\n      GCLSTM\n      0.512\n      8\n      STGCN\n      0.823\n      0.048\n    \n    \n      10\n      GConvGRU\n      0.512\n      8\n      IT-STGCN\n      0.533\n      0.003\n    \n    \n      11\n      GConvGRU\n      0.512\n      8\n      STGCN\n      0.726\n      0.015\n    \n    \n      12\n      GConvLSTM\n      0.512\n      8\n      IT-STGCN\n      0.653\n      0.033\n    \n    \n      13\n      GConvLSTM\n      0.512\n      8\n      STGCN\n      0.963\n      0.098\n    \n    \n      14\n      GNAR\n      0.512\n      8\n      GNAR\n      1.354\n      0.000\n    \n    \n      15\n      LRGCN\n      0.512\n      8\n      IT-STGCN\n      0.624\n      0.019\n    \n    \n      16\n      LRGCN\n      0.512\n      8\n      STGCN\n      0.810\n      0.064\n    \n    \n      17\n      TGCN\n      0.512\n      8\n      IT-STGCN\n      0.750\n      0.039\n    \n    \n      18\n      TGCN\n      0.512\n      8\n      STGCN\n      0.782\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-4",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['model','lags'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['model','lags'])['mse'].std().reset_index(),\n         on=['model','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      GCLSTM\n      8\n      0.993\n      0.013\n    \n    \n      1\n      GConvGRU\n      8\n      1.003\n      0.004\n    \n    \n      2\n      GConvLSTM\n      8\n      1.019\n      0.045\n    \n    \n      3\n      GNAR\n      8\n      1.649\n      0.000"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-4",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ((ax1)) = plt.subplots(nrows=1, ncols=1, figsize=(50, 6), sharey=True)\ndf.query(\"dataset=='windmillsmall' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax1,grid=False,widths=0.5)\n\n<Axes: title={'center': 'mse'}, xlabel='[model, mrate, method]'>\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.085\n      0.040\n    \n    \n      1\n      DCRNN\n      0.7\n      8\n      linear\n      STGCN\n      1.375\n      0.024\n    \n    \n      2\n      GCLSTM\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.116\n      0.021\n    \n    \n      3\n      GCLSTM\n      0.7\n      8\n      linear\n      STGCN\n      1.574\n      0.104\n    \n    \n      4\n      GConvGRU\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.194\n      0.042\n    \n    \n      5\n      GConvGRU\n      0.7\n      8\n      linear\n      STGCN\n      1.662\n      0.073\n    \n    \n      6\n      GConvLSTM\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.142\n      0.021\n    \n    \n      7\n      GConvLSTM\n      0.7\n      8\n      linear\n      STGCN\n      1.600\n      0.056\n    \n    \n      8\n      GNAR\n      0.7\n      8\n      nearest\n      GNAR\n      1.649\n      0.000"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-4",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['model','mrate','nof_filters','lags','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['model','mrate','nof_filters','lags','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      GCLSTM\n      0.081\n      16.0\n      8\n      IT-STGCN\n      0.985\n      0.002\n    \n    \n      1\n      GCLSTM\n      0.081\n      16.0\n      8\n      STGCN\n      0.985\n      0.002\n    \n    \n      2\n      GConvGRU\n      0.081\n      12.0\n      8\n      IT-STGCN\n      1.007\n      0.005\n    \n    \n      3\n      GConvGRU\n      0.081\n      12.0\n      8\n      STGCN\n      1.008\n      0.006\n    \n    \n      4\n      GConvLSTM\n      0.081\n      16.0\n      8\n      IT-STGCN\n      0.997\n      0.022\n    \n    \n      5\n      GConvLSTM\n      0.081\n      16.0\n      8\n      STGCN\n      0.989\n      0.009"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-5",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='monte' and mrate==0\").groupby(['model','lags'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mrate==0\").groupby(['model','lags'])['mse'].std().reset_index(),\n         on=['model','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      4\n      0.936\n      0.002\n    \n    \n      1\n      DyGrEncoder\n      4\n      0.995\n      0.034\n    \n    \n      2\n      EvolveGCNH\n      4\n      1.182\n      0.192\n    \n    \n      3\n      EvolveGCNO\n      4\n      1.157\n      0.182\n    \n    \n      4\n      GCLSTM\n      4\n      0.970\n      0.011\n    \n    \n      5\n      GConvGRU\n      4\n      0.931\n      0.002\n    \n    \n      6\n      GConvLSTM\n      4\n      0.960\n      0.011\n    \n    \n      7\n      GNAR\n      4\n      1.062\n      0.000\n    \n    \n      8\n      LRGCN\n      4\n      0.980\n      0.024\n    \n    \n      9\n      TGCN\n      4\n      0.983\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-5",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ((ax1)) = plt.subplots(nrows=1, ncols=1, figsize=(50, 6), sharey=True)\ndf.query(\"dataset=='monte' and mtype=='rand' and inter_method == 'nearest' and lags==4 and epoch==50\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax1,grid=False,widths=0.5)\n\n<Axes: title={'center': 'mse'}, xlabel='[model, mrate, method]'>\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='monte' and mtype=='rand'\").groupby(['model','mrate','nof_filters','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='rand'\").groupby(['model','mrate','nof_filters','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','mrate','nof_filters','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.111\n      0.036\n    \n    \n      1\n      DCRNN\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.225\n      0.073\n    \n    \n      2\n      DyGrEncoder\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.216\n      0.118\n    \n    \n      3\n      DyGrEncoder\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.358\n      0.149\n    \n    \n      4\n      EvolveGCNH\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.845\n      0.504\n    \n    \n      5\n      EvolveGCNH\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      2.158\n      0.545\n    \n    \n      6\n      EvolveGCNO\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      2.263\n      0.476\n    \n    \n      7\n      EvolveGCNO\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      2.623\n      0.693\n    \n    \n      8\n      GCLSTM\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.968\n      0.013\n    \n    \n      9\n      GCLSTM\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      1.003\n      0.016\n    \n    \n      10\n      GCLSTM\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.957\n      0.008\n    \n    \n      11\n      GCLSTM\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.074\n      0.040\n    \n    \n      12\n      GCLSTM\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.001\n      0.010\n    \n    \n      13\n      GCLSTM\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.131\n      0.070\n    \n    \n      14\n      GCLSTM\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.032\n      0.028\n    \n    \n      15\n      GCLSTM\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.140\n      0.061\n    \n    \n      16\n      GConvGRU\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.936\n      0.002\n    \n    \n      17\n      GConvGRU\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      0.991\n      0.007\n    \n    \n      18\n      GConvGRU\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.942\n      0.003\n    \n    \n      19\n      GConvGRU\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.149\n      0.018\n    \n    \n      20\n      GConvGRU\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.015\n      0.012\n    \n    \n      21\n      GConvGRU\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.393\n      0.028\n    \n    \n      22\n      GConvGRU\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.096\n      0.019\n    \n    \n      23\n      GConvGRU\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.516\n      0.040\n    \n    \n      24\n      GConvLSTM\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.951\n      0.009\n    \n    \n      25\n      GConvLSTM\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      0.981\n      0.020\n    \n    \n      26\n      GConvLSTM\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.947\n      0.006\n    \n    \n      27\n      GConvLSTM\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.055\n      0.030\n    \n    \n      28\n      GConvLSTM\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.997\n      0.013\n    \n    \n      29\n      GConvLSTM\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.121\n      0.065\n    \n    \n      30\n      GConvLSTM\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.156\n      0.062\n    \n    \n      31\n      GConvLSTM\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.134\n      0.069\n    \n    \n      32\n      LRGCN\n      0.8\n      2.0\n      4\n      nearest\n      IT-STGCN\n      0.982\n      0.013\n    \n    \n      33\n      LRGCN\n      0.8\n      2.0\n      4\n      nearest\n      STGCN\n      0.989\n      0.029\n    \n    \n      34\n      TGCN\n      0.8\n      8.0\n      4\n      nearest\n      IT-STGCN\n      1.073\n      0.024\n    \n    \n      35\n      TGCN\n      0.8\n      8.0\n      4\n      nearest\n      STGCN\n      1.218\n      0.086"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-5",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.940\n      0.001\n    \n    \n      1\n      DCRNN\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.003\n    \n    \n      2\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.005\n      0.046\n    \n    \n      3\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      STGCN\n      1.030\n      0.044\n    \n    \n      4\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.392\n      0.110\n    \n    \n      5\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      STGCN\n      1.612\n      0.216\n    \n    \n      6\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.345\n      0.110\n    \n    \n      7\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      STGCN\n      1.766\n      0.123\n    \n    \n      8\n      GCLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.959\n      0.008\n    \n    \n      9\n      GCLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.005\n    \n    \n      10\n      GConvGRU\n      0.149\n      4\n      cubic\n      IT-STGCN\n      1.023\n      0.021\n    \n    \n      11\n      GConvGRU\n      0.149\n      4\n      cubic\n      STGCN\n      1.028\n      0.031\n    \n    \n      12\n      GConvGRU\n      0.149\n      4\n      linear\n      IT-STGCN\n      0.930\n      0.002\n    \n    \n      13\n      GConvGRU\n      0.149\n      4\n      linear\n      STGCN\n      0.935\n      0.005\n    \n    \n      14\n      GConvGRU\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.932\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.149\n      4\n      nearest\n      STGCN\n      0.935\n      0.004\n    \n    \n      16\n      GConvLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.949\n      0.008\n    \n    \n      17\n      GConvLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.950\n      0.005\n    \n    \n      18\n      GNAR\n      0.149\n      4\n      nearest\n      GNAR\n      1.062\n      0.000\n    \n    \n      19\n      LRGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.978\n      0.024\n    \n    \n      20\n      LRGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.977\n      0.020\n    \n    \n      21\n      TGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      22\n      TGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.985\n      0.005\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.940\n      0.001\n    \n    \n      1\n      DCRNN\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.003\n    \n    \n      2\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.005\n      0.046\n    \n    \n      3\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      STGCN\n      1.030\n      0.044\n    \n    \n      4\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.392\n      0.110\n    \n    \n      5\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      STGCN\n      1.612\n      0.216\n    \n    \n      6\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.345\n      0.110\n    \n    \n      7\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      STGCN\n      1.766\n      0.123\n    \n    \n      8\n      GCLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.959\n      0.008\n    \n    \n      9\n      GCLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.005\n    \n    \n      14\n      GConvGRU\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.932\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.149\n      4\n      nearest\n      STGCN\n      0.935\n      0.004\n    \n    \n      16\n      GConvLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.949\n      0.008\n    \n    \n      17\n      GConvLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.950\n      0.005\n    \n    \n      18\n      GNAR\n      0.149\n      4\n      nearest\n      GNAR\n      1.062\n      0.000\n    \n    \n      19\n      LRGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.978\n      0.024\n    \n    \n      20\n      LRGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.977\n      0.020\n    \n    \n      21\n      TGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      22\n      TGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.985\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-07-18-EbayesThresh toy ex.html",
    "href": "posts/GCN/2023-07-18-EbayesThresh toy ex.html",
    "title": "EbayesThresh Toy ex",
    "section": "",
    "text": "Import\n\nfrom itstgcn.learners import * \n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\n\n\nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nWhile \\({\\bf p}_y\\) serves as a consistent estimator for \\(\\mathbb{E}[|{\\bf V}^H{\\bf y}|^2]\\), it is not an efficient estimator, and therefore, improvement is needed [@djuric2018cooperative]. The traditional approach for improvement is to use the windowed periodogram.\nThe windowed periodogram is efficient in detecting specific frequencies or periods, but it may not be as efficient in estimating the underlying function. One notable paper that utilized the windowed periodogram is the one that detected the El Niño phenomenon.\nAs this structure exhibits a “sparse signal + heavy-tailed” characteristics, by applying Bayesian modeling and thresholding \\({\\bf p}_y\\), we can estimate an appropriate \\({\\bf p}_{pp}\\) as discussed in [@johnstone2004needles].\n\n\n\nBayesian Model\n\\(x_i \\sim N(\\mu_i,1)\\)\n확률변수가 잘 정의되어 있을때, 여기서 \\(\\mu_i\\)를 정하는 Baysian.\n\n\\(\\mu_i \\sim\\) 사전분포(\\(\\mu_i\\)를 뽑을 수 있는)\n\\((\\mu_i | X_i = x_i)^n_{i=1} \\sim\\) 사후분포\n\nex) \\(N(10,1) \\sim\\) 사전분포\n관측치\n\n_obs = [7.1,6.9,8.5]\n\n\nnp.mean(_obs)\n\n7.5\n\n\n관측치를 보니 평균이 10이 아닌 것 같다.\n\\(N(10-3,1) \\sim\\) 사후분포\n\n여기서, \\(10-3\\)이 posterior meman\n사후 분포를 정의할때, 이벤트의 mean이냐, median이냐로 잡는 방법은 정해진 것이 아니다.(이베이즈에서는 median으로 잡음)\n\nEbayes는 사전분포를 Heavy-tail으로 정의했다.\nheavy tail?\n\n\n\nimage.png\n\n\n\\(\\mu_x \\sim\\) Double Exponential \\(= p_{pp} + p_{ac}\\) -> 혼합형(misture) = pure point + absolutely continuous\n\\(E(\\mu_i | X_i = x_i) = \\hat{\\mu}_i\\) -> thresholding의 결과\n\\(f_{prior}(\\mu) = (1-w)\\delta_0(\\mu) + w \\gamma (\\mu)\\)\n\n\\(\\delta_0\\) = 디렉함수(특정값이 아니면 다 0으로 봄)\n\\(\\gamma = \\frac{a}{2} e^{-a|\\mu|}\\)\n\nEbayes의 역할 = 자동으로 \\(w\\)를 계산 혹은 추정\n\n\\(1-w\\) 확률로 \\(\\delta_0\\)를 정의, \\(w\\)의 확룔로 \\(\\gamma\\)를 정의.\n\n\\(X_i = \\mu_i + \\epsilon_i, \\epsilon_i \\sim N(0,1)\\)에서 \\(\\mu_i\\)를 찾는게 목적이다. 이게 바로 \\(\\eta\\)값\n\nEbayes로 sparse signal만 골러낼 것이다.\n평균 이상의 값에서 자를 것이다.\n\nthresh(임계치)를 잡는 게 어려울 텐데, 위에서 이베이즈가 \\(w\\)를 자동으로 잡아 확률 계산되는 방법론을 제안한 것,\n\nbaysian modeling 사용하여 heavy tail + impulse(sparse)에서 posterior median 추정하여 임계값thresh으로 \\(p\\)에서 \\(p_{pp}\\)를 추출하는 것이 GODE 목적\n\n\n\nEbayesThresh\n\nT = 100\n\n\nt = np.arange(T)/T * 10\n\n\ny_true = 3*np.sin(0.5*t) + 1.2*np.sin(1.0*t) + 0.5*np.sin(1.2*t) \n\n\ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y_true)\n\n\n\n\n- 관찰한 신호\n\nplt.plot(t,y,'o')\nplt.plot(t,y_true,'--')\n\n\n\n\n- 퓨리에 변환\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nplt.plot(t,fbar**2) # periodogram \n\n\n\n\n- threshed\n\nfbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\nplt.plot((fbar**2)) # periodogram \nplt.plot((fbar_threshed**2)) \n\n\n\n\n\nplt.plot((fbar**2)[20:80]) # periodogram \nplt.plot((fbar_threshed**2)[20:80]) \n\n\n\n\n- 역퓨리에변환\n\nyhat = Psi @ fbar_threshed # inverse dft\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y,'.')\nplt.plot(t,y_true,'--')\nplt.plot(t,yhat)\n\n\n\n\n\nplt.figure(figsize=(10,6))\nplt.plot(y,'.')\nplt.plot(y_true)\n\n\n\n\n\n\nResult\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(40,15))\n    fig.suptitle('Figure 1',fontsize=40)\n    \n    ax1.plot(y, 'b.',alpha=0.5)\n    ax1.plot(y_true,'p--',label='True')\n    ax1.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    \n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(y, 'b.',alpha=0.5)\n    ax2.plot(y_true,'p--',label='True')\n    ax2.plot(yhat,label='y hat')\n    ax2.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot((fbar**2)) # periodogram \n    ax3.plot((fbar_threshed**2)) \n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    ax3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n    \n    ax4.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \n    ax4.plot(range(20, 80),(fbar_threshed**2)[20:80]) \n    ax4.set_xticks(range(20, 81, 10))\n    ax4.set_xticklabels(range(20, 81, 10))\n    # ax4.set_xticklabels(['20','40','60'])\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\n\n\n\nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset, inset_axes\nplt.figure(figsize = (20,10))\nplt.suptitle('Figure',fontsize=40)\nax = plt.subplot(1, 1, 1)\nax.plot(range(0,100),(fbar**2))\nax.plot((fbar_threshed**2)) \naxins = inset_axes(ax, 8, 3, loc = 1, bbox_to_anchor=(0.8, 0.8),\n                   bbox_transform = ax.figure.transFigure)\naxins.plot(range(20, 80),(fbar**2)[20:80])\naxins.plot(range(20, 80),(fbar_threshed**2)[20:80]) \naxins.set_xlim(20, 80)\naxins.set_ylim(-0.1, 7)\nmark_inset(ax, axins, loc1=4, loc2=3, fc=\"none\", ec = \"0.01\")\nax.tick_params(axis='y', labelsize=20)\nax.tick_params(axis='x', labelsize=20)\naxins.tick_params(axis='y', labelsize=15)\naxins.tick_params(axis='x', labelsize=15)\n# plt.savefig('Ebayes_Toy.png')\n\n\n\n\n\nfrom matplotlib.patches import ConnectionPatch\nfig = plt.figure(figsize=(20,10))\nplt.suptitle('Figure 1',fontsize=40)\nplot1 = fig.add_subplot(2,2,(1,2))\n\nplot1.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \nplot1.plot(range(20, 80),(fbar_threshed**2)[20:80]) \nplot1.set_xticks(range(20, 81, 10))\nplot1.set_xticklabels(range(20, 81, 10))\nplot1.tick_params(axis='y', labelsize=20)\nplot1.tick_params(axis='x', labelsize=20)\n\nplot3 = fig.add_subplot(2,2,(3,4)) \n\nplot3.plot((fbar**2)) # periodogram \nplot3.plot((fbar_threshed**2)) \nplot3.tick_params(axis='y', labelsize=20)\nplot3.tick_params(axis='x', labelsize=20)\nplot3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n# plot3.fill_between((20, 80), 10, 60, facecolor= \"red\", alpha = 0.2)\nconn1 = ConnectionPatch(xyA = (20, -0.1), coordsA=plot1.transData,\n                       xyB=(20, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn1)\nconn2 = ConnectionPatch(xyA = (79, -0.1), coordsA=plot1.transData,\n                       xyB=(80, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn2)\nplt.show()\n\n\n\n\n\n\nIn article\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\nimport rpy2\n\n\nfrom rpy2.robjects.packages import importr\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n#import rpy2\n#import rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nGNAR = importr('GNAR') # import GNAR \n#igraph = importr('igraph') # import igraph \nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n%%R\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\n\n\\(X_i\\)에서 \\(\\mu_i\\) 추출 가능하는 것을 증명할 예제\n\n%%R\n# png(\"Ebayes_plot1.png\", width=1600, height=800)\npar(mfrow=c(1,2))\npar(cex.axis=2) \npar(cex.lab=2)\nplot(x, type='l', xlab=\"Observed data\", ylab=\"\")\nplot(ebayesthresh(x, sdev=1),type='l', xlab=\"Estimate\", ylab=\"\")\n# dev.off()\n\n\n\n\n\nimport itstgcn\n\n\nitstgcn.make_Psi(T)\n\narray([[ 0.07106691, -0.10050378,  0.10050378, ..., -0.10050378,\n        -0.10050378,  0.07106691],\n       [ 0.10050378, -0.14206225,  0.14184765, ...,  0.14184765,\n         0.14206225, -0.10050378],\n       [ 0.10050378, -0.14184765,  0.14099032, ..., -0.14099032,\n        -0.14184765,  0.10050378],\n       ...,\n       [ 0.10050378,  0.14184765,  0.14099032, ...,  0.14099032,\n        -0.14184765, -0.10050378],\n       [ 0.10050378,  0.14206225,  0.14184765, ..., -0.14184765,\n         0.14206225,  0.10050378],\n       [ 0.07106691,  0.10050378,  0.10050378, ...,  0.10050378,\n        -0.10050378, -0.07106691]])\n\n\ndef trim(f):\n    f = np.array(f)\n    if len(f.shape)==1: f = f.reshape(-1,1)\n    T,N = f.shape\n    Psi = make_Psi(T)\n    fbar = Psi.T @ f # apply dft \n    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n    fhat = Psi @ fbar_threshed # inverse dft \n    return fhat\n\nplt.plot(y)\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T).T@y)\n\n\n\n\n\nplt.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T)@ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\n_T = 1000\n\n\n_t = np.arange(_T)/_T * 10\n\n\n_x = 1.5*np.sin(2*_t)+2*np.random.rand(_T)+1.5*np.sin(4*_t)+1.5*np.sin(8*_t)\nplt.plot(_x)\n\n\n\n\n\nimport itstgcn\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\n_node_ids = {'node1':0,'node2':1}\n\n_FX1 = np.stack([_x,_x],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\ndata1 = pd.DataFrame({'x':_x,'x1':_x,'xer':_x,'xer1':_x})\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=2)\n\n\nmindex = itstgcn.rand_mindex(dataset,mrate=0.7)\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\nPsi\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fst.pdf', format='pdf')\n\n\n\n\nfourier transform\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem(itstgcn.make_Psi(_T).T@np.array(_x),linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem((itstgcn.make_Psi(_T).T@np.array(_x))[:100],linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd_zin.pdf', format='pdf')\n\n\n\n\nEbayesthresh/trim\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem((ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))))[:100],linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd_zout.pdf', format='pdf')\n\n\n\n\nfhat\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3,alpha=0.3)\n    ax1.plot(itstgcn.make_Psi(_T)@ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='Inverse Fourier Transform',lw=5)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fth.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_fst.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax2 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data',markersize=15)\n    ax2.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=40)\n    ax2.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_snd.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax3 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=40)\n    ax3.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_3rd.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax4 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(138, -1.2, 'o', markersize=230, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(220, -1.5, 'o', markersize=200, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(290, -1.2, 'o', markersize=310, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(455, -0.9, 'o', markersize=280, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=40)\n    ax4.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_4th_1.png')\n\n\n\n\n\n\nFor Paper\n\nT = 500\n\n\nt = np.arange(T)/T * 10\n\n\ny_true = 3*np.sin(0.5*t) + 1.2*np.sin(1.0*t) + 0.5*np.sin(1.2*t) \n\n\ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(20,10))\nplt.plot(t,y_true,color='red',label = 'true')\nplt.plot(t,y,'.',color='black',label = 'f')\nplt.legend(fontsize=15,loc='lower left',facecolor='white', frameon=True)\n# plt.savefig('1.png')\n\n\n\n\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nfbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n\n\nplt.figure(figsize=(20,10))\nplt.plot(fbar**2,color='black')\n# plt.savefig('1.png')\n\n\n\n\n\nplt.figure(figsize=(20,10))\nplt.plot(fbar_threshed**2,color='blue')\n# plt.savefig('2.png')\n\n\n\n\n\nplt.figure(figsize = (20,10))\nax = plt.subplot(1, 1, 1)\nax.plot(range(0,500),(fbar**2),color='black')\nax.plot((fbar_threshed**2),color='blue')\naxins = inset_axes(ax, 8, 3, loc = 1, bbox_to_anchor=(0.8, 0.8),\n                   bbox_transform = ax.figure.transFigure)\naxins.plot(range(100, 200),(fbar**2)[100:200],color='black')\naxins.plot(range(100, 200),(fbar_threshed**2)[100:200],color='blue') \naxins.set_xlim(100, 200)\naxins.set_ylim(-0.1, 7)\nmark_inset(ax, axins, loc1=4, loc2=3, fc=\"none\", ec = \"0.01\")\nax.tick_params(axis='y', labelsize=20)\nax.tick_params(axis='x', labelsize=20)\naxins.tick_params(axis='y', labelsize=15)\naxins.tick_params(axis='x', labelsize=15)\n# plt.savefig('3.png')\n\n\n\n\n\nplt.figure(figsize=(20,10))\nplt.plot((fbar_threshed**2),color='blue')\n# plt.savefig('4.png')\n\n\n\n\n\nfbar_hat = Psi @ fbar_threshed # apply dft \n\n\nplt.figure(figsize=(20,10))\nplt.plot(y_true,'r',label = 'True')\nplt.plot(y,'k.',label='f')\nplt.plot(fbar_hat,color='blue',label = 'fhat')\nplt.legend(fontsize=15,loc='lower left',facecolor='white', frameon=True)\n# plt.savefig('5.png')"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "",
    "text": "Try to divide train and test(ST-GCN WikiMathsDatasetLoader)"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#train",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#train",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n583\n\n\n\nT_train = time\nN = len(data[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([583, 1068, 1])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([583, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([583, 1068, 1]), torch.Size([583, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#test",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#test",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "ST-GCN",
    "text": "ST-GCN\n\nmean_f_train = x_train_mean.reshape(T_train,N,1).float()\n\n\nmean_X = mean_f_train[:438,:,:]\nmean_y = mean_f_train[145:,:,:]\n\n\nmean_X.shape,mean_y.shape\n\n(torch.Size([438, 1068, 1]), torch.Size([438, 1068, 1]))\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X,mean_y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [04:17<00:00,  5.15s/it]\n\n\n\nmean_X_fore = mean_f_train[438:,:]\n\n\nmean_fhat = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fore]).detach().numpy()\n\n\nmean_X_fore.shape,x_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068, 1]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn-1",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn-1",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "ST-GCN",
    "text": "ST-GCN\n\nlinear_f_train = x_train_linear.clone()\n\n\nlinear_X = linear_f_train[:438,:,:]\nlinear_y = linear_f_train[145:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X,linear_y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [04:20<00:00,  5.22s/it]\n\n\n\nlinear_X_fore = linear_f_train[438:,:]\n\n\nlinear_X_fore.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\nlinear_fhat = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_fore]).detach().numpy()\n\n\nlinear_X_fore.shape,x_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068, 1]))"
  },
  {
    "objectID": "posts/GCN/2023-07-17-toy_example_guebin.html",
    "href": "posts/GCN/2023-07-17-toy_example_guebin.html",
    "title": "Toy example using GNAR",
    "section": "",
    "text": "Import\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nimport torch\nimport itstgcn_gb as itstgcn\nimport random\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef toy_analyze(FX,edges,lags,train_ratio,mrate,filters,epoch,mtype): \n    data_dict = {'edges':edges, 'node_ids':{i:'node'+str(i) for i in range(FX.shape[-1])}, 'FX':FX}\n    save_data(data_dict,'toy_ex_dataset.pkl')\n    data_dict = load_data('toy_ex_dataset.pkl')\n    loader = itstgcn.DatasetLoader(data_dict)\n    dataset = loader.get_dataset(lags=lags)\n    train_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=train_ratio)\n    mindex_rand = itstgcn.rand_mindex(train_dataset,mrate=mrate)\n    train_dataset_miss_rand = itstgcn.miss(train_dataset,mindex_rand,mtype=mtype)\n    train_dataset_padded_rand = itstgcn.padding(train_dataset_miss_rand) # padding(train_dataset_miss,method='linear'와 같음)\n    lrnr_classic = itstgcn.StgcnLearner(train_dataset_padded_rand)\n    lrnr_proposed = itstgcn.ITStgcnLearner(train_dataset_padded_rand)\n    lrnr_classic.learn(filters=filters,epoch=epoch)\n    lrnr_proposed.learn(filters=filters,epoch=epoch)\n    yhat_classic=lrnr_classic(dataset)['yhat']\n    yhat_proposed=lrnr_proposed(dataset)['yhat']    \n    return yhat_classic,yhat_proposed\n\n\n\nData\n\nT = 50\nt = np.linspace(0,np.pi*2,T)\ne = np.random.randn(T)*0.1\ny1 = np.cos(2*t)\ny2 = np.cos(3*t)\ny3 = y1+y2+e\ny = np.stack([y1,y2,y3],axis=1)\n_, N = y.shape \ntrain_ratio = 0.9\ntest_len = int(T*(1-train_ratio))\ntr_len = T - test_len\ntest_index = [False]*tr_len + [True]*test_len \nedges = [[0,2],[1,2]]\nlags = 8\nmrate = 0.8\nfilters = 2\nepoch = 50\nmtype = 'rand' \n### \nyhat_classic,yhat_proposed = toy_analyze(y,edges,lags,train_ratio,mrate,filters,epoch,mtype)\n\n50/50\n\n\n\nnode = 2\nplt.rcParams['figure.dpi'] = 200\nplt.plot(y[lags:,node],'.')\nplt.plot(yhat_classic[:,node],'--',label='classic')\nplt.plot(yhat_proposed[:,node],'--',label='proposed')\nplt.plot(y[lags:,0]+y[lags:,1],'-',label='true')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f30c156c970>"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html",
    "title": "Padalme GSO_st",
    "section": "",
    "text": "edit"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html#random",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html#random",
    "title": "Padalme GSO_st",
    "section": "random",
    "text": "random\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.3,0.6],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnsnd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-07-02_07-01-12.csv"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html#block",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html#block",
    "title": "Padalme GSO_st",
    "section": "block",
    "text": "block\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(10,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[4] = another_list\nmy_list[5] = another_list\nanother_list = list(range(5,20))\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[10] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnsnd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-07-02_07-19-21.csv\n\n\n\n# df1 = pd.read_csv('./simulation_results/2023-04-13_20-37-59.csv')\n\n\n# data = pd.concat([df1],axis=0);data"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 일정",
    "text": "missing 일정\n\nstgcn_train1 = []\nstgcn_test1 = []\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    for epoch in range(50):\n        for time, (xt,yt) in enumerate(zip(X,y)):\n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n    \n    train_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    stgcn_train1.append(train_mse_total_stgcn.tolist())\n    stgcn_test1.append(test_mse_total_stgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_train1);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-다르게",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-다르게",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 다르게",
    "text": "missing 다르게\n\nstgcn_train2 = []\nstgcn_test2 = []\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    for epoch in range(50):\n        for time, (xt,yt) in enumerate(zip(X,y)):\n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n    \n    train_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean() \n    \n    stgcn_train2.append(train_mse_total_stgcn.tolist())\n    stgcn_test2.append(test_mse_total_stgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_test2);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정-1",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정-1",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 일정",
    "text": "missing 일정\n\nestgcn_train1 = []\nestgcn_test1 = []\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    signal = interpolated_signal.copy()\n    for epoch in range(50):\n        signal = update_from_freq_domain(signal,missing_index)\n        X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n        y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for time, (xt,yt) in enumerate(zip(X,y)):        \n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n    train_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    estgcn_train1.append(train_mse_total_estgcn.tolist())\n    estgcn_test1.append(test_mse_total_estgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_train1); \n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-매번-다르게",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-매번-다르게",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 매번 다르게",
    "text": "missing 매번 다르게\n\nestgcn_train2 = []\nestgcn_test2 = []\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    signal = interpolated_signal.copy()\n    for epoch in range(50):\n        signal = update_from_freq_domain(signal,missing_index)\n        X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n        y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for time, (xt,yt) in enumerate(zip(X,y)):        \n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n    train_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    estgcn_train2.append(train_mse_total_estgcn.tolist())\n    estgcn_test2.append(test_mse_total_estgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_test2);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정-2",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-일정-2",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 일정",
    "text": "missing 일정\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = np.array(torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:].squeeze())\ny = np.array(torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:].squeeze())\n\nXX = np.array(torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float().squeeze())\nyy = np.array(torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float().squeeze())\n\nreal_y = np.array(torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:])\n\n\n%R -i X\n%R -i XX\n\n\n%%R\ngnar_train1 <- matrix(ncol=1,nrow=100)\ngnar_test1 <- matrix(ncol=1,nrow=100)\nfor(i in 1:100){\n  answer <- GNARfit(vts = X, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\n  prediction <- predict(answer,n.ahead=40)\n  \n  train_mse_total_gnar <- mean(residuals(answer)**2)\n  test_mse_total_gnar <- mean((XX - prediction[1:40])**2)\n  \n  gnar_train1[i] <- train_mse_total_gnar\n  gnar_test1[i] <- train_mse_total_gnar\n}\n\n\n%R -o gnar_train1\n%R -o gnar_test1\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_train1);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-다르게-1",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-다르게-1",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing 다르게",
    "text": "missing 다르게\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n\ngnar_train2 = []\ngnar_test2 = []\n\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n    answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n    predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n    \n    train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n    test_mse_total_gnar = ((yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n    \n    gnar_train2.append(train_mse_total_gnar.tolist())\n    gnar_test2.append(test_mse_total_gnar.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_test2);"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and inter_method=='cubic' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' and inter_method!='cubic' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#weight-matrix-time-node-고려한-결과",
    "title": "Simulation",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-04-30_13-00-12.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-30_13-31-32.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-30_14-01-49.csv')\ndf4 = pd.read_csv('./simulation_results/2023-04-30_14-31-56.csv')\ndf5 = pd.read_csv('./simulation_results/2023-04-30_15-02-23.csv')\ndf6 = pd.read_csv('./simulation_results/2023-04-30_15-33-03.csv')\ndf7 = pd.read_csv('./simulation_results/2023-04-30_16-07-43.csv')\ndf8 = pd.read_csv('./simulation_results/2023-04-30_16-41-35.csv')\ndf9 = pd.read_csv('./simulation_results/2023-04-30_17-14-51.csv')\ndf10 = pd.read_csv('./simulation_results/2023-04-30_17-49-34.csv')\ndf11 = pd.read_csv('./simulation_results/2023-04-30_18-21-29.csv')\ndf12 = pd.read_csv('./simulation_results/2023-04-30_18-50-24.csv')\ndf13 = pd.read_csv('./simulation_results/2023-04-30_20-33-28.csv')\ndf14 = pd.read_csv('./simulation_results/2023-05-04_16-40-05.csv')\ndf15 = pd.read_csv('./simulation_results/2023-05-04_17-34-00.csv')\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype!='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-1",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-1",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR'\").groupby('mrate')['mse'].unique()\n\nmrate\n0.0    [1.2959295511245728, 1.2547194957733154]\n0.3    [1.2959295511245728, 1.2547194957733154]\n0.5    [1.2959295511245728, 1.2547194957733154]\nName: mse, dtype: object\n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-1",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-04-27_07-50-11.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-27_22-09-07.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-28_14-40-59.csv')\ndf4 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n# df5 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/wikimath_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/wikimath_block.csv')\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#missing-values-on-the-same-nodes",
    "title": "Simulation",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\ndf1 = pd.read_csv('./simulation_results/2023-04-29_03-57-07.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-04-29_20-15-46.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-30_16-19-58.csv') # STGCN IT-STGCN\n# 60% 확인하고 다시 돌리기\ndf4 = pd.read_csv('./simulation_results/2023-05-05_04-21-57.csv') # STGCN IT-STGCN 60%\ndf5 = pd.read_csv('./simulation_results/2023-05-06_11-34-46.csv') # STGCN IT-STGCN\ndf6 = pd.read_csv('./simulation_results/2023-05-06_23-43-35.csv') # STGCN IT-STGCN\ndf7 = pd.read_csv('./simulation_results/2023-05-07_14-06-44.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\narray([], dtype=float64)\n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-2",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndf1 = pd.read_csv('./simulation_results/2023-04-17_06-05-37.csv') # STGCN IT-STGCN 70%\ndf2 = pd.read_csv('./simulation_results/2023-04-17_08-05-26.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-17_13-41-19.csv') # STGCN IT-STGCN\ndf4 = pd.read_csv('./simulation_results/2023-04-17_15-44-21.csv') # STGCN IT-STGCN\ndf5 = pd.read_csv('./simulation_results/2023-04-17_21-27-38.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-04-15_15-00-32.csv') # GNAR 30%, 50%, 70% # 뭔가 일단 필요없어서 데이터셋에서 뺌\ndf7 = pd.read_csv('./simulation_results/2023-04-18_05-01-55.csv') # STGCN IT-STGCN\ndf8 = pd.read_csv('./simulation_results/2023-04-18_06-14-06.csv') # STGCN IT-STGCN\ndf9 = pd.read_csv('./simulation_results/2023-04-18_17-32-30.csv') # STGCN IT-STGCN\ndf10 = pd.read_csv('./simulation_results/2023-04-19_01-52-24.csv') # STGCN IT-STGCN\ndf11 = pd.read_csv('./simulation_results/2023-04-19_07-50-52.csv') # STGCN IT-STGCN\ndf12 = pd.read_csv('./simulation_results/2023-04-19_09-30-25.csv') # STGCN IT-STGCN\ndf13 = pd.read_csv('./simulation_results/2023-04-19_15-32-55.csv') # STGCN IT-STGCN\ndf14 = pd.read_csv('./simulation_results/2023-04-19_17-12-06.csv') # STGCN IT-STGCN\ndf15 = pd.read_csv('./simulation_results/2023-04-19_23-07-36.csv') # STGCN IT-STGCN\ndf16 = pd.read_csv('./simulation_results/2023-04-20_00-46-43.csv') # STGCN IT-STGCN\ndf17 = pd.read_csv('./simulation_results/2023-04-20_06-51-34.csv') # STGCN IT-STGCN\ndf18 = pd.read_csv('./simulation_results/2023-04-20_08-30-27.csv') # STGCN IT-STGCN\ndf19 = pd.read_csv('./simulation_results/2023-04-20_14-28-35.csv') # STGCN IT-STGCN\ndf20 = pd.read_csv('./simulation_results/2023-04-20_16-08-39.csv') # STGCN IT-STGCN\ndf21 = pd.read_csv('./simulation_results/2023-04-20_22-09-37.csv') # STGCN IT-STGCN\ndf22 = pd.read_csv('./simulation_results/2023-04-20_23-48-26.csv') # STGCN IT-STGCN\ndf23 = pd.read_csv('./simulation_results/2023-04-21_05-36-47.csv') # STGCN IT-STGCN\ndf24 = pd.read_csv('./simulation_results/2023-04-21_15-26-00.csv') # STGCN IT-STGCN\ndf25 = pd.read_csv('./simulation_results/2023-04-21_23-27-11.csv') # STGCN IT-STGCN\ndf26 = pd.read_csv('./simulation_results/2023-04-22_07-46-08.csv') # STGCN IT-STGCN\ndf27 = pd.read_csv('./simulation_results/2023-04-22_15-45-20.csv') # STGCN IT-STGCN\ndf28 = pd.read_csv('./simulation_results/2023-04-22_22-57-31.csv') # STGCN IT-STGCN\ndf29 = pd.read_csv('./simulation_results/2023-04-23_07-00-15.csv') # STGCN IT-STGCN\ndf30 = pd.read_csv('./simulation_results/2023-04-23_15-18-02.csv') # STGCN IT-STGCN\ndf31 = pd.read_csv('./simulation_results/2023-04-23_15-22-36.csv') # GNAR 70%\n# baseline\ndf32 = pd.read_csv('./simulation_results/2023-04-29_06-54-40.csv') # GNAR \ndf33 = pd.read_csv('./simulation_results/2023-04-30_18-55-12.csv')\ndf34 = pd.read_csv('./simulation_results/2023-05-01_02-55-33.csv')\ndf35 = pd.read_csv('./simulation_results/2023-05-01_10-21-15.csv')\ndf36 = pd.read_csv('./simulation_results/2023-05-01_19-23-57.csv')\ndf37 = pd.read_csv('./simulation_results/2023-05-02_01-10-53.csv')\ndf38 = pd.read_csv('./simulation_results/2023-05-02_08-26-53.csv')\ndf39 = pd.read_csv('./simulation_results/2023-05-02_16-00-40.csv')\ndf40 = pd.read_csv('./simulation_results/2023-05-03_00-34-09.csv')\ndf41 = pd.read_csv('./simulation_results/2023-05-03_08-04-42.csv')\ndf42 = pd.read_csv('./simulation_results/2023-05-03_15-50-50.csv')\ndf43 = pd.read_csv('./simulation_results/2023-05-03_23-46-56.csv')\ndf44 = pd.read_csv('./simulation_results/2023-05-04_05-22-59.csv')\ndf45 = pd.read_csv('./simulation_results/2023-05-04_09-22-37.csv')\ndf46 = pd.read_csv('./simulation_results/2023-05-04_15-00-57.csv')\ndf47 = pd.read_csv('./simulation_results/2023-05-04_23-41-21.csv')\ndf48 = pd.read_csv('./simulation_results/2023-05-05_07-23-04.csv')\ndf49 = pd.read_csv('./simulation_results/2023-05-05_15-03-17.csv')\ndf50 = pd.read_csv('./simulation_results/2023-05-06_05-18-07.csv')\ndf51 = pd.read_csv('./simulation_results/2023-05-06_12-57-14.csv')\ndf52 = pd.read_csv('./simulation_results/2023-05-06_19-10-23.csv')\ndf53 = pd.read_csv('./simulation_results/2023-05-07_03-20-10.csv')\ndf54 = pd.read_csv('./simulation_results/2023-05-07_11-26-24.csv')\ndf55 = pd.read_csv('./simulation_results/2023-05-08_00-04-56.csv')\ndf56 = pd.read_csv('./simulation_results/2023-05-08_04-27-01.csv')\ndf57 = pd.read_csv('./simulation_results/2023-05-08_10-06-55.csv')\ndf58 = pd.read_csv('./simulation_results/2023-05-08_17-50-36.csv')\ndf59 = pd.read_csv('./simulation_results/2023-05-09_03-28-08.csv')\ndf60 = pd.read_csv('./simulation_results/2023-05-09_11-08-10.csv')\ndf61 = pd.read_csv('./simulation_results/2023-05-09_20-11-45.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,\n                 df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,\n                 df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,\n                 df51,df52,df53,df54,df55,df56,df57,df58,df59,df60,df61],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/windmillsmall.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/windmillsmall.csv')\n\n\ndata.query(\"method=='GNAR' and mrate ==0\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-2",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR' and mrate !=0\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-2",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-04-24_02-48-08.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-04-24_10-57-10.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-24_18-53-34.csv') # STGCN IT-STGCN\ndf4 = pd.read_csv('./simulation_results/2023-04-25_02-30-27.csv') # STGCN IT-STGCN\ndf5 = pd.read_csv('./simulation_results/2023-04-25_10-48-46.csv') # STGCN IT-STGCN\ndf6 = pd.read_csv('./simulation_results/2023-04-25_10-53-14.csv') # GNAR \ndf7 = pd.read_csv('./simulation_results/2023-04-25_18-40-53.csv') # STGCN IT-STGCN\ndf8 = pd.read_csv('./simulation_results/2023-04-25_23-30-08.csv') # STGCN IT-STGCN\ndf9 = pd.read_csv('./simulation_results/2023-04-26_04-15-00.csv') # STGCN IT-STGCN\ndf10 = pd.read_csv('./simulation_results/2023-04-27_07-59-36.csv') # STGCN IT-STGCN\ndf11 = pd.read_csv('./simulation_results/2023-04-27_15-29-00.csv') # STGCN IT-STGCN\ndf12 = pd.read_csv('./simulation_results/2023-04-27_23-37-18.csv') # STGCN IT-STGCN\ndf13 = pd.read_csv('./simulation_results/2023-04-28_08-21-54.csv') # STGCN IT-STGCN\ndf14 = pd.read_csv('./simulation_results/2023-04-28_16-06-55.csv') # STGCN IT-STGCN\ndf15 = pd.read_csv('./simulation_results/2023-04-28_21-19-37.csv') # STGCN IT-STGCN\ndf16 = pd.read_csv('./simulation_results/2023-04-29_03-07-03.csv') # STGCN IT-STGCN\ndf17 = pd.read_csv('./simulation_results/2023-04-29_09-00-42.csv') # STGCN IT-STGCN\ndf18 = pd.read_csv('./simulation_results/2023-04-29_19-07-49.csv') # STGCN IT-STGCN\ndf19 = pd.read_csv('./simulation_results/2023-04-30_05-14-07.csv') # STGCN IT-STGCN\ndf20 = pd.read_csv('./simulation_results/2023-04-30_15-23-16.csv') # STGCN IT-STGCN\ndf21 = pd.read_csv('./simulation_results/2023-05-01_00-16-37.csv') # STGCN IT-STGCN\ndf22 = pd.read_csv('./simulation_results/2023-05-01_07-41-52.csv') # STGCN IT-STGCN\ndf23 = pd.read_csv('./simulation_results/2023-05-01_16-21-41.csv') # STGCN IT-STGCN\ndf24 = pd.read_csv('./simulation_results/2023-05-01_23-38-23.csv') # STGCN IT-STGCN\ndf25 = pd.read_csv('./simulation_results/2023-05-02_13-51-13.csv') # STGCN IT-STGCN\ndf26 = pd.read_csv('./simulation_results/2023-05-02_21-43-26.csv') # STGCN IT-STGCN\ndf27 = pd.read_csv('./simulation_results/2023-05-03_06-04-32.csv') # STGCN IT-STGCN\ndf28 = pd.read_csv('./simulation_results/2023-05-03_13-43-11.csv') # STGCN IT-STGCN\ndf29 = pd.read_csv('./simulation_results/2023-05-03_21-58-04.csv') # STGCN IT-STGCN\ndf30 = pd.read_csv('./simulation_results/2023-05-04_04-39-00.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,\n                 df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/windmillsmall_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/windmillsmall_block.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-3",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-3",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR'\").groupby('mrate')['mse'].unique()\n\nmrate\n0.0    [1.0619367361068726, 1.068463921546936]\n0.3    [1.0619367361068726, 1.068463921546936]\n0.4    [1.0619367361068726, 1.068463921546936]\n0.8    [1.0619367361068726, 1.068463921546936]\n0.9    [1.0619367361068726, 1.068463921546936]\nName: mse, dtype: object\n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.8 and mrate!=0.9\").sort_values('lags').plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)\n\n\n                                                \n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.3 and mrate!=0.4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-3",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-05-04_21-03-21.csv')\ndf2 = pd.read_csv('./simulation_results/2023-05-05_12-10-44.csv')\ndf3 = pd.read_csv('./simulation_results/2023-05-06_12-42-22.csv')\ndf4 = pd.read_csv('./simulation_results/2023-05-06_15-40-47.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/monte_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/monte_block.csv')\n\n\ndata.query(\"mtype=='block' and method=='GNAR'\")['mse'].mean()\n\n1.0652003288269043\n\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html",
    "title": "TGCN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random",
    "title": "TGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block",
    "title": "TGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-2",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-2",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "TGCN_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-21_22-29-02.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-21_22-51-34.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/TGCN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/TGCN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-3",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-3",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "TGCN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-27_03-08-38.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-27_15-49-21.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-27_09-33-29.csv') \n\n\ndata = pd.concat([df1],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/TGCN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/TGCN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-4",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-4",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-5",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-5",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html",
    "href": "posts/GCN/2023-04-25-note_matrix.html",
    "title": "Note_weight amatrix",
    "section": "",
    "text": "weight matrix\n- 하이퍼파라메터\n- wt,ws,f\n- f를 펼침\n- 펼쳐진 f에 대응하는 W 생성\n- trim\n임의로 ftrimed_flatten이 f_flatten과 같다고 생각하자.\n- ftrimed"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#chickenpox",
    "href": "posts/GCN/2023-04-25-note_matrix.html#chickenpox",
    "title": "Note_weight amatrix",
    "section": "Chickenpox",
    "text": "Chickenpox\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\na = loader1.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(20, 20)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- f를 펼침\n\nf_flatten = f.reshape(-1,1)\nf_flatten\n\narray([[-1.08135724e-03],\n       [-7.11136085e-01],\n       [-3.22808515e+00],\n       ...,\n       [ 4.71099041e-02],\n       [ 2.45684924e+00],\n       [-3.44296107e-01]])\n\n\n- 펼쳐진 f에 대응하는 W 생성\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\narray([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]])\n\n\n\nnp.save('./weight_st/W_chickenpox.npy', W_flatten)\n\n\nnp.load('./weight_st/W_chickenpox.npy')\n\narray([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]])\n\n\n\nd = np.array(W_flatten.sum(axis=1))\n\n\nD = np.diag(d)\n\n\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-W_flatten) @ np.diag(1/np.sqrt(d)))\n\n\nlamb, Psi = np.linalg.eigh(L)\n\n\nnp.save('./weight_st/Psi_chickenpox.npy', Psi)\n\n\nnp.load('./weight_st/Psi_chickenpox.npy')\n\narray([[ 1.04115841e-02, -1.47242159e-02,  1.47242532e-02, ...,\n         6.41186713e-04, -4.27546925e-04,  2.13800213e-04],\n       [ 8.23107997e-03, -1.16404883e-02,  1.16404382e-02, ...,\n        -4.77715858e-04,  3.18549731e-04, -1.59296626e-04],\n       [ 8.23107997e-03, -1.16404502e-02,  1.16402861e-02, ...,\n         2.85275946e-04, -1.90235274e-04,  9.51330388e-05],\n       ...,\n       [ 8.23107997e-03,  1.16404565e-02,  1.16403112e-02, ...,\n        -6.65738542e-04, -4.43946869e-04, -2.22009806e-04],\n       [ 1.04115841e-02,  1.47242028e-02,  1.47242009e-02, ...,\n         1.35543431e-04,  9.03781585e-05,  4.51938438e-05],\n       [ 8.23107997e-03,  1.16404680e-02,  1.16403570e-02, ...,\n         5.65995233e-04,  3.77431091e-04,  1.88745843e-04]])\n\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#pedalme",
    "href": "posts/GCN/2023-04-25-note_matrix.html#pedalme",
    "title": "Note_weight amatrix",
    "section": "Pedalme",
    "text": "Pedalme\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\na = loader2.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(wt).shape\n\n(34, 34)\n\n\n\nnp.array(ws).shape\n\n(15, 15)\n\n\n\n34*15\n\n510\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- f를 펼침\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- 펼쳐진 f에 대응하는 W 생성\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\narray([[1.        , 0.42545896, 0.15735536, ..., 0.        , 0.        ,\n        0.        ],\n       [0.42545896, 1.        , 0.06751402, ..., 0.        , 0.        ,\n        0.        ],\n       [0.15735536, 0.06751402, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 1.        , 0.07069877,\n        0.06899971],\n       [0.        , 0.        , 0.        , ..., 0.07069877, 1.        ,\n        0.32983841],\n       [0.        , 0.        , 0.        , ..., 0.06899971, 0.32983841,\n        1.        ]])\n\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_pedalme.npy', W_flatten)\n\n\nnp.load('./weight_st/W_pedalme.npy')\n\narray([[1.        , 0.42545896, 0.15735536, ..., 0.        , 0.        ,\n        0.        ],\n       [0.42545896, 1.        , 0.06751402, ..., 0.        , 0.        ,\n        0.        ],\n       [0.15735536, 0.06751402, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 1.        , 0.07069877,\n        0.06899971],\n       [0.        , 0.        , 0.        , ..., 0.07069877, 1.        ,\n        0.32983841],\n       [0.        , 0.        , 0.        , ..., 0.06899971, 0.32983841,\n        1.        ]])\n\n\n\nd = np.array(W_flatten.sum(axis=1))\n\n\nD = np.diag(d)\n\n\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-W_flatten) @ np.diag(1/np.sqrt(d)))\n\n\nlamb, Psi = np.linalg.eigh(L)\n\n\nPsi.T.shape\n\n(510, 510)\n\n\n\nPsi.shape\n\n(510, 510)\n\n\n\nnp.save('./weight_st/Psi_pedalme.npy', Psi)\n\n\nnp.load('./weight_st/Psi_pedalme.npy')\n\narray([[ 4.61219573e-02, -6.52404719e-02,  6.52791904e-02, ...,\n        -4.33862149e-04, -2.17206920e-04,  8.97548015e-05],\n       [ 4.44297451e-02, -6.28451968e-02,  6.28773329e-02, ...,\n        -2.56832039e-05, -1.49624707e-05,  7.00873447e-06],\n       [ 3.51291880e-02, -4.95907787e-02,  4.93238061e-02, ...,\n        -2.71803598e-02, -1.77647577e-02,  8.79413561e-03],\n       ...,\n       [ 3.75563137e-02,  5.30576275e-02,  5.28917644e-02, ...,\n         5.85830960e-03, -4.16888716e-03, -2.15565030e-03],\n       [ 3.87057680e-02,  5.47153694e-02,  5.46437177e-02, ...,\n         1.08555123e-03, -6.10976014e-04, -2.76608545e-04],\n       [ 4.03127107e-02,  5.70025038e-02,  5.69740769e-02, ...,\n        -2.05662084e-04,  9.91534370e-05,  4.05213281e-05]])"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#wikimath",
    "href": "posts/GCN/2023-04-25-note_matrix.html#wikimath",
    "title": "Note_weight amatrix",
    "section": "Wikimath",
    "text": "Wikimath\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\na = loader3.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nnp.array(mtr).shape\n\n(2, 27079)\n\n\n\nnp.array(mtr2).shape\n\n(27079,)\n\n\n\nmtr\n\narray([[   0,    0,    0, ..., 1056, 1063, 1065],\n       [   1,    2,    3, ..., 1059, 1064, 1066]])\n\n\n\npd.DataFrame(mtr2).iloc[:,0].unique()\n\narray([ 1,  4,  2,  5,  3,  6,  7,  9,  8, 12, 10, 13, 16, 11])\n\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(1068, 1068)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- f를 펼침\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- 펼쳐진 f에 대응하는 W 생성\n\nN = len(ws)\nT = len(wt)\nIs = np.eye(N,N)\nlst = [[0]*T for t in range(T)]\n\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_wikimath.npy', W_flatten)\n\n\nnp.load('./weight_st/W_wikimath.npy')"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#windmillsmall",
    "href": "posts/GCN/2023-04-25-note_matrix.html#windmillsmall",
    "title": "Note_weight amatrix",
    "section": "Windmillsmall",
    "text": "Windmillsmall\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader6 = WindmillOutputSmallDatasetLoader()\n\n\na = loader6.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(11, 11)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- f를 펼침\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- 펼쳐진 f에 대응하는 W 생성\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_windmillsmall.npy', W_flatten)\n\n\nnp.load('./weight_st/W_windmillsmall.npy')"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "",
    "text": "PyTorch Geometric Temporal"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Applications",
    "text": "Applications\n\nEpidemiological Forecasting\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 200/200 [02:40<00:00,  1.24it/s]\n\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 1.0232\n\nMSE: 1.0247\n\n\n\n\nShape Check (1)\n\na = torch.randn(20, 1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\n\n\nDoesn’t it have to ‘y_hat’ be the same shape as snapshot.y?\n\nIf we want to compare the y_hat from the model with the values y, the same shape is appropriate to evaluate.\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 200/200 [01:27<00:00,  2.30it/s]\n\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 1.0232\n\nMSE: 1.2844\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(20, 1).reshape(-1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Web Traffic Prediction",
    "text": "Web Traffic Prediction\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 50/50 [31:26<00:00, 37.73s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 0.7760\n\nMSE: 0.7939\n\n\n\n\nShape Check (1)\n\na = torch.randn(1068, 1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\nIf the code changes the shape of y_hat?\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 50/50 [36:39<00:00, 43.99s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 0.7760\n\nMSE: 0.7807\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(1068, 1).reshape(-1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068]) torch.Size([1068]) torch.Size([1068])\n\n\n\nFix : https://github.com/benedekrozemberczki/pytorch_geometric_temporal/issues/231"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      2\n      1.212\n      0.026\n    \n    \n      1\n      4\n      STGCN\n      2\n      1.206\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      IT-STGCN\n      2\n      1.219\n      0.022\n    \n    \n      1\n      0.3\n      4\n      STGCN\n      2\n      1.221\n      0.029\n    \n    \n      2\n      0.5\n      4\n      IT-STGCN\n      2\n      1.220\n      0.027\n    \n    \n      3\n      0.5\n      4\n      STGCN\n      2\n      1.236\n      0.035\n    \n    \n      4\n      0.6\n      4\n      IT-STGCN\n      2\n      1.215\n      0.024\n    \n    \n      5\n      0.6\n      4\n      STGCN\n      2\n      1.242\n      0.041\n    \n    \n      6\n      0.7\n      4\n      IT-STGCN\n      2\n      1.226\n      0.033\n    \n    \n      7\n      0.7\n      4\n      STGCN\n      2\n      1.245\n      0.052\n    \n    \n      8\n      0.8\n      4\n      IT-STGCN\n      2\n      1.236\n      0.028\n    \n    \n      9\n      0.8\n      4\n      STGCN\n      2\n      1.261\n      0.048"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      4\n      IT-STGCN\n      1.217\n      0.023\n    \n    \n      1\n      0.125\n      4\n      STGCN\n      1.246\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.878\n      0.047\n    \n    \n      1\n      16\n      STGCN\n      0.892\n      0.054"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.850\n      0.022\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.050\n      0.036\n    \n    \n      2\n      0.5\n      linear\n      16\n      IT-STGCN\n      0.899\n      0.023\n    \n    \n      3\n      0.5\n      linear\n      16\n      STGCN\n      1.514\n      0.050\n    \n    \n      4\n      0.6\n      linear\n      16\n      IT-STGCN\n      0.997\n      0.030\n    \n    \n      5\n      0.6\n      linear\n      16\n      STGCN\n      1.807\n      0.064\n    \n    \n      6\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.371\n      0.072\n    \n    \n      7\n      0.8\n      linear\n      16\n      STGCN\n      2.172\n      0.186"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.883365\n      0.045500\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.889922\n      0.033144\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.901308\n      0.054389\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.884887\n      0.041756"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      4\n      IT-STGCN\n      1.170\n      0.040\n    \n    \n      1\n      4\n      4\n      STGCN\n      1.191\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.202\n      0.029\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.267\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.039\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.256\n      0.038\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.040\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.364\n      0.068\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.042\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.365\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.031\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.211\n      0.023\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#w_st",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.191\n      0.041\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.264\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.193\n      0.033\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.250\n      0.049\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.044\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.355\n      0.068\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.185\n      0.035\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.249\n      0.027"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      64\n      IT-STGCN\n      0.643\n      0.024\n    \n    \n      1\n      8\n      64\n      STGCN\n      0.645\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.628\n      0.020\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.674\n      0.020\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.815\n      0.058\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.407\n      0.117"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.640461\n      0.019198\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.637772\n      0.012983"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.617\n      0.011\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.823\n      0.048"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      0.994\n      0.014\n    \n    \n      1\n      8\n      STGCN\n      0.992\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.116\n      0.021\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.574\n      0.104"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      0.985\n      0.002\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      0.985\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.969\n      0.012\n    \n    \n      1\n      4\n      STGCN\n      0.970\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.031532\n      0.028135\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.140193\n      0.061301"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.958620\n      0.007766\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.955762\n      0.005461"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html",
    "title": "2nd ITSTGCN",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn",
    "title": "2nd ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn",
    "title": "2nd ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar",
    "title": "2nd ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn-1",
    "title": "2nd ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn-1",
    "title": "2nd ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar-1",
    "title": "2nd ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "",
    "text": "ST-GCN Dataset WikiMathsDatasetLoader"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#train",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#train",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 4]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n580\n\n\n\nT_train = time\nN = len(data_train[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([580, 1068, 4])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([580, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([580, 1068, 4]), torch.Size([580, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#test",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#test",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 4]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 4])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 4]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오1-baseline",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오1-baseline",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "시나리오1 (Baseline)",
    "text": "시나리오1 (Baseline)\n시나리오1\n\nmissing rate: 0%\n보간방법: None\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([x_train_f[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = x_train_f[4:T_train,:].reshape(T_train-4,N,-1).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:47<00:00,  6.96s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y.squeeze()-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y.squeeze()-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\n\nGNAR 으로 적합 + 예측\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train_f)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((yy-gnar_test)**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n GNAR: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(4,580),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(4,583),gnar_train[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(583,728),gnar_test[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오2",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오2",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "시나리오2",
    "text": "시나리오2\n시나리오2\n\nmissing rate: 50%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train[:,:,0][:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\nimport numpy as np\n\nT= 100\nN= 5\nlag =4 \n\nsignal=np.arange(T*N).reshape(T,N)\n\nX= np.stack([signal[i:(T-lag+i),:] for i in range(lag)],axis=-1)\nX.shape\n\ny=signal[lag:].reshape(T-lag,N,1)\ny.shape\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:23<00:00,  7.67s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|██████████| 50/50 [07:11<00:00,  8.63s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\ny_train.shape,T_train\n\n(torch.Size([580, 1068]), 580)\n\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오3",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오3",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "시나리오3",
    "text": "시나리오3\n시나리오3\n\nmissing rate: 80%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train_f[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:40<00:00,  8.01s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|██████████| 50/50 [07:18<00:00,  8.77s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오4",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#시나리오4",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "시나리오4",
    "text": "시나리오4\n시나리오4\n\nmissing rate: 30%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train_f[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:32<00:00,  7.86s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|██████████| 50/50 [07:13<00:00,  8.66s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario4: \\n missing=30% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html",
    "title": "SY 1st ITSTGCN",
    "section": "",
    "text": "edit"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_rand",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_rand",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nplans_stgcn_rand = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nclass PLNR_STGCN_RAND:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):  \n            product_iterator = itertools.product(\n                self.plans['method'], \n                self.plans['mrate'], \n                self.plans['lags'], \n                self.plans['nof_filters'], \n                self.plans['inter_method'],\n                self.plans['epoch']\n            )\n            for prod_iter in product_iterator:\n                method,mrate,lags,nof_filters,inter_method,epoch = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                if mrate > 0: \n                    mtype = 'rand'\n                    mindex = rand_mindex(train_dataset,mrate=mrate)\n                    train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                elif mrate ==0: \n                    mtype = None\n                    inter_method = None \n                if method == 'STGCN':\n                    lrnr = StgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                elif method == 'IT-STGCN':\n                    lrnr = ITStgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn(filters=nof_filters,epoch=epoch)\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n            print('{}/{} is done'.format(_+1,self.plans['max_iteration']))\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_STGCN_RAND(plans,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/3 is done\n2/3 is done\n3/3 is done\n\n\n\ndf = plnr.simulation_results\ndf\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      8\n      None\n      1\n      1.202111\n    \n    \n      1\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      8\n      None\n      1\n      1.173311\n    \n    \n      2\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      16\n      None\n      1\n      1.170123\n    \n    \n      3\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      16\n      None\n      1\n      1.18629\n    \n    \n      4\n      five_nodes\n      STGCN\n      0.0\n      None\n      4\n      8\n      None\n      1\n      1.238957\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      139\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      2\n      16\n      linear\n      1\n      1.195191\n    \n    \n      140\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      8\n      nearest\n      1\n      1.208371\n    \n    \n      141\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      8\n      linear\n      1\n      1.160624\n    \n    \n      142\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      16\n      nearest\n      1\n      1.15774\n    \n    \n      143\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      16\n      linear\n      1\n      1.217873\n    \n  \n\n144 rows × 9 columns"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_block",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_block",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_STGCN_BLOCK",
    "text": "PLNR_STGCN_BLOCK\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nmindex_block = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex_block],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nclass PLNR_STGCN_BLOCK:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['method'], \n                self.plans['mindex'],\n                self.plans['lags'],\n                self.plans['nof_filters'],\n                self.plans['inter_method'],\n                self.plans['epoch']\n            )\n            for prod_iter in product_iterator:\n                method,mrate,lags,nof_filters,inter_method,epoch = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                mtype = 'block'\n                train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                if method == 'STGCN':\n                    lrnr = StgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                elif method == 'IT-STGCN':\n                    lrnr = ITStgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn(filters=nof_filters,epoch=epoch)\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                mrate= lrnr.mrate_total\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_STGCN_BLOCK(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/1\n\n\n\ndf = plnr.simulation_results\ndf\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.162601\n    \n    \n      1\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.145895\n    \n    \n      2\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.166197\n    \n    \n      3\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.165355\n    \n    \n      4\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.157954\n    \n    \n      5\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.162674\n    \n    \n      6\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.179143\n    \n    \n      7\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.175561\n    \n    \n      8\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.195364\n    \n    \n      9\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.2184\n    \n    \n      10\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.210481\n    \n    \n      11\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.169326\n    \n    \n      12\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.193523\n    \n    \n      13\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.199567\n    \n    \n      14\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.201094\n    \n    \n      15\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.210867\n    \n    \n      16\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.169622\n    \n    \n      17\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.173848\n    \n    \n      18\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.176841\n    \n    \n      19\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.15848\n    \n    \n      20\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.191304\n    \n    \n      21\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.155874\n    \n    \n      22\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.188419\n    \n    \n      23\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.197183\n    \n    \n      24\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.210021\n    \n    \n      25\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.184674\n    \n    \n      26\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.274009\n    \n    \n      27\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.188723\n    \n    \n      28\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.217735\n    \n    \n      29\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.202317\n    \n    \n      30\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.219543\n    \n    \n      31\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.202418\n    \n    \n      32\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.158991\n    \n    \n      33\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.187762\n    \n    \n      34\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.182213\n    \n    \n      35\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.161439\n    \n    \n      36\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.188787\n    \n    \n      37\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.233327\n    \n    \n      38\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.15206\n    \n    \n      39\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.161346\n    \n    \n      40\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.215097\n    \n    \n      41\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.163064\n    \n    \n      42\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.206054\n    \n    \n      43\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.177454\n    \n    \n      44\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.233471\n    \n    \n      45\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.209842\n    \n    \n      46\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.221017\n    \n    \n      47\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.218403"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_rand",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_rand",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nclass PLNR_GNAR_RAND:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['mrate'],\n                self.plans['lags'],\n                self.plans['inter_method']\n            )\n            for prod_iter in product_iterator:\n                mrate,lags,inter_method = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                if mrate > 0: \n                    mtype = 'rand'\n                    mindex = rand_mindex(train_dataset,mrate=mrate)\n                    train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                elif mrate ==0: \n                    mtype = None\n                    inter_method = None \n                method = 'GNAR'\n                lrnr = GNARLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn()\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                nof_filters = None \n                epoch= None\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nplnr.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      1\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      2\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      3\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      4\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      5\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      6\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      7\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      8\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      9\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      10\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      11\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      12\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      13\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      14\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      15\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      16\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      17\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      18\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      19\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      20\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      21\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      22\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      23\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      24\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      25\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      26\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      27\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      28\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      29\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      30\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      31\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      32\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      33\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      34\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      35\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_block",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_block",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nmindex_block = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex_block],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nclass PLNR_GNAR_BLOCK:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['mindex'],\n                self.plans['lags'],\n                self.plans['inter_method']\n            )\n            for prod_iter in product_iterator:\n                mrate,lags,inter_method = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                mtype = 'block'\n                train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                method = 'GNAR'\n                lrnr = GNARLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn()\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                nof_filters = None \n                epoch= None\n                mrate= lrnr.mrate_total\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_GNAR_BLOCK(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nplnr.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      1\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      2\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      3\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      4\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      5\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      6\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      7\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      8\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      9\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      10\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      11\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n  \n\n\n\n\n\n여기부터 서연이코드\n\nedges_tensor = torch.tensor(data['edges'])\nfiveVTS = np.array(data['f'])\nnonzero_indices = edges_tensor.nonzero()\nfiveNet_edge = np.array(nonzero_indices).T\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\nedge_index\n\nNameError: name 'edge_index' is not defined\n\n\n- train / test\n\nfiveVTS_train = fiveVTS[:int(len(fiveVTS)*0.8)]\nfiveVTS_test = fiveVTS[int(len(fiveVTS)*0.8):]"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#random-missing-values",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#random-missing-values",
    "title": "SY 1st ITSTGCN",
    "section": "Random Missing Values",
    "text": "Random Missing Values\n\nclass Missing:\n    def __init__(self,df):\n        self.df = df\n        self.N = N\n        self.number = []\n    def miss(self,percent=0.5):\n        self.missing = self.df.copy()\n        self.percent = percent\n        for i in range(self.N):\n            #self.seed = np.random.choice(1000,1,replace=False)\n            #np.random.seed(self.seed)\n            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n            self.missing[self.number[i],i] = float('nan')\n    def first_mean(self):\n        self.train_mean = self.missing.copy()\n        for i in range(self.N):\n            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n    def second_linear(self):\n        self.train_linear = pd.DataFrame(self.missing)\n        self.train_linear.interpolate(method='linear', inplace=True)\n        self.train_linear = self.train_linear.fillna(0)\n        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)\n\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n\nrate = [i/10 for i in range(10)]"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#class-code-by-method",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#class-code-by-method",
    "title": "SY 1st ITSTGCN",
    "section": "Class code by Method",
    "text": "Class code by Method"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn",
    "title": "SY 1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn",
    "title": "SY 1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar",
    "title": "SY 1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn-1",
    "title": "SY 1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn-1",
    "title": "SY 1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar-1",
    "title": "SY 1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      0.732\n      0.005\n    \n    \n      1\n      12\n      STGCN\n      2\n      0.732\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      12\n      IT-STGCN\n      2\n      1.186\n      0.051\n    \n    \n      1\n      0.3\n      12\n      STGCN\n      2\n      1.208\n      0.051\n    \n    \n      2\n      0.5\n      12\n      IT-STGCN\n      2\n      1.242\n      0.061\n    \n    \n      3\n      0.5\n      12\n      STGCN\n      2\n      1.330\n      0.073\n    \n    \n      4\n      0.6\n      12\n      IT-STGCN\n      2\n      1.251\n      0.055\n    \n    \n      5\n      0.6\n      12\n      STGCN\n      2\n      1.422\n      0.086\n    \n    \n      6\n      0.7\n      12\n      IT-STGCN\n      2\n      1.167\n      0.059\n    \n    \n      7\n      0.7\n      12\n      STGCN\n      2\n      2.077\n      0.252\n    \n    \n      8\n      0.8\n      12\n      IT-STGCN\n      2\n      1.371\n      0.097\n    \n    \n      9\n      0.8\n      12\n      STGCN\n      2\n      2.432\n      0.263"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.160\n      0.042\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.215\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.752\n      0.013\n    \n    \n      1\n      16\n      STGCN\n      0.752\n      0.012"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.087\n      0.046\n    \n    \n      2\n      0.5\n      linear\n      16\n      IT-STGCN\n      0.958\n      0.072\n    \n    \n      3\n      0.5\n      linear\n      16\n      STGCN\n      1.530\n      0.106\n    \n    \n      4\n      0.6\n      linear\n      16\n      IT-STGCN\n      1.120\n      0.072\n    \n    \n      5\n      0.6\n      linear\n      16\n      STGCN\n      1.753\n      0.181\n    \n    \n      6\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      7\n      0.8\n      linear\n      16\n      STGCN\n      2.529\n      0.292"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.807041\n      0.016362\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.828224\n      0.021919\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.823756\n      0.022918\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.828498\n      0.022007"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.233\n      0.115\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.233\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      4\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.528\n      0.190\n    \n    \n      5\n      0.5\n      4\n      linear\n      STGCN\n      1.593\n      0.195\n    \n    \n      6\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.507\n      0.235\n    \n    \n      7\n      0.5\n      4\n      nearest\n      STGCN\n      1.673\n      0.223\n    \n    \n      8\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      9\n      0.6\n      4\n      linear\n      STGCN\n      1.655\n      0.179\n    \n    \n      10\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      11\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254\n    \n    \n      12\n      0.8\n      4\n      linear\n      IT-STGCN\n      1.753\n      0.306\n    \n    \n      13\n      0.8\n      4\n      linear\n      STGCN\n      1.753\n      0.148\n    \n    \n      14\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.608\n      0.243\n    \n    \n      15\n      0.8\n      4\n      nearest\n      STGCN\n      1.871\n      0.214"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#w_st",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.528\n      0.003"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.570\n      0.006\n    \n    \n      2\n      0.5\n      8\n      IT-STGCN\n      0.524\n      0.003\n    \n    \n      3\n      0.5\n      8\n      STGCN\n      0.658\n      0.010\n    \n    \n      4\n      0.6\n      8\n      IT-STGCN\n      0.539\n      0.004\n    \n    \n      5\n      0.6\n      8\n      STGCN\n      0.731\n      0.015\n    \n    \n      6\n      0.8\n      8\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      7\n      0.8\n      8\n      STGCN\n      0.932\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003835\n      8\n      IT-STGCN\n      0.528737\n      0.002806\n    \n    \n      1\n      0.003835\n      8\n      STGCN\n      0.527871\n      0.002606\n    \n    \n      2\n      0.095870\n      8\n      IT-STGCN\n      0.529440\n      0.003820\n    \n    \n      3\n      0.095870\n      8\n      STGCN\n      0.544176\n      0.010772\n    \n    \n      4\n      0.119837\n      8\n      IT-STGCN\n      0.522825\n      0.002422\n    \n    \n      5\n      0.119837\n      8\n      STGCN\n      0.531188\n      0.002295"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.533\n      0.003\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.726\n      0.015"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.004\n      0.004\n    \n    \n      1\n      8\n      STGCN\n      1.003\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.194\n      0.042\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.662\n      0.073"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      1.007\n      0.005\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      1.008\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.931\n      0.001\n    \n    \n      1\n      4\n      STGCN\n      0.931\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      nearest\n      IT-STGCN\n      0.936185\n      0.001825\n    \n    \n      1\n      0.3\n      4\n      nearest\n      STGCN\n      0.991390\n      0.007285\n    \n    \n      2\n      0.5\n      4\n      nearest\n      IT-STGCN\n      0.942045\n      0.002642\n    \n    \n      3\n      0.5\n      4\n      nearest\n      STGCN\n      1.149221\n      0.017820\n    \n    \n      4\n      0.7\n      4\n      nearest\n      IT-STGCN\n      1.015221\n      0.012403\n    \n    \n      5\n      0.7\n      4\n      nearest\n      STGCN\n      1.393108\n      0.027555\n    \n    \n      6\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.095560\n      0.018743\n    \n    \n      7\n      0.8\n      4\n      nearest\n      STGCN\n      1.516000\n      0.039793"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      cubic\n      IT-STGCN\n      1.022866\n      0.021048\n    \n    \n      1\n      0.149142\n      4\n      cubic\n      STGCN\n      1.028363\n      0.031275\n    \n    \n      2\n      0.149142\n      4\n      linear\n      IT-STGCN\n      0.930156\n      0.001956\n    \n    \n      3\n      0.149142\n      4\n      linear\n      STGCN\n      0.934719\n      0.004724\n    \n    \n      4\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.931785\n      0.002158\n    \n    \n      5\n      0.149142\n      4\n      nearest\n      STGCN\n      0.934596\n      0.003562"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html",
    "title": "Class of Method(GNAR) lag 2",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 2"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오1-baseline",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오1-baseline",
    "title": "Class of Method(GNAR) lag 2",
    "section": "시나리오1 (Baseline)",
    "text": "시나리오1 (Baseline)\n시나리오1\n\nmissing rate: 0%\n보간방법: None\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([fiveVTS_train[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(fiveVTS_train[2:int(T*0.8),:].reshape(int(T*0.8)-2,N,-1)).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:26<00:00,  1.87it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR 으로 적합 + 예측\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\nlibrary(tidyverse)\n\n\n%R -i fiveVTS_train\n\n\n%%R\nanswer <- GNARfit(vts = fiveVTS_train, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean(axis=0)\ntest_mse_total_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.995256618187614, 1.2577286248028454)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(2,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),gnar_train.reshape(-1,5)[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(160,200),gnar_test.reshape(-1,5)[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오2",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오2",
    "title": "Class of Method(GNAR) lag 2",
    "section": "시나리오2",
    "text": "시나리오2\n시나리오2\n\nmissing rate: 50%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:26<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:28<00:00,  1.78it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.6280648350096797, 1.3222499750457097)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오3",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오3",
    "title": "Class of Method(GNAR) lag 2",
    "section": "시나리오3",
    "text": "시나리오3\n시나리오3\n\nmissing rate: 80%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:28<00:00,  1.77it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.2092691948436627, 1.5191113001100904)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오4",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#시나리오4",
    "title": "Class of Method(GNAR) lag 2",
    "section": "시나리오4",
    "text": "시나리오4\n시나리오4\n\nmissing rate: 30%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN 으로 적합 + 예측\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [00:27<00:00,  1.79it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\n결과시각화\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7594163080873634, 1.2656937545324825)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2022-12-07-torchgcn.html",
    "href": "posts/GCN/2022-12-07-torchgcn.html",
    "title": "TORCH_GEOMETRIC.NN",
    "section": "",
    "text": "221207\nhttps://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html\n\nimport torch\nfrom torch_geometric.data import Data\n\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index)\n\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\nG=nx.Graph()\nG.add_node('0')\nG.add_node('1')\nG.add_node('2')\nG.add_edge('0','1')\nG.add_edge('1','2')\npos = {}\npos['0'] = (0,0)\npos['1'] = (1,1)\npos['2'] = (2,0)\nnx.draw(G,pos,with_labels=True)\nplt.show()\n\n\n\n\n\nfrom torch.nn import Linear, ReLU\nfrom torch_geometric.nn import Sequential, GCNConv\n\nex\nmodel = Sequential('x, edge_index', [\n    (GCNConv(in_channels, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    Linear(64, out_channels),\n])\n\nmodel = Sequential('x, edge_index', [\n    (GCNConv(3, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    Linear(64, 3),\n])\n\n\nmodel(x,edge_index)\n\n\nfrom torch.nn import Linear, ReLU, Dropout\nfrom torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\nfrom torch_geometric.nn import global_mean_pool\n\nmodel = Sequential('x, edge_index, batch', [\n    (Dropout(p=0.5), 'x -> x'),\n    (GCNConv(dataset.num_features, 64), 'x, edge_index -> x1'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n    ReLU(inplace=True),\n    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n    (global_mean_pool, 'x, batch -> x'),\n    Linear(2 * 64, dataset.num_classes),\n])\n\nmodel = Sequential('x, edge_index, batch', [\n    (Dropout(p=0.5), 'x -> x'),\n    (GCNConv(dataset.num_features, 64), 'x, edge_index -> x1'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n    ReLU(inplace=True),\n    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n    (global_mean_pool, 'x, batch -> x'),\n    Linear(2 * 64, dataset.num_classes),\n])\n\n\ntorch_geometric.nn.Linear()"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html",
    "href": "posts/GCN/2023-01-21-Class.html",
    "title": "Class of Method",
    "section": "",
    "text": "Class"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean",
    "href": "posts/GCN/2023-01-21-Class.html#mean",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero.train_mean\nc = ___zero.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n\n\n3282.4832243919373\n\n\n\nmean_mse100_10 = pd.DataFrame(_mse)\n\n\nmean_mae100_10 = pd.DataFrame(_mae)\n\n\n_train_result_mean10 = _train_result.copy()\n\n\n_test_result_mean10 = _test_result.copy()\n\n\nplt.plot(mean_mse100_10.T);\n\n\n\n\n\nplt.plot(mean_mae100_10.T);\n\n\n\n\n\nvis2(_zero.train_mean,_train_result[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear",
    "href": "posts/GCN/2023-01-21-Class.html#linear",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero.second_linear\nc = ___zero.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3295.478456020355\n\n\n\nlinear_mse100_10 = pd.DataFrame(_mse)\n\n\nlinear_mae100_10 = pd.DataFrame(_mae)\n\n\n_train_result_linear10 = _train_result.copy()\n\n\n_test_result_linear10 = _test_result.copy()\n\n\nplt.plot(linear_mse100_10.T);\n\n\n\n\n\nplt.plot(linear_mae100_10.T);\n\n\n\n\n\nvis2(_zero.train_mean,_train_result_linear10[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear10[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-1",
    "href": "posts/GCN/2023-01-21-Class.html#mean-1",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero20.train_mean\nc = ___zero20.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:52<00:00,  1.89it/s]\n100%|██████████| 100/100 [00:52<00:00,  1.89it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n\n\n3277.0478909015656\n\n\n\nmean_mse100_20 = pd.DataFrame(_mse)\n\n\nmean_mae100_20 = pd.DataFrame(_mae)\n\n\n_train_result_mean20 = _train_result.copy()\n\n\n_test_result_mean20 = _test_result.copy()\n\n\nplt.plot(mean_mse100_20.T);\n\n\n\n\n\nplt.plot(mean_mae100_20.T);\n\n\n\n\n\nvis2(___zero20.train_mean,_train_result_mean20[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean20[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean20)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-1",
    "href": "posts/GCN/2023-01-21-Class.html#linear-1",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero20.second_linear\nc = ___zero20.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3298.6988050937653\n\n\n\nlinear_mse100_20 = pd.DataFrame(_mse)\n\n\nlinear_mae100_20 = pd.DataFrame(_mae)\n\n\n_train_result_linear20 = _train_result.copy()\n\n\n_test_result_linear20 = _test_result.copy()\n\n\nplt.plot(linear_mse100_20.T);\n\n\n\n\n\nplt.plot(linear_mae100_20.T);\n\n\n\n\n\nvis2(___zero20.train_mean,_train_result_linear20[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear20[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear20)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-2",
    "href": "posts/GCN/2023-01-21-Class.html#mean-2",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero30.train_mean\nc = ___zero30.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n\n\n3280.9767186641693\n\n\n\nmean_mse_30 = pd.DataFrame(_mse)\n\n\nmean_mae_30 = pd.DataFrame(_mae)\n\n\n_train_result_mean30 = _train_result.copy()\n\n\n_test_result_mean30 = _test_result.copy()\n\n\nplt.plot(mean_mse_30.T);\n\n\n\n\n\nplt.plot(mean_mae_30.T);\n\n\n\n\n\nvis2(___zero30.train_mean,_train_result_mean30[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean30[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean30)\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-2",
    "href": "posts/GCN/2023-01-21-Class.html#linear-2",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero30.second_linear\nc = ___zero30.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3305.375289440155\n\n\n\nlinear_mse_30 = pd.DataFrame(_mse)\n\n\nlinear_mae_30 = pd.DataFrame(_mae)\n\n\n_train_result_linear30 = _train_result.copy()\n\n\n_test_result_linear30 = _test_result.copy()\n\n\nplt.plot(linear_mse_30.T);\n\n\n\n\n\nplt.plot(linear_mae_30.T);\n\n\n\n\n\nvis2(___zero30.train_mean,_train_result_linear30[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear30[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear30)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-3",
    "href": "posts/GCN/2023-01-21-Class.html#mean-3",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero40.train_mean\nc = ___zero40.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n\n\n3287.529237985611\n\n\n\nmean_mse_40 = pd.DataFrame(_mse)\n\n\nmean_mae_40 = pd.DataFrame(_mae)\n\n\n_train_result_mean40 = _train_result.copy()\n\n\n_test_result_mean40 = _test_result.copy()\n\n\nplt.plot(mean_mse_40.T);\n\n\n\n\n\nplt.plot(mean_mae_40.T);\n\n\n\n\n\nvis2(___zero40.train_mean,_train_result_mean40[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean40[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean40)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-3",
    "href": "posts/GCN/2023-01-21-Class.html#linear-3",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero40.second_linear\nc = ___zero40.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.82it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3303.96302652359\n\n\n\nlinear_mse_40 = pd.DataFrame(_mse)\n\n\nlinear_mae_40 = pd.DataFrame(_mae)\n\n\n_train_result_linear40 = _train_result.copy()\n\n\n_test_result_linear40 = _test_result.copy()\n\n\nplt.plot(linear_mse_40.T);\n\n\n\n\n\nplt.plot(linear_mae_40.T);\n\n\n\n\n\nvis2(___zero40.train_mean,_train_result_linear40[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear40[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear40)\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-4",
    "href": "posts/GCN/2023-01-21-Class.html#mean-4",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero50.train_mean\nc = ___zero50.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n\nmean_mse_50 = pd.DataFrame(_mse)\n\n\nmean_mae_50 = pd.DataFrame(_mae)\n\n\n_train_result_mean50 = _train_result.copy()\n\n\n_test_result_mean50 = _test_result.copy()\n\n\nplt.plot(mean_mse_50.T);\n\n\nplt.plot(mean_mae_50.T);\n\n\nvis2(_zero.train_mean,_train_result_mean50[59]);\n\n\nvis2(fiveVTS_test[1:],_test_result_mean50[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-4",
    "href": "posts/GCN/2023-01-21-Class.html#linear-4",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero50.second_linear\nc = ___zero50.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n\nlinear_mse_50 = pd.DataFrame(_mse)\n\n\nlinear_mae_50 = pd.DataFrame(_mae)\n\n\n_train_result_linear50 = _train_result.copy()\n\n\n_test_result_linear50 = _test_result.copy()\n\n\nplt.plot(linear_mse_50.T);\n\n\nplt.plot(linear_mae_50.T);\n\n\nvis2(_zero.train_mean,_train_result_linear50[59]);\n\n\nvis2(fiveVTS_test[1:],_test_result_linear50[0]);"
  },
  {
    "objectID": "posts/GCN/2023-07-04-toy_example_figure.html",
    "href": "posts/GCN/2023-07-04-toy_example_figure.html",
    "title": "Toy Example Figure(Intro)",
    "section": "",
    "text": "edit\n\n\n교수님 설정(수정 안 한 것)\n\nT = 100\nt = np.arange(T)/T * 5\n\nx = 0.1*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\ndf1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset_DCRNN = loader1.get_dataset(lags=1)\n\n\nmindex = [[np.array(list(range(20,35)))],random.sample(range(0, T), int(T*0.5))]\ndataset_miss_DCRNN = itstgcn.miss(dataset_DCRNN,mindex,mtype='block')\n\n\ndataset_padded_DCRNN = itstgcn.padding(dataset_miss_DCRNN,interpolation_method='linear')\n\n\nlrnr_DCRNN = itstgcn.StgcnLearner(dataset_padded_DCRNN)\n\n\nlrnr_DCRNN.learn(filters=1,epoch=10,lr=0.01,RecurrentGCN='GConvLSTM')\n\n\nevtor_DCRNN = Eval_csy(lrnr_DCRNN,dataset_padded_DCRNN)\n\n\nlrnr_DCRNN2 = itstgcn.ITStgcnLearner(dataset_padded_DCRNN)\n\n\nlrnr_DCRNN2.learn(filters=1,epoch=10,lr=0.01,RecurrentGCN='GConvLSTM')\n\n\n\n\n초기 설정(수정 안 한 것)\n\nT = 200\nt = np.arange(T)/T * 10\nx = 0.1*np.sin(2*t)+0.2*np.sin(4*t)+0.1*np.sin(8*t)+0.2*np.sin(16*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\neps_y  = np.random.normal(size=T)*0\nx = x*0.35\ny = y*0.3\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1],[1,0]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\ndf1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset_GConvLSTM = loader1.get_dataset(lags=1)\n\n\nmindex = [random.sample(range(0, T), int(T*0.5)),[np.array(list(range(100,120)))]]\ndataset_miss_GConvLSTM = itstgcn.miss(dataset_GConvLSTM,mindex,mtype='block')\n\n\ndataset_padded_cubic_GConvLSTM = itstgcn.padding(dataset_miss_GConvLSTM,interpolation_method='cubic')\n\n\nlrnr_GConvLSTM = itstgcn.StgcnLearner(dataset_padded_cubic_GConvLSTM)\n\n\nlrnr_GConvLSTM.learn(filters=8,epoch=50,RecurrentGCN='GConvLSTM')\n\n\n\n\nimport\n\nimport itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nimport random\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nfrom plotnine import *\n\n\n\nExample\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+np.random.rand(T)+np.sin(4*t)+1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n_x = np.array(dataset_padded.targets)[:,0]\n\n\nplt.plot(_x)\nplt.plot(itstgcn.trim(_x))\n\n\n\n\n\n# T = 100\n# t = np.arange(T)/T * 5\n\n# x = 0.01*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\n# eps_x  = np.random.normal(size=T)*0\n# y = x.copy()\n# for i in range(2,T):\n#     y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \n# eps_y  = np.random.normal(size=T)*0\n# x = x\n# y = y\n# plt.plot(t,x,color='C0',lw=5)\n# plt.plot(t,x+eps_x,alpha=0.5,color='C0')\n# plt.plot(t,y,color='C1',lw=5)\n# plt.plot(t,y+eps_y,alpha=0.5,color='C1')\n# _node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n# _edges1 = torch.tensor([[0,1]]).tolist()\n\n# data_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\n# data1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.9)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1],'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot((mindex[1][0][0]+mindex[1][0][len(mindex[1][0])-1])/2, 0.1,'s', markersize=110, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [[np.array(list(range(40,55)))],[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=1,epoch=10)\n\n10/10\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=1,epoch=10)\n\n10/10\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nnp.array(dataset_miss.features).shape\n\n(96, 2, 4)\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\n\n시도 1\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = np.sin(2*t)+0.5*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=4,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax1 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n#     ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax1.tick_params(axis='y', labelsize=40)\n#     ax1.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_fst.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax2 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data',markersize=15)\n#     ax2.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax2.tick_params(axis='y', labelsize=40)\n#     ax2.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_snd.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax3 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)    \n#     ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n#     ax3.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax3.tick_params(axis='y', labelsize=40)\n#     ax3.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_3rd.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax4 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n#     ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n#     ax4.plot(138, -1.2, 'o', markersize=230, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(220, -1.5, 'o', markersize=200, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(290, -1.2, 'o', markersize=310, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(455, -0.9, 'o', markersize=280, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax4.tick_params(axis='y', labelsize=40)\n#     ax4.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_4th_1.png')\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\n시도 2\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.4*np.random.rand(T)+np.sin(4*t)+1.3*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try1_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try1_node2.png')\n\n\n\n\n\n\n시도 3\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n_data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n_loader = itstgcn.DatasetLoader(_data_dict)\n\n\n_dataset = _loader.get_dataset(lags=2)\n\n\nmindex = [random.sample(range(0, 200), int(200*0.8)),[np.array(list(range(40,100)))]]\n_dataset_miss = itstgcn.miss(_dataset,mindex,mtype='block')\n\n\n# mindex = itstgcn.rand_mindex(dataset,mrate=0.8)\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n_dataset_padded = itstgcn.padding(_dataset_miss,interpolation_method='linear')\n\n\n_lrnr = itstgcn.StgcnLearner(_dataset_padded)\n\n\n_lrnr.learn(filters=12,epoch=10)\n\n10/10\n\n\n\n_evtor = Eval_csy(_lrnr,_dataset_padded)\n\n\n_lrnr_2 = itstgcn.ITStgcnLearner(_dataset_padded)\n\n\n_lrnr_2.learn(filters=12,epoch=10)\n\n10/10\n\n\n\n_evtor_2 = Eval_csy(_lrnr_2,_dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(_dataset.features)[:2,0,0],torch.tensor(_dataset_miss.targets).reshape(-1,5)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(_evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(_evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(_evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(torch.tensor(_dataset.features)[:,1,0],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(_dataset.features)[:2,1,0],torch.tensor(_dataset_miss.targets).reshape(-1,5)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(_evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(_evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(_evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\n시도 4 noise 0\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+np.sin(4*t)+1.2*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.5)),[np.array(list(range(50,95)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(135, -1.5, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(220, -1.5, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(290, -1.8, 'o', markersize=120, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(450, -1.5, 'o', markersize=120, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1_2.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(75, 0.75, 'o', markersize=150, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2_2.png')\n\n\n\n\n\n\n시도 5 noise 10%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.1*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try3_node1_noise10.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try3_node2_noise10.png')\n\n\n\n\n\n\n시도 6 noise 20%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.2*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.75)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try4_node1_noise20.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2_noise20.png')\n\n\n\n\n\n\n시도 7 noise 30%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.75)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try5_node1_noise30.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try5_node2_noise20.png')\n\n\n\n\n\n\n시도 8 noise 30% only random\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\n# mindex = [random.sample(range(0, T), int(T*0.7)),[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\nmindex = itstgcn.rand_mindex(dataset,mrate=0.75)\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\n시도 9 noise 40%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.4*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [[np.array(list(range(40,85)))],random.sample(range(0, T), int(T*0.7))]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=32,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=32,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node1_noise40.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node2_noise40.png')\n\n\n\n\n\n\n시도 10 noise 50%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.1*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.7)),[np.array(list(range(40,85)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node1_noise40.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node2_noise40.png')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html",
    "title": "1st ITSTGCN",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn",
    "title": "1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn",
    "title": "1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar",
    "title": "1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn-1",
    "title": "1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn-1",
    "title": "1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar-1",
    "title": "1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-10_15-33-00.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-10_16-06-20.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-14_19-23-44.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-15_15-51-38.csv')\ndf3 = pd.read_csv('./simulation_results/2023-06-16_04-32-51.csv')\n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      2\n      1.211\n      0.021\n    \n    \n      1\n      4\n      STGCN\n      2\n      1.213\n      0.026"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      IT-STGCN\n      2\n      1.220\n      0.026\n    \n    \n      1\n      0.3\n      4\n      STGCN\n      2\n      1.216\n      0.020\n    \n    \n      2\n      0.5\n      4\n      IT-STGCN\n      2\n      1.215\n      0.025\n    \n    \n      3\n      0.5\n      4\n      STGCN\n      2\n      1.237\n      0.038\n    \n    \n      4\n      0.6\n      4\n      IT-STGCN\n      2\n      1.226\n      0.031\n    \n    \n      5\n      0.6\n      4\n      STGCN\n      2\n      1.234\n      0.036\n    \n    \n      6\n      0.7\n      4\n      IT-STGCN\n      2\n      1.232\n      0.036\n    \n    \n      7\n      0.7\n      4\n      STGCN\n      2\n      1.250\n      0.048\n    \n    \n      8\n      0.8\n      4\n      IT-STGCN\n      2\n      1.232\n      0.038\n    \n    \n      9\n      0.8\n      4\n      STGCN\n      2\n      1.250\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      4\n      IT-STGCN\n      1.218\n      0.025\n    \n    \n      1\n      0.125\n      4\n      STGCN\n      1.245\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      0.865\n      0.040\n    \n    \n      1\n      8\n      STGCN\n      0.872\n      0.053"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      8\n      IT-STGCN\n      0.870\n      0.035\n    \n    \n      1\n      0.3\n      linear\n      8\n      STGCN\n      1.086\n      0.029\n    \n    \n      2\n      0.5\n      linear\n      8\n      IT-STGCN\n      0.931\n      0.034\n    \n    \n      3\n      0.5\n      linear\n      8\n      STGCN\n      1.458\n      0.068\n    \n    \n      4\n      0.6\n      linear\n      8\n      IT-STGCN\n      1.017\n      0.029\n    \n    \n      5\n      0.6\n      linear\n      8\n      STGCN\n      1.615\n      0.134\n    \n    \n      6\n      0.8\n      linear\n      8\n      IT-STGCN\n      1.334\n      0.071\n    \n    \n      7\n      0.8\n      linear\n      8\n      STGCN\n      1.632\n      0.156"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      8\n      IT-STGCN\n      0.888210\n      0.034704\n    \n    \n      1\n      linear\n      0.28777\n      8\n      STGCN\n      0.910671\n      0.047118\n    \n    \n      2\n      nearest\n      0.28777\n      8\n      IT-STGCN\n      0.888035\n      0.040932\n    \n    \n      3\n      nearest\n      0.28777\n      8\n      STGCN\n      0.902404\n      0.039003"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      8\n      IT-STGCN\n      1.193\n      0.059\n    \n    \n      1\n      4\n      8\n      STGCN\n      1.188\n      0.050"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.210\n      0.039\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.274\n      0.045\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.220\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      4\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.242\n      0.057\n    \n    \n      5\n      0.5\n      4\n      linear\n      STGCN\n      1.432\n      0.077\n    \n    \n      6\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.240\n      0.036\n    \n    \n      7\n      0.5\n      4\n      nearest\n      STGCN\n      1.379\n      0.079\n    \n    \n      8\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.286\n      0.053\n    \n    \n      9\n      0.6\n      4\n      linear\n      STGCN\n      1.459\n      0.073\n    \n    \n      10\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.286\n      0.033\n    \n    \n      11\n      0.6\n      4\n      nearest\n      STGCN\n      1.462\n      0.084\n    \n    \n      12\n      0.8\n      4\n      linear\n      IT-STGCN\n      1.440\n      0.094\n    \n    \n      13\n      0.8\n      4\n      linear\n      STGCN\n      1.496\n      0.086\n    \n    \n      14\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.436\n      0.091\n    \n    \n      15\n      0.8\n      4\n      nearest\n      STGCN\n      1.529\n      0.071"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.169\n      0.040\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.204\n      0.032\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#w_st",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.299\n      0.147\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.325\n      0.086\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.117\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.087\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.331\n      0.120\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.453\n      0.115\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.106\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.347\n      0.117"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      32\n      IT-STGCN\n      0.610\n      0.017\n    \n    \n      1\n      8\n      32\n      STGCN\n      0.608\n      0.014"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.619\n      0.019\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.689\n      0.032\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.769\n      0.045\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.105\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.608375\n      0.012177\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.624250\n      0.023857"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.624\n      0.019\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.810\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.977\n      0.024\n    \n    \n      1\n      4\n      STGCN\n      0.983\n      0.024"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      0.982006\n      0.013261\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      0.989219\n      0.028653"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.978381\n      0.024324\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.976996\n      0.020351"
  },
  {
    "objectID": "posts/GCN/2023-04-27-toy_example_notes.html",
    "href": "posts/GCN/2023-04-27-toy_example_notes.html",
    "title": "Toy Example Note",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nimport pickle\n\n\nT = 50\nt = np.arange(T)/T * 10 \n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nimport torch\n\n\nx = 50*np.sin(2*t)#+30*np.sin(5*t)\neps_x  = np.random.normal(size=T)\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 50*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)\n\n\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x,y],axis=1).tolist()\n\n_edges1 = torch.tensor([[1,0]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nnp.stack([x+eps_x,y+eps_y],axis=1).shape\n\n(800, 2)\n\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_FX = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n\n_edges = torch.tensor([[0,0],[0,1],[1,0],[1,1]]).tolist()\n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\ndata_dict['edges']\n\n[[0, 0], [0, 1], [1, 0], [1, 1]]\n\n\n\nnp.array(data_dict['edges']).shape\n\n(4, 2)\n\n\n\nsave_data(data_dict, './data/toy_example.pkl')\n\n\ndata_dict = load_data('./data/toy_example.pkl')\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\ndata_dict['edges']\n\n[[0, 0], [0, 1], [1, 0], [1, 1]]\n\n\n\ndata_dict['node_ids']\n\n{'node1': 0, 'node2': 1}\n\n\n\nnp.array(data_dict['FX']).shape\n\n(800, 2)\n\n\n\ndata = pd.DataFrame({'x':x,'y':y,'xer':x+eps_x,'yer':y+eps_y})\n\n\nsave_data(data, './data/toy_example_true.csv')\n\n\ndata = load_data('./data/toy_example_true.csv')\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_FX1 = np.stack([x,y],axis=1).tolist()\n\n\n_edges1 = torch.tensor([[1,0]]).tolist()\n\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\nsave_data(data1, './data/toy_example_true1.csv')"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html",
    "title": "data load, data save as pickle",
    "section": "",
    "text": "data load, data save as pickle\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/index.html\n1st\n2nd\n3rd\n4rd\n5th - TwitterTennisDatasetLoader(원핫 인코딩 함수도 별도로 있음) - get_dataset(self) -> DynamicGraphTemporalSignal: - dataset = DynamicGraphTemporalSignal(self.edges, self.edge_weights, self.features, self.target"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#chickenpoxdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#chickenpoxdatasetloader",
    "title": "data load, data save as pickle",
    "section": "ChickenpoxDatasetLoader",
    "text": "ChickenpoxDatasetLoader\nChickenpox Hungary\n\nA dataset of county level chicken pox cases in Hungary between 2004 and 2014. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are counties and edges are neighbourhoods. Vertex features are lagged weekly counts of the chickenpox cases (we included 4 lags). The target is the weekly number of cases for the upcoming week (signed integers). Our dataset consist of more than 500 snapshots (weeks).\n2004년부터 2014년 사이 헝가리의 지역별 수두증 발생 데이터셋\n그래프는 정적\nnode 지역\nedge 이웃 관계\nnode 특성은 수두증 발생의 지연된 주간 횟수(4주의 지연이 포함되어 있음)\ntarget는 다음 주에 대한 주간 사례 수\n500개 이상의 스냅샷(주간)\n\n데이터정리\n\nT = 519\nN = 20 # number of nodes\nE = 102 # edges\n\\(f(v,t)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 517\n\nbetween 2004 and 2014\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\na = loader1.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(520, 20, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 102)\n\n\n\nnp.array(a.edge_weight).shape\n\n(102,)\n\n\n\na.edge_weight\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\n\n\na.edge_index\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nfrom haversine import haversine\n\n\nhaversine?\n\n\nSignature:\nhaversine(\n    point1,\n    point2,\n    unit=<Unit.KILOMETERS: 'km'>,\n    normalize=False,\n    check=True,\n)\nDocstring:\nCalculate the great-circle distance between two points on the Earth surface.\nTakes two 2-tuples, containing the latitude and longitude of each point in decimal degrees,\nand, optionally, a unit of length.\n:param point1: first point; tuple of (latitude, longitude) in decimal degrees\n:param point2: second point; tuple of (latitude, longitude) in decimal degrees\n:param unit: a member of haversine.Unit, or, equivalently, a string containing the\n             initials of its corresponding unit of measurement (i.e. miles = mi)\n             default 'km' (kilometers).\n:param normalize: if True, normalize the points to [-90, 90] latitude and [-180, 180] longitude.\n:param check: if True, check that points are normalized.\nExample: ``haversine((45.7597, 4.8422), (48.8567, 2.3508), unit=Unit.METERS)``\nPrecondition: ``unit`` is a supported unit (supported units are listed in the `Unit` enum)\n:return: the distance between the two points in the requested unit, as a float.\nThe default returned unit is kilometers. The default unit can be changed by\nsetting the unit parameter to a member of ``haversine.Unit``\n(e.g. ``haversine.Unit.INCHES``), or, equivalently, to a string containing the\ncorresponding abbreviation (e.g. 'in'). All available units can be found in the ``Unit`` enum.\nFile:      ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/haversine/haversine.py\nType:      function\n\n\n\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_chickenpox.png\")\n\n\n\n\n\n# nx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\nnode_list = []\nfor i in range(0, 20):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(20,1,figsize=(30,70))\nfor k in range(20):\n    ax[k].plot(np.array(loader1.targets).reshape(20,-1)[k][:],alpha=1,label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\n# fig,ax = plt.subplots(3,1,figsize=(20,10))\n# for k in range(3):\n#     ax[k].plot(np.array(loader1.targets).reshape(20,-1)[k][:],alpha=1,label='observed')\n#     ax[k].set_title('node: {}'.format(node_list[k]))\n#     ax[k].legend()\n# fig.tight_layout()\n# plt.savefig('graph_node_ex2.png')\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\n# fig = px.line(_df, x='x', y=['y1', 'y2','y3','y4','y5','y6'])\n# fig.update_layout(width=900, height=500)\n# fig.show()\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# 서브플롯 생성\nfig = make_subplots(rows=2, cols=3)\n\n# 각 서브플롯에 선 그래프 추가\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# 그래프 크기 조정\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# 그래프 출력\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_chickenpox.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_chickenpox.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#pedalmedatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#pedalmedatasetloader",
    "title": "data load, data save as pickle",
    "section": "PedalMeDatasetLoader",
    "text": "PedalMeDatasetLoader\nPedal Me Deliveries\n\nA dataset of PedalMe Bicycle deliver orders in London between 2020 and 2021. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are localities and edges are spatial_connections. Vertex features are lagged weekly counts of the delivery demands (we included 4 lags). The target is the weekly number of deliveries the upcoming week. Our dataset consist of more than 30 snapshots (weeks)\n2020년과 2021년 사이 런던에서 PedalMe 자전거 배송 주문 데이터셋\n그래프는 정적\nnode 장소\nedge 공간 연결\nnode 특성은 배송 수요의 지연된 주간 횟수(4주의 지연이 포함되어 있음)\ntarget 다음 주에 대한 주간 배송 횟수\n30개 이상의 스냅샷(주간)\n\n데이터정리\n\nT = 31\nV = 지역의 집합\nN = 15 # number of nodes\nE = 225 # edges\n\\(f(v,t)\\)의 차원? (1,) # number of deliveries\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (15,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (15,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 15\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 31\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\na = loader2.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(34, 15, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 225)\n\n\n\nnp.array(a.edge_weight).shape\n\n(225,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_pedalme.png\")\n\n\n\n\n\nnode_list = []\nfor i in range(0, 15):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(15,1,figsize=(20,50))\nfor k in range(15):\n    ax[k].plot(np.array(loader2.targets).reshape(15,-1)[k][:],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\n# fig = px.line(_df, x='x', y=['y1', 'y2','y3','y4','y5','y6'])\n# fig.update_layout(width=900, height=500)\n# fig.show()\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# 서브플롯 생성\nfig = make_subplots(rows=2, cols=3)\n\n# 각 서브플롯에 선 그래프 추가\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# 그래프 크기 조정\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# 그래프 출력\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_pedalme.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_pedalme.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#wikimathsdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#wikimathsdatasetloader",
    "title": "data load, data save as pickle",
    "section": "WikiMathsDatasetLoader",
    "text": "WikiMathsDatasetLoader\nWikipedia Math\n\nA dataset of vital mathematics articles from Wikipedia. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are Wikipedia pages and edges are links between them. The graph is directed and weighted. Weights represent the number of links found at the source Wikipedia page linking to the target Wikipedia page. The target is the daily user visits to the Wikipedia pages between March 16th 2019 and March 15th 2021 which results in 731 periods.\n위키피디아에서 중요한 수학 기사들로 이루어진 데이터셋\n그래프는 정적\nnode 위키피디아 페이지\nedge 페이지 간의 링크\n그래프는 방향성이 있으며 가중치가 있음\n가중치는 소스 위키피디아 페이지에서 대상 위키피디아 페이지로 연결된 링크 수\ntarget 2019년 3월 16일부터 2021년 3월 15일까지 위키피디아 페이지의 일일 사용자 방문 수\n기간은 731개의 기간으로 구성됩니다.\n\n데이터정리\n\nT = 723\nV = 위키피디아 페이지\nN = 1068 # number of nodes\nE = 27079 # edges\n\\(f(v,t)\\)의 차원? (1,) # 해당페이지를 유저가 방문한 횟수\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (1068,8) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3),f(v,t_4),f(v,t_5),f(v,t_6),f(v,t_7)\\)\ny: (1068,) (N,), \\(f(v,t_8)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 1068\n\nvertices are Wikipedia pages\n\n-Edges : 27079\n\nedges are links between them\n\n- Time : 723\n\nWikipedia pages between March 16th 2019 and March 15th 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\na = loader3.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(730, 1068, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 27079)\n\n\n\nnp.array(a.edge_weight).shape\n\n(27079,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_wikimath.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 1068):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(20, 70))\nindices = random.sample(range(0, 1068), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader3.targets).reshape(1068,-1)[idx][:], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# 각 서브플롯에 선 그래프 추가\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# 그래프 크기 조정\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# 그래프 출력\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_wikimath.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_wikimath.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputlargedatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputlargedatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputLargeDatasetLoader",
    "text": "WindmillOutputLargeDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 319 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks\n유럽 국가의 풍력 발전소에서 2년 이상에 걸쳐 발생한 시간별 에너지 출력 데이터\nnode 319개의 풍력 발전소\n가중치가 있는 edge는 관계의 강도\n회귀 분석 작업에 적합한 목표 변수를 제공\n\n데이터정리\n\nT = 17464\nV = 풍력발전소\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 319\n\nvertices represent 319 windmills\n\n-Edges : 101761\n\nweighted edges describe the strength of relationships.\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputLargeDatasetLoader\nloader4 = WindmillOutputLargeDatasetLoader()\n\n\na = loader4.get_dataset()\n\n\nnp.array(a.features).shape\n\n(17464, 319, 8)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 101761)\n\n\n\nnp.array(a.edge_weight).shape\n\n(101761,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\na= np.arange(1,100)\na\n\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n\n\n\na[::10]\n\narray([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n\n\n\nnp.array(loader4.targets).reshape(319,-1)[idx][::100].shape\n\n(175,)\n\n\n\nnode_list = []\nfor i in range(0, 319):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader4.targets).reshape(319,-1)[idx][:1000], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader4.targets).reshape(319,-1)[idx][:], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputmediumdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputmediumdatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputMediumDatasetLoader",
    "text": "WindmillOutputMediumDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 26 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n유럽 국가의 풍력 발전소에서 2년 이상에 걸쳐 발생한 시간별 에너지 출력 데이터셋\nnode 26개의 풍력 발전소\n가중치가 있는 edge는 관계의 강도\n회귀 분석 작업에 적합한 목표 변수를 제공\n\n데이터정리\n\nT = 17464\nV = 풍력발전소\nN = 26 # number of nodes\nE = 676 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (26,4) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (26,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 26\n\nvertices represent 26 windmills\n\n-Edges : 676\n\nweighted edges describe the strength of relationships\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputMediumDatasetLoader\nloader5 = WindmillOutputMediumDatasetLoader()\n\n\na = loader5.get_dataset()\n\n\nnp.array(a.features).shape\n\n(17464, 26, 8)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 676)\n\n\n\nnp.array(a.edge_weight).shape\n\n(676,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 26):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(26,1,figsize=(30,70))\nfor k in range(26):\n    ax[k].plot(np.array(loader5.targets).reshape(26,-1)[k],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nfig,ax = plt.subplots(26,1,figsize=(30,70))\nfor k in range(26):\n    ax[k].plot(np.array(loader5.targets).reshape(26,-1)[k][:1000],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputsmalldatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputsmalldatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputSmallDatasetLoader",
    "text": "WindmillOutputSmallDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 11 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n유럽 국가의 풍력 발전소에서 2년 이상에 걸쳐 발생한 시간별 에너지 출력 데이터셋\nnode 11개의 풍력 발전소\n가중치가 있는 edge는 관계의 강도\n회귀 분석 작업에 적합한 목표 변수를 제공합니다.\n\n데이터정리\n\nT = 17464\nV = 풍력발전소\nN = 11 # number of nodes\nE = 121 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (11,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (11,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 11\n\nvertices represent 11 windmills\n\n-Edges : 121\n\nweighted edges describe the strength of relationships\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader6 = WindmillOutputSmallDatasetLoader()\n\n\na = loader6.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(17471, 11, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 121)\n\n\n\nnp.array(a.edge_weight).shape\n\n(121,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_windmillsmall.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 11):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(11,1,figsize=(30,50))\nfor k in range(11):\n    ax[k].plot(np.array(loader6.targets).reshape(11,-1)[k][:],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# 각 서브플롯에 선 그래프 추가\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# 그래프 크기 조정\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# 그래프 출력\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_windmillsmall.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_windmillsmall.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#metrladatasetloader_real-world-traffic-dataset",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#metrladatasetloader_real-world-traffic-dataset",
    "title": "data load, data save as pickle",
    "section": "METRLADatasetLoader_real world traffic dataset",
    "text": "METRLADatasetLoader_real world traffic dataset\nA traffic forecasting dataset based on Los Angeles Metropolitan traffic conditions. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County in aggregated 5 minute intervals for 4 months between March 2012 to June 2012.\n데이터정리\n\nT = 33\nV = 구역\nN = 207 # number of nodes\nE = 225\n\\(f(v,t)\\)의 차원? (3,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? False\nX: (207,4) (N,2,12), \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny: (207,) (N,), \\((x_{12})\\)\n예제코드적용가능여부: No\n\nhttps://arxiv.org/pdf/1707.01926.pdf\n- Nodes : 207\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nloader7 = METRLADatasetLoader()\n\n\na = loader7.get_dataset(num_timesteps_in=1,num_timesteps_out=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 1722)\n\n\n\nnp.array(a.edge_weight).shape\n\n(1722,)\n\n\n\nnp.array(a.targets).shape\n\n(34271, 207, 1)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 207):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 207), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader7.targets).reshape(207,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#pemsbaydatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#pemsbaydatasetloader",
    "title": "data load, data save as pickle",
    "section": "PemsBayDatasetLoader",
    "text": "PemsBayDatasetLoader\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12644\n\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nThis traffic dataset is collected by California Transportation Agencies (CalTrans) Performance Measurement System (PeMS). It is represented by a network of 325 traffic sensors in the Bay Area with 6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals.\nFor details see: \"Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>\n캘리포니아 교통국(CalTrans) 성능 측정 시스템(PeMS)에서 수집\n2017년 1월 1일부터 2017년 5월 31일까지 6개월 동안 5분 간격으로 트래픽 판독치가 포함된 베이 지역의 325개 교통 센서 네트워크로 표시\n\n데이터정리\n\nT = 17470\nV = 교통센서\nN = 325 # number of nodes\nE = 2694 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # Hourly energy output\n시간에 따라서 N이 변하는지? False\n시간에 따라서 E가 변하는지? No\nX: (325,2,12) (N,2,12),\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\n\ny: (325,) (N,2,12),\n\n\\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n예제코드적용가능여부: No\n\n- Nodes : 325\n\nvertices are sensors\n\n-Edges : 2694\n\nweighted edges are between seonsor paris measured by the road nretwork distance\n\n- Time : 52081\n\n6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nloader8 = PemsBayDatasetLoader()\n\n\na = loader8.get_dataset(num_timesteps_in=1,num_timesteps_out=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 2694)\n\n\n\na.edge_index\n\narray([[  0,   1,   2, ..., 324, 324, 324],\n       [  0,   1,   2, ..., 257, 310, 324]])\n\n\n\nnp.array(a.edge_weight).shape\n\n(2694,)\n\n\n\nnp.array(a.targets).shape\n\n(52104, 325, 2, 1)\n\n\n\na.targets[0][0][0]\n\narray([0.99281436], dtype=float32)\n\n\n\nnode_list = []\nfor i in range(0, 325):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 325), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader8.targets).reshape(325,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#englandcoviddatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#englandcoviddatasetloader",
    "title": "data load, data save as pickle",
    "section": "EnglandCovidDatasetLoader",
    "text": "EnglandCovidDatasetLoader\nCovid19 England\n\nA dataset about mass mobility between regions in England and the number of confirmed COVID-19 cases from March to May 2020 [38]. Each day contains a different mobility graph and node features corresponding to the number of cases in the previous days. Mobility stems from Facebook Data For Good 1 and cases from gov.uk 2\n\nhttps://arxiv.org/pdf/2009.08388.pdf\n데이터정리\n\nT = 60\nV = 지역\nN = 129 # number of nodes\nE = 2158\n\\(f(v,t)\\)의 차원? (1,) # 코로나확진자수\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of edge가 변하는지? TRUE\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 129\n\nvertices are correspond to the number of COVID-19 cases in the region in the past window days.\n\n-Edges : 2158\n\nthe spatial edges capture county-to-county movement at a specific date, and a county is connected to a number of past instances of itself with temporal edges.\n\n- Time : 61\n\nfrom 3 March to 12 of May\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nloader9 = EnglandCovidDatasetLoader()\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n\na = loader9.get_dataset(lags=1)\n\n\na, _a = temporal_signal_split(a, train_ratio=0.8)\n\n\na.snapshot_count,_a.snapshot_count\n\n(60, 12)\n\n\n원래 60\n\na.edge_indices[59]\n\nIndexError: list index out of range\n\n\n\nnp.array(a.edge_indices[59]).shape\n\n(2, 1476)\n\n\n\na.edge_weights[59]\n\narray([2.96600e+03, 1.88595e+05, 1.30000e+02, ..., 1.10000e+01,\n       1.80000e+01, 1.00000e+01])\n\n\n\nnp.array(a.edge_weights[59]).shape\n\n(1476,)\n\n\n\na.snapshot_count\n\n60\n\n\n\nnp.array(a.features).shape\n\n(60, 129, 1)\n\n\n\nnp.array(a.targets).shape\n\n(60, 129)\n\n\n\nG = nx.Graph()\nG.add_edges_from(a.edge_indices[0].T)\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nG = nx.Graph()\nG.add_edges_from(a.edge_indices[58].T)\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 129):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 129), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader9.targets).reshape(129,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#montevideobusdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#montevideobusdatasetloader",
    "title": "data load, data save as pickle",
    "section": "MontevideoBusDatasetLoader",
    "text": "MontevideoBusDatasetLoader\nMontevideo Buses\n\nA dataset of inflow passenger at bus stop level from Montevideo city. This dataset comprises hourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay). The bus lines selected are the ones that carry people to the center of the city and they load more than 25% of the total daily inflow traffic. Vertices are bus stops, edges are links between bus stops when a bus line connects them and the weight represent the road distance. The target is the passenger inflow. This is a curated dataset made from different data sources of the Metropolitan Transportation System (STM) of Montevideo. These datasets are freely available to anyone in the National Catalog of Open Data from the government of Uruguay (https://catalogodatos.gub.uy/)\n몬테비데오 시티에서 버스 정류장 층으로 유입된 승객의 데이터 셋\n2020년 10월 동안 몬테비데오 시티(우루과이)에서 11개 버스 노선에 대한 버스 정류장 수준의 시간당 유입 승객 데이터\n선정된 버스 노선은 도심까지 사람을 실어 나르는 노선으로 하루 총 유입량의 25% 이상을 적재\nnode는 버스 정류장\nedge는 버스 노선이 버스 정류장을 연결할 때 버스 정류장 사이의 링크\nweight는 도로 거리\ntarget은 승객 유입\n몬테비데오의 메트로폴리탄 교통 시스템(STM)의 서로 다른 데이터 소스로 만들어진 큐레이션된 데이터 셋\n\n데이터정리\n\nT = 743\nV = 버스정류장\nN = 675 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # passenger inflow\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\nX: (675,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (675,,) (N,), \\(f(v,t_4)\\)\n예제코드적용가능여부: Yes\n\n- Nodes : 675\n\nvertices are bus stops\n\n-Edges : 690\n\nedges are links between bus stops when a bus line connects them and the weight represent the road distance\n\n- Time : 743\n\nhourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay).\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader10 = MontevideoBusDatasetLoader()\n\n\na = loader10.get_dataset(lags=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 690)\n\n\n\nnp.array(a.edge_weight).shape\n\n(690,)\n\n\n\nnp.array(a.features).shape\n\n(743, 675, 1)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_monte.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 675):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader10.targets).reshape(675,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# 각 서브플롯에 선 그래프 추가\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# 그래프 크기 조정\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# 그래프 출력\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_monte.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_monte.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#twittertennisdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#twittertennisdatasetloader",
    "title": "data load, data save as pickle",
    "section": "TwitterTennisDatasetLoader",
    "text": "TwitterTennisDatasetLoader\nhttps://appliednetsci.springeropen.com/articles/10.1007/s41109-018-0080-5?ref=https://githubhelp.com\nTwitter Tennis RG and UO\n\nTwitter mention graphs of major tennis tournaments from 2017. Each snapshot contains the graph of popular player or sport news accounts and mentions between them [5, 6]. Node labels encode the number of mentions received and vertex features are structural properties\n\n데이터정리\n\nT = 52081\nV = 트위터계정\n\nN = 1000 # number of nodes\nE = 119 = N^2 # edges\n\\(f(v,t)\\)의 차원? (1,) # passenger inflow\n시간에 따라서 N이 변하는지? ??\n시간에 따라서 E가 변하는지? True\nX: ?\ny: ?\n예제코드적용가능여부: No\n\n- Nodes : 1000\n\nvertices are Twitter accounts\n\n-Edges : 119\n\nedges are mentions between them\n\n- Time : 52081\n\nTwitter mention graphs related to major tennis tournaments from 2017\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nloader11 = TwitterTennisDatasetLoader()\n\n\na = loader11.get_dataset()\n\n\na.edge_indices[119]\n\narray([[900, 347, 347, 407, 407, 407, 407, 407, 407,   0,  35, 448, 407,\n        396, 396, 370, 233, 233, 357,  15,  15, 135, 135, 358, 233, 233,\n        243, 115, 115, 667, 667, 667, 667, 440, 440, 440, 101, 650, 309,\n        309, 309, 233, 347, 347, 974, 161, 218, 309, 309,  93,  93, 813,\n        101, 417,  69,  69, 480, 480, 416, 272, 813, 813, 813, 379, 903,\n        903, 903,  95, 309, 309, 309, 144, 890, 890, 484, 484, 484, 653,\n        653, 234, 234, 234, 253, 253, 630, 769, 769, 156, 156, 156, 892,\n        912, 912,   0, 278, 896, 896, 896, 233,  92,  69, 802, 324, 324,\n        574,  87,  87,  87, 365, 365,  87, 522, 611, 427, 427, 427, 110,\n        246, 246, 445, 156, 156, 133, 133, 217, 217,   4,   4, 105, 105,\n        105, 105, 630, 630, 630, 792,  84, 452,  51,  84, 445, 613, 985,\n        290, 290, 290, 290, 290, 290, 420, 420, 420, 420, 420, 420, 420,\n        420, 420,   0, 626, 626, 519, 519, 519, 519, 519, 519, 519, 519,\n        519, 217, 437, 437, 437, 309, 309, 217, 666,   4, 637, 540,  38,\n         38, 605, 605, 605, 605, 605, 215],\n       [  0,   0, 152,  41, 590,   0, 133, 116, 731,   1,   1,   1,   2,\n          0,   1,   0,   0, 982,   2,   1,   0,   0,   1,  51,   1, 427,\n          2,  74,   0,   1,  97,   0,   5,   0,   1, 614,  99,   0, 427,\n          0,   1, 203,   2,   1, 731,   1,   1,   2,  15,   0, 152,   1,\n          1,   0,   0,   1,   1,   0,   0,   0,  81,  97,   0,   0,   0,\n        416,  69,   1, 317,  67, 438,   0,   0,   1,   0,   1, 234,  15,\n          0,   1, 484,   0,   0, 141,   0,   1,  97, 221,   0, 540, 445,\n          1,   0,   2,   0,   0, 132, 438, 745,  92,   2,  80,   0, 152,\n          0,   0,   1,   4, 129, 338, 170,   0,   1, 123,   1,   0,   1,\n          1,   0,   1,   1, 427,   0,   1,   1, 217,   0,   1,   1,  97,\n          0, 226, 123,   1, 427,   0,   0,   1,   1,   1,   0,   1,   1,\n          5, 121,   0,  99,  15, 226,   5,   2, 221,  97,   6,  99, 226,\n        121,   0, 706,   0, 211,  99,   0,   5,  97, 226, 121,   6, 221,\n          2,   0,   1,   0, 217,  69, 416, 210,   0, 634, 291, 236,   1,\n          0, 234, 437, 286,   1, 745,  56]])\n\n\n\na.edge_weights[119]\n\narray([1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 6, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 3, 1,\n       3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n\na.features[119]\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])\n\n\n\na.snapshot_count\n\n120\n\n\n\nnp.array(a.targets).shape\n\n(120, 1000)\n\n\n\nnode_list = []\nfor i in range(0, 1000):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 1000), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader11.targets).reshape(1000,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\ndef transform_degree(x, cutoff=4):\n    log_deg = np.ceil(np.log(x + 1.0))\n    return np.minimum(log_deg, cutoff)\n\n\ndef transform_transitivity(x):\n    trans = x * 10\n    return np.floor(trans)\n\n\ndef onehot_encoding(x, unique_vals):\n    E = np.zeros((len(x), len(unique_vals)))\n    for i, val in enumerate(x):\n        E[i, unique_vals.index(val)] = 1.0\n    return E\n\n\ndef encode_features(X, log_degree_cutoff=4):\n    X_arr = np.array(X)\n    a = transform_degree(X_arr[:, 0], log_degree_cutoff)\n    b = transform_transitivity(X_arr[:, 1])\n    A = onehot_encoding(a, range(log_degree_cutoff + 1))\n    B = onehot_encoding(b, range(11))\n    return np.concatenate((A, B), axis=1)"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#mtmdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#mtmdatasetloader",
    "title": "data load, data save as pickle",
    "section": "MTMDatasetLoader",
    "text": "MTMDatasetLoader\nMTM-1 Hand Motions\n\nA dataset of Methods-Time Measurement-1 <https://en.wikipedia.org/wiki/Methods-time_measurement>(MTM-1) motions, signalled as consecutive video frames of 21 3D hand keypoints, acquired via MediaPipe Hands <https://google.github.io/mediapipe/solutions/hands.html> from RGB-Video material. Vertices are the finger joints of the human hand and edges are the bones connecting them. The targets are manually labeled for each frame, according to one of the five MTM-1 motions (classes :math:C): Grasp, Release, Move, Reach, Position plus a negative class for frames without graph signals (no hand present). This is a classification task where :math:T consecutive frames need to be assigned to the corresponding class :math:C. The data x is returned in shape :obj:(3, 21, T), the target is returned one-hot-encoded in shape :obj:(T, 6).\n\n데이터정리\n\nT = 14452\nV = 손의 shape에 대응하는 dot\n\nN = 325 # number of nodes\nE = 19 = N^2 # edges\n\\(f(v,t)\\)의 차원? (Grasp, Release, Move, Reach, Poision, -1)\n시간에 따라서 N이 변하는지? ??\n시간에 따라서 E가 변하는지? ??\nX: ?\ny: ?\n예제코드적용가능여부: No\n\n- Nodes : 325\n\nvertices are are the finger joints of the human hand\n\n-Edges : 19\n\nedges are the bones connecting them\n\n- Time : 14452\n\n # target eoncoding: {0 : 'Grasp', 1 : 'Move', 2 : 'Negative',\n        #                   3 : 'Position', 4 : 'Reach', 5 : 'Release'}\n\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nloader12 = MTMDatasetLoader()\n\n\na = loader12.get_dataset(frames=16)\n\n\nnp.array(a.edge_index).shape\n\n(2, 19)\n\n\n\nnp.shape(a.edge_weight)\n\n(19,)\n\n\n\nnp.array(a.features).shape\n\n(14453, 3, 21, 16)\n\n\n\na.snapshot_count\n\n14453\n\n\n\nnp.array(a.targets).shape\n\n(14453, 16, 6)\n\n\n\na.targets[0]\n\narray([[0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.]])\n\n\n\nb=[]\nfor i in range(a.snapshot_count):\n    b.append(np.argmax(a.targets[i]))\n\n\npd.DataFrame(b)[0].unique()\n\narray([2, 4, 0, 1, 3, 5])\n\n\n\npd.DataFrame(b).value_counts()\n\n0    3910\n1    3189\n3    3069\n4    2480\n2    1266\n5     539\ndtype: int64"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.172\n      0.064\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.164\n      0.065"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.173\n      0.048\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.201\n      0.064\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.209\n      0.073\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.216\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.165\n      0.051\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.185\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      32\n      IT-STGCN\n      0.984\n      0.016\n    \n    \n      1\n      32\n      STGCN\n      0.988\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      32\n      IT-STGCN\n      0.998\n      0.019\n    \n    \n      1\n      0.3\n      linear\n      32\n      STGCN\n      1.054\n      0.011\n    \n    \n      2\n      0.8\n      linear\n      32\n      IT-STGCN\n      1.161\n      0.054\n    \n    \n      3\n      0.8\n      linear\n      32\n      STGCN\n      1.234\n      0.096"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      32\n      IT-STGCN\n      1.002350\n      0.015102\n    \n    \n      1\n      linear\n      0.28777\n      32\n      STGCN\n      1.027605\n      0.015945\n    \n    \n      2\n      nearest\n      0.28777\n      32\n      IT-STGCN\n      0.998713\n      0.021721\n    \n    \n      3\n      nearest\n      0.28777\n      32\n      STGCN\n      1.025797\n      0.014844"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.213\n      0.045\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.234\n      0.055"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.251\n      0.072\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.267\n      0.072\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.251\n      0.057\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.265\n      0.056\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.065\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.305\n      0.092\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.267\n      0.067\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.292\n      0.075"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.246\n      0.034\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#w_st",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.223\n      0.041\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.048\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.234\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.252\n      0.071\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.072\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.321\n      0.094\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.033\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.241\n      0.095"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      nof_filters\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.317\n      0.118\n    \n    \n      1\n      4\n      STGCN\n      0.997\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      2.263371\n      0.476410\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      2.622998\n      0.693321"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.345316\n      0.110313\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.766133\n      0.123163"
  },
  {
    "objectID": "posts/GCN/2023-05-11-CPUvsGPU.html",
    "href": "posts/GCN/2023-05-11-CPUvsGPU.html",
    "title": "PyG Geometric Temporal CPU vs GPU",
    "section": "",
    "text": "CPU vs GPU\n\n\n!nvidia-smi\n\nFri May 12 06:42:19 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n|  0%   37C    P8    35W / 420W |     19MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A      1062      G   /usr/lib/xorg/Xorg                  9MiB |\n|    0   N/A  N/A      1309      G   /usr/bin/gnome-shell                8MiB |\n+-----------------------------------------------------------------------------+\n\n\n\nimport time\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue\n\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\n\nGPU\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n\ntime.time()\n\n1683806883.6646736\n\n\n\nt1=time.time()\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).to(\"cuda:0\")\n        cost = cost + torch.mean((y_hat-snapshot.y.to(\"cuda:0\"))**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [03:05<00:00,  1.08it/s]\n\n\n\nimport time\n\n\nt2=time.time()\n\n\nt2-t1\n\n185.09801506996155\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.0507\n\n\n\n\nCPU\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n\nimport time\n\n\nt1=time.time()\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [05:08<00:00,  1.54s/it]\n\n\n\nimport time\n\n\nt2=time.time()\n\n\nt2-t1\n\n308.58231496810913\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.0542"
  },
  {
    "objectID": "posts/GCN/2022-12-28-gcn_simulation.html",
    "href": "posts/GCN/2022-12-28-gcn_simulation.html",
    "title": "Simulation of geometric-temporal",
    "section": "",
    "text": "Simulation\n\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\n\nimport\n\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\n\n공식 홈페이지 예제\n\ndata\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\n\nRecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\n\nLearn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(1)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 1/1 [00:11<00:00, 11.93s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\nsnapshot.y.shape\n\ntorch.Size([1068])\n\n\n\n1068개의 nodes\n한 개의 node에 mapping된 차원의 수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n\n\n우리 예제\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\nT = 100\nN = 4 # number of Nodes\nE = np.array([[0,1],[1,2],[2,3],[3,0]]).T\nV = np.array([1,2,3,4])\nAMP = np.array([3,2,1,2.2])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = np.stack([a*np.sin(2*t**2/1000)+np.random.normal(loc=0,scale=0.2,size=T) for a in AMP],axis=1).reshape(T,N,node_features)\nf = torch.tensor(f).float()\n\n\nf.shape\n\ntorch.Size([100, 4, 1])\n\n\n\nX = f[:99,:,:]\ny = f[1:,:,:]\n\n\nplt.plot(y[:,0,0],label=\"v1\")\nplt.plot(y[:,1,0],label=\"v2\")\nplt.plot(y[:,2,0],label=\"v3\")\nplt.plot(y[:,3,0],label=\"v4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc48673490>\n\n\n\n\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(y[:,0,0],label=\"y in V1\")\nplt.plot(yhat[:,0,0],label=\"yhat in V1\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc48524730>\n\n\n\n\n\n\nplt.plot(y[:,1,0],label=\"y in V2\")\nplt.plot(yhat[:,1,0],label=\"yhat in V2\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc4849c730>\n\n\n\n\n\n\nplt.plot(y[:,2,0],label=\"y in V3\")\nplt.plot(yhat[:,2,0],label=\"yhat in V3\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc484098e0>\n\n\n\n\n\n\nplt.plot(y[:,3,0],label=\"y in V4\")\nplt.plot(yhat[:,3,0],label=\"yhat in V4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc483f5880>\n\n\n\n\n\n\n\nGNAR\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\n%%R\nsummary(fiveNet)\n\nGNARnet with 5 nodes and 10 edges\n of equal length  1\n\n\n\n%%R\nedges <- as.matrix(fiveNet)\nedges\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n%%R\nprint(fiveNet)\n\nGNARnet with 5 nodes \nedges:1--4 1--5 2--3 2--4 3--2 3--4 4--1 4--2 4--3 5--1 \n     \n edges of each of length  1 \n\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\n%%R\nlayout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))\nplot(fiveVTS[, 1], ylab = \"Node A Time Series\")\nlines(fitted(answer)[, 1], col = 2)\nplot(fiveVTS[, 2], ylab = \"Node B Time Series\")\nlines(fitted(answer)[, 2], col = 2)\nplot(fiveVTS[, 3], ylab = \"Node C Time Series\")\nlines(fitted(answer)[, 3], col = 2)\nplot(fiveVTS[, 4], ylab = \"Node D Time Series\")\nlines(fitted(answer)[, 4], col = 2)\n\n\n\n\n\n%R -o fiveVTS\n%R -o edges\n\n\nnode: 5\ntime 200\n\n\nedges_tensor = torch.tensor(edges)\n\n\nnonzero_indices = edges_tensor.nonzero()\n\n\nfiveNet_edge = np.array(nonzero_indices).T\nfiveNet_edge\n\narray([[0, 0, 1, 1, 2, 2, 3, 3, 3, 4],\n       [3, 4, 2, 3, 1, 3, 0, 1, 2, 0]])\n\n\n\nfiveVTS.shape\n\n(200, 5)\n\n\n\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(fiveVTS).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=8)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|█| 50/50 [00:34<00:00,  1.45it/\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nyhat.shape\n\n(199, 5, 1)\n\n\n\nplt.plot(y[:,1])\nplt.plot(yhat[:,1].data)\n\n\n\n\n\n\nWind network time series\nthe data suite vswind that contains a number of R objects pertaining to 721 wind speeds taken at each of 102 weather stations in England and Wales. The suite contains the vector time series vswindts, the associated network vswindnet, a character vector of the weather station location names in vswindnames and coordinates of the stations in the two column matrix vswindcoords. The data originate from the UK Met Office site http://wow.metoffice.gov.uk and full details can be found in the vswind help file in the GNAR package.\n\n%%R\noldpar <- par(cex = 0.75)\nwindnetplot()\npar(oldpar)\n\n\n\n\n\n%%R\nedges_wind <- as.matrix(vswindnet)\n\n\n%R -o vswindts\n%R -o edges_wind\n\n\nnodes : 102\ntime step : 721\n\n\nvswindts.shape\n\n(721, 102)\n\n\n\nedges_wind.shape\n\n(102, 102)\n\n\n\nedges_winds = torch.tensor(edges_wind)\n\n\nnonzero_indices_wind = edges_winds.nonzero()\n\n\nvswindnet_edge = np.array(nonzero_indices_wind).T\nvswindnet_edge.shape\n\n(2, 202)\n\n\n\nT = 721\nN = 102 # number of Nodes\nE = vswindnet_edge\nV = np.array(range(101))\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(vswindts).reshape(721,102,1).float()\n\n\nX = f[:720,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1]*202),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [02:16<00:00,  2.73s/it]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nyhat.shape\n\n(720, 102, 1)\n\n\n\nplt.plot(y[:,1])\nplt.plot(yhat[:,1].data)\n\n\n\n\n\n\nOECD GDP\n해당예제는 GNAR 패키지에서 네트워크(엣지)를 맞추는 예제로서 나옴, 그렇기에 네트워크 존재하지 않아 연구 예제로서 사용하지 않을 예정\n이 데이터는 네트워크를 추정하여 fit 및 predict함\nGOP growth rate time series\n\n35 countries from the OECD website\ntime series : 1961 - 2013\nT = 52\nNodes = 35\nIn this data set 20.8% (379 out of 1820) of the observations were missing due to some nodes not being included from the start.\n\n\n%%R\nlibrary(\"fields\")\n\n\n%R -o gdpVTS\n\n\ngdpVTS.shape\n\n(52, 35)\n\n\n\nplt.plot(gdpVTS[:,1])"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "",
    "text": "ST-GCN Dataset WikiMathsDatasetLoader"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#train",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#train",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n583\n\n\n\nT_train = time\nN = len(data_train[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([583, 1068, 1])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([583, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([583, 1068, 1]), torch.Size([583, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#test",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#test",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오1-baseline",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오1-baseline",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "시나리오1 (Baseline)",
    "text": "시나리오1 (Baseline)\n시나리오1\n\nmissing rate: 0%\n보간방법: None\n\n\nSTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:31<00:00,  6.62s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR 으로 적합 + 예측\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n GNAR: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(1,583),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),gnar_train[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(583,728),gnar_test[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오2",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오2",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "시나리오2",
    "text": "시나리오2\n시나리오2\n\nmissing rate: 50%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train[:,:,0][:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:34<00:00,  6.68s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [06:56<00:00,  8.33s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nx_test.shape,y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))\n\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오3",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오3",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "시나리오3",
    "text": "시나리오3\n시나리오3\n\nmissing rate: 80%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train.squeeze()[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:51<00:00,  7.04s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [07:00<00:00,  8.40s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오4",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#시나리오4",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "시나리오4",
    "text": "시나리오4\n시나리오4\n\nmissing rate: 30%\n보간방법: linear\n\n- 결측치생성 + 보간\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train.squeeze()[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:54<00:00,  7.09s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN 으로 적합 + 예측\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|██████████| 50/50 [07:00<00:00,  8.40s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcn은 stgcn에 의한 적합결과를 의미함\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR 으로 적합 + 예측\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\n결과시각화\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html",
    "title": "SimualtionPlanner-Tutorial",
    "section": "",
    "text": "table"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_rand",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.3,0.6],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n1/15 is done\n2/15 is done\n3/15 is done\n4/15 is done\n5/500\n\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.7],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGConvLSTM/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n1/50\n\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGCLSTM/learners.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader5,dataset_name='windmillmedium')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_manual",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_manual",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,200))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = list(range(200,500))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(26)] #windmilmedi\nanother_list = list(range(200,500)) # 676*0.8 = 540.8\nmy_list[10] = another_list\nmindex = my_list\n\n\nimport numpy as np\n\n\nimport random\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,7500)) # 17470*0.8 = 13976.0\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nimport random\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = random.sample(range(0, 576), 432)\nfor i in range(0, 1068):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_rand",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\nplans_gnar_rand = {\n    'max_iteration': 30, \n#    'method': ['GNAR'], \n    'mrate': [0.8, 0.9],\n    'lags': [4], \n#    'nof_filters': [8,16], \n    'inter_method': ['cubic','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader2,dataset_name='pedalme')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_block",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_block",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,200))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = list(range(10,20))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(26)] #windmilmedi\nanother_list = list(range(200,500)) # 676*0.8 = 540.8\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,10000)) # 17470*0.8 = 13976.0\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex = [[],[],list(range(50,250)),[],[]]\n# mindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [4,8], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex,mtype='block')\n\n\n# mindex = [[],[],list(range(50,250)),[],[]]\n# mindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [8], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader10,dataset_name='monte')\nplnr.simulate(mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html",
    "href": "posts/GCN/2023-04-05-Simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random",
    "href": "posts/GCN/2023-04-05-Simulation.html#random",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch200.csv')\n\n\ndf_gnar = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_random.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df_gnar],axis=0)\n\n\ndata.query(\"method!='GNAR' and inter_method=='linear' and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\n시뮬 예정(평균 시간, 평균mse)\n0.7,0.75,0.8,0.85\n12,16\n150\n\n# 1. mrate = 0.8, filter = 12, epoch = 150\ndata.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\")['calculation_time'].mean(),data.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\")['mse'].mean()\n\n(109.59549897114435, 1.2304790377616883)\n\n\n\ndata.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block",
    "href": "posts/GCN/2023-04-05-Simulation.html#block",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch200.csv')\ndf5 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch50.csv')\ndf6 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch100.csv')\ndf7 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch150.csv')\ndf8 = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_block_node1.csv')\ndf9 = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_block_node2.csv')\n\n\ndf1['block']=1\ndf2['block']=1\ndf3['block']=1\ndf4['block']=1\ndf5['block']=2\ndf6['block']=2\ndf7['block']=2\ndf8['block']=1\ndf9['block']=2\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9],axis=0)\n\n\ndata2.query(\"method=='GNAR' and block == 1\")['mse'].mean(),data2.query(\"method=='GNAR' and block == 2\")['mse'].mean()\n\n(1.455923080444336, 1.5004450678825378)\n\n\n\ndata2.query(\"method=='GNAR' and inter_method == 'linear'\")['mse'].mean(),data2.query(\"method=='GNAR' and inter_method == 'nearest'\")['mse'].mean() # 차이 없음\n\n(1.4813642161233085, 1.4813642161233085)\n\n\n\ndata2.query(\"epoch==50\")['calculation_time'].mean(),data2.query(\"epoch==50\")['calculation_time'].max()\n\n(39.11611335332747, 56.8712797164917)\n\n\n\ndata2.query(\"epoch==150\")['calculation_time'].mean(),data2.query(\"epoch==150\")['calculation_time'].max()\n\n(102.26520284502594, 152.8869686126709)\n\n\n\ndata2.query(\"method!='GNAR' and lags == 2 and inter_method=='nearest'\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=800)\n\n\n                                                \n\n\n\ndata2.query(\"inter_method=='linear' and epoch==150\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\n시뮬 예정(평균 시간, 평균mse)\nblock 1,2 위 세팅 그대로\n랜덤ㅁ 말고 block만\n\n# 1. block = 2 interpolation = linear, filter = 12, epoch = 150\ndata2.query(\"block==1 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\")['calculation_time'].mean(),data2.query(\"block==2 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\")['mse'].mean()\n\n(40.18422634204229, 1.2096982955932618)\n\n\n\ndata2.query(\"block==1 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-1",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-1",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\n공식 패키지: lags 4 지정\nmrate = 0.3\n\n결측값 비율 크니까 오차 많이 커지는 경향 있어서\n\nnof_filters = 4\n\n차이 없어서\n\nlags = 4, 8\n\n클 수록 작아지는 경향 있어서\n\nGNAR보다 MSE는 낮음\ncal_time\n\nmean = 10\nmax = 21\n\nblock 은 임의로 한 노드만 해 본 결과임\n\n\ndata = pd.read_csv('./simulation_results/chickenpox_random.csv').sort_values(by='lags')\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n(10.42619569649299, 21.886654376983643, 7.567165851593018)\n\n\n\ndata.query(\"method!='GNAR' and inter_method=='cubic' and mrate==0.3\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\ndata.query(\"method=='GNAR' and inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=600)\n\n\n                                                \n\n\n\n시뮬 예정(평균 시간, 평균mse)\nepoch = 50\nmrate = 0.3~0.5\nfilter 32 공식예제로 가기 하고 샆으면 3개 정도 추가로\n\n# 1. mrate = 0.3, filter = 4, epoch = 50, lags = 4\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\")['calculation_time'].mean(),data.query(\"method != 'GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\")['mse'].mean()\n\n(10.115000387032827, 1.0320488701264063)\n\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-1",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-1",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/chickenpox_block.csv')\n\n\ndata.query(\"method != 'GNAR' and lags!=4 and lags!=6 and inter_method !='linear'\").plot.box(backend='plotly',x='nof_filters',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method=='GNAR'\").plot.box(backend='plotly',x='mrate',color='inter_method',y='mse',facet_col='lags',height=600)\n\n\n                                                \n\n\n\n시뮬 예정(평균 시간, 평균mse)\nblock, rand 다\n공식예제 수 따라\nepoch 50\n나중에 시간 남으면 100\n\ndata.query(\"inter_method=='cubic' and nof_filters==4 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-2",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-2",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/pedalme_block.csv');data\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      0\n      pedalme\n      IT-STGCN\n      0.047619\n      block\n      2\n      4.0\n      cubic\n      5.0\n      1.229210\n      0.758090\n    \n    \n      1\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      12.0\n      linear\n      5.0\n      1.223644\n      0.681700\n    \n    \n      2\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      12.0\n      cubic\n      5.0\n      1.237086\n      0.684113\n    \n    \n      3\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      4.0\n      linear\n      5.0\n      1.225114\n      0.659210\n    \n    \n      4\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      4.0\n      cubic\n      5.0\n      1.216191\n      0.664208\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      715\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      4.0\n      cubic\n      5.0\n      1.425474\n      0.640063\n    \n    \n      716\n      pedalme\n      STGCN\n      0.045977\n      block\n      8\n      12.0\n      cubic\n      5.0\n      1.302402\n      0.718187\n    \n    \n      717\n      pedalme\n      STGCN\n      0.045977\n      block\n      8\n      12.0\n      linear\n      5.0\n      1.336038\n      0.719500\n    \n    \n      718\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      12.0\n      linear\n      5.0\n      1.311962\n      0.831888\n    \n    \n      719\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      12.0\n      cubic\n      5.0\n      1.315647\n      0.667004\n    \n  \n\n720 rows × 10 columns\n\n\n\nmissing rate 조정하기 30~50% 여러개 block 해서\n\ndata.query(\"method!='GNAR'\").plot.box(backend='plotly',x='inter_method',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\n시뮬 예정(평균 시간, 평균mse)\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-3",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-3",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndf1 = pd.read_csv('./simulation_results/2023-04-15_16-58-03.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-15_17-01-39.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-15_17-07-23.csv')\ndf4 = pd.read_csv('./simulation_results/2023-04-15_17-13-13.csv')\ndf5 = pd.read_csv('./simulation_results/2023-04-15_17-29-49.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df5],axis=0)\n\n\ndata.query(\"method=='STGCN'\").sort_values(['mrate','lags','nof_filters'])\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      0\n      wikimath\n      STGCN\n      0.3\n      rand\n      4\n      12\n      linear\n      1\n      0.863623\n      25.504817\n    \n    \n      0\n      wikimath\n      STGCN\n      0.3\n      rand\n      4\n      12\n      cubic\n      1\n      0.847675\n      27.086116\n    \n    \n      0\n      wikimath\n      STGCN\n      0.4\n      rand\n      2\n      12\n      linear\n      1\n      0.912734\n      30.048937\n    \n    \n      1\n      wikimath\n      STGCN\n      0.4\n      rand\n      2\n      12\n      cubic\n      1\n      0.916843\n      27.104823\n    \n    \n      0\n      wikimath\n      STGCN\n      0.4\n      rand\n      4\n      12\n      linear\n      1\n      0.907305\n      24.776503\n    \n    \n      1\n      wikimath\n      STGCN\n      0.4\n      rand\n      4\n      12\n      cubic\n      1\n      0.854127\n      24.608104\n    \n    \n      2\n      wikimath\n      STGCN\n      0.4\n      rand\n      8\n      12\n      linear\n      1\n      0.788011\n      24.233431\n    \n    \n      3\n      wikimath\n      STGCN\n      0.4\n      rand\n      8\n      12\n      cubic\n      1\n      0.795219\n      24.228026\n    \n    \n      0\n      wikimath\n      STGCN\n      0.5\n      rand\n      4\n      12\n      linear\n      1\n      0.914080\n      26.301605\n    \n    \n      1\n      wikimath\n      STGCN\n      0.5\n      rand\n      4\n      12\n      cubic\n      1\n      0.975948\n      27.855870\n    \n  \n\n\n\n\n\ndata.query(\"method!='STGCN'\").sort_values(['mrate','lags','nof_filters'])\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      1\n      wikimath\n      IT-STGCN\n      0.3\n      rand\n      4\n      12\n      linear\n      1\n      0.908916\n      28.928112\n    \n    \n      1\n      wikimath\n      IT-STGCN\n      0.3\n      rand\n      4\n      12\n      cubic\n      1\n      0.856639\n      29.759748\n    \n    \n      4\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      2\n      12\n      linear\n      1\n      0.864580\n      29.660712\n    \n    \n      5\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      2\n      12\n      cubic\n      1\n      0.926426\n      30.838968\n    \n    \n      2\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      4\n      12\n      linear\n      1\n      0.871146\n      29.008776\n    \n    \n      3\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      4\n      12\n      cubic\n      1\n      0.905354\n      30.405766\n    \n    \n      6\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      8\n      12\n      linear\n      1\n      0.822462\n      32.329447\n    \n    \n      7\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      8\n      12\n      cubic\n      1\n      0.817621\n      29.447260\n    \n    \n      2\n      wikimath\n      IT-STGCN\n      0.5\n      rand\n      4\n      12\n      linear\n      1\n      0.878943\n      31.140878\n    \n    \n      3\n      wikimath\n      IT-STGCN\n      0.5\n      rand\n      4\n      12\n      cubic\n      1\n      1.002361\n      28.461372\n    \n  \n\n\n\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n\ndata.query(\"mtype=='rand' and mrate != 0.9 and method!='GNAR' and inter_method=='cubic'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\ndata.query(\"mtype=='rand' and method!='GNAR' and inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n시뮬 예정(평균 시간, 평균mse)\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='linear' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"method !='GNAR' and mrate==0.3 and inter_method=='linear' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and nof_filters==12 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-3",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-3",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/wiki_block.csv');data\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n\ndata.query(\"method!='GNAR' and inter_method=='cubic'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\ndata.query(\"inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n시뮬 예정(평균 시간, 평균mse)\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"inter_method=='linear' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-4",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-4",
    "title": "Simulation",
    "section": "random",
    "text": "random"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-4",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-4",
    "title": "Simulation",
    "section": "block",
    "text": "block"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-5",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-5",
    "title": "Simulation",
    "section": "random",
    "text": "random"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-5",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-5",
    "title": "Simulation",
    "section": "block",
    "text": "block"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html",
    "title": "GCLSTM_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "GCLSTM_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\n# df1 = pd.read_csv('./simulation_results/2023-06-13_18-41-53.csv') # gclm 잘못 돌림\ndf1 = pd.read_csv('./simulation_results/2023-06-13_18-14-13.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-16_20-25-15.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/GCLSTM_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/GCLSTM_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GCLSTM_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-17_01-42-41.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-06-17_03-35-20.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-17_10-06-34.csv') \n\ndf4 = pd.read_csv('./simulation_results/2023-07-10_05-37-15.csv') \ndf5 = pd.read_csv('./simulation_results/2023-07-10_11-00-23.csv') \ndf6 = pd.read_csv('./simulation_results/2023-07-10_16-03-18.csv') \n\n\ndata = pd.concat([df1,df3,df4,df5,df6],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/GCLSTM_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/GCLSTM_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-11-PyGGeometricTemporalEx.html",
    "href": "posts/GCN/2023-05-11-PyGGeometricTemporalEx.html",
    "title": "PyG Geometric Temporal Examples",
    "section": "",
    "text": "Examples\n\nRefer: https://github.com/benedekrozemberczki/pytorch_geometric_temporal/tree/master/examples/recurrent\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\nT = 250\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+0.5+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nimport itstgcn\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nGConvGRU(Done)\n\nGConvGRU?\n\n\nInit signature:\nGConvGRU(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the Chebyshev Graph Convolutional Gated Recurrent Unit\nCell. For details see this paper: `\"Structured Sequence Modeling with Graph\nConvolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gconv_gru.py\nType:           type\nSubclasses:     \n\n\n\n\n\n# from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):# 50\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        _b.append(y_hat)\n        mean_diff = torch.mean((y_hat-snapshot.y), dim=0)\n        cost = torch.square(mean_diff)\n        _d.append(cost)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a = []\n_a1 = []\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.4200\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nA3GCN2\n\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n\n# import torch\n# import torch.nn.functional as F\n# from torch_geometric.nn import GCNConv\n# from torch_geometric_temporal.nn.recurrent import A3TGCN2\n\n\n# # GPU support\n# DEVICE = torch.device('cuda') # cuda\n# shuffle=True\n# batch_size = 32\n\n\n#Dataset\n#Traffic forecasting dataset based on Los Angeles Metropolitan traffic\n#207 loop detectors on highways\n#March 2012 - June 2012\n#From the paper: Diffusion Convolutional Recurrent Neural Network\n\n\n# from torch_geometric_temporal.dataset import METRLADatasetLoader\n# loader = METRLADatasetLoader()\n# dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\n\n# # Visualize traffic over time\n# sensor_number = 1\n# hours = 24\n# sensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\n# plt.plot(sensor_labels)\n\n\n# # Train test split \n\n# from torch_geometric_temporal.signal import temporal_signal_split\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\n# # Creating Dataloaders\n\n# train_input = np.array(train_dataset.features) # (27399, 207, 2, 12)\n# train_target = np.array(train_dataset.targets) # (27399, 207, 12)\n# train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n# train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n# train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n# train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)\n\n\n# test_input = np.array(test_dataset.features) # (, 207, 2, 12)\n# test_target = np.array(test_dataset.targets) # (, 207, 12)\n# test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n# test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n# test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n# test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)\n\n\n# # Making the model \n# class TemporalGNN(torch.nn.Module):\n#     def __init__(self, node_features, periods, batch_size):\n#         super(TemporalGNN, self).__init__()\n#         # Attention Temporal Graph Convolutional Cell\n#         self.tgnn = A3TGCN2(in_channels=node_features,  out_channels=32, periods=periods,batch_size=batch_size) # node_features=2, periods=12\n#         # Equals single-shot prediction\n#         self.linear = torch.nn.Linear(32, periods)\n\n#     def forward(self, x, edge_index):\n#         \"\"\"\n#         x = Node features for T time steps\n#         edge_index = Graph edge indices\n#         \"\"\"\n#         h = self.tgnn(x, edge_index) # x [b, 207, 2, 12]  returns h [b, 207, 12]\n#         h = F.relu(h) \n#         h = self.linear(h)\n#         return h\n\n\n# TemporalGNN(node_features=2, periods=12, batch_size=2)\n\n\n# # Create model and optimizers\n# model = TemporalGNN(node_features=2, periods=12, batch_size=batch_size).to(DEVICE)\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# loss_fn = torch.nn.MSELoss()\n\n\n# print('Net\\'s state_dict:')\n# total_param = 0\n# for param_tensor in model.state_dict():\n#     print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n#     total_param += np.prod(model.state_dict()[param_tensor].size())\n# print('Net\\'s total params:', total_param)\n# #--------------------------------------------------\n# print('Optimizer\\'s state_dict:')  # If you notice here the Attention is a trainable parameter\n# for var_name in optimizer.state_dict():\n#     print(var_name, '\\t', optimizer.state_dict()[var_name])\n\n\n# # Loading the graph once because it's a static graph\n\n# for snapshot in train_dataset:\n#     static_edge_index = snapshot.edge_index.to(DEVICE)\n#     break;\n\n\n# # Training the model \n# model.train()\n\n# for epoch in range(3): # 30\n#     step = 0\n#     loss_list = []\n#     for encoder_inputs, labels in train_loader:\n#         y_hat = model(encoder_inputs, static_edge_index)         # Get model predictions\n#         loss = loss_fn(y_hat, labels) # Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse\n#         loss.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n#         step= step+ 1\n#         loss_list.append(loss.item())\n#         if step % 100 == 0 :\n#             print(sum(loss_list)/len(loss_list))\n#     print(\"Epoch {} train RMSE: {:.4f}\".format(epoch, sum(loss_list)/len(loss_list)))\n\n\n## Evaluation\n\n#- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n#- The model always gets one hour and needs to predict the next hour\n\n\n# model.eval()\n# step = 0\n# # Store for analysis\n# total_loss = []\n# for encoder_inputs, labels in test_loader:\n#     # Get model predictions\n#     y_hat = model(encoder_inputs, static_edge_index)\n#     # Mean squared error\n#     loss = loss_fn(y_hat, labels)\n#     total_loss.append(loss.item())\n#     # Store for analysis below\n#     #test_labels.append(labels)\n#     #predictions.append(y_hat)\n\n\n# print(\"Test MSE: {:.4f}\".format(sum(total_loss)/len(total_loss)))\n\n\n## Visualization\n\n# - The further away the point in time is, the worse the predictions get\n# - Predictions shape: [num_data_points, num_sensors, num_timesteps]\n\n\n# sensor = 123\n# timestep = 11 \n# preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in y_hat])\n# labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n# print(\"Data points:,\", preds.shape)\n\n\n# plt.figure(figsize=(20,5))\n# sns.lineplot(data=preds, label=\"pred\")\n# sns.lineplot(data=labs, label=\"true\")\n\n\n\nA3GCN(cuda 문제)\n\n# try:\n#     from tqdm import tqdm\n# except ImportError:\n#     def tqdm(iterable):\n#         return iterable\n\n\n# # import torch\n# # import torch.nn.functional as F\n# from torch_geometric_temporal.nn.recurrent import A3TGCN\n\n\n# # from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n# from torch_geometric_temporal.signal import temporal_signal_split\n\n\n# # loader = ChickenpoxDatasetLoader()\n\n# dataset = loader.get_dataset(lags=4)\n\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\n# class RecurrentGCN(torch.nn.Module):\n#     def __init__(self, node_features, periods):\n#         super(RecurrentGCN, self).__init__()\n#         self.recurrent = A3TGCN(node_features, 32, periods)\n#         self.linear = torch.nn.Linear(32, 1)\n\n#     def forward(self, x, edge_index, edge_weight):\n#         h = self.recurrent(x.to(\"cuda:0\").view(x.shape[0], 1, x.shape[1]), edge_index, edge_weight)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         return h\n\n\n# model = RecurrentGCN(node_features = 4, periods = 4)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     cost = 0\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = cost + torch.mean((y_hat-snapshot.y)**2)\n#     cost = cost / (time+1)\n#     cost.backward()\n#     optimizer.step()\n#     optimizer.zero_grad()\n\n\n# model.eval()\n# cost = 0\n# for time, snapshot in enumerate(test_dataset):\n#     y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#     cost = cost + torch.mean((y_hat-snapshot.y)**2)\n# cost = cost / (time+1)\n# cost = cost.item()\n# print(\"MSE: {:.4f}\".format(cost))\n\n\n\nAGCRN\n\nAGCRN?\n\n\nInit signature:\nAGCRN(\n    number_of_nodes: int,\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    embedding_dimensions: int,\n)\nDocstring:     \nAn implementation of the Adaptive Graph Convolutional Recurrent Unit.\nFor details see: `\"Adaptive Graph Convolutional Recurrent Network\nfor Traffic Forecasting\" <https://arxiv.org/abs/2007.02842>`_\nArgs:\n    number_of_nodes (int): Number of vertices.\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Filter size :math:`K`.\n    embedding_dimensions (int): Number of node embedding dimensions.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/agcrn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import AGCRN\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=8)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features,number_of_nodes):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = AGCRN(number_of_nodes = 20,\n                              in_channels = node_features,\n                              out_channels = 2,\n                              K = 2,\n                              embedding_dimensions = 4)\n        self.linear = torch.nn.Linear(2, 1)\n\n    def forward(self, x, e, h):\n        h_0 = self.recurrent(x, e, h)\n        y = F.relu(h_0)\n        y = self.linear(y)\n        return y, h_0\n\ntorch.nn.init.xavier_uniform_(e) 가중치 초기화\n\ne = torch.empty(20, 4)\n\n\ne\n\ntensor([[ 2.3516e+23,  3.0646e-41,  1.2073e+23,  3.0646e-41],\n        [ 1.2839e+00,  4.5579e-41,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 3.1494e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 1.2162e-01,  3.0726e-01,  5.5876e+24,  3.0646e-41],\n        [        nan,  4.5912e-41,         nan,  4.5912e-41],\n        [ 0.0000e+00,  0.0000e+00, -5.1905e-35,  4.5579e-41],\n        [ 4.5606e-01,  1.7410e-01,  4.3082e-01,  4.4134e-01],\n        [ 4.2527e-01,  3.9021e-01,  6.6931e-02,  1.1973e-03],\n        [ 8.9360e-02,  3.5911e-02,  3.8786e-02,  3.9897e-01],\n        [ 4.7854e-01,  0.0000e+00,  1.4659e-01,  3.2289e-01],\n        [ 4.2682e-01,  9.1125e-02,  1.1351e-43,  0.0000e+00],\n        [ 8.2566e+26,  3.0646e-41, -7.3231e+36,  4.5579e-41],\n        [ 3.2420e-02,  3.5085e-02,  2.4460e-02,  2.4794e-01]])\n\n\n\ntorch.nn.init.xavier_uniform_(e)\n\ntensor([[-0.1886, -0.1182, -0.2437,  0.4621],\n        [-0.2045, -0.0095, -0.2639, -0.3215],\n        [-0.3641,  0.1362, -0.2829,  0.3273],\n        [ 0.1198, -0.0813,  0.2029,  0.1687],\n        [ 0.2984, -0.3694,  0.2065, -0.4666],\n        [ 0.2634, -0.4748,  0.2762, -0.1667],\n        [-0.1677,  0.3808,  0.1978, -0.4734],\n        [-0.3368, -0.1218, -0.4826, -0.0898],\n        [ 0.1866,  0.0516, -0.4581,  0.0136],\n        [-0.2521, -0.3840, -0.2820,  0.0543],\n        [ 0.4000, -0.1176, -0.3463, -0.3728],\n        [-0.0128, -0.1869, -0.2293,  0.3790],\n        [-0.4311, -0.1795, -0.3970,  0.2133],\n        [-0.0487,  0.3308, -0.1300, -0.2409],\n        [ 0.4507, -0.3846,  0.1356, -0.3181],\n        [ 0.3372, -0.2599, -0.4767,  0.0201],\n        [-0.4959,  0.0642, -0.0844, -0.2929],\n        [-0.1447, -0.3859,  0.4434, -0.2623],\n        [ 0.0794,  0.2285, -0.1525,  0.4936],\n        [ 0.2819, -0.1921,  0.3888, -0.2040]])\n\n\n\ne\n\ntensor([[-0.1886, -0.1182, -0.2437,  0.4621],\n        [-0.2045, -0.0095, -0.2639, -0.3215],\n        [-0.3641,  0.1362, -0.2829,  0.3273],\n        [ 0.1198, -0.0813,  0.2029,  0.1687],\n        [ 0.2984, -0.3694,  0.2065, -0.4666],\n        [ 0.2634, -0.4748,  0.2762, -0.1667],\n        [-0.1677,  0.3808,  0.1978, -0.4734],\n        [-0.3368, -0.1218, -0.4826, -0.0898],\n        [ 0.1866,  0.0516, -0.4581,  0.0136],\n        [-0.2521, -0.3840, -0.2820,  0.0543],\n        [ 0.4000, -0.1176, -0.3463, -0.3728],\n        [-0.0128, -0.1869, -0.2293,  0.3790],\n        [-0.4311, -0.1795, -0.3970,  0.2133],\n        [-0.0487,  0.3308, -0.1300, -0.2409],\n        [ 0.4507, -0.3846,  0.1356, -0.3181],\n        [ 0.3372, -0.2599, -0.4767,  0.0201],\n        [-0.4959,  0.0642, -0.0844, -0.2929],\n        [-0.1447, -0.3859,  0.4434, -0.2623],\n        [ 0.0794,  0.2285, -0.1525,  0.4936],\n        [ 0.2819, -0.1921,  0.3888, -0.2040]])\n\n\n\nmodel = RecurrentGCN(node_features = 8,number_of_nodes=20)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\ne = torch.empty(20, 4)\n\ntorch.nn.init.xavier_uniform_(e)\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    h = None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        x = snapshot.x.view(1, 20, 8)\n        y_hat, h = model(x, e, h)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:11<00:00,  4.26it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    x = snapshot.x.view(1, 20, 8)\n    y_hat, h = model(x, e, h)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.1103\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nDCRNN(Done)\n\nDCRNN?\n\n\nInit signature: DCRNN(in_channels: int, out_channels: int, K: int, bias: bool = True)\nDocstring:     \nAn implementation of the Diffusion Convolutional Gated Recurrent Unit.\nFor details see: `\"Diffusion Convolutional Recurrent Neural Network:\nData-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Filter size :math:`K`.\n    bias (bool, optional): If set to :obj:`False`, the layer\n        will not learn an additive bias (default :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/dcrnn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [00:21<00:00,  9.44it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a = []\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1927\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nDYGRENCODER(Done)\n\nDyGrEncoder?\n\n\nInit signature:\nDyGrEncoder(\n    conv_out_channels: int,\n    conv_num_layers: int,\n    conv_aggr: str,\n    lstm_out_channels: int,\n    lstm_num_layers: int,\n)\nDocstring:     \nAn implementation of the integrated Gated Graph Convolution Long Short\nTerm Memory Layer. For details see this paper: `\"Predictive Temporal Embedding\nof Dynamic Graphs.\" <https://ieeexplore.ieee.org/document/9073186>`_\nArgs:\n    conv_out_channels (int): Number of output channels for the GGCN.\n    conv_num_layers (int): Number of Gated Graph Convolutions.\n    conv_aggr (str): Aggregation scheme to use\n        (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n    lstm_out_channels (int): Number of LSTM channels.\n    lstm_num_layers (int): Number of neurons in LSTM.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/dygrae.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DyGrEncoder\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DyGrEncoder(conv_out_channels=4, conv_num_layers=1, conv_aggr=\"mean\", lstm_out_channels=32, lstm_num_layers=1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h_0, c_0):\n        h, h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h_0, c_0)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [00:20<00:00,  9.58it/s]\n\n\n\nmodel.eval()\ncost = 0\nh, c = None, None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.4587\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nEvolveGCNH(Done)\n\nEvolveGCNH?\n\n\nInit signature:\nEvolveGCNH(\n    num_of_nodes: int,\n    in_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    normalize: bool = True,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Evolving Graph Convolutional Hidden Layer.\nFor details see this paper: `\"EvolveGCN: Evolving Graph Convolutional\nNetworks for Dynamic Graph.\" <https://arxiv.org/abs/1902.10191>`_\nArgs:\n    num_of_nodes (int): Number of vertices.\n    in_channels (int): Number of filters.\n    improved (bool, optional): If set to :obj:`True`, the layer computes\n        :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n        (default: :obj:`False`)\n    cached (bool, optional): If set to :obj:`True`, the layer will cache\n        the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n        \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n        cached version for further executions.\n        This parameter should only be set to :obj:`True` in transductive\n        learning scenarios. (default: :obj:`False`)\n    normalize (bool, optional): Whether to add self-loops and apply\n        symmetric normalization. (default: :obj:`True`)\n    add_self_loops (bool, optional): If set to :obj:`False`, will not add\n        self-loops to the input graph. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/evolvegcnh.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import EvolveGCNH\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, num_of_nodes, in_channels):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = EvolveGCNH(num_of_nodes, in_channels)\n        self.linear = torch.nn.Linear(in_channels, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(num_of_nodes = 20,in_channels = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [00:33<00:00,  5.96it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.9995\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nEVOLVEGCNO(Done)\n\nEvolveGCNO?\n\n\nInit signature:\nEvolveGCNO(\n    in_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    normalize: bool = True,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Evolving Graph Convolutional without Hidden Layer.\nFor details see this paper: `\"EvolveGCN: Evolving Graph Convolutional\nNetworks for Dynamic Graph.\" <https://arxiv.org/abs/1902.10191>`_\nArgs:\n    in_channels (int): Number of filters.\n    improved (bool, optional): If set to :obj:`True`, the layer computes\n        :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n        (default: :obj:`False`)\n    cached (bool, optional): If set to :obj:`True`, the layer will cache\n        the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n        \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n        cached version for further executions.\n        This parameter should only be set to :obj:`True` in transductive\n        learning scenarios. (default: :obj:`False`)\n    normalize (bool, optional): Whether to add self-loops and apply\n        symmetric normalization. (default: :obj:`True`)\n    add_self_loops (bool, optional): If set to :obj:`False`, will not add\n        self-loops to the input graph. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/evolvegcno.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import EvolveGCNO\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = EvolveGCNO(node_features)\n        self.linear = torch.nn.Linear(node_features, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\nfor param in model.parameters():\n    param.retain_grad()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward(retain_graph=True)\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [00:08<00:00, 22.31it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    if time == 0:\n        model.recurrent.weight = None\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.5661\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nGCLSTM(Done)\n\nGCLSTM?\n\n\nInit signature:\nGCLSTM(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the the Integrated Graph Convolutional Long Short Term\nMemory Cell. For details see this paper: `\"GC-LSTM: Graph Convolution Embedded LSTM\nfor Dynamic Link Prediction.\" <https://arxiv.org/abs/1812.04206>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gc_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GCLSTM\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GCLSTM(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(100)): #200\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 100/100 [00:10<00:00,  9.17it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2557\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nGConvLSTM(Done)\n\nGConvLSTM?\n\n\nInit signature:\nGConvLSTM(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the Chebyshev Graph Convolutional Long Short Term Memory\nCell. For details see this paper: `\"Structured Sequence Modeling with Graph\nConvolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gconv_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(node_features, 8, 1)\n        self.linear = torch.nn.Linear(8, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)): #200\n    cost = 0\n    h, c = None, None\n    _b = []\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:30<00:00,  1.66it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.7228\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nLightning(설치 안 됨)\n\n# import torch\n# from torch.nn import functional as F\n\n# import pytorch_lightning as pl\n# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n# from torch_geometric_temporal.signal import temporal_signal_split\n\n\n# class LitDiffConvModel(pl.LightningModule):\n\n#     def __init__(self, node_features, filters):\n#         super().__init__()\n#         self.recurrent = DCRNN(node_features, filters, 1)\n#         self.linear = torch.nn.Linear(filters, 1)\n\n\n#     def configure_optimizers(self):\n#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-2)\n#         return optimizer\n\n#     def training_step(self, train_batch, batch_idx):\n#         x = train_batch.x\n#         y = train_batch.y.view(-1, 1)\n#         edge_index = train_batch.edge_index\n#         h = self.recurrent(x, edge_index)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         loss = F.mse_loss(h, y)\n#         return loss\n\n#     def validation_step(self, val_batch, batch_idx):\n#         x = val_batch.x\n#         y = val_batch.y.view(-1, 1)\n#         edge_index = val_batch.edge_index\n#         h = self.recurrent(x, edge_index)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         loss = F.mse_loss(h, y)\n#         metrics = {'val_loss': loss}\n#         self.log_dict(metrics)\n#         return metrics\n\n\n# loader = ChickenpoxDatasetLoader()\n\n# dataset_loader = loader.get_dataset(lags=32)\n\n# train_loader, val_loader = temporal_signal_split(dataset_loader,\n#                                                  train_ratio=0.2)\n\n\n# model = LitDiffConvModel(node_features=32,\n#                          filters=16)\n\n\n# early_stop_callback = EarlyStopping(monitor='val_loss',\n#                                     min_delta=0.00,\n#                                     patience=10,\n#                                     verbose=False,\n#                                     mode='max')\n\n\n# trainer = pl.Trainer(callbacks=[early_stop_callback])\n\n\n# trainer.fit(model, train_loader, val_loader)\n\n\n\nLRGCN(Done)\n\nLRGCN?\n\n\nInit signature:\nLRGCN(\n    in_channels: int,\n    out_channels: int,\n    num_relations: int,\n    num_bases: int,\n)\nDocstring:     \nAn implementation of the Long Short Term Memory Relational\nGraph Convolution Layer. For details see this paper: `\"Predicting Path\nFailure In Time-Evolving Graphs.\" <https://arxiv.org/abs/1905.03994>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    num_relations (int): Number of relations.\n    num_bases (int): Number of bases.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/lrgcn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import LRGCN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = LRGCN(node_features, 32, 1, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h_0, c_0):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h_0, c_0)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 200/200 [00:47<00:00,  4.23it/s]\n\n\n\nmodel.eval()\ncost = 0\nh, c = None, None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2608\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nMPNNLSTM\n\nMPNNLSTM?\n\n\nInit signature:\nMPNNLSTM(\n    in_channels: int,\n    hidden_size: int,\n    num_nodes: int,\n    window: int,\n    dropout: float,\n)\nDocstring:     \nAn implementation of the Message Passing Neural Network with Long Short Term Memory.\nFor details see this paper: `\"Transfer Graph Neural Networks for Pandemic Forecasting.\" <https://arxiv.org/abs/2009.08388>`_\nArgs:\n    in_channels (int): Number of input features.\n    hidden_size (int): Dimension of hidden representations.\n    num_nodes (int): Number of nodes in the network.\n    window (int): Number of past samples included in the input.\n    dropout (float): Dropout rate.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/mpnn_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import MPNNLSTM\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nnum_nodes=2\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = MPNNLSTM(node_features, 8,  num_nodes, 1, 0.3) # 32, 32, 20, 1, 0.5 이었는데 position 잘못되었다해서 32하나 뺌\n        self.linear = torch.nn.Linear(num_nodes*8 + node_features, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:57<00:00,  1.14s/it]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.3623\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nTGCN(Done)\n\nTGCN?\n\n\nInit signature:\nTGCN(\n    in_channels: int,\n    out_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Temporal Graph Convolutional Gated Recurrent Cell.\nFor details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\nTraffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    improved (bool): Stronger self loops. Default is False.\n    cached (bool): Caching the message weights. Default is False.\n    add_self_loops (bool): Adding self-loops for smoothing. Default is True.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import TGCN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = TGCN(node_features, 8)\n        self.linear = torch.nn.Linear(8, 1)\n\n    def forward(self, x, edge_index, edge_weight, prev_hidden_state):\n        h = self.recurrent(x, edge_index, edge_weight, prev_hidden_state)\n        y = F.relu(h)\n        y = self.linear(y)\n        return y, h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    hidden_state = None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr,hidden_state)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:06<00:00,  8.10it/s]\n\n\n\nmodel.eval()\ncost = 0\nhidden_state = None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, hidden_state)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.8115\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='mrate',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-05-28_10-40-44.csv')\ndf2 = pd.read_csv('./simulation_results/2023-05-28_11-09-06.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\ndf1 = pd.read_csv('./simulation_results/2023-05-30_15-07-43.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-05-31_01-58-40.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html",
    "title": "LRGCN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random",
    "title": "LRGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block",
    "title": "LRGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "LRGCN_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-20_19-13-42.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-20_19-46-03.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/LRGCN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/LRGCN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "LRGCN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-21_19-31-38.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-21_22-43-39.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-22_02-04-05.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/LRGCN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/LRGCN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html",
    "title": "SimualtionPlanner-Tutorial",
    "section": "",
    "text": "table"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.7,0.8],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='fivenodes')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3,0.8],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.3],\n    'lags': [2, 4], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'RecurrentGCN' : ['DCRNN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,7500)) # 17470*0.8 = 13976.0\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGCLSTM/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmy_list[13] = another_list\nmy_list[15] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,35))\nmy_list[2] = another_list\nmy_list[4] = another_list\nmy_list[7] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 72)\n# my_list에서 250개 요소 무작위 선택\nselected_indexes = random.sample(range(len(my_list)), 250)\n# 선택된 요소에 해당하는 값들을 another_list에 할당\nfor index in selected_indexes:\n    my_list[index] = another_list\n\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n# loader = itstgcn.DatasetLoader(data_dict)\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'RecurrentGCN' : ['GConvGRU','GConvLSTM'],\n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50],\n    'lr': [0.01]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'RecurrentGCN' : ['GConvGRU','GConvLSTM'],\n    'mindex': [mindex],\n    'lags': [2,4], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\n\n\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# data_dict=itstgcn.load_data('./data/fivenodes.pkl')\n# loader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 30, \n#    'method': ['GNAR'], \n    'mrate': [0.1],\n    'lags': [4], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear','cubic'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader2,dataset_name='pedalme')\nplnr.simulate()\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0],\n    'lags': [2,4], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0,0.3],\n    'lags': [8], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader5,dataset_name='windmillmedium')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# loader = itstgcn.load_data('./data/fivenodes.pkl')\n\n\n Nodes : 26\n\nvertices represent 26 windmills\n-Edges : 676\n\nweighted edges describe the strength of relationships\n- Time : 17464\n\n\nmy_list = [[] for _ in range(26)] #medium\nanother_list = list(range(1000,2000))+list(range(4000,5000))+list(range(7000,8000)) #17464\n\nfor i in np.array(random.sample(range(0, 26), 15)):\n    my_list[i] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[2] = another_list\nmy_list[4] = another_list\nmy_list[6] = another_list\nmy_list[8] = another_list\nmy_list[10] = another_list\nmy_list[12] = another_list\nmy_list[14] = another_list\nmy_list[16] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [4], \n    'inter_method': ['cubic','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2,4], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.126\n      0.034\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.137\n      0.047"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.7\n      12\n      IT-STGCN\n      2\n      1.287\n      0.075\n    \n    \n      1\n      linear\n      0.7\n      12\n      STGCN\n      2\n      1.472\n      0.125\n    \n    \n      2\n      linear\n      0.8\n      12\n      IT-STGCN\n      2\n      1.298\n      0.060\n    \n    \n      3\n      linear\n      0.8\n      12\n      STGCN\n      2\n      1.442\n      0.111\n    \n    \n      4\n      nearest\n      0.7\n      12\n      IT-STGCN\n      2\n      1.261\n      0.077\n    \n    \n      5\n      nearest\n      0.7\n      12\n      STGCN\n      2\n      1.394\n      0.085\n    \n    \n      6\n      nearest\n      0.8\n      12\n      IT-STGCN\n      2\n      1.312\n      0.065\n    \n    \n      7\n      nearest\n      0.8\n      12\n      STGCN\n      2\n      1.436\n      0.098"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.125\n      12\n      IT-STGCN\n      1.140\n      0.038\n    \n    \n      1\n      linear\n      0.125\n      12\n      STGCN\n      1.172\n      0.055\n    \n    \n      2\n      nearest\n      0.125\n      12\n      IT-STGCN\n      1.121\n      0.027\n    \n    \n      3\n      nearest\n      0.125\n      12\n      STGCN\n      1.140\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.3\n      32\n      IT-STGCN\n      4\n      0.035\n      0.035\n    \n    \n      1\n      linear\n      0.3\n      32\n      STGCN\n      4\n      0.057\n      0.057\n    \n    \n      2\n      linear\n      0.8\n      32\n      IT-STGCN\n      4\n      0.080\n      0.080\n    \n    \n      3\n      linear\n      0.8\n      32\n      STGCN\n      4\n      0.111\n      0.111"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.288\n      32\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      1\n      linear\n      0.288\n      32\n      STGCN\n      0.900\n      0.049\n    \n    \n      2\n      nearest\n      0.288\n      32\n      IT-STGCN\n      0.885\n      0.040\n    \n    \n      3\n      nearest\n      0.288\n      32\n      STGCN\n      0.896\n      0.054"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.213\n      0.050\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.215\n      0.059"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.227\n      0.056\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.244\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.224\n      0.035\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.266\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.255\n      0.049\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.332\n      0.089\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.045\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.274\n      0.078"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.069\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.223\n      0.042\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#w_st",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.340\n      0.166\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.392\n      0.109\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.368\n      0.158\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.338\n      0.118\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.313\n      0.205\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.503\n      0.101\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.310\n      0.151\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.459\n      0.153"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      64\n      IT-STGCN\n      0.626\n      0.015\n    \n    \n      1\n      8\n      64\n      STGCN\n      0.640\n      0.031"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.631\n      0.019\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.764\n      0.057\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.920\n      0.069\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.423\n      0.121"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.627324\n      0.013908\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.660386\n      0.033577"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.653\n      0.033\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.963\n      0.098"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.014\n      0.031\n    \n    \n      1\n      8\n      STGCN\n      1.023\n      0.055"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.142\n      0.021\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.600\n      0.056"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      0.997\n      0.022\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      0.989\n      0.009"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.959\n      0.012\n    \n    \n      1\n      4\n      STGCN\n      0.960\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.156399\n      0.061898\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.133692\n      0.068590"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.949276\n      0.007582\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.949673\n      0.005402"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "",
    "text": "Simulation"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f3423668bd0>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#learn",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#learn",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:57<00:00,  1.15s/it]"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#visualization",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#visualization",
    "title": "[IT-STGCN] STGCN 튜토리얼",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      0.732\n      0.005\n    \n    \n      1\n      12\n      STGCN\n      2\n      0.732\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.167\n      0.059\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      2.077\n      0.252\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.371\n      0.097\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      2.432\n      0.263"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.160\n      0.042\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.215\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.752\n      0.013\n    \n    \n      1\n      16\n      STGCN\n      0.752\n      0.012"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.087\n      0.046\n    \n    \n      2\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      3\n      0.8\n      linear\n      16\n      STGCN\n      2.529\n      0.292"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.807041\n      0.016362\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.828224\n      0.021919\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.823756\n      0.022918\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.828498\n      0.022007"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.233\n      0.115\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.233\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.655\n      0.179\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#w_st",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.528\n      0.003"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.570\n      0.006\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.932\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003835\n      8\n      IT-STGCN\n      0.528737\n      0.002806\n    \n    \n      1\n      0.003835\n      8\n      STGCN\n      0.527871\n      0.002606\n    \n    \n      2\n      0.095870\n      8\n      IT-STGCN\n      0.529440\n      0.003820\n    \n    \n      3\n      0.095870\n      8\n      STGCN\n      0.544176\n      0.010772"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.531\n      0.002\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.720\n      0.013"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.004\n      0.004\n    \n    \n      1\n      8\n      STGCN\n      1.003\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.193\n      0.045\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.661\n      0.076"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.931\n      0.001\n    \n    \n      1\n      4\n      STGCN\n      0.931\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.09556\n      0.018743\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.51600\n      0.039793"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      cubic\n      IT-STGCN\n      1.022866\n      0.021048\n    \n    \n      1\n      0.149142\n      4\n      cubic\n      STGCN\n      1.028363\n      0.031275\n    \n    \n      2\n      0.149142\n      4\n      linear\n      IT-STGCN\n      0.930156\n      0.001956\n    \n    \n      3\n      0.149142\n      4\n      linear\n      STGCN\n      0.934719\n      0.004724\n    \n    \n      4\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.931785\n      0.002158\n    \n    \n      5\n      0.149142\n      4\n      nearest\n      STGCN\n      0.934596\n      0.003562"
  },
  {
    "objectID": "posts/GCN/2099-05-31-Other Method.html",
    "href": "posts/GCN/2099-05-31-Other Method.html",
    "title": "ITSTGCN add Model",
    "section": "",
    "text": "summerizing it\n\n\nRANDOM\n\n\n예\n\nimport itstgcnDCRNN\nimport torch\nimport itstgcnDCRNN.planner \nimport pandas as pd\n\nimport numpy as np\nimport random\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndata_dict = itstgcnGCLSTM.load_data('./data/fivenodes.pkl')\nloader = itstgcnGConvLSTM.DatasetLoader(data_dict)\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputLargeDatasetLoader\n# loader4 = WindmillOutputLargeDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputMediumDatasetLoader\n# loader5 = WindmillOutputMediumDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\n# loader6 = WindmillOutputSmallDatasetLoader()\n\n\nloader6 = itstgcnDCRNN.load_data('./data/Windmillsmall.pkl')\n\n\n# dataset6 = _a.get_dataset(lags=8)\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader10 = MontevideoBusDatasetLoader()\n\n\n\nSimulation\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.7],\n    'lags': [8], \n    'nof_filters': [4], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n50/50\n\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.7],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.8],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nmindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mindex': [mindex],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3,0.8],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmy_list[13] = another_list\nmy_list[15] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.3,0.6],\n    'lags': [4], \n    'nof_filters': [2], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [2], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 72)\n# my_list에서 250개 요소 무작위 선택\nselected_indexes = random.sample(range(len(my_list)), 250)\n# 선택된 요소에 해당하는 값들을 another_list에 할당\nfor index in selected_indexes:\n    my_list[index] = another_list\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 150)\n# my_list에서 250개 요소 무작위 선택\nselected_indexes = random.sample(range(len(my_list)), 500)\n# 선택된 요소에 해당하는 값들을 another_list에 할당\nfor index in selected_indexes:\n    my_list[index] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n같은 노드 같은 missing\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = random.sample(range(0, 576), 300)\nfor i in range(0, 1068):\n    my_list[i] = another_list\nmindex = my_list\n\n\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html",
    "title": "GCN Algorithm Example 1",
    "section": "",
    "text": "Our method; GNAR Dataset Example(fiveVTS, fiveNet)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#데이터-일부-missing-처리",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#데이터-일부-missing-처리",
    "title": "GCN Algorithm Example 1",
    "section": "데이터 일부 missing 처리",
    "text": "데이터 일부 missing 처리\n\n1) Block 처리\n\n[1] ST-GCN\n\n%%R\nfiveVTS0 <- fiveVTS\nfiveVTS0[50:150, 3] <- NA\n\n\nplt.plot(fiveVTS0[:,2])\n\n\n\n\n\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(fiveVTS0).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(yhat[:,0].data)\nplt.plot(yhat[:,1].data)\nplt.plot(yhat[:,2].data)\nplt.plot(yhat[:,3].data)\n\n\n\n\n\n\n\n2) Random missing values\n\n%%R\nset.seed(1)\nfiveVTSrandom <- fiveVTS\nsampleindex = sort(sample(1:200, 100))\nfiveVTSrandom[sampleindex,3] <- NA\n\n\n%R -o fiveVTSrandom\n%R -o sampleindex\n\n\nplt.plot(fiveVTSrandom[:,2],'o')\n\n\n\n\n\n\n3) By 2\n\n%%R\nfiveVTStwo <- fiveVTS\nindextwo <- rep(seq(1, by = 2, 200))\nfiveVTStwo[indextwo, 3] <- NA\n\n\n%R -o fiveVTStwo\n%R -o indextwo\n\n\nplt.plot(fiveVTStwo[:,2],'o')"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean",
    "title": "GCN Algorithm Example 1",
    "section": "1.1. Mean",
    "text": "1.1. Mean\n\n1) Block\n\nfiveVTS0_mean = fiveVTS0.copy()\n\n\nfiveVTS0_mean[49:150,2] = np.mean(fiveVTS0[:49,2].tolist()+fiveVTS0[150:,2].tolist())\n\n\nplt.plot(fiveVTS0_mean[:,2])\n\n\n\n\n\n\n2) Random missing values\n\nfiveVTSrandom_mean = fiveVTSrandom.copy()\n\n\ndf = pd.DataFrame(fiveVTSrandom[:,2])\nmean_value = df.mean() # finds the mean value of the column A\ndf = df.fillna(mean_value) # replace missing values with the mean value\n\n\nfiveVTSrandom_mean[:,2] = np.array(df).reshape(200,)\n\n\nplt.plot(fiveVTSrandom_mean[:,2])\n\n\n\n\n\n\n3) By 2\n\nfiveVTStwo_mean = fiveVTStwo.copy()\n\n\ndf = pd.DataFrame(fiveVTStwo[:,2])\nmean_value = df.mean() # finds the mean value of the column A\ndf = df.fillna(mean_value) # replace missing values with the mean value\n\n\nfiveVTStwo_mean[:,2] = np.array(df).reshape(200,)\n\n\nplt.plot(fiveVTStwo_mean[:,2])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation",
    "title": "GCN Algorithm Example 1",
    "section": "1.2. linear interpolation",
    "text": "1.2. linear interpolation\n\n1) Block\n\nfiveVTS0_linearinterpolation = fiveVTS0.copy()\n\n\n# Sample data points\nx = np.array([48,150])\ny = np.array([fiveVTS0_linearinterpolation[48,2],fiveVTS0_linearinterpolation[150,2]])\n\n# Create interpolating function\nf = interp1d(x, y, kind='linear')\n\n# Estimate y value for x = 2.5\ny_interp = f(range(49,150))\n\n\nfiveVTS0_linearinterpolation[49:150,2] = y_interp\n\n\nplt.plot(fiveVTS0_linearinterpolation[:,2])\n\n\n\n\n\n\n2) Random missing values\n\nfiveVTSrandom_linearinterpolation = fiveVTSrandom.copy()\n\n\n_df = pd.DataFrame(fiveVTSrandom_linearinterpolation[:,2])\n_df.interpolate(method='linear', inplace=True)\n_df = _df.fillna(0)\n\n\nfiveVTSrandom_linearinterpolation[:,2] = np.array(_df).reshape(200,)\n\n\nplt.plot(fiveVTSrandom_linearinterpolation[:,2])\n\n\n\n\n\n\n3) By 2\n\nfiveVTStwo_linearinterpolation = fiveVTStwo.copy()\n\n\n_df = pd.Series(fiveVTStwo_linearinterpolation[:,2])\n_df.interpolate(method='linear', inplace=True)\n_df = _df.fillna(0)\n\n\nfiveVTStwo_linearinterpolation[:,2] = _df\n\n\nplt.plot(fiveVTStwo_linearinterpolation[:,2])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-1",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-1",
    "title": "GCN Algorithm Example 1",
    "section": "2.1. Mean",
    "text": "2.1. Mean\n\n1) Block\n\nf_mean = torch.tensor(fiveVTS0_mean).reshape(200,5,1).float()\n\n\nX_mean = f_mean[:199,:,:]\ny_mean = f_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_mean,y_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.56it/s]\n\n\n\nfhat_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_mean]).detach().numpy()\n\n\nplt.plot(fhat_mean[:,2].data)\n\n\n\n\n\n\n2) Random missing values\n\nf_fiveVTSrandom_mean = torch.tensor(fiveVTSrandom_mean).reshape(200,5,1).float()\n\n\nX_fiveVTSrandom_mean = f_fiveVTSrandom_mean[:199,:,:]\ny_fiveVTSrandom_mean = f_fiveVTSrandom_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTSrandom_mean,y_fiveVTSrandom_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTSrandom_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTSrandom_mean]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTSrandom_mean[:,2].data)\n\n\n\n\n\n\n3) By 2\n\nf_fiveVTStwo_mean = torch.tensor(fiveVTStwo_mean).reshape(200,5,1).float()\n\n\nX_fiveVTStwo_mean = f_fiveVTStwo_mean[:199,:,:]\ny_fiveVTStwo_mean = f_fiveVTStwo_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTStwo_mean,y_fiveVTStwo_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n\n\n\nfhat_fiveVTStwo_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTStwo_mean]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTStwo_mean[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-1",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-1",
    "title": "GCN Algorithm Example 1",
    "section": "2.2. linear interpolation",
    "text": "2.2. linear interpolation\n\n1) Block\n\nf_linearinterpolation = torch.tensor(fiveVTS0_linearinterpolation).reshape(200,5,1).float()\n\n\nX_linearinterpolation = f_linearinterpolation[:199,:,:]\ny_linearinterpolation = f_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_linearinterpolation,y_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_linearinterpolation[:,2].data)\n\n\n\n\n\n\n2) Random missing values\n\nf_fiveVTSrandom_linearinterpolation = torch.tensor(fiveVTSrandom_linearinterpolation).reshape(200,5,1).float()\n\n\nX_fiveVTSrandom_linearinterpolation = f_fiveVTSrandom_linearinterpolation[:199,:,:]\ny_fiveVTSrandom_linearinterpolation = f_fiveVTSrandom_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTSrandom_linearinterpolation,y_fiveVTSrandom_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTSrandom_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTSrandom_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTSrandom_linearinterpolation[:,2].data)\n\n\n\n\n\n\n3) By 2\n\nf_fiveVTStwo_linearinterpolation = torch.tensor(fiveVTStwo_linearinterpolation).reshape(200,5,1).float()\n\n\nX_fiveVTStwo_linearinterpolation = f_fiveVTSrandom_linearinterpolation[:199,:,:]\ny_fiveVTStwo_linearinterpolation = f_fiveVTSrandom_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTStwo_linearinterpolation,y_fiveVTStwo_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTStwo_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTStwo_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTStwo_linearinterpolation[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#원래-f",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#원래-f",
    "title": "GCN Algorithm Example 1",
    "section": "2.3. 원래 f",
    "text": "2.3. 원래 f\n\nf = torch.tensor(fiveVTS).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTS[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-2",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-2",
    "title": "GCN Algorithm Example 1",
    "section": "3.1. Mean",
    "text": "3.1. Mean\n\n3.1.1. Temporal\n\n1) Block\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_mean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_mean_temporal[:,0])\nplt.plot(fhatbarhat_mean_temporal[:,1])\nplt.plot(fhatbarhat_mean_temporal[:,2])\nplt.plot(fhatbarhat_mean_temporal[:,3])\nplt.plot(fhatbarhat_mean_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTSrandom_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_random_mean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_mean_temporal[:,0])\nplt.plot(fhatbarhat_random_mean_temporal[:,1])\nplt.plot(fhatbarhat_random_mean_temporal[:,2])\nplt.plot(fhatbarhat_random_mean_temporal[:,3])\nplt.plot(fhatbarhat_random_mean_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTStwo_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_twomean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_twomean_temporal[:,0])\nplt.plot(fhatbarhat_twomean_temporal[:,1])\nplt.plot(fhatbarhat_twomean_temporal[:,2])\nplt.plot(fhatbarhat_twomean_temporal[:,3])\nplt.plot(fhatbarhat_twomean_temporal[:,4])\n\n\n\n\n\n\n\n3.1.2. Spatio\n\n1) Block\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_mean_spatio[:,0])\nplt.plot(fhatbarhat_mean_spatio[:,1])\nplt.plot(fhatbarhat_mean_spatio[:,2])\nplt.plot(fhatbarhat_mean_spatio[:,3])\nplt.plot(fhatbarhat_mean_spatio[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_mean_spatio[:,0])\nplt.plot(fhatbarhat_random_mean_spatio[:,1])\nplt.plot(fhatbarhat_random_mean_spatio[:,2])\nplt.plot(fhatbarhat_random_mean_spatio[:,3])\nplt.plot(fhatbarhat_random_mean_spatio[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_mean_spatio[:,0])\nplt.plot(fhatbarhat_two_mean_spatio[:,1])\nplt.plot(fhatbarhat_two_mean_spatio[:,2])\nplt.plot(fhatbarhat_two_mean_spatio[:,3])\nplt.plot(fhatbarhat_two_mean_spatio[:,4])\n\n\n\n\n\n\n\n3.1.3. Spatio-Temporal\n\n1) Block\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-2",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-2",
    "title": "GCN Algorithm Example 1",
    "section": "3.2.linear interpolation",
    "text": "3.2.linear interpolation\n\n3.2.1. Temporal\n\n1) Block\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTSrandom_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_random_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTStwo_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_two_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n\n3.2.2. Spatio\n\n1) Block\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n\n3.2.3. Spatio-Temporal\n\n1) Block\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_random_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_two_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#original",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#original",
    "title": "GCN Algorithm Example 1",
    "section": "3.3. original",
    "text": "3.3. original\n\n1) Temporal\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTS[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_temporal[:,0])\nplt.plot(fhatbarhat_temporal[:,1])\nplt.plot(fhatbarhat_temporal[:,2])\nplt.plot(fhatbarhat_temporal[:,3])\nplt.plot(fhatbarhat_temporal[:,4])\n\n\n\n\n\n\n2) Spatio\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTS.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_spatio[:,0])\nplt.plot(fhatbarhat_spatio[:,1])\nplt.plot(fhatbarhat_spatio[:,2])\nplt.plot(fhatbarhat_spatio[:,3])\nplt.plot(fhatbarhat_spatio[:,4])\n\n\n\n\n\n\n3) Spatio-Temporal\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTS.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_spatio_temporal[:,0])\nplt.plot(fhat_spatio_temporal[:,1])\nplt.plot(fhat_spatio_temporal[:,2])\nplt.plot(fhat_spatio_temporal[:,3])\nplt.plot(fhat_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      2\n      IT-STGCN\n      2\n      1.228\n      0.041\n    \n    \n      1\n      2\n      STGCN\n      2\n      1.230\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      2\n      IT-STGCN\n      1.227\n      0.030\n    \n    \n      1\n      0.125\n      2\n      STGCN\n      1.254\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.726\n      0.007\n    \n    \n      1\n      16\n      STGCN\n      0.727\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.797\n      0.010\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.032\n      0.039\n    \n    \n      2\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.467\n      0.076\n    \n    \n      3\n      0.8\n      linear\n      16\n      STGCN\n      2.287\n      0.074"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.739812\n      0.007356\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.812195\n      0.006422\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.738336\n      0.007345\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.832292\n      0.009452"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      8\n      IT-STGCN\n      1.131\n      0.015\n    \n    \n      1\n      4\n      8\n      STGCN\n      1.131\n      0.015"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.190\n      0.029\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.277\n      0.064\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.179\n      0.035\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.278\n      0.060\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.551\n      0.092\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.303\n      0.078\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.509\n      0.068"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.154\n      0.014\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.248\n      0.019\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#w_st",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.153\n      0.036\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.053\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.154\n      0.038\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.079\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.552\n      0.087\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.143\n      0.011\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.310\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.936\n      0.002\n    \n    \n      1\n      4\n      STGCN\n      0.936\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.111060\n      0.036307\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.225077\n      0.072743"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.940344\n      0.001323\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.955944\n      0.003010"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.084\n      0.017\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.085\n      0.014"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.119\n      0.043\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.156\n      0.070\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.132\n      0.051\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.169\n      0.065"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.090\n      0.015\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.099\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      12\n      IT-STGCN\n      1.042\n      0.020\n    \n    \n      1\n      0.3\n      linear\n      12\n      STGCN\n      1.054\n      0.015\n    \n    \n      2\n      0.8\n      linear\n      12\n      IT-STGCN\n      1.183\n      0.028\n    \n    \n      3\n      0.8\n      linear\n      12\n      STGCN\n      1.466\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      12\n      IT-STGCN\n      1.064651\n      0.030813\n    \n    \n      1\n      linear\n      0.28777\n      12\n      STGCN\n      1.082494\n      0.028106\n    \n    \n      2\n      nearest\n      0.28777\n      12\n      IT-STGCN\n      1.069594\n      0.028391\n    \n    \n      3\n      nearest\n      0.28777\n      12\n      STGCN\n      1.079100\n      0.027403"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.341\n      0.067\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.274\n      0.067"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.070\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.302\n      0.112\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.074\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.291\n      0.111\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.257\n      0.048\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.257\n      0.072\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.072\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.301\n      0.090"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.056\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.244\n      0.071\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#w_st",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.320\n      0.164\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.287\n      0.126\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.276\n      0.105\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.313\n      0.101\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.338\n      0.202\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.297\n      0.093\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.237\n      0.083\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.258\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      nof_filters\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.748\n      0.052\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.720\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      1\n      4\n      STGCN\n      0.982\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.072795\n      0.024438\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.217952\n      0.085842"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.983640\n      0.006550\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.985485\n      0.005308"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html",
    "title": "Data management Figure for ITSTGCN",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\n\n\ndf <- read.csv(\"./df_fig.csv\")\n\n\nhead(df)\n\n\n\n\n\n    Xdatasetmethodmratemtypelagsnof_filtersinter_methodepochmsecalculation_timemodel\n    <int><chr><chr><dbl><chr><int><dbl><chr><dbl><dbl><dbl><chr>\n\n\n    10fivenodesSTGCN0.0    212       500.7293743 80.98522GConvGRU\n    21fivenodesSTGCN0.0    212       500.7290817 80.89179GConvGRU\n    32fivenodesSTGCN0.7rand212linear 501.8922616 81.97655GConvGRU\n    43fivenodesSTGCN0.7rand212nearest502.2112885 87.80387GConvGRU\n    54fivenodesSTGCN0.8rand212linear 502.0728178103.64874GConvGRU\n    65fivenodesSTGCN0.8rand212nearest502.5664744 98.34010GConvGRU\n\n\nA data.frame: 6 × 12"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#후보-1",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#후보-1",
    "title": "Data management Figure for ITSTGCN",
    "section": "후보 1",
    "text": "후보 1\n\nggplot(fivenodes, aes(x=mrate,y= mse,group=mrate)) + facet_wrap(model~method) + \ngeom_boxplot(fill='grey',color='black',width=0.7,outlier.color = 'darkblue',outlier.shape = 2) + theme_classic()\n# ggsave(\"random_list_fivenodes.png\")"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#후보-2",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#후보-2",
    "title": "Data management Figure for ITSTGCN",
    "section": "후보 2",
    "text": "후보 2\n\nggplot(fivenodes, aes(x=mrate,y= log10(mse),group=mrate)) + facet_wrap(model~method,,ncol=4) + \ngeom_boxplot(fill='grey',color='black',width=0.7,outlier.color = 'darkblue',outlier.shape = 2) + \ntheme_classic() \n# ggsave(\"random_list_fivenodes.png\")"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#weight-matrix-time-node-고려한-결과",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "weight matrix time, node 고려한 결과",
    "text": "weight matrix time, node 고려한 결과\n\ndf1 = pd.read_csv('./simulation_results/2023-06-30_13-25-56.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-30_14-00-19.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-07-01_17-41-40.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-07-01_21-00-26.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-07-02_00-17-30.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/FRAUD/2023-07-10-fraud_data.html",
    "href": "posts/FRAUD/2023-07-10-fraud_data.html",
    "title": "Fraud data",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport sklearn\n\n# from ctgan import CTGAN\n# from ctgan import load_demo\n\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\nref: https://miruetoto.github.io/yechan3/posts/3_Researches/BORAM/2023-07-03-CTGAN_%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C.html\n\n\nData\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf50 = down_sample_textbook(df02)\n_df50 = df50.assign(Date=list(map(lambda x: x.split(' ')[0],df50['trans_date_trans_time'])),Time=list(map(lambda x: x.split(' ')[1],df50['trans_date_trans_time'])))\n\n\n_df50\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      city_pop\n      job\n      dob\n      trans_num\n      unix_time\n      merch_lat\n      merch_long\n      is_fraud\n      Date\n      Time\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      885\n      Soil scientist\n      1988-09-15\n      e8a81877ae9a0a7f883e15cb39dc4022\n      1325466397\n      36.430124\n      -81.179483\n      1\n      2019-01-02\n      1:06\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      bc7d41c41103877b03232f03f1f8d3f5\n      1325468849\n      29.819364\n      -99.142791\n      1\n      2019-01-02\n      1:47\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      b98f12f4168391b2203238813df5aa8c\n      1325473523\n      29.273085\n      -98.836360\n      1\n      2019-01-02\n      3:05\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      885\n      Soil scientist\n      1988-09-15\n      397894a5c4c02e3c61c784001f0f14e4\n      1325475483\n      35.909292\n      -82.091010\n      1\n      2019-01-02\n      3:38\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      7863235a750d73a244c07f1fb7f0185a\n      1325476547\n      29.786426\n      -98.683410\n      1\n      2019-01-02\n      3:55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      1507\n      Land/geomatics surveyor\n      1993-10-12\n      c66cb411019c7dfd4d89f42a1ba4765f\n      1339961448\n      44.212695\n      -95.661879\n      0\n      2019-06-17\n      19:30\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      965\n      Horticultural therapist\n      1982-02-10\n      316b9d25b9fa7d08a6831b7dab6634cd\n      1331994839\n      38.394240\n      -86.413557\n      0\n      2019-03-17\n      14:33\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      530\n      Transport planner\n      1967-09-23\n      d92e9e63d9b24c3ccb92d05cba4cac54\n      1355747517\n      39.695248\n      -89.853063\n      0\n      2019-12-17\n      12:31\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      885\n      Pilot, airline\n      1949-08-14\n      8390ce51cfb8482b618ebc4ac370bcf7\n      1326878457\n      42.633204\n      -95.598143\n      0\n      2019-01-18\n      9:20\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      1760\n      Occupational psychologist\n      1972-01-20\n      04e1be9bcb18ea8b96048659bd02177b\n      1345123058\n      33.885236\n      -95.885110\n      0\n      2019-08-16\n      13:17\n    \n  \n\n12012 rows × 24 columns\n\n\n\n\n_df50.columns\n\nIndex(['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n       'merch_long', 'is_fraud', 'Date', 'Time'],\n      dtype='object')\n\n\n\ndf50['is_fraud'].mean()\n\n0.5\n\n\n\ndf50['category'].unique()\n\narray(['grocery_pos', 'gas_transport', 'shopping_net', 'misc_net',\n       'shopping_pos', 'travel', 'grocery_net', 'misc_pos',\n       'health_fitness', 'kids_pets', 'entertainment', 'food_dining',\n       'home', 'personal_care'], dtype=object)\n\n\n\n_df50_add = _df50.assign(Year = list(map(lambda x: x.split('-')[0],_df50['Date'])),\\\n                        Mon = list(map(lambda x: x.split('-')[1],_df50['Date'])),\\\n                        Day = list(map(lambda x: x.split('-')[2],_df50['Date'])),\\\n                         Hour= list(map(lambda x: x.split(':')[0],_df50['Time'])),\\\n                         Sec= list(map(lambda x: x.split(':')[1],_df50['Time'])))\n_df50_add.Year = _df50_add.Year.astype(np.float64)\n_df50_add.Mon = _df50_add.Mon.astype(np.float64)\n_df50_add.Day = _df50_add.Day.astype(np.float64)\n_df50_add.Hour = _df50_add.Hour.astype(np.float64)\n_df50_add.Sec = _df50_add.Sec.astype(np.float64)\n\n\n_df50_add\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      merch_lat\n      merch_long\n      is_fraud\n      Date\n      Time\n      Year\n      Mon\n      Day\n      Hour\n      Sec\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      36.430124\n      -81.179483\n      1\n      2019-01-02\n      1:06\n      2019.0\n      1.0\n      2.0\n      1.0\n      6.0\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.819364\n      -99.142791\n      1\n      2019-01-02\n      1:47\n      2019.0\n      1.0\n      2.0\n      1.0\n      47.0\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.273085\n      -98.836360\n      1\n      2019-01-02\n      3:05\n      2019.0\n      1.0\n      2.0\n      3.0\n      5.0\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.909292\n      -82.091010\n      1\n      2019-01-02\n      3:38\n      2019.0\n      1.0\n      2.0\n      3.0\n      38.0\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.786426\n      -98.683410\n      1\n      2019-01-02\n      3:55\n      2019.0\n      1.0\n      2.0\n      3.0\n      55.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      44.212695\n      -95.661879\n      0\n      2019-06-17\n      19:30\n      2019.0\n      6.0\n      17.0\n      19.0\n      30.0\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      38.394240\n      -86.413557\n      0\n      2019-03-17\n      14:33\n      2019.0\n      3.0\n      17.0\n      14.0\n      33.0\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      39.695248\n      -89.853063\n      0\n      2019-12-17\n      12:31\n      2019.0\n      12.0\n      17.0\n      12.0\n      31.0\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      42.633204\n      -95.598143\n      0\n      2019-01-18\n      9:20\n      2019.0\n      1.0\n      18.0\n      9.0\n      20.0\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      33.885236\n      -95.885110\n      0\n      2019-08-16\n      13:17\n      2019.0\n      8.0\n      16.0\n      13.0\n      17.0\n    \n  \n\n12012 rows × 29 columns\n\n\n\n\nfig,ax =plt.subplots(5,5)\nk=0\nfor i in range(5):\n    for j in range(5):\n        ax[i][j].hist(_df50_add[(_df50_add['Hour'] > k) & (_df50_add['Hour'] <= k+1)]['amt'])\n        # ax[i][j].set_xlim([0,15000])\n        ax[i][j].set_title(str(k))\n        if k < 24:\n            k = k + 1\n        else:\n            pass\nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig,ax =plt.subplots(4,4)\nk=0\nfor i in range(4):\n    for j in range(4):\n        ax[i][j].hist(df50[df50['category']==df50['category'].unique()[k]]['amt'])\n        # ax[i][j].set_ylim([-2,7])\n        ax[i][j].set_title(df50['category'].unique()[k])\n        if k < 12:\n            k = k + 1\n        else:\n            pass\nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html",
    "title": "Other Outlier Detection",
    "section": "",
    "text": "Note\n\n\n\nknn, cblof, ocsvm 을 제외한 이상치 탐지 기법들에 데이터 집합에서 이상치 비율을 지정할 수 있는 옵션이 존재하였음.\ndefault값은 10%인데, ABOD 방법에서는 5로 지정해주었고, 다른 방법들은 default인 10%가 들어갔다.\n일단 우리 방법이랑 비교해서 좋은지 보기\niter\niter x - kNN, Feature Bagging, ABOD, Isolation, HBOS, SOS, SO-GAAL, MO-GAAL, LSCP\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(5,7)\\) and \\(U(-7,-5)\\).\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(3,7)\\) and \\(U(-7,-3)\\)."
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#class-code",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#class-code",
    "title": "Other Outlier Detection",
    "section": "Class Code",
    "text": "Class Code\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_orbit = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_bunny = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\nclass Conf_matrx:\n    def __init__(self,original,compare,tab):\n        self.original = original\n        self.compare = compare\n        self.tab = tab\n    def conf(self,name):\n        self.conf_matrix = confusion_matrix(self.original, self.compare)\n        \n        fig, ax = plt.subplots(figsize=(5, 5))\n        ax.matshow(self.conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n        for i in range(self.conf_matrix.shape[0]):\n            for j in range(self.conf_matrix.shape[1]):\n                ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n        plt.xlabel('Predictions', fontsize=18)\n        plt.ylabel('Actuals', fontsize=18)\n        plt.title('Confusion Matrix', fontsize=18)\n        plt.show()\n        \n        self.acc = accuracy_score(self.original, self.compare)\n        self.pre = precision_score(self.original, self.compare)\n        self.rec = recall_score(self.original, self.compare)\n        self.f1 = f1_score(self.original, self.compare)\n        \n        print('Accuracy: %.3f' % self.acc)\n        print('Precision: %.3f' % self.pre)\n        print('Recall: %.3f' % self.rec)\n        print('F1 Score: %.3f' % self.f1)\n        \n        self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\nclass Linear:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        #self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=20): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n\n\nclass Orbit:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=20): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n\n\nclass BUNNY:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = _W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-ebayesthresh",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-ebayesthresh",
    "title": "Other Outlier Detection",
    "section": "Linear EbayesThresh",
    "text": "Linear EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\n# signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))\nsignal_1 = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier_1 = which(signal_1!=0)\nindex_of_trueoutlier_1\nx_1=signal_1+epsilon\n\n\n%R -o x_1\n%R -o index_of_trueoutlier_1\n%R -o signal_1\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\noutlier_true_index_1 = index_of_trueoutlier_1\n\n\noutlier_true_value_1 = x_1[index_of_trueoutlier_1]\n\n\noutlier_true_one_1 = signal_1.copy()\n\n\noutlier_true_one_1 = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one_1))"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear",
    "title": "Other Outlier Detection",
    "section": "Linear",
    "text": "Linear\n\n_x_1 = np.linspace(0,2,1000)\n_y1_1 = 5*_x_1\n_y_1 = _y1_1 + x_1 # x is epsilon\n\n\n_df=pd.DataFrame({'x':_x_1, 'y':_y_1})\n\n\nX = np.array(_df)\n\n\n# _df.to_csv('simple_linear_df.csv')\n\n\n# pd.DataFrame(outlier_true_one_1).to_csv('simple_linear_outlier.csv')\n\n\nGODE\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n_Linear = Linear(_df)\n\n\n_Linear.fit(sd=20)\n\n\noutlier_simul_one = (_Linear.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 9.8 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)\n\n\noutlier_simul_one.count(1)\n\n950\n\n\n\noutlier_simul_one.count(-1)\n\n50\n\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF(Breunig et al. 2000)\\(\\star\\)\n\nBreunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. “LOF: Identifying Density-Based Local Outliers.” In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 93–104.\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\nLof 논문 원문에 따라 LOF를 계산하고, min-max 범위를 넘으면 이상치\n\n\n\nFigure: LOF’s outliers detection method\n\n\n\n_conf = Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.926\nPrecision: 0.961\nRecall: 0.961\nF1 Score: 0.961\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nfrom pyod.models.knn import KNN\n\n\nclf = KNN()\nclf.fit(_df[['x', 'y']])\n_df['knn_Clf'] = clf.labels_\n\nk번째 이상은 outlier로 본다.\n이상치 비율 정하지 않음\nThree kNN detectors are supported:\n\nlargest: use the distance to the kth neighbor as the outlier score\nmean: use the average of all k neighbors as the outlier score\nmedian: use the median of the distance to k neighbors as the outlier score\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 1.000\nRecall: 0.947\nF1 Score: 0.973\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF(오류)\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n_df =  pd.read_csv('simple_linear_df.csv')\n\n\noutlier_true_one_1 = pd.read_csv('simple_linear_outlier.csv').iloc[:,1].tolist()\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\noutlier_CBLOF_one = list(clf.labels_)\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)\n\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.972\nPrecision: 0.985\nRecall: 0.985\nF1 Score: 0.985\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\n# four = three.append(_conf.tab)\n\n\nAccuracy: 0.972\nPrecision: 0.985\nRecall: 0.985\nF1 Score: 0.985\n\n\n\nOCSVM\ndefault=10%\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.05, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.05, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.991\nRecall: 0.940\nF1 Score: 0.965\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\\(\\star\\)\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\\(\\star\\)\ndefault값은 10%로 설정되어 있었고, 5%로 지정한 결과, 평가지표값이 전반적으로 1%이상 낮아졌다.\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.986\nPrecision: 0.993\nRecall: 0.993\nF1 Score: 0.993\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\\(\\star\\)\ndefault 값이 5%이며, 이미 지정된 채려 시뮬레이션 돌림\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['ABOD_Clf'] = clf.labels_\n\ncontamination : float in (0., 0.5), optional (default=0.1)\n\nThe amount of contamination of the data set, i.e.\nthe proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\n\n\nIForest\\(\\star\\)\nn_estimators Number of base estimators in the ensemble.\n\nn이 총 1000개니까 5%인 50 지정해줄 수 있음\n\n\nod = IForest(\n    threshold=0.,\n    n_estimators=50\n)\n\n\nod.fit(_df[['x', 'y']])\n\n\npreds = od.predict(\n    _df[['x', 'y']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.868\nPrecision: 0.999\nRecall: 0.862\nF1 Score: 0.925\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\\(\\star\\)\ndefault값은 이상치값을 10%로 지정하였으며, 5%로 지정한 결과 값 다 작아짐\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.960\nPrecision: 0.978\nRecall: 0.980\nF1 Score: 0.979\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\\(\\star\\)\ndefault 는 10%\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3130\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.3524\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3562\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3857\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3845\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3516\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3861\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4008\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3870\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4348\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.3913\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4431\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4510\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4427\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.4704\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4752\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4794\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4972\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4998\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.5168\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5228\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.5560\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5677\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.4929\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5675\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5508\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5679\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5563\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5806\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.5637\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5749\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6370\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6088\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6408\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6699\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5958\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5661\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.6471\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.6815\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6419\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6967\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7016\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6348\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 5ms/step - loss: 1.6519\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6470\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6582\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6890\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7197\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7613\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7085\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6933\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7013\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7330\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7275\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7635\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7682\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8321\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7557\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.7231\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7787\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.7553\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7782\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7678\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8069\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.7798\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8038\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.8120\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7591\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8204\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8033\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8414\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.7215\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8414\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8143\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8406\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8562\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8167\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8597\n32/32 [==============================] - 0s 2ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.936\nPrecision: 0.966\nRecall: 0.966\nF1 Score: 0.966\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\\(\\star\\)\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n32/32 [==============================] - 0s 658us/step\n\nTesting for epoch 1 index 2:\n32/32 [==============================] - 0s 865us/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n32/32 [==============================] - 0s 597us/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n32/32 [==============================] - 0s 623us/step\n\nTesting for epoch 4 index 2:\n32/32 [==============================] - 0s 633us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n32/32 [==============================] - 0s 597us/step\n\nTesting for epoch 5 index 2:\n32/32 [==============================] - 0s 605us/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n32/32 [==============================] - 0s 810us/step\n\nTesting for epoch 6 index 2:\n32/32 [==============================] - 0s 613us/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n32/32 [==============================] - 0s 610us/step\n\nTesting for epoch 7 index 2:\n32/32 [==============================] - 0s 624us/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n32/32 [==============================] - 0s 597us/step\n\nTesting for epoch 8 index 2:\n32/32 [==============================] - 0s 833us/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n32/32 [==============================] - 0s 615us/step\n\nTesting for epoch 9 index 2:\n32/32 [==============================] - 0s 600us/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n32/32 [==============================] - 0s 614us/step\n\nTesting for epoch 10 index 2:\n32/32 [==============================] - 0s 635us/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n32/32 [==============================] - 0s 619us/step\n\nTesting for epoch 11 index 2:\n32/32 [==============================] - 0s 610us/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n32/32 [==============================] - 0s 610us/step\n\nTesting for epoch 12 index 2:\n32/32 [==============================] - 0s 613us/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n32/32 [==============================] - 0s 616us/step\n\nTesting for epoch 13 index 2:\n32/32 [==============================] - 0s 627us/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n32/32 [==============================] - 0s 621us/step\n\nTesting for epoch 14 index 2:\n32/32 [==============================] - 0s 614us/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n32/32 [==============================] - 0s 846us/step\n\nTesting for epoch 15 index 2:\n32/32 [==============================] - 0s 623us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n32/32 [==============================] - 0s 915us/step\n\nTesting for epoch 16 index 2:\n32/32 [==============================] - 0s 836us/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 17 index 2:\n32/32 [==============================] - 0s 829us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n32/32 [==============================] - 0s 860us/step\n\nTesting for epoch 18 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n32/32 [==============================] - 0s 832us/step\n\nTesting for epoch 20 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n32/32 [==============================] - 0s 870us/step\n\nTesting for epoch 21 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3802\n16/16 [==============================] - 0s 992us/step - loss: 0.7194\n16/16 [==============================] - 0s 1ms/step - loss: 0.9382\n16/16 [==============================] - 0s 2ms/step - loss: 1.1679\n16/16 [==============================] - 0s 1ms/step - loss: 1.2953\n16/16 [==============================] - 0s 982us/step - loss: 1.3707\n16/16 [==============================] - 0s 1ms/step - loss: 1.4090\n16/16 [==============================] - 0s 1ms/step - loss: 1.4370\n16/16 [==============================] - 0s 1ms/step - loss: 1.4481\n16/16 [==============================] - 0s 1ms/step - loss: 1.4524\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3784\n16/16 [==============================] - 0s 3ms/step - loss: 0.7280\n16/16 [==============================] - 0s 1ms/step - loss: 0.9713\n16/16 [==============================] - 0s 2ms/step - loss: 1.2091\n16/16 [==============================] - 0s 1ms/step - loss: 1.3341\n16/16 [==============================] - 0s 2ms/step - loss: 1.4019\n16/16 [==============================] - 0s 2ms/step - loss: 1.4333\n16/16 [==============================] - 0s 1ms/step - loss: 1.4551\n16/16 [==============================] - 0s 1ms/step - loss: 1.4629\n16/16 [==============================] - 0s 1ms/step - loss: 1.4656\n\nTesting for epoch 22 index 2:\n32/32 [==============================] - 0s 913us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3866\n16/16 [==============================] - 0s 1ms/step - loss: 0.7327\n16/16 [==============================] - 0s 2ms/step - loss: 0.9839\n16/16 [==============================] - 0s 5ms/step - loss: 1.2335\n16/16 [==============================] - 0s 1ms/step - loss: 1.3481\n16/16 [==============================] - 0s 3ms/step - loss: 1.4093\n16/16 [==============================] - 0s 1ms/step - loss: 1.4348\n16/16 [==============================] - 0s 2ms/step - loss: 1.4506\n16/16 [==============================] - 0s 1ms/step - loss: 1.4559\n16/16 [==============================] - 0s 2ms/step - loss: 1.4576\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.3956\n16/16 [==============================] - 0s 1ms/step - loss: 0.7406\n16/16 [==============================] - 0s 1ms/step - loss: 0.9936\n16/16 [==============================] - 0s 2ms/step - loss: 1.2356\n16/16 [==============================] - 0s 2ms/step - loss: 1.3418\n16/16 [==============================] - 0s 1ms/step - loss: 1.3928\n16/16 [==============================] - 0s 2ms/step - loss: 1.4131\n16/16 [==============================] - 0s 1ms/step - loss: 1.4239\n16/16 [==============================] - 0s 1ms/step - loss: 1.4275\n16/16 [==============================] - 0s 1ms/step - loss: 1.4283\n\nTesting for epoch 23 index 2:\n32/32 [==============================] - 0s 5ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3925\n16/16 [==============================] - 0s 1ms/step - loss: 0.7523\n16/16 [==============================] - 0s 1ms/step - loss: 1.0367\n16/16 [==============================] - 0s 1ms/step - loss: 1.2950\n16/16 [==============================] - 0s 2ms/step - loss: 1.3968\n16/16 [==============================] - 0s 2ms/step - loss: 1.4439\n16/16 [==============================] - 0s 2ms/step - loss: 1.4623\n16/16 [==============================] - 0s 1ms/step - loss: 1.4710\n16/16 [==============================] - 0s 2ms/step - loss: 1.4735\n16/16 [==============================] - 0s 2ms/step - loss: 1.4740\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4051\n16/16 [==============================] - 0s 2ms/step - loss: 0.7528\n16/16 [==============================] - 0s 2ms/step - loss: 1.0473\n16/16 [==============================] - 0s 1ms/step - loss: 1.2922\n16/16 [==============================] - 0s 1ms/step - loss: 1.3798\n16/16 [==============================] - 0s 2ms/step - loss: 1.4177\n16/16 [==============================] - 0s 2ms/step - loss: 1.4316\n16/16 [==============================] - 0s 2ms/step - loss: 1.4376\n16/16 [==============================] - 0s 1ms/step - loss: 1.4391\n16/16 [==============================] - 0s 2ms/step - loss: 1.4393\n\nTesting for epoch 24 index 2:\n32/32 [==============================] - 0s 897us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.4123\n16/16 [==============================] - 0s 2ms/step - loss: 0.7576\n16/16 [==============================] - 0s 2ms/step - loss: 1.0566\n16/16 [==============================] - 0s 2ms/step - loss: 1.2987\n16/16 [==============================] - 0s 2ms/step - loss: 1.3765\n16/16 [==============================] - 0s 4ms/step - loss: 1.4095\n16/16 [==============================] - 0s 2ms/step - loss: 1.4206\n16/16 [==============================] - 0s 2ms/step - loss: 1.4250\n16/16 [==============================] - 0s 2ms/step - loss: 1.4259\n16/16 [==============================] - 0s 1ms/step - loss: 1.4259\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4149\n16/16 [==============================] - 0s 2ms/step - loss: 0.7675\n16/16 [==============================] - 0s 1ms/step - loss: 1.0765\n16/16 [==============================] - 0s 2ms/step - loss: 1.3167\n16/16 [==============================] - 0s 1ms/step - loss: 1.3880\n16/16 [==============================] - 0s 1ms/step - loss: 1.4164\n16/16 [==============================] - 0s 2ms/step - loss: 1.4257\n16/16 [==============================] - 0s 1ms/step - loss: 1.4288\n16/16 [==============================] - 0s 1ms/step - loss: 1.4294\n16/16 [==============================] - 0s 1ms/step - loss: 1.4293\n\nTesting for epoch 25 index 2:\n32/32 [==============================] - 0s 899us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4172\n16/16 [==============================] - 0s 1ms/step - loss: 0.7677\n16/16 [==============================] - 0s 1ms/step - loss: 1.0818\n16/16 [==============================] - 0s 1ms/step - loss: 1.3143\n16/16 [==============================] - 0s 1ms/step - loss: 1.3797\n16/16 [==============================] - 0s 1ms/step - loss: 1.4048\n16/16 [==============================] - 0s 1ms/step - loss: 1.4123\n16/16 [==============================] - 0s 1ms/step - loss: 1.4147\n16/16 [==============================] - 0s 2ms/step - loss: 1.4150\n16/16 [==============================] - 0s 2ms/step - loss: 1.4148\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n32/32 [==============================] - 0s 754us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4148\n16/16 [==============================] - 0s 2ms/step - loss: 0.7766\n16/16 [==============================] - 0s 4ms/step - loss: 1.1064\n16/16 [==============================] - 0s 2ms/step - loss: 1.3376\n16/16 [==============================] - 0s 1ms/step - loss: 1.4002\n16/16 [==============================] - 0s 1ms/step - loss: 1.4228\n16/16 [==============================] - 0s 1ms/step - loss: 1.4290\n16/16 [==============================] - 0s 1ms/step - loss: 1.4308\n16/16 [==============================] - 0s 1ms/step - loss: 1.4309\n16/16 [==============================] - 0s 1ms/step - loss: 1.4307\n\nTesting for epoch 26 index 2:\n32/32 [==============================] - 0s 842us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4190\n16/16 [==============================] - 0s 1ms/step - loss: 0.7761\n16/16 [==============================] - 0s 2ms/step - loss: 1.1055\n16/16 [==============================] - 0s 1ms/step - loss: 1.3282\n16/16 [==============================] - 0s 2ms/step - loss: 1.3846\n16/16 [==============================] - 0s 1ms/step - loss: 1.4044\n16/16 [==============================] - 0s 2ms/step - loss: 1.4095\n16/16 [==============================] - 0s 1ms/step - loss: 1.4108\n16/16 [==============================] - 0s 2ms/step - loss: 1.4108\n16/16 [==============================] - 0s 2ms/step - loss: 1.4105\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4225\n16/16 [==============================] - 0s 1ms/step - loss: 0.7746\n16/16 [==============================] - 0s 1ms/step - loss: 1.1026\n16/16 [==============================] - 0s 1ms/step - loss: 1.3159\n16/16 [==============================] - 0s 1ms/step - loss: 1.3665\n16/16 [==============================] - 0s 2ms/step - loss: 1.3838\n16/16 [==============================] - 0s 972us/step - loss: 1.3880\n16/16 [==============================] - 0s 1ms/step - loss: 1.3888\n16/16 [==============================] - 0s 1ms/step - loss: 1.3887\n16/16 [==============================] - 0s 2ms/step - loss: 1.3884\n\nTesting for epoch 27 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4196\n16/16 [==============================] - 0s 1ms/step - loss: 0.7825\n16/16 [==============================] - 0s 2ms/step - loss: 1.1245\n16/16 [==============================] - 0s 1ms/step - loss: 1.3411\n16/16 [==============================] - 0s 2ms/step - loss: 1.3905\n16/16 [==============================] - 0s 1ms/step - loss: 1.4071\n16/16 [==============================] - 0s 2ms/step - loss: 1.4109\n16/16 [==============================] - 0s 2ms/step - loss: 1.4116\n16/16 [==============================] - 0s 1ms/step - loss: 1.4115\n16/16 [==============================] - 0s 3ms/step - loss: 1.4112\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4124\n16/16 [==============================] - 0s 2ms/step - loss: 0.7896\n16/16 [==============================] - 0s 2ms/step - loss: 1.1481\n16/16 [==============================] - 0s 2ms/step - loss: 1.3684\n16/16 [==============================] - 0s 2ms/step - loss: 1.4180\n16/16 [==============================] - 0s 2ms/step - loss: 1.4340\n16/16 [==============================] - 0s 2ms/step - loss: 1.4374\n16/16 [==============================] - 0s 1ms/step - loss: 1.4380\n16/16 [==============================] - 0s 1ms/step - loss: 1.4378\n16/16 [==============================] - 0s 1ms/step - loss: 1.4375\n\nTesting for epoch 28 index 2:\n32/32 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4173\n16/16 [==============================] - 0s 2ms/step - loss: 0.7865\n16/16 [==============================] - 0s 2ms/step - loss: 1.1353\n16/16 [==============================] - 0s 1ms/step - loss: 1.3465\n16/16 [==============================] - 0s 1ms/step - loss: 1.3927\n16/16 [==============================] - 0s 1ms/step - loss: 1.4072\n16/16 [==============================] - 0s 2ms/step - loss: 1.4101\n16/16 [==============================] - 0s 1ms/step - loss: 1.4105\n16/16 [==============================] - 0s 1ms/step - loss: 1.4102\n16/16 [==============================] - 0s 1ms/step - loss: 1.4099\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n32/32 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4145\n16/16 [==============================] - 0s 1ms/step - loss: 0.7933\n16/16 [==============================] - 0s 1ms/step - loss: 1.1517\n16/16 [==============================] - 0s 1ms/step - loss: 1.3656\n16/16 [==============================] - 0s 5ms/step - loss: 1.4111\n16/16 [==============================] - 0s 4ms/step - loss: 1.4251\n16/16 [==============================] - 0s 4ms/step - loss: 1.4278\n16/16 [==============================] - 0s 2ms/step - loss: 1.4281\n16/16 [==============================] - 0s 2ms/step - loss: 1.4278\n16/16 [==============================] - 0s 2ms/step - loss: 1.4275\n\nTesting for epoch 29 index 2:\n32/32 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4111\n16/16 [==============================] - 0s 1ms/step - loss: 0.7909\n16/16 [==============================] - 0s 1ms/step - loss: 1.1516\n16/16 [==============================] - 0s 2ms/step - loss: 1.3647\n16/16 [==============================] - 0s 1ms/step - loss: 1.4090\n16/16 [==============================] - 0s 1ms/step - loss: 1.4224\n16/16 [==============================] - 0s 2ms/step - loss: 1.4249\n16/16 [==============================] - 0s 2ms/step - loss: 1.4250\n16/16 [==============================] - 0s 2ms/step - loss: 1.4247\n16/16 [==============================] - 0s 2ms/step - loss: 1.4244\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n32/32 [==============================] - 0s 869us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4107\n16/16 [==============================] - 0s 1ms/step - loss: 0.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.1611\n16/16 [==============================] - 0s 2ms/step - loss: 1.3750\n16/16 [==============================] - 0s 994us/step - loss: 1.4188\n16/16 [==============================] - 0s 903us/step - loss: 1.4319\n16/16 [==============================] - 0s 916us/step - loss: 1.4343\n16/16 [==============================] - 0s 997us/step - loss: 1.4344\n16/16 [==============================] - 0s 4ms/step - loss: 1.4341\n16/16 [==============================] - 0s 1ms/step - loss: 1.4338\n\nTesting for epoch 30 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4054\n16/16 [==============================] - 0s 4ms/step - loss: 0.7927\n16/16 [==============================] - 0s 3ms/step - loss: 1.1646\n16/16 [==============================] - 0s 2ms/step - loss: 1.3805\n16/16 [==============================] - 0s 4ms/step - loss: 1.4241\n16/16 [==============================] - 0s 2ms/step - loss: 1.4369\n16/16 [==============================] - 0s 2ms/step - loss: 1.4391\n16/16 [==============================] - 0s 1ms/step - loss: 1.4391\n16/16 [==============================] - 0s 1ms/step - loss: 1.4388\n16/16 [==============================] - 0s 1ms/step - loss: 1.4384\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3962\n16/16 [==============================] - 0s 2ms/step - loss: 0.7984\n16/16 [==============================] - 0s 1ms/step - loss: 1.1888\n16/16 [==============================] - 0s 5ms/step - loss: 1.4144\n16/16 [==============================] - 0s 3ms/step - loss: 1.4594\n16/16 [==============================] - 0s 2ms/step - loss: 1.4726\n16/16 [==============================] - 0s 4ms/step - loss: 1.4748\n16/16 [==============================] - 0s 2ms/step - loss: 1.4749\n16/16 [==============================] - 0s 1ms/step - loss: 1.4745\n16/16 [==============================] - 0s 1ms/step - loss: 1.4742\n\nTesting for epoch 31 index 2:\n32/32 [==============================] - 0s 898us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3984\n16/16 [==============================] - 0s 1ms/step - loss: 0.7936\n16/16 [==============================] - 0s 1ms/step - loss: 1.1789\n16/16 [==============================] - 0s 3ms/step - loss: 1.4023\n16/16 [==============================] - 0s 2ms/step - loss: 1.4465\n16/16 [==============================] - 0s 1ms/step - loss: 1.4593\n16/16 [==============================] - 0s 954us/step - loss: 1.4615\n16/16 [==============================] - 0s 1ms/step - loss: 1.4616\n16/16 [==============================] - 0s 998us/step - loss: 1.4612\n16/16 [==============================] - 0s 2ms/step - loss: 1.4608\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3891\n16/16 [==============================] - 0s 1ms/step - loss: 0.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.1911\n16/16 [==============================] - 0s 1ms/step - loss: 1.4219\n16/16 [==============================] - 0s 3ms/step - loss: 1.4666\n16/16 [==============================] - 0s 2ms/step - loss: 1.4796\n16/16 [==============================] - 0s 2ms/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.4815\n16/16 [==============================] - 0s 1ms/step - loss: 1.4811\n\nTesting for epoch 32 index 2:\n32/32 [==============================] - 0s 913us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.3883\n16/16 [==============================] - 0s 3ms/step - loss: 0.7919\n16/16 [==============================] - 0s 2ms/step - loss: 1.1930\n16/16 [==============================] - 0s 1ms/step - loss: 1.4285\n16/16 [==============================] - 0s 2ms/step - loss: 1.4721\n16/16 [==============================] - 0s 1ms/step - loss: 1.4852\n16/16 [==============================] - 0s 2ms/step - loss: 1.4875\n16/16 [==============================] - 0s 1ms/step - loss: 1.4875\n16/16 [==============================] - 0s 1ms/step - loss: 1.4871\n16/16 [==============================] - 0s 3ms/step - loss: 1.4867\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3772\n16/16 [==============================] - 0s 1ms/step - loss: 0.7929\n16/16 [==============================] - 0s 2ms/step - loss: 1.2122\n16/16 [==============================] - 0s 1ms/step - loss: 1.4584\n16/16 [==============================] - 0s 3ms/step - loss: 1.5041\n16/16 [==============================] - 0s 3ms/step - loss: 1.5178\n16/16 [==============================] - 0s 1ms/step - loss: 1.5201\n16/16 [==============================] - 0s 1ms/step - loss: 1.5202\n16/16 [==============================] - 0s 1ms/step - loss: 1.5198\n16/16 [==============================] - 0s 973us/step - loss: 1.5194\n\nTesting for epoch 33 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3685\n16/16 [==============================] - 0s 2ms/step - loss: 0.7940\n16/16 [==============================] - 0s 1ms/step - loss: 1.2262\n16/16 [==============================] - 0s 2ms/step - loss: 1.4829\n16/16 [==============================] - 0s 2ms/step - loss: 1.5311\n16/16 [==============================] - 0s 1ms/step - loss: 1.5455\n16/16 [==============================] - 0s 2ms/step - loss: 1.5481\n16/16 [==============================] - 0s 4ms/step - loss: 1.5482\n16/16 [==============================] - 0s 2ms/step - loss: 1.5478\n16/16 [==============================] - 0s 3ms/step - loss: 1.5474\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.3693\n16/16 [==============================] - 0s 1ms/step - loss: 0.7909\n16/16 [==============================] - 0s 1ms/step - loss: 1.2196\n16/16 [==============================] - 0s 1ms/step - loss: 1.4752\n16/16 [==============================] - 0s 2ms/step - loss: 1.5233\n16/16 [==============================] - 0s 2ms/step - loss: 1.5375\n16/16 [==============================] - 0s 1ms/step - loss: 1.5400\n16/16 [==============================] - 0s 1ms/step - loss: 1.5400\n16/16 [==============================] - 0s 2ms/step - loss: 1.5396\n16/16 [==============================] - 0s 3ms/step - loss: 1.5392\n\nTesting for epoch 34 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3592\n16/16 [==============================] - 0s 1ms/step - loss: 0.7936\n16/16 [==============================] - 0s 2ms/step - loss: 1.2413\n16/16 [==============================] - 0s 2ms/step - loss: 1.5117\n16/16 [==============================] - 0s 2ms/step - loss: 1.5633\n16/16 [==============================] - 0s 2ms/step - loss: 1.5786\n16/16 [==============================] - 0s 4ms/step - loss: 1.5814\n16/16 [==============================] - 0s 2ms/step - loss: 1.5816\n16/16 [==============================] - 0s 2ms/step - loss: 1.5812\n16/16 [==============================] - 0s 1ms/step - loss: 1.5808\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n32/32 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 923us/step - loss: 0.3582\n16/16 [==============================] - 0s 1ms/step - loss: 0.7895\n16/16 [==============================] - 0s 1ms/step - loss: 1.2360\n16/16 [==============================] - 0s 1ms/step - loss: 1.5072\n16/16 [==============================] - 0s 952us/step - loss: 1.5584\n16/16 [==============================] - 0s 2ms/step - loss: 1.5735\n16/16 [==============================] - 0s 2ms/step - loss: 1.5763\n16/16 [==============================] - 0s 1ms/step - loss: 1.5764\n16/16 [==============================] - 0s 2ms/step - loss: 1.5760\n16/16 [==============================] - 0s 1ms/step - loss: 1.5756\n\nTesting for epoch 35 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3488\n16/16 [==============================] - 0s 2ms/step - loss: 0.7942\n16/16 [==============================] - 0s 1ms/step - loss: 1.2601\n16/16 [==============================] - 0s 1ms/step - loss: 1.5469\n16/16 [==============================] - 0s 1ms/step - loss: 1.6015\n16/16 [==============================] - 0s 1ms/step - loss: 1.6177\n16/16 [==============================] - 0s 1ms/step - loss: 1.6207\n16/16 [==============================] - 0s 2ms/step - loss: 1.6210\n16/16 [==============================] - 0s 2ms/step - loss: 1.6206\n16/16 [==============================] - 0s 1ms/step - loss: 1.6202\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n32/32 [==============================] - 0s 829us/step\n16/16 [==============================] - 0s 980us/step - loss: 0.3512\n16/16 [==============================] - 0s 943us/step - loss: 0.7854\n16/16 [==============================] - 0s 842us/step - loss: 1.2413\n16/16 [==============================] - 0s 816us/step - loss: 1.5228\n16/16 [==============================] - 0s 1ms/step - loss: 1.5761\n16/16 [==============================] - 0s 829us/step - loss: 1.5918\n16/16 [==============================] - 0s 819us/step - loss: 1.5947\n16/16 [==============================] - 0s 801us/step - loss: 1.5949\n16/16 [==============================] - 0s 852us/step - loss: 1.5945\n16/16 [==============================] - 0s 874us/step - loss: 1.5940\n\nTesting for epoch 36 index 2:\n32/32 [==============================] - 0s 637us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.3437\n16/16 [==============================] - 0s 798us/step - loss: 0.7857\n16/16 [==============================] - 0s 793us/step - loss: 1.2551\n16/16 [==============================] - 0s 784us/step - loss: 1.5475\n16/16 [==============================] - 0s 778us/step - loss: 1.6036\n16/16 [==============================] - 0s 789us/step - loss: 1.6201\n16/16 [==============================] - 0s 800us/step - loss: 1.6232\n16/16 [==============================] - 0s 786us/step - loss: 1.6234\n16/16 [==============================] - 0s 804us/step - loss: 1.6230\n16/16 [==============================] - 0s 771us/step - loss: 1.6226\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n32/32 [==============================] - 0s 837us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.3392\n16/16 [==============================] - 0s 772us/step - loss: 0.7786\n16/16 [==============================] - 0s 1ms/step - loss: 1.2518\n16/16 [==============================] - 0s 1ms/step - loss: 1.5415\n16/16 [==============================] - 0s 1ms/step - loss: 1.5975\n16/16 [==============================] - 0s 1ms/step - loss: 1.6140\n16/16 [==============================] - 0s 836us/step - loss: 1.6171\n16/16 [==============================] - 0s 781us/step - loss: 1.6173\n16/16 [==============================] - 0s 805us/step - loss: 1.6169\n16/16 [==============================] - 0s 802us/step - loss: 1.6165\n\nTesting for epoch 37 index 2:\n32/32 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.3362\n16/16 [==============================] - 0s 795us/step - loss: 0.7794\n16/16 [==============================] - 0s 806us/step - loss: 1.2570\n16/16 [==============================] - 0s 780us/step - loss: 1.5521\n16/16 [==============================] - 0s 821us/step - loss: 1.6094\n16/16 [==============================] - 0s 778us/step - loss: 1.6265\n16/16 [==============================] - 0s 835us/step - loss: 1.6298\n16/16 [==============================] - 0s 774us/step - loss: 1.6300\n16/16 [==============================] - 0s 773us/step - loss: 1.6296\n16/16 [==============================] - 0s 782us/step - loss: 1.6291\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n32/32 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.3350\n16/16 [==============================] - 0s 780us/step - loss: 0.7829\n16/16 [==============================] - 0s 807us/step - loss: 1.2628\n16/16 [==============================] - 0s 798us/step - loss: 1.5617\n16/16 [==============================] - 0s 790us/step - loss: 1.6196\n16/16 [==============================] - 0s 810us/step - loss: 1.6369\n16/16 [==============================] - 0s 814us/step - loss: 1.6402\n16/16 [==============================] - 0s 784us/step - loss: 1.6404\n16/16 [==============================] - 0s 812us/step - loss: 1.6400\n16/16 [==============================] - 0s 808us/step - loss: 1.6395\n\nTesting for epoch 38 index 2:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 854us/step - loss: 0.3207\n16/16 [==============================] - 0s 771us/step - loss: 0.7883\n16/16 [==============================] - 0s 791us/step - loss: 1.2870\n16/16 [==============================] - 0s 762us/step - loss: 1.6028\n16/16 [==============================] - 0s 770us/step - loss: 1.6645\n16/16 [==============================] - 0s 770us/step - loss: 1.6830\n16/16 [==============================] - 0s 792us/step - loss: 1.6866\n16/16 [==============================] - 0s 788us/step - loss: 1.6869\n16/16 [==============================] - 0s 827us/step - loss: 1.6865\n16/16 [==============================] - 0s 758us/step - loss: 1.6861\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 807us/step - loss: 0.3234\n16/16 [==============================] - 0s 771us/step - loss: 0.7890\n16/16 [==============================] - 0s 777us/step - loss: 1.2822\n16/16 [==============================] - 0s 780us/step - loss: 1.5961\n16/16 [==============================] - 0s 807us/step - loss: 1.6572\n16/16 [==============================] - 0s 795us/step - loss: 1.6753\n16/16 [==============================] - 0s 803us/step - loss: 1.6788\n16/16 [==============================] - 0s 1ms/step - loss: 1.6791\n16/16 [==============================] - 0s 682us/step - loss: 1.6786\n16/16 [==============================] - 0s 750us/step - loss: 1.6782\n\nTesting for epoch 39 index 2:\n32/32 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 660us/step - loss: 0.3169\n16/16 [==============================] - 0s 1ms/step - loss: 0.7846\n16/16 [==============================] - 0s 664us/step - loss: 1.2831\n16/16 [==============================] - 0s 655us/step - loss: 1.6025\n16/16 [==============================] - 0s 771us/step - loss: 1.6649\n16/16 [==============================] - 0s 675us/step - loss: 1.6836\n16/16 [==============================] - 0s 677us/step - loss: 1.6870\n16/16 [==============================] - 0s 815us/step - loss: 1.6873\n16/16 [==============================] - 0s 791us/step - loss: 1.6868\n16/16 [==============================] - 0s 785us/step - loss: 1.6863\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.3223\n16/16 [==============================] - 0s 769us/step - loss: 0.7759\n16/16 [==============================] - 0s 774us/step - loss: 1.2607\n16/16 [==============================] - 0s 769us/step - loss: 1.5701\n16/16 [==============================] - 0s 806us/step - loss: 1.6300\n16/16 [==============================] - 0s 781us/step - loss: 1.6478\n16/16 [==============================] - 0s 791us/step - loss: 1.6509\n16/16 [==============================] - 0s 779us/step - loss: 1.6511\n16/16 [==============================] - 0s 1ms/step - loss: 1.6506\n16/16 [==============================] - 0s 779us/step - loss: 1.6501\n\nTesting for epoch 40 index 2:\n32/32 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.3189\n16/16 [==============================] - 0s 824us/step - loss: 0.7810\n16/16 [==============================] - 0s 808us/step - loss: 1.2802\n16/16 [==============================] - 0s 809us/step - loss: 1.6001\n16/16 [==============================] - 0s 777us/step - loss: 1.6622\n16/16 [==============================] - 0s 785us/step - loss: 1.6807\n16/16 [==============================] - 0s 780us/step - loss: 1.6840\n16/16 [==============================] - 0s 805us/step - loss: 1.6842\n16/16 [==============================] - 0s 783us/step - loss: 1.6838\n16/16 [==============================] - 0s 818us/step - loss: 1.6833\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n32/32 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.3072\n16/16 [==============================] - 0s 828us/step - loss: 0.7912\n16/16 [==============================] - 0s 783us/step - loss: 1.3176\n16/16 [==============================] - 0s 819us/step - loss: 1.6547\n16/16 [==============================] - 0s 783us/step - loss: 1.7199\n16/16 [==============================] - 0s 810us/step - loss: 1.7392\n16/16 [==============================] - 0s 818us/step - loss: 1.7426\n16/16 [==============================] - 0s 773us/step - loss: 1.7428\n16/16 [==============================] - 0s 769us/step - loss: 1.7424\n16/16 [==============================] - 0s 772us/step - loss: 1.7419\n\nTesting for epoch 41 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.3088\n16/16 [==============================] - 0s 818us/step - loss: 0.7812\n16/16 [==============================] - 0s 804us/step - loss: 1.2987\n16/16 [==============================] - 0s 774us/step - loss: 1.6308\n16/16 [==============================] - 0s 770us/step - loss: 1.6949\n16/16 [==============================] - 0s 772us/step - loss: 1.7138\n16/16 [==============================] - 0s 803us/step - loss: 1.7172\n16/16 [==============================] - 0s 773us/step - loss: 1.7174\n16/16 [==============================] - 0s 789us/step - loss: 1.7170\n16/16 [==============================] - 0s 771us/step - loss: 1.7165\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n32/32 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.3021\n16/16 [==============================] - 0s 792us/step - loss: 0.7873\n16/16 [==============================] - 0s 673us/step - loss: 1.3203\n16/16 [==============================] - 0s 786us/step - loss: 1.6612\n16/16 [==============================] - 0s 2ms/step - loss: 1.7264\n16/16 [==============================] - 0s 2ms/step - loss: 1.7454\n16/16 [==============================] - 0s 2ms/step - loss: 1.7487\n16/16 [==============================] - 0s 767us/step - loss: 1.7489\n16/16 [==============================] - 0s 2ms/step - loss: 1.7484\n16/16 [==============================] - 0s 844us/step - loss: 1.7479\n\nTesting for epoch 42 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2994\n16/16 [==============================] - 0s 655us/step - loss: 0.7933\n16/16 [==============================] - 0s 1ms/step - loss: 1.3330\n16/16 [==============================] - 0s 818us/step - loss: 1.6811\n16/16 [==============================] - 0s 1ms/step - loss: 1.7477\n16/16 [==============================] - 0s 806us/step - loss: 1.7671\n16/16 [==============================] - 0s 825us/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.7707\n16/16 [==============================] - 0s 1ms/step - loss: 1.7702\n16/16 [==============================] - 0s 2ms/step - loss: 1.7697\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3054\n16/16 [==============================] - 0s 2ms/step - loss: 0.7894\n16/16 [==============================] - 0s 2ms/step - loss: 1.3140\n16/16 [==============================] - 0s 799us/step - loss: 1.6513\n16/16 [==============================] - 0s 1ms/step - loss: 1.7147\n16/16 [==============================] - 0s 894us/step - loss: 1.7329\n16/16 [==============================] - 0s 2ms/step - loss: 1.7359\n16/16 [==============================] - 0s 896us/step - loss: 1.7360\n16/16 [==============================] - 0s 1ms/step - loss: 1.7355\n16/16 [==============================] - 0s 2ms/step - loss: 1.7350\n\nTesting for epoch 43 index 2:\n32/32 [==============================] - 0s 551us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2985\n16/16 [==============================] - 0s 2ms/step - loss: 0.7894\n16/16 [==============================] - 0s 2ms/step - loss: 1.3189\n16/16 [==============================] - 0s 2ms/step - loss: 1.6614\n16/16 [==============================] - 0s 803us/step - loss: 1.7256\n16/16 [==============================] - 0s 2ms/step - loss: 1.7439\n16/16 [==============================] - 0s 2ms/step - loss: 1.7470\n16/16 [==============================] - 0s 2ms/step - loss: 1.7471\n16/16 [==============================] - 0s 2ms/step - loss: 1.7465\n16/16 [==============================] - 0s 2ms/step - loss: 1.7460\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2929\n16/16 [==============================] - 0s 773us/step - loss: 0.7969\n16/16 [==============================] - 0s 1ms/step - loss: 1.3407\n16/16 [==============================] - 0s 2ms/step - loss: 1.6916\n16/16 [==============================] - 0s 2ms/step - loss: 1.7567\n16/16 [==============================] - 0s 819us/step - loss: 1.7749\n16/16 [==============================] - 0s 2ms/step - loss: 1.7779\n16/16 [==============================] - 0s 2ms/step - loss: 1.7780\n16/16 [==============================] - 0s 2ms/step - loss: 1.7775\n16/16 [==============================] - 0s 2ms/step - loss: 1.7769\n\nTesting for epoch 44 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 796us/step - loss: 0.2909\n16/16 [==============================] - 0s 772us/step - loss: 0.7933\n16/16 [==============================] - 0s 823us/step - loss: 1.3388\n16/16 [==============================] - 0s 2ms/step - loss: 1.6890\n16/16 [==============================] - 0s 951us/step - loss: 1.7538\n16/16 [==============================] - 0s 831us/step - loss: 1.7717\n16/16 [==============================] - 0s 1ms/step - loss: 1.7746\n16/16 [==============================] - 0s 2ms/step - loss: 1.7747\n16/16 [==============================] - 0s 796us/step - loss: 1.7741\n16/16 [==============================] - 0s 2ms/step - loss: 1.7736\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 791us/step - loss: 0.2946\n16/16 [==============================] - 0s 786us/step - loss: 0.7951\n16/16 [==============================] - 0s 823us/step - loss: 1.3410\n16/16 [==============================] - 0s 1ms/step - loss: 1.6875\n16/16 [==============================] - 0s 1ms/step - loss: 1.7506\n16/16 [==============================] - 0s 812us/step - loss: 1.7678\n16/16 [==============================] - 0s 1ms/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.7705\n16/16 [==============================] - 0s 1ms/step - loss: 1.7700\n16/16 [==============================] - 0s 2ms/step - loss: 1.7694\n\nTesting for epoch 45 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2911\n16/16 [==============================] - 0s 789us/step - loss: 0.7943\n16/16 [==============================] - 0s 817us/step - loss: 1.3485\n16/16 [==============================] - 0s 2ms/step - loss: 1.6968\n16/16 [==============================] - 0s 934us/step - loss: 1.7600\n16/16 [==============================] - 0s 2ms/step - loss: 1.7771\n16/16 [==============================] - 0s 816us/step - loss: 1.7797\n16/16 [==============================] - 0s 807us/step - loss: 1.7796\n16/16 [==============================] - 0s 820us/step - loss: 1.7791\n16/16 [==============================] - 0s 932us/step - loss: 1.7785\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 804us/step - loss: 0.2932\n16/16 [==============================] - 0s 2ms/step - loss: 0.7938\n16/16 [==============================] - 0s 2ms/step - loss: 1.3487\n16/16 [==============================] - 0s 942us/step - loss: 1.6919\n16/16 [==============================] - 0s 984us/step - loss: 1.7534\n16/16 [==============================] - 0s 828us/step - loss: 1.7699\n16/16 [==============================] - 0s 2ms/step - loss: 1.7723\n16/16 [==============================] - 0s 839us/step - loss: 1.7722\n16/16 [==============================] - 0s 801us/step - loss: 1.7717\n16/16 [==============================] - 0s 796us/step - loss: 1.7711\n\nTesting for epoch 46 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 805us/step - loss: 0.2842\n16/16 [==============================] - 0s 2ms/step - loss: 0.8012\n16/16 [==============================] - 0s 2ms/step - loss: 1.3785\n16/16 [==============================] - 0s 809us/step - loss: 1.7329\n16/16 [==============================] - 0s 853us/step - loss: 1.7961\n16/16 [==============================] - 0s 2ms/step - loss: 1.8129\n16/16 [==============================] - 0s 812us/step - loss: 1.8153\n16/16 [==============================] - 0s 1ms/step - loss: 1.8152\n16/16 [==============================] - 0s 760us/step - loss: 1.8146\n16/16 [==============================] - 0s 794us/step - loss: 1.8141\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 831us/step - loss: 0.2767\n16/16 [==============================] - 0s 805us/step - loss: 0.8072\n16/16 [==============================] - 0s 1ms/step - loss: 1.4037\n16/16 [==============================] - 0s 869us/step - loss: 1.7654\n16/16 [==============================] - 0s 843us/step - loss: 1.8289\n16/16 [==============================] - 0s 814us/step - loss: 1.8455\n16/16 [==============================] - 0s 837us/step - loss: 1.8479\n16/16 [==============================] - 0s 827us/step - loss: 1.8477\n16/16 [==============================] - 0s 2ms/step - loss: 1.8471\n16/16 [==============================] - 0s 2ms/step - loss: 1.8466\n\nTesting for epoch 47 index 2:\n32/32 [==============================] - 0s 582us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2830\n16/16 [==============================] - 0s 2ms/step - loss: 0.8001\n16/16 [==============================] - 0s 2ms/step - loss: 1.3796\n16/16 [==============================] - 0s 799us/step - loss: 1.7297\n16/16 [==============================] - 0s 822us/step - loss: 1.7904\n16/16 [==============================] - 0s 2ms/step - loss: 1.8061\n16/16 [==============================] - 0s 830us/step - loss: 1.8082\n16/16 [==============================] - 0s 2ms/step - loss: 1.8080\n16/16 [==============================] - 0s 805us/step - loss: 1.8074\n16/16 [==============================] - 0s 842us/step - loss: 1.8069\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n32/32 [==============================] - 0s 671us/step\n16/16 [==============================] - 0s 763us/step - loss: 0.2810\n16/16 [==============================] - 0s 786us/step - loss: 0.8040\n16/16 [==============================] - 0s 770us/step - loss: 1.3884\n16/16 [==============================] - 0s 764us/step - loss: 1.7378\n16/16 [==============================] - 0s 757us/step - loss: 1.7973\n16/16 [==============================] - 0s 769us/step - loss: 1.8124\n16/16 [==============================] - 0s 773us/step - loss: 1.8144\n16/16 [==============================] - 0s 1ms/step - loss: 1.8141\n16/16 [==============================] - 0s 1ms/step - loss: 1.8134\n16/16 [==============================] - 0s 1ms/step - loss: 1.8129\n\nTesting for epoch 48 index 2:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2789\n16/16 [==============================] - 0s 783us/step - loss: 0.8059\n16/16 [==============================] - 0s 779us/step - loss: 1.3913\n16/16 [==============================] - 0s 762us/step - loss: 1.7401\n16/16 [==============================] - 0s 762us/step - loss: 1.7989\n16/16 [==============================] - 0s 846us/step - loss: 1.8136\n16/16 [==============================] - 0s 857us/step - loss: 1.8155\n16/16 [==============================] - 0s 839us/step - loss: 1.8151\n16/16 [==============================] - 0s 860us/step - loss: 1.8145\n16/16 [==============================] - 0s 877us/step - loss: 1.8139\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2754\n16/16 [==============================] - 0s 800us/step - loss: 0.8119\n16/16 [==============================] - 0s 791us/step - loss: 1.4077\n16/16 [==============================] - 0s 786us/step - loss: 1.7589\n16/16 [==============================] - 0s 1ms/step - loss: 1.8171\n16/16 [==============================] - 0s 801us/step - loss: 1.8315\n16/16 [==============================] - 0s 886us/step - loss: 1.8332\n16/16 [==============================] - 0s 1ms/step - loss: 1.8328\n16/16 [==============================] - 0s 875us/step - loss: 1.8322\n16/16 [==============================] - 0s 861us/step - loss: 1.8316\n\nTesting for epoch 49 index 2:\n32/32 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.2707\n16/16 [==============================] - 0s 784us/step - loss: 0.8127\n16/16 [==============================] - 0s 817us/step - loss: 1.4127\n16/16 [==============================] - 0s 815us/step - loss: 1.7644\n16/16 [==============================] - 0s 792us/step - loss: 1.8221\n16/16 [==============================] - 0s 817us/step - loss: 1.8361\n16/16 [==============================] - 0s 800us/step - loss: 1.8377\n16/16 [==============================] - 0s 800us/step - loss: 1.8373\n16/16 [==============================] - 0s 812us/step - loss: 1.8366\n16/16 [==============================] - 0s 856us/step - loss: 1.8360\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n32/32 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.2747\n16/16 [==============================] - 0s 783us/step - loss: 0.8236\n16/16 [==============================] - 0s 793us/step - loss: 1.4341\n16/16 [==============================] - 0s 1ms/step - loss: 1.7868\n16/16 [==============================] - 0s 904us/step - loss: 1.8438\n16/16 [==============================] - 0s 877us/step - loss: 1.8574\n16/16 [==============================] - 0s 811us/step - loss: 1.8589\n16/16 [==============================] - 0s 807us/step - loss: 1.8584\n16/16 [==============================] - 0s 791us/step - loss: 1.8578\n16/16 [==============================] - 0s 820us/step - loss: 1.8572\n\nTesting for epoch 50 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2854\n16/16 [==============================] - 0s 818us/step - loss: 0.8126\n16/16 [==============================] - 0s 790us/step - loss: 1.3992\n16/16 [==============================] - 0s 837us/step - loss: 1.7342\n16/16 [==============================] - 0s 789us/step - loss: 1.7876\n16/16 [==============================] - 0s 781us/step - loss: 1.8000\n16/16 [==============================] - 0s 785us/step - loss: 1.8013\n16/16 [==============================] - 0s 779us/step - loss: 1.8007\n16/16 [==============================] - 0s 781us/step - loss: 1.8000\n16/16 [==============================] - 0s 806us/step - loss: 1.7995\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n32/32 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.2657\n16/16 [==============================] - 0s 813us/step - loss: 0.8298\n16/16 [==============================] - 0s 787us/step - loss: 1.4637\n16/16 [==============================] - 0s 791us/step - loss: 1.8214\n16/16 [==============================] - 0s 790us/step - loss: 1.8778\n16/16 [==============================] - 0s 780us/step - loss: 1.8907\n16/16 [==============================] - 0s 803us/step - loss: 1.8920\n16/16 [==============================] - 0s 817us/step - loss: 1.8915\n16/16 [==============================] - 0s 779us/step - loss: 1.8908\n16/16 [==============================] - 0s 777us/step - loss: 1.8902\n\nTesting for epoch 51 index 2:\n32/32 [==============================] - 0s 594us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.2715\n16/16 [==============================] - 0s 1ms/step - loss: 0.8213\n16/16 [==============================] - 0s 1ms/step - loss: 1.4421\n16/16 [==============================] - 0s 1ms/step - loss: 1.7886\n16/16 [==============================] - 0s 1ms/step - loss: 1.8427\n16/16 [==============================] - 0s 787us/step - loss: 1.8549\n16/16 [==============================] - 0s 1ms/step - loss: 1.8561\n16/16 [==============================] - 0s 1ms/step - loss: 1.8555\n16/16 [==============================] - 0s 1ms/step - loss: 1.8549\n16/16 [==============================] - 0s 796us/step - loss: 1.8543\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.2673\n16/16 [==============================] - 0s 799us/step - loss: 0.8241\n16/16 [==============================] - 0s 780us/step - loss: 1.4541\n16/16 [==============================] - 0s 796us/step - loss: 1.8011\n16/16 [==============================] - 0s 811us/step - loss: 1.8543\n16/16 [==============================] - 0s 779us/step - loss: 1.8660\n16/16 [==============================] - 0s 791us/step - loss: 1.8671\n16/16 [==============================] - 0s 771us/step - loss: 1.8665\n16/16 [==============================] - 0s 823us/step - loss: 1.8658\n16/16 [==============================] - 0s 774us/step - loss: 1.8652\n\nTesting for epoch 52 index 2:\n32/32 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.2792\n16/16 [==============================] - 0s 780us/step - loss: 0.8209\n16/16 [==============================] - 0s 825us/step - loss: 1.4352\n16/16 [==============================] - 0s 812us/step - loss: 1.7676\n16/16 [==============================] - 0s 821us/step - loss: 1.8181\n16/16 [==============================] - 0s 814us/step - loss: 1.8289\n16/16 [==============================] - 0s 1ms/step - loss: 1.8298\n16/16 [==============================] - 0s 1ms/step - loss: 1.8291\n16/16 [==============================] - 0s 802us/step - loss: 1.8284\n16/16 [==============================] - 0s 797us/step - loss: 1.8278\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n32/32 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 859us/step - loss: 0.2657\n16/16 [==============================] - 0s 817us/step - loss: 0.8274\n16/16 [==============================] - 0s 799us/step - loss: 1.4711\n16/16 [==============================] - 0s 898us/step - loss: 1.8159\n16/16 [==============================] - 0s 791us/step - loss: 1.8675\n16/16 [==============================] - 0s 821us/step - loss: 1.8786\n16/16 [==============================] - 0s 802us/step - loss: 1.8795\n16/16 [==============================] - 0s 823us/step - loss: 1.8789\n16/16 [==============================] - 0s 779us/step - loss: 1.8782\n16/16 [==============================] - 0s 797us/step - loss: 1.8776\n\nTesting for epoch 53 index 2:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.2711\n16/16 [==============================] - 0s 779us/step - loss: 0.8247\n16/16 [==============================] - 0s 798us/step - loss: 1.4613\n16/16 [==============================] - 0s 772us/step - loss: 1.7968\n16/16 [==============================] - 0s 780us/step - loss: 1.8466\n16/16 [==============================] - 0s 797us/step - loss: 1.8571\n16/16 [==============================] - 0s 811us/step - loss: 1.8579\n16/16 [==============================] - 0s 801us/step - loss: 1.8572\n16/16 [==============================] - 0s 776us/step - loss: 1.8565\n16/16 [==============================] - 0s 774us/step - loss: 1.8559\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n32/32 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2669\n16/16 [==============================] - 0s 830us/step - loss: 0.8337\n16/16 [==============================] - 0s 782us/step - loss: 1.4889\n16/16 [==============================] - 0s 901us/step - loss: 1.8301\n16/16 [==============================] - 0s 812us/step - loss: 1.8797\n16/16 [==============================] - 0s 816us/step - loss: 1.8901\n16/16 [==============================] - 0s 775us/step - loss: 1.8908\n16/16 [==============================] - 0s 778us/step - loss: 1.8901\n16/16 [==============================] - 0s 797us/step - loss: 1.8894\n16/16 [==============================] - 0s 784us/step - loss: 1.8888\n\nTesting for epoch 54 index 2:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 811us/step - loss: 0.2687\n16/16 [==============================] - 0s 800us/step - loss: 0.8254\n16/16 [==============================] - 0s 794us/step - loss: 1.4729\n16/16 [==============================] - 0s 777us/step - loss: 1.8040\n16/16 [==============================] - 0s 775us/step - loss: 1.8518\n16/16 [==============================] - 0s 790us/step - loss: 1.8616\n16/16 [==============================] - 0s 806us/step - loss: 1.8622\n16/16 [==============================] - 0s 781us/step - loss: 1.8615\n16/16 [==============================] - 0s 804us/step - loss: 1.8608\n16/16 [==============================] - 0s 782us/step - loss: 1.8602\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n32/32 [==============================] - 0s 848us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2630\n16/16 [==============================] - 0s 1ms/step - loss: 0.8345\n16/16 [==============================] - 0s 1ms/step - loss: 1.5023\n16/16 [==============================] - 0s 1ms/step - loss: 1.8396\n16/16 [==============================] - 0s 1ms/step - loss: 1.8872\n16/16 [==============================] - 0s 769us/step - loss: 1.8970\n16/16 [==============================] - 0s 822us/step - loss: 1.8976\n16/16 [==============================] - 0s 778us/step - loss: 1.8968\n16/16 [==============================] - 0s 778us/step - loss: 1.8961\n16/16 [==============================] - 0s 804us/step - loss: 1.8955\n\nTesting for epoch 55 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.2649\n16/16 [==============================] - 0s 825us/step - loss: 0.8307\n16/16 [==============================] - 0s 785us/step - loss: 1.4969\n16/16 [==============================] - 0s 799us/step - loss: 1.8271\n16/16 [==============================] - 0s 800us/step - loss: 1.8735\n16/16 [==============================] - 0s 1ms/step - loss: 1.8829\n16/16 [==============================] - 0s 1ms/step - loss: 1.8834\n16/16 [==============================] - 0s 1ms/step - loss: 1.8826\n16/16 [==============================] - 0s 1ms/step - loss: 1.8818\n16/16 [==============================] - 0s 1ms/step - loss: 1.8813\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n32/32 [==============================] - 0s 845us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2646\n16/16 [==============================] - 0s 1ms/step - loss: 0.8302\n16/16 [==============================] - 0s 1ms/step - loss: 1.4973\n16/16 [==============================] - 0s 780us/step - loss: 1.8229\n16/16 [==============================] - 0s 773us/step - loss: 1.8679\n16/16 [==============================] - 0s 794us/step - loss: 1.8768\n16/16 [==============================] - 0s 1ms/step - loss: 1.8772\n16/16 [==============================] - 0s 1ms/step - loss: 1.8763\n16/16 [==============================] - 0s 804us/step - loss: 1.8756\n16/16 [==============================] - 0s 806us/step - loss: 1.8750\n\nTesting for epoch 56 index 2:\n32/32 [==============================] - 0s 843us/step\n16/16 [==============================] - 0s 844us/step - loss: 0.2654\n16/16 [==============================] - 0s 777us/step - loss: 0.8271\n16/16 [==============================] - 0s 797us/step - loss: 1.4953\n16/16 [==============================] - 0s 781us/step - loss: 1.8151\n16/16 [==============================] - 0s 797us/step - loss: 1.8594\n16/16 [==============================] - 0s 774us/step - loss: 1.8680\n16/16 [==============================] - 0s 811us/step - loss: 1.8683\n16/16 [==============================] - 0s 808us/step - loss: 1.8674\n16/16 [==============================] - 0s 782us/step - loss: 1.8667\n16/16 [==============================] - 0s 785us/step - loss: 1.8661\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n32/32 [==============================] - 0s 626us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.2603\n16/16 [==============================] - 0s 797us/step - loss: 0.8334\n16/16 [==============================] - 0s 781us/step - loss: 1.5190\n16/16 [==============================] - 0s 775us/step - loss: 1.8422\n16/16 [==============================] - 0s 772us/step - loss: 1.8866\n16/16 [==============================] - 0s 819us/step - loss: 1.8950\n16/16 [==============================] - 0s 814us/step - loss: 1.8952\n16/16 [==============================] - 0s 790us/step - loss: 1.8943\n16/16 [==============================] - 0s 798us/step - loss: 1.8935\n16/16 [==============================] - 0s 802us/step - loss: 1.8930\n\nTesting for epoch 57 index 2:\n32/32 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.2586\n16/16 [==============================] - 0s 775us/step - loss: 0.8385\n16/16 [==============================] - 0s 784us/step - loss: 1.5405\n16/16 [==============================] - 0s 786us/step - loss: 1.8654\n16/16 [==============================] - 0s 784us/step - loss: 1.9105\n16/16 [==============================] - 0s 787us/step - loss: 1.9188\n16/16 [==============================] - 0s 787us/step - loss: 1.9191\n16/16 [==============================] - 0s 825us/step - loss: 1.9182\n16/16 [==============================] - 0s 796us/step - loss: 1.9175\n16/16 [==============================] - 0s 790us/step - loss: 1.9169\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n32/32 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2664\n16/16 [==============================] - 0s 887us/step - loss: 0.8317\n16/16 [==============================] - 0s 789us/step - loss: 1.5162\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 807us/step - loss: 1.8701\n16/16 [==============================] - 0s 780us/step - loss: 1.8777\n16/16 [==============================] - 0s 782us/step - loss: 1.8779\n16/16 [==============================] - 0s 782us/step - loss: 1.8769\n16/16 [==============================] - 0s 778us/step - loss: 1.8762\n16/16 [==============================] - 0s 801us/step - loss: 1.8756\n\nTesting for epoch 58 index 2:\n32/32 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.2565\n16/16 [==============================] - 0s 790us/step - loss: 0.8364\n16/16 [==============================] - 0s 832us/step - loss: 1.5469\n16/16 [==============================] - 0s 782us/step - loss: 1.8653\n16/16 [==============================] - 0s 796us/step - loss: 1.9092\n16/16 [==============================] - 0s 783us/step - loss: 1.9169\n16/16 [==============================] - 0s 790us/step - loss: 1.9171\n16/16 [==============================] - 0s 785us/step - loss: 1.9162\n16/16 [==============================] - 0s 799us/step - loss: 1.9154\n16/16 [==============================] - 0s 822us/step - loss: 1.9149\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n32/32 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 843us/step - loss: 0.2551\n16/16 [==============================] - 0s 823us/step - loss: 0.8408\n16/16 [==============================] - 0s 1ms/step - loss: 1.5610\n16/16 [==============================] - 0s 804us/step - loss: 1.8795\n16/16 [==============================] - 0s 1ms/step - loss: 1.9230\n16/16 [==============================] - 0s 832us/step - loss: 1.9304\n16/16 [==============================] - 0s 1ms/step - loss: 1.9306\n16/16 [==============================] - 0s 1ms/step - loss: 1.9296\n16/16 [==============================] - 0s 875us/step - loss: 1.9289\n16/16 [==============================] - 0s 825us/step - loss: 1.9283\n\nTesting for epoch 59 index 2:\n32/32 [==============================] - 0s 794us/step\n16/16 [==============================] - 0s 827us/step - loss: 0.2557\n16/16 [==============================] - 0s 812us/step - loss: 0.8404\n16/16 [==============================] - 0s 1ms/step - loss: 1.5661\n16/16 [==============================] - 0s 1ms/step - loss: 1.8818\n16/16 [==============================] - 0s 1ms/step - loss: 1.9253\n16/16 [==============================] - 0s 1ms/step - loss: 1.9326\n16/16 [==============================] - 0s 820us/step - loss: 1.9327\n16/16 [==============================] - 0s 1ms/step - loss: 1.9318\n16/16 [==============================] - 0s 1ms/step - loss: 1.9311\n16/16 [==============================] - 0s 1ms/step - loss: 1.9305\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2626\n16/16 [==============================] - 0s 1ms/step - loss: 0.8359\n16/16 [==============================] - 0s 1ms/step - loss: 1.5479\n16/16 [==============================] - 0s 1ms/step - loss: 1.8518\n16/16 [==============================] - 0s 1ms/step - loss: 1.8930\n16/16 [==============================] - 0s 1ms/step - loss: 1.8996\n16/16 [==============================] - 0s 853us/step - loss: 1.8996\n16/16 [==============================] - 0s 825us/step - loss: 1.8986\n16/16 [==============================] - 0s 819us/step - loss: 1.8979\n16/16 [==============================] - 0s 857us/step - loss: 1.8973\n\nTesting for epoch 60 index 2:\n32/32 [==============================] - 0s 645us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.2643\n16/16 [==============================] - 0s 836us/step - loss: 0.8245\n16/16 [==============================] - 0s 851us/step - loss: 1.5218\n16/16 [==============================] - 0s 854us/step - loss: 1.8173\n16/16 [==============================] - 0s 807us/step - loss: 1.8571\n16/16 [==============================] - 0s 829us/step - loss: 1.8634\n16/16 [==============================] - 0s 803us/step - loss: 1.8633\n16/16 [==============================] - 0s 814us/step - loss: 1.8623\n16/16 [==============================] - 0s 811us/step - loss: 1.8615\n16/16 [==============================] - 0s 828us/step - loss: 1.8609\n32/32 [==============================] - 0s 634us/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.965\nRecall: 0.972\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntherteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  therteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\\(\\star\\)\ndefault=10%\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = therteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = therteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-result",
    "title": "Other Outlier Detection",
    "section": "Linear Result",
    "text": "Linear Result\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(5,7)\\) and \\(U(-7,-5)\\).\n\nfourteen\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.998\n      0.998947\n      0.998947\n      0.998947\n    \n    \n      LOF (Breunig et al., 2000)\n      0.926\n      0.961053\n      0.961053\n      0.961053\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.950\n      1.000000\n      0.947368\n      0.972973\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.935\n      0.991121\n      0.940000\n      0.964884\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.998\n      0.998947\n      0.998947\n      0.998947\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.986\n      0.992632\n      0.992632\n      0.992632\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.993684\n      0.993684\n      0.993684\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.868\n      0.998780\n      0.862105\n      0.925424\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.960\n      0.977941\n      0.980000\n      0.978970\n    \n    \n      SOS (Janssens et al., 2012)\n      0.916\n      0.955789\n      0.955789\n      0.955789\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.936\n      0.966316\n      0.966316\n      0.966316\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.940\n      0.965481\n      0.971579\n      0.968520\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.988\n      0.993684\n      0.993684\n      0.993684"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-ebayesthresh",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-ebayesthresh",
    "title": "Other Outlier Detection",
    "section": "Orbit EbayesThresh",
    "text": "Orbit EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier = which(signal!=0)\nindex_of_trueoutlier\nx=signal+epsilon\nplot(1:1000,x)\npoints(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)\n\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\n\n\n\n%R -o x\n%R -o index_of_trueoutlier\n%R -o signal\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n# plt.plot(x)\n# plt.plot(xhat)\n\n\noutlier_true_index = index_of_trueoutlier\n\n\noutlier_true_value = x[index_of_trueoutlier]\n\npackage와 비교를 위해 outlier는 -1, inlier는 1로 표시\n\noutlier_true_one = signal.copy()\n\n\noutlier_true_one = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one))\n\n\n# pd.DataFrame(outlier_true_one).to_csv('orbit_outlier.csv')"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit",
    "title": "Other Outlier Detection",
    "section": "Orbit",
    "text": "Orbit\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\n_df = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f})\n\n\nX = np.array(_df)\n\n\n# save_data(_df,'Orbit.pkl')\n\n\nGODE\n\n_Orbit = Orbit(_df)\n\n\n_Orbit.get_distance()\n\n100%|██████████| 1000/1000 [00:02<00:00, 340.03it/s]\n\n\n\n_Orbit.get_weightmatrix(theta=(_Orbit.D[_Orbit.D>0].mean()),kappa=2500) \n\n\n_Orbit.fit(sd=15,ref=20)\n\n\noutlier_simul_one = (_Orbit.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 13 else 1,outlier_simul_one))\n\n\noutlier_simul_one.count(1)\n\n950\n\n\n\noutlier_simul_one.count(-1)\n\n50\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF\\(\\star\\)\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.954\nPrecision: 0.976\nRecall: 0.976\nF1 Score: 0.976\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','f']])\n_df['knn_clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF\n\nimport pickle\n\n\n_df = load_data('Orbit.pkl')\n\n\noutlier_true_one = pd.read_csv('orbit_outlier.csv').iloc[:,1].tolist()\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\noutlier_CBLOF_one = list(clf.labels_)\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n_conf = Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n# four = three.append(_conf.tab)\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.05, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.05, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.908\nPrecision: 0.977\nRecall: 0.925\nF1 Score: 0.950\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\\(\\star\\)\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\\(\\star\\)\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.942\nPrecision: 0.969\nRecall: 0.969\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\\(\\star\\)\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\n\n\nIForest\\(\\star\\)\n\nod = IForest(\n    threshold=0.,\n    n_estimators=50\n)\n\n\nod.fit(_df[['x', 'y','f']])\n\n\npreds = od.predict(\n    _df[['x', 'y','f']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.443\nPrecision: 0.992\nRecall: 0.417\nF1 Score: 0.587\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\\(\\star\\)\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.960\nRecall: 0.973\nF1 Score: 0.966\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\\(\\star\\)\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.974\nRecall: 0.974\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\\(\\star\\)\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 969us/step - loss: 1.3463\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3506\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3586\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3721\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3866\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3800\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4006\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4023\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4122\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.4314\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4473\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.4588\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4734\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4913\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5128\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5221\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5512\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5569\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5717\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5833\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5991\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6237\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.6486\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6528\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6775\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6728\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7114\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7382\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7361\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7442\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7632\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7813\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7997\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8135\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8074\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8185\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8404\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.8432\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8590\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8644\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8872\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9012\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.9049\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9139\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9184\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.9365\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9581\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9824\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9639\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0122\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0024\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0080\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.0230\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0424\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0419\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0648\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0705\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0983\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1023\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1145\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1403\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1403\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1572\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1621\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1594\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1776\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1913\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2041\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2355\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2292\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2431\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2475\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2408\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2696\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2748\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3000\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3168\n32/32 [==============================] - 0s 2ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\\(\\star\\)\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 5 index 2:\n32/32 [==============================] - 0s 3ms/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 10 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n32/32 [==============================] - 0s 3ms/step\n\nTesting for epoch 12 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 13 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 14 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 2:\n32/32 [==============================] - 0s 992us/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 2:\n32/32 [==============================] - 0s 782us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n32/32 [==============================] - 0s 680us/step\n\nTesting for epoch 18 index 2:\n32/32 [==============================] - 0s 801us/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n32/32 [==============================] - 0s 642us/step\n\nTesting for epoch 19 index 2:\n32/32 [==============================] - 0s 617us/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n32/32 [==============================] - 0s 801us/step\n\nTesting for epoch 20 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n32/32 [==============================] - 0s 894us/step\n\nTesting for epoch 21 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4662\n16/16 [==============================] - 0s 1ms/step - loss: 1.1250\n16/16 [==============================] - 0s 1ms/step - loss: 1.1652\n16/16 [==============================] - 0s 1ms/step - loss: 1.1668\n16/16 [==============================] - 0s 997us/step - loss: 1.1673\n16/16 [==============================] - 0s 965us/step - loss: 1.1677\n16/16 [==============================] - 0s 1ms/step - loss: 1.1681\n16/16 [==============================] - 0s 1ms/step - loss: 1.1688\n16/16 [==============================] - 0s 971us/step - loss: 1.1690\n16/16 [==============================] - 0s 2ms/step - loss: 1.1690\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n32/32 [==============================] - 0s 858us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4861\n16/16 [==============================] - 0s 2ms/step - loss: 1.1078\n16/16 [==============================] - 0s 1ms/step - loss: 1.1395\n16/16 [==============================] - 0s 1ms/step - loss: 1.1408\n16/16 [==============================] - 0s 1ms/step - loss: 1.1412\n16/16 [==============================] - 0s 1ms/step - loss: 1.1417\n16/16 [==============================] - 0s 2ms/step - loss: 1.1423\n16/16 [==============================] - 0s 2ms/step - loss: 1.1430\n16/16 [==============================] - 0s 1ms/step - loss: 1.1433\n16/16 [==============================] - 0s 1ms/step - loss: 1.1433\n\nTesting for epoch 22 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4978\n16/16 [==============================] - 0s 2ms/step - loss: 1.1226\n16/16 [==============================] - 0s 1ms/step - loss: 1.1496\n16/16 [==============================] - 0s 2ms/step - loss: 1.1507\n16/16 [==============================] - 0s 1ms/step - loss: 1.1512\n16/16 [==============================] - 0s 4ms/step - loss: 1.1516\n16/16 [==============================] - 0s 3ms/step - loss: 1.1520\n16/16 [==============================] - 0s 2ms/step - loss: 1.1527\n16/16 [==============================] - 0s 2ms/step - loss: 1.1529\n16/16 [==============================] - 0s 1ms/step - loss: 1.1529\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n32/32 [==============================] - 0s 900us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5048\n16/16 [==============================] - 0s 1ms/step - loss: 1.1336\n16/16 [==============================] - 0s 2ms/step - loss: 1.1607\n16/16 [==============================] - 0s 1ms/step - loss: 1.1618\n16/16 [==============================] - 0s 2ms/step - loss: 1.1622\n16/16 [==============================] - 0s 4ms/step - loss: 1.1625\n16/16 [==============================] - 0s 2ms/step - loss: 1.1630\n16/16 [==============================] - 0s 1ms/step - loss: 1.1636\n16/16 [==============================] - 0s 1ms/step - loss: 1.1638\n16/16 [==============================] - 0s 2ms/step - loss: 1.1638\n\nTesting for epoch 23 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5183\n16/16 [==============================] - 0s 2ms/step - loss: 1.1345\n16/16 [==============================] - 0s 2ms/step - loss: 1.1583\n16/16 [==============================] - 0s 2ms/step - loss: 1.1593\n16/16 [==============================] - 0s 2ms/step - loss: 1.1597\n16/16 [==============================] - 0s 2ms/step - loss: 1.1601\n16/16 [==============================] - 0s 1ms/step - loss: 1.1606\n16/16 [==============================] - 0s 1ms/step - loss: 1.1612\n16/16 [==============================] - 0s 2ms/step - loss: 1.1614\n16/16 [==============================] - 0s 2ms/step - loss: 1.1614\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5228\n16/16 [==============================] - 0s 1ms/step - loss: 1.1392\n16/16 [==============================] - 0s 1ms/step - loss: 1.1615\n16/16 [==============================] - 0s 977us/step - loss: 1.1623\n16/16 [==============================] - 0s 1ms/step - loss: 1.1628\n16/16 [==============================] - 0s 1ms/step - loss: 1.1633\n16/16 [==============================] - 0s 1ms/step - loss: 1.1639\n16/16 [==============================] - 0s 2ms/step - loss: 1.1646\n16/16 [==============================] - 0s 1ms/step - loss: 1.1649\n16/16 [==============================] - 0s 1ms/step - loss: 1.1649\n\nTesting for epoch 24 index 2:\n32/32 [==============================] - 0s 848us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5259\n16/16 [==============================] - 0s 1ms/step - loss: 1.1609\n16/16 [==============================] - 0s 1ms/step - loss: 1.1832\n16/16 [==============================] - 0s 1ms/step - loss: 1.1841\n16/16 [==============================] - 0s 2ms/step - loss: 1.1845\n16/16 [==============================] - 0s 2ms/step - loss: 1.1848\n16/16 [==============================] - 0s 2ms/step - loss: 1.1853\n16/16 [==============================] - 0s 2ms/step - loss: 1.1859\n16/16 [==============================] - 0s 2ms/step - loss: 1.1861\n16/16 [==============================] - 0s 2ms/step - loss: 1.1861\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5249\n16/16 [==============================] - 0s 2ms/step - loss: 1.1680\n16/16 [==============================] - 0s 2ms/step - loss: 1.1921\n16/16 [==============================] - 0s 1ms/step - loss: 1.1930\n16/16 [==============================] - 0s 1ms/step - loss: 1.1933\n16/16 [==============================] - 0s 1ms/step - loss: 1.1937\n16/16 [==============================] - 0s 959us/step - loss: 1.1941\n16/16 [==============================] - 0s 3ms/step - loss: 1.1947\n16/16 [==============================] - 0s 1ms/step - loss: 1.1949\n16/16 [==============================] - 0s 1ms/step - loss: 1.1949\n\nTesting for epoch 25 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5256\n16/16 [==============================] - 0s 4ms/step - loss: 1.1816\n16/16 [==============================] - 0s 1ms/step - loss: 1.2066\n16/16 [==============================] - 0s 1ms/step - loss: 1.2075\n16/16 [==============================] - 0s 1ms/step - loss: 1.2079\n16/16 [==============================] - 0s 2ms/step - loss: 1.2082\n16/16 [==============================] - 0s 1ms/step - loss: 1.2087\n16/16 [==============================] - 0s 1ms/step - loss: 1.2092\n16/16 [==============================] - 0s 1ms/step - loss: 1.2095\n16/16 [==============================] - 0s 2ms/step - loss: 1.2095\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.1842\n16/16 [==============================] - 0s 1ms/step - loss: 1.2109\n16/16 [==============================] - 0s 2ms/step - loss: 1.2118\n16/16 [==============================] - 0s 2ms/step - loss: 1.2122\n16/16 [==============================] - 0s 1ms/step - loss: 1.2126\n16/16 [==============================] - 0s 1ms/step - loss: 1.2131\n16/16 [==============================] - 0s 4ms/step - loss: 1.2137\n16/16 [==============================] - 0s 2ms/step - loss: 1.2140\n16/16 [==============================] - 0s 878us/step - loss: 1.2140\n\nTesting for epoch 26 index 2:\n32/32 [==============================] - 0s 656us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.5174\n16/16 [==============================] - 0s 864us/step - loss: 1.1946\n16/16 [==============================] - 0s 732us/step - loss: 1.2231\n16/16 [==============================] - 0s 767us/step - loss: 1.2241\n16/16 [==============================] - 0s 810us/step - loss: 1.2245\n16/16 [==============================] - 0s 822us/step - loss: 1.2248\n16/16 [==============================] - 0s 808us/step - loss: 1.2252\n16/16 [==============================] - 0s 788us/step - loss: 1.2257\n16/16 [==============================] - 0s 821us/step - loss: 1.2259\n16/16 [==============================] - 0s 810us/step - loss: 1.2260\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n32/32 [==============================] - 0s 615us/step\n16/16 [==============================] - 0s 796us/step - loss: 0.5052\n16/16 [==============================] - 0s 812us/step - loss: 1.2202\n16/16 [==============================] - 0s 814us/step - loss: 1.2513\n16/16 [==============================] - 0s 778us/step - loss: 1.2525\n16/16 [==============================] - 0s 782us/step - loss: 1.2529\n16/16 [==============================] - 0s 804us/step - loss: 1.2532\n16/16 [==============================] - 0s 777us/step - loss: 1.2536\n16/16 [==============================] - 0s 785us/step - loss: 1.2541\n16/16 [==============================] - 0s 795us/step - loss: 1.2544\n16/16 [==============================] - 0s 797us/step - loss: 1.2544\n\nTesting for epoch 27 index 2:\n32/32 [==============================] - 0s 631us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.5002\n16/16 [==============================] - 0s 831us/step - loss: 1.2353\n16/16 [==============================] - 0s 827us/step - loss: 1.2665\n16/16 [==============================] - 0s 780us/step - loss: 1.2678\n16/16 [==============================] - 0s 798us/step - loss: 1.2682\n16/16 [==============================] - 0s 771us/step - loss: 1.2685\n16/16 [==============================] - 0s 778us/step - loss: 1.2690\n16/16 [==============================] - 0s 809us/step - loss: 1.2696\n16/16 [==============================] - 0s 818us/step - loss: 1.2698\n16/16 [==============================] - 0s 784us/step - loss: 1.2698\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n32/32 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.4877\n16/16 [==============================] - 0s 796us/step - loss: 1.2490\n16/16 [==============================] - 0s 816us/step - loss: 1.2845\n16/16 [==============================] - 0s 825us/step - loss: 1.2858\n16/16 [==============================] - 0s 782us/step - loss: 1.2862\n16/16 [==============================] - 0s 824us/step - loss: 1.2866\n16/16 [==============================] - 0s 812us/step - loss: 1.2870\n16/16 [==============================] - 0s 799us/step - loss: 1.2875\n16/16 [==============================] - 0s 792us/step - loss: 1.2877\n16/16 [==============================] - 0s 811us/step - loss: 1.2877\n\nTesting for epoch 28 index 2:\n32/32 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 782us/step - loss: 0.4795\n16/16 [==============================] - 0s 819us/step - loss: 1.2762\n16/16 [==============================] - 0s 807us/step - loss: 1.3130\n16/16 [==============================] - 0s 810us/step - loss: 1.3144\n16/16 [==============================] - 0s 812us/step - loss: 1.3148\n16/16 [==============================] - 0s 816us/step - loss: 1.3151\n16/16 [==============================] - 0s 774us/step - loss: 1.3156\n16/16 [==============================] - 0s 780us/step - loss: 1.3161\n16/16 [==============================] - 0s 805us/step - loss: 1.3163\n16/16 [==============================] - 0s 775us/step - loss: 1.3163\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n32/32 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.4700\n16/16 [==============================] - 0s 815us/step - loss: 1.2786\n16/16 [==============================] - 0s 795us/step - loss: 1.3164\n16/16 [==============================] - 0s 800us/step - loss: 1.3177\n16/16 [==============================] - 0s 781us/step - loss: 1.3182\n16/16 [==============================] - 0s 768us/step - loss: 1.3186\n16/16 [==============================] - 0s 775us/step - loss: 1.3191\n16/16 [==============================] - 0s 795us/step - loss: 1.3197\n16/16 [==============================] - 0s 799us/step - loss: 1.3199\n16/16 [==============================] - 0s 775us/step - loss: 1.3199\n\nTesting for epoch 29 index 2:\n32/32 [==============================] - 0s 611us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.4639\n16/16 [==============================] - 0s 816us/step - loss: 1.2951\n16/16 [==============================] - 0s 784us/step - loss: 1.3344\n16/16 [==============================] - 0s 821us/step - loss: 1.3358\n16/16 [==============================] - 0s 769us/step - loss: 1.3362\n16/16 [==============================] - 0s 798us/step - loss: 1.3366\n16/16 [==============================] - 0s 773us/step - loss: 1.3371\n16/16 [==============================] - 0s 781us/step - loss: 1.3376\n16/16 [==============================] - 0s 803us/step - loss: 1.3379\n16/16 [==============================] - 0s 795us/step - loss: 1.3379\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n32/32 [==============================] - 0s 629us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.4496\n16/16 [==============================] - 0s 777us/step - loss: 1.3229\n16/16 [==============================] - 0s 782us/step - loss: 1.3686\n16/16 [==============================] - 0s 793us/step - loss: 1.3703\n16/16 [==============================] - 0s 798us/step - loss: 1.3707\n16/16 [==============================] - 0s 792us/step - loss: 1.3710\n16/16 [==============================] - 0s 784us/step - loss: 1.3714\n16/16 [==============================] - 0s 780us/step - loss: 1.3719\n16/16 [==============================] - 0s 803us/step - loss: 1.3720\n16/16 [==============================] - 0s 773us/step - loss: 1.3721\n\nTesting for epoch 30 index 2:\n32/32 [==============================] - 0s 598us/step\n16/16 [==============================] - 0s 780us/step - loss: 0.4461\n16/16 [==============================] - 0s 772us/step - loss: 1.3343\n16/16 [==============================] - 0s 771us/step - loss: 1.3836\n16/16 [==============================] - 0s 777us/step - loss: 1.3853\n16/16 [==============================] - 0s 823us/step - loss: 1.3857\n16/16 [==============================] - 0s 797us/step - loss: 1.3861\n16/16 [==============================] - 0s 783us/step - loss: 1.3865\n16/16 [==============================] - 0s 770us/step - loss: 1.3870\n16/16 [==============================] - 0s 769us/step - loss: 1.3871\n16/16 [==============================] - 0s 791us/step - loss: 1.3872\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n32/32 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.4388\n16/16 [==============================] - 0s 803us/step - loss: 1.3348\n16/16 [==============================] - 0s 785us/step - loss: 1.3881\n16/16 [==============================] - 0s 795us/step - loss: 1.3898\n16/16 [==============================] - 0s 784us/step - loss: 1.3903\n16/16 [==============================] - 0s 814us/step - loss: 1.3906\n16/16 [==============================] - 0s 764us/step - loss: 1.3910\n16/16 [==============================] - 0s 769us/step - loss: 1.3915\n16/16 [==============================] - 0s 766us/step - loss: 1.3917\n16/16 [==============================] - 0s 770us/step - loss: 1.3917\n\nTesting for epoch 31 index 2:\n32/32 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.4335\n16/16 [==============================] - 0s 778us/step - loss: 1.3689\n16/16 [==============================] - 0s 776us/step - loss: 1.4249\n16/16 [==============================] - 0s 794us/step - loss: 1.4268\n16/16 [==============================] - 0s 773us/step - loss: 1.4272\n16/16 [==============================] - 0s 770us/step - loss: 1.4275\n16/16 [==============================] - 0s 770us/step - loss: 1.4279\n16/16 [==============================] - 0s 788us/step - loss: 1.4283\n16/16 [==============================] - 0s 792us/step - loss: 1.4285\n16/16 [==============================] - 0s 802us/step - loss: 1.4285\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.4265\n16/16 [==============================] - 0s 805us/step - loss: 1.3817\n16/16 [==============================] - 0s 815us/step - loss: 1.4402\n16/16 [==============================] - 0s 784us/step - loss: 1.4422\n16/16 [==============================] - 0s 785us/step - loss: 1.4426\n16/16 [==============================] - 0s 791us/step - loss: 1.4429\n16/16 [==============================] - 0s 811us/step - loss: 1.4432\n16/16 [==============================] - 0s 791us/step - loss: 1.4435\n16/16 [==============================] - 0s 809us/step - loss: 1.4437\n16/16 [==============================] - 0s 777us/step - loss: 1.4437\n\nTesting for epoch 32 index 2:\n32/32 [==============================] - 0s 622us/step\n16/16 [==============================] - 0s 819us/step - loss: 0.4303\n16/16 [==============================] - 0s 794us/step - loss: 1.3806\n16/16 [==============================] - 0s 809us/step - loss: 1.4368\n16/16 [==============================] - 0s 791us/step - loss: 1.4388\n16/16 [==============================] - 0s 781us/step - loss: 1.4392\n16/16 [==============================] - 0s 797us/step - loss: 1.4396\n16/16 [==============================] - 0s 784us/step - loss: 1.4399\n16/16 [==============================] - 0s 786us/step - loss: 1.4404\n16/16 [==============================] - 0s 808us/step - loss: 1.4406\n16/16 [==============================] - 0s 809us/step - loss: 1.4406\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.4255\n16/16 [==============================] - 0s 2ms/step - loss: 1.3957\n16/16 [==============================] - 0s 2ms/step - loss: 1.4540\n16/16 [==============================] - 0s 2ms/step - loss: 1.4562\n16/16 [==============================] - 0s 1ms/step - loss: 1.4566\n16/16 [==============================] - 0s 2ms/step - loss: 1.4569\n16/16 [==============================] - 0s 1ms/step - loss: 1.4573\n16/16 [==============================] - 0s 2ms/step - loss: 1.4577\n16/16 [==============================] - 0s 2ms/step - loss: 1.4579\n16/16 [==============================] - 0s 4ms/step - loss: 1.4579\n\nTesting for epoch 33 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4288\n16/16 [==============================] - 0s 1ms/step - loss: 1.4084\n16/16 [==============================] - 0s 1ms/step - loss: 1.4660\n16/16 [==============================] - 0s 1ms/step - loss: 1.4681\n16/16 [==============================] - 0s 2ms/step - loss: 1.4686\n16/16 [==============================] - 0s 2ms/step - loss: 1.4689\n16/16 [==============================] - 0s 1ms/step - loss: 1.4692\n16/16 [==============================] - 0s 1ms/step - loss: 1.4696\n16/16 [==============================] - 0s 1ms/step - loss: 1.4698\n16/16 [==============================] - 0s 1ms/step - loss: 1.4698\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4279\n16/16 [==============================] - 0s 1ms/step - loss: 1.4181\n16/16 [==============================] - 0s 1ms/step - loss: 1.4764\n16/16 [==============================] - 0s 5ms/step - loss: 1.4786\n16/16 [==============================] - 0s 4ms/step - loss: 1.4790\n16/16 [==============================] - 0s 2ms/step - loss: 1.4793\n16/16 [==============================] - 0s 2ms/step - loss: 1.4796\n16/16 [==============================] - 0s 1ms/step - loss: 1.4800\n16/16 [==============================] - 0s 1ms/step - loss: 1.4802\n16/16 [==============================] - 0s 1ms/step - loss: 1.4802\n\nTesting for epoch 34 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.4335\n16/16 [==============================] - 0s 1ms/step - loss: 1.4360\n16/16 [==============================] - 0s 2ms/step - loss: 1.4928\n16/16 [==============================] - 0s 3ms/step - loss: 1.4949\n16/16 [==============================] - 0s 1ms/step - loss: 1.4954\n16/16 [==============================] - 0s 1ms/step - loss: 1.4957\n16/16 [==============================] - 0s 938us/step - loss: 1.4960\n16/16 [==============================] - 0s 3ms/step - loss: 1.4964\n16/16 [==============================] - 0s 4ms/step - loss: 1.4966\n16/16 [==============================] - 0s 2ms/step - loss: 1.4966\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4357\n16/16 [==============================] - 0s 1ms/step - loss: 1.4423\n16/16 [==============================] - 0s 1ms/step - loss: 1.4991\n16/16 [==============================] - 0s 1ms/step - loss: 1.5013\n16/16 [==============================] - 0s 987us/step - loss: 1.5017\n16/16 [==============================] - 0s 2ms/step - loss: 1.5019\n16/16 [==============================] - 0s 2ms/step - loss: 1.5022\n16/16 [==============================] - 0s 1ms/step - loss: 1.5026\n16/16 [==============================] - 0s 1ms/step - loss: 1.5028\n16/16 [==============================] - 0s 2ms/step - loss: 1.5028\n\nTesting for epoch 35 index 2:\n32/32 [==============================] - 0s 4ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4458\n16/16 [==============================] - 0s 3ms/step - loss: 1.4532\n16/16 [==============================] - 0s 1ms/step - loss: 1.5074\n16/16 [==============================] - 0s 1ms/step - loss: 1.5094\n16/16 [==============================] - 0s 1ms/step - loss: 1.5098\n16/16 [==============================] - 0s 1ms/step - loss: 1.5100\n16/16 [==============================] - 0s 1ms/step - loss: 1.5103\n16/16 [==============================] - 0s 1ms/step - loss: 1.5106\n16/16 [==============================] - 0s 1ms/step - loss: 1.5107\n16/16 [==============================] - 0s 2ms/step - loss: 1.5107\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4508\n16/16 [==============================] - 0s 2ms/step - loss: 1.4504\n16/16 [==============================] - 0s 2ms/step - loss: 1.5026\n16/16 [==============================] - 0s 1ms/step - loss: 1.5046\n16/16 [==============================] - 0s 1ms/step - loss: 1.5050\n16/16 [==============================] - 0s 1ms/step - loss: 1.5053\n16/16 [==============================] - 0s 1ms/step - loss: 1.5056\n16/16 [==============================] - 0s 1ms/step - loss: 1.5060\n16/16 [==============================] - 0s 1ms/step - loss: 1.5062\n16/16 [==============================] - 0s 1ms/step - loss: 1.5062\n\nTesting for epoch 36 index 2:\n32/32 [==============================] - 0s 988us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4614\n16/16 [==============================] - 0s 1ms/step - loss: 1.4690\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.5217\n16/16 [==============================] - 0s 1ms/step - loss: 1.5222\n16/16 [==============================] - 0s 1ms/step - loss: 1.5225\n16/16 [==============================] - 0s 2ms/step - loss: 1.5228\n16/16 [==============================] - 0s 891us/step - loss: 1.5233\n16/16 [==============================] - 0s 1ms/step - loss: 1.5235\n16/16 [==============================] - 0s 1ms/step - loss: 1.5235\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4674\n16/16 [==============================] - 0s 1ms/step - loss: 1.4703\n16/16 [==============================] - 0s 3ms/step - loss: 1.5202\n16/16 [==============================] - 0s 1ms/step - loss: 1.5220\n16/16 [==============================] - 0s 1ms/step - loss: 1.5224\n16/16 [==============================] - 0s 1ms/step - loss: 1.5226\n16/16 [==============================] - 0s 1ms/step - loss: 1.5229\n16/16 [==============================] - 0s 1ms/step - loss: 1.5232\n16/16 [==============================] - 0s 1ms/step - loss: 1.5233\n16/16 [==============================] - 0s 1ms/step - loss: 1.5233\n\nTesting for epoch 37 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4817\n16/16 [==============================] - 0s 2ms/step - loss: 1.4794\n16/16 [==============================] - 0s 2ms/step - loss: 1.5276\n16/16 [==============================] - 0s 2ms/step - loss: 1.5293\n16/16 [==============================] - 0s 1ms/step - loss: 1.5296\n16/16 [==============================] - 0s 1ms/step - loss: 1.5299\n16/16 [==============================] - 0s 2ms/step - loss: 1.5301\n16/16 [==============================] - 0s 2ms/step - loss: 1.5304\n16/16 [==============================] - 0s 2ms/step - loss: 1.5305\n16/16 [==============================] - 0s 2ms/step - loss: 1.5305\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4878\n16/16 [==============================] - 0s 1ms/step - loss: 1.4939\n16/16 [==============================] - 0s 1ms/step - loss: 1.5415\n16/16 [==============================] - 0s 2ms/step - loss: 1.5431\n16/16 [==============================] - 0s 2ms/step - loss: 1.5435\n16/16 [==============================] - 0s 1ms/step - loss: 1.5437\n16/16 [==============================] - 0s 2ms/step - loss: 1.5439\n16/16 [==============================] - 0s 2ms/step - loss: 1.5442\n16/16 [==============================] - 0s 2ms/step - loss: 1.5443\n16/16 [==============================] - 0s 2ms/step - loss: 1.5443\n\nTesting for epoch 38 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5035\n16/16 [==============================] - 0s 1ms/step - loss: 1.4905\n16/16 [==============================] - 0s 1ms/step - loss: 1.5351\n16/16 [==============================] - 0s 1ms/step - loss: 1.5365\n16/16 [==============================] - 0s 1ms/step - loss: 1.5370\n16/16 [==============================] - 0s 1ms/step - loss: 1.5373\n16/16 [==============================] - 0s 988us/step - loss: 1.5376\n16/16 [==============================] - 0s 2ms/step - loss: 1.5381\n16/16 [==============================] - 0s 2ms/step - loss: 1.5382\n16/16 [==============================] - 0s 2ms/step - loss: 1.5383\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5103\n16/16 [==============================] - 0s 1ms/step - loss: 1.5127\n16/16 [==============================] - 0s 1ms/step - loss: 1.5577\n16/16 [==============================] - 0s 1ms/step - loss: 1.5592\n16/16 [==============================] - 0s 4ms/step - loss: 1.5596\n16/16 [==============================] - 0s 4ms/step - loss: 1.5598\n16/16 [==============================] - 0s 1ms/step - loss: 1.5601\n16/16 [==============================] - 0s 3ms/step - loss: 1.5604\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n\nTesting for epoch 39 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5264\n16/16 [==============================] - 0s 1ms/step - loss: 1.5167\n16/16 [==============================] - 0s 3ms/step - loss: 1.5597\n16/16 [==============================] - 0s 2ms/step - loss: 1.5612\n16/16 [==============================] - 0s 1ms/step - loss: 1.5615\n16/16 [==============================] - 0s 1ms/step - loss: 1.5617\n16/16 [==============================] - 0s 1ms/step - loss: 1.5620\n16/16 [==============================] - 0s 1ms/step - loss: 1.5622\n16/16 [==============================] - 0s 1ms/step - loss: 1.5623\n16/16 [==============================] - 0s 1ms/step - loss: 1.5623\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5342\n16/16 [==============================] - 0s 2ms/step - loss: 1.5283\n16/16 [==============================] - 0s 2ms/step - loss: 1.5709\n16/16 [==============================] - 0s 1ms/step - loss: 1.5724\n16/16 [==============================] - 0s 1ms/step - loss: 1.5727\n16/16 [==============================] - 0s 1ms/step - loss: 1.5729\n16/16 [==============================] - 0s 2ms/step - loss: 1.5732\n16/16 [==============================] - 0s 1ms/step - loss: 1.5734\n16/16 [==============================] - 0s 1ms/step - loss: 1.5735\n16/16 [==============================] - 0s 1ms/step - loss: 1.5735\n\nTesting for epoch 40 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5499\n16/16 [==============================] - 0s 2ms/step - loss: 1.5318\n16/16 [==============================] - 0s 2ms/step - loss: 1.5719\n16/16 [==============================] - 0s 1ms/step - loss: 1.5733\n16/16 [==============================] - 0s 1ms/step - loss: 1.5736\n16/16 [==============================] - 0s 2ms/step - loss: 1.5738\n16/16 [==============================] - 0s 2ms/step - loss: 1.5740\n16/16 [==============================] - 0s 2ms/step - loss: 1.5743\n16/16 [==============================] - 0s 1ms/step - loss: 1.5744\n16/16 [==============================] - 0s 1ms/step - loss: 1.5744\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5570\n16/16 [==============================] - 0s 1ms/step - loss: 1.5475\n16/16 [==============================] - 0s 1ms/step - loss: 1.5874\n16/16 [==============================] - 0s 1ms/step - loss: 1.5888\n16/16 [==============================] - 0s 2ms/step - loss: 1.5891\n16/16 [==============================] - 0s 2ms/step - loss: 1.5892\n16/16 [==============================] - 0s 2ms/step - loss: 1.5893\n16/16 [==============================] - 0s 1ms/step - loss: 1.5895\n16/16 [==============================] - 0s 1ms/step - loss: 1.5896\n16/16 [==============================] - 0s 2ms/step - loss: 1.5896\n\nTesting for epoch 41 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5733\n16/16 [==============================] - 0s 1ms/step - loss: 1.5531\n16/16 [==============================] - 0s 1ms/step - loss: 1.5914\n16/16 [==============================] - 0s 1ms/step - loss: 1.5927\n16/16 [==============================] - 0s 2ms/step - loss: 1.5931\n16/16 [==============================] - 0s 2ms/step - loss: 1.5932\n16/16 [==============================] - 0s 2ms/step - loss: 1.5934\n16/16 [==============================] - 0s 1ms/step - loss: 1.5937\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n32/32 [==============================] - 0s 830us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5804\n16/16 [==============================] - 0s 2ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5989\n16/16 [==============================] - 0s 2ms/step - loss: 1.6002\n16/16 [==============================] - 0s 1ms/step - loss: 1.6005\n16/16 [==============================] - 0s 1ms/step - loss: 1.6007\n16/16 [==============================] - 0s 2ms/step - loss: 1.6010\n16/16 [==============================] - 0s 2ms/step - loss: 1.6013\n16/16 [==============================] - 0s 1ms/step - loss: 1.6014\n16/16 [==============================] - 0s 2ms/step - loss: 1.6014\n\nTesting for epoch 42 index 2:\n32/32 [==============================] - 0s 770us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5964\n16/16 [==============================] - 0s 3ms/step - loss: 1.5755\n16/16 [==============================] - 0s 2ms/step - loss: 1.6137\n16/16 [==============================] - 0s 2ms/step - loss: 1.6149\n16/16 [==============================] - 0s 1ms/step - loss: 1.6153\n16/16 [==============================] - 0s 1ms/step - loss: 1.6155\n16/16 [==============================] - 0s 1ms/step - loss: 1.6157\n16/16 [==============================] - 0s 2ms/step - loss: 1.6160\n16/16 [==============================] - 0s 2ms/step - loss: 1.6161\n16/16 [==============================] - 0s 3ms/step - loss: 1.6161\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6020\n16/16 [==============================] - 0s 2ms/step - loss: 1.5861\n16/16 [==============================] - 0s 4ms/step - loss: 1.6247\n16/16 [==============================] - 0s 2ms/step - loss: 1.6259\n16/16 [==============================] - 0s 2ms/step - loss: 1.6263\n16/16 [==============================] - 0s 2ms/step - loss: 1.6264\n16/16 [==============================] - 0s 1ms/step - loss: 1.6266\n16/16 [==============================] - 0s 2ms/step - loss: 1.6268\n16/16 [==============================] - 0s 2ms/step - loss: 1.6269\n16/16 [==============================] - 0s 2ms/step - loss: 1.6269\n\nTesting for epoch 43 index 2:\n32/32 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6162\n16/16 [==============================] - 0s 1ms/step - loss: 1.5924\n16/16 [==============================] - 0s 988us/step - loss: 1.6302\n16/16 [==============================] - 0s 2ms/step - loss: 1.6314\n16/16 [==============================] - 0s 2ms/step - loss: 1.6318\n16/16 [==============================] - 0s 1ms/step - loss: 1.6319\n16/16 [==============================] - 0s 1ms/step - loss: 1.6321\n16/16 [==============================] - 0s 1ms/step - loss: 1.6323\n16/16 [==============================] - 0s 2ms/step - loss: 1.6324\n16/16 [==============================] - 0s 2ms/step - loss: 1.6324\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.6208\n16/16 [==============================] - 0s 3ms/step - loss: 1.6042\n16/16 [==============================] - 0s 2ms/step - loss: 1.6422\n16/16 [==============================] - 0s 1ms/step - loss: 1.6435\n16/16 [==============================] - 0s 2ms/step - loss: 1.6438\n16/16 [==============================] - 0s 2ms/step - loss: 1.6440\n16/16 [==============================] - 0s 2ms/step - loss: 1.6442\n16/16 [==============================] - 0s 1ms/step - loss: 1.6444\n16/16 [==============================] - 0s 1ms/step - loss: 1.6445\n16/16 [==============================] - 0s 1ms/step - loss: 1.6445\n\nTesting for epoch 44 index 2:\n32/32 [==============================] - 0s 855us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6333\n16/16 [==============================] - 0s 1ms/step - loss: 1.6115\n16/16 [==============================] - 0s 2ms/step - loss: 1.6493\n16/16 [==============================] - 0s 2ms/step - loss: 1.6505\n16/16 [==============================] - 0s 1ms/step - loss: 1.6508\n16/16 [==============================] - 0s 1ms/step - loss: 1.6510\n16/16 [==============================] - 0s 2ms/step - loss: 1.6512\n16/16 [==============================] - 0s 2ms/step - loss: 1.6515\n16/16 [==============================] - 0s 1ms/step - loss: 1.6516\n16/16 [==============================] - 0s 2ms/step - loss: 1.6516\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n32/32 [==============================] - 0s 836us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6363\n16/16 [==============================] - 0s 2ms/step - loss: 1.6203\n16/16 [==============================] - 0s 1ms/step - loss: 1.6589\n16/16 [==============================] - 0s 1ms/step - loss: 1.6601\n16/16 [==============================] - 0s 1ms/step - loss: 1.6604\n16/16 [==============================] - 0s 1ms/step - loss: 1.6606\n16/16 [==============================] - 0s 771us/step - loss: 1.6608\n16/16 [==============================] - 0s 1ms/step - loss: 1.6610\n16/16 [==============================] - 0s 954us/step - loss: 1.6611\n16/16 [==============================] - 0s 943us/step - loss: 1.6611\n\nTesting for epoch 45 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.6489\n16/16 [==============================] - 0s 1ms/step - loss: 1.6337\n16/16 [==============================] - 0s 1ms/step - loss: 1.6729\n16/16 [==============================] - 0s 1ms/step - loss: 1.6741\n16/16 [==============================] - 0s 1ms/step - loss: 1.6744\n16/16 [==============================] - 0s 1ms/step - loss: 1.6746\n16/16 [==============================] - 0s 2ms/step - loss: 1.6747\n16/16 [==============================] - 0s 2ms/step - loss: 1.6749\n16/16 [==============================] - 0s 1ms/step - loss: 1.6749\n16/16 [==============================] - 0s 2ms/step - loss: 1.6750\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6501\n16/16 [==============================] - 0s 1ms/step - loss: 1.6367\n16/16 [==============================] - 0s 1ms/step - loss: 1.6765\n16/16 [==============================] - 0s 3ms/step - loss: 1.6777\n16/16 [==============================] - 0s 2ms/step - loss: 1.6780\n16/16 [==============================] - 0s 2ms/step - loss: 1.6781\n16/16 [==============================] - 0s 2ms/step - loss: 1.6783\n16/16 [==============================] - 0s 1ms/step - loss: 1.6784\n16/16 [==============================] - 0s 2ms/step - loss: 1.6785\n16/16 [==============================] - 0s 1ms/step - loss: 1.6785\n\nTesting for epoch 46 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 819us/step - loss: 0.6612\n16/16 [==============================] - 0s 804us/step - loss: 1.6441\n16/16 [==============================] - 0s 1ms/step - loss: 1.6840\n16/16 [==============================] - 0s 785us/step - loss: 1.6852\n16/16 [==============================] - 0s 1ms/step - loss: 1.6855\n16/16 [==============================] - 0s 1ms/step - loss: 1.6856\n16/16 [==============================] - 0s 1ms/step - loss: 1.6857\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n32/32 [==============================] - 0s 835us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6626\n16/16 [==============================] - 0s 1ms/step - loss: 1.6545\n16/16 [==============================] - 0s 805us/step - loss: 1.6944\n16/16 [==============================] - 0s 804us/step - loss: 1.6957\n16/16 [==============================] - 0s 1ms/step - loss: 1.6960\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n16/16 [==============================] - 0s 1ms/step - loss: 1.6962\n16/16 [==============================] - 0s 778us/step - loss: 1.6962\n16/16 [==============================] - 0s 792us/step - loss: 1.6962\n\nTesting for epoch 47 index 2:\n32/32 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.6744\n16/16 [==============================] - 0s 976us/step - loss: 1.6678\n16/16 [==============================] - 0s 1ms/step - loss: 1.7065\n16/16 [==============================] - 0s 804us/step - loss: 1.7078\n16/16 [==============================] - 0s 1ms/step - loss: 1.7081\n16/16 [==============================] - 0s 1ms/step - loss: 1.7083\n16/16 [==============================] - 0s 1ms/step - loss: 1.7085\n16/16 [==============================] - 0s 777us/step - loss: 1.7087\n16/16 [==============================] - 0s 800us/step - loss: 1.7088\n16/16 [==============================] - 0s 789us/step - loss: 1.7088\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n32/32 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.6775\n16/16 [==============================] - 0s 800us/step - loss: 1.6875\n16/16 [==============================] - 0s 1ms/step - loss: 1.7276\n16/16 [==============================] - 0s 1ms/step - loss: 1.7289\n16/16 [==============================] - 0s 808us/step - loss: 1.7292\n16/16 [==============================] - 0s 776us/step - loss: 1.7293\n16/16 [==============================] - 0s 792us/step - loss: 1.7294\n16/16 [==============================] - 0s 1ms/step - loss: 1.7295\n16/16 [==============================] - 0s 1ms/step - loss: 1.7296\n16/16 [==============================] - 0s 1ms/step - loss: 1.7296\n\nTesting for epoch 48 index 2:\n32/32 [==============================] - 0s 831us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6904\n16/16 [==============================] - 0s 1ms/step - loss: 1.7060\n16/16 [==============================] - 0s 1ms/step - loss: 1.7464\n16/16 [==============================] - 0s 1ms/step - loss: 1.7477\n16/16 [==============================] - 0s 1ms/step - loss: 1.7480\n16/16 [==============================] - 0s 1ms/step - loss: 1.7481\n16/16 [==============================] - 0s 1ms/step - loss: 1.7482\n16/16 [==============================] - 0s 1ms/step - loss: 1.7484\n16/16 [==============================] - 0s 813us/step - loss: 1.7485\n16/16 [==============================] - 0s 1ms/step - loss: 1.7485\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n32/32 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.6923\n16/16 [==============================] - 0s 771us/step - loss: 1.7161\n16/16 [==============================] - 0s 799us/step - loss: 1.7569\n16/16 [==============================] - 0s 819us/step - loss: 1.7583\n16/16 [==============================] - 0s 1ms/step - loss: 1.7586\n16/16 [==============================] - 0s 1ms/step - loss: 1.7587\n16/16 [==============================] - 0s 1ms/step - loss: 1.7589\n16/16 [==============================] - 0s 1ms/step - loss: 1.7591\n16/16 [==============================] - 0s 1ms/step - loss: 1.7592\n16/16 [==============================] - 0s 1ms/step - loss: 1.7592\n\nTesting for epoch 49 index 2:\n32/32 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.7016\n16/16 [==============================] - 0s 782us/step - loss: 1.7163\n16/16 [==============================] - 0s 798us/step - loss: 1.7574\n16/16 [==============================] - 0s 790us/step - loss: 1.7587\n16/16 [==============================] - 0s 796us/step - loss: 1.7589\n16/16 [==============================] - 0s 778us/step - loss: 1.7590\n16/16 [==============================] - 0s 770us/step - loss: 1.7591\n16/16 [==============================] - 0s 799us/step - loss: 1.7591\n16/16 [==============================] - 0s 810us/step - loss: 1.7591\n16/16 [==============================] - 0s 779us/step - loss: 1.7591\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.7041\n16/16 [==============================] - 0s 787us/step - loss: 1.7274\n16/16 [==============================] - 0s 833us/step - loss: 1.7685\n16/16 [==============================] - 0s 826us/step - loss: 1.7698\n16/16 [==============================] - 0s 792us/step - loss: 1.7702\n16/16 [==============================] - 0s 818us/step - loss: 1.7703\n16/16 [==============================] - 0s 778us/step - loss: 1.7705\n16/16 [==============================] - 0s 841us/step - loss: 1.7707\n16/16 [==============================] - 0s 805us/step - loss: 1.7708\n16/16 [==============================] - 0s 838us/step - loss: 1.7708\n\nTesting for epoch 50 index 2:\n32/32 [==============================] - 0s 624us/step\n16/16 [==============================] - 0s 824us/step - loss: 0.7152\n16/16 [==============================] - 0s 796us/step - loss: 1.7311\n16/16 [==============================] - 0s 817us/step - loss: 1.7720\n16/16 [==============================] - 0s 781us/step - loss: 1.7732\n16/16 [==============================] - 0s 1ms/step - loss: 1.7736\n16/16 [==============================] - 0s 1ms/step - loss: 1.7737\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 895us/step - loss: 1.7741\n16/16 [==============================] - 0s 776us/step - loss: 1.7742\n16/16 [==============================] - 0s 804us/step - loss: 1.7742\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.7194\n16/16 [==============================] - 0s 799us/step - loss: 1.7544\n16/16 [==============================] - 0s 796us/step - loss: 1.7966\n16/16 [==============================] - 0s 790us/step - loss: 1.7980\n16/16 [==============================] - 0s 810us/step - loss: 1.7983\n16/16 [==============================] - 0s 804us/step - loss: 1.7984\n16/16 [==============================] - 0s 821us/step - loss: 1.7985\n16/16 [==============================] - 0s 791us/step - loss: 1.7987\n16/16 [==============================] - 0s 781us/step - loss: 1.7987\n16/16 [==============================] - 0s 789us/step - loss: 1.7987\n\nTesting for epoch 51 index 2:\n32/32 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.7322\n16/16 [==============================] - 0s 802us/step - loss: 1.7637\n16/16 [==============================] - 0s 793us/step - loss: 1.8060\n16/16 [==============================] - 0s 795us/step - loss: 1.8073\n16/16 [==============================] - 0s 783us/step - loss: 1.8076\n16/16 [==============================] - 0s 776us/step - loss: 1.8077\n16/16 [==============================] - 0s 770us/step - loss: 1.8079\n16/16 [==============================] - 0s 779us/step - loss: 1.8080\n16/16 [==============================] - 0s 787us/step - loss: 1.8081\n16/16 [==============================] - 0s 805us/step - loss: 1.8081\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.7334\n16/16 [==============================] - 0s 807us/step - loss: 1.7648\n16/16 [==============================] - 0s 785us/step - loss: 1.8070\n16/16 [==============================] - 0s 789us/step - loss: 1.8083\n16/16 [==============================] - 0s 788us/step - loss: 1.8086\n16/16 [==============================] - 0s 825us/step - loss: 1.8088\n16/16 [==============================] - 0s 794us/step - loss: 1.8089\n16/16 [==============================] - 0s 839us/step - loss: 1.8091\n16/16 [==============================] - 0s 827us/step - loss: 1.8092\n16/16 [==============================] - 0s 832us/step - loss: 1.8092\n\nTesting for epoch 52 index 2:\n32/32 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 953us/step - loss: 0.7473\n16/16 [==============================] - 0s 1ms/step - loss: 1.7771\n16/16 [==============================] - 0s 1ms/step - loss: 1.8202\n16/16 [==============================] - 0s 782us/step - loss: 1.8215\n16/16 [==============================] - 0s 806us/step - loss: 1.8217\n16/16 [==============================] - 0s 789us/step - loss: 1.8217\n16/16 [==============================] - 0s 821us/step - loss: 1.8217\n16/16 [==============================] - 0s 810us/step - loss: 1.8217\n16/16 [==============================] - 0s 706us/step - loss: 1.8217\n16/16 [==============================] - 0s 675us/step - loss: 1.8217\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n32/32 [==============================] - 0s 543us/step\n16/16 [==============================] - 0s 815us/step - loss: 0.7534\n16/16 [==============================] - 0s 798us/step - loss: 1.7954\n16/16 [==============================] - 0s 682us/step - loss: 1.8386\n16/16 [==============================] - 0s 821us/step - loss: 1.8399\n16/16 [==============================] - 0s 786us/step - loss: 1.8402\n16/16 [==============================] - 0s 788us/step - loss: 1.8403\n16/16 [==============================] - 0s 801us/step - loss: 1.8404\n16/16 [==============================] - 0s 864us/step - loss: 1.8405\n16/16 [==============================] - 0s 866us/step - loss: 1.8405\n16/16 [==============================] - 0s 861us/step - loss: 1.8405\n\nTesting for epoch 53 index 2:\n32/32 [==============================] - 0s 821us/step\n16/16 [==============================] - 0s 901us/step - loss: 0.7658\n16/16 [==============================] - 0s 876us/step - loss: 1.7944\n16/16 [==============================] - 0s 904us/step - loss: 1.8367\n16/16 [==============================] - 0s 923us/step - loss: 1.8380\n16/16 [==============================] - 0s 863us/step - loss: 1.8382\n16/16 [==============================] - 0s 888us/step - loss: 1.8383\n16/16 [==============================] - 0s 892us/step - loss: 1.8384\n16/16 [==============================] - 0s 872us/step - loss: 1.8385\n16/16 [==============================] - 0s 874us/step - loss: 1.8385\n16/16 [==============================] - 0s 1ms/step - loss: 1.8385\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n32/32 [==============================] - 0s 675us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.7743\n16/16 [==============================] - 0s 878us/step - loss: 1.8193\n16/16 [==============================] - 0s 800us/step - loss: 1.8622\n16/16 [==============================] - 0s 791us/step - loss: 1.8635\n16/16 [==============================] - 0s 786us/step - loss: 1.8638\n16/16 [==============================] - 0s 794us/step - loss: 1.8639\n16/16 [==============================] - 0s 798us/step - loss: 1.8640\n16/16 [==============================] - 0s 828us/step - loss: 1.8641\n16/16 [==============================] - 0s 797us/step - loss: 1.8642\n16/16 [==============================] - 0s 812us/step - loss: 1.8642\n\nTesting for epoch 54 index 2:\n32/32 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.7864\n16/16 [==============================] - 0s 822us/step - loss: 1.8117\n16/16 [==============================] - 0s 809us/step - loss: 1.8535\n16/16 [==============================] - 0s 794us/step - loss: 1.8547\n16/16 [==============================] - 0s 811us/step - loss: 1.8550\n16/16 [==============================] - 0s 806us/step - loss: 1.8551\n16/16 [==============================] - 0s 844us/step - loss: 1.8552\n16/16 [==============================] - 0s 794us/step - loss: 1.8553\n16/16 [==============================] - 0s 784us/step - loss: 1.8554\n16/16 [==============================] - 0s 802us/step - loss: 1.8554\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n32/32 [==============================] - 0s 621us/step\n16/16 [==============================] - 0s 873us/step - loss: 0.7953\n16/16 [==============================] - 0s 873us/step - loss: 1.8319\n16/16 [==============================] - 0s 808us/step - loss: 1.8741\n16/16 [==============================] - 0s 859us/step - loss: 1.8754\n16/16 [==============================] - 0s 809us/step - loss: 1.8757\n16/16 [==============================] - 0s 847us/step - loss: 1.8758\n16/16 [==============================] - 0s 827us/step - loss: 1.8758\n16/16 [==============================] - 0s 860us/step - loss: 1.8759\n16/16 [==============================] - 0s 804us/step - loss: 1.8760\n16/16 [==============================] - 0s 876us/step - loss: 1.8760\n\nTesting for epoch 55 index 2:\n32/32 [==============================] - 0s 643us/step\n16/16 [==============================] - 0s 808us/step - loss: 0.8131\n16/16 [==============================] - 0s 893us/step - loss: 1.8454\n16/16 [==============================] - 0s 809us/step - loss: 1.8876\n16/16 [==============================] - 0s 907us/step - loss: 1.8889\n16/16 [==============================] - 0s 873us/step - loss: 1.8891\n16/16 [==============================] - 0s 886us/step - loss: 1.8892\n16/16 [==============================] - 0s 869us/step - loss: 1.8892\n16/16 [==============================] - 0s 876us/step - loss: 1.8892\n16/16 [==============================] - 0s 808us/step - loss: 1.8892\n16/16 [==============================] - 0s 796us/step - loss: 1.8892\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 694us/step - loss: 0.8154\n16/16 [==============================] - 0s 812us/step - loss: 1.8371\n16/16 [==============================] - 0s 815us/step - loss: 1.8781\n16/16 [==============================] - 0s 796us/step - loss: 1.8793\n16/16 [==============================] - 0s 867us/step - loss: 1.8796\n16/16 [==============================] - 0s 798us/step - loss: 1.8797\n16/16 [==============================] - 0s 791us/step - loss: 1.8798\n16/16 [==============================] - 0s 878us/step - loss: 1.8799\n16/16 [==============================] - 0s 872us/step - loss: 1.8800\n16/16 [==============================] - 0s 799us/step - loss: 1.8800\n\nTesting for epoch 56 index 2:\n32/32 [==============================] - 0s 611us/step\n16/16 [==============================] - 0s 830us/step - loss: 0.8363\n16/16 [==============================] - 0s 883us/step - loss: 1.8623\n16/16 [==============================] - 0s 873us/step - loss: 1.9037\n16/16 [==============================] - 0s 817us/step - loss: 1.9049\n16/16 [==============================] - 0s 837us/step - loss: 1.9052\n16/16 [==============================] - 0s 811us/step - loss: 1.9052\n16/16 [==============================] - 0s 862us/step - loss: 1.9053\n16/16 [==============================] - 0s 859us/step - loss: 1.9054\n16/16 [==============================] - 0s 839us/step - loss: 1.9054\n16/16 [==============================] - 0s 809us/step - loss: 1.9054\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n32/32 [==============================] - 0s 860us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.8392\n16/16 [==============================] - 0s 866us/step - loss: 1.8604\n16/16 [==============================] - 0s 854us/step - loss: 1.9012\n16/16 [==============================] - 0s 1ms/step - loss: 1.9024\n16/16 [==============================] - 0s 1ms/step - loss: 1.9027\n16/16 [==============================] - 0s 853us/step - loss: 1.9028\n16/16 [==============================] - 0s 892us/step - loss: 1.9029\n16/16 [==============================] - 0s 901us/step - loss: 1.9030\n16/16 [==============================] - 0s 666us/step - loss: 1.9031\n16/16 [==============================] - 0s 2ms/step - loss: 1.9031\n\nTesting for epoch 57 index 2:\n32/32 [==============================] - 0s 570us/step\n16/16 [==============================] - 0s 875us/step - loss: 0.8581\n16/16 [==============================] - 0s 839us/step - loss: 1.8764\n16/16 [==============================] - 0s 1ms/step - loss: 1.9169\n16/16 [==============================] - 0s 793us/step - loss: 1.9180\n16/16 [==============================] - 0s 829us/step - loss: 1.9183\n16/16 [==============================] - 0s 852us/step - loss: 1.9184\n16/16 [==============================] - 0s 2ms/step - loss: 1.9185\n16/16 [==============================] - 0s 786us/step - loss: 1.9186\n16/16 [==============================] - 0s 890us/step - loss: 1.9187\n16/16 [==============================] - 0s 2ms/step - loss: 1.9187\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n32/32 [==============================] - 0s 549us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.8680\n16/16 [==============================] - 0s 922us/step - loss: 1.8985\n16/16 [==============================] - 0s 765us/step - loss: 1.9394\n16/16 [==============================] - 0s 781us/step - loss: 1.9405\n16/16 [==============================] - 0s 820us/step - loss: 1.9408\n16/16 [==============================] - 0s 1ms/step - loss: 1.9409\n16/16 [==============================] - 0s 781us/step - loss: 1.9410\n16/16 [==============================] - 0s 755us/step - loss: 1.9411\n16/16 [==============================] - 0s 811us/step - loss: 1.9412\n16/16 [==============================] - 0s 2ms/step - loss: 1.9412\n\nTesting for epoch 58 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.8825\n16/16 [==============================] - 0s 2ms/step - loss: 1.9008\n16/16 [==============================] - 0s 799us/step - loss: 1.9412\n16/16 [==============================] - 0s 2ms/step - loss: 1.9423\n16/16 [==============================] - 0s 2ms/step - loss: 1.9425\n16/16 [==============================] - 0s 2ms/step - loss: 1.9426\n16/16 [==============================] - 0s 791us/step - loss: 1.9427\n16/16 [==============================] - 0s 851us/step - loss: 1.9427\n16/16 [==============================] - 0s 2ms/step - loss: 1.9427\n16/16 [==============================] - 0s 2ms/step - loss: 1.9427\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n32/32 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.8879\n16/16 [==============================] - 0s 803us/step - loss: 1.9056\n16/16 [==============================] - 0s 2ms/step - loss: 1.9456\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 962us/step - loss: 1.9470\n16/16 [==============================] - 0s 794us/step - loss: 1.9470\n16/16 [==============================] - 0s 800us/step - loss: 1.9471\n16/16 [==============================] - 0s 2ms/step - loss: 1.9471\n16/16 [==============================] - 0s 2ms/step - loss: 1.9471\n16/16 [==============================] - 0s 1ms/step - loss: 1.9471\n\nTesting for epoch 59 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 830us/step - loss: 0.9059\n16/16 [==============================] - 0s 1ms/step - loss: 1.9160\n16/16 [==============================] - 0s 838us/step - loss: 1.9552\n16/16 [==============================] - 0s 788us/step - loss: 1.9563\n16/16 [==============================] - 0s 2ms/step - loss: 1.9566\n16/16 [==============================] - 0s 761us/step - loss: 1.9567\n16/16 [==============================] - 0s 808us/step - loss: 1.9569\n16/16 [==============================] - 0s 2ms/step - loss: 1.9571\n16/16 [==============================] - 0s 2ms/step - loss: 1.9571\n16/16 [==============================] - 0s 1ms/step - loss: 1.9571\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n32/32 [==============================] - 0s 561us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.9083\n16/16 [==============================] - 0s 2ms/step - loss: 1.9140\n16/16 [==============================] - 0s 800us/step - loss: 1.9538\n16/16 [==============================] - 0s 793us/step - loss: 1.9549\n16/16 [==============================] - 0s 877us/step - loss: 1.9551\n16/16 [==============================] - 0s 783us/step - loss: 1.9551\n16/16 [==============================] - 0s 1ms/step - loss: 1.9551\n16/16 [==============================] - 0s 1ms/step - loss: 1.9552\n16/16 [==============================] - 0s 884us/step - loss: 1.9552\n16/16 [==============================] - 0s 2ms/step - loss: 1.9552\n\nTesting for epoch 60 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.9274\n16/16 [==============================] - 0s 2ms/step - loss: 1.9310\n16/16 [==============================] - 0s 2ms/step - loss: 1.9710\n16/16 [==============================] - 0s 775us/step - loss: 1.9721\n16/16 [==============================] - 0s 960us/step - loss: 1.9723\n16/16 [==============================] - 0s 2ms/step - loss: 1.9723\n16/16 [==============================] - 0s 794us/step - loss: 1.9722\n16/16 [==============================] - 0s 1ms/step - loss: 1.9721\n16/16 [==============================] - 0s 2ms/step - loss: 1.9721\n16/16 [==============================] - 0s 2ms/step - loss: 1.9721\n32/32 [==============================] - 0s 1ms/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthirteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  thirteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\\(\\star\\)\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = thirteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-result",
    "title": "Other Outlier Detection",
    "section": "Orbit Result",
    "text": "Orbit Result\n\nround(fourteen,3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.998\n      0.999\n      0.999\n      0.999\n    \n    \n      LOF (Breunig et al., 2000)\n      0.954\n      0.976\n      0.976\n      0.976\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.948\n      0.999\n      0.946\n      0.972\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.908\n      0.977\n      0.925\n      0.950\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.916\n      0.956\n      0.956\n      0.956\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.942\n      0.969\n      0.969\n      0.969\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.994\n      0.994\n      0.994\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.443\n      0.992\n      0.417\n      0.587\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.935\n      0.960\n      0.973\n      0.966\n    \n    \n      SOS (Janssens et al., 2012)\n      0.950\n      0.974\n      0.974\n      0.974\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.950\n      0.950\n      1.000\n      0.974\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.950\n      0.950\n      1.000\n      0.974\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.988\n      0.994\n      0.994\n      0.994\n    \n  \n\n\n\n\n\n\n\nOrbit\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nLOF (Breunig et al., 2000)\n0.954\n0.976\n0.976\n0.976\n\n\nKNN\n\n\n\n\n\n\nCBLOF\n\n\n\n\n\n\nOCSVM (Sch ̈olkopf et al., 2001)\n\n\n\n\n\n\nMCD (Hardin and Rocke, 2004)\n0.916\n0.956\n0.956\n0.956\n\n\nFeature Bagging (Lazarevic and Kumar, 2005)\n0.942\n0.969\n0.969\n0.969\n\n\nABOD (Kriegel et al., 2008)\n0.988\n0.994\n0.994\n0.994\n\n\nIsolation Forest (Liu et al., 2008)\n0.443\n0.992\n0.417\n0.587\n\n\nHBOS (Goldstein and Dengel, 2012)\n0.935\n0.960\n0.973\n0.966\n\n\nSOS (Janssens et al., 2012)\n0.950\n0.974\n0.974\n0.974\n\n\nSO-GAAL (Liu et al., 2019)\n0.950\n0.950\n1.000\n0.974\n\n\nMO-GAAL (Liu et al., 2019)\n0.950\n0.950\n1.000\n0.974\n\n\nLSCP (Zhao et al., 2019)\n0.988\n0.994\n0.994\n0.994"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny",
    "title": "Other Outlier Detection",
    "section": "Bunny",
    "text": "Bunny\n\n\nbunny 저장용\n\nfrom pygsp import graphs, filters, plotting, utils\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nimport numpy as np\n\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) \n\n\nn=2503\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\nindex_of_trueoutlier2 = np.where(unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2023-07-04 17:37:32,017:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nG.coords.shape\n\n(2503, 3)\n\n\n\n_W = G.W.toarray()\n_x = G.coords[:,0]\n_y = G.coords[:,1]\n_z = -G.coords[:,2]\n\n\nimport pandas as pd\n\n\n_df = pd.DataFrame({'x':_x,'y':_y,'z':_z})\n\n\nimport pickle\n\n\n_df = {'W':_W,'x':_x,'y':_y,'z':_z, 'fnoise':f+noise,'f' : f, 'noise': noise,'unif':unif,'index_of_trueoutlier2':index_of_trueoutlier2}\n\n\nsave_data(_df,'Bunny.pkl')\n\n\n_df\n\n{'W': array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n 'x': array([ 0.26815193, -0.58456893, -0.02730755, ...,  0.15397547,\n        -0.45056488, -0.29405249]),\n 'y': array([ 0.39314334,  0.63468595,  0.33280949, ...,  0.80205526,\n         0.6207154 , -0.40187451]),\n 'z': array([-0.13834514, -0.22438843,  0.08658215, ...,  0.33698514,\n         0.58353051, -0.08647485]),\n 'fnoise': array([-1.63569131,  0.49423926, -1.04026277, ..., -1.0694093 ,\n        -0.24395499,  0.41729667]),\n 'f': array([-1.54422488, -0.03596483, -0.93972715, ..., -0.01924028,\n        -0.02470869, -0.26266752]),\n 'noise': array([-0.09146643,  0.53020409, -0.10053563, ..., -1.05016902,\n        -0.2192463 ,  0.67996419]),\n 'unif': array([0., 0., 0., ..., 0., 0., 0.]),\n 'index_of_trueoutlier2': (array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,\n          240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,\n          397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,\n          569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,\n          858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,\n         1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,\n         1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,\n         1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,\n         1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,\n         2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,\n         2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)}\n\n\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\n_df1 = load_data('Bunny.pkl')\n\n\n_df = pd.DataFrame({'x': _df1['x'],'y':_df1['y'],'z':_df1['z'],'fnoise':_df1['fnoise'],'f':_df1['f'],'noise':_df1['noise']})\n\n\nunif = _df1['unif']\n\n\n_df1['index_of_trueoutlier2']\n\n(array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,\n         240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,\n         397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,\n         569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,\n         858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,\n        1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,\n        1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,\n        1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,\n        1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,\n        2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,\n        2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)\n\n\n\n# _df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})\n\n\noutlier_true_one_2 = unif.copy()\n\n\noutlier_true_one_2 = list(map(lambda x: -1 if x !=0  else 1,outlier_true_one_2))\n\n\n# pd.DataFrame(outlier_true_one_2).to_csv('bunny_outlier.csv')\n\n\nX = np.array(_df)[:,:4]\n\n\n\nGODE\n\n_W = _df1['W']\n\n\n_BUNNY = BUNNY(_df)\n\n\n_BUNNY.fit(sd=20,ref=10)\n\n\nlen(_BUNNY.f)\n\n2503\n\n\n\n2503*0.05\n\n125.15\n\n\n\noutlier_simul_one = (_BUNNY.df['Residual']**2).tolist()\n\n\n# outlier_simul_one = list(map(lambda x: -1 if x > 8.7 else 1,outlier_simul_one))\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 8.05 else 1,outlier_simul_one))\n\n\noutlier_simul_one.count(1)\n\n2378\n\n\n\noutlier_simul_one.count(-1)\n\n125\n\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.995\nRecall: 0.993\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\n\n_conf = Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.913\nPrecision: 0.955\nRecall: 0.953\nF1 Score: 0.954\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.942\nPrecision: 0.997\nRecall: 0.942\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF\n\n_df1 = load_data('Bunny.pkl')\n\n\noutlier_true_one_2 = pd.read_csv('bunny_outlier.csv').iloc[:,1].to_list()\n\n\n_df = pd.DataFrame({'x': _df1['x'],'y':_df1['y'],'z':_df1['z'],'fnoise':_df1['fnoise'],'f':_df1['f'],'noise':_df1['noise']})\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.974\nPrecision: 0.988\nRecall: 0.985\nF1 Score: 0.987\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\n# four = three.append(_conf.tab)\n\n\nAccuracy: 0.974\nPrecision: 0.988\nRecall: 0.985\nF1 Score: 0.987\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.992\nRecall: 0.939\nF1 Score: 0.965\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.982\nPrecision: 0.992\nRecall: 0.989\nF1 Score: 0.990\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.954\nPrecision: 0.977\nRecall: 0.974\nF1 Score: 0.976\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.979\nPrecision: 0.990\nRecall: 0.988\nF1 Score: 0.989\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\nnormal fix 안 해줘서 좀 다른듯\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=125\n)\n\n\nod.fit(_df[['x', 'y','fnoise']])\n\n\npreds = od.predict(\n    _df[['x', 'y','fnoise']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.827\nPrecision: 0.995\nRecall: 0.822\nF1 Score: 0.900\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.919\nPrecision: 0.958\nRecall: 0.956\nF1 Score: 0.957\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.955\nRecall: 0.953\nF1 Score: 0.954\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7853\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 5ms/step - loss: 1.8346\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8320\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8046\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8184\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8771\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8672\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8837\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8886\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9140\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8837\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9102\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9125\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0084\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9376\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9044\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9835\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9699\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9834\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0290\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9765\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9838\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9822\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0609\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0396\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0832\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0676\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0518\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0792\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1063\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1162\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0633\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0415\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1830\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1030\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0691\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1029\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0695\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1422\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1041\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1561\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1334\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1333\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0868\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0846\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1405\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1730\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1575\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1294\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1989\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1998\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1295\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2162\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2034\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1361\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2382\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2261\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1818\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2120\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2132\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2494\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2255\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2671\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2116\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2581\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2491\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2208\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2014\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2550\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2830\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2405\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3333\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2521\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2896\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3155\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3146\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2681\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2337\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2561\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2611\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3340\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2951\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2973\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3241\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3202\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2970\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2818\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2771\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3100\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2902\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3639\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2836\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4120\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3052\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2881\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3652\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3530\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3983\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3804\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3145\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3505\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3759\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3779\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4360\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3967\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4442\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3817\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4227\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3354\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3362\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3727\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4077\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4266\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4087\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3740\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4019\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4554\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4162\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4631\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4390\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3997\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4826\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3973\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4596\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4296\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4578\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5058\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4464\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4684\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4405\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4991\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4709\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4676\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4131\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4753\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5160\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4963\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4678\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4248\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5513\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4780\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4913\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4956\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4918\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4777\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5556\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4938\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4807\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5070\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5431\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4874\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5284\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5150\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5187\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5245\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5878\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5331\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5031\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5649\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.5189\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5311\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5879\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5670\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5522\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5572\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5563\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5327\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5742\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4747\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.5711\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5344\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5182\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4722\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5704\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6122\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5826\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5456\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5821\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5895\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.6114\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5628\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5592\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.6494\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5955\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6131\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6084\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5200\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5612\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5473\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 5ms/step - loss: 2.6558\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6821\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5944\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6211\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5937\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6623\n79/79 [==============================] - 0s 1ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 2 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 3:\n79/79 [==============================] - 0s 664us/step\n\nTesting for epoch 3 index 4:\n79/79 [==============================] - 0s 875us/step\n\nTesting for epoch 3 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n79/79 [==============================] - 0s 820us/step\n\nTesting for epoch 4 index 3:\n79/79 [==============================] - 0s 609us/step\n\nTesting for epoch 4 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 4 index 5:\n79/79 [==============================] - 0s 512us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 2:\n79/79 [==============================] - 0s 684us/step\n\nTesting for epoch 5 index 3:\n79/79 [==============================] - 0s 589us/step\n\nTesting for epoch 5 index 4:\n79/79 [==============================] - 0s 742us/step\n\nTesting for epoch 5 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n79/79 [==============================] - 0s 3ms/step\n\nTesting for epoch 6 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 6 index 4:\n79/79 [==============================] - 0s 3ms/step\n\nTesting for epoch 6 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 7 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 7 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 8 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 8 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 9 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 9 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 10 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 11 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 5:\n79/79 [==============================] - 0s 976us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 17 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 18 index 2:\n79/79 [==============================] - 0s 891us/step\n\nTesting for epoch 18 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 18 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 18 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 19 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 20 index 2:\n79/79 [==============================] - 0s 978us/step\n\nTesting for epoch 20 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 4:\n79/79 [==============================] - 0s 969us/step\n\nTesting for epoch 20 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 21 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2249\n16/16 [==============================] - 0s 1ms/step - loss: 1.3848\n16/16 [==============================] - 0s 2ms/step - loss: 1.5898\n16/16 [==============================] - 1s 2ms/step - loss: 1.6900\n16/16 [==============================] - 0s 1ms/step - loss: 1.7373\n16/16 [==============================] - 0s 2ms/step - loss: 1.7695\n16/16 [==============================] - 0s 1ms/step - loss: 1.7774\n16/16 [==============================] - 0s 1ms/step - loss: 1.7766\n16/16 [==============================] - 0s 1ms/step - loss: 1.7754\n16/16 [==============================] - 0s 1ms/step - loss: 1.7754\n\nTesting for epoch 21 index 3:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2249\n16/16 [==============================] - 0s 2ms/step - loss: 1.4195\n16/16 [==============================] - 0s 3ms/step - loss: 1.6365\n16/16 [==============================] - 0s 2ms/step - loss: 1.7426\n16/16 [==============================] - 0s 2ms/step - loss: 1.7927\n16/16 [==============================] - 0s 2ms/step - loss: 1.8275\n16/16 [==============================] - 0s 1ms/step - loss: 1.8359\n16/16 [==============================] - 0s 1ms/step - loss: 1.8351\n16/16 [==============================] - 0s 2ms/step - loss: 1.8338\n16/16 [==============================] - 0s 2ms/step - loss: 1.8338\n\nTesting for epoch 21 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.2255\n16/16 [==============================] - 0s 2ms/step - loss: 1.4083\n16/16 [==============================] - 0s 2ms/step - loss: 1.6229\n16/16 [==============================] - 0s 1ms/step - loss: 1.7262\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 2ms/step - loss: 1.8067\n16/16 [==============================] - 0s 2ms/step - loss: 1.8141\n16/16 [==============================] - 0s 1ms/step - loss: 1.8131\n16/16 [==============================] - 0s 2ms/step - loss: 1.8118\n16/16 [==============================] - 0s 2ms/step - loss: 1.8117\n\nTesting for epoch 21 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2193\n16/16 [==============================] - 0s 2ms/step - loss: 1.4150\n16/16 [==============================] - 0s 2ms/step - loss: 1.6347\n16/16 [==============================] - 0s 2ms/step - loss: 1.7387\n16/16 [==============================] - 0s 1ms/step - loss: 1.7855\n16/16 [==============================] - 0s 2ms/step - loss: 1.8169\n16/16 [==============================] - 0s 2ms/step - loss: 1.8234\n16/16 [==============================] - 0s 2ms/step - loss: 1.8219\n16/16 [==============================] - 0s 2ms/step - loss: 1.8205\n16/16 [==============================] - 0s 2ms/step - loss: 1.8205\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2173\n16/16 [==============================] - 0s 2ms/step - loss: 1.4357\n16/16 [==============================] - 0s 2ms/step - loss: 1.6634\n16/16 [==============================] - 0s 5ms/step - loss: 1.7700\n16/16 [==============================] - 0s 2ms/step - loss: 1.8171\n16/16 [==============================] - 0s 3ms/step - loss: 1.8488\n16/16 [==============================] - 0s 5ms/step - loss: 1.8558\n16/16 [==============================] - 0s 2ms/step - loss: 1.8544\n16/16 [==============================] - 0s 2ms/step - loss: 1.8529\n16/16 [==============================] - 0s 3ms/step - loss: 1.8529\n\nTesting for epoch 22 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2139\n16/16 [==============================] - 0s 2ms/step - loss: 1.4286\n16/16 [==============================] - 0s 2ms/step - loss: 1.6561\n16/16 [==============================] - 0s 1ms/step - loss: 1.7609\n16/16 [==============================] - 0s 4ms/step - loss: 1.8068\n16/16 [==============================] - 0s 2ms/step - loss: 1.8372\n16/16 [==============================] - 0s 6ms/step - loss: 1.8438\n16/16 [==============================] - 0s 2ms/step - loss: 1.8422\n16/16 [==============================] - 0s 2ms/step - loss: 1.8407\n16/16 [==============================] - 0s 2ms/step - loss: 1.8407\n\nTesting for epoch 22 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.2148\n16/16 [==============================] - 0s 1ms/step - loss: 1.4293\n16/16 [==============================] - 0s 2ms/step - loss: 1.6578\n16/16 [==============================] - 0s 4ms/step - loss: 1.7632\n16/16 [==============================] - 0s 2ms/step - loss: 1.8090\n16/16 [==============================] - 0s 2ms/step - loss: 1.8394\n16/16 [==============================] - 0s 2ms/step - loss: 1.8454\n16/16 [==============================] - 0s 5ms/step - loss: 1.8437\n16/16 [==============================] - 0s 2ms/step - loss: 1.8423\n16/16 [==============================] - 0s 2ms/step - loss: 1.8423\n\nTesting for epoch 22 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2181\n16/16 [==============================] - 0s 3ms/step - loss: 1.3837\n16/16 [==============================] - 0s 2ms/step - loss: 1.6049\n16/16 [==============================] - 0s 2ms/step - loss: 1.7082\n16/16 [==============================] - 0s 2ms/step - loss: 1.7544\n16/16 [==============================] - 0s 4ms/step - loss: 1.7860\n16/16 [==============================] - 0s 3ms/step - loss: 1.7928\n16/16 [==============================] - 0s 2ms/step - loss: 1.7913\n16/16 [==============================] - 0s 3ms/step - loss: 1.7897\n16/16 [==============================] - 0s 2ms/step - loss: 1.7897\n\nTesting for epoch 22 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2083\n16/16 [==============================] - 0s 991us/step - loss: 1.4684\n16/16 [==============================] - 0s 873us/step - loss: 1.7111\n16/16 [==============================] - 0s 2ms/step - loss: 1.8243\n16/16 [==============================] - 0s 820us/step - loss: 1.8730\n16/16 [==============================] - 0s 947us/step - loss: 1.9051\n16/16 [==============================] - 0s 771us/step - loss: 1.9109\n16/16 [==============================] - 0s 1ms/step - loss: 1.9087\n16/16 [==============================] - 0s 1ms/step - loss: 1.9069\n16/16 [==============================] - 0s 839us/step - loss: 1.9069\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n79/79 [==============================] - 0s 564us/step\n16/16 [==============================] - 0s 872us/step - loss: 0.2068\n16/16 [==============================] - 0s 929us/step - loss: 1.4438\n16/16 [==============================] - 0s 859us/step - loss: 1.6817\n16/16 [==============================] - 0s 829us/step - loss: 1.7917\n16/16 [==============================] - 0s 1ms/step - loss: 1.8384\n16/16 [==============================] - 0s 672us/step - loss: 1.8677\n16/16 [==============================] - 0s 2ms/step - loss: 1.8721\n16/16 [==============================] - 0s 3ms/step - loss: 1.8696\n16/16 [==============================] - 0s 1ms/step - loss: 1.8677\n16/16 [==============================] - 0s 942us/step - loss: 1.8676\n\nTesting for epoch 23 index 2:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 827us/step - loss: 0.2075\n16/16 [==============================] - 0s 724us/step - loss: 1.4278\n16/16 [==============================] - 0s 781us/step - loss: 1.6611\n16/16 [==============================] - 0s 855us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.8137\n16/16 [==============================] - 0s 689us/step - loss: 1.8419\n16/16 [==============================] - 0s 846us/step - loss: 1.8465\n16/16 [==============================] - 0s 826us/step - loss: 1.8442\n16/16 [==============================] - 0s 818us/step - loss: 1.8425\n16/16 [==============================] - 0s 818us/step - loss: 1.8425\n\nTesting for epoch 23 index 3:\n79/79 [==============================] - 0s 843us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2072\n16/16 [==============================] - 0s 1ms/step - loss: 1.4404\n16/16 [==============================] - 0s 2ms/step - loss: 1.6810\n16/16 [==============================] - 0s 5ms/step - loss: 1.7908\n16/16 [==============================] - 0s 1ms/step - loss: 1.8406\n16/16 [==============================] - 0s 1ms/step - loss: 1.8710\n16/16 [==============================] - 0s 1ms/step - loss: 1.8762\n16/16 [==============================] - 0s 2ms/step - loss: 1.8739\n16/16 [==============================] - 0s 2ms/step - loss: 1.8721\n16/16 [==============================] - 0s 1ms/step - loss: 1.8720\n\nTesting for epoch 23 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2005\n16/16 [==============================] - 0s 4ms/step - loss: 1.4690\n16/16 [==============================] - 0s 2ms/step - loss: 1.7149\n16/16 [==============================] - 0s 1ms/step - loss: 1.8240\n16/16 [==============================] - 0s 1ms/step - loss: 1.8711\n16/16 [==============================] - 0s 2ms/step - loss: 1.8977\n16/16 [==============================] - 0s 2ms/step - loss: 1.9010\n16/16 [==============================] - 0s 2ms/step - loss: 1.8979\n16/16 [==============================] - 0s 2ms/step - loss: 1.8961\n16/16 [==============================] - 0s 2ms/step - loss: 1.8960\n\nTesting for epoch 23 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1965\n16/16 [==============================] - 0s 933us/step - loss: 1.4857\n16/16 [==============================] - 0s 2ms/step - loss: 1.7374\n16/16 [==============================] - 0s 1ms/step - loss: 1.8489\n16/16 [==============================] - 0s 1ms/step - loss: 1.8958\n16/16 [==============================] - 0s 1ms/step - loss: 1.9208\n16/16 [==============================] - 0s 2ms/step - loss: 1.9232\n16/16 [==============================] - 0s 1ms/step - loss: 1.9199\n16/16 [==============================] - 0s 2ms/step - loss: 1.9179\n16/16 [==============================] - 0s 2ms/step - loss: 1.9179\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n79/79 [==============================] - 0s 934us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1949\n16/16 [==============================] - 0s 2ms/step - loss: 1.5125\n16/16 [==============================] - 0s 1ms/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.8843\n16/16 [==============================] - 0s 1ms/step - loss: 1.9321\n16/16 [==============================] - 0s 1ms/step - loss: 1.9573\n16/16 [==============================] - 0s 934us/step - loss: 1.9592\n16/16 [==============================] - 0s 2ms/step - loss: 1.9558\n16/16 [==============================] - 0s 2ms/step - loss: 1.9537\n16/16 [==============================] - 0s 1ms/step - loss: 1.9537\n\nTesting for epoch 24 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1959\n16/16 [==============================] - 0s 1ms/step - loss: 1.4640\n16/16 [==============================] - 0s 2ms/step - loss: 1.7067\n16/16 [==============================] - 0s 2ms/step - loss: 1.8128\n16/16 [==============================] - 0s 2ms/step - loss: 1.8585\n16/16 [==============================] - 0s 2ms/step - loss: 1.8822\n16/16 [==============================] - 0s 970us/step - loss: 1.8835\n16/16 [==============================] - 0s 1ms/step - loss: 1.8799\n16/16 [==============================] - 0s 2ms/step - loss: 1.8778\n16/16 [==============================] - 0s 1ms/step - loss: 1.8777\n\nTesting for epoch 24 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1986\n16/16 [==============================] - 0s 1ms/step - loss: 1.4867\n16/16 [==============================] - 0s 4ms/step - loss: 1.7359\n16/16 [==============================] - 0s 3ms/step - loss: 1.8473\n16/16 [==============================] - 0s 2ms/step - loss: 1.8954\n16/16 [==============================] - 0s 2ms/step - loss: 1.9193\n16/16 [==============================] - 0s 2ms/step - loss: 1.9209\n16/16 [==============================] - 0s 1ms/step - loss: 1.9173\n16/16 [==============================] - 0s 2ms/step - loss: 1.9152\n16/16 [==============================] - 0s 1ms/step - loss: 1.9151\n\nTesting for epoch 24 index 4:\n79/79 [==============================] - 0s 862us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1967\n16/16 [==============================] - 0s 1ms/step - loss: 1.4806\n16/16 [==============================] - 0s 2ms/step - loss: 1.7273\n16/16 [==============================] - 0s 1ms/step - loss: 1.8367\n16/16 [==============================] - 0s 2ms/step - loss: 1.8844\n16/16 [==============================] - 0s 2ms/step - loss: 1.9072\n16/16 [==============================] - 0s 1ms/step - loss: 1.9083\n16/16 [==============================] - 0s 1ms/step - loss: 1.9047\n16/16 [==============================] - 0s 2ms/step - loss: 1.9027\n16/16 [==============================] - 0s 2ms/step - loss: 1.9027\n\nTesting for epoch 24 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1922\n16/16 [==============================] - 0s 1ms/step - loss: 1.5153\n16/16 [==============================] - 0s 1ms/step - loss: 1.7681\n16/16 [==============================] - 0s 1ms/step - loss: 1.8780\n16/16 [==============================] - 0s 1ms/step - loss: 1.9241\n16/16 [==============================] - 0s 1ms/step - loss: 1.9447\n16/16 [==============================] - 0s 2ms/step - loss: 1.9445\n16/16 [==============================] - 0s 1ms/step - loss: 1.9402\n16/16 [==============================] - 0s 954us/step - loss: 1.9381\n16/16 [==============================] - 0s 1ms/step - loss: 1.9380\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.1929\n16/16 [==============================] - 0s 1ms/step - loss: 1.4627\n16/16 [==============================] - 0s 1ms/step - loss: 1.7036\n16/16 [==============================] - 0s 953us/step - loss: 1.8077\n16/16 [==============================] - 0s 1000us/step - loss: 1.8516\n16/16 [==============================] - 0s 2ms/step - loss: 1.8687\n16/16 [==============================] - 0s 1ms/step - loss: 1.8670\n16/16 [==============================] - 0s 4ms/step - loss: 1.8625\n16/16 [==============================] - 0s 3ms/step - loss: 1.8602\n16/16 [==============================] - 0s 2ms/step - loss: 1.8602\n\nTesting for epoch 25 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.1918\n16/16 [==============================] - 0s 1ms/step - loss: 1.5117\n16/16 [==============================] - 0s 2ms/step - loss: 1.7683\n16/16 [==============================] - 0s 1ms/step - loss: 1.8769\n16/16 [==============================] - 0s 2ms/step - loss: 1.9240\n16/16 [==============================] - 0s 2ms/step - loss: 1.9418\n16/16 [==============================] - 0s 1ms/step - loss: 1.9400\n16/16 [==============================] - 0s 1ms/step - loss: 1.9352\n16/16 [==============================] - 0s 2ms/step - loss: 1.9327\n16/16 [==============================] - 0s 2ms/step - loss: 1.9326\n\nTesting for epoch 25 index 3:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1905\n16/16 [==============================] - 0s 1ms/step - loss: 1.5434\n16/16 [==============================] - 0s 1ms/step - loss: 1.8096\n16/16 [==============================] - 0s 1ms/step - loss: 1.9206\n16/16 [==============================] - 0s 1ms/step - loss: 1.9683\n16/16 [==============================] - 0s 5ms/step - loss: 1.9856\n16/16 [==============================] - 0s 2ms/step - loss: 1.9832\n16/16 [==============================] - 0s 2ms/step - loss: 1.9781\n16/16 [==============================] - 0s 4ms/step - loss: 1.9756\n16/16 [==============================] - 0s 2ms/step - loss: 1.9755\n\nTesting for epoch 25 index 4:\n79/79 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 856us/step - loss: 0.1849\n16/16 [==============================] - 0s 898us/step - loss: 1.5488\n16/16 [==============================] - 0s 842us/step - loss: 1.8135\n16/16 [==============================] - 0s 817us/step - loss: 1.9221\n16/16 [==============================] - 0s 797us/step - loss: 1.9682\n16/16 [==============================] - 0s 795us/step - loss: 1.9825\n16/16 [==============================] - 0s 833us/step - loss: 1.9783\n16/16 [==============================] - 0s 813us/step - loss: 1.9727\n16/16 [==============================] - 0s 792us/step - loss: 1.9702\n16/16 [==============================] - 0s 794us/step - loss: 1.9701\n\nTesting for epoch 25 index 5:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 817us/step - loss: 0.1847\n16/16 [==============================] - 0s 809us/step - loss: 1.5567\n16/16 [==============================] - 0s 778us/step - loss: 1.8307\n16/16 [==============================] - 0s 778us/step - loss: 1.9453\n16/16 [==============================] - 0s 771us/step - loss: 1.9954\n16/16 [==============================] - 0s 826us/step - loss: 2.0152\n16/16 [==============================] - 0s 802us/step - loss: 2.0137\n16/16 [==============================] - 0s 813us/step - loss: 2.0085\n16/16 [==============================] - 0s 779us/step - loss: 2.0058\n16/16 [==============================] - 0s 769us/step - loss: 2.0056\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n79/79 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1844\n16/16 [==============================] - 0s 807us/step - loss: 1.5198\n16/16 [==============================] - 0s 785us/step - loss: 1.7813\n16/16 [==============================] - 0s 804us/step - loss: 1.8883\n16/16 [==============================] - 0s 778us/step - loss: 1.9336\n16/16 [==============================] - 0s 799us/step - loss: 1.9494\n16/16 [==============================] - 0s 789us/step - loss: 1.9453\n16/16 [==============================] - 0s 816us/step - loss: 1.9398\n16/16 [==============================] - 0s 785us/step - loss: 1.9373\n16/16 [==============================] - 0s 785us/step - loss: 1.9372\n\nTesting for epoch 26 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 806us/step - loss: 0.1859\n16/16 [==============================] - 0s 815us/step - loss: 1.5434\n16/16 [==============================] - 0s 803us/step - loss: 1.8104\n16/16 [==============================] - 0s 770us/step - loss: 1.9219\n16/16 [==============================] - 0s 847us/step - loss: 1.9699\n16/16 [==============================] - 0s 794us/step - loss: 1.9883\n16/16 [==============================] - 0s 779us/step - loss: 1.9855\n16/16 [==============================] - 0s 801us/step - loss: 1.9802\n16/16 [==============================] - 0s 835us/step - loss: 1.9775\n16/16 [==============================] - 0s 1ms/step - loss: 1.9773\n\nTesting for epoch 26 index 3:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1817\n16/16 [==============================] - 0s 1ms/step - loss: 1.5762\n16/16 [==============================] - 0s 1ms/step - loss: 1.8483\n16/16 [==============================] - 0s 1ms/step - loss: 1.9610\n16/16 [==============================] - 0s 781us/step - loss: 2.0079\n16/16 [==============================] - 0s 1ms/step - loss: 2.0228\n16/16 [==============================] - 0s 1ms/step - loss: 2.0191\n16/16 [==============================] - 0s 1ms/step - loss: 2.0135\n16/16 [==============================] - 0s 771us/step - loss: 2.0108\n16/16 [==============================] - 0s 785us/step - loss: 2.0106\n\nTesting for epoch 26 index 4:\n79/79 [==============================] - 0s 749us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1829\n16/16 [==============================] - 0s 1ms/step - loss: 1.5509\n16/16 [==============================] - 0s 808us/step - loss: 1.8163\n16/16 [==============================] - 0s 782us/step - loss: 1.9243\n16/16 [==============================] - 0s 783us/step - loss: 1.9681\n16/16 [==============================] - 0s 782us/step - loss: 1.9796\n16/16 [==============================] - 0s 785us/step - loss: 1.9733\n16/16 [==============================] - 0s 789us/step - loss: 1.9671\n16/16 [==============================] - 0s 795us/step - loss: 1.9644\n16/16 [==============================] - 0s 797us/step - loss: 1.9643\n\nTesting for epoch 26 index 5:\n79/79 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 834us/step - loss: 0.1804\n16/16 [==============================] - 0s 785us/step - loss: 1.5986\n16/16 [==============================] - 0s 791us/step - loss: 1.8789\n16/16 [==============================] - 0s 810us/step - loss: 1.9937\n16/16 [==============================] - 0s 786us/step - loss: 2.0401\n16/16 [==============================] - 0s 775us/step - loss: 2.0543\n16/16 [==============================] - 0s 813us/step - loss: 2.0491\n16/16 [==============================] - 0s 841us/step - loss: 2.0430\n16/16 [==============================] - 0s 787us/step - loss: 2.0402\n16/16 [==============================] - 0s 802us/step - loss: 2.0401\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 980us/step - loss: 0.1780\n16/16 [==============================] - 0s 1ms/step - loss: 1.5897\n16/16 [==============================] - 0s 1ms/step - loss: 1.8713\n16/16 [==============================] - 0s 1ms/step - loss: 1.9847\n16/16 [==============================] - 0s 785us/step - loss: 2.0309\n16/16 [==============================] - 0s 800us/step - loss: 2.0444\n16/16 [==============================] - 0s 801us/step - loss: 2.0382\n16/16 [==============================] - 0s 800us/step - loss: 2.0316\n16/16 [==============================] - 0s 775us/step - loss: 2.0287\n16/16 [==============================] - 0s 772us/step - loss: 2.0286\n\nTesting for epoch 27 index 2:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1847\n16/16 [==============================] - 0s 776us/step - loss: 1.5399\n16/16 [==============================] - 0s 808us/step - loss: 1.8078\n16/16 [==============================] - 0s 805us/step - loss: 1.9151\n16/16 [==============================] - 0s 1ms/step - loss: 1.9593\n16/16 [==============================] - 0s 774us/step - loss: 1.9706\n16/16 [==============================] - 0s 922us/step - loss: 1.9641\n16/16 [==============================] - 0s 1ms/step - loss: 1.9579\n16/16 [==============================] - 0s 1ms/step - loss: 1.9552\n16/16 [==============================] - 0s 1ms/step - loss: 1.9551\n\nTesting for epoch 27 index 3:\n79/79 [==============================] - 0s 609us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1802\n16/16 [==============================] - 0s 1ms/step - loss: 1.5996\n16/16 [==============================] - 0s 840us/step - loss: 1.8825\n16/16 [==============================] - 0s 865us/step - loss: 1.9942\n16/16 [==============================] - 0s 893us/step - loss: 2.0396\n16/16 [==============================] - 0s 707us/step - loss: 2.0499\n16/16 [==============================] - 0s 796us/step - loss: 2.0429\n16/16 [==============================] - 0s 686us/step - loss: 2.0363\n16/16 [==============================] - 0s 703us/step - loss: 2.0335\n16/16 [==============================] - 0s 713us/step - loss: 2.0335\n\nTesting for epoch 27 index 4:\n79/79 [==============================] - 0s 763us/step\n16/16 [==============================] - 0s 845us/step - loss: 0.1746\n16/16 [==============================] - 0s 1ms/step - loss: 1.6245\n16/16 [==============================] - 0s 1ms/step - loss: 1.9167\n16/16 [==============================] - 0s 796us/step - loss: 2.0309\n16/16 [==============================] - 0s 813us/step - loss: 2.0769\n16/16 [==============================] - 0s 803us/step - loss: 2.0875\n16/16 [==============================] - 0s 811us/step - loss: 2.0801\n16/16 [==============================] - 0s 796us/step - loss: 2.0733\n16/16 [==============================] - 0s 815us/step - loss: 2.0704\n16/16 [==============================] - 0s 790us/step - loss: 2.0703\n\nTesting for epoch 27 index 5:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.1721\n16/16 [==============================] - 0s 817us/step - loss: 1.6490\n16/16 [==============================] - 0s 829us/step - loss: 1.9488\n16/16 [==============================] - 0s 804us/step - loss: 2.0650\n16/16 [==============================] - 0s 814us/step - loss: 2.1109\n16/16 [==============================] - 0s 828us/step - loss: 2.1218\n16/16 [==============================] - 0s 836us/step - loss: 2.1139\n16/16 [==============================] - 0s 2ms/step - loss: 2.1069\n16/16 [==============================] - 0s 2ms/step - loss: 2.1038\n16/16 [==============================] - 0s 2ms/step - loss: 2.1037\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 842us/step - loss: 0.1745\n16/16 [==============================] - 0s 841us/step - loss: 1.6265\n16/16 [==============================] - 0s 856us/step - loss: 1.9218\n16/16 [==============================] - 0s 844us/step - loss: 2.0351\n16/16 [==============================] - 0s 870us/step - loss: 2.0786\n16/16 [==============================] - 0s 884us/step - loss: 2.0882\n16/16 [==============================] - 0s 929us/step - loss: 2.0794\n16/16 [==============================] - 0s 911us/step - loss: 2.0722\n16/16 [==============================] - 0s 983us/step - loss: 2.0691\n16/16 [==============================] - 0s 924us/step - loss: 2.0690\n\nTesting for epoch 28 index 2:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1718\n16/16 [==============================] - 0s 4ms/step - loss: 1.6199\n16/16 [==============================] - 0s 2ms/step - loss: 1.9153\n16/16 [==============================] - 0s 1ms/step - loss: 2.0279\n16/16 [==============================] - 0s 2ms/step - loss: 2.0710\n16/16 [==============================] - 0s 2ms/step - loss: 2.0805\n16/16 [==============================] - 0s 1ms/step - loss: 2.0718\n16/16 [==============================] - 0s 2ms/step - loss: 2.0644\n16/16 [==============================] - 0s 2ms/step - loss: 2.0613\n16/16 [==============================] - 0s 2ms/step - loss: 2.0612\n\nTesting for epoch 28 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1764\n16/16 [==============================] - 0s 2ms/step - loss: 1.5756\n16/16 [==============================] - 0s 992us/step - loss: 1.8577\n16/16 [==============================] - 0s 1ms/step - loss: 1.9628\n16/16 [==============================] - 0s 4ms/step - loss: 2.0023\n16/16 [==============================] - 0s 1ms/step - loss: 2.0074\n16/16 [==============================] - 0s 2ms/step - loss: 1.9974\n16/16 [==============================] - 0s 2ms/step - loss: 1.9900\n16/16 [==============================] - 0s 2ms/step - loss: 1.9869\n16/16 [==============================] - 0s 2ms/step - loss: 1.9867\n\nTesting for epoch 28 index 4:\n79/79 [==============================] - 0s 897us/step\n16/16 [==============================] - 0s 991us/step - loss: 0.1714\n16/16 [==============================] - 0s 2ms/step - loss: 1.5748\n16/16 [==============================] - 0s 2ms/step - loss: 1.8565\n16/16 [==============================] - 0s 1ms/step - loss: 1.9601\n16/16 [==============================] - 0s 2ms/step - loss: 1.9993\n16/16 [==============================] - 0s 2ms/step - loss: 2.0048\n16/16 [==============================] - 0s 2ms/step - loss: 1.9951\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 1ms/step - loss: 1.9850\n16/16 [==============================] - 0s 2ms/step - loss: 1.9849\n\nTesting for epoch 28 index 5:\n79/79 [==============================] - 0s 947us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1700\n16/16 [==============================] - 0s 1ms/step - loss: 1.6374\n16/16 [==============================] - 0s 1ms/step - loss: 1.9381\n16/16 [==============================] - 0s 1ms/step - loss: 2.0497\n16/16 [==============================] - 0s 1ms/step - loss: 2.0926\n16/16 [==============================] - 0s 1ms/step - loss: 2.0984\n16/16 [==============================] - 0s 1ms/step - loss: 2.0886\n16/16 [==============================] - 0s 1ms/step - loss: 2.0809\n16/16 [==============================] - 0s 1ms/step - loss: 2.0778\n16/16 [==============================] - 0s 2ms/step - loss: 2.0776\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n79/79 [==============================] - 0s 878us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1688\n16/16 [==============================] - 0s 2ms/step - loss: 1.6160\n16/16 [==============================] - 0s 2ms/step - loss: 1.9106\n16/16 [==============================] - 0s 1ms/step - loss: 2.0177\n16/16 [==============================] - 0s 1ms/step - loss: 2.0581\n16/16 [==============================] - 0s 1ms/step - loss: 2.0626\n16/16 [==============================] - 0s 2ms/step - loss: 2.0522\n16/16 [==============================] - 0s 1ms/step - loss: 2.0446\n16/16 [==============================] - 0s 1ms/step - loss: 2.0417\n16/16 [==============================] - 0s 3ms/step - loss: 2.0417\n\nTesting for epoch 29 index 2:\n79/79 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1690\n16/16 [==============================] - 0s 1ms/step - loss: 1.6719\n16/16 [==============================] - 0s 1ms/step - loss: 1.9800\n16/16 [==============================] - 0s 2ms/step - loss: 2.0915\n16/16 [==============================] - 0s 1ms/step - loss: 2.1340\n16/16 [==============================] - 0s 1ms/step - loss: 2.1376\n16/16 [==============================] - 0s 1ms/step - loss: 2.1260\n16/16 [==============================] - 0s 1ms/step - loss: 2.1178\n16/16 [==============================] - 0s 964us/step - loss: 2.1145\n16/16 [==============================] - 0s 1ms/step - loss: 2.1144\n\nTesting for epoch 29 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1690\n16/16 [==============================] - 0s 2ms/step - loss: 1.5813\n16/16 [==============================] - 0s 1ms/step - loss: 1.8637\n16/16 [==============================] - 0s 1ms/step - loss: 1.9638\n16/16 [==============================] - 0s 2ms/step - loss: 2.0025\n16/16 [==============================] - 0s 2ms/step - loss: 2.0058\n16/16 [==============================] - 0s 2ms/step - loss: 1.9953\n16/16 [==============================] - 0s 2ms/step - loss: 1.9879\n16/16 [==============================] - 0s 2ms/step - loss: 1.9850\n16/16 [==============================] - 0s 1ms/step - loss: 1.9849\n\nTesting for epoch 29 index 4:\n79/79 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1653\n16/16 [==============================] - 0s 2ms/step - loss: 1.7200\n16/16 [==============================] - 0s 2ms/step - loss: 2.0423\n16/16 [==============================] - 0s 1ms/step - loss: 2.1567\n16/16 [==============================] - 0s 1ms/step - loss: 2.2005\n16/16 [==============================] - 0s 1ms/step - loss: 2.2035\n16/16 [==============================] - 0s 1ms/step - loss: 2.1900\n16/16 [==============================] - 0s 1ms/step - loss: 2.1809\n16/16 [==============================] - 0s 2ms/step - loss: 2.1772\n16/16 [==============================] - 0s 3ms/step - loss: 2.1770\n\nTesting for epoch 29 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1656\n16/16 [==============================] - 0s 2ms/step - loss: 1.6312\n16/16 [==============================] - 0s 1ms/step - loss: 1.9296\n16/16 [==============================] - 0s 1ms/step - loss: 2.0334\n16/16 [==============================] - 0s 1ms/step - loss: 2.0736\n16/16 [==============================] - 0s 1ms/step - loss: 2.0773\n16/16 [==============================] - 0s 1ms/step - loss: 2.0655\n16/16 [==============================] - 0s 2ms/step - loss: 2.0575\n16/16 [==============================] - 0s 2ms/step - loss: 2.0543\n16/16 [==============================] - 0s 2ms/step - loss: 2.0542\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1641\n16/16 [==============================] - 0s 1ms/step - loss: 1.6943\n16/16 [==============================] - 0s 1ms/step - loss: 2.0115\n16/16 [==============================] - 0s 1ms/step - loss: 2.1206\n16/16 [==============================] - 0s 2ms/step - loss: 2.1614\n16/16 [==============================] - 0s 1ms/step - loss: 2.1623\n16/16 [==============================] - 0s 933us/step - loss: 2.1487\n16/16 [==============================] - 0s 2ms/step - loss: 2.1400\n16/16 [==============================] - 0s 2ms/step - loss: 2.1366\n16/16 [==============================] - 0s 1ms/step - loss: 2.1364\n\nTesting for epoch 30 index 2:\n79/79 [==============================] - 0s 864us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1658\n16/16 [==============================] - 0s 1ms/step - loss: 1.6611\n16/16 [==============================] - 0s 1ms/step - loss: 1.9702\n16/16 [==============================] - 0s 1ms/step - loss: 2.0763\n16/16 [==============================] - 0s 1ms/step - loss: 2.1169\n16/16 [==============================] - 0s 1ms/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.1036\n16/16 [==============================] - 0s 1ms/step - loss: 2.0951\n16/16 [==============================] - 0s 1ms/step - loss: 2.0918\n16/16 [==============================] - 0s 2ms/step - loss: 2.0917\n\nTesting for epoch 30 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1678\n16/16 [==============================] - 0s 2ms/step - loss: 1.6270\n16/16 [==============================] - 0s 2ms/step - loss: 1.9300\n16/16 [==============================] - 0s 2ms/step - loss: 2.0320\n16/16 [==============================] - 0s 2ms/step - loss: 2.0718\n16/16 [==============================] - 0s 2ms/step - loss: 2.0723\n16/16 [==============================] - 0s 1ms/step - loss: 2.0596\n16/16 [==============================] - 0s 2ms/step - loss: 2.0514\n16/16 [==============================] - 0s 2ms/step - loss: 2.0481\n16/16 [==============================] - 0s 2ms/step - loss: 2.0479\n\nTesting for epoch 30 index 4:\n79/79 [==============================] - 0s 932us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1629\n16/16 [==============================] - 0s 2ms/step - loss: 1.6611\n16/16 [==============================] - 0s 2ms/step - loss: 1.9644\n16/16 [==============================] - 0s 2ms/step - loss: 2.0613\n16/16 [==============================] - 0s 1ms/step - loss: 2.0966\n16/16 [==============================] - 0s 3ms/step - loss: 2.0905\n16/16 [==============================] - 0s 2ms/step - loss: 2.0735\n16/16 [==============================] - 0s 1ms/step - loss: 2.0643\n16/16 [==============================] - 0s 2ms/step - loss: 2.0611\n16/16 [==============================] - 0s 1ms/step - loss: 2.0611\n\nTesting for epoch 30 index 5:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1580\n16/16 [==============================] - 0s 1ms/step - loss: 1.7343\n16/16 [==============================] - 0s 926us/step - loss: 2.0589\n16/16 [==============================] - 0s 3ms/step - loss: 2.1636\n16/16 [==============================] - 0s 2ms/step - loss: 2.2026\n16/16 [==============================] - 0s 960us/step - loss: 2.1988\n16/16 [==============================] - 0s 2ms/step - loss: 2.1826\n16/16 [==============================] - 0s 2ms/step - loss: 2.1732\n16/16 [==============================] - 0s 2ms/step - loss: 2.1697\n16/16 [==============================] - 0s 2ms/step - loss: 2.1695\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1629\n16/16 [==============================] - 0s 2ms/step - loss: 1.6340\n16/16 [==============================] - 0s 2ms/step - loss: 1.9369\n16/16 [==============================] - 0s 4ms/step - loss: 2.0366\n16/16 [==============================] - 0s 1ms/step - loss: 2.0749\n16/16 [==============================] - 0s 2ms/step - loss: 2.0736\n16/16 [==============================] - 0s 1ms/step - loss: 2.0595\n16/16 [==============================] - 0s 2ms/step - loss: 2.0507\n16/16 [==============================] - 0s 1ms/step - loss: 2.0472\n16/16 [==============================] - 0s 2ms/step - loss: 2.0470\n\nTesting for epoch 31 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1602\n16/16 [==============================] - 0s 2ms/step - loss: 1.6604\n16/16 [==============================] - 0s 1ms/step - loss: 1.9645\n16/16 [==============================] - 0s 2ms/step - loss: 2.0619\n16/16 [==============================] - 0s 1ms/step - loss: 2.0977\n16/16 [==============================] - 0s 2ms/step - loss: 2.0922\n16/16 [==============================] - 0s 1ms/step - loss: 2.0766\n16/16 [==============================] - 0s 2ms/step - loss: 2.0677\n16/16 [==============================] - 0s 2ms/step - loss: 2.0645\n16/16 [==============================] - 0s 2ms/step - loss: 2.0644\n\nTesting for epoch 31 index 3:\n79/79 [==============================] - 0s 814us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1592\n16/16 [==============================] - 0s 3ms/step - loss: 1.7109\n16/16 [==============================] - 0s 2ms/step - loss: 2.0223\n16/16 [==============================] - 0s 1ms/step - loss: 2.1224\n16/16 [==============================] - 0s 1ms/step - loss: 2.1597\n16/16 [==============================] - 0s 977us/step - loss: 2.1517\n16/16 [==============================] - 0s 961us/step - loss: 2.1344\n16/16 [==============================] - 0s 2ms/step - loss: 2.1248\n16/16 [==============================] - 0s 1ms/step - loss: 2.1212\n16/16 [==============================] - 0s 1ms/step - loss: 2.1210\n\nTesting for epoch 31 index 4:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 975us/step - loss: 0.1591\n16/16 [==============================] - 0s 1ms/step - loss: 1.7203\n16/16 [==============================] - 0s 1ms/step - loss: 2.0343\n16/16 [==============================] - 0s 4ms/step - loss: 2.1337\n16/16 [==============================] - 0s 1ms/step - loss: 2.1707\n16/16 [==============================] - 0s 2ms/step - loss: 2.1621\n16/16 [==============================] - 0s 2ms/step - loss: 2.1441\n16/16 [==============================] - 0s 2ms/step - loss: 2.1342\n16/16 [==============================] - 0s 1ms/step - loss: 2.1305\n16/16 [==============================] - 0s 1ms/step - loss: 2.1303\n\nTesting for epoch 31 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1568\n16/16 [==============================] - 0s 2ms/step - loss: 1.7400\n16/16 [==============================] - 0s 2ms/step - loss: 2.0591\n16/16 [==============================] - 0s 2ms/step - loss: 2.1605\n16/16 [==============================] - 0s 2ms/step - loss: 2.1977\n16/16 [==============================] - 0s 2ms/step - loss: 2.1903\n16/16 [==============================] - 0s 1ms/step - loss: 2.1724\n16/16 [==============================] - 0s 2ms/step - loss: 2.1626\n16/16 [==============================] - 0s 2ms/step - loss: 2.1590\n16/16 [==============================] - 0s 1ms/step - loss: 2.1589\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n79/79 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1585\n16/16 [==============================] - 0s 2ms/step - loss: 1.7001\n16/16 [==============================] - 0s 1ms/step - loss: 2.0088\n16/16 [==============================] - 0s 2ms/step - loss: 2.1060\n16/16 [==============================] - 0s 2ms/step - loss: 2.1420\n16/16 [==============================] - 0s 2ms/step - loss: 2.1348\n16/16 [==============================] - 0s 2ms/step - loss: 2.1169\n16/16 [==============================] - 0s 2ms/step - loss: 2.1072\n16/16 [==============================] - 0s 4ms/step - loss: 2.1037\n16/16 [==============================] - 0s 2ms/step - loss: 2.1035\n\nTesting for epoch 32 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 899us/step - loss: 0.1574\n16/16 [==============================] - 0s 1ms/step - loss: 1.7923\n16/16 [==============================] - 0s 1ms/step - loss: 2.1196\n16/16 [==============================] - 0s 2ms/step - loss: 2.2226\n16/16 [==============================] - 0s 990us/step - loss: 2.2597\n16/16 [==============================] - 0s 1ms/step - loss: 2.2503\n16/16 [==============================] - 0s 1ms/step - loss: 2.2299\n16/16 [==============================] - 0s 962us/step - loss: 2.2193\n16/16 [==============================] - 0s 1ms/step - loss: 2.2156\n16/16 [==============================] - 0s 996us/step - loss: 2.2155\n\nTesting for epoch 32 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 7ms/step - loss: 0.1557\n16/16 [==============================] - 0s 2ms/step - loss: 1.7954\n16/16 [==============================] - 0s 2ms/step - loss: 2.1247\n16/16 [==============================] - 0s 2ms/step - loss: 2.2272\n16/16 [==============================] - 0s 2ms/step - loss: 2.2635\n16/16 [==============================] - 0s 2ms/step - loss: 2.2531\n16/16 [==============================] - 0s 2ms/step - loss: 2.2322\n16/16 [==============================] - 0s 2ms/step - loss: 2.2215\n16/16 [==============================] - 0s 2ms/step - loss: 2.2178\n16/16 [==============================] - 0s 2ms/step - loss: 2.2177\n\nTesting for epoch 32 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1537\n16/16 [==============================] - 0s 1ms/step - loss: 1.7869\n16/16 [==============================] - 0s 1ms/step - loss: 2.1168\n16/16 [==============================] - 0s 1ms/step - loss: 2.2210\n16/16 [==============================] - 0s 1ms/step - loss: 2.2596\n16/16 [==============================] - 0s 1ms/step - loss: 2.2526\n16/16 [==============================] - 0s 992us/step - loss: 2.2329\n16/16 [==============================] - 0s 969us/step - loss: 2.2226\n16/16 [==============================] - 0s 1ms/step - loss: 2.2187\n16/16 [==============================] - 0s 1ms/step - loss: 2.2184\n\nTesting for epoch 32 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1510\n16/16 [==============================] - 0s 2ms/step - loss: 1.7654\n16/16 [==============================] - 0s 1ms/step - loss: 2.0879\n16/16 [==============================] - 0s 2ms/step - loss: 2.1879\n16/16 [==============================] - 0s 1ms/step - loss: 2.2230\n16/16 [==============================] - 0s 1ms/step - loss: 2.2123\n16/16 [==============================] - 0s 1ms/step - loss: 2.1914\n16/16 [==============================] - 0s 1ms/step - loss: 2.1809\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 1ms/step - loss: 2.1768\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1555\n16/16 [==============================] - 0s 1ms/step - loss: 1.7559\n16/16 [==============================] - 0s 2ms/step - loss: 2.0784\n16/16 [==============================] - 0s 2ms/step - loss: 2.1784\n16/16 [==============================] - 0s 4ms/step - loss: 2.2136\n16/16 [==============================] - 0s 2ms/step - loss: 2.2035\n16/16 [==============================] - 0s 2ms/step - loss: 2.1825\n16/16 [==============================] - 0s 1ms/step - loss: 2.1721\n16/16 [==============================] - 0s 3ms/step - loss: 2.1683\n16/16 [==============================] - 0s 2ms/step - loss: 2.1681\n\nTesting for epoch 33 index 2:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1507\n16/16 [==============================] - 0s 932us/step - loss: 1.7736\n16/16 [==============================] - 0s 877us/step - loss: 2.0996\n16/16 [==============================] - 0s 821us/step - loss: 2.2003\n16/16 [==============================] - 0s 801us/step - loss: 2.2338\n16/16 [==============================] - 0s 821us/step - loss: 2.2216\n16/16 [==============================] - 0s 842us/step - loss: 2.2004\n16/16 [==============================] - 0s 791us/step - loss: 2.1900\n16/16 [==============================] - 0s 787us/step - loss: 2.1864\n16/16 [==============================] - 0s 816us/step - loss: 2.1863\n\nTesting for epoch 33 index 3:\n79/79 [==============================] - 0s 589us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1522\n16/16 [==============================] - 0s 829us/step - loss: 1.7884\n16/16 [==============================] - 0s 806us/step - loss: 2.1161\n16/16 [==============================] - 0s 793us/step - loss: 2.2152\n16/16 [==============================] - 0s 777us/step - loss: 2.2465\n16/16 [==============================] - 0s 780us/step - loss: 2.2315\n16/16 [==============================] - 0s 794us/step - loss: 2.2087\n16/16 [==============================] - 0s 783us/step - loss: 2.1979\n16/16 [==============================] - 0s 824us/step - loss: 2.1942\n16/16 [==============================] - 0s 1ms/step - loss: 2.1941\n\nTesting for epoch 33 index 4:\n79/79 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1512\n16/16 [==============================] - 0s 838us/step - loss: 1.7421\n16/16 [==============================] - 0s 848us/step - loss: 2.0614\n16/16 [==============================] - 0s 818us/step - loss: 2.1598\n16/16 [==============================] - 0s 791us/step - loss: 2.1919\n16/16 [==============================] - 0s 785us/step - loss: 2.1795\n16/16 [==============================] - 0s 815us/step - loss: 2.1576\n16/16 [==============================] - 0s 800us/step - loss: 2.1471\n16/16 [==============================] - 0s 835us/step - loss: 2.1433\n16/16 [==============================] - 0s 804us/step - loss: 2.1431\n\nTesting for epoch 33 index 5:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 850us/step - loss: 0.1533\n16/16 [==============================] - 0s 823us/step - loss: 1.7343\n16/16 [==============================] - 0s 841us/step - loss: 2.0496\n16/16 [==============================] - 0s 819us/step - loss: 2.1449\n16/16 [==============================] - 0s 840us/step - loss: 2.1741\n16/16 [==============================] - 0s 829us/step - loss: 2.1592\n16/16 [==============================] - 0s 810us/step - loss: 2.1358\n16/16 [==============================] - 0s 784us/step - loss: 2.1250\n16/16 [==============================] - 0s 834us/step - loss: 2.1212\n16/16 [==============================] - 0s 850us/step - loss: 2.1210\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1524\n16/16 [==============================] - 0s 1ms/step - loss: 1.7155\n16/16 [==============================] - 0s 1ms/step - loss: 2.0298\n16/16 [==============================] - 0s 1ms/step - loss: 2.1247\n16/16 [==============================] - 0s 816us/step - loss: 2.1539\n16/16 [==============================] - 0s 845us/step - loss: 2.1409\n16/16 [==============================] - 0s 784us/step - loss: 2.1187\n16/16 [==============================] - 0s 1ms/step - loss: 2.1082\n16/16 [==============================] - 0s 1ms/step - loss: 2.1044\n16/16 [==============================] - 0s 970us/step - loss: 2.1041\n\nTesting for epoch 34 index 2:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1485\n16/16 [==============================] - 0s 826us/step - loss: 1.7384\n16/16 [==============================] - 0s 794us/step - loss: 2.0580\n16/16 [==============================] - 0s 786us/step - loss: 2.1532\n16/16 [==============================] - 0s 782us/step - loss: 2.1809\n16/16 [==============================] - 0s 782us/step - loss: 2.1669\n16/16 [==============================] - 0s 792us/step - loss: 2.1444\n16/16 [==============================] - 0s 779us/step - loss: 2.1341\n16/16 [==============================] - 0s 782us/step - loss: 2.1306\n16/16 [==============================] - 0s 828us/step - loss: 2.1305\n\nTesting for epoch 34 index 3:\n79/79 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.1477\n16/16 [==============================] - 0s 1ms/step - loss: 1.7757\n16/16 [==============================] - 0s 1ms/step - loss: 2.1041\n16/16 [==============================] - 0s 820us/step - loss: 2.1998\n16/16 [==============================] - 0s 783us/step - loss: 2.2271\n16/16 [==============================] - 0s 774us/step - loss: 2.2111\n16/16 [==============================] - 0s 783us/step - loss: 2.1877\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 772us/step - loss: 2.1732\n16/16 [==============================] - 0s 817us/step - loss: 2.1731\n\nTesting for epoch 34 index 4:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 807us/step - loss: 0.1443\n16/16 [==============================] - 0s 797us/step - loss: 1.8313\n16/16 [==============================] - 0s 766us/step - loss: 2.1753\n16/16 [==============================] - 0s 775us/step - loss: 2.2750\n16/16 [==============================] - 0s 775us/step - loss: 2.3028\n16/16 [==============================] - 0s 782us/step - loss: 2.2844\n16/16 [==============================] - 0s 778us/step - loss: 2.2581\n16/16 [==============================] - 0s 780us/step - loss: 2.2464\n16/16 [==============================] - 0s 793us/step - loss: 2.2425\n16/16 [==============================] - 0s 798us/step - loss: 2.2424\n\nTesting for epoch 34 index 5:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.1507\n16/16 [==============================] - 0s 1ms/step - loss: 1.7991\n16/16 [==============================] - 0s 1ms/step - loss: 2.1385\n16/16 [==============================] - 0s 805us/step - loss: 2.2388\n16/16 [==============================] - 0s 777us/step - loss: 2.2689\n16/16 [==============================] - 0s 769us/step - loss: 2.2553\n16/16 [==============================] - 0s 770us/step - loss: 2.2330\n16/16 [==============================] - 0s 766us/step - loss: 2.2225\n16/16 [==============================] - 0s 796us/step - loss: 2.2189\n16/16 [==============================] - 0s 802us/step - loss: 2.2187\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 810us/step - loss: 0.1468\n16/16 [==============================] - 0s 1000us/step - loss: 1.8167\n16/16 [==============================] - 0s 1ms/step - loss: 2.1570\n16/16 [==============================] - 0s 783us/step - loss: 2.2540\n16/16 [==============================] - 0s 816us/step - loss: 2.2807\n16/16 [==============================] - 0s 980us/step - loss: 2.2621\n16/16 [==============================] - 0s 787us/step - loss: 2.2360\n16/16 [==============================] - 0s 814us/step - loss: 2.2244\n16/16 [==============================] - 0s 805us/step - loss: 2.2204\n16/16 [==============================] - 0s 832us/step - loss: 2.2203\n\nTesting for epoch 35 index 2:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1469\n16/16 [==============================] - 0s 791us/step - loss: 1.8178\n16/16 [==============================] - 0s 775us/step - loss: 2.1558\n16/16 [==============================] - 0s 784us/step - loss: 2.2515\n16/16 [==============================] - 0s 796us/step - loss: 2.2769\n16/16 [==============================] - 0s 783us/step - loss: 2.2571\n16/16 [==============================] - 0s 802us/step - loss: 2.2299\n16/16 [==============================] - 0s 779us/step - loss: 2.2181\n16/16 [==============================] - 0s 811us/step - loss: 2.2141\n16/16 [==============================] - 0s 798us/step - loss: 2.2140\n\nTesting for epoch 35 index 3:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1499\n16/16 [==============================] - 0s 823us/step - loss: 1.7804\n16/16 [==============================] - 0s 814us/step - loss: 2.1084\n16/16 [==============================] - 0s 789us/step - loss: 2.1988\n16/16 [==============================] - 0s 779us/step - loss: 2.2227\n16/16 [==============================] - 0s 772us/step - loss: 2.2030\n16/16 [==============================] - 0s 794us/step - loss: 2.1772\n16/16 [==============================] - 0s 787us/step - loss: 2.1661\n16/16 [==============================] - 0s 822us/step - loss: 2.1624\n16/16 [==============================] - 0s 797us/step - loss: 2.1623\n\nTesting for epoch 35 index 4:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1474\n16/16 [==============================] - 0s 804us/step - loss: 1.7882\n16/16 [==============================] - 0s 816us/step - loss: 2.1206\n16/16 [==============================] - 0s 826us/step - loss: 2.2126\n16/16 [==============================] - 0s 844us/step - loss: 2.2362\n16/16 [==============================] - 0s 804us/step - loss: 2.2145\n16/16 [==============================] - 0s 1ms/step - loss: 2.1867\n16/16 [==============================] - 0s 881us/step - loss: 2.1749\n16/16 [==============================] - 0s 852us/step - loss: 2.1709\n16/16 [==============================] - 0s 785us/step - loss: 2.1708\n\nTesting for epoch 35 index 5:\n79/79 [==============================] - 0s 585us/step\n16/16 [==============================] - 0s 861us/step - loss: 0.1426\n16/16 [==============================] - 0s 1ms/step - loss: 1.8107\n16/16 [==============================] - 0s 762us/step - loss: 2.1481\n16/16 [==============================] - 0s 757us/step - loss: 2.2402\n16/16 [==============================] - 0s 771us/step - loss: 2.2636\n16/16 [==============================] - 0s 772us/step - loss: 2.2406\n16/16 [==============================] - 0s 768us/step - loss: 2.2119\n16/16 [==============================] - 0s 766us/step - loss: 2.1997\n16/16 [==============================] - 0s 765us/step - loss: 2.1956\n16/16 [==============================] - 0s 771us/step - loss: 2.1955\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 782us/step - loss: 0.1440\n16/16 [==============================] - 0s 780us/step - loss: 1.8571\n16/16 [==============================] - 0s 775us/step - loss: 2.2097\n16/16 [==============================] - 0s 779us/step - loss: 2.3070\n16/16 [==============================] - 0s 776us/step - loss: 2.3319\n16/16 [==============================] - 0s 788us/step - loss: 2.3098\n16/16 [==============================] - 0s 1ms/step - loss: 2.2808\n16/16 [==============================] - 0s 1ms/step - loss: 2.2685\n16/16 [==============================] - 0s 800us/step - loss: 2.2645\n16/16 [==============================] - 0s 891us/step - loss: 2.2644\n\nTesting for epoch 36 index 2:\n79/79 [==============================] - 0s 693us/step\n16/16 [==============================] - 0s 833us/step - loss: 0.1417\n16/16 [==============================] - 0s 814us/step - loss: 1.8655\n16/16 [==============================] - 0s 906us/step - loss: 2.2205\n16/16 [==============================] - 0s 829us/step - loss: 2.3178\n16/16 [==============================] - 0s 872us/step - loss: 2.3425\n16/16 [==============================] - 0s 864us/step - loss: 2.3198\n16/16 [==============================] - 0s 792us/step - loss: 2.2908\n16/16 [==============================] - 0s 803us/step - loss: 2.2784\n16/16 [==============================] - 0s 796us/step - loss: 2.2743\n16/16 [==============================] - 0s 821us/step - loss: 2.2743\n\nTesting for epoch 36 index 3:\n79/79 [==============================] - 0s 620us/step\n16/16 [==============================] - 0s 820us/step - loss: 0.1445\n16/16 [==============================] - 0s 830us/step - loss: 1.8152\n16/16 [==============================] - 0s 800us/step - loss: 2.1608\n16/16 [==============================] - 0s 826us/step - loss: 2.2564\n16/16 [==============================] - 0s 814us/step - loss: 2.2806\n16/16 [==============================] - 0s 806us/step - loss: 2.2592\n16/16 [==============================] - 0s 792us/step - loss: 2.2315\n16/16 [==============================] - 0s 823us/step - loss: 2.2197\n16/16 [==============================] - 0s 819us/step - loss: 2.2156\n16/16 [==============================] - 0s 807us/step - loss: 2.2155\n\nTesting for epoch 36 index 4:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.1423\n16/16 [==============================] - 0s 803us/step - loss: 1.8472\n16/16 [==============================] - 0s 782us/step - loss: 2.1950\n16/16 [==============================] - 0s 816us/step - loss: 2.2881\n16/16 [==============================] - 0s 794us/step - loss: 2.3102\n16/16 [==============================] - 0s 786us/step - loss: 2.2857\n16/16 [==============================] - 0s 786us/step - loss: 2.2565\n16/16 [==============================] - 0s 794us/step - loss: 2.2442\n16/16 [==============================] - 0s 788us/step - loss: 2.2402\n16/16 [==============================] - 0s 792us/step - loss: 2.2401\n\nTesting for epoch 36 index 5:\n79/79 [==============================] - 0s 659us/step\n16/16 [==============================] - 0s 872us/step - loss: 0.1383\n16/16 [==============================] - 0s 805us/step - loss: 1.8481\n16/16 [==============================] - 0s 806us/step - loss: 2.2002\n16/16 [==============================] - 0s 807us/step - loss: 2.2955\n16/16 [==============================] - 0s 810us/step - loss: 2.3191\n16/16 [==============================] - 0s 818us/step - loss: 2.2953\n16/16 [==============================] - 0s 846us/step - loss: 2.2663\n16/16 [==============================] - 0s 817us/step - loss: 2.2540\n16/16 [==============================] - 0s 842us/step - loss: 2.2498\n16/16 [==============================] - 0s 808us/step - loss: 2.2496\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1396\n16/16 [==============================] - 0s 800us/step - loss: 1.8411\n16/16 [==============================] - 0s 794us/step - loss: 2.1902\n16/16 [==============================] - 0s 789us/step - loss: 2.2840\n16/16 [==============================] - 0s 805us/step - loss: 2.3066\n16/16 [==============================] - 0s 794us/step - loss: 2.2821\n16/16 [==============================] - 0s 787us/step - loss: 2.2532\n16/16 [==============================] - 0s 790us/step - loss: 2.2411\n16/16 [==============================] - 0s 814us/step - loss: 2.2372\n16/16 [==============================] - 0s 796us/step - loss: 2.2371\n\nTesting for epoch 37 index 2:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1395\n16/16 [==============================] - 0s 832us/step - loss: 1.8573\n16/16 [==============================] - 0s 835us/step - loss: 2.2095\n16/16 [==============================] - 0s 826us/step - loss: 2.3029\n16/16 [==============================] - 0s 804us/step - loss: 2.3241\n16/16 [==============================] - 0s 805us/step - loss: 2.2983\n16/16 [==============================] - 0s 796us/step - loss: 2.2682\n16/16 [==============================] - 0s 807us/step - loss: 2.2556\n16/16 [==============================] - 0s 1ms/step - loss: 2.2513\n16/16 [==============================] - 0s 1ms/step - loss: 2.2511\n\nTesting for epoch 37 index 3:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1401\n16/16 [==============================] - 0s 796us/step - loss: 1.8239\n16/16 [==============================] - 0s 798us/step - loss: 2.1752\n16/16 [==============================] - 0s 804us/step - loss: 2.2721\n16/16 [==============================] - 0s 838us/step - loss: 2.2980\n16/16 [==============================] - 0s 841us/step - loss: 2.2774\n16/16 [==============================] - 0s 820us/step - loss: 2.2510\n16/16 [==============================] - 0s 694us/step - loss: 2.2395\n16/16 [==============================] - 0s 737us/step - loss: 2.2355\n16/16 [==============================] - 0s 689us/step - loss: 2.2353\n\nTesting for epoch 37 index 4:\n79/79 [==============================] - 0s 668us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1385\n16/16 [==============================] - 0s 2ms/step - loss: 1.8566\n16/16 [==============================] - 0s 2ms/step - loss: 2.2037\n16/16 [==============================] - 0s 2ms/step - loss: 2.2918\n16/16 [==============================] - 0s 2ms/step - loss: 2.3097\n16/16 [==============================] - 0s 844us/step - loss: 2.2792\n16/16 [==============================] - 0s 855us/step - loss: 2.2463\n16/16 [==============================] - 0s 2ms/step - loss: 2.2331\n16/16 [==============================] - 0s 2ms/step - loss: 2.2290\n16/16 [==============================] - 0s 769us/step - loss: 2.2290\n\nTesting for epoch 37 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 876us/step - loss: 0.1371\n16/16 [==============================] - 0s 2ms/step - loss: 1.8841\n16/16 [==============================] - 0s 781us/step - loss: 2.2415\n16/16 [==============================] - 0s 754us/step - loss: 2.3349\n16/16 [==============================] - 0s 831us/step - loss: 2.3552\n16/16 [==============================] - 0s 788us/step - loss: 2.3269\n16/16 [==============================] - 0s 832us/step - loss: 2.2956\n16/16 [==============================] - 0s 797us/step - loss: 2.2825\n16/16 [==============================] - 0s 2ms/step - loss: 2.2780\n16/16 [==============================] - 0s 2ms/step - loss: 2.2778\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1392\n16/16 [==============================] - 0s 846us/step - loss: 1.9016\n16/16 [==============================] - 0s 2ms/step - loss: 2.2615\n16/16 [==============================] - 0s 2ms/step - loss: 2.3548\n16/16 [==============================] - 0s 2ms/step - loss: 2.3744\n16/16 [==============================] - 0s 783us/step - loss: 2.3445\n16/16 [==============================] - 0s 1ms/step - loss: 2.3121\n16/16 [==============================] - 0s 2ms/step - loss: 2.2989\n16/16 [==============================] - 0s 2ms/step - loss: 2.2947\n16/16 [==============================] - 0s 1ms/step - loss: 2.2946\n\nTesting for epoch 38 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1370\n16/16 [==============================] - 0s 2ms/step - loss: 1.8808\n16/16 [==============================] - 0s 2ms/step - loss: 2.2309\n16/16 [==============================] - 0s 803us/step - loss: 2.3252\n16/16 [==============================] - 0s 2ms/step - loss: 2.3458\n16/16 [==============================] - 0s 2ms/step - loss: 2.3187\n16/16 [==============================] - 0s 2ms/step - loss: 2.2874\n16/16 [==============================] - 0s 840us/step - loss: 2.2746\n16/16 [==============================] - 0s 2ms/step - loss: 2.2703\n16/16 [==============================] - 0s 805us/step - loss: 2.2702\n\nTesting for epoch 38 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1335\n16/16 [==============================] - 0s 2ms/step - loss: 1.9326\n16/16 [==============================] - 0s 2ms/step - loss: 2.2893\n16/16 [==============================] - 0s 804us/step - loss: 2.3820\n16/16 [==============================] - 0s 2ms/step - loss: 2.3984\n16/16 [==============================] - 0s 817us/step - loss: 2.3647\n16/16 [==============================] - 0s 2ms/step - loss: 2.3292\n16/16 [==============================] - 0s 2ms/step - loss: 2.3153\n16/16 [==============================] - 0s 883us/step - loss: 2.3110\n16/16 [==============================] - 0s 2ms/step - loss: 2.3111\n\nTesting for epoch 38 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 849us/step - loss: 0.1333\n16/16 [==============================] - 0s 805us/step - loss: 1.9265\n16/16 [==============================] - 0s 793us/step - loss: 2.2845\n16/16 [==============================] - 0s 815us/step - loss: 2.3802\n16/16 [==============================] - 0s 808us/step - loss: 2.3993\n16/16 [==============================] - 0s 818us/step - loss: 2.3696\n16/16 [==============================] - 0s 2ms/step - loss: 2.3358\n16/16 [==============================] - 0s 800us/step - loss: 2.3221\n16/16 [==============================] - 0s 792us/step - loss: 2.3175\n16/16 [==============================] - 0s 2ms/step - loss: 2.3173\n\nTesting for epoch 38 index 5:\n79/79 [==============================] - 0s 759us/step\n16/16 [==============================] - 0s 844us/step - loss: 0.1361\n16/16 [==============================] - 0s 833us/step - loss: 1.9262\n16/16 [==============================] - 0s 799us/step - loss: 2.2858\n16/16 [==============================] - 0s 2ms/step - loss: 2.3821\n16/16 [==============================] - 0s 814us/step - loss: 2.4018\n16/16 [==============================] - 0s 2ms/step - loss: 2.3724\n16/16 [==============================] - 0s 2ms/step - loss: 2.3391\n16/16 [==============================] - 0s 833us/step - loss: 2.3258\n16/16 [==============================] - 0s 814us/step - loss: 2.3215\n16/16 [==============================] - 0s 823us/step - loss: 2.3214\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 833us/step - loss: 0.1330\n16/16 [==============================] - 0s 1ms/step - loss: 1.8945\n16/16 [==============================] - 0s 2ms/step - loss: 2.2436\n16/16 [==============================] - 0s 1ms/step - loss: 2.3363\n16/16 [==============================] - 0s 911us/step - loss: 2.3546\n16/16 [==============================] - 0s 808us/step - loss: 2.3242\n16/16 [==============================] - 0s 2ms/step - loss: 2.2909\n16/16 [==============================] - 0s 2ms/step - loss: 2.2776\n16/16 [==============================] - 0s 2ms/step - loss: 2.2733\n16/16 [==============================] - 0s 791us/step - loss: 2.2731\n\nTesting for epoch 39 index 2:\n79/79 [==============================] - 0s 929us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1358\n16/16 [==============================] - 0s 2ms/step - loss: 1.8447\n16/16 [==============================] - 0s 832us/step - loss: 2.1816\n16/16 [==============================] - 0s 795us/step - loss: 2.2687\n16/16 [==============================] - 0s 807us/step - loss: 2.2848\n16/16 [==============================] - 0s 2ms/step - loss: 2.2549\n16/16 [==============================] - 0s 1ms/step - loss: 2.2232\n16/16 [==============================] - 0s 919us/step - loss: 2.2103\n16/16 [==============================] - 0s 2ms/step - loss: 2.2061\n16/16 [==============================] - 0s 787us/step - loss: 2.2059\n\nTesting for epoch 39 index 3:\n79/79 [==============================] - 0s 533us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1353\n16/16 [==============================] - 0s 1ms/step - loss: 1.9032\n16/16 [==============================] - 0s 2ms/step - loss: 2.2511\n16/16 [==============================] - 0s 2ms/step - loss: 2.3409\n16/16 [==============================] - 0s 780us/step - loss: 2.3580\n16/16 [==============================] - 0s 891us/step - loss: 2.3288\n16/16 [==============================] - 0s 863us/step - loss: 2.2962\n16/16 [==============================] - 0s 876us/step - loss: 2.2830\n16/16 [==============================] - 0s 1ms/step - loss: 2.2787\n16/16 [==============================] - 0s 937us/step - loss: 2.2786\n\nTesting for epoch 39 index 4:\n79/79 [==============================] - 0s 781us/step\n16/16 [==============================] - 0s 835us/step - loss: 0.1367\n16/16 [==============================] - 0s 2ms/step - loss: 1.9084\n16/16 [==============================] - 0s 990us/step - loss: 2.2575\n16/16 [==============================] - 0s 814us/step - loss: 2.3489\n16/16 [==============================] - 0s 777us/step - loss: 2.3668\n16/16 [==============================] - 0s 782us/step - loss: 2.3375\n16/16 [==============================] - 0s 714us/step - loss: 2.3043\n16/16 [==============================] - 0s 1ms/step - loss: 2.2911\n16/16 [==============================] - 0s 649us/step - loss: 2.2868\n16/16 [==============================] - 0s 790us/step - loss: 2.2867\n\nTesting for epoch 39 index 5:\n79/79 [==============================] - 0s 661us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1330\n16/16 [==============================] - 0s 780us/step - loss: 1.9413\n16/16 [==============================] - 0s 778us/step - loss: 2.3006\n16/16 [==============================] - 0s 786us/step - loss: 2.3940\n16/16 [==============================] - 0s 804us/step - loss: 2.4106\n16/16 [==============================] - 0s 791us/step - loss: 2.3794\n16/16 [==============================] - 0s 780us/step - loss: 2.3453\n16/16 [==============================] - 0s 779us/step - loss: 2.3317\n16/16 [==============================] - 0s 815us/step - loss: 2.3272\n16/16 [==============================] - 0s 790us/step - loss: 2.3271\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1342\n16/16 [==============================] - 0s 1ms/step - loss: 1.9180\n16/16 [==============================] - 0s 1ms/step - loss: 2.2724\n16/16 [==============================] - 0s 1ms/step - loss: 2.3660\n16/16 [==============================] - 0s 1ms/step - loss: 2.3839\n16/16 [==============================] - 0s 781us/step - loss: 2.3552\n16/16 [==============================] - 0s 1ms/step - loss: 2.3228\n16/16 [==============================] - 0s 788us/step - loss: 2.3097\n16/16 [==============================] - 0s 800us/step - loss: 2.3054\n16/16 [==============================] - 0s 800us/step - loss: 2.3052\n\nTesting for epoch 40 index 2:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1336\n16/16 [==============================] - 0s 806us/step - loss: 1.8845\n16/16 [==============================] - 0s 785us/step - loss: 2.2270\n16/16 [==============================] - 0s 789us/step - loss: 2.3128\n16/16 [==============================] - 0s 803us/step - loss: 2.3252\n16/16 [==============================] - 0s 807us/step - loss: 2.2901\n16/16 [==============================] - 0s 789us/step - loss: 2.2552\n16/16 [==============================] - 0s 803us/step - loss: 2.2418\n16/16 [==============================] - 0s 903us/step - loss: 2.2374\n16/16 [==============================] - 0s 860us/step - loss: 2.2373\n\nTesting for epoch 40 index 3:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1321\n16/16 [==============================] - 0s 817us/step - loss: 1.9400\n16/16 [==============================] - 0s 819us/step - loss: 2.2933\n16/16 [==============================] - 0s 825us/step - loss: 2.3799\n16/16 [==============================] - 0s 819us/step - loss: 2.3924\n16/16 [==============================] - 0s 885us/step - loss: 2.3564\n16/16 [==============================] - 0s 882us/step - loss: 2.3207\n16/16 [==============================] - 0s 823us/step - loss: 2.3070\n16/16 [==============================] - 0s 865us/step - loss: 2.3027\n16/16 [==============================] - 0s 803us/step - loss: 2.3027\n\nTesting for epoch 40 index 4:\n79/79 [==============================] - 0s 669us/step\n16/16 [==============================] - 0s 815us/step - loss: 0.1334\n16/16 [==============================] - 0s 833us/step - loss: 1.9022\n16/16 [==============================] - 0s 806us/step - loss: 2.2463\n16/16 [==============================] - 0s 796us/step - loss: 2.3297\n16/16 [==============================] - 0s 790us/step - loss: 2.3413\n16/16 [==============================] - 0s 790us/step - loss: 2.3067\n16/16 [==============================] - 0s 791us/step - loss: 2.2727\n16/16 [==============================] - 0s 828us/step - loss: 2.2595\n16/16 [==============================] - 0s 819us/step - loss: 2.2552\n16/16 [==============================] - 0s 798us/step - loss: 2.2550\n\nTesting for epoch 40 index 5:\n79/79 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.1269\n16/16 [==============================] - 0s 804us/step - loss: 1.9772\n16/16 [==============================] - 0s 796us/step - loss: 2.3427\n16/16 [==============================] - 0s 779us/step - loss: 2.4319\n16/16 [==============================] - 0s 792us/step - loss: 2.4454\n16/16 [==============================] - 0s 806us/step - loss: 2.4078\n16/16 [==============================] - 0s 804us/step - loss: 2.3714\n16/16 [==============================] - 0s 817us/step - loss: 2.3572\n16/16 [==============================] - 0s 854us/step - loss: 2.3526\n16/16 [==============================] - 0s 889us/step - loss: 2.3524\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n79/79 [==============================] - 0s 862us/step\n16/16 [==============================] - 0s 846us/step - loss: 0.1301\n16/16 [==============================] - 0s 833us/step - loss: 1.9242\n16/16 [==============================] - 0s 1ms/step - loss: 2.2728\n16/16 [==============================] - 0s 814us/step - loss: 2.3565\n16/16 [==============================] - 0s 834us/step - loss: 2.3696\n16/16 [==============================] - 0s 832us/step - loss: 2.3336\n16/16 [==============================] - 0s 849us/step - loss: 2.2979\n16/16 [==============================] - 0s 895us/step - loss: 2.2839\n16/16 [==============================] - 0s 835us/step - loss: 2.2793\n16/16 [==============================] - 0s 842us/step - loss: 2.2791\n\nTesting for epoch 41 index 2:\n79/79 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 832us/step - loss: 0.1314\n16/16 [==============================] - 0s 845us/step - loss: 1.9663\n16/16 [==============================] - 0s 874us/step - loss: 2.3249\n16/16 [==============================] - 0s 816us/step - loss: 2.4099\n16/16 [==============================] - 0s 824us/step - loss: 2.4224\n16/16 [==============================] - 0s 826us/step - loss: 2.3848\n16/16 [==============================] - 0s 849us/step - loss: 2.3482\n16/16 [==============================] - 0s 800us/step - loss: 2.3341\n16/16 [==============================] - 0s 856us/step - loss: 2.3296\n16/16 [==============================] - 0s 797us/step - loss: 2.3295\n\nTesting for epoch 41 index 3:\n79/79 [==============================] - 0s 719us/step\n16/16 [==============================] - 0s 843us/step - loss: 0.1290\n16/16 [==============================] - 0s 858us/step - loss: 2.0148\n16/16 [==============================] - 0s 784us/step - loss: 2.3873\n16/16 [==============================] - 0s 856us/step - loss: 2.4746\n16/16 [==============================] - 0s 835us/step - loss: 2.4879\n16/16 [==============================] - 0s 810us/step - loss: 2.4474\n16/16 [==============================] - 0s 865us/step - loss: 2.4088\n16/16 [==============================] - 0s 884us/step - loss: 2.3940\n16/16 [==============================] - 0s 869us/step - loss: 2.3894\n16/16 [==============================] - 0s 785us/step - loss: 2.3893\n\nTesting for epoch 41 index 4:\n79/79 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1312\n16/16 [==============================] - 0s 807us/step - loss: 1.9137\n16/16 [==============================] - 0s 1ms/step - loss: 2.2591\n16/16 [==============================] - 0s 798us/step - loss: 2.3380\n16/16 [==============================] - 0s 1ms/step - loss: 2.3479\n16/16 [==============================] - 0s 1ms/step - loss: 2.3084\n16/16 [==============================] - 0s 830us/step - loss: 2.2720\n16/16 [==============================] - 0s 788us/step - loss: 2.2582\n16/16 [==============================] - 0s 795us/step - loss: 2.2539\n16/16 [==============================] - 0s 855us/step - loss: 2.2538\n\nTesting for epoch 41 index 5:\n79/79 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 857us/step - loss: 0.1289\n16/16 [==============================] - 0s 817us/step - loss: 1.9509\n16/16 [==============================] - 0s 905us/step - loss: 2.3031\n16/16 [==============================] - 0s 799us/step - loss: 2.3834\n16/16 [==============================] - 0s 915us/step - loss: 2.3938\n16/16 [==============================] - 0s 1ms/step - loss: 2.3538\n16/16 [==============================] - 0s 911us/step - loss: 2.3167\n16/16 [==============================] - 0s 934us/step - loss: 2.3026\n16/16 [==============================] - 0s 891us/step - loss: 2.2981\n16/16 [==============================] - 0s 866us/step - loss: 2.2980\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1312\n16/16 [==============================] - 0s 3ms/step - loss: 1.9436\n16/16 [==============================] - 0s 1ms/step - loss: 2.2942\n16/16 [==============================] - 0s 1ms/step - loss: 2.3728\n16/16 [==============================] - 0s 801us/step - loss: 2.3809\n16/16 [==============================] - 0s 1ms/step - loss: 2.3390\n16/16 [==============================] - 0s 881us/step - loss: 2.3013\n16/16 [==============================] - 0s 818us/step - loss: 2.2872\n16/16 [==============================] - 0s 807us/step - loss: 2.2829\n16/16 [==============================] - 0s 794us/step - loss: 2.2830\n\nTesting for epoch 42 index 2:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 830us/step - loss: 0.1277\n16/16 [==============================] - 0s 825us/step - loss: 1.9867\n16/16 [==============================] - 0s 818us/step - loss: 2.3500\n16/16 [==============================] - 0s 797us/step - loss: 2.4348\n16/16 [==============================] - 0s 795us/step - loss: 2.4465\n16/16 [==============================] - 0s 798us/step - loss: 2.4073\n16/16 [==============================] - 0s 790us/step - loss: 2.3709\n16/16 [==============================] - 0s 803us/step - loss: 2.3569\n16/16 [==============================] - 0s 799us/step - loss: 2.3525\n16/16 [==============================] - 0s 796us/step - loss: 2.3524\n\nTesting for epoch 42 index 3:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1334\n16/16 [==============================] - 0s 821us/step - loss: 1.9570\n16/16 [==============================] - 0s 806us/step - loss: 2.3121\n16/16 [==============================] - 0s 808us/step - loss: 2.3937\n16/16 [==============================] - 0s 805us/step - loss: 2.4031\n16/16 [==============================] - 0s 824us/step - loss: 2.3619\n16/16 [==============================] - 0s 808us/step - loss: 2.3245\n16/16 [==============================] - 0s 827us/step - loss: 2.3104\n16/16 [==============================] - 0s 827us/step - loss: 2.3060\n16/16 [==============================] - 0s 813us/step - loss: 2.3059\n\nTesting for epoch 42 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1268\n16/16 [==============================] - 0s 794us/step - loss: 1.9501\n16/16 [==============================] - 0s 868us/step - loss: 2.3015\n16/16 [==============================] - 0s 822us/step - loss: 2.3798\n16/16 [==============================] - 0s 828us/step - loss: 2.3880\n16/16 [==============================] - 0s 789us/step - loss: 2.3466\n16/16 [==============================] - 0s 802us/step - loss: 2.3094\n16/16 [==============================] - 0s 821us/step - loss: 2.2953\n16/16 [==============================] - 0s 815us/step - loss: 2.2908\n16/16 [==============================] - 0s 839us/step - loss: 2.2906\n\nTesting for epoch 42 index 5:\n79/79 [==============================] - 0s 730us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1280\n16/16 [==============================] - 0s 1ms/step - loss: 1.9975\n16/16 [==============================] - 0s 805us/step - loss: 2.3589\n16/16 [==============================] - 0s 798us/step - loss: 2.4382\n16/16 [==============================] - 0s 829us/step - loss: 2.4454\n16/16 [==============================] - 0s 821us/step - loss: 2.4015\n16/16 [==============================] - 0s 797us/step - loss: 2.3619\n16/16 [==============================] - 0s 1ms/step - loss: 2.3472\n16/16 [==============================] - 0s 815us/step - loss: 2.3427\n16/16 [==============================] - 0s 813us/step - loss: 2.3427\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1275\n16/16 [==============================] - 0s 1ms/step - loss: 2.0014\n16/16 [==============================] - 0s 773us/step - loss: 2.3669\n16/16 [==============================] - 0s 771us/step - loss: 2.4493\n16/16 [==============================] - 0s 1ms/step - loss: 2.4593\n16/16 [==============================] - 0s 1ms/step - loss: 2.4179\n16/16 [==============================] - 0s 1ms/step - loss: 2.3796\n16/16 [==============================] - 0s 1ms/step - loss: 2.3652\n16/16 [==============================] - 0s 1ms/step - loss: 2.3606\n16/16 [==============================] - 0s 787us/step - loss: 2.3604\n\nTesting for epoch 43 index 2:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1274\n16/16 [==============================] - 0s 800us/step - loss: 1.9885\n16/16 [==============================] - 0s 800us/step - loss: 2.3486\n16/16 [==============================] - 0s 793us/step - loss: 2.4281\n16/16 [==============================] - 0s 810us/step - loss: 2.4365\n16/16 [==============================] - 0s 805us/step - loss: 2.3939\n16/16 [==============================] - 0s 806us/step - loss: 2.3558\n16/16 [==============================] - 0s 830us/step - loss: 2.3415\n16/16 [==============================] - 0s 830us/step - loss: 2.3370\n16/16 [==============================] - 0s 812us/step - loss: 2.3370\n\nTesting for epoch 43 index 3:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 810us/step - loss: 0.1306\n16/16 [==============================] - 0s 811us/step - loss: 1.9621\n16/16 [==============================] - 0s 817us/step - loss: 2.3132\n16/16 [==============================] - 0s 805us/step - loss: 2.3880\n16/16 [==============================] - 0s 784us/step - loss: 2.3952\n16/16 [==============================] - 0s 820us/step - loss: 2.3532\n16/16 [==============================] - 0s 793us/step - loss: 2.3157\n16/16 [==============================] - 0s 778us/step - loss: 2.3018\n16/16 [==============================] - 0s 786us/step - loss: 2.2976\n16/16 [==============================] - 0s 785us/step - loss: 2.2976\n\nTesting for epoch 43 index 4:\n79/79 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1253\n16/16 [==============================] - 0s 825us/step - loss: 2.0501\n16/16 [==============================] - 0s 816us/step - loss: 2.4197\n16/16 [==============================] - 0s 851us/step - loss: 2.4972\n16/16 [==============================] - 0s 822us/step - loss: 2.5028\n16/16 [==============================] - 0s 876us/step - loss: 2.4551\n16/16 [==============================] - 0s 910us/step - loss: 2.4127\n16/16 [==============================] - 0s 879us/step - loss: 2.3973\n16/16 [==============================] - 0s 871us/step - loss: 2.3927\n16/16 [==============================] - 0s 818us/step - loss: 2.3928\n\nTesting for epoch 43 index 5:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 828us/step - loss: 0.1265\n16/16 [==============================] - 0s 801us/step - loss: 2.0007\n16/16 [==============================] - 0s 796us/step - loss: 2.3614\n16/16 [==============================] - 0s 798us/step - loss: 2.4380\n16/16 [==============================] - 0s 812us/step - loss: 2.4449\n16/16 [==============================] - 0s 809us/step - loss: 2.4011\n16/16 [==============================] - 0s 821us/step - loss: 2.3625\n16/16 [==============================] - 0s 811us/step - loss: 2.3483\n16/16 [==============================] - 0s 815us/step - loss: 2.3439\n16/16 [==============================] - 0s 808us/step - loss: 2.3438\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1299\n16/16 [==============================] - 0s 803us/step - loss: 1.9974\n16/16 [==============================] - 0s 782us/step - loss: 2.3529\n16/16 [==============================] - 0s 792us/step - loss: 2.4269\n16/16 [==============================] - 0s 795us/step - loss: 2.4322\n16/16 [==============================] - 0s 797us/step - loss: 2.3865\n16/16 [==============================] - 0s 805us/step - loss: 2.3467\n16/16 [==============================] - 0s 805us/step - loss: 2.3323\n16/16 [==============================] - 0s 795us/step - loss: 2.3279\n16/16 [==============================] - 0s 793us/step - loss: 2.3279\n\nTesting for epoch 44 index 2:\n79/79 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1263\n16/16 [==============================] - 0s 809us/step - loss: 2.0233\n16/16 [==============================] - 0s 809us/step - loss: 2.3927\n16/16 [==============================] - 0s 835us/step - loss: 2.4734\n16/16 [==============================] - 0s 809us/step - loss: 2.4828\n16/16 [==============================] - 0s 835us/step - loss: 2.4407\n16/16 [==============================] - 0s 810us/step - loss: 2.4019\n16/16 [==============================] - 0s 906us/step - loss: 2.3872\n16/16 [==============================] - 0s 824us/step - loss: 2.3824\n16/16 [==============================] - 0s 789us/step - loss: 2.3822\n\nTesting for epoch 44 index 3:\n79/79 [==============================] - 0s 595us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1234\n16/16 [==============================] - 0s 929us/step - loss: 2.0523\n16/16 [==============================] - 0s 784us/step - loss: 2.4219\n16/16 [==============================] - 0s 829us/step - loss: 2.4981\n16/16 [==============================] - 0s 831us/step - loss: 2.5027\n16/16 [==============================] - 0s 805us/step - loss: 2.4546\n16/16 [==============================] - 0s 1ms/step - loss: 2.4132\n16/16 [==============================] - 0s 1ms/step - loss: 2.3981\n16/16 [==============================] - 0s 1ms/step - loss: 2.3935\n16/16 [==============================] - 0s 1ms/step - loss: 2.3934\n\nTesting for epoch 44 index 4:\n79/79 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1256\n16/16 [==============================] - 0s 787us/step - loss: 1.9662\n16/16 [==============================] - 0s 788us/step - loss: 2.3195\n16/16 [==============================] - 0s 787us/step - loss: 2.3944\n16/16 [==============================] - 0s 790us/step - loss: 2.4012\n16/16 [==============================] - 0s 790us/step - loss: 2.3588\n16/16 [==============================] - 0s 795us/step - loss: 2.3210\n16/16 [==============================] - 0s 790us/step - loss: 2.3069\n16/16 [==============================] - 0s 788us/step - loss: 2.3024\n16/16 [==============================] - 0s 801us/step - loss: 2.3022\n\nTesting for epoch 44 index 5:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1243\n16/16 [==============================] - 0s 807us/step - loss: 2.0090\n16/16 [==============================] - 0s 838us/step - loss: 2.3705\n16/16 [==============================] - 0s 823us/step - loss: 2.4464\n16/16 [==============================] - 0s 817us/step - loss: 2.4520\n16/16 [==============================] - 0s 803us/step - loss: 2.4062\n16/16 [==============================] - 0s 809us/step - loss: 2.3657\n16/16 [==============================] - 0s 829us/step - loss: 2.3510\n16/16 [==============================] - 0s 824us/step - loss: 2.3466\n16/16 [==============================] - 0s 796us/step - loss: 2.3466\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n79/79 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1223\n16/16 [==============================] - 0s 1ms/step - loss: 2.0306\n16/16 [==============================] - 0s 1ms/step - loss: 2.3982\n16/16 [==============================] - 0s 1ms/step - loss: 2.4740\n16/16 [==============================] - 0s 806us/step - loss: 2.4773\n16/16 [==============================] - 0s 825us/step - loss: 2.4287\n16/16 [==============================] - 0s 821us/step - loss: 2.3869\n16/16 [==============================] - 0s 791us/step - loss: 2.3718\n16/16 [==============================] - 0s 1ms/step - loss: 2.3672\n16/16 [==============================] - 0s 791us/step - loss: 2.3671\n\nTesting for epoch 45 index 2:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1210\n16/16 [==============================] - 0s 791us/step - loss: 2.0704\n16/16 [==============================] - 0s 1ms/step - loss: 2.4462\n16/16 [==============================] - 0s 1ms/step - loss: 2.5242\n16/16 [==============================] - 0s 1ms/step - loss: 2.5296\n16/16 [==============================] - 0s 1ms/step - loss: 2.4812\n16/16 [==============================] - 0s 1ms/step - loss: 2.4387\n16/16 [==============================] - 0s 1ms/step - loss: 2.4232\n16/16 [==============================] - 0s 1ms/step - loss: 2.4184\n16/16 [==============================] - 0s 786us/step - loss: 2.4183\n\nTesting for epoch 45 index 3:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1213\n16/16 [==============================] - 0s 1ms/step - loss: 2.0630\n16/16 [==============================] - 0s 1ms/step - loss: 2.4339\n16/16 [==============================] - 0s 791us/step - loss: 2.5090\n16/16 [==============================] - 0s 1ms/step - loss: 2.5119\n16/16 [==============================] - 0s 1ms/step - loss: 2.4617\n16/16 [==============================] - 0s 796us/step - loss: 2.4184\n16/16 [==============================] - 0s 790us/step - loss: 2.4027\n16/16 [==============================] - 0s 787us/step - loss: 2.3979\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n\nTesting for epoch 45 index 4:\n79/79 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1207\n16/16 [==============================] - 0s 1ms/step - loss: 2.0925\n16/16 [==============================] - 0s 916us/step - loss: 2.4711\n16/16 [==============================] - 0s 783us/step - loss: 2.5501\n16/16 [==============================] - 0s 783us/step - loss: 2.5549\n16/16 [==============================] - 0s 826us/step - loss: 2.5060\n16/16 [==============================] - 0s 813us/step - loss: 2.4629\n16/16 [==============================] - 0s 857us/step - loss: 2.4472\n16/16 [==============================] - 0s 1ms/step - loss: 2.4425\n16/16 [==============================] - 0s 1ms/step - loss: 2.4424\n\nTesting for epoch 45 index 5:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1209\n16/16 [==============================] - 0s 794us/step - loss: 2.0450\n16/16 [==============================] - 0s 781us/step - loss: 2.4120\n16/16 [==============================] - 0s 811us/step - loss: 2.4853\n16/16 [==============================] - 0s 1ms/step - loss: 2.4875\n16/16 [==============================] - 0s 1ms/step - loss: 2.4384\n16/16 [==============================] - 0s 1ms/step - loss: 2.3963\n16/16 [==============================] - 0s 1ms/step - loss: 2.3811\n16/16 [==============================] - 0s 807us/step - loss: 2.3765\n16/16 [==============================] - 0s 797us/step - loss: 2.3764\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1157\n16/16 [==============================] - 0s 803us/step - loss: 2.0892\n16/16 [==============================] - 0s 783us/step - loss: 2.4688\n16/16 [==============================] - 0s 779us/step - loss: 2.5448\n16/16 [==============================] - 0s 790us/step - loss: 2.5463\n16/16 [==============================] - 0s 791us/step - loss: 2.4953\n16/16 [==============================] - 0s 788us/step - loss: 2.4526\n16/16 [==============================] - 0s 786us/step - loss: 2.4370\n16/16 [==============================] - 0s 788us/step - loss: 2.4322\n16/16 [==============================] - 0s 792us/step - loss: 2.4321\n\nTesting for epoch 46 index 2:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 784us/step - loss: 0.1203\n16/16 [==============================] - 0s 786us/step - loss: 2.0153\n16/16 [==============================] - 0s 774us/step - loss: 2.3790\n16/16 [==============================] - 0s 782us/step - loss: 2.4528\n16/16 [==============================] - 0s 786us/step - loss: 2.4549\n16/16 [==============================] - 0s 791us/step - loss: 2.4069\n16/16 [==============================] - 0s 776us/step - loss: 2.3664\n16/16 [==============================] - 0s 778us/step - loss: 2.3517\n16/16 [==============================] - 0s 772us/step - loss: 2.3471\n16/16 [==============================] - 0s 782us/step - loss: 2.3469\n\nTesting for epoch 46 index 3:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1176\n16/16 [==============================] - 0s 784us/step - loss: 2.0705\n16/16 [==============================] - 0s 780us/step - loss: 2.4423\n16/16 [==============================] - 0s 778us/step - loss: 2.5156\n16/16 [==============================] - 0s 787us/step - loss: 2.5160\n16/16 [==============================] - 0s 775us/step - loss: 2.4639\n16/16 [==============================] - 0s 780us/step - loss: 2.4200\n16/16 [==============================] - 0s 783us/step - loss: 2.4040\n16/16 [==============================] - 0s 779us/step - loss: 2.3992\n16/16 [==============================] - 0s 780us/step - loss: 2.3991\n\nTesting for epoch 46 index 4:\n79/79 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1199\n16/16 [==============================] - 0s 796us/step - loss: 2.0859\n16/16 [==============================] - 0s 808us/step - loss: 2.4654\n16/16 [==============================] - 0s 790us/step - loss: 2.5423\n16/16 [==============================] - 0s 787us/step - loss: 2.5441\n16/16 [==============================] - 0s 1ms/step - loss: 2.4922\n16/16 [==============================] - 0s 781us/step - loss: 2.4480\n16/16 [==============================] - 0s 794us/step - loss: 2.4320\n16/16 [==============================] - 0s 800us/step - loss: 2.4271\n16/16 [==============================] - 0s 783us/step - loss: 2.4269\n\nTesting for epoch 46 index 5:\n79/79 [==============================] - 0s 594us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1187\n16/16 [==============================] - 0s 794us/step - loss: 2.0720\n16/16 [==============================] - 0s 787us/step - loss: 2.4514\n16/16 [==============================] - 0s 784us/step - loss: 2.5300\n16/16 [==============================] - 0s 806us/step - loss: 2.5335\n16/16 [==============================] - 0s 798us/step - loss: 2.4858\n16/16 [==============================] - 0s 802us/step - loss: 2.4440\n16/16 [==============================] - 0s 798us/step - loss: 2.4288\n16/16 [==============================] - 0s 794us/step - loss: 2.4241\n16/16 [==============================] - 0s 794us/step - loss: 2.4240\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1168\n16/16 [==============================] - 0s 779us/step - loss: 2.0878\n16/16 [==============================] - 0s 786us/step - loss: 2.4644\n16/16 [==============================] - 0s 803us/step - loss: 2.5367\n16/16 [==============================] - 0s 800us/step - loss: 2.5353\n16/16 [==============================] - 0s 821us/step - loss: 2.4811\n16/16 [==============================] - 0s 796us/step - loss: 2.4357\n16/16 [==============================] - 0s 793us/step - loss: 2.4197\n16/16 [==============================] - 0s 784us/step - loss: 2.4149\n16/16 [==============================] - 0s 793us/step - loss: 2.4149\n\nTesting for epoch 47 index 2:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1129\n16/16 [==============================] - 0s 863us/step - loss: 2.1291\n16/16 [==============================] - 0s 866us/step - loss: 2.5159\n16/16 [==============================] - 0s 877us/step - loss: 2.5921\n16/16 [==============================] - 0s 791us/step - loss: 2.5924\n16/16 [==============================] - 0s 785us/step - loss: 2.5399\n16/16 [==============================] - 0s 793us/step - loss: 2.4954\n16/16 [==============================] - 0s 794us/step - loss: 2.4795\n16/16 [==============================] - 0s 808us/step - loss: 2.4746\n16/16 [==============================] - 0s 813us/step - loss: 2.4745\n\nTesting for epoch 47 index 3:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1157\n16/16 [==============================] - 0s 801us/step - loss: 2.0875\n16/16 [==============================] - 0s 797us/step - loss: 2.4622\n16/16 [==============================] - 0s 793us/step - loss: 2.5350\n16/16 [==============================] - 0s 793us/step - loss: 2.5349\n16/16 [==============================] - 0s 802us/step - loss: 2.4821\n16/16 [==============================] - 0s 803us/step - loss: 2.4374\n16/16 [==============================] - 0s 803us/step - loss: 2.4214\n16/16 [==============================] - 0s 790us/step - loss: 2.4166\n16/16 [==============================] - 0s 784us/step - loss: 2.4165\n\nTesting for epoch 47 index 4:\n79/79 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1148\n16/16 [==============================] - 0s 780us/step - loss: 2.1379\n16/16 [==============================] - 0s 809us/step - loss: 2.5248\n16/16 [==============================] - 0s 780us/step - loss: 2.5999\n16/16 [==============================] - 0s 872us/step - loss: 2.5989\n16/16 [==============================] - 0s 866us/step - loss: 2.5435\n16/16 [==============================] - 0s 863us/step - loss: 2.4969\n16/16 [==============================] - 0s 863us/step - loss: 2.4802\n16/16 [==============================] - 0s 787us/step - loss: 2.4751\n16/16 [==============================] - 0s 859us/step - loss: 2.4750\n\nTesting for epoch 47 index 5:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.1154\n16/16 [==============================] - 0s 786us/step - loss: 2.0392\n16/16 [==============================] - 0s 788us/step - loss: 2.4002\n16/16 [==============================] - 0s 784us/step - loss: 2.4684\n16/16 [==============================] - 0s 795us/step - loss: 2.4659\n16/16 [==============================] - 0s 801us/step - loss: 2.4131\n16/16 [==============================] - 0s 824us/step - loss: 2.3696\n16/16 [==============================] - 0s 790us/step - loss: 2.3543\n16/16 [==============================] - 0s 812us/step - loss: 2.3497\n16/16 [==============================] - 0s 795us/step - loss: 2.3497\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 876us/step - loss: 0.1150\n16/16 [==============================] - 0s 864us/step - loss: 2.1081\n16/16 [==============================] - 0s 861us/step - loss: 2.4903\n16/16 [==============================] - 0s 856us/step - loss: 2.5626\n16/16 [==============================] - 0s 862us/step - loss: 2.5596\n16/16 [==============================] - 0s 865us/step - loss: 2.5044\n16/16 [==============================] - 0s 865us/step - loss: 2.4593\n16/16 [==============================] - 0s 870us/step - loss: 2.4434\n16/16 [==============================] - 0s 875us/step - loss: 2.4386\n16/16 [==============================] - 0s 808us/step - loss: 2.4386\n\nTesting for epoch 48 index 2:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1147\n16/16 [==============================] - 0s 781us/step - loss: 2.1044\n16/16 [==============================] - 0s 779us/step - loss: 2.4888\n16/16 [==============================] - 0s 782us/step - loss: 2.5643\n16/16 [==============================] - 0s 825us/step - loss: 2.5644\n16/16 [==============================] - 0s 801us/step - loss: 2.5118\n16/16 [==============================] - 0s 819us/step - loss: 2.4675\n16/16 [==============================] - 0s 796us/step - loss: 2.4516\n16/16 [==============================] - 0s 786us/step - loss: 2.4465\n16/16 [==============================] - 0s 779us/step - loss: 2.4463\n\nTesting for epoch 48 index 3:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1152\n16/16 [==============================] - 0s 774us/step - loss: 2.0719\n16/16 [==============================] - 0s 786us/step - loss: 2.4408\n16/16 [==============================] - 0s 809us/step - loss: 2.5109\n16/16 [==============================] - 0s 793us/step - loss: 2.5086\n16/16 [==============================] - 0s 795us/step - loss: 2.4552\n16/16 [==============================] - 0s 811us/step - loss: 2.4115\n16/16 [==============================] - 0s 797us/step - loss: 2.3960\n16/16 [==============================] - 0s 824us/step - loss: 2.3913\n16/16 [==============================] - 0s 818us/step - loss: 2.3912\n\nTesting for epoch 48 index 4:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1107\n16/16 [==============================] - 0s 795us/step - loss: 2.1577\n16/16 [==============================] - 0s 857us/step - loss: 2.5481\n16/16 [==============================] - 0s 813us/step - loss: 2.6204\n16/16 [==============================] - 0s 797us/step - loss: 2.6165\n16/16 [==============================] - 0s 790us/step - loss: 2.5579\n16/16 [==============================] - 0s 782us/step - loss: 2.5097\n16/16 [==============================] - 0s 804us/step - loss: 2.4927\n16/16 [==============================] - 0s 779us/step - loss: 2.4877\n16/16 [==============================] - 0s 782us/step - loss: 2.4876\n\nTesting for epoch 48 index 5:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1159\n16/16 [==============================] - 0s 803us/step - loss: 2.0767\n16/16 [==============================] - 0s 810us/step - loss: 2.4525\n16/16 [==============================] - 0s 781us/step - loss: 2.5232\n16/16 [==============================] - 0s 796us/step - loss: 2.5203\n16/16 [==============================] - 0s 810us/step - loss: 2.4657\n16/16 [==============================] - 0s 782us/step - loss: 2.4213\n16/16 [==============================] - 0s 814us/step - loss: 2.4055\n16/16 [==============================] - 0s 805us/step - loss: 2.4008\n16/16 [==============================] - 0s 781us/step - loss: 2.4008\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1130\n16/16 [==============================] - 0s 806us/step - loss: 2.1188\n16/16 [==============================] - 0s 784us/step - loss: 2.5027\n16/16 [==============================] - 0s 783us/step - loss: 2.5749\n16/16 [==============================] - 0s 777us/step - loss: 2.5720\n16/16 [==============================] - 0s 790us/step - loss: 2.5164\n16/16 [==============================] - 0s 787us/step - loss: 2.4706\n16/16 [==============================] - 0s 823us/step - loss: 2.4543\n16/16 [==============================] - 0s 811us/step - loss: 2.4493\n16/16 [==============================] - 0s 819us/step - loss: 2.4491\n\nTesting for epoch 49 index 2:\n79/79 [==============================] - 0s 589us/step\n16/16 [==============================] - 0s 806us/step - loss: 0.1130\n16/16 [==============================] - 0s 798us/step - loss: 2.1207\n16/16 [==============================] - 0s 791us/step - loss: 2.5027\n16/16 [==============================] - 0s 807us/step - loss: 2.5732\n16/16 [==============================] - 0s 794us/step - loss: 2.5696\n16/16 [==============================] - 0s 795us/step - loss: 2.5133\n16/16 [==============================] - 0s 790us/step - loss: 2.4675\n16/16 [==============================] - 0s 787us/step - loss: 2.4516\n16/16 [==============================] - 0s 790us/step - loss: 2.4468\n16/16 [==============================] - 0s 789us/step - loss: 2.4468\n\nTesting for epoch 49 index 3:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1157\n16/16 [==============================] - 0s 771us/step - loss: 2.1044\n16/16 [==============================] - 0s 773us/step - loss: 2.4790\n16/16 [==============================] - 0s 775us/step - loss: 2.5455\n16/16 [==============================] - 0s 783us/step - loss: 2.5407\n16/16 [==============================] - 0s 848us/step - loss: 2.4851\n16/16 [==============================] - 0s 846us/step - loss: 2.4397\n16/16 [==============================] - 0s 861us/step - loss: 2.4239\n16/16 [==============================] - 0s 847us/step - loss: 2.4191\n16/16 [==============================] - 0s 868us/step - loss: 2.4191\n\nTesting for epoch 49 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1159\n16/16 [==============================] - 0s 797us/step - loss: 2.1415\n16/16 [==============================] - 0s 792us/step - loss: 2.5249\n16/16 [==============================] - 0s 821us/step - loss: 2.5930\n16/16 [==============================] - 0s 888us/step - loss: 2.5871\n16/16 [==============================] - 0s 879us/step - loss: 2.5281\n16/16 [==============================] - 0s 867us/step - loss: 2.4804\n16/16 [==============================] - 0s 893us/step - loss: 2.4640\n16/16 [==============================] - 0s 804us/step - loss: 2.4592\n16/16 [==============================] - 0s 808us/step - loss: 2.4592\n\nTesting for epoch 49 index 5:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.1108\n16/16 [==============================] - 0s 839us/step - loss: 2.1666\n16/16 [==============================] - 0s 802us/step - loss: 2.5501\n16/16 [==============================] - 0s 670us/step - loss: 2.6150\n16/16 [==============================] - 0s 783us/step - loss: 2.6061\n16/16 [==============================] - 0s 2ms/step - loss: 2.5432\n16/16 [==============================] - 0s 748us/step - loss: 2.4931\n16/16 [==============================] - 0s 2ms/step - loss: 2.4759\n16/16 [==============================] - 0s 746us/step - loss: 2.4708\n16/16 [==============================] - 0s 2ms/step - loss: 2.4707\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1092\n16/16 [==============================] - 0s 2ms/step - loss: 2.1786\n16/16 [==============================] - 0s 2ms/step - loss: 2.5691\n16/16 [==============================] - 0s 783us/step - loss: 2.6374\n16/16 [==============================] - 0s 1ms/step - loss: 2.6307\n16/16 [==============================] - 0s 983us/step - loss: 2.5707\n16/16 [==============================] - 0s 1ms/step - loss: 2.5218\n16/16 [==============================] - 0s 2ms/step - loss: 2.5047\n16/16 [==============================] - 0s 827us/step - loss: 2.4996\n16/16 [==============================] - 0s 820us/step - loss: 2.4996\n\nTesting for epoch 50 index 2:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1106\n16/16 [==============================] - 0s 812us/step - loss: 2.1213\n16/16 [==============================] - 0s 2ms/step - loss: 2.4972\n16/16 [==============================] - 0s 805us/step - loss: 2.5617\n16/16 [==============================] - 0s 2ms/step - loss: 2.5540\n16/16 [==============================] - 0s 779us/step - loss: 2.4949\n16/16 [==============================] - 0s 798us/step - loss: 2.4473\n16/16 [==============================] - 0s 802us/step - loss: 2.4311\n16/16 [==============================] - 0s 827us/step - loss: 2.4263\n16/16 [==============================] - 0s 827us/step - loss: 2.4263\n\nTesting for epoch 50 index 3:\n79/79 [==============================] - 0s 574us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1134\n16/16 [==============================] - 0s 833us/step - loss: 2.1640\n16/16 [==============================] - 0s 831us/step - loss: 2.5466\n16/16 [==============================] - 0s 806us/step - loss: 2.6094\n16/16 [==============================] - 0s 2ms/step - loss: 2.5990\n16/16 [==============================] - 0s 2ms/step - loss: 2.5356\n16/16 [==============================] - 0s 2ms/step - loss: 2.4853\n16/16 [==============================] - 0s 2ms/step - loss: 2.4681\n16/16 [==============================] - 0s 830us/step - loss: 2.4631\n16/16 [==============================] - 0s 2ms/step - loss: 2.4631\n\nTesting for epoch 50 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1106\n16/16 [==============================] - 0s 2ms/step - loss: 2.1669\n16/16 [==============================] - 0s 2ms/step - loss: 2.5499\n16/16 [==============================] - 0s 2ms/step - loss: 2.6154\n16/16 [==============================] - 0s 919us/step - loss: 2.6077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5490\n16/16 [==============================] - 0s 2ms/step - loss: 2.5020\n16/16 [==============================] - 0s 2ms/step - loss: 2.4856\n16/16 [==============================] - 0s 2ms/step - loss: 2.4805\n16/16 [==============================] - 0s 1ms/step - loss: 2.4803\n\nTesting for epoch 50 index 5:\n79/79 [==============================] - 0s 853us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1134\n16/16 [==============================] - 0s 1ms/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.5127\n16/16 [==============================] - 0s 1ms/step - loss: 2.5788\n16/16 [==============================] - 0s 818us/step - loss: 2.5713\n16/16 [==============================] - 0s 828us/step - loss: 2.5120\n16/16 [==============================] - 0s 806us/step - loss: 2.4655\n16/16 [==============================] - 0s 1ms/step - loss: 2.4496\n16/16 [==============================] - 0s 825us/step - loss: 2.4450\n16/16 [==============================] - 0s 851us/step - loss: 2.4451\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1102\n16/16 [==============================] - 0s 2ms/step - loss: 2.1080\n16/16 [==============================] - 0s 1ms/step - loss: 2.4813\n16/16 [==============================] - 0s 801us/step - loss: 2.5444\n16/16 [==============================] - 0s 1ms/step - loss: 2.5367\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 779us/step - loss: 2.4343\n16/16 [==============================] - 0s 780us/step - loss: 2.4184\n16/16 [==============================] - 0s 809us/step - loss: 2.4137\n16/16 [==============================] - 0s 816us/step - loss: 2.4137\n\nTesting for epoch 51 index 2:\n79/79 [==============================] - 0s 544us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1094\n16/16 [==============================] - 0s 2ms/step - loss: 2.1884\n16/16 [==============================] - 0s 825us/step - loss: 2.5791\n16/16 [==============================] - 0s 1ms/step - loss: 2.6449\n16/16 [==============================] - 0s 837us/step - loss: 2.6358\n16/16 [==============================] - 0s 1ms/step - loss: 2.5744\n16/16 [==============================] - 0s 792us/step - loss: 2.5257\n16/16 [==============================] - 0s 2ms/step - loss: 2.5088\n16/16 [==============================] - 0s 807us/step - loss: 2.5036\n16/16 [==============================] - 0s 2ms/step - loss: 2.5035\n\nTesting for epoch 51 index 3:\n79/79 [==============================] - 0s 575us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1135\n16/16 [==============================] - 0s 918us/step - loss: 2.1417\n16/16 [==============================] - 0s 778us/step - loss: 2.5163\n16/16 [==============================] - 0s 839us/step - loss: 2.5775\n16/16 [==============================] - 0s 1ms/step - loss: 2.5668\n16/16 [==============================] - 0s 817us/step - loss: 2.5060\n16/16 [==============================] - 0s 820us/step - loss: 2.4582\n16/16 [==============================] - 0s 2ms/step - loss: 2.4420\n16/16 [==============================] - 0s 2ms/step - loss: 2.4372\n16/16 [==============================] - 0s 2ms/step - loss: 2.4371\n\nTesting for epoch 51 index 4:\n79/79 [==============================] - 0s 660us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1133\n16/16 [==============================] - 0s 2ms/step - loss: 2.1446\n16/16 [==============================] - 0s 780us/step - loss: 2.5259\n16/16 [==============================] - 0s 2ms/step - loss: 2.5907\n16/16 [==============================] - 0s 2ms/step - loss: 2.5826\n16/16 [==============================] - 0s 2ms/step - loss: 2.5259\n16/16 [==============================] - 0s 778us/step - loss: 2.4802\n16/16 [==============================] - 0s 945us/step - loss: 2.4642\n16/16 [==============================] - 0s 2ms/step - loss: 2.4593\n16/16 [==============================] - 0s 937us/step - loss: 2.4592\n\nTesting for epoch 51 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 867us/step - loss: 0.1097\n16/16 [==============================] - 0s 2ms/step - loss: 2.1334\n16/16 [==============================] - 0s 2ms/step - loss: 2.5077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5687\n16/16 [==============================] - 0s 814us/step - loss: 2.5580\n16/16 [==============================] - 0s 1ms/step - loss: 2.4978\n16/16 [==============================] - 0s 1ms/step - loss: 2.4505\n16/16 [==============================] - 0s 2ms/step - loss: 2.4342\n16/16 [==============================] - 0s 804us/step - loss: 2.4293\n16/16 [==============================] - 0s 831us/step - loss: 2.4292\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n79/79 [==============================] - 0s 964us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1128\n16/16 [==============================] - 0s 2ms/step - loss: 2.1843\n16/16 [==============================] - 0s 1ms/step - loss: 2.5731\n16/16 [==============================] - 0s 992us/step - loss: 2.6381\n16/16 [==============================] - 0s 2ms/step - loss: 2.6285\n16/16 [==============================] - 0s 2ms/step - loss: 2.5692\n16/16 [==============================] - 0s 815us/step - loss: 2.5219\n16/16 [==============================] - 0s 944us/step - loss: 2.5053\n16/16 [==============================] - 0s 740us/step - loss: 2.5000\n16/16 [==============================] - 0s 799us/step - loss: 2.4998\n\nTesting for epoch 52 index 2:\n79/79 [==============================] - 0s 498us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1151\n16/16 [==============================] - 0s 662us/step - loss: 2.1366\n16/16 [==============================] - 0s 786us/step - loss: 2.5143\n16/16 [==============================] - 0s 832us/step - loss: 2.5790\n16/16 [==============================] - 0s 828us/step - loss: 2.5708\n16/16 [==============================] - 0s 772us/step - loss: 2.5126\n16/16 [==============================] - 0s 763us/step - loss: 2.4669\n16/16 [==============================] - 0s 761us/step - loss: 2.4509\n16/16 [==============================] - 0s 762us/step - loss: 2.4460\n16/16 [==============================] - 0s 765us/step - loss: 2.4459\n\nTesting for epoch 52 index 3:\n79/79 [==============================] - 0s 651us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1137\n16/16 [==============================] - 0s 776us/step - loss: 2.1214\n16/16 [==============================] - 0s 777us/step - loss: 2.4961\n16/16 [==============================] - 0s 810us/step - loss: 2.5559\n16/16 [==============================] - 0s 1ms/step - loss: 2.5443\n16/16 [==============================] - 0s 1ms/step - loss: 2.4830\n16/16 [==============================] - 0s 1ms/step - loss: 2.4348\n16/16 [==============================] - 0s 1ms/step - loss: 2.4184\n16/16 [==============================] - 0s 823us/step - loss: 2.4137\n16/16 [==============================] - 0s 786us/step - loss: 2.4137\n\nTesting for epoch 52 index 4:\n79/79 [==============================] - 0s 809us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1077\n16/16 [==============================] - 0s 1ms/step - loss: 2.2251\n16/16 [==============================] - 0s 765us/step - loss: 2.6189\n16/16 [==============================] - 0s 1ms/step - loss: 2.6792\n16/16 [==============================] - 0s 1ms/step - loss: 2.6652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5992\n16/16 [==============================] - 0s 1ms/step - loss: 2.5479\n16/16 [==============================] - 0s 787us/step - loss: 2.5304\n16/16 [==============================] - 0s 1ms/step - loss: 2.5253\n16/16 [==============================] - 0s 1ms/step - loss: 2.5253\n\nTesting for epoch 52 index 5:\n79/79 [==============================] - 0s 575us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1081\n16/16 [==============================] - 0s 787us/step - loss: 2.1911\n16/16 [==============================] - 0s 801us/step - loss: 2.5848\n16/16 [==============================] - 0s 776us/step - loss: 2.6481\n16/16 [==============================] - 0s 819us/step - loss: 2.6369\n16/16 [==============================] - 0s 784us/step - loss: 2.5737\n16/16 [==============================] - 0s 778us/step - loss: 2.5244\n16/16 [==============================] - 0s 774us/step - loss: 2.5073\n16/16 [==============================] - 0s 830us/step - loss: 2.5021\n16/16 [==============================] - 0s 783us/step - loss: 2.5019\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.1105\n16/16 [==============================] - 0s 798us/step - loss: 2.2424\n16/16 [==============================] - 0s 801us/step - loss: 2.6434\n16/16 [==============================] - 0s 782us/step - loss: 2.7071\n16/16 [==============================] - 0s 809us/step - loss: 2.6960\n16/16 [==============================] - 0s 781us/step - loss: 2.6329\n16/16 [==============================] - 0s 796us/step - loss: 2.5825\n16/16 [==============================] - 0s 785us/step - loss: 2.5653\n16/16 [==============================] - 0s 779us/step - loss: 2.5603\n16/16 [==============================] - 0s 780us/step - loss: 2.5603\n\nTesting for epoch 53 index 2:\n79/79 [==============================] - 0s 666us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1065\n16/16 [==============================] - 0s 773us/step - loss: 2.2126\n16/16 [==============================] - 0s 780us/step - loss: 2.5990\n16/16 [==============================] - 0s 799us/step - loss: 2.6537\n16/16 [==============================] - 0s 775us/step - loss: 2.6362\n16/16 [==============================] - 0s 778us/step - loss: 2.5665\n16/16 [==============================] - 0s 777us/step - loss: 2.5130\n16/16 [==============================] - 0s 782us/step - loss: 2.4951\n16/16 [==============================] - 0s 793us/step - loss: 2.4897\n16/16 [==============================] - 0s 783us/step - loss: 2.4896\n\nTesting for epoch 53 index 3:\n79/79 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1109\n16/16 [==============================] - 0s 783us/step - loss: 2.2409\n16/16 [==============================] - 0s 826us/step - loss: 2.6359\n16/16 [==============================] - 0s 802us/step - loss: 2.6951\n16/16 [==============================] - 0s 784us/step - loss: 2.6803\n16/16 [==============================] - 0s 818us/step - loss: 2.6154\n16/16 [==============================] - 0s 854us/step - loss: 2.5654\n16/16 [==============================] - 0s 824us/step - loss: 2.5480\n16/16 [==============================] - 0s 878us/step - loss: 2.5427\n16/16 [==============================] - 0s 823us/step - loss: 2.5425\n\nTesting for epoch 53 index 4:\n79/79 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 822us/step - loss: 0.1077\n16/16 [==============================] - 0s 774us/step - loss: 2.1988\n16/16 [==============================] - 0s 791us/step - loss: 2.5828\n16/16 [==============================] - 0s 824us/step - loss: 2.6395\n16/16 [==============================] - 0s 777us/step - loss: 2.6247\n16/16 [==============================] - 0s 786us/step - loss: 2.5585\n16/16 [==============================] - 0s 791us/step - loss: 2.5071\n16/16 [==============================] - 0s 796us/step - loss: 2.4895\n16/16 [==============================] - 0s 784us/step - loss: 2.4842\n16/16 [==============================] - 0s 781us/step - loss: 2.4840\n\nTesting for epoch 53 index 5:\n79/79 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.1101\n16/16 [==============================] - 0s 823us/step - loss: 2.1742\n16/16 [==============================] - 0s 806us/step - loss: 2.5541\n16/16 [==============================] - 0s 815us/step - loss: 2.6106\n16/16 [==============================] - 0s 786us/step - loss: 2.5974\n16/16 [==============================] - 0s 779us/step - loss: 2.5359\n16/16 [==============================] - 0s 777us/step - loss: 2.4884\n16/16 [==============================] - 0s 821us/step - loss: 2.4719\n16/16 [==============================] - 0s 831us/step - loss: 2.4668\n16/16 [==============================] - 0s 794us/step - loss: 2.4666\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 824us/step - loss: 0.1084\n16/16 [==============================] - 0s 791us/step - loss: 2.1517\n16/16 [==============================] - 0s 804us/step - loss: 2.5217\n16/16 [==============================] - 0s 781us/step - loss: 2.5735\n16/16 [==============================] - 0s 773us/step - loss: 2.5572\n16/16 [==============================] - 0s 860us/step - loss: 2.4921\n16/16 [==============================] - 0s 798us/step - loss: 2.4427\n16/16 [==============================] - 0s 783us/step - loss: 2.4259\n16/16 [==============================] - 0s 788us/step - loss: 2.4209\n16/16 [==============================] - 0s 779us/step - loss: 2.4208\n\nTesting for epoch 54 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 841us/step - loss: 0.1095\n16/16 [==============================] - 0s 791us/step - loss: 2.1899\n16/16 [==============================] - 0s 857us/step - loss: 2.5646\n16/16 [==============================] - 0s 832us/step - loss: 2.6178\n16/16 [==============================] - 0s 805us/step - loss: 2.5997\n16/16 [==============================] - 0s 811us/step - loss: 2.5326\n16/16 [==============================] - 0s 1ms/step - loss: 2.4819\n16/16 [==============================] - 0s 799us/step - loss: 2.4647\n16/16 [==============================] - 0s 810us/step - loss: 2.4596\n16/16 [==============================] - 0s 818us/step - loss: 2.4596\n\nTesting for epoch 54 index 3:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1083\n16/16 [==============================] - 0s 802us/step - loss: 2.1131\n16/16 [==============================] - 0s 796us/step - loss: 2.4631\n16/16 [==============================] - 0s 776us/step - loss: 2.5087\n16/16 [==============================] - 0s 791us/step - loss: 2.4890\n16/16 [==============================] - 0s 833us/step - loss: 2.4226\n16/16 [==============================] - 0s 784us/step - loss: 2.3731\n16/16 [==============================] - 0s 772us/step - loss: 2.3567\n16/16 [==============================] - 0s 772us/step - loss: 2.3520\n16/16 [==============================] - 0s 798us/step - loss: 2.3520\n\nTesting for epoch 54 index 4:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1097\n16/16 [==============================] - 0s 820us/step - loss: 2.2147\n16/16 [==============================] - 0s 790us/step - loss: 2.5931\n16/16 [==============================] - 0s 786us/step - loss: 2.6463\n16/16 [==============================] - 0s 793us/step - loss: 2.6278\n16/16 [==============================] - 0s 815us/step - loss: 2.5607\n16/16 [==============================] - 0s 786us/step - loss: 2.5099\n16/16 [==============================] - 0s 800us/step - loss: 2.4930\n16/16 [==============================] - 0s 804us/step - loss: 2.4882\n16/16 [==============================] - 0s 803us/step - loss: 2.4882\n\nTesting for epoch 54 index 5:\n79/79 [==============================] - 0s 598us/step\n16/16 [==============================] - 0s 865us/step - loss: 0.1090\n16/16 [==============================] - 0s 821us/step - loss: 2.2205\n16/16 [==============================] - 0s 781us/step - loss: 2.5931\n16/16 [==============================] - 0s 1ms/step - loss: 2.6411\n16/16 [==============================] - 0s 1ms/step - loss: 2.6206\n16/16 [==============================] - 0s 783us/step - loss: 2.5518\n16/16 [==============================] - 0s 789us/step - loss: 2.5000\n16/16 [==============================] - 0s 791us/step - loss: 2.4825\n16/16 [==============================] - 0s 786us/step - loss: 2.4773\n16/16 [==============================] - 0s 784us/step - loss: 2.4773\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.1066\n16/16 [==============================] - 0s 821us/step - loss: 2.2507\n16/16 [==============================] - 0s 780us/step - loss: 2.6376\n16/16 [==============================] - 0s 776us/step - loss: 2.6928\n16/16 [==============================] - 0s 775us/step - loss: 2.6741\n16/16 [==============================] - 0s 780us/step - loss: 2.6065\n16/16 [==============================] - 0s 778us/step - loss: 2.5550\n16/16 [==============================] - 0s 908us/step - loss: 2.5376\n16/16 [==============================] - 0s 1ms/step - loss: 2.5325\n16/16 [==============================] - 0s 1ms/step - loss: 2.5324\n\nTesting for epoch 55 index 2:\n79/79 [==============================] - 0s 827us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1066\n16/16 [==============================] - 0s 830us/step - loss: 2.2226\n16/16 [==============================] - 0s 782us/step - loss: 2.5906\n16/16 [==============================] - 0s 780us/step - loss: 2.6408\n16/16 [==============================] - 0s 1ms/step - loss: 2.6207\n16/16 [==============================] - 0s 1ms/step - loss: 2.5530\n16/16 [==============================] - 0s 1ms/step - loss: 2.5026\n16/16 [==============================] - 0s 1ms/step - loss: 2.4856\n16/16 [==============================] - 0s 1ms/step - loss: 2.4805\n16/16 [==============================] - 0s 1ms/step - loss: 2.4805\n\nTesting for epoch 55 index 3:\n79/79 [==============================] - 0s 733us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1096\n16/16 [==============================] - 0s 1ms/step - loss: 2.2626\n16/16 [==============================] - 0s 1ms/step - loss: 2.6387\n16/16 [==============================] - 0s 1ms/step - loss: 2.6881\n16/16 [==============================] - 0s 1ms/step - loss: 2.6669\n16/16 [==============================] - 0s 1ms/step - loss: 2.5970\n16/16 [==============================] - 0s 1ms/step - loss: 2.5450\n16/16 [==============================] - 0s 1ms/step - loss: 2.5276\n16/16 [==============================] - 0s 1ms/step - loss: 2.5226\n16/16 [==============================] - 0s 799us/step - loss: 2.5226\n\nTesting for epoch 55 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1016\n16/16 [==============================] - 0s 783us/step - loss: 2.2888\n16/16 [==============================] - 0s 782us/step - loss: 2.6711\n16/16 [==============================] - 0s 815us/step - loss: 2.7212\n16/16 [==============================] - 0s 1ms/step - loss: 2.6985\n16/16 [==============================] - 0s 848us/step - loss: 2.6265\n16/16 [==============================] - 0s 837us/step - loss: 2.5724\n16/16 [==============================] - 0s 788us/step - loss: 2.5543\n16/16 [==============================] - 0s 828us/step - loss: 2.5490\n16/16 [==============================] - 0s 827us/step - loss: 2.5490\n\nTesting for epoch 55 index 5:\n79/79 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 924us/step - loss: 0.1076\n16/16 [==============================] - 0s 874us/step - loss: 2.3363\n16/16 [==============================] - 0s 793us/step - loss: 2.7287\n16/16 [==============================] - 0s 798us/step - loss: 2.7820\n16/16 [==============================] - 0s 796us/step - loss: 2.7605\n16/16 [==============================] - 0s 836us/step - loss: 2.6894\n16/16 [==============================] - 0s 801us/step - loss: 2.6356\n16/16 [==============================] - 0s 797us/step - loss: 2.6175\n16/16 [==============================] - 0s 791us/step - loss: 2.6122\n16/16 [==============================] - 0s 794us/step - loss: 2.6122\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1053\n16/16 [==============================] - 0s 823us/step - loss: 2.2654\n16/16 [==============================] - 0s 784us/step - loss: 2.6376\n16/16 [==============================] - 0s 796us/step - loss: 2.6831\n16/16 [==============================] - 0s 798us/step - loss: 2.6585\n16/16 [==============================] - 0s 784us/step - loss: 2.5853\n16/16 [==============================] - 0s 784us/step - loss: 2.5317\n16/16 [==============================] - 0s 776us/step - loss: 2.5138\n16/16 [==============================] - 0s 788us/step - loss: 2.5086\n16/16 [==============================] - 0s 780us/step - loss: 2.5085\n\nTesting for epoch 56 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1091\n16/16 [==============================] - 0s 846us/step - loss: 2.2312\n16/16 [==============================] - 0s 782us/step - loss: 2.6027\n16/16 [==============================] - 0s 806us/step - loss: 2.6531\n16/16 [==============================] - 0s 791us/step - loss: 2.6318\n16/16 [==============================] - 0s 771us/step - loss: 2.5612\n16/16 [==============================] - 0s 795us/step - loss: 2.5079\n16/16 [==============================] - 0s 779us/step - loss: 2.4899\n16/16 [==============================] - 0s 788us/step - loss: 2.4844\n16/16 [==============================] - 0s 784us/step - loss: 2.4842\n\nTesting for epoch 56 index 3:\n79/79 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1080\n16/16 [==============================] - 0s 804us/step - loss: 2.2179\n16/16 [==============================] - 0s 792us/step - loss: 2.5805\n16/16 [==============================] - 0s 778us/step - loss: 2.6276\n16/16 [==============================] - 0s 777us/step - loss: 2.6063\n16/16 [==============================] - 0s 784us/step - loss: 2.5380\n16/16 [==============================] - 0s 779us/step - loss: 2.4867\n16/16 [==============================] - 0s 795us/step - loss: 2.4695\n16/16 [==============================] - 0s 798us/step - loss: 2.4644\n16/16 [==============================] - 0s 791us/step - loss: 2.4644\n\nTesting for epoch 56 index 4:\n79/79 [==============================] - 0s 709us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1050\n16/16 [==============================] - 0s 1ms/step - loss: 2.2906\n16/16 [==============================] - 0s 1ms/step - loss: 2.6671\n16/16 [==============================] - 0s 1ms/step - loss: 2.7144\n16/16 [==============================] - 0s 1ms/step - loss: 2.6909\n16/16 [==============================] - 0s 1ms/step - loss: 2.6183\n16/16 [==============================] - 0s 787us/step - loss: 2.5653\n16/16 [==============================] - 0s 783us/step - loss: 2.5474\n16/16 [==============================] - 0s 800us/step - loss: 2.5423\n16/16 [==============================] - 0s 1ms/step - loss: 2.5422\n\nTesting for epoch 56 index 5:\n79/79 [==============================] - 0s 823us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1082\n16/16 [==============================] - 0s 831us/step - loss: 2.2431\n16/16 [==============================] - 0s 843us/step - loss: 2.6105\n16/16 [==============================] - 0s 781us/step - loss: 2.6582\n16/16 [==============================] - 0s 786us/step - loss: 2.6367\n16/16 [==============================] - 0s 790us/step - loss: 2.5673\n16/16 [==============================] - 0s 809us/step - loss: 2.5156\n16/16 [==============================] - 0s 805us/step - loss: 2.4986\n16/16 [==============================] - 0s 807us/step - loss: 2.4937\n16/16 [==============================] - 0s 804us/step - loss: 2.4937\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n79/79 [==============================] - 0s 582us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1051\n16/16 [==============================] - 0s 794us/step - loss: 2.3166\n16/16 [==============================] - 0s 852us/step - loss: 2.6952\n16/16 [==============================] - 0s 812us/step - loss: 2.7417\n16/16 [==============================] - 0s 788us/step - loss: 2.7163\n16/16 [==============================] - 0s 781us/step - loss: 2.6402\n16/16 [==============================] - 0s 775us/step - loss: 2.5838\n16/16 [==============================] - 0s 787us/step - loss: 2.5650\n16/16 [==============================] - 0s 783us/step - loss: 2.5596\n16/16 [==============================] - 0s 808us/step - loss: 2.5596\n\nTesting for epoch 57 index 2:\n79/79 [==============================] - 0s 614us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1056\n16/16 [==============================] - 0s 1ms/step - loss: 2.1999\n16/16 [==============================] - 0s 1ms/step - loss: 2.5532\n16/16 [==============================] - 0s 1ms/step - loss: 2.5957\n16/16 [==============================] - 0s 1ms/step - loss: 2.5734\n16/16 [==============================] - 0s 930us/step - loss: 2.5046\n16/16 [==============================] - 0s 902us/step - loss: 2.4545\n16/16 [==============================] - 0s 1ms/step - loss: 2.4380\n16/16 [==============================] - 0s 1ms/step - loss: 2.4332\n16/16 [==============================] - 0s 1ms/step - loss: 2.4332\n\nTesting for epoch 57 index 3:\n79/79 [==============================] - 0s 665us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1134\n16/16 [==============================] - 0s 842us/step - loss: 2.1538\n16/16 [==============================] - 0s 780us/step - loss: 2.5023\n16/16 [==============================] - 0s 775us/step - loss: 2.5460\n16/16 [==============================] - 0s 788us/step - loss: 2.5254\n16/16 [==============================] - 0s 775us/step - loss: 2.4601\n16/16 [==============================] - 0s 775us/step - loss: 2.4117\n16/16 [==============================] - 0s 789us/step - loss: 2.3954\n16/16 [==============================] - 0s 788us/step - loss: 2.3907\n16/16 [==============================] - 0s 787us/step - loss: 2.3906\n\nTesting for epoch 57 index 4:\n79/79 [==============================] - 0s 909us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1055\n16/16 [==============================] - 0s 809us/step - loss: 2.3141\n16/16 [==============================] - 0s 817us/step - loss: 2.6890\n16/16 [==============================] - 0s 861us/step - loss: 2.7333\n16/16 [==============================] - 0s 789us/step - loss: 2.7077\n16/16 [==============================] - 0s 777us/step - loss: 2.6323\n16/16 [==============================] - 0s 780us/step - loss: 2.5774\n16/16 [==============================] - 0s 780us/step - loss: 2.5593\n16/16 [==============================] - 0s 802us/step - loss: 2.5541\n16/16 [==============================] - 0s 790us/step - loss: 2.5541\n\nTesting for epoch 57 index 5:\n79/79 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1056\n16/16 [==============================] - 0s 789us/step - loss: 2.2966\n16/16 [==============================] - 0s 796us/step - loss: 2.6697\n16/16 [==============================] - 0s 781us/step - loss: 2.7157\n16/16 [==============================] - 0s 781us/step - loss: 2.6915\n16/16 [==============================] - 0s 1ms/step - loss: 2.6184\n16/16 [==============================] - 0s 1ms/step - loss: 2.5641\n16/16 [==============================] - 0s 803us/step - loss: 2.5462\n16/16 [==============================] - 0s 776us/step - loss: 2.5410\n16/16 [==============================] - 0s 805us/step - loss: 2.5409\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n79/79 [==============================] - 0s 585us/step\n16/16 [==============================] - 0s 781us/step - loss: 0.1061\n16/16 [==============================] - 0s 785us/step - loss: 2.3267\n16/16 [==============================] - 0s 777us/step - loss: 2.7069\n16/16 [==============================] - 0s 784us/step - loss: 2.7544\n16/16 [==============================] - 0s 782us/step - loss: 2.7306\n16/16 [==============================] - 0s 1ms/step - loss: 2.6573\n16/16 [==============================] - 0s 816us/step - loss: 2.6031\n16/16 [==============================] - 0s 1ms/step - loss: 2.5850\n16/16 [==============================] - 0s 1ms/step - loss: 2.5797\n16/16 [==============================] - 0s 1ms/step - loss: 2.5796\n\nTesting for epoch 58 index 2:\n79/79 [==============================] - 0s 578us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1053\n16/16 [==============================] - 0s 1ms/step - loss: 2.2433\n16/16 [==============================] - 0s 778us/step - loss: 2.6007\n16/16 [==============================] - 0s 778us/step - loss: 2.6389\n16/16 [==============================] - 0s 782us/step - loss: 2.6116\n16/16 [==============================] - 0s 784us/step - loss: 2.5366\n16/16 [==============================] - 0s 777us/step - loss: 2.4824\n16/16 [==============================] - 0s 773us/step - loss: 2.4647\n16/16 [==============================] - 0s 780us/step - loss: 2.4596\n16/16 [==============================] - 0s 792us/step - loss: 2.4596\n\nTesting for epoch 58 index 3:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 796us/step - loss: 0.1060\n16/16 [==============================] - 0s 813us/step - loss: 2.2387\n16/16 [==============================] - 0s 788us/step - loss: 2.5997\n16/16 [==============================] - 0s 780us/step - loss: 2.6431\n16/16 [==============================] - 0s 827us/step - loss: 2.6195\n16/16 [==============================] - 0s 818us/step - loss: 2.5483\n16/16 [==============================] - 0s 820us/step - loss: 2.4955\n16/16 [==============================] - 0s 774us/step - loss: 2.4780\n16/16 [==============================] - 0s 791us/step - loss: 2.4729\n16/16 [==============================] - 0s 801us/step - loss: 2.4729\n\nTesting for epoch 58 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 812us/step - loss: 0.1044\n16/16 [==============================] - 0s 792us/step - loss: 2.3186\n16/16 [==============================] - 0s 778us/step - loss: 2.6976\n16/16 [==============================] - 0s 779us/step - loss: 2.7451\n16/16 [==============================] - 0s 783us/step - loss: 2.7220\n16/16 [==============================] - 0s 795us/step - loss: 2.6492\n16/16 [==============================] - 0s 787us/step - loss: 2.5949\n16/16 [==============================] - 0s 792us/step - loss: 2.5768\n16/16 [==============================] - 0s 1ms/step - loss: 2.5714\n16/16 [==============================] - 0s 807us/step - loss: 2.5713\n\nTesting for epoch 58 index 5:\n79/79 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.1039\n16/16 [==============================] - 0s 794us/step - loss: 2.2733\n16/16 [==============================] - 0s 768us/step - loss: 2.6396\n16/16 [==============================] - 0s 790us/step - loss: 2.6824\n16/16 [==============================] - 0s 774us/step - loss: 2.6577\n16/16 [==============================] - 0s 780us/step - loss: 2.5860\n16/16 [==============================] - 0s 1ms/step - loss: 2.5336\n16/16 [==============================] - 0s 1ms/step - loss: 2.5162\n16/16 [==============================] - 0s 1ms/step - loss: 2.5110\n16/16 [==============================] - 0s 1ms/step - loss: 2.5109\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n79/79 [==============================] - 0s 574us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1015\n16/16 [==============================] - 0s 799us/step - loss: 2.2663\n16/16 [==============================] - 0s 786us/step - loss: 2.6320\n16/16 [==============================] - 0s 785us/step - loss: 2.6746\n16/16 [==============================] - 0s 782us/step - loss: 2.6500\n16/16 [==============================] - 0s 779us/step - loss: 2.5779\n16/16 [==============================] - 0s 776us/step - loss: 2.5255\n16/16 [==============================] - 0s 781us/step - loss: 2.5079\n16/16 [==============================] - 0s 780us/step - loss: 2.5025\n16/16 [==============================] - 0s 807us/step - loss: 2.5023\n\nTesting for epoch 59 index 2:\n79/79 [==============================] - 0s 578us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1025\n16/16 [==============================] - 0s 807us/step - loss: 2.3515\n16/16 [==============================] - 0s 777us/step - loss: 2.7275\n16/16 [==============================] - 0s 774us/step - loss: 2.7688\n16/16 [==============================] - 0s 1ms/step - loss: 2.7405\n16/16 [==============================] - 0s 1ms/step - loss: 2.6618\n16/16 [==============================] - 0s 776us/step - loss: 2.6044\n16/16 [==============================] - 0s 1ms/step - loss: 2.5857\n16/16 [==============================] - 0s 780us/step - loss: 2.5804\n16/16 [==============================] - 0s 786us/step - loss: 2.5804\n\nTesting for epoch 59 index 3:\n79/79 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1027\n16/16 [==============================] - 0s 791us/step - loss: 2.2619\n16/16 [==============================] - 0s 780us/step - loss: 2.6166\n16/16 [==============================] - 0s 783us/step - loss: 2.6521\n16/16 [==============================] - 0s 819us/step - loss: 2.6231\n16/16 [==============================] - 0s 796us/step - loss: 2.5477\n16/16 [==============================] - 0s 827us/step - loss: 2.4932\n16/16 [==============================] - 0s 795us/step - loss: 2.4756\n16/16 [==============================] - 0s 786us/step - loss: 2.4707\n16/16 [==============================] - 0s 778us/step - loss: 2.4708\n\nTesting for epoch 59 index 4:\n79/79 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 808us/step - loss: 0.1013\n16/16 [==============================] - 0s 800us/step - loss: 2.2814\n16/16 [==============================] - 0s 797us/step - loss: 2.6450\n16/16 [==============================] - 0s 797us/step - loss: 2.6843\n16/16 [==============================] - 0s 797us/step - loss: 2.6560\n16/16 [==============================] - 0s 801us/step - loss: 2.5800\n16/16 [==============================] - 0s 792us/step - loss: 2.5259\n16/16 [==============================] - 0s 796us/step - loss: 2.5080\n16/16 [==============================] - 0s 814us/step - loss: 2.5027\n16/16 [==============================] - 0s 820us/step - loss: 2.5026\n\nTesting for epoch 59 index 5:\n79/79 [==============================] - 0s 657us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1035\n16/16 [==============================] - 0s 785us/step - loss: 2.3241\n16/16 [==============================] - 0s 810us/step - loss: 2.7005\n16/16 [==============================] - 0s 802us/step - loss: 2.7443\n16/16 [==============================] - 0s 788us/step - loss: 2.7189\n16/16 [==============================] - 0s 785us/step - loss: 2.6445\n16/16 [==============================] - 0s 783us/step - loss: 2.5895\n16/16 [==============================] - 0s 787us/step - loss: 2.5711\n16/16 [==============================] - 0s 794us/step - loss: 2.5655\n16/16 [==============================] - 0s 1ms/step - loss: 2.5654\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n79/79 [==============================] - 0s 828us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0991\n16/16 [==============================] - 0s 797us/step - loss: 2.3587\n16/16 [==============================] - 0s 1ms/step - loss: 2.7350\n16/16 [==============================] - 0s 1ms/step - loss: 2.7747\n16/16 [==============================] - 0s 1ms/step - loss: 2.7463\n16/16 [==============================] - 0s 1ms/step - loss: 2.6678\n16/16 [==============================] - 0s 1ms/step - loss: 2.6113\n16/16 [==============================] - 0s 1ms/step - loss: 2.5929\n16/16 [==============================] - 0s 1ms/step - loss: 2.5877\n16/16 [==============================] - 0s 809us/step - loss: 2.5878\n\nTesting for epoch 60 index 2:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 828us/step - loss: 0.1038\n16/16 [==============================] - 0s 830us/step - loss: 2.2804\n16/16 [==============================] - 0s 783us/step - loss: 2.6366\n16/16 [==============================] - 0s 788us/step - loss: 2.6709\n16/16 [==============================] - 0s 1ms/step - loss: 2.6408\n16/16 [==============================] - 0s 1ms/step - loss: 2.5626\n16/16 [==============================] - 0s 1ms/step - loss: 2.5067\n16/16 [==============================] - 0s 1ms/step - loss: 2.4886\n16/16 [==============================] - 0s 1ms/step - loss: 2.4834\n16/16 [==============================] - 0s 803us/step - loss: 2.4834\n\nTesting for epoch 60 index 3:\n79/79 [==============================] - 0s 812us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.0991\n16/16 [==============================] - 0s 1ms/step - loss: 2.3934\n16/16 [==============================] - 0s 1ms/step - loss: 2.7744\n16/16 [==============================] - 0s 1ms/step - loss: 2.8152\n16/16 [==============================] - 0s 1ms/step - loss: 2.7874\n16/16 [==============================] - 0s 1ms/step - loss: 2.7085\n16/16 [==============================] - 0s 777us/step - loss: 2.6519\n16/16 [==============================] - 0s 1ms/step - loss: 2.6333\n16/16 [==============================] - 0s 778us/step - loss: 2.6279\n16/16 [==============================] - 0s 1ms/step - loss: 2.6278\n\nTesting for epoch 60 index 4:\n79/79 [==============================] - 0s 579us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.0991\n16/16 [==============================] - 0s 784us/step - loss: 2.3763\n16/16 [==============================] - 0s 782us/step - loss: 2.7524\n16/16 [==============================] - 0s 782us/step - loss: 2.7925\n16/16 [==============================] - 0s 1ms/step - loss: 2.7641\n16/16 [==============================] - 0s 1ms/step - loss: 2.6876\n16/16 [==============================] - 0s 1ms/step - loss: 2.6322\n16/16 [==============================] - 0s 1ms/step - loss: 2.6139\n16/16 [==============================] - 0s 1ms/step - loss: 2.6085\n16/16 [==============================] - 0s 1ms/step - loss: 2.6085\n\nTesting for epoch 60 index 5:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1005\n16/16 [==============================] - 0s 785us/step - loss: 2.3451\n16/16 [==============================] - 0s 785us/step - loss: 2.7153\n16/16 [==============================] - 0s 771us/step - loss: 2.7525\n16/16 [==============================] - 0s 774us/step - loss: 2.7234\n16/16 [==============================] - 0s 789us/step - loss: 2.6445\n16/16 [==============================] - 0s 784us/step - loss: 2.5884\n16/16 [==============================] - 0s 789us/step - loss: 2.5702\n16/16 [==============================] - 0s 789us/step - loss: 2.5652\n16/16 [==============================] - 0s 802us/step - loss: 2.5653\n79/79 [==============================] - 0s 580us/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthirteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  thirteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.978\nPrecision: 0.990\nRecall: 0.987\nF1 Score: 0.989\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = thirteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny-result",
    "title": "Other Outlier Detection",
    "section": "Bunny Result",
    "text": "Bunny Result\n\nfourteen.round(3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.988\n      0.995\n      0.993\n      0.994\n    \n    \n      LOF (Breunig et al., 2000)\n      0.913\n      0.955\n      0.953\n      0.954\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.942\n      0.997\n      0.942\n      0.969\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.935\n      0.992\n      0.939\n      0.965\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.982\n      0.992\n      0.989\n      0.990\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.954\n      0.977\n      0.974\n      0.976\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.979\n      0.990\n      0.988\n      0.989\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.827\n      0.995\n      0.822\n      0.900\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.919\n      0.958\n      0.956\n      0.957\n    \n    \n      SOS (Janssens et al., 2012)\n      0.912\n      0.955\n      0.953\n      0.954\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.952\n      0.952\n      1.000\n      0.975\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.952\n      0.952\n      1.000\n      0.975\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.978\n      0.990\n      0.987\n      0.989\n    \n  \n\n\n\n\n\n\n\nBunny 5%\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nGODE\n0.988\n0.995\n0.993\n0.994\n\n\nLOF (Breunig et al., 2000)\n0.913\n0.955\n0.953\n0.954\n\n\nKNN\n\n\n\n\n\n\nCBLOF\n\n\n\n\n\n\nOCSVM (Sch ̈olkopf et al., 2001)\n\n\n\n\n\n\nMCD (Hardin and Rocke, 2004)\n0.982\n0.992\n0.989\n0.990\n\n\nFeature Bagging (Lazarevic and Kumar, 2005)\n0.954\n0.977\n0.975\n0.976\n\n\nABOD (Kriegel et al., 2008)\n0.977\n0.989\n0.987\n0.988\n\n\nIsolation Forest (Liu et al., 2008)\n0.802\n0.996\n0.795\n0.884\n\n\nHBOS (Goldstein and Dengel, 2012)\n0.919\n0.958\n0.956\n0.957\n\n\nSOS (Janssens et al., 2012)\n0.912\n0.955\n0.953\n0.954\n\n\nSO-GAAL (Liu et al., 2019)\n0.952\n0.952\n1.000\n0.975\n\n\nMO-GAAL (Liu et al., 2019)\n0.952\n0.952\n1.000\n0.975\n\n\nLSCP (Zhao et al., 2019)\n0.980\n0.991\n0.988\n0.989"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html",
    "title": "Graph code",
    "section": "",
    "text": "Poster"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#linear1",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#linear1",
    "title": "Graph code",
    "section": "Linear(1)",
    "text": "Linear(1)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5,ref=30,ymin=-5,ymax=20,cuts=0,cutf=995): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color 표현은 위핸 표준화\n        self.df = self.df.assign(differ = self.differ)\n        \n        fig,ax = plt.subplots(figsize=(10,10))\n        ax.scatter(self.x,self.y,color='gray',s=50,alpha=0.7)\n        ax.scatter(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],color='red',s=50)\n        ax.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], '--k',lw=3)\n        ax.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=550,facecolors='none', edgecolors='r')\n        fig.tight_layout()\n        fig.savefig('fig1.eps',format='eps')\n\n\n_simul = SIMUL(df1)\n\n\n_simul.fit(sd=20,ref=25,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#linear2",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#linear2",
    "title": "Graph code",
    "section": "Linear(2)",
    "text": "Linear(2)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul2 = SIMUL(df2)\n\n\n_simul2.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#cos",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#cos",
    "title": "Graph code",
    "section": "COS",
    "text": "COS\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul4 = SIMUL(df4)\n\n\n_simul4.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#sin",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#sin",
    "title": "Graph code",
    "section": "SIN",
    "text": "SIN\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul5 = SIMUL(df5)\n\n\n_simul5.fit(ref=15,ymin=-10,ymax=15,cuts=5)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#d-manifold",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#d-manifold",
    "title": "Graph code",
    "section": "1D manifold",
    "text": "1D manifold\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n#         fig = plt.figure(figsize=(10,10))\n        # ax = fig.add_subplot(1,1,1, projection='3d')\n        #\n        fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,15),subplot_kw={\"projection\":\"3d\"})\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax1.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red')\n        ax1.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax1.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=60)\n        \n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax2.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax2.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax2.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=40)\n        \n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax3.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax3.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax3.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax3.view_init(elev=30., azim=10)\n        \n        fig.savefig('fig2.eps',format='eps')\n\n\n_simul3d = SIMUL(df)\n\n\n_simul3d.get_distance()\n\n100%|██████████| 1000/1000 [00:01<00:00, 562.21it/s]\n\n\n\n_simul3d.get_weightmatrix(theta=(_simul3d.D[_simul3d.D>0].mean()),kappa=2500) \n\n\n(_simul3d.D[_simul3d.D>0].mean())\n\n6.453496488349201\n\n\n\n%%capture --no-display\n_simul3d.fit(sd=15,ref=20)"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#bunny",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#bunny",
    "title": "Graph code",
    "section": "Bunny",
    "text": "Bunny\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) # 꼬리부분의 빨간신호를 퍼지게하는 정도\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\n\n\nindex_of_trueoutlier_bool = (unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2022-11-10 21:12:29,879:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nW = G.W.toarray()\nx = G.coords[:,0]\ny = G.coords[:,1]\nz = -G.coords[:,2]\n\n\ndf = pd.DataFrame({'x' : x, 'y' : y, 'z' : z, 'f' : f, 'noise' : noise})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=2.5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig = plt.figure(figsize=(30,12),dpi=400)\n        ax1 = fig.add_subplot(251, projection='3d')\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax1.view_init(elev=60., azim=-90)\n\n        ax2= fig.add_subplot(252, projection='3d')\n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax2.view_init(elev=60., azim=-90)\n\n        ax3= fig.add_subplot(253, projection='3d')\n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax3.view_init(elev=60., azim=-90)\n        \n        ax4= fig.add_subplot(254, projection='3d')\n        ax4.grid(False)\n        ax4.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax4.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax4.view_init(elev=60., azim=-90)\n\n        ax5= fig.add_subplot(255, projection='3d')\n        ax5.grid(False)\n        ax5.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax5.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax5.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax5.view_init(elev=60., azim=-90)\n        \n        ax6 = fig.add_subplot(256, projection='3d')\n        ax6.grid(False)\n        ax6.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax6.view_init(elev=-60., azim=-90)\n\n        ax7= fig.add_subplot(257, projection='3d')\n        ax7.grid(False)\n        ax7.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax7.view_init(elev=-60., azim=-90)\n\n        ax8= fig.add_subplot(258, projection='3d')\n        ax8.grid(False)\n        ax8.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax8.view_init(elev=-60., azim=-90)\n        \n        ax9= fig.add_subplot(259, projection='3d')\n        ax9.grid(False)\n        ax9.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax9.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax9.view_init(elev=-60., azim=-90)\n\n        ax10= fig.add_subplot(2,5,10, projection='3d')\n        ax10.grid(False)\n        ax10.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax10.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax10.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax10.view_init(elev=-60., azim=-90)        \n        fig.savefig('fig_bunny.eps',format='eps')\n\n\n_simul = SIMUL(df)\n\n\nmax(_simul.f),max(_simul.fnoise)\n\n(-0.010827167666814895, 8.453057038638512)\n\n\n\nmin(_simul.f),min(_simul.fnoise)\n\n(-4.74620052476489, -11.196627043702925)\n\n\n\n%%capture --no-display\n_simul.fit(sd=20,ref=10)"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#earthquake",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#earthquake",
    "title": "Graph code",
    "section": "Earthquake",
    "text": "Earthquake\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\n\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh 기능추가\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\neach_location.get_distance()\n\n100%|██████████| 12498/12498 [03:24<00:00, 61.15it/s] \n\n\n\neach_location.D[each_location.D>0].mean()\n\n8810.865423093777\n\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n(array([14176290., 16005894., 21186674., 22331128., 19394182., 17548252.,\n        16668048., 13316436., 12973260.,  2582550.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig = each_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig.write_image('fig_haiti.png',scale=3)\n\n\neach_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_lquique.svg',scale=3)\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_sichuan.svg',scale=3)"
  },
  {
    "objectID": "posts/GODE/index.html",
    "href": "posts/GODE/index.html",
    "title": "GODE",
    "section": "",
    "text": "About GODE paper"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html",
    "title": "Class code for Comparison Study",
    "section": "",
    "text": "Simulation\nex - The Stanford bunny data generated using the pygsp package is a common graphics 3D test model and NN-graph. It has 2503 data. We use filter.Heat in this package and it calculate data by \\(\\hat{g}(x) = \\exp(\\frac{-\\tau x}{\\lambda_{max}})\\) and \\(\\tau\\) is 75. We use Chebyshev polynomial approximation on this filter. We make zero vector whixh size is 2503, and put -3000 to one value to use a Lanczos approximation. A Lanczos approximation will resize signals by flattened.\nref: https://pygsp.readthedocs.io/en/v0.5.1/reference/filters.html\n\\(r = 5 + \\cos(\\frac{12\\pi - (-\\pi)}{n})\\times i , (i=1,2,\\dots , n)\\)\n\\(r \\cos(\\frac{\\pi - 2\\times \\pi /n - (-\\pi) }{n}\\times i)),(i=1,2,\\dots ,n)\\)\n\\(r \\sin((\\frac{\\pi - 2\\times \\pi /n - (-\\pi) }{n}\\times i)),(i=1,2,\\dots ,n)\\)\n\\(f = 10 \\times (\\frac{6 \\pi}{n} \\times i),(i=1,2, \\dots , n)\\)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#import",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#import",
    "title": "Class code for Comparison Study",
    "section": "Import",
    "text": "Import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.linear_model import SGDOneClassSVM\nfrom sklearn.kernel_approximation import Nystroem\nfrom sklearn.pipeline import make_pipeline\n\nimport pandas as pd\nfrom sklearn.neighbors import LocalOutlierFactor\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\nfrom sklearn.datasets import fetch_kddcup99, fetch_covtype, fetch_openml\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport tqdm\n\nfrom pygsp import graphs, filters, plotting, utils\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\n\nimport plotly.express as px\n\nfrom sklearn.covariance import EmpiricalCovariance, MinCovDet\n\nfrom alibi_detect.od import IForest\n# from pyod.models.iforest import IForest\n\nfrom pyod.models.abod import ABOD\nfrom pyod.models.cblof import CBLOF\nimport seaborn as sns\n\nfrom PyNomaly import loop\n\nfrom sklearn import svm\n\nfrom pyod.models.lscp import LSCP\nfrom pyod.models.hbos import HBOS\n\nfrom pyod.models.so_gaal import SO_GAAL\nfrom pyod.models.mcd import MCD\nfrom pyod.models.mo_gaal import MO_GAAL\nfrom pyod.models.knn import KNN\nfrom pyod.models.lof import LOF\nfrom pyod.models.ocsvm import OCSVM\n\nfrom pyod.models.feature_bagging import FeatureBagging\nfrom pyod.models.sos import SOS"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#class-code",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#class-code",
    "title": "Class code for Comparison Study",
    "section": "Class Code",
    "text": "Class Code\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_orbit = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_bunny = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\nclass Conf_matrx:\n    def __init__(self,original,compare,tab):\n        self.original = original\n        self.compare = compare\n        self.tab = tab\n    def conf(self,name):\n        self.conf_matrix = confusion_matrix(self.original, self.compare)\n        \n        fig, ax = plt.subplots(figsize=(5, 5))\n        ax.matshow(self.conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n        for i in range(self.conf_matrix.shape[0]):\n            for j in range(self.conf_matrix.shape[1]):\n                ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n        plt.xlabel('Predictions', fontsize=18)\n        plt.ylabel('Actuals', fontsize=18)\n        plt.title('Confusion Matrix', fontsize=18)\n        plt.show()\n        \n        self.acc = accuracy_score(self.original, self.compare)\n        self.pre = precision_score(self.original, self.compare)\n        self.rec = recall_score(self.original, self.compare)\n        self.f1 = f1_score(self.original, self.compare)\n        \n        print('Accuracy: %.3f' % self.acc)\n        print('Precision: %.3f' % self.pre)\n        print('Recall: %.3f' % self.rec)\n        print('F1 Score: %.3f' % self.f1)\n        \n        self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\nclass Linear:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        #self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=20): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n\n\nclass Orbit:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=20): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n\n\nclass BUNNY:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = _W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-ebayesthresh",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-ebayesthresh",
    "title": "Class code for Comparison Study",
    "section": "Linear EbayesThresh",
    "text": "Linear EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))\nindex_of_trueoutlier_1 = which(signal_1!=0)\nindex_of_trueoutlier_1\nx_1=signal_1+epsilon\n\n\n%R -o x_1\n%R -o index_of_trueoutlier_1\n%R -o signal_1\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\noutlier_true_index_1 = index_of_trueoutlier_1\n\n\noutlier_true_value_1 = x_1[index_of_trueoutlier_1]\n\n\noutlier_true_one_1 = signal_1.copy()\n\n\noutlier_true_one_1 = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one_1))"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear",
    "title": "Class code for Comparison Study",
    "section": "Linear",
    "text": "Linear\n\n_x_1 = np.linspace(0,2,1000)\n_y1_1 = 5*_x_1\n_y_1 = _y1_1 + x_1 # x is epsilon\n\n\n_df=pd.DataFrame({'x':_x_1, 'y':_y_1})\n\n\nX = np.array(_df)\n\n\nGODE\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n_Linear = Linear(_df)\n\n\n_Linear.fit(sd=5)\n\n\noutlier_simul_one = (_Linear.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 20 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.890\nPrecision: 0.973\nRecall: 0.909\nF1 Score: 0.940\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nfrom pyod.models.knn import KNN\n\n\nclf = KNN()\nclf.fit(_df[['x', 'y']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.979\nRecall: 0.927\nF1 Score: 0.952\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.920\nPrecision: 0.958\nRecall: 0.958\nF1 Score: 0.958\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.909\nPrecision: 0.978\nRecall: 0.925\nF1 Score: 0.951\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.982\nRecall: 0.931\nF1 Score: 0.956\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.982\nRecall: 0.931\nF1 Score: 0.956\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.946\nPrecision: 0.972\nRecall: 0.972\nF1 Score: 0.972\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y']])\n\n\npreds = od.predict(\n    _df[['x', 'y']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.800\nPrecision: 0.984\nRecall: 0.802\nF1 Score: 0.884\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.889\nPrecision: 0.960\nRecall: 0.921\nF1 Score: 0.940\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.889\nPrecision: 0.960\nRecall: 0.921\nF1 Score: 0.940\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3973\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 679us/step - loss: 1.4180\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4019\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4210\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4234\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 691us/step - loss: 1.4552\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 663us/step - loss: 1.4271\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 767us/step - loss: 1.4613\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 602us/step - loss: 1.4776\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 715us/step - loss: 1.4349\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4333\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4840\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5092\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4956\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5026\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 831us/step - loss: 1.5576\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 611us/step - loss: 1.5602\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 1.4791\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 619us/step - loss: 1.5625\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5635\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5925\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5807\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 844us/step - loss: 1.5739\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6122\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 657us/step - loss: 1.6156\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6021\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6237\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6302\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6586\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6349\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6708\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 726us/step - loss: 1.7010\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 826us/step - loss: 1.6865\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 820us/step - loss: 1.6874\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 680us/step - loss: 1.7410\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 663us/step - loss: 1.7334\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 1.6871\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 621us/step - loss: 1.7771\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 1.7724\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7815\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 647us/step - loss: 1.7470\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 612us/step - loss: 1.7897\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 660us/step - loss: 1.8400\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8351\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 689us/step - loss: 1.8388\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8174\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 974us/step - loss: 1.8131\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 712us/step - loss: 1.8391\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 635us/step - loss: 1.7937\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 971us/step - loss: 1.8550\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 628us/step - loss: 1.8632\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8457\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 628us/step - loss: 1.8924\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 1.8481\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8722\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9405\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 640us/step - loss: 1.9428\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8585\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 638us/step - loss: 1.8806\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 608us/step - loss: 1.9145\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9380\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 615us/step - loss: 1.8934\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9282\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 651us/step - loss: 1.8956\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 630us/step - loss: 1.8997\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9230\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 671us/step - loss: 1.9290\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 885us/step - loss: 1.9631\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 1.9394\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9368\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9715\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9327\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 690us/step - loss: 1.9782\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 612us/step - loss: 1.9637\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 575us/step - loss: 1.9657\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 890us/step - loss: 1.9923\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9824\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.0536\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.868\nPrecision: 0.954\nRecall: 0.904\nF1 Score: 0.929\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 674us/step - loss: 0.5119\n16/16 [==============================] - 0s 1ms/step - loss: 0.8174\n16/16 [==============================] - 0s 1ms/step - loss: 1.0584\n16/16 [==============================] - 0s 1ms/step - loss: 1.2057\n16/16 [==============================] - 0s 1ms/step - loss: 1.2512\n16/16 [==============================] - 0s 653us/step - loss: 1.2690\n16/16 [==============================] - 0s 640us/step - loss: 1.2744\n16/16 [==============================] - 0s 846us/step - loss: 1.2761\n16/16 [==============================] - 0s 782us/step - loss: 1.2766\n16/16 [==============================] - 0s 1ms/step - loss: 1.2766\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 665us/step - loss: 0.5016\n16/16 [==============================] - 0s 1ms/step - loss: 0.8168\n16/16 [==============================] - 0s 729us/step - loss: 1.0701\n16/16 [==============================] - 0s 619us/step - loss: 1.2239\n16/16 [==============================] - 0s 952us/step - loss: 1.2703\n16/16 [==============================] - 0s 680us/step - loss: 1.2884\n16/16 [==============================] - 0s 1ms/step - loss: 1.2938\n16/16 [==============================] - 0s 1ms/step - loss: 1.2955\n16/16 [==============================] - 0s 674us/step - loss: 1.2959\n16/16 [==============================] - 0s 680us/step - loss: 1.2959\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.4978\n16/16 [==============================] - 0s 1ms/step - loss: 0.8174\n16/16 [==============================] - 0s 988us/step - loss: 1.0777\n16/16 [==============================] - 0s 683us/step - loss: 1.2388\n16/16 [==============================] - 0s 1ms/step - loss: 1.2871\n16/16 [==============================] - 0s 1ms/step - loss: 1.3063\n16/16 [==============================] - 0s 899us/step - loss: 1.3121\n16/16 [==============================] - 0s 701us/step - loss: 1.3140\n16/16 [==============================] - 0s 674us/step - loss: 1.3144\n16/16 [==============================] - 0s 894us/step - loss: 1.3144\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.4856\n16/16 [==============================] - 0s 911us/step - loss: 0.8190\n16/16 [==============================] - 0s 1ms/step - loss: 1.0913\n16/16 [==============================] - 0s 1ms/step - loss: 1.2605\n16/16 [==============================] - 0s 1ms/step - loss: 1.3112\n16/16 [==============================] - 0s 1ms/step - loss: 1.3310\n16/16 [==============================] - 0s 2ms/step - loss: 1.3370\n16/16 [==============================] - 0s 1ms/step - loss: 1.3389\n16/16 [==============================] - 0s 745us/step - loss: 1.3393\n16/16 [==============================] - 0s 964us/step - loss: 1.3393\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 0.4780\n16/16 [==============================] - 0s 851us/step - loss: 0.8265\n16/16 [==============================] - 0s 1ms/step - loss: 1.1094\n16/16 [==============================] - 0s 1ms/step - loss: 1.2901\n16/16 [==============================] - 0s 702us/step - loss: 1.3448\n16/16 [==============================] - 0s 939us/step - loss: 1.3665\n16/16 [==============================] - 0s 854us/step - loss: 1.3731\n16/16 [==============================] - 0s 872us/step - loss: 1.3753\n16/16 [==============================] - 0s 633us/step - loss: 1.3759\n16/16 [==============================] - 0s 1ms/step - loss: 1.3759\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 709us/step - loss: 0.4680\n16/16 [==============================] - 0s 964us/step - loss: 0.8342\n16/16 [==============================] - 0s 717us/step - loss: 1.1328\n16/16 [==============================] - 0s 631us/step - loss: 1.3245\n16/16 [==============================] - 0s 1ms/step - loss: 1.3825\n16/16 [==============================] - 0s 1ms/step - loss: 1.4056\n16/16 [==============================] - 0s 1ms/step - loss: 1.4125\n16/16 [==============================] - 0s 675us/step - loss: 1.4148\n16/16 [==============================] - 0s 1ms/step - loss: 1.4154\n16/16 [==============================] - 0s 1ms/step - loss: 1.4154\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 683us/step - loss: 0.4700\n16/16 [==============================] - 0s 1ms/step - loss: 0.8212\n16/16 [==============================] - 0s 608us/step - loss: 1.1067\n16/16 [==============================] - 0s 1ms/step - loss: 1.2919\n16/16 [==============================] - 0s 645us/step - loss: 1.3484\n16/16 [==============================] - 0s 655us/step - loss: 1.3713\n16/16 [==============================] - 0s 1ms/step - loss: 1.3780\n16/16 [==============================] - 0s 707us/step - loss: 1.3802\n16/16 [==============================] - 0s 1ms/step - loss: 1.3807\n16/16 [==============================] - 0s 1ms/step - loss: 1.3807\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4568\n16/16 [==============================] - 0s 1ms/step - loss: 0.8264\n16/16 [==============================] - 0s 866us/step - loss: 1.1304\n16/16 [==============================] - 0s 737us/step - loss: 1.3292\n16/16 [==============================] - 0s 1ms/step - loss: 1.3891\n16/16 [==============================] - 0s 859us/step - loss: 1.4139\n16/16 [==============================] - 0s 664us/step - loss: 1.4209\n16/16 [==============================] - 0s 1ms/step - loss: 1.4233\n16/16 [==============================] - 0s 632us/step - loss: 1.4239\n16/16 [==============================] - 0s 2ms/step - loss: 1.4239\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.4472\n16/16 [==============================] - 0s 613us/step - loss: 0.8308\n16/16 [==============================] - 0s 633us/step - loss: 1.1472\n16/16 [==============================] - 0s 640us/step - loss: 1.3580\n16/16 [==============================] - 0s 1ms/step - loss: 1.4212\n16/16 [==============================] - 0s 644us/step - loss: 1.4477\n16/16 [==============================] - 0s 621us/step - loss: 1.4553\n16/16 [==============================] - 0s 601us/step - loss: 1.4579\n16/16 [==============================] - 0s 799us/step - loss: 1.4585\n16/16 [==============================] - 0s 663us/step - loss: 1.4585\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4458\n16/16 [==============================] - 0s 639us/step - loss: 0.8332\n16/16 [==============================] - 0s 622us/step - loss: 1.1594\n16/16 [==============================] - 0s 620us/step - loss: 1.3754\n16/16 [==============================] - 0s 987us/step - loss: 1.4394\n16/16 [==============================] - 0s 652us/step - loss: 1.4660\n16/16 [==============================] - 0s 641us/step - loss: 1.4735\n16/16 [==============================] - 0s 628us/step - loss: 1.4761\n16/16 [==============================] - 0s 1ms/step - loss: 1.4766\n16/16 [==============================] - 0s 597us/step - loss: 1.4766\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4323\n16/16 [==============================] - 0s 1ms/step - loss: 0.8289\n16/16 [==============================] - 0s 1ms/step - loss: 1.1745\n16/16 [==============================] - 0s 2ms/step - loss: 1.4047\n16/16 [==============================] - 0s 1ms/step - loss: 1.4730\n16/16 [==============================] - 0s 835us/step - loss: 1.5017\n16/16 [==============================] - 0s 684us/step - loss: 1.5100\n16/16 [==============================] - 0s 643us/step - loss: 1.5128\n16/16 [==============================] - 0s 1ms/step - loss: 1.5135\n16/16 [==============================] - 0s 1ms/step - loss: 1.5135\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4311\n16/16 [==============================] - 0s 693us/step - loss: 0.8327\n16/16 [==============================] - 0s 639us/step - loss: 1.1867\n16/16 [==============================] - 0s 606us/step - loss: 1.4217\n16/16 [==============================] - 0s 816us/step - loss: 1.4904\n16/16 [==============================] - 0s 828us/step - loss: 1.5189\n16/16 [==============================] - 0s 1ms/step - loss: 1.5270\n16/16 [==============================] - 0s 1ms/step - loss: 1.5298\n16/16 [==============================] - 0s 1ms/step - loss: 1.5303\n16/16 [==============================] - 0s 779us/step - loss: 1.5303\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4224\n16/16 [==============================] - 0s 1ms/step - loss: 0.8208\n16/16 [==============================] - 0s 998us/step - loss: 1.1776\n16/16 [==============================] - 0s 1ms/step - loss: 1.4157\n16/16 [==============================] - 0s 635us/step - loss: 1.4850\n16/16 [==============================] - 0s 1ms/step - loss: 1.5136\n16/16 [==============================] - 0s 1ms/step - loss: 1.5217\n16/16 [==============================] - 0s 640us/step - loss: 1.5245\n16/16 [==============================] - 0s 590us/step - loss: 1.5251\n16/16 [==============================] - 0s 1ms/step - loss: 1.5251\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 707us/step - loss: 0.4220\n16/16 [==============================] - 0s 790us/step - loss: 0.8241\n16/16 [==============================] - 0s 1ms/step - loss: 1.1871\n16/16 [==============================] - 0s 829us/step - loss: 1.4277\n16/16 [==============================] - 0s 796us/step - loss: 1.4965\n16/16 [==============================] - 0s 1ms/step - loss: 1.5243\n16/16 [==============================] - 0s 1ms/step - loss: 1.5321\n16/16 [==============================] - 0s 1ms/step - loss: 1.5347\n16/16 [==============================] - 0s 611us/step - loss: 1.5352\n16/16 [==============================] - 0s 607us/step - loss: 1.5351\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4162\n16/16 [==============================] - 0s 765us/step - loss: 0.8240\n16/16 [==============================] - 0s 1ms/step - loss: 1.1967\n16/16 [==============================] - 0s 1ms/step - loss: 1.4447\n16/16 [==============================] - 0s 1ms/step - loss: 1.5154\n16/16 [==============================] - 0s 718us/step - loss: 1.5437\n16/16 [==============================] - 0s 1ms/step - loss: 1.5517\n16/16 [==============================] - 0s 1ms/step - loss: 1.5543\n16/16 [==============================] - 0s 659us/step - loss: 1.5548\n16/16 [==============================] - 0s 2ms/step - loss: 1.5547\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4156\n16/16 [==============================] - 0s 843us/step - loss: 0.8177\n16/16 [==============================] - 0s 623us/step - loss: 1.1876\n16/16 [==============================] - 0s 1ms/step - loss: 1.4313\n16/16 [==============================] - 0s 1ms/step - loss: 1.4993\n16/16 [==============================] - 0s 1ms/step - loss: 1.5259\n16/16 [==============================] - 0s 723us/step - loss: 1.5332\n16/16 [==============================] - 0s 640us/step - loss: 1.5355\n16/16 [==============================] - 0s 625us/step - loss: 1.5358\n16/16 [==============================] - 0s 634us/step - loss: 1.5357\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4090\n16/16 [==============================] - 0s 1ms/step - loss: 0.8233\n16/16 [==============================] - 0s 1ms/step - loss: 1.2093\n16/16 [==============================] - 0s 643us/step - loss: 1.4641\n16/16 [==============================] - 0s 627us/step - loss: 1.5348\n16/16 [==============================] - 0s 668us/step - loss: 1.5623\n16/16 [==============================] - 0s 885us/step - loss: 1.5697\n16/16 [==============================] - 0s 887us/step - loss: 1.5721\n16/16 [==============================] - 0s 640us/step - loss: 1.5724\n16/16 [==============================] - 0s 1ms/step - loss: 1.5724\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4023\n16/16 [==============================] - 0s 847us/step - loss: 0.8249\n16/16 [==============================] - 0s 1ms/step - loss: 1.2211\n16/16 [==============================] - 0s 669us/step - loss: 1.4795\n16/16 [==============================] - 0s 837us/step - loss: 1.5497\n16/16 [==============================] - 0s 1ms/step - loss: 1.5763\n16/16 [==============================] - 0s 792us/step - loss: 1.5833\n16/16 [==============================] - 0s 1ms/step - loss: 1.5854\n16/16 [==============================] - 0s 821us/step - loss: 1.5856\n16/16 [==============================] - 0s 654us/step - loss: 1.5855\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 815us/step - loss: 0.4039\n16/16 [==============================] - 0s 621us/step - loss: 0.8273\n16/16 [==============================] - 0s 636us/step - loss: 1.2286\n16/16 [==============================] - 0s 1ms/step - loss: 1.4900\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5869\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\n16/16 [==============================] - 0s 2ms/step - loss: 1.5958\n16/16 [==============================] - 0s 1ms/step - loss: 1.5960\n16/16 [==============================] - 0s 721us/step - loss: 1.5958\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 822us/step - loss: 0.3922\n16/16 [==============================] - 0s 618us/step - loss: 0.8303\n16/16 [==============================] - 0s 979us/step - loss: 1.2484\n16/16 [==============================] - 0s 594us/step - loss: 1.5177\n16/16 [==============================] - 0s 584us/step - loss: 1.5887\n16/16 [==============================] - 0s 886us/step - loss: 1.6148\n16/16 [==============================] - 0s 616us/step - loss: 1.6214\n16/16 [==============================] - 0s 986us/step - loss: 1.6232\n16/16 [==============================] - 0s 634us/step - loss: 1.6234\n16/16 [==============================] - 0s 647us/step - loss: 1.6232\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3917\n16/16 [==============================] - 0s 638us/step - loss: 0.8412\n16/16 [==============================] - 0s 1ms/step - loss: 1.2745\n16/16 [==============================] - 0s 1ms/step - loss: 1.5525\n16/16 [==============================] - 0s 597us/step - loss: 1.6251\n16/16 [==============================] - 0s 1ms/step - loss: 1.6514\n16/16 [==============================] - 0s 1ms/step - loss: 1.6580\n16/16 [==============================] - 0s 1ms/step - loss: 1.6598\n16/16 [==============================] - 0s 1ms/step - loss: 1.6598\n16/16 [==============================] - 0s 875us/step - loss: 1.6597\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 0.3861\n16/16 [==============================] - 0s 1ms/step - loss: 0.8410\n16/16 [==============================] - 0s 1ms/step - loss: 1.2819\n16/16 [==============================] - 0s 747us/step - loss: 1.5604\n16/16 [==============================] - 0s 1ms/step - loss: 1.6314\n16/16 [==============================] - 0s 2ms/step - loss: 1.6566\n16/16 [==============================] - 0s 1ms/step - loss: 1.6625\n16/16 [==============================] - 0s 1ms/step - loss: 1.6641\n16/16 [==============================] - 0s 682us/step - loss: 1.6641\n16/16 [==============================] - 0s 868us/step - loss: 1.6639\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3785\n16/16 [==============================] - 0s 640us/step - loss: 0.8366\n16/16 [==============================] - 0s 620us/step - loss: 1.2831\n16/16 [==============================] - 0s 630us/step - loss: 1.5628\n16/16 [==============================] - 0s 569us/step - loss: 1.6327\n16/16 [==============================] - 0s 1ms/step - loss: 1.6570\n16/16 [==============================] - 0s 1ms/step - loss: 1.6626\n16/16 [==============================] - 0s 671us/step - loss: 1.6639\n16/16 [==============================] - 0s 1ms/step - loss: 1.6638\n16/16 [==============================] - 0s 1ms/step - loss: 1.6636\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 686us/step - loss: 0.3794\n16/16 [==============================] - 0s 1ms/step - loss: 0.8368\n16/16 [==============================] - 0s 590us/step - loss: 1.2836\n16/16 [==============================] - 0s 1ms/step - loss: 1.5578\n16/16 [==============================] - 0s 1ms/step - loss: 1.6242\n16/16 [==============================] - 0s 1ms/step - loss: 1.6467\n16/16 [==============================] - 0s 1ms/step - loss: 1.6516\n16/16 [==============================] - 0s 880us/step - loss: 1.6526\n16/16 [==============================] - 0s 1ms/step - loss: 1.6524\n16/16 [==============================] - 0s 744us/step - loss: 1.6521\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 639us/step - loss: 0.3767\n16/16 [==============================] - 0s 675us/step - loss: 0.8386\n16/16 [==============================] - 0s 636us/step - loss: 1.2925\n16/16 [==============================] - 0s 667us/step - loss: 1.5686\n16/16 [==============================] - 0s 570us/step - loss: 1.6342\n16/16 [==============================] - 0s 650us/step - loss: 1.6560\n16/16 [==============================] - 0s 1ms/step - loss: 1.6605\n16/16 [==============================] - 0s 1ms/step - loss: 1.6614\n16/16 [==============================] - 0s 828us/step - loss: 1.6611\n16/16 [==============================] - 0s 754us/step - loss: 1.6608\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3785\n16/16 [==============================] - 0s 606us/step - loss: 0.8568\n16/16 [==============================] - 0s 1ms/step - loss: 1.3267\n16/16 [==============================] - 0s 1ms/step - loss: 1.6075\n16/16 [==============================] - 0s 632us/step - loss: 1.6723\n16/16 [==============================] - 0s 700us/step - loss: 1.6932\n16/16 [==============================] - 0s 814us/step - loss: 1.6974\n16/16 [==============================] - 0s 1ms/step - loss: 1.6980\n16/16 [==============================] - 0s 2ms/step - loss: 1.6977\n16/16 [==============================] - 0s 1ms/step - loss: 1.6974\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 611us/step - loss: 0.3640\n16/16 [==============================] - 0s 586us/step - loss: 0.8516\n16/16 [==============================] - 0s 613us/step - loss: 1.3334\n16/16 [==============================] - 0s 631us/step - loss: 1.6188\n16/16 [==============================] - 0s 635us/step - loss: 1.6834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7039\n16/16 [==============================] - 0s 600us/step - loss: 1.7078\n16/16 [==============================] - 0s 784us/step - loss: 1.7083\n16/16 [==============================] - 0s 1ms/step - loss: 1.7080\n16/16 [==============================] - 0s 654us/step - loss: 1.7076\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 642us/step - loss: 0.3623\n16/16 [==============================] - 0s 870us/step - loss: 0.8627\n16/16 [==============================] - 0s 1ms/step - loss: 1.3550\n16/16 [==============================] - 0s 935us/step - loss: 1.6411\n16/16 [==============================] - 0s 631us/step - loss: 1.7039\n16/16 [==============================] - 0s 1ms/step - loss: 1.7231\n16/16 [==============================] - 0s 659us/step - loss: 1.7264\n16/16 [==============================] - 0s 1ms/step - loss: 1.7267\n16/16 [==============================] - 0s 1ms/step - loss: 1.7262\n16/16 [==============================] - 0s 706us/step - loss: 1.7259\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3604\n16/16 [==============================] - 0s 635us/step - loss: 0.8668\n16/16 [==============================] - 0s 889us/step - loss: 1.3676\n16/16 [==============================] - 0s 1ms/step - loss: 1.6572\n16/16 [==============================] - 0s 947us/step - loss: 1.7200\n16/16 [==============================] - 0s 2ms/step - loss: 1.7389\n16/16 [==============================] - 0s 772us/step - loss: 1.7421\n16/16 [==============================] - 0s 1ms/step - loss: 1.7424\n16/16 [==============================] - 0s 1ms/step - loss: 1.7419\n16/16 [==============================] - 0s 744us/step - loss: 1.7415\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3571\n16/16 [==============================] - 0s 680us/step - loss: 0.8755\n16/16 [==============================] - 0s 751us/step - loss: 1.3899\n16/16 [==============================] - 0s 1ms/step - loss: 1.6814\n16/16 [==============================] - 0s 1ms/step - loss: 1.7429\n16/16 [==============================] - 0s 1ms/step - loss: 1.7609\n16/16 [==============================] - 0s 681us/step - loss: 1.7637\n16/16 [==============================] - 0s 677us/step - loss: 1.7638\n16/16 [==============================] - 0s 646us/step - loss: 1.7633\n16/16 [==============================] - 0s 1ms/step - loss: 1.7629\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3680\n16/16 [==============================] - 0s 623us/step - loss: 0.8560\n16/16 [==============================] - 0s 652us/step - loss: 1.3413\n16/16 [==============================] - 0s 605us/step - loss: 1.6123\n16/16 [==============================] - 0s 622us/step - loss: 1.6680\n16/16 [==============================] - 0s 808us/step - loss: 1.6837\n16/16 [==============================] - 0s 1ms/step - loss: 1.6859\n16/16 [==============================] - 0s 889us/step - loss: 1.6858\n16/16 [==============================] - 0s 633us/step - loss: 1.6852\n16/16 [==============================] - 0s 626us/step - loss: 1.6848\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3582\n16/16 [==============================] - 0s 660us/step - loss: 0.8667\n16/16 [==============================] - 0s 649us/step - loss: 1.3768\n16/16 [==============================] - 0s 1000us/step - loss: 1.6562\n16/16 [==============================] - 0s 1ms/step - loss: 1.7123\n16/16 [==============================] - 0s 634us/step - loss: 1.7277\n16/16 [==============================] - 0s 685us/step - loss: 1.7297\n16/16 [==============================] - 0s 1ms/step - loss: 1.7295\n16/16 [==============================] - 0s 1ms/step - loss: 1.7288\n16/16 [==============================] - 0s 628us/step - loss: 1.7284\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3583\n16/16 [==============================] - 0s 1ms/step - loss: 0.8671\n16/16 [==============================] - 0s 1ms/step - loss: 1.3803\n16/16 [==============================] - 0s 1ms/step - loss: 1.6596\n16/16 [==============================] - 0s 1ms/step - loss: 1.7150\n16/16 [==============================] - 0s 692us/step - loss: 1.7298\n16/16 [==============================] - 0s 979us/step - loss: 1.7317\n16/16 [==============================] - 0s 1ms/step - loss: 1.7314\n16/16 [==============================] - 0s 1ms/step - loss: 1.7308\n16/16 [==============================] - 0s 1ms/step - loss: 1.7304\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 863us/step - loss: 0.3471\n16/16 [==============================] - 0s 661us/step - loss: 0.8780\n16/16 [==============================] - 0s 659us/step - loss: 1.4219\n16/16 [==============================] - 0s 1ms/step - loss: 1.7117\n16/16 [==============================] - 0s 1ms/step - loss: 1.7680\n16/16 [==============================] - 0s 1ms/step - loss: 1.7827\n16/16 [==============================] - 0s 824us/step - loss: 1.7845\n16/16 [==============================] - 0s 1ms/step - loss: 1.7841\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 2ms/step - loss: 1.7830\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3466\n16/16 [==============================] - 0s 680us/step - loss: 0.8801\n16/16 [==============================] - 0s 1ms/step - loss: 1.4285\n16/16 [==============================] - 0s 615us/step - loss: 1.7186\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 1ms/step - loss: 1.7880\n16/16 [==============================] - 0s 1ms/step - loss: 1.7895\n16/16 [==============================] - 0s 619us/step - loss: 1.7890\n16/16 [==============================] - 0s 1ms/step - loss: 1.7882\n16/16 [==============================] - 0s 587us/step - loss: 1.7878\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 861us/step - loss: 0.3492\n16/16 [==============================] - 0s 879us/step - loss: 0.8719\n16/16 [==============================] - 0s 664us/step - loss: 1.4147\n16/16 [==============================] - 0s 643us/step - loss: 1.6946\n16/16 [==============================] - 0s 1ms/step - loss: 1.7465\n16/16 [==============================] - 0s 621us/step - loss: 1.7591\n16/16 [==============================] - 0s 594us/step - loss: 1.7602\n16/16 [==============================] - 0s 612us/step - loss: 1.7596\n16/16 [==============================] - 0s 594us/step - loss: 1.7588\n16/16 [==============================] - 0s 660us/step - loss: 1.7584\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3448\n16/16 [==============================] - 0s 891us/step - loss: 0.8840\n16/16 [==============================] - 0s 1ms/step - loss: 1.4475\n16/16 [==============================] - 0s 634us/step - loss: 1.7374\n16/16 [==============================] - 0s 1ms/step - loss: 1.7907\n16/16 [==============================] - 0s 1ms/step - loss: 1.8035\n16/16 [==============================] - 0s 698us/step - loss: 1.8046\n16/16 [==============================] - 0s 660us/step - loss: 1.8040\n16/16 [==============================] - 0s 828us/step - loss: 1.8032\n16/16 [==============================] - 0s 1ms/step - loss: 1.8028\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 0.3427\n16/16 [==============================] - 0s 629us/step - loss: 0.8792\n16/16 [==============================] - 0s 613us/step - loss: 1.4449\n16/16 [==============================] - 0s 605us/step - loss: 1.7294\n16/16 [==============================] - 0s 1ms/step - loss: 1.7803\n16/16 [==============================] - 0s 1ms/step - loss: 1.7920\n16/16 [==============================] - 0s 670us/step - loss: 1.7928\n16/16 [==============================] - 0s 1ms/step - loss: 1.7921\n16/16 [==============================] - 0s 702us/step - loss: 1.7912\n16/16 [==============================] - 0s 978us/step - loss: 1.7908\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 884us/step - loss: 0.3356\n16/16 [==============================] - 0s 1ms/step - loss: 0.8885\n16/16 [==============================] - 0s 850us/step - loss: 1.4743\n16/16 [==============================] - 0s 730us/step - loss: 1.7694\n16/16 [==============================] - 0s 1ms/step - loss: 1.8221\n16/16 [==============================] - 0s 944us/step - loss: 1.8343\n16/16 [==============================] - 0s 932us/step - loss: 1.8352\n16/16 [==============================] - 0s 696us/step - loss: 1.8345\n16/16 [==============================] - 0s 1ms/step - loss: 1.8337\n16/16 [==============================] - 0s 1ms/step - loss: 1.8333\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 612us/step - loss: 0.3393\n16/16 [==============================] - 0s 595us/step - loss: 0.8775\n16/16 [==============================] - 0s 1ms/step - loss: 1.4502\n16/16 [==============================] - 0s 1ms/step - loss: 1.7321\n16/16 [==============================] - 0s 1ms/step - loss: 1.7808\n16/16 [==============================] - 0s 1ms/step - loss: 1.7913\n16/16 [==============================] - 0s 1ms/step - loss: 1.7917\n16/16 [==============================] - 0s 663us/step - loss: 1.7909\n16/16 [==============================] - 0s 688us/step - loss: 1.7900\n16/16 [==============================] - 0s 659us/step - loss: 1.7895\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3349\n16/16 [==============================] - 0s 913us/step - loss: 0.8782\n16/16 [==============================] - 0s 683us/step - loss: 1.4573\n16/16 [==============================] - 0s 2ms/step - loss: 1.7431\n16/16 [==============================] - 0s 1ms/step - loss: 1.7923\n16/16 [==============================] - 0s 1ms/step - loss: 1.8028\n16/16 [==============================] - 0s 647us/step - loss: 1.8033\n16/16 [==============================] - 0s 633us/step - loss: 1.8024\n16/16 [==============================] - 0s 573us/step - loss: 1.8015\n16/16 [==============================] - 0s 2ms/step - loss: 1.8011\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 712us/step - loss: 0.3296\n16/16 [==============================] - 0s 757us/step - loss: 0.8910\n16/16 [==============================] - 0s 1ms/step - loss: 1.4933\n16/16 [==============================] - 0s 676us/step - loss: 1.7869\n16/16 [==============================] - 0s 639us/step - loss: 1.8366\n16/16 [==============================] - 0s 622us/step - loss: 1.8470\n16/16 [==============================] - 0s 605us/step - loss: 1.8474\n16/16 [==============================] - 0s 1ms/step - loss: 1.8464\n16/16 [==============================] - 0s 1ms/step - loss: 1.8456\n16/16 [==============================] - 0s 1ms/step - loss: 1.8451\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3304\n16/16 [==============================] - 0s 1ms/step - loss: 0.8862\n16/16 [==============================] - 0s 704us/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.7733\n16/16 [==============================] - 0s 679us/step - loss: 1.8222\n16/16 [==============================] - 0s 644us/step - loss: 1.8324\n16/16 [==============================] - 0s 1ms/step - loss: 1.8327\n16/16 [==============================] - 0s 1ms/step - loss: 1.8318\n16/16 [==============================] - 0s 653us/step - loss: 1.8309\n16/16 [==============================] - 0s 1ms/step - loss: 1.8304\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 769us/step - loss: 0.3289\n16/16 [==============================] - 0s 1ms/step - loss: 0.8923\n16/16 [==============================] - 0s 889us/step - loss: 1.4981\n16/16 [==============================] - 0s 676us/step - loss: 1.7912\n16/16 [==============================] - 0s 576us/step - loss: 1.8395\n16/16 [==============================] - 0s 594us/step - loss: 1.8492\n16/16 [==============================] - 0s 614us/step - loss: 1.8493\n16/16 [==============================] - 0s 754us/step - loss: 1.8483\n16/16 [==============================] - 0s 1ms/step - loss: 1.8474\n16/16 [==============================] - 0s 620us/step - loss: 1.8469\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3236\n16/16 [==============================] - 0s 669us/step - loss: 0.8897\n16/16 [==============================] - 0s 1ms/step - loss: 1.4962\n16/16 [==============================] - 0s 622us/step - loss: 1.7918\n16/16 [==============================] - 0s 636us/step - loss: 1.8402\n16/16 [==============================] - 0s 609us/step - loss: 1.8499\n16/16 [==============================] - 0s 589us/step - loss: 1.8499\n16/16 [==============================] - 0s 1ms/step - loss: 1.8488\n16/16 [==============================] - 0s 1ms/step - loss: 1.8479\n16/16 [==============================] - 0s 1ms/step - loss: 1.8474\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3240\n16/16 [==============================] - 0s 1ms/step - loss: 0.9065\n16/16 [==============================] - 0s 1ms/step - loss: 1.5340\n16/16 [==============================] - 0s 699us/step - loss: 1.8380\n16/16 [==============================] - 0s 644us/step - loss: 1.8875\n16/16 [==============================] - 0s 603us/step - loss: 1.8973\n16/16 [==============================] - 0s 1ms/step - loss: 1.8974\n16/16 [==============================] - 0s 1ms/step - loss: 1.8964\n16/16 [==============================] - 0s 1ms/step - loss: 1.8954\n16/16 [==============================] - 0s 773us/step - loss: 1.8950\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3120\n16/16 [==============================] - 0s 980us/step - loss: 0.9140\n16/16 [==============================] - 0s 1ms/step - loss: 1.5655\n16/16 [==============================] - 0s 1ms/step - loss: 1.8840\n16/16 [==============================] - 0s 1ms/step - loss: 1.9360\n16/16 [==============================] - 0s 677us/step - loss: 1.9465\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 736us/step - loss: 1.9458\n16/16 [==============================] - 0s 645us/step - loss: 1.9449\n16/16 [==============================] - 0s 648us/step - loss: 1.9444\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 673us/step - loss: 0.3280\n16/16 [==============================] - 0s 651us/step - loss: 0.8989\n16/16 [==============================] - 0s 1ms/step - loss: 1.5171\n16/16 [==============================] - 0s 626us/step - loss: 1.8154\n16/16 [==============================] - 0s 1ms/step - loss: 1.8629\n16/16 [==============================] - 0s 629us/step - loss: 1.8720\n16/16 [==============================] - 0s 1ms/step - loss: 1.8720\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n16/16 [==============================] - 0s 1ms/step - loss: 1.8700\n16/16 [==============================] - 0s 632us/step - loss: 1.8696\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3253\n16/16 [==============================] - 0s 816us/step - loss: 0.8820\n16/16 [==============================] - 0s 782us/step - loss: 1.4859\n16/16 [==============================] - 0s 1ms/step - loss: 1.7760\n16/16 [==============================] - 0s 1ms/step - loss: 1.8211\n16/16 [==============================] - 0s 672us/step - loss: 1.8292\n16/16 [==============================] - 0s 2ms/step - loss: 1.8287\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 2ms/step - loss: 1.8265\n16/16 [==============================] - 0s 705us/step - loss: 1.8259\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.3018\n16/16 [==============================] - 0s 609us/step - loss: 0.9113\n16/16 [==============================] - 0s 1ms/step - loss: 1.5796\n16/16 [==============================] - 0s 1ms/step - loss: 1.8997\n16/16 [==============================] - 0s 1ms/step - loss: 1.9496\n16/16 [==============================] - 0s 657us/step - loss: 1.9589\n16/16 [==============================] - 0s 591us/step - loss: 1.9587\n16/16 [==============================] - 0s 1ms/step - loss: 1.9575\n16/16 [==============================] - 0s 2ms/step - loss: 1.9565\n16/16 [==============================] - 0s 893us/step - loss: 1.9560\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3160\n16/16 [==============================] - 0s 649us/step - loss: 0.8929\n16/16 [==============================] - 0s 663us/step - loss: 1.5280\n16/16 [==============================] - 0s 668us/step - loss: 1.8325\n16/16 [==============================] - 0s 1ms/step - loss: 1.8797\n16/16 [==============================] - 0s 698us/step - loss: 1.8884\n16/16 [==============================] - 0s 700us/step - loss: 1.8881\n16/16 [==============================] - 0s 631us/step - loss: 1.8869\n16/16 [==============================] - 0s 1ms/step - loss: 1.8859\n16/16 [==============================] - 0s 649us/step - loss: 1.8854\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 684us/step - loss: 0.3158\n16/16 [==============================] - 0s 627us/step - loss: 0.9064\n16/16 [==============================] - 0s 1ms/step - loss: 1.5588\n16/16 [==============================] - 0s 632us/step - loss: 1.8678\n16/16 [==============================] - 0s 618us/step - loss: 1.9149\n16/16 [==============================] - 0s 585us/step - loss: 1.9232\n16/16 [==============================] - 0s 1ms/step - loss: 1.9228\n16/16 [==============================] - 0s 1ms/step - loss: 1.9215\n16/16 [==============================] - 0s 1ms/step - loss: 1.9205\n16/16 [==============================] - 0s 694us/step - loss: 1.9200\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 695us/step - loss: 0.3114\n16/16 [==============================] - 0s 805us/step - loss: 0.8972\n16/16 [==============================] - 0s 899us/step - loss: 1.5487\n16/16 [==============================] - 0s 1ms/step - loss: 1.8577\n16/16 [==============================] - 0s 705us/step - loss: 1.9042\n16/16 [==============================] - 0s 597us/step - loss: 1.9123\n16/16 [==============================] - 0s 630us/step - loss: 1.9118\n16/16 [==============================] - 0s 706us/step - loss: 1.9105\n16/16 [==============================] - 0s 1ms/step - loss: 1.9094\n16/16 [==============================] - 0s 790us/step - loss: 1.9089\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3079\n16/16 [==============================] - 0s 1ms/step - loss: 0.9138\n16/16 [==============================] - 0s 610us/step - loss: 1.5910\n16/16 [==============================] - 0s 1ms/step - loss: 1.9092\n16/16 [==============================] - 0s 680us/step - loss: 1.9566\n16/16 [==============================] - 0s 609us/step - loss: 1.9647\n16/16 [==============================] - 0s 617us/step - loss: 1.9641\n16/16 [==============================] - 0s 620us/step - loss: 1.9628\n16/16 [==============================] - 0s 621us/step - loss: 1.9617\n16/16 [==============================] - 0s 639us/step - loss: 1.9612\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2996\n16/16 [==============================] - 0s 668us/step - loss: 0.9044\n16/16 [==============================] - 0s 1ms/step - loss: 1.5879\n16/16 [==============================] - 0s 1ms/step - loss: 1.9109\n16/16 [==============================] - 0s 1ms/step - loss: 1.9594\n16/16 [==============================] - 0s 1ms/step - loss: 1.9680\n16/16 [==============================] - 0s 677us/step - loss: 1.9676\n16/16 [==============================] - 0s 640us/step - loss: 1.9664\n16/16 [==============================] - 0s 630us/step - loss: 1.9654\n16/16 [==============================] - 0s 612us/step - loss: 1.9649\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3126\n16/16 [==============================] - 0s 1ms/step - loss: 0.8881\n16/16 [==============================] - 0s 985us/step - loss: 1.5372\n16/16 [==============================] - 0s 2ms/step - loss: 1.8393\n16/16 [==============================] - 0s 621us/step - loss: 1.8833\n16/16 [==============================] - 0s 753us/step - loss: 1.8904\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 602us/step - loss: 1.8883\n16/16 [==============================] - 0s 689us/step - loss: 1.8872\n16/16 [==============================] - 0s 1ms/step - loss: 1.8867\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 0.3055\n16/16 [==============================] - 0s 641us/step - loss: 0.8975\n16/16 [==============================] - 0s 577us/step - loss: 1.5715\n16/16 [==============================] - 0s 612us/step - loss: 1.8861\n16/16 [==============================] - 0s 605us/step - loss: 1.9320\n16/16 [==============================] - 0s 997us/step - loss: 1.9395\n16/16 [==============================] - 0s 1ms/step - loss: 1.9388\n16/16 [==============================] - 0s 644us/step - loss: 1.9374\n16/16 [==============================] - 0s 952us/step - loss: 1.9364\n16/16 [==============================] - 0s 628us/step - loss: 1.9358\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 796us/step - loss: 0.2940\n16/16 [==============================] - 0s 649us/step - loss: 0.9002\n16/16 [==============================] - 0s 1ms/step - loss: 1.5930\n16/16 [==============================] - 0s 964us/step - loss: 1.9135\n16/16 [==============================] - 0s 1ms/step - loss: 1.9596\n16/16 [==============================] - 0s 674us/step - loss: 1.9670\n16/16 [==============================] - 0s 652us/step - loss: 1.9662\n16/16 [==============================] - 0s 642us/step - loss: 1.9648\n16/16 [==============================] - 0s 1ms/step - loss: 1.9638\n16/16 [==============================] - 0s 1ms/step - loss: 1.9633\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 665us/step - loss: 0.3044\n16/16 [==============================] - 0s 665us/step - loss: 0.9019\n16/16 [==============================] - 0s 1ms/step - loss: 1.5888\n16/16 [==============================] - 0s 665us/step - loss: 1.9064\n16/16 [==============================] - 0s 1ms/step - loss: 1.9517\n16/16 [==============================] - 0s 660us/step - loss: 1.9588\n16/16 [==============================] - 0s 691us/step - loss: 1.9579\n16/16 [==============================] - 0s 1ms/step - loss: 1.9565\n16/16 [==============================] - 0s 1ms/step - loss: 1.9554\n16/16 [==============================] - 0s 693us/step - loss: 1.9549\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 939us/step - loss: 0.3020\n16/16 [==============================] - 0s 739us/step - loss: 0.8987\n16/16 [==============================] - 0s 698us/step - loss: 1.5860\n16/16 [==============================] - 0s 1ms/step - loss: 1.9003\n16/16 [==============================] - 0s 652us/step - loss: 1.9445\n16/16 [==============================] - 0s 807us/step - loss: 1.9511\n16/16 [==============================] - 0s 1ms/step - loss: 1.9502\n16/16 [==============================] - 0s 1ms/step - loss: 1.9488\n16/16 [==============================] - 0s 669us/step - loss: 1.9477\n16/16 [==============================] - 0s 642us/step - loss: 1.9472\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 919us/step - loss: 0.2888\n16/16 [==============================] - 0s 799us/step - loss: 0.9191\n16/16 [==============================] - 0s 639us/step - loss: 1.6532\n16/16 [==============================] - 0s 1ms/step - loss: 1.9907\n16/16 [==============================] - 0s 617us/step - loss: 2.0383\n16/16 [==============================] - 0s 1000us/step - loss: 2.0458\n16/16 [==============================] - 0s 1ms/step - loss: 2.0449\n16/16 [==============================] - 0s 617us/step - loss: 2.0435\n16/16 [==============================] - 0s 1ms/step - loss: 2.0424\n16/16 [==============================] - 0s 617us/step - loss: 2.0419\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2896\n16/16 [==============================] - 0s 692us/step - loss: 0.9198\n16/16 [==============================] - 0s 662us/step - loss: 1.6543\n16/16 [==============================] - 0s 644us/step - loss: 1.9879\n16/16 [==============================] - 0s 1ms/step - loss: 2.0342\n16/16 [==============================] - 0s 642us/step - loss: 2.0410\n16/16 [==============================] - 0s 1ms/step - loss: 2.0401\n16/16 [==============================] - 0s 1ms/step - loss: 2.0387\n16/16 [==============================] - 0s 1ms/step - loss: 2.0376\n16/16 [==============================] - 0s 1ms/step - loss: 2.0371\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2887\n16/16 [==============================] - 0s 655us/step - loss: 0.9164\n16/16 [==============================] - 0s 625us/step - loss: 1.6524\n16/16 [==============================] - 0s 664us/step - loss: 1.9863\n16/16 [==============================] - 0s 1ms/step - loss: 2.0320\n16/16 [==============================] - 0s 1ms/step - loss: 2.0386\n16/16 [==============================] - 0s 695us/step - loss: 2.0375\n16/16 [==============================] - 0s 671us/step - loss: 2.0360\n16/16 [==============================] - 0s 593us/step - loss: 2.0348\n16/16 [==============================] - 0s 592us/step - loss: 2.0343\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2903\n16/16 [==============================] - 0s 652us/step - loss: 0.9111\n16/16 [==============================] - 0s 634us/step - loss: 1.6388\n16/16 [==============================] - 0s 820us/step - loss: 1.9646\n16/16 [==============================] - 0s 1ms/step - loss: 2.0082\n16/16 [==============================] - 0s 730us/step - loss: 2.0139\n16/16 [==============================] - 0s 592us/step - loss: 2.0126\n16/16 [==============================] - 0s 590us/step - loss: 2.0110\n16/16 [==============================] - 0s 854us/step - loss: 2.0098\n16/16 [==============================] - 0s 639us/step - loss: 2.0093\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2907\n16/16 [==============================] - 0s 1ms/step - loss: 0.9147\n16/16 [==============================] - 0s 719us/step - loss: 1.6530\n16/16 [==============================] - 0s 658us/step - loss: 1.9850\n16/16 [==============================] - 0s 634us/step - loss: 2.0298\n16/16 [==============================] - 0s 653us/step - loss: 2.0361\n16/16 [==============================] - 0s 2ms/step - loss: 2.0350\n16/16 [==============================] - 0s 1ms/step - loss: 2.0335\n16/16 [==============================] - 0s 625us/step - loss: 2.0324\n16/16 [==============================] - 0s 2ms/step - loss: 2.0319\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2956\n16/16 [==============================] - 0s 1ms/step - loss: 0.9136\n16/16 [==============================] - 0s 1ms/step - loss: 1.6438\n16/16 [==============================] - 0s 1ms/step - loss: 1.9674\n16/16 [==============================] - 0s 1ms/step - loss: 2.0101\n16/16 [==============================] - 0s 1ms/step - loss: 2.0156\n16/16 [==============================] - 0s 1ms/step - loss: 2.0143\n16/16 [==============================] - 0s 1ms/step - loss: 2.0127\n16/16 [==============================] - 0s 1ms/step - loss: 2.0116\n16/16 [==============================] - 0s 1ms/step - loss: 2.0111\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2939\n16/16 [==============================] - 0s 1ms/step - loss: 0.9110\n16/16 [==============================] - 0s 1ms/step - loss: 1.6463\n16/16 [==============================] - 0s 1ms/step - loss: 1.9729\n16/16 [==============================] - 0s 2ms/step - loss: 2.0161\n16/16 [==============================] - 0s 2ms/step - loss: 2.0218\n16/16 [==============================] - 0s 1ms/step - loss: 2.0206\n16/16 [==============================] - 0s 1ms/step - loss: 2.0191\n16/16 [==============================] - 0s 1ms/step - loss: 2.0180\n16/16 [==============================] - 0s 679us/step - loss: 2.0175\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2919\n16/16 [==============================] - 0s 2ms/step - loss: 0.9017\n16/16 [==============================] - 0s 1ms/step - loss: 1.6263\n16/16 [==============================] - 0s 1ms/step - loss: 1.9428\n16/16 [==============================] - 0s 1ms/step - loss: 1.9832\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 694us/step - loss: 1.9863\n16/16 [==============================] - 0s 642us/step - loss: 1.9846\n16/16 [==============================] - 0s 593us/step - loss: 1.9834\n16/16 [==============================] - 0s 607us/step - loss: 1.9829\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 627us/step - loss: 0.2932\n16/16 [==============================] - 0s 619us/step - loss: 0.8949\n16/16 [==============================] - 0s 621us/step - loss: 1.6136\n16/16 [==============================] - 0s 623us/step - loss: 1.9271\n16/16 [==============================] - 0s 610us/step - loss: 1.9666\n16/16 [==============================] - 0s 1ms/step - loss: 1.9708\n16/16 [==============================] - 0s 1ms/step - loss: 1.9692\n16/16 [==============================] - 0s 629us/step - loss: 1.9675\n16/16 [==============================] - 0s 1ms/step - loss: 1.9663\n16/16 [==============================] - 0s 580us/step - loss: 1.9658\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2877\n16/16 [==============================] - 0s 1ms/step - loss: 0.9139\n16/16 [==============================] - 0s 1ms/step - loss: 1.6633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9868\n16/16 [==============================] - 0s 1ms/step - loss: 2.0271\n16/16 [==============================] - 0s 654us/step - loss: 2.0314\n16/16 [==============================] - 0s 683us/step - loss: 2.0298\n16/16 [==============================] - 0s 615us/step - loss: 2.0281\n16/16 [==============================] - 0s 1ms/step - loss: 2.0269\n16/16 [==============================] - 0s 663us/step - loss: 2.0263\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 742us/step - loss: 0.2883\n16/16 [==============================] - 0s 641us/step - loss: 0.8940\n16/16 [==============================] - 0s 1ms/step - loss: 1.6224\n16/16 [==============================] - 0s 634us/step - loss: 1.9361\n16/16 [==============================] - 0s 617us/step - loss: 1.9749\n16/16 [==============================] - 0s 1ms/step - loss: 1.9788\n16/16 [==============================] - 0s 628us/step - loss: 1.9771\n16/16 [==============================] - 0s 628us/step - loss: 1.9755\n16/16 [==============================] - 0s 1ms/step - loss: 1.9743\n16/16 [==============================] - 0s 802us/step - loss: 1.9737\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 0.2843\n16/16 [==============================] - 0s 1ms/step - loss: 0.9090\n16/16 [==============================] - 0s 1ms/step - loss: 1.6600\n16/16 [==============================] - 0s 712us/step - loss: 1.9791\n16/16 [==============================] - 0s 648us/step - loss: 2.0175\n16/16 [==============================] - 0s 647us/step - loss: 2.0210\n16/16 [==============================] - 0s 613us/step - loss: 2.0192\n16/16 [==============================] - 0s 629us/step - loss: 2.0174\n16/16 [==============================] - 0s 1ms/step - loss: 2.0162\n16/16 [==============================] - 0s 859us/step - loss: 2.0156\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2836\n16/16 [==============================] - 0s 1ms/step - loss: 0.9146\n16/16 [==============================] - 0s 2ms/step - loss: 1.6782\n16/16 [==============================] - 0s 1ms/step - loss: 2.0028\n16/16 [==============================] - 0s 1ms/step - loss: 2.0419\n16/16 [==============================] - 0s 1ms/step - loss: 2.0457\n16/16 [==============================] - 0s 1ms/step - loss: 2.0439\n16/16 [==============================] - 0s 1ms/step - loss: 2.0422\n16/16 [==============================] - 0s 676us/step - loss: 2.0410\n16/16 [==============================] - 0s 2ms/step - loss: 2.0405\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 684us/step - loss: 0.2791\n16/16 [==============================] - 0s 1ms/step - loss: 0.9413\n16/16 [==============================] - 0s 1ms/step - loss: 1.7429\n16/16 [==============================] - 0s 1ms/step - loss: 2.0793\n16/16 [==============================] - 0s 748us/step - loss: 2.1192\n16/16 [==============================] - 0s 1ms/step - loss: 2.1229\n16/16 [==============================] - 0s 657us/step - loss: 2.1211\n16/16 [==============================] - 0s 826us/step - loss: 2.1193\n16/16 [==============================] - 0s 654us/step - loss: 2.1181\n16/16 [==============================] - 0s 662us/step - loss: 2.1176\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 623us/step - loss: 0.2745\n16/16 [==============================] - 0s 636us/step - loss: 0.9399\n16/16 [==============================] - 0s 604us/step - loss: 1.7502\n16/16 [==============================] - 0s 1ms/step - loss: 2.0900\n16/16 [==============================] - 0s 1ms/step - loss: 2.1304\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 2ms/step - loss: 2.1327\n16/16 [==============================] - 0s 1ms/step - loss: 2.1310\n16/16 [==============================] - 0s 1ms/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.1293\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 850us/step - loss: 0.2705\n16/16 [==============================] - 0s 624us/step - loss: 0.9431\n16/16 [==============================] - 0s 626us/step - loss: 1.7595\n16/16 [==============================] - 0s 946us/step - loss: 2.0960\n16/16 [==============================] - 0s 631us/step - loss: 2.1341\n16/16 [==============================] - 0s 653us/step - loss: 2.1372\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 745us/step - loss: 2.1335\n16/16 [==============================] - 0s 1ms/step - loss: 2.1322\n16/16 [==============================] - 0s 1ms/step - loss: 2.1317\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.2706\n16/16 [==============================] - 0s 1ms/step - loss: 0.9454\n16/16 [==============================] - 0s 1ms/step - loss: 1.7683\n16/16 [==============================] - 0s 1ms/step - loss: 2.1066\n16/16 [==============================] - 0s 1ms/step - loss: 2.1448\n16/16 [==============================] - 0s 1ms/step - loss: 2.1478\n16/16 [==============================] - 0s 1ms/step - loss: 2.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.1441\n16/16 [==============================] - 0s 676us/step - loss: 2.1429\n16/16 [==============================] - 0s 1ms/step - loss: 2.1423\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 0.2763\n16/16 [==============================] - 0s 1ms/step - loss: 0.9427\n16/16 [==============================] - 0s 690us/step - loss: 1.7522\n16/16 [==============================] - 0s 1ms/step - loss: 2.0797\n16/16 [==============================] - 0s 717us/step - loss: 2.1151\n16/16 [==============================] - 0s 650us/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.1151\n16/16 [==============================] - 0s 1ms/step - loss: 2.1133\n16/16 [==============================] - 0s 674us/step - loss: 2.1120\n16/16 [==============================] - 0s 1ms/step - loss: 2.1114\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.2810\n16/16 [==============================] - 0s 668us/step - loss: 0.9270\n16/16 [==============================] - 0s 615us/step - loss: 1.7161\n16/16 [==============================] - 0s 637us/step - loss: 2.0351\n16/16 [==============================] - 0s 1ms/step - loss: 2.0696\n16/16 [==============================] - 0s 694us/step - loss: 2.0717\n16/16 [==============================] - 0s 1ms/step - loss: 2.0696\n16/16 [==============================] - 0s 641us/step - loss: 2.0678\n16/16 [==============================] - 0s 599us/step - loss: 2.0666\n16/16 [==============================] - 0s 624us/step - loss: 2.0660\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.879\nPrecision: 0.955\nRecall: 0.916\nF1 Score: 0.935\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.908\nPrecision: 0.977\nRecall: 0.925\nF1 Score: 0.950\n\n\n\nfourteen_linear = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-result",
    "title": "Class code for Comparison Study",
    "section": "Linear Result",
    "text": "Linear Result\n\nround(fourteen_linear,3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.959\n      0.960\n      0.999\n      0.979\n    \n    \n      LOF (Breunig et al., 2000)\n      0.890\n      0.973\n      0.909\n      0.940\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.912\n      0.979\n      0.927\n      0.952\n    \n    \n      CBLOF (He et al., 2003)\n      0.920\n      0.958\n      0.958\n      0.958\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.909\n      0.978\n      0.925\n      0.951\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.918\n      0.982\n      0.931\n      0.956\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.918\n      0.982\n      0.931\n      0.956\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.946\n      0.972\n      0.972\n      0.972\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.800\n      0.984\n      0.802\n      0.884\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.889\n      0.960\n      0.921\n      0.940\n    \n    \n      SOS (Janssens et al., 2012)\n      0.889\n      0.960\n      0.921\n      0.940\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.868\n      0.954\n      0.904\n      0.929\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.879\n      0.955\n      0.916\n      0.935\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.908\n      0.977\n      0.925\n      0.950"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-ebayesthresh",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-ebayesthresh",
    "title": "Class code for Comparison Study",
    "section": "Orbit EbayesThresh",
    "text": "Orbit EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier = which(signal!=0)\nindex_of_trueoutlier\nx=signal+epsilon\nplot(1:1000,x)\npoints(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)\n\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\n\n\n\n%R -o x\n%R -o index_of_trueoutlier\n%R -o signal\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n# plt.plot(x)\n# plt.plot(xhat)\n\n\noutlier_true_index = index_of_trueoutlier\n\n\noutlier_true_value = x[index_of_trueoutlier]\n\npackage와 비교를 위해 outlier는 -1, inlier는 1로 표시\n\noutlier_true_one = signal.copy()\n\n\noutlier_true_one = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one))"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit",
    "title": "Class code for Comparison Study",
    "section": "Orbit",
    "text": "Orbit\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\n_df = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f})\n\n\nX = np.array(_df)\n\n\nGODE\n\n_Orbit = Orbit(_df)\n\n\n_Orbit.get_distance()\n\n100%|██████████| 1000/1000 [00:02<00:00, 497.54it/s]\n\n\n\n_Orbit.get_weightmatrix(theta=(_Orbit.D[_Orbit.D>0].mean()),kappa=2500) \n\n\n_Orbit.fit(sd=15,ref=20)\n\n\noutlier_simul_one = (_Orbit.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 20 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.997\nPrecision: 0.997\nRecall: 1.000\nF1 Score: 0.998\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.886\nPrecision: 0.987\nRecall: 0.892\nF1 Score: 0.937\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','f']])\n_df['knn_clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.957\nRecall: 0.957\nF1 Score: 0.957\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.923\nPrecision: 0.988\nRecall: 0.931\nF1 Score: 0.958\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y','f']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.866\nPrecision: 0.953\nRecall: 0.903\nF1 Score: 0.928\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y','f']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.979\nRecall: 0.927\nF1 Score: 0.952\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y','f']])\n\n\npreds = od.predict(\n    _df[['x', 'y','f']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.378\nPrecision: 0.997\nRecall: 0.346\nF1 Score: 0.514\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y','f']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.881\nPrecision: 0.961\nRecall: 0.912\nF1 Score: 0.936\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y','f']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.881\nPrecision: 0.961\nRecall: 0.912\nF1 Score: 0.936\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y','f']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2135\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2178\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 891us/step - loss: 1.2227\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2138\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2244\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 917us/step - loss: 1.2068\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 1.2319\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2260\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2357\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 985us/step - loss: 1.2294\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2426\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2583\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 815us/step - loss: 1.2599\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2752\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 639us/step - loss: 1.3019\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2905\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 635us/step - loss: 1.3191\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 781us/step - loss: 1.3229\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 1.3371\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3418\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 803us/step - loss: 1.3589\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3819\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3966\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 956us/step - loss: 1.3947\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 609us/step - loss: 1.4201\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4322\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 617us/step - loss: 1.4333\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 626us/step - loss: 1.4465\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 640us/step - loss: 1.4560\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4823\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 932us/step - loss: 1.4888\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 782us/step - loss: 1.5030\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5161\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 599us/step - loss: 1.5196\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5412\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 877us/step - loss: 1.5368\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 579us/step - loss: 1.5523\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5574\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 981us/step - loss: 1.5684\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 643us/step - loss: 1.5748\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5725\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5772\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 1.5934\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6053\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 907us/step - loss: 1.6078\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6025\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6277\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 615us/step - loss: 1.6348\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 815us/step - loss: 1.6427\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 606us/step - loss: 1.6405\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 619us/step - loss: 1.6498\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 812us/step - loss: 1.6603\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 614us/step - loss: 1.6775\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 650us/step - loss: 1.6890\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6979\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6971\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 1.7076\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7120\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7271\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 863us/step - loss: 1.7406\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 623us/step - loss: 1.7534\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 677us/step - loss: 1.7597\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 741us/step - loss: 1.7555\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 678us/step - loss: 1.7716\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 827us/step - loss: 1.7776\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7776\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8009\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 626us/step - loss: 1.8053\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8205\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8218\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 666us/step - loss: 1.8259\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8307\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8576\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8445\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 742us/step - loss: 1.8687\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8710\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8824\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8924\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.876\nPrecision: 0.959\nRecall: 0.908\nF1 Score: 0.933\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y','f']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.5986\n16/16 [==============================] - 0s 1ms/step - loss: 1.2168\n16/16 [==============================] - 0s 643us/step - loss: 1.2657\n16/16 [==============================] - 0s 637us/step - loss: 1.2688\n16/16 [==============================] - 0s 1ms/step - loss: 1.2695\n16/16 [==============================] - 0s 1ms/step - loss: 1.2696\n16/16 [==============================] - 0s 653us/step - loss: 1.2696\n16/16 [==============================] - 0s 649us/step - loss: 1.2696\n16/16 [==============================] - 0s 711us/step - loss: 1.2696\n16/16 [==============================] - 0s 1ms/step - loss: 1.2696\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6392\n16/16 [==============================] - 0s 664us/step - loss: 1.2086\n16/16 [==============================] - 0s 711us/step - loss: 1.2461\n16/16 [==============================] - 0s 2ms/step - loss: 1.2488\n16/16 [==============================] - 0s 707us/step - loss: 1.2493\n16/16 [==============================] - 0s 628us/step - loss: 1.2494\n16/16 [==============================] - 0s 642us/step - loss: 1.2494\n16/16 [==============================] - 0s 698us/step - loss: 1.2494\n16/16 [==============================] - 0s 674us/step - loss: 1.2494\n16/16 [==============================] - 0s 788us/step - loss: 1.2494\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 663us/step - loss: 0.6763\n16/16 [==============================] - 0s 1ms/step - loss: 1.2250\n16/16 [==============================] - 0s 1ms/step - loss: 1.2559\n16/16 [==============================] - 0s 642us/step - loss: 1.2583\n16/16 [==============================] - 0s 1ms/step - loss: 1.2588\n16/16 [==============================] - 0s 672us/step - loss: 1.2589\n16/16 [==============================] - 0s 629us/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 658us/step - loss: 0.7044\n16/16 [==============================] - 0s 682us/step - loss: 1.2426\n16/16 [==============================] - 0s 661us/step - loss: 1.2710\n16/16 [==============================] - 0s 1ms/step - loss: 1.2733\n16/16 [==============================] - 0s 757us/step - loss: 1.2738\n16/16 [==============================] - 0s 725us/step - loss: 1.2739\n16/16 [==============================] - 0s 1ms/step - loss: 1.2739\n16/16 [==============================] - 0s 1ms/step - loss: 1.2739\n16/16 [==============================] - 0s 638us/step - loss: 1.2739\n16/16 [==============================] - 0s 648us/step - loss: 1.2739\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.7203\n16/16 [==============================] - 0s 878us/step - loss: 1.2467\n16/16 [==============================] - 0s 647us/step - loss: 1.2715\n16/16 [==============================] - 0s 1ms/step - loss: 1.2737\n16/16 [==============================] - 0s 1ms/step - loss: 1.2741\n16/16 [==============================] - 0s 637us/step - loss: 1.2742\n16/16 [==============================] - 0s 656us/step - loss: 1.2742\n16/16 [==============================] - 0s 1ms/step - loss: 1.2742\n16/16 [==============================] - 0s 645us/step - loss: 1.2742\n16/16 [==============================] - 0s 689us/step - loss: 1.2742\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 656us/step - loss: 0.7260\n16/16 [==============================] - 0s 1ms/step - loss: 1.2580\n16/16 [==============================] - 0s 655us/step - loss: 1.2817\n16/16 [==============================] - 0s 1ms/step - loss: 1.2839\n16/16 [==============================] - 0s 846us/step - loss: 1.2844\n16/16 [==============================] - 0s 696us/step - loss: 1.2844\n16/16 [==============================] - 0s 926us/step - loss: 1.2845\n16/16 [==============================] - 0s 661us/step - loss: 1.2845\n16/16 [==============================] - 0s 1ms/step - loss: 1.2845\n16/16 [==============================] - 0s 1ms/step - loss: 1.2845\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 641us/step - loss: 0.7292\n16/16 [==============================] - 0s 632us/step - loss: 1.2735\n16/16 [==============================] - 0s 780us/step - loss: 1.2970\n16/16 [==============================] - 0s 1ms/step - loss: 1.2995\n16/16 [==============================] - 0s 637us/step - loss: 1.2999\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 981us/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7228\n16/16 [==============================] - 0s 1ms/step - loss: 1.2928\n16/16 [==============================] - 0s 1ms/step - loss: 1.3171\n16/16 [==============================] - 0s 821us/step - loss: 1.3198\n16/16 [==============================] - 0s 611us/step - loss: 1.3203\n16/16 [==============================] - 0s 690us/step - loss: 1.3204\n16/16 [==============================] - 0s 647us/step - loss: 1.3204\n16/16 [==============================] - 0s 1ms/step - loss: 1.3204\n16/16 [==============================] - 0s 974us/step - loss: 1.3204\n16/16 [==============================] - 0s 589us/step - loss: 1.3204\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7136\n16/16 [==============================] - 0s 1ms/step - loss: 1.3031\n16/16 [==============================] - 0s 643us/step - loss: 1.3286\n16/16 [==============================] - 0s 1ms/step - loss: 1.3313\n16/16 [==============================] - 0s 948us/step - loss: 1.3319\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 802us/step - loss: 1.3320\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 837us/step - loss: 1.3320\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 631us/step - loss: 0.6966\n16/16 [==============================] - 0s 1ms/step - loss: 1.3288\n16/16 [==============================] - 0s 820us/step - loss: 1.3566\n16/16 [==============================] - 0s 934us/step - loss: 1.3598\n16/16 [==============================] - 0s 1ms/step - loss: 1.3604\n16/16 [==============================] - 0s 1ms/step - loss: 1.3605\n16/16 [==============================] - 0s 1ms/step - loss: 1.3605\n16/16 [==============================] - 0s 635us/step - loss: 1.3605\n16/16 [==============================] - 0s 865us/step - loss: 1.3605\n16/16 [==============================] - 0s 630us/step - loss: 1.3605\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6781\n16/16 [==============================] - 0s 1ms/step - loss: 1.3420\n16/16 [==============================] - 0s 862us/step - loss: 1.3719\n16/16 [==============================] - 0s 635us/step - loss: 1.3756\n16/16 [==============================] - 0s 611us/step - loss: 1.3763\n16/16 [==============================] - 0s 626us/step - loss: 1.3764\n16/16 [==============================] - 0s 796us/step - loss: 1.3764\n16/16 [==============================] - 0s 1ms/step - loss: 1.3764\n16/16 [==============================] - 0s 920us/step - loss: 1.3764\n16/16 [==============================] - 0s 596us/step - loss: 1.3764\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.6549\n16/16 [==============================] - 0s 1ms/step - loss: 1.3709\n16/16 [==============================] - 0s 712us/step - loss: 1.4048\n16/16 [==============================] - 0s 724us/step - loss: 1.4090\n16/16 [==============================] - 0s 749us/step - loss: 1.4098\n16/16 [==============================] - 0s 653us/step - loss: 1.4099\n16/16 [==============================] - 0s 629us/step - loss: 1.4099\n16/16 [==============================] - 0s 1ms/step - loss: 1.4099\n16/16 [==============================] - 0s 723us/step - loss: 1.4099\n16/16 [==============================] - 0s 634us/step - loss: 1.4099\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 0.6334\n16/16 [==============================] - 0s 618us/step - loss: 1.3962\n16/16 [==============================] - 0s 603us/step - loss: 1.4358\n16/16 [==============================] - 0s 1ms/step - loss: 1.4403\n16/16 [==============================] - 0s 1ms/step - loss: 1.4413\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\n16/16 [==============================] - 0s 893us/step - loss: 1.4415\n16/16 [==============================] - 0s 598us/step - loss: 1.4415\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 662us/step - loss: 0.6050\n16/16 [==============================] - 0s 1ms/step - loss: 1.4078\n16/16 [==============================] - 0s 1ms/step - loss: 1.4521\n16/16 [==============================] - 0s 818us/step - loss: 1.4572\n16/16 [==============================] - 0s 993us/step - loss: 1.4584\n16/16 [==============================] - 0s 1ms/step - loss: 1.4585\n16/16 [==============================] - 0s 1ms/step - loss: 1.4586\n16/16 [==============================] - 0s 1ms/step - loss: 1.4586\n16/16 [==============================] - 0s 765us/step - loss: 1.4585\n16/16 [==============================] - 0s 1ms/step - loss: 1.4585\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5843\n16/16 [==============================] - 0s 739us/step - loss: 1.4360\n16/16 [==============================] - 0s 1ms/step - loss: 1.4867\n16/16 [==============================] - 0s 582us/step - loss: 1.4928\n16/16 [==============================] - 0s 1ms/step - loss: 1.4941\n16/16 [==============================] - 0s 684us/step - loss: 1.4943\n16/16 [==============================] - 0s 884us/step - loss: 1.4943\n16/16 [==============================] - 0s 746us/step - loss: 1.4943\n16/16 [==============================] - 0s 997us/step - loss: 1.4943\n16/16 [==============================] - 0s 1ms/step - loss: 1.4942\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5581\n16/16 [==============================] - 0s 1ms/step - loss: 1.4546\n16/16 [==============================] - 0s 1ms/step - loss: 1.5115\n16/16 [==============================] - 0s 1ms/step - loss: 1.5182\n16/16 [==============================] - 0s 1ms/step - loss: 1.5197\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 612us/step - loss: 1.5199\n16/16 [==============================] - 0s 650us/step - loss: 1.5199\n16/16 [==============================] - 0s 642us/step - loss: 1.5199\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 601us/step - loss: 0.5402\n16/16 [==============================] - 0s 900us/step - loss: 1.4761\n16/16 [==============================] - 0s 1ms/step - loss: 1.5388\n16/16 [==============================] - 0s 1ms/step - loss: 1.5458\n16/16 [==============================] - 0s 1ms/step - loss: 1.5476\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 593us/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 769us/step - loss: 0.5184\n16/16 [==============================] - 0s 606us/step - loss: 1.5000\n16/16 [==============================] - 0s 908us/step - loss: 1.5668\n16/16 [==============================] - 0s 1ms/step - loss: 1.5748\n16/16 [==============================] - 0s 1ms/step - loss: 1.5767\n16/16 [==============================] - 0s 1ms/step - loss: 1.5769\n16/16 [==============================] - 0s 1ms/step - loss: 1.5769\n16/16 [==============================] - 0s 705us/step - loss: 1.5769\n16/16 [==============================] - 0s 613us/step - loss: 1.5769\n16/16 [==============================] - 0s 671us/step - loss: 1.5768\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 603us/step - loss: 0.5062\n16/16 [==============================] - 0s 629us/step - loss: 1.5280\n16/16 [==============================] - 0s 751us/step - loss: 1.5999\n16/16 [==============================] - 0s 615us/step - loss: 1.6088\n16/16 [==============================] - 0s 929us/step - loss: 1.6109\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 613us/step - loss: 1.6112\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 876us/step - loss: 1.6112\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 663us/step - loss: 0.4910\n16/16 [==============================] - 0s 1ms/step - loss: 1.5266\n16/16 [==============================] - 0s 1ms/step - loss: 1.6021\n16/16 [==============================] - 0s 1ms/step - loss: 1.6113\n16/16 [==============================] - 0s 763us/step - loss: 1.6135\n16/16 [==============================] - 0s 956us/step - loss: 1.6138\n16/16 [==============================] - 0s 611us/step - loss: 1.6139\n16/16 [==============================] - 0s 613us/step - loss: 1.6139\n16/16 [==============================] - 0s 1ms/step - loss: 1.6138\n16/16 [==============================] - 0s 718us/step - loss: 1.6138\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4859\n16/16 [==============================] - 0s 622us/step - loss: 1.5514\n16/16 [==============================] - 0s 608us/step - loss: 1.6294\n16/16 [==============================] - 0s 1ms/step - loss: 1.6390\n16/16 [==============================] - 0s 634us/step - loss: 1.6414\n16/16 [==============================] - 0s 593us/step - loss: 1.6417\n16/16 [==============================] - 0s 656us/step - loss: 1.6417\n16/16 [==============================] - 0s 606us/step - loss: 1.6417\n16/16 [==============================] - 0s 627us/step - loss: 1.6417\n16/16 [==============================] - 0s 951us/step - loss: 1.6416\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 886us/step - loss: 0.4775\n16/16 [==============================] - 0s 631us/step - loss: 1.5698\n16/16 [==============================] - 0s 1ms/step - loss: 1.6491\n16/16 [==============================] - 0s 1ms/step - loss: 1.6591\n16/16 [==============================] - 0s 642us/step - loss: 1.6617\n16/16 [==============================] - 0s 1ms/step - loss: 1.6620\n16/16 [==============================] - 0s 606us/step - loss: 1.6621\n16/16 [==============================] - 0s 649us/step - loss: 1.6620\n16/16 [==============================] - 0s 622us/step - loss: 1.6620\n16/16 [==============================] - 0s 621us/step - loss: 1.6619\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 0.4795\n16/16 [==============================] - 0s 638us/step - loss: 1.5898\n16/16 [==============================] - 0s 634us/step - loss: 1.6681\n16/16 [==============================] - 0s 1ms/step - loss: 1.6781\n16/16 [==============================] - 0s 677us/step - loss: 1.6809\n16/16 [==============================] - 0s 977us/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4773\n16/16 [==============================] - 0s 634us/step - loss: 1.5951\n16/16 [==============================] - 0s 1ms/step - loss: 1.6703\n16/16 [==============================] - 0s 599us/step - loss: 1.6803\n16/16 [==============================] - 0s 685us/step - loss: 1.6830\n16/16 [==============================] - 0s 617us/step - loss: 1.6833\n16/16 [==============================] - 0s 945us/step - loss: 1.6833\n16/16 [==============================] - 0s 1ms/step - loss: 1.6833\n16/16 [==============================] - 0s 1ms/step - loss: 1.6833\n16/16 [==============================] - 0s 602us/step - loss: 1.6832\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4855\n16/16 [==============================] - 0s 1ms/step - loss: 1.6287\n16/16 [==============================] - 0s 1ms/step - loss: 1.7034\n16/16 [==============================] - 0s 1ms/step - loss: 1.7137\n16/16 [==============================] - 0s 639us/step - loss: 1.7163\n16/16 [==============================] - 0s 681us/step - loss: 1.7166\n16/16 [==============================] - 0s 620us/step - loss: 1.7167\n16/16 [==============================] - 0s 583us/step - loss: 1.7167\n16/16 [==============================] - 0s 1ms/step - loss: 1.7167\n16/16 [==============================] - 0s 1ms/step - loss: 1.7166\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4900\n16/16 [==============================] - 0s 773us/step - loss: 1.6487\n16/16 [==============================] - 0s 624us/step - loss: 1.7219\n16/16 [==============================] - 0s 1ms/step - loss: 1.7322\n16/16 [==============================] - 0s 1ms/step - loss: 1.7348\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7351\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5048\n16/16 [==============================] - 0s 1ms/step - loss: 1.6447\n16/16 [==============================] - 0s 1ms/step - loss: 1.7129\n16/16 [==============================] - 0s 1ms/step - loss: 1.7226\n16/16 [==============================] - 0s 1ms/step - loss: 1.7250\n16/16 [==============================] - 0s 1ms/step - loss: 1.7253\n16/16 [==============================] - 0s 717us/step - loss: 1.7253\n16/16 [==============================] - 0s 830us/step - loss: 1.7253\n16/16 [==============================] - 0s 624us/step - loss: 1.7253\n16/16 [==============================] - 0s 682us/step - loss: 1.7252\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 0.5151\n16/16 [==============================] - 0s 1ms/step - loss: 1.6720\n16/16 [==============================] - 0s 838us/step - loss: 1.7389\n16/16 [==============================] - 0s 1ms/step - loss: 1.7487\n16/16 [==============================] - 0s 1ms/step - loss: 1.7510\n16/16 [==============================] - 0s 832us/step - loss: 1.7513\n16/16 [==============================] - 0s 1ms/step - loss: 1.7514\n16/16 [==============================] - 0s 595us/step - loss: 1.7514\n16/16 [==============================] - 0s 1ms/step - loss: 1.7514\n16/16 [==============================] - 0s 639us/step - loss: 1.7513\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5348\n16/16 [==============================] - 0s 870us/step - loss: 1.6661\n16/16 [==============================] - 0s 1ms/step - loss: 1.7277\n16/16 [==============================] - 0s 640us/step - loss: 1.7367\n16/16 [==============================] - 0s 897us/step - loss: 1.7389\n16/16 [==============================] - 0s 1ms/step - loss: 1.7391\n16/16 [==============================] - 0s 1ms/step - loss: 1.7392\n16/16 [==============================] - 0s 1ms/step - loss: 1.7392\n16/16 [==============================] - 0s 745us/step - loss: 1.7392\n16/16 [==============================] - 0s 1ms/step - loss: 1.7391\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 688us/step - loss: 0.5491\n16/16 [==============================] - 0s 635us/step - loss: 1.6837\n16/16 [==============================] - 0s 601us/step - loss: 1.7423\n16/16 [==============================] - 0s 601us/step - loss: 1.7511\n16/16 [==============================] - 0s 1ms/step - loss: 1.7531\n16/16 [==============================] - 0s 656us/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5738\n16/16 [==============================] - 0s 1ms/step - loss: 1.6942\n16/16 [==============================] - 0s 1ms/step - loss: 1.7482\n16/16 [==============================] - 0s 1ms/step - loss: 1.7566\n16/16 [==============================] - 0s 623us/step - loss: 1.7585\n16/16 [==============================] - 0s 741us/step - loss: 1.7588\n16/16 [==============================] - 0s 774us/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7587\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 0.5910\n16/16 [==============================] - 0s 1ms/step - loss: 1.7056\n16/16 [==============================] - 0s 1ms/step - loss: 1.7570\n16/16 [==============================] - 0s 1ms/step - loss: 1.7652\n16/16 [==============================] - 0s 596us/step - loss: 1.7670\n16/16 [==============================] - 0s 944us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.7673\n16/16 [==============================] - 0s 619us/step - loss: 1.7673\n16/16 [==============================] - 0s 617us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.7673\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 648us/step - loss: 0.6175\n16/16 [==============================] - 0s 628us/step - loss: 1.7136\n16/16 [==============================] - 0s 666us/step - loss: 1.7615\n16/16 [==============================] - 0s 612us/step - loss: 1.7696\n16/16 [==============================] - 0s 1ms/step - loss: 1.7713\n16/16 [==============================] - 0s 742us/step - loss: 1.7715\n16/16 [==============================] - 0s 626us/step - loss: 1.7716\n16/16 [==============================] - 0s 614us/step - loss: 1.7716\n16/16 [==============================] - 0s 623us/step - loss: 1.7715\n16/16 [==============================] - 0s 932us/step - loss: 1.7715\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6365\n16/16 [==============================] - 0s 1ms/step - loss: 1.7285\n16/16 [==============================] - 0s 1ms/step - loss: 1.7737\n16/16 [==============================] - 0s 1ms/step - loss: 1.7815\n16/16 [==============================] - 0s 1ms/step - loss: 1.7831\n16/16 [==============================] - 0s 617us/step - loss: 1.7834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 601us/step - loss: 1.7834\n16/16 [==============================] - 0s 929us/step - loss: 1.7834\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6645\n16/16 [==============================] - 0s 1ms/step - loss: 1.7425\n16/16 [==============================] - 0s 1ms/step - loss: 1.7848\n16/16 [==============================] - 0s 641us/step - loss: 1.7924\n16/16 [==============================] - 0s 1ms/step - loss: 1.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.7941\n16/16 [==============================] - 0s 821us/step - loss: 1.7941\n16/16 [==============================] - 0s 1ms/step - loss: 1.7941\n16/16 [==============================] - 0s 626us/step - loss: 1.7941\n16/16 [==============================] - 0s 636us/step - loss: 1.7941\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 634us/step - loss: 0.6840\n16/16 [==============================] - 0s 759us/step - loss: 1.7590\n16/16 [==============================] - 0s 1ms/step - loss: 1.7997\n16/16 [==============================] - 0s 1ms/step - loss: 1.8070\n16/16 [==============================] - 0s 1ms/step - loss: 1.8084\n16/16 [==============================] - 0s 1ms/step - loss: 1.8086\n16/16 [==============================] - 0s 639us/step - loss: 1.8086\n16/16 [==============================] - 0s 621us/step - loss: 1.8086\n16/16 [==============================] - 0s 670us/step - loss: 1.8086\n16/16 [==============================] - 0s 1ms/step - loss: 1.8086\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7124\n16/16 [==============================] - 0s 999us/step - loss: 1.7783\n16/16 [==============================] - 0s 1ms/step - loss: 1.8175\n16/16 [==============================] - 0s 688us/step - loss: 1.8245\n16/16 [==============================] - 0s 1ms/step - loss: 1.8258\n16/16 [==============================] - 0s 1ms/step - loss: 1.8261\n16/16 [==============================] - 0s 716us/step - loss: 1.8261\n16/16 [==============================] - 0s 658us/step - loss: 1.8261\n16/16 [==============================] - 0s 632us/step - loss: 1.8261\n16/16 [==============================] - 0s 635us/step - loss: 1.8261\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 921us/step - loss: 0.7273\n16/16 [==============================] - 0s 863us/step - loss: 1.7767\n16/16 [==============================] - 0s 995us/step - loss: 1.8143\n16/16 [==============================] - 0s 593us/step - loss: 1.8210\n16/16 [==============================] - 0s 1ms/step - loss: 1.8223\n16/16 [==============================] - 0s 877us/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8226\n16/16 [==============================] - 0s 820us/step - loss: 1.8226\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 688us/step - loss: 0.7514\n16/16 [==============================] - 0s 1ms/step - loss: 1.7804\n16/16 [==============================] - 0s 1ms/step - loss: 1.8152\n16/16 [==============================] - 0s 585us/step - loss: 1.8214\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n16/16 [==============================] - 0s 619us/step - loss: 1.8227\n16/16 [==============================] - 0s 1ms/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8227\n16/16 [==============================] - 0s 852us/step - loss: 1.8227\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7649\n16/16 [==============================] - 0s 1ms/step - loss: 1.7944\n16/16 [==============================] - 0s 1ms/step - loss: 1.8299\n16/16 [==============================] - 0s 804us/step - loss: 1.8361\n16/16 [==============================] - 0s 1ms/step - loss: 1.8372\n16/16 [==============================] - 0s 612us/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 641us/step - loss: 1.8375\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7882\n16/16 [==============================] - 0s 853us/step - loss: 1.8148\n16/16 [==============================] - 0s 659us/step - loss: 1.8491\n16/16 [==============================] - 0s 615us/step - loss: 1.8553\n16/16 [==============================] - 0s 931us/step - loss: 1.8563\n16/16 [==============================] - 0s 1ms/step - loss: 1.8566\n16/16 [==============================] - 0s 634us/step - loss: 1.8566\n16/16 [==============================] - 0s 861us/step - loss: 1.8566\n16/16 [==============================] - 0s 960us/step - loss: 1.8566\n16/16 [==============================] - 0s 1ms/step - loss: 1.8566\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7975\n16/16 [==============================] - 0s 646us/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8555\n16/16 [==============================] - 0s 588us/step - loss: 1.8616\n16/16 [==============================] - 0s 898us/step - loss: 1.8626\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 661us/step - loss: 1.8628\n16/16 [==============================] - 0s 636us/step - loss: 1.8628\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 590us/step - loss: 0.8169\n16/16 [==============================] - 0s 1ms/step - loss: 1.8391\n16/16 [==============================] - 0s 633us/step - loss: 1.8715\n16/16 [==============================] - 0s 585us/step - loss: 1.8774\n16/16 [==============================] - 0s 615us/step - loss: 1.8784\n16/16 [==============================] - 0s 596us/step - loss: 1.8786\n16/16 [==============================] - 0s 1ms/step - loss: 1.8787\n16/16 [==============================] - 0s 1ms/step - loss: 1.8787\n16/16 [==============================] - 0s 631us/step - loss: 1.8787\n16/16 [==============================] - 0s 671us/step - loss: 1.8787\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 865us/step - loss: 0.8231\n16/16 [==============================] - 0s 1ms/step - loss: 1.8496\n16/16 [==============================] - 0s 620us/step - loss: 1.8823\n16/16 [==============================] - 0s 664us/step - loss: 1.8883\n16/16 [==============================] - 0s 600us/step - loss: 1.8893\n16/16 [==============================] - 0s 1ms/step - loss: 1.8895\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 628us/step - loss: 1.8896\n16/16 [==============================] - 0s 1ms/step - loss: 1.8895\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8391\n16/16 [==============================] - 0s 609us/step - loss: 1.8681\n16/16 [==============================] - 0s 871us/step - loss: 1.9009\n16/16 [==============================] - 0s 565us/step - loss: 1.9070\n16/16 [==============================] - 0s 1ms/step - loss: 1.9079\n16/16 [==============================] - 0s 610us/step - loss: 1.9081\n16/16 [==============================] - 0s 637us/step - loss: 1.9082\n16/16 [==============================] - 0s 1ms/step - loss: 1.9082\n16/16 [==============================] - 0s 1ms/step - loss: 1.9082\n16/16 [==============================] - 0s 880us/step - loss: 1.9082\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8437\n16/16 [==============================] - 0s 1ms/step - loss: 1.8798\n16/16 [==============================] - 0s 923us/step - loss: 1.9120\n16/16 [==============================] - 0s 1ms/step - loss: 1.9179\n16/16 [==============================] - 0s 612us/step - loss: 1.9189\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 681us/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8544\n16/16 [==============================] - 0s 645us/step - loss: 1.8871\n16/16 [==============================] - 0s 632us/step - loss: 1.9189\n16/16 [==============================] - 0s 1ms/step - loss: 1.9248\n16/16 [==============================] - 0s 1ms/step - loss: 1.9257\n16/16 [==============================] - 0s 1ms/step - loss: 1.9259\n16/16 [==============================] - 0s 836us/step - loss: 1.9259\n16/16 [==============================] - 0s 695us/step - loss: 1.9259\n16/16 [==============================] - 0s 1ms/step - loss: 1.9259\n16/16 [==============================] - 0s 808us/step - loss: 1.9259\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8583\n16/16 [==============================] - 0s 1ms/step - loss: 1.9099\n16/16 [==============================] - 0s 785us/step - loss: 1.9431\n16/16 [==============================] - 0s 782us/step - loss: 1.9491\n16/16 [==============================] - 0s 1ms/step - loss: 1.9501\n16/16 [==============================] - 0s 711us/step - loss: 1.9503\n16/16 [==============================] - 0s 617us/step - loss: 1.9503\n16/16 [==============================] - 0s 601us/step - loss: 1.9503\n16/16 [==============================] - 0s 671us/step - loss: 1.9503\n16/16 [==============================] - 0s 602us/step - loss: 1.9504\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8705\n16/16 [==============================] - 0s 1ms/step - loss: 1.9270\n16/16 [==============================] - 0s 928us/step - loss: 1.9599\n16/16 [==============================] - 0s 758us/step - loss: 1.9658\n16/16 [==============================] - 0s 2ms/step - loss: 1.9668\n16/16 [==============================] - 0s 1ms/step - loss: 1.9670\n16/16 [==============================] - 0s 594us/step - loss: 1.9670\n16/16 [==============================] - 0s 600us/step - loss: 1.9670\n16/16 [==============================] - 0s 599us/step - loss: 1.9670\n16/16 [==============================] - 0s 924us/step - loss: 1.9670\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 0.8683\n16/16 [==============================] - 0s 1ms/step - loss: 1.9287\n16/16 [==============================] - 0s 665us/step - loss: 1.9614\n16/16 [==============================] - 0s 1ms/step - loss: 1.9673\n16/16 [==============================] - 0s 1ms/step - loss: 1.9683\n16/16 [==============================] - 0s 1ms/step - loss: 1.9685\n16/16 [==============================] - 0s 654us/step - loss: 1.9685\n16/16 [==============================] - 0s 762us/step - loss: 1.9685\n16/16 [==============================] - 0s 628us/step - loss: 1.9685\n16/16 [==============================] - 0s 654us/step - loss: 1.9685\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 659us/step - loss: 0.8815\n16/16 [==============================] - 0s 1ms/step - loss: 1.9514\n16/16 [==============================] - 0s 1ms/step - loss: 1.9846\n16/16 [==============================] - 0s 1ms/step - loss: 1.9905\n16/16 [==============================] - 0s 1ms/step - loss: 1.9915\n16/16 [==============================] - 0s 786us/step - loss: 1.9916\n16/16 [==============================] - 0s 655us/step - loss: 1.9917\n16/16 [==============================] - 0s 1ms/step - loss: 1.9917\n16/16 [==============================] - 0s 973us/step - loss: 1.9917\n16/16 [==============================] - 0s 1ms/step - loss: 1.9917\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 741us/step - loss: 0.8773\n16/16 [==============================] - 0s 672us/step - loss: 1.9488\n16/16 [==============================] - 0s 660us/step - loss: 1.9816\n16/16 [==============================] - 0s 1ms/step - loss: 1.9875\n16/16 [==============================] - 0s 899us/step - loss: 1.9885\n16/16 [==============================] - 0s 1ms/step - loss: 1.9887\n16/16 [==============================] - 0s 885us/step - loss: 1.9887\n16/16 [==============================] - 0s 661us/step - loss: 1.9887\n16/16 [==============================] - 0s 1ms/step - loss: 1.9887\n16/16 [==============================] - 0s 972us/step - loss: 1.9887\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.8923\n16/16 [==============================] - 0s 802us/step - loss: 1.9764\n16/16 [==============================] - 0s 733us/step - loss: 2.0094\n16/16 [==============================] - 0s 878us/step - loss: 2.0152\n16/16 [==============================] - 0s 667us/step - loss: 2.0162\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 831us/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0165\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8980\n16/16 [==============================] - 0s 829us/step - loss: 2.0059\n16/16 [==============================] - 0s 1ms/step - loss: 2.0403\n16/16 [==============================] - 0s 1ms/step - loss: 2.0464\n16/16 [==============================] - 0s 991us/step - loss: 2.0474\n16/16 [==============================] - 0s 657us/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n16/16 [==============================] - 0s 625us/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 0.9077\n16/16 [==============================] - 0s 1ms/step - loss: 2.0130\n16/16 [==============================] - 0s 1ms/step - loss: 2.0470\n16/16 [==============================] - 0s 953us/step - loss: 2.0530\n16/16 [==============================] - 0s 1ms/step - loss: 2.0539\n16/16 [==============================] - 0s 1ms/step - loss: 2.0541\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9081\n16/16 [==============================] - 0s 1ms/step - loss: 2.0204\n16/16 [==============================] - 0s 1ms/step - loss: 2.0543\n16/16 [==============================] - 0s 694us/step - loss: 2.0602\n16/16 [==============================] - 0s 1ms/step - loss: 2.0611\n16/16 [==============================] - 0s 1ms/step - loss: 2.0613\n16/16 [==============================] - 0s 815us/step - loss: 2.0614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0614\n16/16 [==============================] - 0s 804us/step - loss: 2.0614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0614\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9192\n16/16 [==============================] - 0s 2ms/step - loss: 2.0292\n16/16 [==============================] - 0s 1ms/step - loss: 2.0625\n16/16 [==============================] - 0s 1ms/step - loss: 2.0683\n16/16 [==============================] - 0s 1ms/step - loss: 2.0692\n16/16 [==============================] - 0s 1ms/step - loss: 2.0693\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9220\n16/16 [==============================] - 0s 1ms/step - loss: 2.0413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0749\n16/16 [==============================] - 0s 1ms/step - loss: 2.0807\n16/16 [==============================] - 0s 1ms/step - loss: 2.0816\n16/16 [==============================] - 0s 1ms/step - loss: 2.0818\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.9344\n16/16 [==============================] - 0s 2ms/step - loss: 2.0501\n16/16 [==============================] - 0s 2ms/step - loss: 2.0831\n16/16 [==============================] - 0s 2ms/step - loss: 2.0889\n16/16 [==============================] - 0s 2ms/step - loss: 2.0898\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.9430\n16/16 [==============================] - 0s 2ms/step - loss: 2.0784\n16/16 [==============================] - 0s 1ms/step - loss: 2.1121\n16/16 [==============================] - 0s 1ms/step - loss: 2.1180\n16/16 [==============================] - 0s 1ms/step - loss: 2.1189\n16/16 [==============================] - 0s 670us/step - loss: 2.1191\n16/16 [==============================] - 0s 707us/step - loss: 2.1191\n16/16 [==============================] - 0s 720us/step - loss: 2.1191\n16/16 [==============================] - 0s 685us/step - loss: 2.1191\n16/16 [==============================] - 0s 600us/step - loss: 2.1191\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9590\n16/16 [==============================] - 0s 1ms/step - loss: 2.0944\n16/16 [==============================] - 0s 2ms/step - loss: 2.1283\n16/16 [==============================] - 0s 1ms/step - loss: 2.1342\n16/16 [==============================] - 0s 2ms/step - loss: 2.1351\n16/16 [==============================] - 0s 2ms/step - loss: 2.1353\n16/16 [==============================] - 0s 2ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1354\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9632\n16/16 [==============================] - 0s 1ms/step - loss: 2.1018\n16/16 [==============================] - 0s 1ms/step - loss: 2.1355\n16/16 [==============================] - 0s 1ms/step - loss: 2.1415\n16/16 [==============================] - 0s 1ms/step - loss: 2.1424\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 2ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1427\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 593us/step - loss: 0.9811\n16/16 [==============================] - 0s 1ms/step - loss: 2.1158\n16/16 [==============================] - 0s 601us/step - loss: 2.1494\n16/16 [==============================] - 0s 604us/step - loss: 2.1553\n16/16 [==============================] - 0s 1ms/step - loss: 2.1562\n16/16 [==============================] - 0s 580us/step - loss: 2.1564\n16/16 [==============================] - 0s 606us/step - loss: 2.1564\n16/16 [==============================] - 0s 669us/step - loss: 2.1565\n16/16 [==============================] - 0s 933us/step - loss: 2.1565\n16/16 [==============================] - 0s 604us/step - loss: 2.1565\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 617us/step - loss: 0.9849\n16/16 [==============================] - 0s 874us/step - loss: 2.1127\n16/16 [==============================] - 0s 601us/step - loss: 2.1443\n16/16 [==============================] - 0s 721us/step - loss: 2.1500\n16/16 [==============================] - 0s 709us/step - loss: 2.1508\n16/16 [==============================] - 0s 636us/step - loss: 2.1510\n16/16 [==============================] - 0s 641us/step - loss: 2.1510\n16/16 [==============================] - 0s 3ms/step - loss: 2.1510\n16/16 [==============================] - 0s 832us/step - loss: 2.1510\n16/16 [==============================] - 0s 943us/step - loss: 2.1511\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 960us/step - loss: 1.0029\n16/16 [==============================] - 0s 847us/step - loss: 2.1223\n16/16 [==============================] - 0s 1ms/step - loss: 2.1535\n16/16 [==============================] - 0s 663us/step - loss: 2.1592\n16/16 [==============================] - 0s 1ms/step - loss: 2.1600\n16/16 [==============================] - 0s 1ms/step - loss: 2.1601\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.0201\n16/16 [==============================] - 0s 2ms/step - loss: 2.1555\n16/16 [==============================] - 0s 698us/step - loss: 2.1869\n16/16 [==============================] - 0s 738us/step - loss: 2.1925\n16/16 [==============================] - 0s 974us/step - loss: 2.1933\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 811us/step - loss: 2.1935\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 685us/step - loss: 2.1935\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 644us/step - loss: 1.0391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1625\n16/16 [==============================] - 0s 1ms/step - loss: 2.1931\n16/16 [==============================] - 0s 894us/step - loss: 2.1987\n16/16 [==============================] - 0s 2ms/step - loss: 2.1995\n16/16 [==============================] - 0s 700us/step - loss: 2.1996\n16/16 [==============================] - 0s 1ms/step - loss: 2.1997\n16/16 [==============================] - 0s 851us/step - loss: 2.1997\n16/16 [==============================] - 0s 925us/step - loss: 2.1997\n16/16 [==============================] - 0s 868us/step - loss: 2.1997\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.0520\n16/16 [==============================] - 0s 627us/step - loss: 2.1801\n16/16 [==============================] - 0s 1ms/step - loss: 2.2107\n16/16 [==============================] - 0s 633us/step - loss: 2.2163\n16/16 [==============================] - 0s 899us/step - loss: 2.2171\n16/16 [==============================] - 0s 711us/step - loss: 2.2172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n16/16 [==============================] - 0s 664us/step - loss: 2.2173\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 589us/step - loss: 1.0727\n16/16 [==============================] - 0s 603us/step - loss: 2.1879\n16/16 [==============================] - 0s 581us/step - loss: 2.2176\n16/16 [==============================] - 0s 580us/step - loss: 2.2229\n16/16 [==============================] - 0s 582us/step - loss: 2.2236\n16/16 [==============================] - 0s 571us/step - loss: 2.2238\n16/16 [==============================] - 0s 574us/step - loss: 2.2238\n16/16 [==============================] - 0s 561us/step - loss: 2.2238\n16/16 [==============================] - 0s 506us/step - loss: 2.2238\n16/16 [==============================] - 0s 526us/step - loss: 2.2239\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.0790\n16/16 [==============================] - 0s 1ms/step - loss: 2.1883\n16/16 [==============================] - 0s 2ms/step - loss: 2.2177\n16/16 [==============================] - 0s 2ms/step - loss: 2.2230\n16/16 [==============================] - 0s 2ms/step - loss: 2.2237\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2240\n16/16 [==============================] - 0s 2ms/step - loss: 2.2240\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1019\n16/16 [==============================] - 0s 2ms/step - loss: 2.2025\n16/16 [==============================] - 0s 2ms/step - loss: 2.2310\n16/16 [==============================] - 0s 2ms/step - loss: 2.2362\n16/16 [==============================] - 0s 2ms/step - loss: 2.2369\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2372\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1130\n16/16 [==============================] - 0s 2ms/step - loss: 2.2126\n16/16 [==============================] - 0s 2ms/step - loss: 2.2408\n16/16 [==============================] - 0s 2ms/step - loss: 2.2460\n16/16 [==============================] - 0s 2ms/step - loss: 2.2466\n16/16 [==============================] - 0s 2ms/step - loss: 2.2468\n16/16 [==============================] - 0s 2ms/step - loss: 2.2468\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1360\n16/16 [==============================] - 0s 2ms/step - loss: 2.2253\n16/16 [==============================] - 0s 2ms/step - loss: 2.2519\n16/16 [==============================] - 0s 2ms/step - loss: 2.2569\n16/16 [==============================] - 0s 2ms/step - loss: 2.2576\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2578\n16/16 [==============================] - 0s 1ms/step - loss: 2.2578\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.1524\n16/16 [==============================] - 0s 2ms/step - loss: 2.2520\n16/16 [==============================] - 0s 1ms/step - loss: 2.2798\n16/16 [==============================] - 0s 2ms/step - loss: 2.2850\n16/16 [==============================] - 0s 2ms/step - loss: 2.2857\n16/16 [==============================] - 0s 1ms/step - loss: 2.2858\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n16/16 [==============================] - 0s 966us/step - loss: 2.2859\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1690\n16/16 [==============================] - 0s 984us/step - loss: 2.2519\n16/16 [==============================] - 0s 2ms/step - loss: 2.2784\n16/16 [==============================] - 0s 2ms/step - loss: 2.2834\n16/16 [==============================] - 0s 925us/step - loss: 2.2840\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 767us/step - loss: 2.2842\n16/16 [==============================] - 0s 1ms/step - loss: 2.2843\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1811\n16/16 [==============================] - 0s 2ms/step - loss: 2.2676\n16/16 [==============================] - 0s 2ms/step - loss: 2.2948\n16/16 [==============================] - 0s 2ms/step - loss: 2.2999\n16/16 [==============================] - 0s 2ms/step - loss: 2.3005\n16/16 [==============================] - 0s 2ms/step - loss: 2.3007\n16/16 [==============================] - 0s 2ms/step - loss: 2.3008\n16/16 [==============================] - 0s 1ms/step - loss: 2.3008\n16/16 [==============================] - 0s 657us/step - loss: 2.3008\n16/16 [==============================] - 0s 654us/step - loss: 2.3008\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.1986\n16/16 [==============================] - 0s 600us/step - loss: 2.2691\n16/16 [==============================] - 0s 579us/step - loss: 2.2946\n16/16 [==============================] - 0s 2ms/step - loss: 2.2995\n16/16 [==============================] - 0s 2ms/step - loss: 2.3001\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3004\n16/16 [==============================] - 0s 2ms/step - loss: 2.3004\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.2123\n16/16 [==============================] - 0s 2ms/step - loss: 2.2903\n16/16 [==============================] - 0s 2ms/step - loss: 2.3163\n16/16 [==============================] - 0s 2ms/step - loss: 2.3213\n16/16 [==============================] - 0s 2ms/step - loss: 2.3219\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3222\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 795us/step - loss: 1.2301\n16/16 [==============================] - 0s 1ms/step - loss: 2.2941\n16/16 [==============================] - 0s 597us/step - loss: 2.3188\n16/16 [==============================] - 0s 524us/step - loss: 2.3236\n16/16 [==============================] - 0s 889us/step - loss: 2.3242\n16/16 [==============================] - 0s 675us/step - loss: 2.3243\n16/16 [==============================] - 0s 523us/step - loss: 2.3243\n16/16 [==============================] - 0s 577us/step - loss: 2.3243\n16/16 [==============================] - 0s 531us/step - loss: 2.3243\n16/16 [==============================] - 0s 646us/step - loss: 2.3244\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y','f']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\n\nfourteen_orbit = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-result",
    "title": "Class code for Comparison Study",
    "section": "Orbit Result",
    "text": "Orbit Result\n\nround(fourteen_orbit,4)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.997\n      0.9969\n      1.0000\n      0.9984\n    \n    \n      LOF (Breunig et al., 2000)\n      0.886\n      0.9872\n      0.8916\n      0.9369\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.948\n      0.9989\n      0.9463\n      0.9719\n    \n    \n      CBLOF (He et al., 2003)\n      0.918\n      0.9568\n      0.9568\n      0.9568\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.923\n      0.9877\n      0.9305\n      0.9583\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.866\n      0.9533\n      0.9032\n      0.9276\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.912\n      0.9789\n      0.9274\n      0.9524\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.9937\n      0.9937\n      0.9937\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.378\n      0.9970\n      0.3463\n      0.5141\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.881\n      0.9612\n      0.9116\n      0.9357\n    \n    \n      SOS (Janssens et al., 2012)\n      0.881\n      0.9612\n      0.9116\n      0.9357\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.876\n      0.9589\n      0.9084\n      0.9330\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.950\n      0.9500\n      1.0000\n      0.9744\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.948\n      0.9989\n      0.9463\n      0.9719"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny",
    "title": "Class code for Comparison Study",
    "section": "Bunny",
    "text": "Bunny\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) \n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\nindex_of_trueoutlier2 = np.where(unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2022-11-26 07:54:05,353:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nG.coords.shape\n\n(2503, 3)\n\n\n\n_W = G.W.toarray()\n_x = G.coords[:,0]\n_y = G.coords[:,1]\n_z = -G.coords[:,2]\n\n\n_df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})\n\n\noutlier_true_one_2 = unif.copy()\n\n\noutlier_true_one_2 = list(map(lambda x: -1 if x !=0  else 1,outlier_true_one_2))\n\n\nX = np.array(_df)[:,:4]\n\n\nGODE\n\n_BUNNY = BUNNY(_df)\n\n\n_BUNNY.fit(sd=20,ref=10)\n\n\noutlier_simul_one = (_BUNNY.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 10 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.995\nPrecision: 0.995\nRecall: 0.999\nF1 Score: 0.997\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.928\nPrecision: 0.957\nRecall: 0.969\nF1 Score: 0.963\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.996\nRecall: 0.941\nF1 Score: 0.968\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.978\nPrecision: 0.989\nRecall: 0.987\nF1 Score: 0.988\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.932\nPrecision: 0.991\nRecall: 0.937\nF1 Score: 0.963\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.993\nRecall: 0.938\nF1 Score: 0.965\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.915\nPrecision: 0.982\nRecall: 0.928\nF1 Score: 0.954\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.977\nPrecision: 0.989\nRecall: 0.987\nF1 Score: 0.988\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y','fnoise']])\n\n\npreds = od.predict(\n    _df[['x', 'y','fnoise']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.794\nPrecision: 0.995\nRecall: 0.788\nF1 Score: 0.879\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.895\nPrecision: 0.969\nRecall: 0.919\nF1 Score: 0.944\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.895\nPrecision: 0.969\nRecall: 0.919\nF1 Score: 0.944\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 894us/step - loss: 1.8529\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8921\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9309\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 690us/step - loss: 1.8584\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8820\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9128\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9055\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9463\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9150\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 755us/step - loss: 1.9138\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 636us/step - loss: 2.0252\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 1.9456\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 701us/step - loss: 1.9662\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9841\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0037\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9889\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 871us/step - loss: 1.9856\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0014\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 778us/step - loss: 2.0162\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 664us/step - loss: 2.0739\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 2.0179\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0133\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0655\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 2.0657\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0669\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0880\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 800us/step - loss: 2.0889\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1112\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0641\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0520\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0533\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 601us/step - loss: 2.1067\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 645us/step - loss: 2.1065\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 634us/step - loss: 2.0811\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 633us/step - loss: 2.0727\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 687us/step - loss: 2.1834\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0984\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 599us/step - loss: 2.1578\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1489\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 671us/step - loss: 2.1636\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1516\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 636us/step - loss: 2.1534\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 776us/step - loss: 2.1465\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1006\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 768us/step - loss: 2.1580\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1679\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 932us/step - loss: 2.1854\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1869\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 600us/step - loss: 2.1570\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 701us/step - loss: 2.2004\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 664us/step - loss: 2.2094\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.2316\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1808\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 606us/step - loss: 2.2633\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2481\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 2.2154\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2065\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 632us/step - loss: 2.2313\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 728us/step - loss: 2.2298\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 651us/step - loss: 2.2541\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2413\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.1930\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 607us/step - loss: 2.2856\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 650us/step - loss: 2.2537\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2461\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 654us/step - loss: 2.3097\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 831us/step - loss: 2.3159\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 934us/step - loss: 2.2306\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 654us/step - loss: 2.2956\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2296\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2378\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 926us/step - loss: 2.2114\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 716us/step - loss: 2.2166\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2483\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2669\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 718us/step - loss: 2.2966\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 776us/step - loss: 2.2346\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3040\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 780us/step - loss: 2.3003\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2809\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 789us/step - loss: 2.2804\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2915\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2829\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 923us/step - loss: 2.3199\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 980us/step - loss: 2.2642\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3208\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3127\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3514\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 829us/step - loss: 2.3363\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 2.3203\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.3100\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 625us/step - loss: 2.2837\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 640us/step - loss: 2.2877\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3374\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3149\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.3535\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 652us/step - loss: 2.3861\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 723us/step - loss: 2.3328\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3450\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 641us/step - loss: 2.3578\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3235\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 958us/step - loss: 2.3421\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 593us/step - loss: 2.3656\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 623us/step - loss: 2.3044\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3273\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3797\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 654us/step - loss: 2.3372\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3387\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 608us/step - loss: 2.4377\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 965us/step - loss: 2.4568\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 2.4050\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 943us/step - loss: 2.3936\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3910\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4026\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 647us/step - loss: 2.4177\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 941us/step - loss: 2.4015\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3971\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 678us/step - loss: 2.3933\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4488\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 594us/step - loss: 2.3598\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 655us/step - loss: 2.4883\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4234\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3641\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 649us/step - loss: 2.4212\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 828us/step - loss: 2.5119\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 2.4255\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4828\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4336\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3916\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 630us/step - loss: 2.4157\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 621us/step - loss: 2.4543\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 672us/step - loss: 2.3956\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4783\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 630us/step - loss: 2.4045\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4787\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 880us/step - loss: 2.4557\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4497\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 635us/step - loss: 2.4115\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 613us/step - loss: 2.4469\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 764us/step - loss: 2.4250\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4706\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 620us/step - loss: 2.3919\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 698us/step - loss: 2.4463\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 958us/step - loss: 2.4810\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4359\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4080\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4634\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5226\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 894us/step - loss: 2.4385\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 856us/step - loss: 2.5063\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4672\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5011\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 618us/step - loss: 2.5610\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 679us/step - loss: 2.5239\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5248\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 990us/step - loss: 2.5142\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5164\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3996\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 894us/step - loss: 2.4939\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4897\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 617us/step - loss: 2.5320\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 619us/step - loss: 2.5544\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4986\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 648us/step - loss: 2.5618\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5605\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4780\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.4659\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4696\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 643us/step - loss: 2.5610\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4586\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 665us/step - loss: 2.4735\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 964us/step - loss: 2.5013\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 840us/step - loss: 2.4765\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 908us/step - loss: 2.5925\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 644us/step - loss: 2.5213\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 624us/step - loss: 2.5540\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5273\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 665us/step - loss: 2.5155\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5001\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5154\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5593\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 653us/step - loss: 2.4897\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 621us/step - loss: 2.5391\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5966\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5325\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5563\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4993\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 625us/step - loss: 2.5589\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5403\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 833us/step - loss: 2.5143\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 808us/step - loss: 2.5618\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 796us/step - loss: 2.5960\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 599us/step - loss: 2.5405\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 650us/step - loss: 2.5440\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 839us/step - loss: 0.2862\n16/16 [==============================] - 0s 1ms/step - loss: 1.3562\n16/16 [==============================] - 0s 879us/step - loss: 1.6391\n16/16 [==============================] - 0s 676us/step - loss: 1.7457\n16/16 [==============================] - 0s 668us/step - loss: 1.7800\n16/16 [==============================] - 0s 797us/step - loss: 1.7893\n16/16 [==============================] - 0s 1ms/step - loss: 1.7882\n16/16 [==============================] - 0s 750us/step - loss: 1.7810\n16/16 [==============================] - 0s 661us/step - loss: 1.7768\n16/16 [==============================] - 0s 1ms/step - loss: 1.7746\n\nTesting for epoch 21 index 3:\n16/16 [==============================] - 0s 709us/step - loss: 0.2829\n16/16 [==============================] - 0s 1ms/step - loss: 1.3627\n16/16 [==============================] - 0s 1ms/step - loss: 1.6520\n16/16 [==============================] - 0s 1ms/step - loss: 1.7617\n16/16 [==============================] - 0s 648us/step - loss: 1.7969\n16/16 [==============================] - 0s 655us/step - loss: 1.8064\n16/16 [==============================] - 0s 1ms/step - loss: 1.8050\n16/16 [==============================] - 0s 1ms/step - loss: 1.7975\n16/16 [==============================] - 0s 1ms/step - loss: 1.7932\n16/16 [==============================] - 0s 1ms/step - loss: 1.7909\n\nTesting for epoch 21 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2819\n16/16 [==============================] - 0s 662us/step - loss: 1.3750\n16/16 [==============================] - 0s 649us/step - loss: 1.6692\n16/16 [==============================] - 0s 664us/step - loss: 1.7821\n16/16 [==============================] - 0s 644us/step - loss: 1.8194\n16/16 [==============================] - 0s 671us/step - loss: 1.8316\n16/16 [==============================] - 0s 651us/step - loss: 1.8318\n16/16 [==============================] - 0s 661us/step - loss: 1.8249\n16/16 [==============================] - 0s 990us/step - loss: 1.8208\n16/16 [==============================] - 0s 1ms/step - loss: 1.8185\n\nTesting for epoch 21 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2784\n16/16 [==============================] - 0s 1ms/step - loss: 1.3590\n16/16 [==============================] - 0s 645us/step - loss: 1.6490\n16/16 [==============================] - 0s 1ms/step - loss: 1.7586\n16/16 [==============================] - 0s 655us/step - loss: 1.7914\n16/16 [==============================] - 0s 1ms/step - loss: 1.7998\n16/16 [==============================] - 0s 1ms/step - loss: 1.7975\n16/16 [==============================] - 0s 653us/step - loss: 1.7896\n16/16 [==============================] - 0s 675us/step - loss: 1.7852\n16/16 [==============================] - 0s 1ms/step - loss: 1.7829\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2787\n16/16 [==============================] - 0s 1ms/step - loss: 1.3475\n16/16 [==============================] - 0s 646us/step - loss: 1.6341\n16/16 [==============================] - 0s 690us/step - loss: 1.7422\n16/16 [==============================] - 0s 1ms/step - loss: 1.7757\n16/16 [==============================] - 0s 1ms/step - loss: 1.7855\n16/16 [==============================] - 0s 1ms/step - loss: 1.7843\n16/16 [==============================] - 0s 1ms/step - loss: 1.7771\n16/16 [==============================] - 0s 1ms/step - loss: 1.7729\n16/16 [==============================] - 0s 1ms/step - loss: 1.7708\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 680us/step - loss: 0.2756\n16/16 [==============================] - 0s 1ms/step - loss: 1.3616\n16/16 [==============================] - 0s 678us/step - loss: 1.6485\n16/16 [==============================] - 0s 946us/step - loss: 1.7539\n16/16 [==============================] - 0s 673us/step - loss: 1.7847\n16/16 [==============================] - 0s 656us/step - loss: 1.7921\n16/16 [==============================] - 0s 1ms/step - loss: 1.7895\n16/16 [==============================] - 0s 660us/step - loss: 1.7812\n16/16 [==============================] - 0s 1ms/step - loss: 1.7768\n16/16 [==============================] - 0s 730us/step - loss: 1.7745\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 660us/step - loss: 0.2723\n16/16 [==============================] - 0s 1ms/step - loss: 1.3959\n16/16 [==============================] - 0s 642us/step - loss: 1.7002\n16/16 [==============================] - 0s 874us/step - loss: 1.8105\n16/16 [==============================] - 0s 1ms/step - loss: 1.8423\n16/16 [==============================] - 0s 1ms/step - loss: 1.8494\n16/16 [==============================] - 0s 657us/step - loss: 1.8460\n16/16 [==============================] - 0s 940us/step - loss: 1.8371\n16/16 [==============================] - 0s 634us/step - loss: 1.8324\n16/16 [==============================] - 0s 905us/step - loss: 1.8299\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2702\n16/16 [==============================] - 0s 649us/step - loss: 1.3792\n16/16 [==============================] - 0s 867us/step - loss: 1.6818\n16/16 [==============================] - 0s 619us/step - loss: 1.7923\n16/16 [==============================] - 0s 859us/step - loss: 1.8248\n16/16 [==============================] - 0s 609us/step - loss: 1.8327\n16/16 [==============================] - 0s 1ms/step - loss: 1.8298\n16/16 [==============================] - 0s 584us/step - loss: 1.8209\n16/16 [==============================] - 0s 590us/step - loss: 1.8163\n16/16 [==============================] - 0s 602us/step - loss: 1.8139\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 683us/step - loss: 0.2694\n16/16 [==============================] - 0s 794us/step - loss: 1.3853\n16/16 [==============================] - 0s 1ms/step - loss: 1.6907\n16/16 [==============================] - 0s 1ms/step - loss: 1.8014\n16/16 [==============================] - 0s 634us/step - loss: 1.8329\n16/16 [==============================] - 0s 1ms/step - loss: 1.8400\n16/16 [==============================] - 0s 694us/step - loss: 1.8367\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 589us/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8204\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2679\n16/16 [==============================] - 0s 1ms/step - loss: 1.4280\n16/16 [==============================] - 0s 1ms/step - loss: 1.7530\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n16/16 [==============================] - 0s 1ms/step - loss: 1.9036\n16/16 [==============================] - 0s 643us/step - loss: 1.9107\n16/16 [==============================] - 0s 1ms/step - loss: 1.9074\n16/16 [==============================] - 0s 1ms/step - loss: 1.8981\n16/16 [==============================] - 0s 1ms/step - loss: 1.8933\n16/16 [==============================] - 0s 1ms/step - loss: 1.8908\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2673\n16/16 [==============================] - 0s 974us/step - loss: 1.4127\n16/16 [==============================] - 0s 820us/step - loss: 1.7343\n16/16 [==============================] - 0s 630us/step - loss: 1.8524\n16/16 [==============================] - 0s 606us/step - loss: 1.8844\n16/16 [==============================] - 0s 719us/step - loss: 1.8917\n16/16 [==============================] - 0s 1ms/step - loss: 1.8882\n16/16 [==============================] - 0s 611us/step - loss: 1.8784\n16/16 [==============================] - 0s 666us/step - loss: 1.8735\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2645\n16/16 [==============================] - 0s 1ms/step - loss: 1.4021\n16/16 [==============================] - 0s 594us/step - loss: 1.7169\n16/16 [==============================] - 0s 587us/step - loss: 1.8300\n16/16 [==============================] - 0s 613us/step - loss: 1.8582\n16/16 [==============================] - 0s 1ms/step - loss: 1.8634\n16/16 [==============================] - 0s 1ms/step - loss: 1.8590\n16/16 [==============================] - 0s 644us/step - loss: 1.8494\n16/16 [==============================] - 0s 622us/step - loss: 1.8445\n16/16 [==============================] - 0s 617us/step - loss: 1.8420\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2641\n16/16 [==============================] - 0s 1ms/step - loss: 1.4346\n16/16 [==============================] - 0s 1ms/step - loss: 1.7641\n16/16 [==============================] - 0s 860us/step - loss: 1.8848\n16/16 [==============================] - 0s 1ms/step - loss: 1.9154\n16/16 [==============================] - 0s 962us/step - loss: 1.9222\n16/16 [==============================] - 0s 634us/step - loss: 1.9176\n16/16 [==============================] - 0s 1ms/step - loss: 1.9075\n16/16 [==============================] - 0s 640us/step - loss: 1.9024\n16/16 [==============================] - 0s 1ms/step - loss: 1.8998\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 935us/step - loss: 0.2571\n16/16 [==============================] - 0s 600us/step - loss: 1.4423\n16/16 [==============================] - 0s 1ms/step - loss: 1.7744\n16/16 [==============================] - 0s 1ms/step - loss: 1.8942\n16/16 [==============================] - 0s 1ms/step - loss: 1.9222\n16/16 [==============================] - 0s 1ms/step - loss: 1.9268\n16/16 [==============================] - 0s 702us/step - loss: 1.9205\n16/16 [==============================] - 0s 637us/step - loss: 1.9092\n16/16 [==============================] - 0s 1ms/step - loss: 1.9038\n16/16 [==============================] - 0s 638us/step - loss: 1.9011\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2576\n16/16 [==============================] - 0s 1ms/step - loss: 1.4150\n16/16 [==============================] - 0s 586us/step - loss: 1.7381\n16/16 [==============================] - 0s 825us/step - loss: 1.8529\n16/16 [==============================] - 0s 848us/step - loss: 1.8794\n16/16 [==============================] - 0s 716us/step - loss: 1.8834\n16/16 [==============================] - 0s 1ms/step - loss: 1.8775\n16/16 [==============================] - 0s 598us/step - loss: 1.8670\n16/16 [==============================] - 0s 614us/step - loss: 1.8618\n16/16 [==============================] - 0s 1ms/step - loss: 1.8593\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 604us/step - loss: 0.2602\n16/16 [==============================] - 0s 1ms/step - loss: 1.4321\n16/16 [==============================] - 0s 1ms/step - loss: 1.7581\n16/16 [==============================] - 0s 1ms/step - loss: 1.8731\n16/16 [==============================] - 0s 636us/step - loss: 1.8998\n16/16 [==============================] - 0s 1ms/step - loss: 1.9035\n16/16 [==============================] - 0s 607us/step - loss: 1.8975\n16/16 [==============================] - 0s 1ms/step - loss: 1.8867\n16/16 [==============================] - 0s 646us/step - loss: 1.8815\n16/16 [==============================] - 0s 1ms/step - loss: 1.8790\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2559\n16/16 [==============================] - 0s 1ms/step - loss: 1.4384\n16/16 [==============================] - 0s 610us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.8808\n16/16 [==============================] - 0s 663us/step - loss: 1.9062\n16/16 [==============================] - 0s 844us/step - loss: 1.9082\n16/16 [==============================] - 0s 780us/step - loss: 1.9007\n16/16 [==============================] - 0s 602us/step - loss: 1.8887\n16/16 [==============================] - 0s 735us/step - loss: 1.8831\n16/16 [==============================] - 0s 1ms/step - loss: 1.8805\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 828us/step - loss: 0.2595\n16/16 [==============================] - 0s 1ms/step - loss: 1.4660\n16/16 [==============================] - 0s 1ms/step - loss: 1.8046\n16/16 [==============================] - 0s 1ms/step - loss: 1.9238\n16/16 [==============================] - 0s 613us/step - loss: 1.9510\n16/16 [==============================] - 0s 613us/step - loss: 1.9550\n16/16 [==============================] - 0s 607us/step - loss: 1.9486\n16/16 [==============================] - 0s 600us/step - loss: 1.9375\n16/16 [==============================] - 0s 1ms/step - loss: 1.9321\n16/16 [==============================] - 0s 1ms/step - loss: 1.9295\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 602us/step - loss: 0.2490\n16/16 [==============================] - 0s 783us/step - loss: 1.4405\n16/16 [==============================] - 0s 962us/step - loss: 1.7687\n16/16 [==============================] - 0s 1ms/step - loss: 1.8795\n16/16 [==============================] - 0s 1ms/step - loss: 1.9005\n16/16 [==============================] - 0s 1ms/step - loss: 1.8995\n16/16 [==============================] - 0s 1ms/step - loss: 1.8901\n16/16 [==============================] - 0s 1ms/step - loss: 1.8774\n16/16 [==============================] - 0s 1ms/step - loss: 1.8717\n16/16 [==============================] - 0s 1ms/step - loss: 1.8690\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 951us/step - loss: 0.2496\n16/16 [==============================] - 0s 610us/step - loss: 1.4539\n16/16 [==============================] - 0s 1ms/step - loss: 1.7891\n16/16 [==============================] - 0s 1ms/step - loss: 1.9046\n16/16 [==============================] - 0s 628us/step - loss: 1.9285\n16/16 [==============================] - 0s 645us/step - loss: 1.9295\n16/16 [==============================] - 0s 1ms/step - loss: 1.9219\n16/16 [==============================] - 0s 602us/step - loss: 1.9101\n16/16 [==============================] - 0s 1ms/step - loss: 1.9046\n16/16 [==============================] - 0s 888us/step - loss: 1.9020\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 647us/step - loss: 0.2496\n16/16 [==============================] - 0s 600us/step - loss: 1.4771\n16/16 [==============================] - 0s 677us/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.9419\n16/16 [==============================] - 0s 663us/step - loss: 1.9656\n16/16 [==============================] - 0s 1ms/step - loss: 1.9663\n16/16 [==============================] - 0s 1ms/step - loss: 1.9579\n16/16 [==============================] - 0s 629us/step - loss: 1.9450\n16/16 [==============================] - 0s 638us/step - loss: 1.9393\n16/16 [==============================] - 0s 1ms/step - loss: 1.9365\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 652us/step - loss: 0.2531\n16/16 [==============================] - 0s 591us/step - loss: 1.4810\n16/16 [==============================] - 0s 613us/step - loss: 1.8268\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 992us/step - loss: 1.9711\n16/16 [==============================] - 0s 1ms/step - loss: 1.9715\n16/16 [==============================] - 0s 595us/step - loss: 1.9633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9507\n16/16 [==============================] - 0s 638us/step - loss: 1.9451\n16/16 [==============================] - 0s 1ms/step - loss: 1.9424\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 642us/step - loss: 0.2477\n16/16 [==============================] - 0s 608us/step - loss: 1.4965\n16/16 [==============================] - 0s 1ms/step - loss: 1.8427\n16/16 [==============================] - 0s 1ms/step - loss: 1.9619\n16/16 [==============================] - 0s 707us/step - loss: 1.9847\n16/16 [==============================] - 0s 1ms/step - loss: 1.9844\n16/16 [==============================] - 0s 1ms/step - loss: 1.9761\n16/16 [==============================] - 0s 627us/step - loss: 1.9633\n16/16 [==============================] - 0s 604us/step - loss: 1.9575\n16/16 [==============================] - 0s 1ms/step - loss: 1.9548\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 666us/step - loss: 0.2442\n16/16 [==============================] - 0s 1ms/step - loss: 1.5123\n16/16 [==============================] - 0s 663us/step - loss: 1.8671\n16/16 [==============================] - 0s 868us/step - loss: 1.9886\n16/16 [==============================] - 0s 1ms/step - loss: 2.0106\n16/16 [==============================] - 0s 1ms/step - loss: 2.0090\n16/16 [==============================] - 0s 1ms/step - loss: 1.9998\n16/16 [==============================] - 0s 1ms/step - loss: 1.9861\n16/16 [==============================] - 0s 1ms/step - loss: 1.9801\n16/16 [==============================] - 0s 897us/step - loss: 1.9772\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2455\n16/16 [==============================] - 0s 641us/step - loss: 1.4842\n16/16 [==============================] - 0s 1ms/step - loss: 1.8252\n16/16 [==============================] - 0s 604us/step - loss: 1.9429\n16/16 [==============================] - 0s 853us/step - loss: 1.9640\n16/16 [==============================] - 0s 1ms/step - loss: 1.9625\n16/16 [==============================] - 0s 616us/step - loss: 1.9538\n16/16 [==============================] - 0s 861us/step - loss: 1.9412\n16/16 [==============================] - 0s 1ms/step - loss: 1.9356\n16/16 [==============================] - 0s 1ms/step - loss: 1.9330\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2433\n16/16 [==============================] - 0s 1ms/step - loss: 1.4858\n16/16 [==============================] - 0s 837us/step - loss: 1.8253\n16/16 [==============================] - 0s 1ms/step - loss: 1.9440\n16/16 [==============================] - 0s 1ms/step - loss: 1.9633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9608\n16/16 [==============================] - 0s 1ms/step - loss: 1.9512\n16/16 [==============================] - 0s 595us/step - loss: 1.9375\n16/16 [==============================] - 0s 623us/step - loss: 1.9316\n16/16 [==============================] - 0s 632us/step - loss: 1.9289\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 947us/step - loss: 0.2431\n16/16 [==============================] - 0s 727us/step - loss: 1.5060\n16/16 [==============================] - 0s 614us/step - loss: 1.8472\n16/16 [==============================] - 0s 619us/step - loss: 1.9665\n16/16 [==============================] - 0s 1ms/step - loss: 1.9845\n16/16 [==============================] - 0s 1ms/step - loss: 1.9803\n16/16 [==============================] - 0s 1ms/step - loss: 1.9697\n16/16 [==============================] - 0s 640us/step - loss: 1.9554\n16/16 [==============================] - 0s 1ms/step - loss: 1.9494\n16/16 [==============================] - 0s 1ms/step - loss: 1.9467\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2399\n16/16 [==============================] - 0s 1ms/step - loss: 1.4785\n16/16 [==============================] - 0s 1ms/step - loss: 1.8107\n16/16 [==============================] - 0s 571us/step - loss: 1.9298\n16/16 [==============================] - 0s 1ms/step - loss: 1.9481\n16/16 [==============================] - 0s 1ms/step - loss: 1.9445\n16/16 [==============================] - 0s 625us/step - loss: 1.9342\n16/16 [==============================] - 0s 631us/step - loss: 1.9201\n16/16 [==============================] - 0s 646us/step - loss: 1.9141\n16/16 [==============================] - 0s 626us/step - loss: 1.9114\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 880us/step - loss: 0.2394\n16/16 [==============================] - 0s 1ms/step - loss: 1.5075\n16/16 [==============================] - 0s 632us/step - loss: 1.8517\n16/16 [==============================] - 0s 687us/step - loss: 1.9741\n16/16 [==============================] - 0s 644us/step - loss: 1.9911\n16/16 [==============================] - 0s 671us/step - loss: 1.9874\n16/16 [==============================] - 0s 621us/step - loss: 1.9765\n16/16 [==============================] - 0s 604us/step - loss: 1.9621\n16/16 [==============================] - 0s 610us/step - loss: 1.9561\n16/16 [==============================] - 0s 1ms/step - loss: 1.9533\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 626us/step - loss: 0.2399\n16/16 [==============================] - 0s 1ms/step - loss: 1.5196\n16/16 [==============================] - 0s 1ms/step - loss: 1.8658\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 937us/step - loss: 2.0043\n16/16 [==============================] - 0s 1ms/step - loss: 2.0001\n16/16 [==============================] - 0s 755us/step - loss: 1.9881\n16/16 [==============================] - 0s 607us/step - loss: 1.9734\n16/16 [==============================] - 0s 1ms/step - loss: 1.9673\n16/16 [==============================] - 0s 675us/step - loss: 1.9644\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 584us/step - loss: 0.2383\n16/16 [==============================] - 0s 1ms/step - loss: 1.5491\n16/16 [==============================] - 0s 1ms/step - loss: 1.9024\n16/16 [==============================] - 0s 587us/step - loss: 2.0252\n16/16 [==============================] - 0s 793us/step - loss: 2.0399\n16/16 [==============================] - 0s 1ms/step - loss: 2.0364\n16/16 [==============================] - 0s 589us/step - loss: 2.0246\n16/16 [==============================] - 0s 625us/step - loss: 2.0102\n16/16 [==============================] - 0s 604us/step - loss: 2.0042\n16/16 [==============================] - 0s 600us/step - loss: 2.0014\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2373\n16/16 [==============================] - 0s 1ms/step - loss: 1.5548\n16/16 [==============================] - 0s 1ms/step - loss: 1.9083\n16/16 [==============================] - 0s 1ms/step - loss: 2.0331\n16/16 [==============================] - 0s 594us/step - loss: 2.0485\n16/16 [==============================] - 0s 609us/step - loss: 2.0460\n16/16 [==============================] - 0s 917us/step - loss: 2.0331\n16/16 [==============================] - 0s 1ms/step - loss: 2.0181\n16/16 [==============================] - 0s 1ms/step - loss: 2.0119\n16/16 [==============================] - 0s 1ms/step - loss: 2.0090\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2391\n16/16 [==============================] - 0s 713us/step - loss: 1.5529\n16/16 [==============================] - 0s 1ms/step - loss: 1.9056\n16/16 [==============================] - 0s 666us/step - loss: 2.0294\n16/16 [==============================] - 0s 1ms/step - loss: 2.0429\n16/16 [==============================] - 0s 1ms/step - loss: 2.0388\n16/16 [==============================] - 0s 1ms/step - loss: 2.0248\n16/16 [==============================] - 0s 1ms/step - loss: 2.0092\n16/16 [==============================] - 0s 1ms/step - loss: 2.0028\n16/16 [==============================] - 0s 1ms/step - loss: 1.9998\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 643us/step - loss: 0.2391\n16/16 [==============================] - 0s 1ms/step - loss: 1.5363\n16/16 [==============================] - 0s 896us/step - loss: 1.8850\n16/16 [==============================] - 0s 1ms/step - loss: 2.0052\n16/16 [==============================] - 0s 610us/step - loss: 2.0195\n16/16 [==============================] - 0s 1ms/step - loss: 2.0152\n16/16 [==============================] - 0s 1ms/step - loss: 2.0012\n16/16 [==============================] - 0s 1ms/step - loss: 1.9857\n16/16 [==============================] - 0s 619us/step - loss: 1.9794\n16/16 [==============================] - 0s 1ms/step - loss: 1.9765\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2338\n16/16 [==============================] - 0s 1ms/step - loss: 1.5579\n16/16 [==============================] - 0s 624us/step - loss: 1.9117\n16/16 [==============================] - 0s 1ms/step - loss: 2.0320\n16/16 [==============================] - 0s 612us/step - loss: 2.0450\n16/16 [==============================] - 0s 645us/step - loss: 2.0389\n16/16 [==============================] - 0s 721us/step - loss: 2.0244\n16/16 [==============================] - 0s 696us/step - loss: 2.0088\n16/16 [==============================] - 0s 608us/step - loss: 2.0024\n16/16 [==============================] - 0s 826us/step - loss: 1.9995\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 748us/step - loss: 0.2338\n16/16 [==============================] - 0s 1ms/step - loss: 1.5385\n16/16 [==============================] - 0s 1ms/step - loss: 1.8839\n16/16 [==============================] - 0s 670us/step - loss: 2.0016\n16/16 [==============================] - 0s 626us/step - loss: 2.0138\n16/16 [==============================] - 0s 625us/step - loss: 2.0076\n16/16 [==============================] - 0s 1ms/step - loss: 1.9939\n16/16 [==============================] - 0s 579us/step - loss: 1.9788\n16/16 [==============================] - 0s 898us/step - loss: 1.9727\n16/16 [==============================] - 0s 1ms/step - loss: 1.9699\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2316\n16/16 [==============================] - 0s 590us/step - loss: 1.5536\n16/16 [==============================] - 0s 627us/step - loss: 1.9020\n16/16 [==============================] - 0s 1ms/step - loss: 2.0198\n16/16 [==============================] - 0s 1ms/step - loss: 2.0311\n16/16 [==============================] - 0s 1ms/step - loss: 2.0229\n16/16 [==============================] - 0s 646us/step - loss: 2.0074\n16/16 [==============================] - 0s 606us/step - loss: 1.9907\n16/16 [==============================] - 0s 591us/step - loss: 1.9841\n16/16 [==============================] - 0s 1ms/step - loss: 1.9812\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 618us/step - loss: 0.2325\n16/16 [==============================] - 0s 1ms/step - loss: 1.5661\n16/16 [==============================] - 0s 654us/step - loss: 1.9179\n16/16 [==============================] - 0s 1ms/step - loss: 2.0361\n16/16 [==============================] - 0s 1ms/step - loss: 2.0486\n16/16 [==============================] - 0s 589us/step - loss: 2.0418\n16/16 [==============================] - 0s 676us/step - loss: 2.0272\n16/16 [==============================] - 0s 686us/step - loss: 2.0113\n16/16 [==============================] - 0s 664us/step - loss: 2.0049\n16/16 [==============================] - 0s 1ms/step - loss: 2.0020\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2280\n16/16 [==============================] - 0s 1ms/step - loss: 1.5553\n16/16 [==============================] - 0s 646us/step - loss: 1.9013\n16/16 [==============================] - 0s 1ms/step - loss: 2.0131\n16/16 [==============================] - 0s 929us/step - loss: 2.0218\n16/16 [==============================] - 0s 838us/step - loss: 2.0122\n16/16 [==============================] - 0s 882us/step - loss: 1.9958\n16/16 [==============================] - 0s 602us/step - loss: 1.9791\n16/16 [==============================] - 0s 608us/step - loss: 1.9725\n16/16 [==============================] - 0s 657us/step - loss: 1.9696\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2275\n16/16 [==============================] - 0s 767us/step - loss: 1.6042\n16/16 [==============================] - 0s 629us/step - loss: 1.9618\n16/16 [==============================] - 0s 1ms/step - loss: 2.0777\n16/16 [==============================] - 0s 1ms/step - loss: 2.0859\n16/16 [==============================] - 0s 645us/step - loss: 2.0750\n16/16 [==============================] - 0s 646us/step - loss: 2.0571\n16/16 [==============================] - 0s 900us/step - loss: 2.0390\n16/16 [==============================] - 0s 1ms/step - loss: 2.0319\n16/16 [==============================] - 0s 1ms/step - loss: 2.0288\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 600us/step - loss: 0.2278\n16/16 [==============================] - 0s 625us/step - loss: 1.6003\n16/16 [==============================] - 0s 627us/step - loss: 1.9580\n16/16 [==============================] - 0s 599us/step - loss: 2.0748\n16/16 [==============================] - 0s 608us/step - loss: 2.0844\n16/16 [==============================] - 0s 1ms/step - loss: 2.0744\n16/16 [==============================] - 0s 911us/step - loss: 2.0568\n16/16 [==============================] - 0s 1ms/step - loss: 2.0391\n16/16 [==============================] - 0s 1ms/step - loss: 2.0323\n16/16 [==============================] - 0s 632us/step - loss: 2.0293\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 606us/step - loss: 0.2275\n16/16 [==============================] - 0s 640us/step - loss: 1.5908\n16/16 [==============================] - 0s 787us/step - loss: 1.9416\n16/16 [==============================] - 0s 614us/step - loss: 2.0550\n16/16 [==============================] - 0s 655us/step - loss: 2.0633\n16/16 [==============================] - 0s 1ms/step - loss: 2.0544\n16/16 [==============================] - 0s 624us/step - loss: 2.0373\n16/16 [==============================] - 0s 590us/step - loss: 2.0202\n16/16 [==============================] - 0s 665us/step - loss: 2.0135\n16/16 [==============================] - 0s 1ms/step - loss: 2.0105\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 0.2262\n16/16 [==============================] - 0s 1ms/step - loss: 1.6456\n16/16 [==============================] - 0s 861us/step - loss: 2.0122\n16/16 [==============================] - 0s 1ms/step - loss: 2.1306\n16/16 [==============================] - 0s 1ms/step - loss: 2.1391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1297\n16/16 [==============================] - 0s 621us/step - loss: 2.1118\n16/16 [==============================] - 0s 608us/step - loss: 2.0941\n16/16 [==============================] - 0s 1ms/step - loss: 2.0872\n16/16 [==============================] - 0s 652us/step - loss: 2.0842\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 876us/step - loss: 0.2207\n16/16 [==============================] - 0s 656us/step - loss: 1.5952\n16/16 [==============================] - 0s 647us/step - loss: 1.9409\n16/16 [==============================] - 0s 611us/step - loss: 2.0496\n16/16 [==============================] - 0s 616us/step - loss: 2.0545\n16/16 [==============================] - 0s 1ms/step - loss: 2.0428\n16/16 [==============================] - 0s 599us/step - loss: 2.0236\n16/16 [==============================] - 0s 625us/step - loss: 2.0050\n16/16 [==============================] - 0s 897us/step - loss: 1.9980\n16/16 [==============================] - 0s 1ms/step - loss: 1.9949\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 595us/step - loss: 0.2217\n16/16 [==============================] - 0s 1ms/step - loss: 1.6089\n16/16 [==============================] - 0s 1ms/step - loss: 1.9546\n16/16 [==============================] - 0s 1ms/step - loss: 2.0641\n16/16 [==============================] - 0s 638us/step - loss: 2.0694\n16/16 [==============================] - 0s 636us/step - loss: 2.0580\n16/16 [==============================] - 0s 1ms/step - loss: 2.0394\n16/16 [==============================] - 0s 1ms/step - loss: 2.0217\n16/16 [==============================] - 0s 673us/step - loss: 2.0150\n16/16 [==============================] - 0s 1ms/step - loss: 2.0120\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2210\n16/16 [==============================] - 0s 828us/step - loss: 1.6202\n16/16 [==============================] - 0s 1ms/step - loss: 1.9660\n16/16 [==============================] - 0s 1ms/step - loss: 2.0750\n16/16 [==============================] - 0s 1ms/step - loss: 2.0805\n16/16 [==============================] - 0s 655us/step - loss: 2.0695\n16/16 [==============================] - 0s 1ms/step - loss: 2.0510\n16/16 [==============================] - 0s 1ms/step - loss: 2.0329\n16/16 [==============================] - 0s 681us/step - loss: 2.0260\n16/16 [==============================] - 0s 660us/step - loss: 2.0231\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2210\n16/16 [==============================] - 0s 1ms/step - loss: 1.6647\n16/16 [==============================] - 0s 1ms/step - loss: 2.0279\n16/16 [==============================] - 0s 1ms/step - loss: 2.1422\n16/16 [==============================] - 0s 638us/step - loss: 2.1469\n16/16 [==============================] - 0s 1ms/step - loss: 2.1338\n16/16 [==============================] - 0s 787us/step - loss: 2.1132\n16/16 [==============================] - 0s 1ms/step - loss: 2.0938\n16/16 [==============================] - 0s 1ms/step - loss: 2.0865\n16/16 [==============================] - 0s 1ms/step - loss: 2.0833\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 636us/step - loss: 0.2203\n16/16 [==============================] - 0s 640us/step - loss: 1.6660\n16/16 [==============================] - 0s 629us/step - loss: 2.0216\n16/16 [==============================] - 0s 1ms/step - loss: 2.1328\n16/16 [==============================] - 0s 607us/step - loss: 2.1365\n16/16 [==============================] - 0s 1ms/step - loss: 2.1239\n16/16 [==============================] - 0s 1ms/step - loss: 2.1042\n16/16 [==============================] - 0s 1ms/step - loss: 2.0851\n16/16 [==============================] - 0s 637us/step - loss: 2.0778\n16/16 [==============================] - 0s 1ms/step - loss: 2.0747\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 975us/step - loss: 0.2161\n16/16 [==============================] - 0s 1ms/step - loss: 1.6263\n16/16 [==============================] - 0s 1ms/step - loss: 1.9708\n16/16 [==============================] - 0s 601us/step - loss: 2.0786\n16/16 [==============================] - 0s 806us/step - loss: 2.0799\n16/16 [==============================] - 0s 787us/step - loss: 2.0658\n16/16 [==============================] - 0s 870us/step - loss: 2.0449\n16/16 [==============================] - 0s 1ms/step - loss: 2.0250\n16/16 [==============================] - 0s 1ms/step - loss: 2.0177\n16/16 [==============================] - 0s 826us/step - loss: 2.0146\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 611us/step - loss: 0.2170\n16/16 [==============================] - 0s 1ms/step - loss: 1.6675\n16/16 [==============================] - 0s 814us/step - loss: 2.0171\n16/16 [==============================] - 0s 610us/step - loss: 2.1244\n16/16 [==============================] - 0s 619us/step - loss: 2.1233\n16/16 [==============================] - 0s 1ms/step - loss: 2.1079\n16/16 [==============================] - 0s 856us/step - loss: 2.0871\n16/16 [==============================] - 0s 1ms/step - loss: 2.0677\n16/16 [==============================] - 0s 632us/step - loss: 2.0605\n16/16 [==============================] - 0s 602us/step - loss: 2.0574\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 636us/step - loss: 0.2144\n16/16 [==============================] - 0s 709us/step - loss: 1.6430\n16/16 [==============================] - 0s 667us/step - loss: 1.9817\n16/16 [==============================] - 0s 682us/step - loss: 2.0881\n16/16 [==============================] - 0s 1ms/step - loss: 2.0878\n16/16 [==============================] - 0s 1ms/step - loss: 2.0724\n16/16 [==============================] - 0s 629us/step - loss: 2.0513\n16/16 [==============================] - 0s 1ms/step - loss: 2.0314\n16/16 [==============================] - 0s 884us/step - loss: 2.0241\n16/16 [==============================] - 0s 585us/step - loss: 2.0210\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 726us/step - loss: 0.2157\n16/16 [==============================] - 0s 1ms/step - loss: 1.6566\n16/16 [==============================] - 0s 1ms/step - loss: 2.0048\n16/16 [==============================] - 0s 708us/step - loss: 2.1166\n16/16 [==============================] - 0s 1ms/step - loss: 2.1189\n16/16 [==============================] - 0s 1ms/step - loss: 2.1054\n16/16 [==============================] - 0s 684us/step - loss: 2.0858\n16/16 [==============================] - 0s 922us/step - loss: 2.0670\n16/16 [==============================] - 0s 1ms/step - loss: 2.0600\n16/16 [==============================] - 0s 602us/step - loss: 2.0569\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2162\n16/16 [==============================] - 0s 1ms/step - loss: 1.6785\n16/16 [==============================] - 0s 1ms/step - loss: 2.0249\n16/16 [==============================] - 0s 1ms/step - loss: 2.1348\n16/16 [==============================] - 0s 630us/step - loss: 2.1339\n16/16 [==============================] - 0s 1ms/step - loss: 2.1192\n16/16 [==============================] - 0s 604us/step - loss: 2.0985\n16/16 [==============================] - 0s 660us/step - loss: 2.0787\n16/16 [==============================] - 0s 741us/step - loss: 2.0714\n16/16 [==============================] - 0s 1ms/step - loss: 2.0683\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 636us/step - loss: 0.2121\n16/16 [==============================] - 0s 1ms/step - loss: 1.7297\n16/16 [==============================] - 0s 1ms/step - loss: 2.0914\n16/16 [==============================] - 0s 1ms/step - loss: 2.2077\n16/16 [==============================] - 0s 615us/step - loss: 2.2066\n16/16 [==============================] - 0s 615us/step - loss: 2.1895\n16/16 [==============================] - 0s 1ms/step - loss: 2.1665\n16/16 [==============================] - 0s 659us/step - loss: 2.1450\n16/16 [==============================] - 0s 1ms/step - loss: 2.1372\n16/16 [==============================] - 0s 911us/step - loss: 2.1339\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2120\n16/16 [==============================] - 0s 787us/step - loss: 1.7164\n16/16 [==============================] - 0s 644us/step - loss: 2.0674\n16/16 [==============================] - 0s 629us/step - loss: 2.1800\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 652us/step - loss: 2.1600\n16/16 [==============================] - 0s 620us/step - loss: 2.1373\n16/16 [==============================] - 0s 784us/step - loss: 2.1164\n16/16 [==============================] - 0s 644us/step - loss: 2.1088\n16/16 [==============================] - 0s 606us/step - loss: 2.1055\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 685us/step - loss: 0.2108\n16/16 [==============================] - 0s 789us/step - loss: 1.7226\n16/16 [==============================] - 0s 653us/step - loss: 2.0726\n16/16 [==============================] - 0s 1ms/step - loss: 2.1850\n16/16 [==============================] - 0s 737us/step - loss: 2.1834\n16/16 [==============================] - 0s 659us/step - loss: 2.1657\n16/16 [==============================] - 0s 633us/step - loss: 2.1428\n16/16 [==============================] - 0s 851us/step - loss: 2.1217\n16/16 [==============================] - 0s 636us/step - loss: 2.1141\n16/16 [==============================] - 0s 599us/step - loss: 2.1108\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2095\n16/16 [==============================] - 0s 894us/step - loss: 1.7267\n16/16 [==============================] - 0s 693us/step - loss: 2.0755\n16/16 [==============================] - 0s 1ms/step - loss: 2.1840\n16/16 [==============================] - 0s 1ms/step - loss: 2.1795\n16/16 [==============================] - 0s 932us/step - loss: 2.1586\n16/16 [==============================] - 0s 617us/step - loss: 2.1342\n16/16 [==============================] - 0s 1ms/step - loss: 2.1125\n16/16 [==============================] - 0s 672us/step - loss: 2.1046\n16/16 [==============================] - 0s 1ms/step - loss: 2.1013\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 629us/step - loss: 0.2097\n16/16 [==============================] - 0s 656us/step - loss: 1.7201\n16/16 [==============================] - 0s 725us/step - loss: 2.0713\n16/16 [==============================] - 0s 610us/step - loss: 2.1837\n16/16 [==============================] - 0s 857us/step - loss: 2.1826\n16/16 [==============================] - 0s 1ms/step - loss: 2.1660\n16/16 [==============================] - 0s 619us/step - loss: 2.1441\n16/16 [==============================] - 0s 1ms/step - loss: 2.1235\n16/16 [==============================] - 0s 759us/step - loss: 2.1159\n16/16 [==============================] - 0s 1ms/step - loss: 2.1127\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 617us/step - loss: 0.2078\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 633us/step - loss: 2.0834\n16/16 [==============================] - 0s 617us/step - loss: 2.1909\n16/16 [==============================] - 0s 661us/step - loss: 2.1858\n16/16 [==============================] - 0s 635us/step - loss: 2.1659\n16/16 [==============================] - 0s 675us/step - loss: 2.1419\n16/16 [==============================] - 0s 1ms/step - loss: 2.1201\n16/16 [==============================] - 0s 638us/step - loss: 2.1122\n16/16 [==============================] - 0s 924us/step - loss: 2.1089\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2075\n16/16 [==============================] - 0s 1ms/step - loss: 1.7201\n16/16 [==============================] - 0s 808us/step - loss: 2.0682\n16/16 [==============================] - 0s 1ms/step - loss: 2.1789\n16/16 [==============================] - 0s 1ms/step - loss: 2.1772\n16/16 [==============================] - 0s 832us/step - loss: 2.1596\n16/16 [==============================] - 0s 1ms/step - loss: 2.1366\n16/16 [==============================] - 0s 631us/step - loss: 2.1155\n16/16 [==============================] - 0s 1ms/step - loss: 2.1079\n16/16 [==============================] - 0s 717us/step - loss: 2.1048\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2033\n16/16 [==============================] - 0s 880us/step - loss: 1.7117\n16/16 [==============================] - 0s 689us/step - loss: 2.0529\n16/16 [==============================] - 0s 646us/step - loss: 2.1588\n16/16 [==============================] - 0s 629us/step - loss: 2.1535\n16/16 [==============================] - 0s 977us/step - loss: 2.1332\n16/16 [==============================] - 0s 564us/step - loss: 2.1092\n16/16 [==============================] - 0s 647us/step - loss: 2.0876\n16/16 [==============================] - 0s 1ms/step - loss: 2.0798\n16/16 [==============================] - 0s 591us/step - loss: 2.0766\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 990us/step - loss: 0.2022\n16/16 [==============================] - 0s 1ms/step - loss: 1.7204\n16/16 [==============================] - 0s 612us/step - loss: 2.0604\n16/16 [==============================] - 0s 631us/step - loss: 2.1673\n16/16 [==============================] - 0s 1ms/step - loss: 2.1620\n16/16 [==============================] - 0s 629us/step - loss: 2.1416\n16/16 [==============================] - 0s 929us/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n16/16 [==============================] - 0s 1ms/step - loss: 2.0879\n16/16 [==============================] - 0s 617us/step - loss: 2.0846\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2030\n16/16 [==============================] - 0s 1ms/step - loss: 1.7209\n16/16 [==============================] - 0s 605us/step - loss: 2.0625\n16/16 [==============================] - 0s 1ms/step - loss: 2.1710\n16/16 [==============================] - 0s 700us/step - loss: 2.1667\n16/16 [==============================] - 0s 1ms/step - loss: 2.1474\n16/16 [==============================] - 0s 902us/step - loss: 2.1242\n16/16 [==============================] - 0s 667us/step - loss: 2.1033\n16/16 [==============================] - 0s 1ms/step - loss: 2.0957\n16/16 [==============================] - 0s 1ms/step - loss: 2.0925\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 621us/step - loss: 0.2029\n16/16 [==============================] - 0s 610us/step - loss: 1.7547\n16/16 [==============================] - 0s 611us/step - loss: 2.1118\n16/16 [==============================] - 0s 597us/step - loss: 2.2254\n16/16 [==============================] - 0s 576us/step - loss: 2.2233\n16/16 [==============================] - 0s 580us/step - loss: 2.2050\n16/16 [==============================] - 0s 612us/step - loss: 2.1821\n16/16 [==============================] - 0s 605us/step - loss: 2.1610\n16/16 [==============================] - 0s 807us/step - loss: 2.1534\n16/16 [==============================] - 0s 1ms/step - loss: 2.1502\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1969\n16/16 [==============================] - 0s 955us/step - loss: 1.7401\n16/16 [==============================] - 0s 642us/step - loss: 2.0891\n16/16 [==============================] - 0s 691us/step - loss: 2.1926\n16/16 [==============================] - 0s 1ms/step - loss: 2.1827\n16/16 [==============================] - 0s 706us/step - loss: 2.1592\n16/16 [==============================] - 0s 1ms/step - loss: 2.1331\n16/16 [==============================] - 0s 835us/step - loss: 2.1100\n16/16 [==============================] - 0s 1ms/step - loss: 2.1018\n16/16 [==============================] - 0s 1ms/step - loss: 2.0983\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 659us/step - loss: 0.1983\n16/16 [==============================] - 0s 664us/step - loss: 1.7511\n16/16 [==============================] - 0s 1ms/step - loss: 2.1021\n16/16 [==============================] - 0s 632us/step - loss: 2.2065\n16/16 [==============================] - 0s 1ms/step - loss: 2.1983\n16/16 [==============================] - 0s 1ms/step - loss: 2.1764\n16/16 [==============================] - 0s 1ms/step - loss: 2.1510\n16/16 [==============================] - 0s 639us/step - loss: 2.1285\n16/16 [==============================] - 0s 641us/step - loss: 2.1205\n16/16 [==============================] - 0s 1ms/step - loss: 2.1171\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 774us/step - loss: 0.1992\n16/16 [==============================] - 0s 643us/step - loss: 1.7271\n16/16 [==============================] - 0s 1ms/step - loss: 2.0661\n16/16 [==============================] - 0s 1ms/step - loss: 2.1656\n16/16 [==============================] - 0s 1ms/step - loss: 2.1575\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 620us/step - loss: 2.1083\n16/16 [==============================] - 0s 675us/step - loss: 2.0856\n16/16 [==============================] - 0s 1ms/step - loss: 2.0776\n16/16 [==============================] - 0s 641us/step - loss: 2.0743\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1973\n16/16 [==============================] - 0s 634us/step - loss: 1.7673\n16/16 [==============================] - 0s 641us/step - loss: 2.1133\n16/16 [==============================] - 0s 807us/step - loss: 2.2143\n16/16 [==============================] - 0s 1ms/step - loss: 2.2060\n16/16 [==============================] - 0s 680us/step - loss: 2.1823\n16/16 [==============================] - 0s 915us/step - loss: 2.1568\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 637us/step - loss: 2.1262\n16/16 [==============================] - 0s 1ms/step - loss: 2.1229\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1957\n16/16 [==============================] - 0s 1ms/step - loss: 1.7630\n16/16 [==============================] - 0s 1ms/step - loss: 2.1149\n16/16 [==============================] - 0s 1ms/step - loss: 2.2172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2101\n16/16 [==============================] - 0s 785us/step - loss: 2.1867\n16/16 [==============================] - 0s 767us/step - loss: 2.1611\n16/16 [==============================] - 0s 1ms/step - loss: 2.1384\n16/16 [==============================] - 0s 1ms/step - loss: 2.1303\n16/16 [==============================] - 0s 835us/step - loss: 2.1270\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 659us/step - loss: 0.1958\n16/16 [==============================] - 0s 636us/step - loss: 1.7773\n16/16 [==============================] - 0s 580us/step - loss: 2.1316\n16/16 [==============================] - 0s 632us/step - loss: 2.2359\n16/16 [==============================] - 0s 699us/step - loss: 2.2285\n16/16 [==============================] - 0s 642us/step - loss: 2.2029\n16/16 [==============================] - 0s 953us/step - loss: 2.1759\n16/16 [==============================] - 0s 1ms/step - loss: 2.1522\n16/16 [==============================] - 0s 1ms/step - loss: 2.1437\n16/16 [==============================] - 0s 843us/step - loss: 2.1402\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1914\n16/16 [==============================] - 0s 908us/step - loss: 1.7573\n16/16 [==============================] - 0s 718us/step - loss: 2.1000\n16/16 [==============================] - 0s 1ms/step - loss: 2.1991\n16/16 [==============================] - 0s 626us/step - loss: 2.1890\n16/16 [==============================] - 0s 746us/step - loss: 2.1621\n16/16 [==============================] - 0s 649us/step - loss: 2.1343\n16/16 [==============================] - 0s 653us/step - loss: 2.1108\n16/16 [==============================] - 0s 1ms/step - loss: 2.1026\n16/16 [==============================] - 0s 1ms/step - loss: 2.0992\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 615us/step - loss: 0.1948\n16/16 [==============================] - 0s 637us/step - loss: 1.8010\n16/16 [==============================] - 0s 1ms/step - loss: 2.1603\n16/16 [==============================] - 0s 628us/step - loss: 2.2660\n16/16 [==============================] - 0s 1ms/step - loss: 2.2587\n16/16 [==============================] - 0s 706us/step - loss: 2.2337\n16/16 [==============================] - 0s 637us/step - loss: 2.2068\n16/16 [==============================] - 0s 631us/step - loss: 2.1834\n16/16 [==============================] - 0s 1ms/step - loss: 2.1750\n16/16 [==============================] - 0s 1ms/step - loss: 2.1716\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1911\n16/16 [==============================] - 0s 641us/step - loss: 1.7696\n16/16 [==============================] - 0s 841us/step - loss: 2.1178\n16/16 [==============================] - 0s 778us/step - loss: 2.2186\n16/16 [==============================] - 0s 1ms/step - loss: 2.2089\n16/16 [==============================] - 0s 1ms/step - loss: 2.1826\n16/16 [==============================] - 0s 1ms/step - loss: 2.1555\n16/16 [==============================] - 0s 1ms/step - loss: 2.1326\n16/16 [==============================] - 0s 1ms/step - loss: 2.1245\n16/16 [==============================] - 0s 1ms/step - loss: 2.1212\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 728us/step - loss: 0.1921\n16/16 [==============================] - 0s 635us/step - loss: 1.8098\n16/16 [==============================] - 0s 1ms/step - loss: 2.1669\n16/16 [==============================] - 0s 661us/step - loss: 2.2703\n16/16 [==============================] - 0s 1ms/step - loss: 2.2623\n16/16 [==============================] - 0s 664us/step - loss: 2.2363\n16/16 [==============================] - 0s 650us/step - loss: 2.2087\n16/16 [==============================] - 0s 648us/step - loss: 2.1849\n16/16 [==============================] - 0s 642us/step - loss: 2.1766\n16/16 [==============================] - 0s 662us/step - loss: 2.1732\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1943\n16/16 [==============================] - 0s 873us/step - loss: 1.7990\n16/16 [==============================] - 0s 1ms/step - loss: 2.1590\n16/16 [==============================] - 0s 1ms/step - loss: 2.2620\n16/16 [==============================] - 0s 1ms/step - loss: 2.2528\n16/16 [==============================] - 0s 600us/step - loss: 2.2259\n16/16 [==============================] - 0s 584us/step - loss: 2.1981\n16/16 [==============================] - 0s 1ms/step - loss: 2.1742\n16/16 [==============================] - 0s 1ms/step - loss: 2.1658\n16/16 [==============================] - 0s 1ms/step - loss: 2.1623\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1929\n16/16 [==============================] - 0s 1ms/step - loss: 1.7656\n16/16 [==============================] - 0s 784us/step - loss: 2.1149\n16/16 [==============================] - 0s 619us/step - loss: 2.2138\n16/16 [==============================] - 0s 587us/step - loss: 2.2056\n16/16 [==============================] - 0s 590us/step - loss: 2.1795\n16/16 [==============================] - 0s 567us/step - loss: 2.1526\n16/16 [==============================] - 0s 616us/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.1219\n16/16 [==============================] - 0s 594us/step - loss: 2.1186\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 761us/step - loss: 0.1915\n16/16 [==============================] - 0s 1ms/step - loss: 1.7777\n16/16 [==============================] - 0s 1ms/step - loss: 2.1276\n16/16 [==============================] - 0s 1ms/step - loss: 2.2233\n16/16 [==============================] - 0s 1ms/step - loss: 2.2119\n16/16 [==============================] - 0s 1ms/step - loss: 2.1831\n16/16 [==============================] - 0s 1ms/step - loss: 2.1549\n16/16 [==============================] - 0s 1ms/step - loss: 2.1315\n16/16 [==============================] - 0s 1ms/step - loss: 2.1235\n16/16 [==============================] - 0s 1ms/step - loss: 2.1202\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1890\n16/16 [==============================] - 0s 947us/step - loss: 1.7926\n16/16 [==============================] - 0s 1ms/step - loss: 2.1436\n16/16 [==============================] - 0s 1ms/step - loss: 2.2395\n16/16 [==============================] - 0s 625us/step - loss: 2.2279\n16/16 [==============================] - 0s 1ms/step - loss: 2.1978\n16/16 [==============================] - 0s 1ms/step - loss: 2.1692\n16/16 [==============================] - 0s 1ms/step - loss: 2.1451\n16/16 [==============================] - 0s 1ms/step - loss: 2.1368\n16/16 [==============================] - 0s 1ms/step - loss: 2.1334\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1867\n16/16 [==============================] - 0s 1ms/step - loss: 1.8739\n16/16 [==============================] - 0s 1ms/step - loss: 2.2491\n16/16 [==============================] - 0s 992us/step - loss: 2.3538\n16/16 [==============================] - 0s 1ms/step - loss: 2.3422\n16/16 [==============================] - 0s 870us/step - loss: 2.3119\n16/16 [==============================] - 0s 1ms/step - loss: 2.2828\n16/16 [==============================] - 0s 627us/step - loss: 2.2576\n16/16 [==============================] - 0s 615us/step - loss: 2.2488\n16/16 [==============================] - 0s 748us/step - loss: 2.2452\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1852\n16/16 [==============================] - 0s 725us/step - loss: 1.8347\n16/16 [==============================] - 0s 646us/step - loss: 2.1942\n16/16 [==============================] - 0s 856us/step - loss: 2.2953\n16/16 [==============================] - 0s 661us/step - loss: 2.2842\n16/16 [==============================] - 0s 604us/step - loss: 2.2557\n16/16 [==============================] - 0s 602us/step - loss: 2.2280\n16/16 [==============================] - 0s 908us/step - loss: 2.2039\n16/16 [==============================] - 0s 1ms/step - loss: 2.1955\n16/16 [==============================] - 0s 1ms/step - loss: 2.1921\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 896us/step - loss: 0.1867\n16/16 [==============================] - 0s 668us/step - loss: 1.7861\n16/16 [==============================] - 0s 1ms/step - loss: 2.1329\n16/16 [==============================] - 0s 777us/step - loss: 2.2272\n16/16 [==============================] - 0s 1ms/step - loss: 2.2136\n16/16 [==============================] - 0s 736us/step - loss: 2.1838\n16/16 [==============================] - 0s 606us/step - loss: 2.1556\n16/16 [==============================] - 0s 1ms/step - loss: 2.1315\n16/16 [==============================] - 0s 1ms/step - loss: 2.1232\n16/16 [==============================] - 0s 626us/step - loss: 2.1198\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 579us/step - loss: 0.1835\n16/16 [==============================] - 0s 1ms/step - loss: 1.8104\n16/16 [==============================] - 0s 1ms/step - loss: 2.1585\n16/16 [==============================] - 0s 634us/step - loss: 2.2523\n16/16 [==============================] - 0s 702us/step - loss: 2.2377\n16/16 [==============================] - 0s 635us/step - loss: 2.2062\n16/16 [==============================] - 0s 604us/step - loss: 2.1763\n16/16 [==============================] - 0s 1ms/step - loss: 2.1511\n16/16 [==============================] - 0s 1ms/step - loss: 2.1427\n16/16 [==============================] - 0s 625us/step - loss: 2.1392\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 613us/step - loss: 0.1853\n16/16 [==============================] - 0s 700us/step - loss: 1.8215\n16/16 [==============================] - 0s 1ms/step - loss: 2.1727\n16/16 [==============================] - 0s 723us/step - loss: 2.2672\n16/16 [==============================] - 0s 714us/step - loss: 2.2522\n16/16 [==============================] - 0s 621us/step - loss: 2.2214\n16/16 [==============================] - 0s 669us/step - loss: 2.1932\n16/16 [==============================] - 0s 607us/step - loss: 2.1690\n16/16 [==============================] - 0s 700us/step - loss: 2.1607\n16/16 [==============================] - 0s 651us/step - loss: 2.1573\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 628us/step - loss: 0.1840\n16/16 [==============================] - 0s 600us/step - loss: 1.8633\n16/16 [==============================] - 0s 622us/step - loss: 2.2307\n16/16 [==============================] - 0s 620us/step - loss: 2.3265\n16/16 [==============================] - 0s 622us/step - loss: 2.3089\n16/16 [==============================] - 0s 652us/step - loss: 2.2739\n16/16 [==============================] - 0s 1ms/step - loss: 2.2421\n16/16 [==============================] - 0s 968us/step - loss: 2.2152\n16/16 [==============================] - 0s 1ms/step - loss: 2.2061\n16/16 [==============================] - 0s 851us/step - loss: 2.2024\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 639us/step - loss: 0.1830\n16/16 [==============================] - 0s 1ms/step - loss: 1.8733\n16/16 [==============================] - 0s 621us/step - loss: 2.2434\n16/16 [==============================] - 0s 966us/step - loss: 2.3381\n16/16 [==============================] - 0s 1ms/step - loss: 2.3205\n16/16 [==============================] - 0s 1ms/step - loss: 2.2861\n16/16 [==============================] - 0s 1ms/step - loss: 2.2544\n16/16 [==============================] - 0s 1ms/step - loss: 2.2276\n16/16 [==============================] - 0s 936us/step - loss: 2.2186\n16/16 [==============================] - 0s 617us/step - loss: 2.2149\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1816\n16/16 [==============================] - 0s 618us/step - loss: 1.8904\n16/16 [==============================] - 0s 1ms/step - loss: 2.2667\n16/16 [==============================] - 0s 707us/step - loss: 2.3649\n16/16 [==============================] - 0s 1ms/step - loss: 2.3499\n16/16 [==============================] - 0s 1ms/step - loss: 2.3184\n16/16 [==============================] - 0s 1ms/step - loss: 2.2894\n16/16 [==============================] - 0s 1ms/step - loss: 2.2641\n16/16 [==============================] - 0s 1ms/step - loss: 2.2555\n16/16 [==============================] - 0s 632us/step - loss: 2.2520\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 607us/step - loss: 0.1833\n16/16 [==============================] - 0s 641us/step - loss: 1.8758\n16/16 [==============================] - 0s 1ms/step - loss: 2.2495\n16/16 [==============================] - 0s 617us/step - loss: 2.3460\n16/16 [==============================] - 0s 639us/step - loss: 2.3310\n16/16 [==============================] - 0s 930us/step - loss: 2.2983\n16/16 [==============================] - 0s 622us/step - loss: 2.2679\n16/16 [==============================] - 0s 1ms/step - loss: 2.2418\n16/16 [==============================] - 0s 624us/step - loss: 2.2328\n16/16 [==============================] - 0s 1ms/step - loss: 2.2291\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 969us/step - loss: 0.1794\n16/16 [==============================] - 0s 1ms/step - loss: 1.9049\n16/16 [==============================] - 0s 1ms/step - loss: 2.2851\n16/16 [==============================] - 0s 615us/step - loss: 2.3832\n16/16 [==============================] - 0s 712us/step - loss: 2.3669\n16/16 [==============================] - 0s 616us/step - loss: 2.3326\n16/16 [==============================] - 0s 1ms/step - loss: 2.3017\n16/16 [==============================] - 0s 630us/step - loss: 2.2754\n16/16 [==============================] - 0s 837us/step - loss: 2.2665\n16/16 [==============================] - 0s 1ms/step - loss: 2.2628\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 632us/step - loss: 0.1800\n16/16 [==============================] - 0s 626us/step - loss: 1.8637\n16/16 [==============================] - 0s 904us/step - loss: 2.2352\n16/16 [==============================] - 0s 1ms/step - loss: 2.3308\n16/16 [==============================] - 0s 1ms/step - loss: 2.3141\n16/16 [==============================] - 0s 1ms/step - loss: 2.2801\n16/16 [==============================] - 0s 1ms/step - loss: 2.2488\n16/16 [==============================] - 0s 1ms/step - loss: 2.2227\n16/16 [==============================] - 0s 919us/step - loss: 2.2139\n16/16 [==============================] - 0s 966us/step - loss: 2.2103\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1775\n16/16 [==============================] - 0s 644us/step - loss: 1.9059\n16/16 [==============================] - 0s 669us/step - loss: 2.2860\n16/16 [==============================] - 0s 1ms/step - loss: 2.3835\n16/16 [==============================] - 0s 664us/step - loss: 2.3656\n16/16 [==============================] - 0s 1ms/step - loss: 2.3309\n16/16 [==============================] - 0s 689us/step - loss: 2.2992\n16/16 [==============================] - 0s 1ms/step - loss: 2.2725\n16/16 [==============================] - 0s 1ms/step - loss: 2.2635\n16/16 [==============================] - 0s 1ms/step - loss: 2.2598\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1770\n16/16 [==============================] - 0s 882us/step - loss: 1.8485\n16/16 [==============================] - 0s 1ms/step - loss: 2.2087\n16/16 [==============================] - 0s 843us/step - loss: 2.3001\n16/16 [==============================] - 0s 1ms/step - loss: 2.2820\n16/16 [==============================] - 0s 1ms/step - loss: 2.2470\n16/16 [==============================] - 0s 808us/step - loss: 2.2158\n16/16 [==============================] - 0s 674us/step - loss: 2.1898\n16/16 [==============================] - 0s 665us/step - loss: 2.1810\n16/16 [==============================] - 0s 666us/step - loss: 2.1774\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 702us/step - loss: 0.1778\n16/16 [==============================] - 0s 1ms/step - loss: 1.8604\n16/16 [==============================] - 0s 1ms/step - loss: 2.2199\n16/16 [==============================] - 0s 1ms/step - loss: 2.3081\n16/16 [==============================] - 0s 1ms/step - loss: 2.2886\n16/16 [==============================] - 0s 1ms/step - loss: 2.2537\n16/16 [==============================] - 0s 899us/step - loss: 2.2230\n16/16 [==============================] - 0s 847us/step - loss: 2.1975\n16/16 [==============================] - 0s 674us/step - loss: 2.1890\n16/16 [==============================] - 0s 648us/step - loss: 2.1856\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1772\n16/16 [==============================] - 0s 1ms/step - loss: 1.9029\n16/16 [==============================] - 0s 1ms/step - loss: 2.2795\n16/16 [==============================] - 0s 929us/step - loss: 2.3721\n16/16 [==============================] - 0s 656us/step - loss: 2.3526\n16/16 [==============================] - 0s 685us/step - loss: 2.3171\n16/16 [==============================] - 0s 697us/step - loss: 2.2856\n16/16 [==============================] - 0s 686us/step - loss: 2.2594\n16/16 [==============================] - 0s 1ms/step - loss: 2.2505\n16/16 [==============================] - 0s 938us/step - loss: 2.2469\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 736us/step - loss: 0.1773\n16/16 [==============================] - 0s 1ms/step - loss: 1.8690\n16/16 [==============================] - 0s 1ms/step - loss: 2.2337\n16/16 [==============================] - 0s 997us/step - loss: 2.3199\n16/16 [==============================] - 0s 1ms/step - loss: 2.2990\n16/16 [==============================] - 0s 965us/step - loss: 2.2626\n16/16 [==============================] - 0s 1ms/step - loss: 2.2305\n16/16 [==============================] - 0s 681us/step - loss: 2.2046\n16/16 [==============================] - 0s 701us/step - loss: 2.1959\n16/16 [==============================] - 0s 684us/step - loss: 2.1924\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 857us/step - loss: 0.1749\n16/16 [==============================] - 0s 647us/step - loss: 1.8422\n16/16 [==============================] - 0s 695us/step - loss: 2.2055\n16/16 [==============================] - 0s 1ms/step - loss: 2.2933\n16/16 [==============================] - 0s 858us/step - loss: 2.2752\n16/16 [==============================] - 0s 1ms/step - loss: 2.2414\n16/16 [==============================] - 0s 1ms/step - loss: 2.2106\n16/16 [==============================] - 0s 702us/step - loss: 2.1853\n16/16 [==============================] - 0s 1ms/step - loss: 2.1768\n16/16 [==============================] - 0s 653us/step - loss: 2.1733\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1735\n16/16 [==============================] - 0s 2ms/step - loss: 1.8843\n16/16 [==============================] - 0s 2ms/step - loss: 2.2440\n16/16 [==============================] - 0s 2ms/step - loss: 2.3291\n16/16 [==============================] - 0s 2ms/step - loss: 2.3069\n16/16 [==============================] - 0s 2ms/step - loss: 2.2710\n16/16 [==============================] - 0s 2ms/step - loss: 2.2398\n16/16 [==============================] - 0s 2ms/step - loss: 2.2144\n16/16 [==============================] - 0s 2ms/step - loss: 2.2058\n16/16 [==============================] - 0s 1ms/step - loss: 2.2023\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 776us/step - loss: 0.1737\n16/16 [==============================] - 0s 2ms/step - loss: 1.8765\n16/16 [==============================] - 0s 2ms/step - loss: 2.2332\n16/16 [==============================] - 0s 2ms/step - loss: 2.3172\n16/16 [==============================] - 0s 2ms/step - loss: 2.2945\n16/16 [==============================] - 0s 2ms/step - loss: 2.2569\n16/16 [==============================] - 0s 3ms/step - loss: 2.2234\n16/16 [==============================] - 0s 2ms/step - loss: 2.1967\n16/16 [==============================] - 0s 2ms/step - loss: 2.1880\n16/16 [==============================] - 0s 2ms/step - loss: 2.1844\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1761\n16/16 [==============================] - 0s 716us/step - loss: 1.8934\n16/16 [==============================] - 0s 703us/step - loss: 2.2560\n16/16 [==============================] - 0s 675us/step - loss: 2.3469\n16/16 [==============================] - 0s 683us/step - loss: 2.3263\n16/16 [==============================] - 0s 735us/step - loss: 2.2914\n16/16 [==============================] - 0s 2ms/step - loss: 2.2595\n16/16 [==============================] - 0s 2ms/step - loss: 2.2333\n16/16 [==============================] - 0s 2ms/step - loss: 2.2245\n16/16 [==============================] - 0s 1ms/step - loss: 2.2209\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1722\n16/16 [==============================] - 0s 2ms/step - loss: 1.9280\n16/16 [==============================] - 0s 1ms/step - loss: 2.2976\n16/16 [==============================] - 0s 1ms/step - loss: 2.3871\n16/16 [==============================] - 0s 1ms/step - loss: 2.3629\n16/16 [==============================] - 0s 1ms/step - loss: 2.3248\n16/16 [==============================] - 0s 2ms/step - loss: 2.2908\n16/16 [==============================] - 0s 1ms/step - loss: 2.2634\n16/16 [==============================] - 0s 2ms/step - loss: 2.2542\n16/16 [==============================] - 0s 2ms/step - loss: 2.2505\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 665us/step - loss: 0.1699\n16/16 [==============================] - 0s 649us/step - loss: 1.9410\n16/16 [==============================] - 0s 642us/step - loss: 2.3137\n16/16 [==============================] - 0s 647us/step - loss: 2.4031\n16/16 [==============================] - 0s 634us/step - loss: 2.3771\n16/16 [==============================] - 0s 655us/step - loss: 2.3376\n16/16 [==============================] - 0s 2ms/step - loss: 2.3020\n16/16 [==============================] - 0s 1ms/step - loss: 2.2737\n16/16 [==============================] - 0s 670us/step - loss: 2.2643\n16/16 [==============================] - 0s 643us/step - loss: 2.2604\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 0.1723\n16/16 [==============================] - 0s 2ms/step - loss: 1.8916\n16/16 [==============================] - 0s 807us/step - loss: 2.2597\n16/16 [==============================] - 0s 933us/step - loss: 2.3476\n16/16 [==============================] - 0s 933us/step - loss: 2.3238\n16/16 [==============================] - 0s 923us/step - loss: 2.2886\n16/16 [==============================] - 0s 952us/step - loss: 2.2566\n16/16 [==============================] - 0s 1ms/step - loss: 2.2308\n16/16 [==============================] - 0s 995us/step - loss: 2.2222\n16/16 [==============================] - 0s 911us/step - loss: 2.2188\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1698\n16/16 [==============================] - 0s 2ms/step - loss: 1.9182\n16/16 [==============================] - 0s 1ms/step - loss: 2.2868\n16/16 [==============================] - 0s 755us/step - loss: 2.3684\n16/16 [==============================] - 0s 652us/step - loss: 2.3398\n16/16 [==============================] - 0s 650us/step - loss: 2.3013\n16/16 [==============================] - 0s 648us/step - loss: 2.2666\n16/16 [==============================] - 0s 660us/step - loss: 2.2391\n16/16 [==============================] - 0s 1ms/step - loss: 2.2300\n16/16 [==============================] - 0s 2ms/step - loss: 2.2264\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1686\n16/16 [==============================] - 0s 648us/step - loss: 1.9577\n16/16 [==============================] - 0s 887us/step - loss: 2.3428\n16/16 [==============================] - 0s 1ms/step - loss: 2.4313\n16/16 [==============================] - 0s 645us/step - loss: 2.4052\n16/16 [==============================] - 0s 1ms/step - loss: 2.3674\n16/16 [==============================] - 0s 2ms/step - loss: 2.3327\n16/16 [==============================] - 0s 653us/step - loss: 2.3051\n16/16 [==============================] - 0s 2ms/step - loss: 2.2958\n16/16 [==============================] - 0s 2ms/step - loss: 2.2921\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1707\n16/16 [==============================] - 0s 1ms/step - loss: 1.9381\n16/16 [==============================] - 0s 626us/step - loss: 2.3141\n16/16 [==============================] - 0s 2ms/step - loss: 2.3976\n16/16 [==============================] - 0s 1ms/step - loss: 2.3711\n16/16 [==============================] - 0s 2ms/step - loss: 2.3333\n16/16 [==============================] - 0s 2ms/step - loss: 2.2988\n16/16 [==============================] - 0s 2ms/step - loss: 2.2715\n16/16 [==============================] - 0s 1ms/step - loss: 2.2624\n16/16 [==============================] - 0s 2ms/step - loss: 2.2588\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1687\n16/16 [==============================] - 0s 2ms/step - loss: 1.9747\n16/16 [==============================] - 0s 2ms/step - loss: 2.3635\n16/16 [==============================] - 0s 2ms/step - loss: 2.4468\n16/16 [==============================] - 0s 2ms/step - loss: 2.4175\n16/16 [==============================] - 0s 2ms/step - loss: 2.3761\n16/16 [==============================] - 0s 1ms/step - loss: 2.3383\n16/16 [==============================] - 0s 2ms/step - loss: 2.3088\n16/16 [==============================] - 0s 1ms/step - loss: 2.2990\n16/16 [==============================] - 0s 2ms/step - loss: 2.2950\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1671\n16/16 [==============================] - 0s 1ms/step - loss: 1.9391\n16/16 [==============================] - 0s 2ms/step - loss: 2.3156\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n16/16 [==============================] - 0s 2ms/step - loss: 2.3719\n16/16 [==============================] - 0s 2ms/step - loss: 2.3335\n16/16 [==============================] - 0s 2ms/step - loss: 2.2984\n16/16 [==============================] - 0s 2ms/step - loss: 2.2707\n16/16 [==============================] - 0s 2ms/step - loss: 2.2614\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1662\n16/16 [==============================] - 0s 1ms/step - loss: 1.9564\n16/16 [==============================] - 0s 1ms/step - loss: 2.3366\n16/16 [==============================] - 0s 2ms/step - loss: 2.4170\n16/16 [==============================] - 0s 2ms/step - loss: 2.3906\n16/16 [==============================] - 0s 2ms/step - loss: 2.3517\n16/16 [==============================] - 0s 1ms/step - loss: 2.3168\n16/16 [==============================] - 0s 1ms/step - loss: 2.2891\n16/16 [==============================] - 0s 2ms/step - loss: 2.2799\n16/16 [==============================] - 0s 3ms/step - loss: 2.2762\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1664\n16/16 [==============================] - 0s 836us/step - loss: 1.9228\n16/16 [==============================] - 0s 857us/step - loss: 2.2967\n16/16 [==============================] - 0s 827us/step - loss: 2.3769\n16/16 [==============================] - 0s 2ms/step - loss: 2.3522\n16/16 [==============================] - 0s 2ms/step - loss: 2.3146\n16/16 [==============================] - 0s 2ms/step - loss: 2.2804\n16/16 [==============================] - 0s 2ms/step - loss: 2.2535\n16/16 [==============================] - 0s 2ms/step - loss: 2.2446\n16/16 [==============================] - 0s 2ms/step - loss: 2.2410\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 968us/step - loss: 0.1647\n16/16 [==============================] - 0s 836us/step - loss: 1.9825\n16/16 [==============================] - 0s 1ms/step - loss: 2.3655\n16/16 [==============================] - 0s 991us/step - loss: 2.4400\n16/16 [==============================] - 0s 708us/step - loss: 2.4065\n16/16 [==============================] - 0s 988us/step - loss: 2.3618\n16/16 [==============================] - 0s 1ms/step - loss: 2.3236\n16/16 [==============================] - 0s 769us/step - loss: 2.2942\n16/16 [==============================] - 0s 630us/step - loss: 2.2846\n16/16 [==============================] - 0s 832us/step - loss: 2.2808\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1616\n16/16 [==============================] - 0s 2ms/step - loss: 1.9799\n16/16 [==============================] - 0s 2ms/step - loss: 2.3682\n16/16 [==============================] - 0s 2ms/step - loss: 2.4457\n16/16 [==============================] - 0s 2ms/step - loss: 2.4156\n16/16 [==============================] - 0s 2ms/step - loss: 2.3727\n16/16 [==============================] - 0s 2ms/step - loss: 2.3349\n16/16 [==============================] - 0s 2ms/step - loss: 2.3056\n16/16 [==============================] - 0s 2ms/step - loss: 2.2959\n16/16 [==============================] - 0s 2ms/step - loss: 2.2921\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 594us/step - loss: 0.1670\n16/16 [==============================] - 0s 542us/step - loss: 1.9252\n16/16 [==============================] - 0s 603us/step - loss: 2.3035\n16/16 [==============================] - 0s 638us/step - loss: 2.3810\n16/16 [==============================] - 0s 646us/step - loss: 2.3532\n16/16 [==============================] - 0s 490us/step - loss: 2.3132\n16/16 [==============================] - 0s 517us/step - loss: 2.2779\n16/16 [==============================] - 0s 1ms/step - loss: 2.2503\n16/16 [==============================] - 0s 895us/step - loss: 2.2412\n16/16 [==============================] - 0s 570us/step - loss: 2.2376\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 626us/step - loss: 0.1649\n16/16 [==============================] - 0s 921us/step - loss: 1.9655\n16/16 [==============================] - 0s 1ms/step - loss: 2.3495\n16/16 [==============================] - 0s 708us/step - loss: 2.4250\n16/16 [==============================] - 0s 1ms/step - loss: 2.3950\n16/16 [==============================] - 0s 1ms/step - loss: 2.3532\n16/16 [==============================] - 0s 681us/step - loss: 2.3167\n16/16 [==============================] - 0s 632us/step - loss: 2.2886\n16/16 [==============================] - 0s 1ms/step - loss: 2.2794\n16/16 [==============================] - 0s 644us/step - loss: 2.2756\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 716us/step - loss: 0.1628\n16/16 [==============================] - 0s 631us/step - loss: 1.9172\n16/16 [==============================] - 0s 634us/step - loss: 2.2852\n16/16 [==============================] - 0s 601us/step - loss: 2.3543\n16/16 [==============================] - 0s 1ms/step - loss: 2.3241\n16/16 [==============================] - 0s 1ms/step - loss: 2.2817\n16/16 [==============================] - 0s 1ms/step - loss: 2.2446\n16/16 [==============================] - 0s 637us/step - loss: 2.2162\n16/16 [==============================] - 0s 1ms/step - loss: 2.2068\n16/16 [==============================] - 0s 622us/step - loss: 2.2031\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1632\n16/16 [==============================] - 0s 614us/step - loss: 1.9494\n16/16 [==============================] - 0s 585us/step - loss: 2.3248\n16/16 [==============================] - 0s 1ms/step - loss: 2.3958\n16/16 [==============================] - 0s 605us/step - loss: 2.3639\n16/16 [==============================] - 0s 1ms/step - loss: 2.3212\n16/16 [==============================] - 0s 659us/step - loss: 2.2846\n16/16 [==============================] - 0s 920us/step - loss: 2.2564\n16/16 [==============================] - 0s 642us/step - loss: 2.2472\n16/16 [==============================] - 0s 1ms/step - loss: 2.2436\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1623\n16/16 [==============================] - 0s 632us/step - loss: 1.9453\n16/16 [==============================] - 0s 701us/step - loss: 2.3227\n16/16 [==============================] - 0s 1ms/step - loss: 2.3937\n16/16 [==============================] - 0s 598us/step - loss: 2.3616\n16/16 [==============================] - 0s 623us/step - loss: 2.3172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2785\n16/16 [==============================] - 0s 802us/step - loss: 2.2493\n16/16 [==============================] - 0s 1ms/step - loss: 2.2398\n16/16 [==============================] - 0s 900us/step - loss: 2.2360\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 639us/step - loss: 0.1612\n16/16 [==============================] - 0s 709us/step - loss: 1.9442\n16/16 [==============================] - 0s 617us/step - loss: 2.3257\n16/16 [==============================] - 0s 598us/step - loss: 2.4020\n16/16 [==============================] - 0s 1ms/step - loss: 2.3753\n16/16 [==============================] - 0s 625us/step - loss: 2.3369\n16/16 [==============================] - 0s 611us/step - loss: 2.3024\n16/16 [==============================] - 0s 601us/step - loss: 2.2753\n16/16 [==============================] - 0s 764us/step - loss: 2.2663\n16/16 [==============================] - 0s 1ms/step - loss: 2.2626\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1585\n16/16 [==============================] - 0s 1ms/step - loss: 2.0528\n16/16 [==============================] - 0s 609us/step - loss: 2.4585\n16/16 [==============================] - 0s 789us/step - loss: 2.5358\n16/16 [==============================] - 0s 587us/step - loss: 2.5023\n16/16 [==============================] - 0s 672us/step - loss: 2.4563\n16/16 [==============================] - 0s 805us/step - loss: 2.4162\n16/16 [==============================] - 0s 1ms/step - loss: 2.3857\n16/16 [==============================] - 0s 1ms/step - loss: 2.3757\n16/16 [==============================] - 0s 1ms/step - loss: 2.3718\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 735us/step - loss: 0.1614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0477\n16/16 [==============================] - 0s 646us/step - loss: 2.4531\n16/16 [==============================] - 0s 1ms/step - loss: 2.5273\n16/16 [==============================] - 0s 560us/step - loss: 2.4941\n16/16 [==============================] - 0s 604us/step - loss: 2.4496\n16/16 [==============================] - 0s 1ms/step - loss: 2.4104\n16/16 [==============================] - 0s 599us/step - loss: 2.3801\n16/16 [==============================] - 0s 1ms/step - loss: 2.3702\n16/16 [==============================] - 0s 1ms/step - loss: 2.3661\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1584\n16/16 [==============================] - 0s 1ms/step - loss: 2.0297\n16/16 [==============================] - 0s 1ms/step - loss: 2.4309\n16/16 [==============================] - 0s 1ms/step - loss: 2.5028\n16/16 [==============================] - 0s 844us/step - loss: 2.4704\n16/16 [==============================] - 0s 721us/step - loss: 2.4258\n16/16 [==============================] - 0s 1ms/step - loss: 2.3870\n16/16 [==============================] - 0s 724us/step - loss: 2.3575\n16/16 [==============================] - 0s 1ms/step - loss: 2.3479\n16/16 [==============================] - 0s 1ms/step - loss: 2.3440\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1607\n16/16 [==============================] - 0s 1ms/step - loss: 1.9936\n16/16 [==============================] - 0s 1ms/step - loss: 2.3817\n16/16 [==============================] - 0s 618us/step - loss: 2.4495\n16/16 [==============================] - 0s 1ms/step - loss: 2.4171\n16/16 [==============================] - 0s 1ms/step - loss: 2.3735\n16/16 [==============================] - 0s 929us/step - loss: 2.3355\n16/16 [==============================] - 0s 1ms/step - loss: 2.3067\n16/16 [==============================] - 0s 1ms/step - loss: 2.2974\n16/16 [==============================] - 0s 967us/step - loss: 2.2937\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 0.1592\n16/16 [==============================] - 0s 748us/step - loss: 2.0080\n16/16 [==============================] - 0s 948us/step - loss: 2.3934\n16/16 [==============================] - 0s 626us/step - loss: 2.4562\n16/16 [==============================] - 0s 1ms/step - loss: 2.4202\n16/16 [==============================] - 0s 1ms/step - loss: 2.3733\n16/16 [==============================] - 0s 600us/step - loss: 2.3338\n16/16 [==============================] - 0s 1ms/step - loss: 2.3041\n16/16 [==============================] - 0s 1ms/step - loss: 2.2945\n16/16 [==============================] - 0s 579us/step - loss: 2.2907\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1563\n16/16 [==============================] - 0s 1ms/step - loss: 1.9989\n16/16 [==============================] - 0s 791us/step - loss: 2.3823\n16/16 [==============================] - 0s 592us/step - loss: 2.4454\n16/16 [==============================] - 0s 657us/step - loss: 2.4112\n16/16 [==============================] - 0s 731us/step - loss: 2.3670\n16/16 [==============================] - 0s 1ms/step - loss: 2.3288\n16/16 [==============================] - 0s 745us/step - loss: 2.2995\n16/16 [==============================] - 0s 595us/step - loss: 2.2900\n16/16 [==============================] - 0s 629us/step - loss: 2.2862\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 948us/step - loss: 0.1570\n16/16 [==============================] - 0s 860us/step - loss: 1.9843\n16/16 [==============================] - 0s 836us/step - loss: 2.3656\n16/16 [==============================] - 0s 1ms/step - loss: 2.4254\n16/16 [==============================] - 0s 1ms/step - loss: 2.3894\n16/16 [==============================] - 0s 1ms/step - loss: 2.3424\n16/16 [==============================] - 0s 644us/step - loss: 2.3025\n16/16 [==============================] - 0s 606us/step - loss: 2.2727\n16/16 [==============================] - 0s 1ms/step - loss: 2.2631\n16/16 [==============================] - 0s 810us/step - loss: 2.2593\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1540\n16/16 [==============================] - 0s 621us/step - loss: 2.0578\n16/16 [==============================] - 0s 754us/step - loss: 2.4644\n16/16 [==============================] - 0s 1ms/step - loss: 2.5294\n16/16 [==============================] - 0s 1ms/step - loss: 2.4946\n16/16 [==============================] - 0s 1ms/step - loss: 2.4481\n16/16 [==============================] - 0s 1ms/step - loss: 2.4079\n16/16 [==============================] - 0s 759us/step - loss: 2.3773\n16/16 [==============================] - 0s 1ms/step - loss: 2.3674\n16/16 [==============================] - 0s 634us/step - loss: 2.3635\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1569\n16/16 [==============================] - 0s 624us/step - loss: 2.0009\n16/16 [==============================] - 0s 644us/step - loss: 2.3983\n16/16 [==============================] - 0s 620us/step - loss: 2.4650\n16/16 [==============================] - 0s 1ms/step - loss: 2.4337\n16/16 [==============================] - 0s 657us/step - loss: 2.3895\n16/16 [==============================] - 0s 662us/step - loss: 2.3506\n16/16 [==============================] - 0s 1ms/step - loss: 2.3207\n16/16 [==============================] - 0s 826us/step - loss: 2.3109\n16/16 [==============================] - 0s 1ms/step - loss: 2.3070\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 648us/step - loss: 0.1564\n16/16 [==============================] - 0s 906us/step - loss: 1.9920\n16/16 [==============================] - 0s 1ms/step - loss: 2.3850\n16/16 [==============================] - 0s 632us/step - loss: 2.4473\n16/16 [==============================] - 0s 914us/step - loss: 2.4129\n16/16 [==============================] - 0s 650us/step - loss: 2.3665\n16/16 [==============================] - 0s 1ms/step - loss: 2.3262\n16/16 [==============================] - 0s 1ms/step - loss: 2.2963\n16/16 [==============================] - 0s 631us/step - loss: 2.2867\n16/16 [==============================] - 0s 1ms/step - loss: 2.2828\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1523\n16/16 [==============================] - 0s 610us/step - loss: 1.9810\n16/16 [==============================] - 0s 1ms/step - loss: 2.3695\n16/16 [==============================] - 0s 599us/step - loss: 2.4291\n16/16 [==============================] - 0s 1ms/step - loss: 2.3939\n16/16 [==============================] - 0s 596us/step - loss: 2.3485\n16/16 [==============================] - 0s 651us/step - loss: 2.3100\n16/16 [==============================] - 0s 1ms/step - loss: 2.2810\n16/16 [==============================] - 0s 1ms/step - loss: 2.2716\n16/16 [==============================] - 0s 789us/step - loss: 2.2678\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 605us/step - loss: 0.1539\n16/16 [==============================] - 0s 946us/step - loss: 2.0070\n16/16 [==============================] - 0s 1ms/step - loss: 2.3983\n16/16 [==============================] - 0s 562us/step - loss: 2.4547\n16/16 [==============================] - 0s 1ms/step - loss: 2.4185\n16/16 [==============================] - 0s 646us/step - loss: 2.3714\n16/16 [==============================] - 0s 1ms/step - loss: 2.3316\n16/16 [==============================] - 0s 1ms/step - loss: 2.3019\n16/16 [==============================] - 0s 1ms/step - loss: 2.2923\n16/16 [==============================] - 0s 629us/step - loss: 2.2885\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1531\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n16/16 [==============================] - 0s 1ms/step - loss: 2.5234\n16/16 [==============================] - 0s 649us/step - loss: 2.5872\n16/16 [==============================] - 0s 1ms/step - loss: 2.5491\n16/16 [==============================] - 0s 1ms/step - loss: 2.4983\n16/16 [==============================] - 0s 1ms/step - loss: 2.4550\n16/16 [==============================] - 0s 1ms/step - loss: 2.4226\n16/16 [==============================] - 0s 1ms/step - loss: 2.4122\n16/16 [==============================] - 0s 1ms/step - loss: 2.4080\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 631us/step - loss: 0.1539\n16/16 [==============================] - 0s 877us/step - loss: 2.0259\n16/16 [==============================] - 0s 1ms/step - loss: 2.4331\n16/16 [==============================] - 0s 724us/step - loss: 2.4907\n16/16 [==============================] - 0s 631us/step - loss: 2.4546\n16/16 [==============================] - 0s 631us/step - loss: 2.4070\n16/16 [==============================] - 0s 1ms/step - loss: 2.3665\n16/16 [==============================] - 0s 1ms/step - loss: 2.3359\n16/16 [==============================] - 0s 995us/step - loss: 2.3261\n16/16 [==============================] - 0s 1ms/step - loss: 2.3222\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1519\n16/16 [==============================] - 0s 639us/step - loss: 2.0542\n16/16 [==============================] - 0s 934us/step - loss: 2.4779\n16/16 [==============================] - 0s 1ms/step - loss: 2.5430\n16/16 [==============================] - 0s 666us/step - loss: 2.5111\n16/16 [==============================] - 0s 645us/step - loss: 2.4667\n16/16 [==============================] - 0s 606us/step - loss: 2.4283\n16/16 [==============================] - 0s 842us/step - loss: 2.3987\n16/16 [==============================] - 0s 617us/step - loss: 2.3890\n16/16 [==============================] - 0s 1ms/step - loss: 2.3851\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1528\n16/16 [==============================] - 0s 957us/step - loss: 2.0201\n16/16 [==============================] - 0s 1ms/step - loss: 2.4226\n16/16 [==============================] - 0s 610us/step - loss: 2.4747\n16/16 [==============================] - 0s 626us/step - loss: 2.4384\n16/16 [==============================] - 0s 1ms/step - loss: 2.3899\n16/16 [==============================] - 0s 1ms/step - loss: 2.3487\n16/16 [==============================] - 0s 1ms/step - loss: 2.3181\n16/16 [==============================] - 0s 1ms/step - loss: 2.3083\n16/16 [==============================] - 0s 635us/step - loss: 2.3044\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1513\n16/16 [==============================] - 0s 1ms/step - loss: 2.0221\n16/16 [==============================] - 0s 953us/step - loss: 2.4286\n16/16 [==============================] - 0s 584us/step - loss: 2.4816\n16/16 [==============================] - 0s 794us/step - loss: 2.4463\n16/16 [==============================] - 0s 1ms/step - loss: 2.3995\n16/16 [==============================] - 0s 1ms/step - loss: 2.3596\n16/16 [==============================] - 0s 1ms/step - loss: 2.3298\n16/16 [==============================] - 0s 635us/step - loss: 2.3202\n16/16 [==============================] - 0s 1ms/step - loss: 2.3163\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1505\n16/16 [==============================] - 0s 1ms/step - loss: 2.0238\n16/16 [==============================] - 0s 1ms/step - loss: 2.4319\n16/16 [==============================] - 0s 1ms/step - loss: 2.4849\n16/16 [==============================] - 0s 628us/step - loss: 2.4502\n16/16 [==============================] - 0s 1ms/step - loss: 2.4034\n16/16 [==============================] - 0s 660us/step - loss: 2.3643\n16/16 [==============================] - 0s 614us/step - loss: 2.3350\n16/16 [==============================] - 0s 628us/step - loss: 2.3256\n16/16 [==============================] - 0s 1ms/step - loss: 2.3218\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 0.1506\n16/16 [==============================] - 0s 929us/step - loss: 2.0292\n16/16 [==============================] - 0s 635us/step - loss: 2.4452\n16/16 [==============================] - 0s 625us/step - loss: 2.5006\n16/16 [==============================] - 0s 639us/step - loss: 2.4658\n16/16 [==============================] - 0s 1ms/step - loss: 2.4185\n16/16 [==============================] - 0s 640us/step - loss: 2.3780\n16/16 [==============================] - 0s 1ms/step - loss: 2.3475\n16/16 [==============================] - 0s 593us/step - loss: 2.3377\n16/16 [==============================] - 0s 947us/step - loss: 2.3338\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 642us/step - loss: 0.1520\n16/16 [==============================] - 0s 927us/step - loss: 2.0468\n16/16 [==============================] - 0s 907us/step - loss: 2.4645\n16/16 [==============================] - 0s 1ms/step - loss: 2.5202\n16/16 [==============================] - 0s 721us/step - loss: 2.4857\n16/16 [==============================] - 0s 1ms/step - loss: 2.4381\n16/16 [==============================] - 0s 1ms/step - loss: 2.3972\n16/16 [==============================] - 0s 1ms/step - loss: 2.3664\n16/16 [==============================] - 0s 755us/step - loss: 2.3565\n16/16 [==============================] - 0s 1ms/step - loss: 2.3525\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 836us/step - loss: 0.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.0895\n16/16 [==============================] - 0s 1ms/step - loss: 2.5139\n16/16 [==============================] - 0s 1ms/step - loss: 2.5640\n16/16 [==============================] - 0s 773us/step - loss: 2.5243\n16/16 [==============================] - 0s 754us/step - loss: 2.4719\n16/16 [==============================] - 0s 617us/step - loss: 2.4279\n16/16 [==============================] - 0s 1ms/step - loss: 2.3952\n16/16 [==============================] - 0s 935us/step - loss: 2.3847\n16/16 [==============================] - 0s 1ms/step - loss: 2.3804\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 635us/step - loss: 0.1465\n16/16 [==============================] - 0s 640us/step - loss: 2.0292\n16/16 [==============================] - 0s 610us/step - loss: 2.4415\n16/16 [==============================] - 0s 635us/step - loss: 2.4915\n16/16 [==============================] - 0s 634us/step - loss: 2.4547\n16/16 [==============================] - 0s 621us/step - loss: 2.4048\n16/16 [==============================] - 0s 644us/step - loss: 2.3627\n16/16 [==============================] - 0s 750us/step - loss: 2.3313\n16/16 [==============================] - 0s 1ms/step - loss: 2.3213\n16/16 [==============================] - 0s 705us/step - loss: 2.3173\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 624us/step - loss: 0.1449\n16/16 [==============================] - 0s 1ms/step - loss: 2.0603\n16/16 [==============================] - 0s 1ms/step - loss: 2.4760\n16/16 [==============================] - 0s 1ms/step - loss: 2.5243\n16/16 [==============================] - 0s 1ms/step - loss: 2.4877\n16/16 [==============================] - 0s 1ms/step - loss: 2.4388\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n16/16 [==============================] - 0s 615us/step - loss: 2.3674\n16/16 [==============================] - 0s 1ms/step - loss: 2.3576\n16/16 [==============================] - 0s 1ms/step - loss: 2.3537\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1456\n16/16 [==============================] - 0s 1ms/step - loss: 2.1177\n16/16 [==============================] - 0s 1ms/step - loss: 2.5539\n16/16 [==============================] - 0s 1ms/step - loss: 2.6038\n16/16 [==============================] - 0s 641us/step - loss: 2.5627\n16/16 [==============================] - 0s 1ms/step - loss: 2.5085\n16/16 [==============================] - 0s 1ms/step - loss: 2.4635\n16/16 [==============================] - 0s 1ms/step - loss: 2.4301\n16/16 [==============================] - 0s 1ms/step - loss: 2.4196\n16/16 [==============================] - 0s 1ms/step - loss: 2.4155\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 633us/step - loss: 0.1446\n16/16 [==============================] - 0s 650us/step - loss: 2.0868\n16/16 [==============================] - 0s 634us/step - loss: 2.5135\n16/16 [==============================] - 0s 605us/step - loss: 2.5636\n16/16 [==============================] - 0s 1ms/step - loss: 2.5272\n16/16 [==============================] - 0s 640us/step - loss: 2.4769\n16/16 [==============================] - 0s 1ms/step - loss: 2.4353\n16/16 [==============================] - 0s 608us/step - loss: 2.4045\n16/16 [==============================] - 0s 1ms/step - loss: 2.3946\n16/16 [==============================] - 0s 1ms/step - loss: 2.3907\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 649us/step - loss: 0.1457\n16/16 [==============================] - 0s 624us/step - loss: 2.0862\n16/16 [==============================] - 0s 875us/step - loss: 2.5107\n16/16 [==============================] - 0s 590us/step - loss: 2.5578\n16/16 [==============================] - 0s 573us/step - loss: 2.5165\n16/16 [==============================] - 0s 1ms/step - loss: 2.4632\n16/16 [==============================] - 0s 1ms/step - loss: 2.4191\n16/16 [==============================] - 0s 1ms/step - loss: 2.3864\n16/16 [==============================] - 0s 1ms/step - loss: 2.3760\n16/16 [==============================] - 0s 611us/step - loss: 2.3718\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 664us/step - loss: 0.1438\n16/16 [==============================] - 0s 610us/step - loss: 2.0347\n16/16 [==============================] - 0s 601us/step - loss: 2.4431\n16/16 [==============================] - 0s 1ms/step - loss: 2.4871\n16/16 [==============================] - 0s 636us/step - loss: 2.4479\n16/16 [==============================] - 0s 606us/step - loss: 2.3982\n16/16 [==============================] - 0s 618us/step - loss: 2.3571\n16/16 [==============================] - 0s 639us/step - loss: 2.3267\n16/16 [==============================] - 0s 657us/step - loss: 2.3170\n16/16 [==============================] - 0s 629us/step - loss: 2.3131\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 641us/step - loss: 0.1474\n16/16 [==============================] - 0s 988us/step - loss: 2.0366\n16/16 [==============================] - 0s 1ms/step - loss: 2.4480\n16/16 [==============================] - 0s 903us/step - loss: 2.4936\n16/16 [==============================] - 0s 1ms/step - loss: 2.4559\n16/16 [==============================] - 0s 1ms/step - loss: 2.4066\n16/16 [==============================] - 0s 635us/step - loss: 2.3658\n16/16 [==============================] - 0s 1ms/step - loss: 2.3355\n16/16 [==============================] - 0s 797us/step - loss: 2.3259\n16/16 [==============================] - 0s 735us/step - loss: 2.3222\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 696us/step - loss: 0.1436\n16/16 [==============================] - 0s 905us/step - loss: 2.1021\n16/16 [==============================] - 0s 841us/step - loss: 2.5288\n16/16 [==============================] - 0s 1ms/step - loss: 2.5741\n16/16 [==============================] - 0s 623us/step - loss: 2.5332\n16/16 [==============================] - 0s 637us/step - loss: 2.4820\n16/16 [==============================] - 0s 644us/step - loss: 2.4395\n16/16 [==============================] - 0s 949us/step - loss: 2.4076\n16/16 [==============================] - 0s 640us/step - loss: 2.3974\n16/16 [==============================] - 0s 1ms/step - loss: 2.3933\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 745us/step - loss: 0.1413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0536\n16/16 [==============================] - 0s 1ms/step - loss: 2.4615\n16/16 [==============================] - 0s 1ms/step - loss: 2.4976\n16/16 [==============================] - 0s 1ms/step - loss: 2.4550\n16/16 [==============================] - 0s 1ms/step - loss: 2.4020\n16/16 [==============================] - 0s 1ms/step - loss: 2.3590\n16/16 [==============================] - 0s 1ms/step - loss: 2.3276\n16/16 [==============================] - 0s 1ms/step - loss: 2.3176\n16/16 [==============================] - 0s 1ms/step - loss: 2.3137\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 624us/step - loss: 0.1436\n16/16 [==============================] - 0s 1ms/step - loss: 2.0689\n16/16 [==============================] - 0s 1ms/step - loss: 2.4842\n16/16 [==============================] - 0s 1ms/step - loss: 2.5212\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 613us/step - loss: 2.4299\n16/16 [==============================] - 0s 614us/step - loss: 2.3885\n16/16 [==============================] - 0s 622us/step - loss: 2.3575\n16/16 [==============================] - 0s 1ms/step - loss: 2.3477\n16/16 [==============================] - 0s 1ms/step - loss: 2.3438\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 636us/step - loss: 0.1412\n16/16 [==============================] - 0s 622us/step - loss: 2.0655\n16/16 [==============================] - 0s 584us/step - loss: 2.4782\n16/16 [==============================] - 0s 999us/step - loss: 2.5137\n16/16 [==============================] - 0s 648us/step - loss: 2.4722\n16/16 [==============================] - 0s 843us/step - loss: 2.4209\n16/16 [==============================] - 0s 889us/step - loss: 2.3791\n16/16 [==============================] - 0s 1ms/step - loss: 2.3482\n16/16 [==============================] - 0s 1ms/step - loss: 2.3383\n16/16 [==============================] - 0s 1ms/step - loss: 2.3344\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1411\n16/16 [==============================] - 0s 608us/step - loss: 2.0600\n16/16 [==============================] - 0s 591us/step - loss: 2.4682\n16/16 [==============================] - 0s 1ms/step - loss: 2.5009\n16/16 [==============================] - 0s 885us/step - loss: 2.4578\n16/16 [==============================] - 0s 1ms/step - loss: 2.4045\n16/16 [==============================] - 0s 918us/step - loss: 2.3612\n16/16 [==============================] - 0s 1ms/step - loss: 2.3293\n16/16 [==============================] - 0s 1ms/step - loss: 2.3193\n16/16 [==============================] - 0s 648us/step - loss: 2.3153\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 658us/step - loss: 0.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.0524\n16/16 [==============================] - 0s 593us/step - loss: 2.4624\n16/16 [==============================] - 0s 1ms/step - loss: 2.4994\n16/16 [==============================] - 0s 1ms/step - loss: 2.4614\n16/16 [==============================] - 0s 647us/step - loss: 2.4144\n16/16 [==============================] - 0s 956us/step - loss: 2.3751\n16/16 [==============================] - 0s 619us/step - loss: 2.3456\n16/16 [==============================] - 0s 1ms/step - loss: 2.3363\n16/16 [==============================] - 0s 1ms/step - loss: 2.3326\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1414\n16/16 [==============================] - 0s 691us/step - loss: 2.1374\n16/16 [==============================] - 0s 586us/step - loss: 2.5654\n16/16 [==============================] - 0s 1ms/step - loss: 2.5987\n16/16 [==============================] - 0s 601us/step - loss: 2.5514\n16/16 [==============================] - 0s 615us/step - loss: 2.4948\n16/16 [==============================] - 0s 952us/step - loss: 2.4484\n16/16 [==============================] - 0s 996us/step - loss: 2.4143\n16/16 [==============================] - 0s 1ms/step - loss: 2.4035\n16/16 [==============================] - 0s 1ms/step - loss: 2.3993\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1408\n16/16 [==============================] - 0s 1ms/step - loss: 2.1433\n16/16 [==============================] - 0s 1ms/step - loss: 2.5741\n16/16 [==============================] - 0s 1ms/step - loss: 2.6115\n16/16 [==============================] - 0s 684us/step - loss: 2.5677\n16/16 [==============================] - 0s 566us/step - loss: 2.5132\n16/16 [==============================] - 0s 617us/step - loss: 2.4685\n16/16 [==============================] - 0s 1ms/step - loss: 2.4356\n16/16 [==============================] - 0s 1ms/step - loss: 2.4250\n16/16 [==============================] - 0s 977us/step - loss: 2.4208\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1386\n16/16 [==============================] - 0s 626us/step - loss: 2.2159\n16/16 [==============================] - 0s 607us/step - loss: 2.6627\n16/16 [==============================] - 0s 1ms/step - loss: 2.7016\n16/16 [==============================] - 0s 616us/step - loss: 2.6579\n16/16 [==============================] - 0s 624us/step - loss: 2.6043\n16/16 [==============================] - 0s 593us/step - loss: 2.5597\n16/16 [==============================] - 0s 1ms/step - loss: 2.5264\n16/16 [==============================] - 0s 596us/step - loss: 2.5158\n16/16 [==============================] - 0s 1ms/step - loss: 2.5116\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 988us/step - loss: 0.1406\n16/16 [==============================] - 0s 819us/step - loss: 2.1877\n16/16 [==============================] - 0s 1ms/step - loss: 2.6298\n16/16 [==============================] - 0s 1ms/step - loss: 2.6666\n16/16 [==============================] - 0s 1ms/step - loss: 2.6212\n16/16 [==============================] - 0s 611us/step - loss: 2.5652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5194\n16/16 [==============================] - 0s 1ms/step - loss: 2.4854\n16/16 [==============================] - 0s 787us/step - loss: 2.4747\n16/16 [==============================] - 0s 1ms/step - loss: 2.4704\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1726\n16/16 [==============================] - 0s 1ms/step - loss: 2.6126\n16/16 [==============================] - 0s 1ms/step - loss: 2.6499\n16/16 [==============================] - 0s 622us/step - loss: 2.6046\n16/16 [==============================] - 0s 1ms/step - loss: 2.5491\n16/16 [==============================] - 0s 602us/step - loss: 2.5038\n16/16 [==============================] - 0s 1ms/step - loss: 2.4703\n16/16 [==============================] - 0s 1ms/step - loss: 2.4596\n16/16 [==============================] - 0s 625us/step - loss: 2.4553\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 722us/step - loss: 0.1402\n16/16 [==============================] - 0s 1ms/step - loss: 2.1077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5214\n16/16 [==============================] - 0s 1ms/step - loss: 2.5507\n16/16 [==============================] - 0s 1ms/step - loss: 2.5038\n16/16 [==============================] - 0s 638us/step - loss: 2.4486\n16/16 [==============================] - 0s 1ms/step - loss: 2.4039\n16/16 [==============================] - 0s 1ms/step - loss: 2.3711\n16/16 [==============================] - 0s 1ms/step - loss: 2.3608\n16/16 [==============================] - 0s 806us/step - loss: 2.3567\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0789\n16/16 [==============================] - 0s 635us/step - loss: 2.4879\n16/16 [==============================] - 0s 827us/step - loss: 2.5226\n16/16 [==============================] - 0s 1ms/step - loss: 2.4818\n16/16 [==============================] - 0s 1ms/step - loss: 2.4316\n16/16 [==============================] - 0s 1ms/step - loss: 2.3905\n16/16 [==============================] - 0s 1ms/step - loss: 2.3598\n16/16 [==============================] - 0s 702us/step - loss: 2.3501\n16/16 [==============================] - 0s 672us/step - loss: 2.3462\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 645us/step - loss: 0.1397\n16/16 [==============================] - 0s 615us/step - loss: 2.2173\n16/16 [==============================] - 0s 828us/step - loss: 2.6506\n16/16 [==============================] - 0s 1ms/step - loss: 2.6828\n16/16 [==============================] - 0s 1ms/step - loss: 2.6351\n16/16 [==============================] - 0s 1ms/step - loss: 2.5777\n16/16 [==============================] - 0s 603us/step - loss: 2.5312\n16/16 [==============================] - 0s 586us/step - loss: 2.4972\n16/16 [==============================] - 0s 874us/step - loss: 2.4864\n16/16 [==============================] - 0s 806us/step - loss: 2.4822\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1400\n16/16 [==============================] - 0s 1ms/step - loss: 2.1024\n16/16 [==============================] - 0s 1ms/step - loss: 2.5108\n16/16 [==============================] - 0s 1ms/step - loss: 2.5405\n16/16 [==============================] - 0s 656us/step - loss: 2.4959\n16/16 [==============================] - 0s 1ms/step - loss: 2.4414\n16/16 [==============================] - 0s 1ms/step - loss: 2.3972\n16/16 [==============================] - 0s 928us/step - loss: 2.3648\n16/16 [==============================] - 0s 1ms/step - loss: 2.3547\n16/16 [==============================] - 0s 1ms/step - loss: 2.3508\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 638us/step - loss: 0.1365\n16/16 [==============================] - 0s 618us/step - loss: 2.0904\n16/16 [==============================] - 0s 1ms/step - loss: 2.4896\n16/16 [==============================] - 0s 894us/step - loss: 2.5170\n16/16 [==============================] - 0s 1ms/step - loss: 2.4731\n16/16 [==============================] - 0s 995us/step - loss: 2.4215\n16/16 [==============================] - 0s 1ms/step - loss: 2.3790\n16/16 [==============================] - 0s 625us/step - loss: 2.3476\n16/16 [==============================] - 0s 634us/step - loss: 2.3377\n16/16 [==============================] - 0s 645us/step - loss: 2.3337\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1351\n16/16 [==============================] - 0s 1ms/step - loss: 2.1565\n16/16 [==============================] - 0s 618us/step - loss: 2.5687\n16/16 [==============================] - 0s 762us/step - loss: 2.5966\n16/16 [==============================] - 0s 1ms/step - loss: 2.5494\n16/16 [==============================] - 0s 1ms/step - loss: 2.4930\n16/16 [==============================] - 0s 648us/step - loss: 2.4471\n16/16 [==============================] - 0s 608us/step - loss: 2.4134\n16/16 [==============================] - 0s 959us/step - loss: 2.4028\n16/16 [==============================] - 0s 1ms/step - loss: 2.3986\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 809us/step - loss: 0.1389\n16/16 [==============================] - 0s 1ms/step - loss: 2.1419\n16/16 [==============================] - 0s 1ms/step - loss: 2.5512\n16/16 [==============================] - 0s 677us/step - loss: 2.5797\n16/16 [==============================] - 0s 668us/step - loss: 2.5344\n16/16 [==============================] - 0s 671us/step - loss: 2.4806\n16/16 [==============================] - 0s 657us/step - loss: 2.4371\n16/16 [==============================] - 0s 1ms/step - loss: 2.4050\n16/16 [==============================] - 0s 652us/step - loss: 2.3948\n16/16 [==============================] - 0s 1ms/step - loss: 2.3908\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1349\n16/16 [==============================] - 0s 1ms/step - loss: 2.1901\n16/16 [==============================] - 0s 716us/step - loss: 2.6044\n16/16 [==============================] - 0s 1ms/step - loss: 2.6295\n16/16 [==============================] - 0s 1ms/step - loss: 2.5800\n16/16 [==============================] - 0s 632us/step - loss: 2.5219\n16/16 [==============================] - 0s 1ms/step - loss: 2.4752\n16/16 [==============================] - 0s 1ms/step - loss: 2.4411\n16/16 [==============================] - 0s 1ms/step - loss: 2.4303\n16/16 [==============================] - 0s 608us/step - loss: 2.4260\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 626us/step - loss: 0.1361\n16/16 [==============================] - 0s 1ms/step - loss: 2.1862\n16/16 [==============================] - 0s 634us/step - loss: 2.6026\n16/16 [==============================] - 0s 1ms/step - loss: 2.6289\n16/16 [==============================] - 0s 602us/step - loss: 2.5794\n16/16 [==============================] - 0s 608us/step - loss: 2.5210\n16/16 [==============================] - 0s 945us/step - loss: 2.4747\n16/16 [==============================] - 0s 1ms/step - loss: 2.4412\n16/16 [==============================] - 0s 1ms/step - loss: 2.4307\n16/16 [==============================] - 0s 1ms/step - loss: 2.4265\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 591us/step - loss: 0.1354\n16/16 [==============================] - 0s 716us/step - loss: 2.1140\n16/16 [==============================] - 0s 645us/step - loss: 2.5078\n16/16 [==============================] - 0s 1ms/step - loss: 2.5307\n16/16 [==============================] - 0s 576us/step - loss: 2.4835\n16/16 [==============================] - 0s 1ms/step - loss: 2.4278\n16/16 [==============================] - 0s 1ms/step - loss: 2.3835\n16/16 [==============================] - 0s 721us/step - loss: 2.3512\n16/16 [==============================] - 0s 683us/step - loss: 2.3411\n16/16 [==============================] - 0s 973us/step - loss: 2.3371\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 746us/step - loss: 0.1375\n16/16 [==============================] - 0s 1ms/step - loss: 2.1227\n16/16 [==============================] - 0s 1ms/step - loss: 2.5193\n16/16 [==============================] - 0s 1ms/step - loss: 2.5434\n16/16 [==============================] - 0s 1ms/step - loss: 2.4969\n16/16 [==============================] - 0s 928us/step - loss: 2.4432\n16/16 [==============================] - 0s 851us/step - loss: 2.4006\n16/16 [==============================] - 0s 661us/step - loss: 2.3696\n16/16 [==============================] - 0s 980us/step - loss: 2.3598\n16/16 [==============================] - 0s 1ms/step - loss: 2.3560\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 939us/step - loss: 0.1385\n16/16 [==============================] - 0s 1ms/step - loss: 2.1281\n16/16 [==============================] - 0s 629us/step - loss: 2.5285\n16/16 [==============================] - 0s 1ms/step - loss: 2.5562\n16/16 [==============================] - 0s 598us/step - loss: 2.5119\n16/16 [==============================] - 0s 633us/step - loss: 2.4583\n16/16 [==============================] - 0s 638us/step - loss: 2.4151\n16/16 [==============================] - 0s 639us/step - loss: 2.3836\n16/16 [==============================] - 0s 900us/step - loss: 2.3737\n16/16 [==============================] - 0s 1ms/step - loss: 2.3698\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 650us/step - loss: 0.1350\n16/16 [==============================] - 0s 636us/step - loss: 2.1239\n16/16 [==============================] - 0s 1ms/step - loss: 2.5171\n16/16 [==============================] - 0s 853us/step - loss: 2.5400\n16/16 [==============================] - 0s 596us/step - loss: 2.4914\n16/16 [==============================] - 0s 619us/step - loss: 2.4353\n16/16 [==============================] - 0s 1ms/step - loss: 2.3913\n16/16 [==============================] - 0s 1ms/step - loss: 2.3594\n16/16 [==============================] - 0s 1ms/step - loss: 2.3494\n16/16 [==============================] - 0s 665us/step - loss: 2.3455\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1328\n16/16 [==============================] - 0s 1ms/step - loss: 2.1880\n16/16 [==============================] - 0s 1ms/step - loss: 2.5967\n16/16 [==============================] - 0s 619us/step - loss: 2.6189\n16/16 [==============================] - 0s 603us/step - loss: 2.5676\n16/16 [==============================] - 0s 1ms/step - loss: 2.5074\n16/16 [==============================] - 0s 1ms/step - loss: 2.4597\n16/16 [==============================] - 0s 1ms/step - loss: 2.4251\n16/16 [==============================] - 0s 1ms/step - loss: 2.4143\n16/16 [==============================] - 0s 1ms/step - loss: 2.4100\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1320\n16/16 [==============================] - 0s 624us/step - loss: 2.2799\n16/16 [==============================] - 0s 824us/step - loss: 2.7184\n16/16 [==============================] - 0s 644us/step - loss: 2.7484\n16/16 [==============================] - 0s 655us/step - loss: 2.6979\n16/16 [==============================] - 0s 690us/step - loss: 2.6378\n16/16 [==============================] - 0s 1ms/step - loss: 2.5895\n16/16 [==============================] - 0s 637us/step - loss: 2.5547\n16/16 [==============================] - 0s 806us/step - loss: 2.5438\n16/16 [==============================] - 0s 757us/step - loss: 2.5395\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1319\n16/16 [==============================] - 0s 1ms/step - loss: 2.2685\n16/16 [==============================] - 0s 1ms/step - loss: 2.6951\n16/16 [==============================] - 0s 1ms/step - loss: 2.7210\n16/16 [==============================] - 0s 1ms/step - loss: 2.6693\n16/16 [==============================] - 0s 905us/step - loss: 2.6086\n16/16 [==============================] - 0s 985us/step - loss: 2.5598\n16/16 [==============================] - 0s 897us/step - loss: 2.5247\n16/16 [==============================] - 0s 1ms/step - loss: 2.5138\n16/16 [==============================] - 0s 726us/step - loss: 2.5094\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1306\n16/16 [==============================] - 0s 628us/step - loss: 2.1294\n16/16 [==============================] - 0s 571us/step - loss: 2.5162\n16/16 [==============================] - 0s 651us/step - loss: 2.5364\n16/16 [==============================] - 0s 657us/step - loss: 2.4872\n16/16 [==============================] - 0s 620us/step - loss: 2.4317\n16/16 [==============================] - 0s 627us/step - loss: 2.3874\n16/16 [==============================] - 0s 631us/step - loss: 2.3554\n16/16 [==============================] - 0s 911us/step - loss: 2.3455\n16/16 [==============================] - 0s 1ms/step - loss: 2.3416\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1298\n16/16 [==============================] - 0s 633us/step - loss: 2.2952\n16/16 [==============================] - 0s 1ms/step - loss: 2.7216\n16/16 [==============================] - 0s 1ms/step - loss: 2.7446\n16/16 [==============================] - 0s 1ms/step - loss: 2.6897\n16/16 [==============================] - 0s 611us/step - loss: 2.6254\n16/16 [==============================] - 0s 1ms/step - loss: 2.5745\n16/16 [==============================] - 0s 1ms/step - loss: 2.5375\n16/16 [==============================] - 0s 1ms/step - loss: 2.5260\n16/16 [==============================] - 0s 935us/step - loss: 2.5215\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 604us/step - loss: 0.1304\n16/16 [==============================] - 0s 1ms/step - loss: 2.1990\n16/16 [==============================] - 0s 598us/step - loss: 2.6016\n16/16 [==============================] - 0s 1ms/step - loss: 2.6241\n16/16 [==============================] - 0s 1ms/step - loss: 2.5736\n16/16 [==============================] - 0s 753us/step - loss: 2.5147\n16/16 [==============================] - 0s 1ms/step - loss: 2.4677\n16/16 [==============================] - 0s 626us/step - loss: 2.4338\n16/16 [==============================] - 0s 718us/step - loss: 2.4233\n16/16 [==============================] - 0s 852us/step - loss: 2.4191\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1279\n16/16 [==============================] - 0s 629us/step - loss: 2.1722\n16/16 [==============================] - 0s 1ms/step - loss: 2.5696\n16/16 [==============================] - 0s 1ms/step - loss: 2.5888\n16/16 [==============================] - 0s 687us/step - loss: 2.5353\n16/16 [==============================] - 0s 644us/step - loss: 2.4735\n16/16 [==============================] - 0s 1ms/step - loss: 2.4255\n16/16 [==============================] - 0s 1ms/step - loss: 2.3910\n16/16 [==============================] - 0s 1ms/step - loss: 2.3803\n16/16 [==============================] - 0s 1ms/step - loss: 2.3761\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 725us/step - loss: 0.1313\n16/16 [==============================] - 0s 1ms/step - loss: 2.1862\n16/16 [==============================] - 0s 644us/step - loss: 2.5858\n16/16 [==============================] - 0s 1ms/step - loss: 2.6081\n16/16 [==============================] - 0s 1ms/step - loss: 2.5577\n16/16 [==============================] - 0s 1ms/step - loss: 2.4986\n16/16 [==============================] - 0s 1ms/step - loss: 2.4523\n16/16 [==============================] - 0s 1ms/step - loss: 2.4191\n16/16 [==============================] - 0s 708us/step - loss: 2.4087\n16/16 [==============================] - 0s 632us/step - loss: 2.4046\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 620us/step - loss: 0.1281\n16/16 [==============================] - 0s 632us/step - loss: 2.2017\n16/16 [==============================] - 0s 607us/step - loss: 2.5988\n16/16 [==============================] - 0s 573us/step - loss: 2.6178\n16/16 [==============================] - 0s 653us/step - loss: 2.5652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5044\n16/16 [==============================] - 0s 808us/step - loss: 2.4563\n16/16 [==============================] - 0s 648us/step - loss: 2.4216\n16/16 [==============================] - 0s 724us/step - loss: 2.4108\n16/16 [==============================] - 0s 727us/step - loss: 2.4066\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1283\n16/16 [==============================] - 0s 643us/step - loss: 2.2432\n16/16 [==============================] - 0s 1ms/step - loss: 2.6497\n16/16 [==============================] - 0s 612us/step - loss: 2.6688\n16/16 [==============================] - 0s 1ms/step - loss: 2.6142\n16/16 [==============================] - 0s 837us/step - loss: 2.5514\n16/16 [==============================] - 0s 836us/step - loss: 2.5023\n16/16 [==============================] - 0s 1ms/step - loss: 2.4675\n16/16 [==============================] - 0s 641us/step - loss: 2.4567\n16/16 [==============================] - 0s 1ms/step - loss: 2.4524\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 876us/step - loss: 0.1307\n16/16 [==============================] - 0s 1ms/step - loss: 2.2389\n16/16 [==============================] - 0s 1ms/step - loss: 2.6476\n16/16 [==============================] - 0s 1ms/step - loss: 2.6694\n16/16 [==============================] - 0s 646us/step - loss: 2.6174\n16/16 [==============================] - 0s 651us/step - loss: 2.5567\n16/16 [==============================] - 0s 630us/step - loss: 2.5086\n16/16 [==============================] - 0s 645us/step - loss: 2.4744\n16/16 [==============================] - 0s 1ms/step - loss: 2.4637\n16/16 [==============================] - 0s 634us/step - loss: 2.4595\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1294\n16/16 [==============================] - 0s 1ms/step - loss: 2.2039\n16/16 [==============================] - 0s 1ms/step - loss: 2.6016\n16/16 [==============================] - 0s 1ms/step - loss: 2.6199\n16/16 [==============================] - 0s 618us/step - loss: 2.5666\n16/16 [==============================] - 0s 1ms/step - loss: 2.5066\n16/16 [==============================] - 0s 1ms/step - loss: 2.4594\n16/16 [==============================] - 0s 1ms/step - loss: 2.4255\n16/16 [==============================] - 0s 967us/step - loss: 2.4150\n16/16 [==============================] - 0s 594us/step - loss: 2.4109\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.1284\n16/16 [==============================] - 0s 633us/step - loss: 2.2483\n16/16 [==============================] - 0s 996us/step - loss: 2.6576\n16/16 [==============================] - 0s 1ms/step - loss: 2.6801\n16/16 [==============================] - 0s 610us/step - loss: 2.6274\n16/16 [==============================] - 0s 1ms/step - loss: 2.5661\n16/16 [==============================] - 0s 1ms/step - loss: 2.5171\n16/16 [==============================] - 0s 905us/step - loss: 2.4817\n16/16 [==============================] - 0s 1ms/step - loss: 2.4707\n16/16 [==============================] - 0s 1ms/step - loss: 2.4664\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 629us/step - loss: 0.1308\n16/16 [==============================] - 0s 1ms/step - loss: 2.2241\n16/16 [==============================] - 0s 776us/step - loss: 2.6243\n16/16 [==============================] - 0s 1ms/step - loss: 2.6430\n16/16 [==============================] - 0s 1ms/step - loss: 2.5906\n16/16 [==============================] - 0s 647us/step - loss: 2.5309\n16/16 [==============================] - 0s 632us/step - loss: 2.4834\n16/16 [==============================] - 0s 617us/step - loss: 2.4493\n16/16 [==============================] - 0s 622us/step - loss: 2.4387\n16/16 [==============================] - 0s 619us/step - loss: 2.4346\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1249\n16/16 [==============================] - 0s 1ms/step - loss: 2.2824\n16/16 [==============================] - 0s 886us/step - loss: 2.6944\n16/16 [==============================] - 0s 1ms/step - loss: 2.7119\n16/16 [==============================] - 0s 840us/step - loss: 2.6561\n16/16 [==============================] - 0s 1ms/step - loss: 2.5941\n16/16 [==============================] - 0s 749us/step - loss: 2.5456\n16/16 [==============================] - 0s 633us/step - loss: 2.5112\n16/16 [==============================] - 0s 631us/step - loss: 2.5004\n16/16 [==============================] - 0s 598us/step - loss: 2.4962\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1268\n16/16 [==============================] - 0s 641us/step - loss: 2.2303\n16/16 [==============================] - 0s 987us/step - loss: 2.6315\n16/16 [==============================] - 0s 755us/step - loss: 2.6520\n16/16 [==============================] - 0s 1ms/step - loss: 2.6023\n16/16 [==============================] - 0s 1ms/step - loss: 2.5447\n16/16 [==============================] - 0s 1ms/step - loss: 2.4980\n16/16 [==============================] - 0s 1ms/step - loss: 2.4644\n16/16 [==============================] - 0s 1ms/step - loss: 2.4540\n16/16 [==============================] - 0s 1ms/step - loss: 2.4499\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1253\n16/16 [==============================] - 0s 1ms/step - loss: 2.2804\n16/16 [==============================] - 0s 1ms/step - loss: 2.6909\n16/16 [==============================] - 0s 1ms/step - loss: 2.7047\n16/16 [==============================] - 0s 1ms/step - loss: 2.6461\n16/16 [==============================] - 0s 890us/step - loss: 2.5810\n16/16 [==============================] - 0s 1ms/step - loss: 2.5304\n16/16 [==============================] - 0s 1ms/step - loss: 2.4944\n16/16 [==============================] - 0s 1ms/step - loss: 2.4833\n16/16 [==============================] - 0s 1ms/step - loss: 2.4788\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 749us/step - loss: 0.1268\n16/16 [==============================] - 0s 1ms/step - loss: 2.2590\n16/16 [==============================] - 0s 613us/step - loss: 2.6587\n16/16 [==============================] - 0s 617us/step - loss: 2.6734\n16/16 [==============================] - 0s 1ms/step - loss: 2.6186\n16/16 [==============================] - 0s 1ms/step - loss: 2.5570\n16/16 [==============================] - 0s 950us/step - loss: 2.5081\n16/16 [==============================] - 0s 1ms/step - loss: 2.4730\n16/16 [==============================] - 0s 661us/step - loss: 2.4621\n16/16 [==============================] - 0s 623us/step - loss: 2.4579\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1254\n16/16 [==============================] - 0s 854us/step - loss: 2.2600\n16/16 [==============================] - 0s 1ms/step - loss: 2.6602\n16/16 [==============================] - 0s 655us/step - loss: 2.6753\n16/16 [==============================] - 0s 1ms/step - loss: 2.6206\n16/16 [==============================] - 0s 1ms/step - loss: 2.5580\n16/16 [==============================] - 0s 706us/step - loss: 2.5089\n16/16 [==============================] - 0s 1ms/step - loss: 2.4739\n16/16 [==============================] - 0s 1ms/step - loss: 2.4630\n16/16 [==============================] - 0s 1ms/step - loss: 2.4588\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 681us/step - loss: 0.1267\n16/16 [==============================] - 0s 775us/step - loss: 2.2358\n16/16 [==============================] - 0s 608us/step - loss: 2.6324\n16/16 [==============================] - 0s 628us/step - loss: 2.6479\n16/16 [==============================] - 0s 610us/step - loss: 2.5940\n16/16 [==============================] - 0s 608us/step - loss: 2.5341\n16/16 [==============================] - 0s 637us/step - loss: 2.4871\n16/16 [==============================] - 0s 611us/step - loss: 2.4534\n16/16 [==============================] - 0s 641us/step - loss: 2.4430\n16/16 [==============================] - 0s 763us/step - loss: 2.4389\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1232\n16/16 [==============================] - 0s 1ms/step - loss: 2.3007\n16/16 [==============================] - 0s 1ms/step - loss: 2.7090\n16/16 [==============================] - 0s 631us/step - loss: 2.7214\n16/16 [==============================] - 0s 973us/step - loss: 2.6639\n16/16 [==============================] - 0s 667us/step - loss: 2.5993\n16/16 [==============================] - 0s 1ms/step - loss: 2.5482\n16/16 [==============================] - 0s 1ms/step - loss: 2.5115\n16/16 [==============================] - 0s 1ms/step - loss: 2.5002\n16/16 [==============================] - 0s 1ms/step - loss: 2.4957\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1249\n16/16 [==============================] - 0s 703us/step - loss: 2.2634\n16/16 [==============================] - 0s 1ms/step - loss: 2.6562\n16/16 [==============================] - 0s 1ms/step - loss: 2.6629\n16/16 [==============================] - 0s 1ms/step - loss: 2.6041\n16/16 [==============================] - 0s 872us/step - loss: 2.5390\n16/16 [==============================] - 0s 617us/step - loss: 2.4883\n16/16 [==============================] - 0s 687us/step - loss: 2.4527\n16/16 [==============================] - 0s 615us/step - loss: 2.4419\n16/16 [==============================] - 0s 783us/step - loss: 2.4376\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 700us/step - loss: 0.1249\n16/16 [==============================] - 0s 601us/step - loss: 2.2865\n16/16 [==============================] - 0s 625us/step - loss: 2.6880\n16/16 [==============================] - 0s 581us/step - loss: 2.7004\n16/16 [==============================] - 0s 1ms/step - loss: 2.6446\n16/16 [==============================] - 0s 714us/step - loss: 2.5815\n16/16 [==============================] - 0s 1ms/step - loss: 2.5315\n16/16 [==============================] - 0s 1ms/step - loss: 2.4957\n16/16 [==============================] - 0s 740us/step - loss: 2.4847\n16/16 [==============================] - 0s 1ms/step - loss: 2.4803\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 584us/step - loss: 0.1245\n16/16 [==============================] - 0s 787us/step - loss: 2.2729\n16/16 [==============================] - 0s 1ms/step - loss: 2.6637\n16/16 [==============================] - 0s 1ms/step - loss: 2.6712\n16/16 [==============================] - 0s 608us/step - loss: 2.6147\n16/16 [==============================] - 0s 654us/step - loss: 2.5526\n16/16 [==============================] - 0s 1ms/step - loss: 2.5033\n16/16 [==============================] - 0s 891us/step - loss: 2.4684\n16/16 [==============================] - 0s 697us/step - loss: 2.4576\n16/16 [==============================] - 0s 639us/step - loss: 2.4534\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 0.1250\n16/16 [==============================] - 0s 941us/step - loss: 2.2686\n16/16 [==============================] - 0s 599us/step - loss: 2.6612\n16/16 [==============================] - 0s 1ms/step - loss: 2.6698\n16/16 [==============================] - 0s 778us/step - loss: 2.6129\n16/16 [==============================] - 0s 691us/step - loss: 2.5509\n16/16 [==============================] - 0s 1ms/step - loss: 2.5026\n16/16 [==============================] - 0s 623us/step - loss: 2.4683\n16/16 [==============================] - 0s 885us/step - loss: 2.4578\n16/16 [==============================] - 0s 701us/step - loss: 2.4537\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1234\n16/16 [==============================] - 0s 1ms/step - loss: 2.3238\n16/16 [==============================] - 0s 803us/step - loss: 2.7242\n16/16 [==============================] - 0s 601us/step - loss: 2.7327\n16/16 [==============================] - 0s 647us/step - loss: 2.6743\n16/16 [==============================] - 0s 970us/step - loss: 2.6098\n16/16 [==============================] - 0s 926us/step - loss: 2.5591\n16/16 [==============================] - 0s 1ms/step - loss: 2.5229\n16/16 [==============================] - 0s 1ms/step - loss: 2.5118\n16/16 [==============================] - 0s 678us/step - loss: 2.5074\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 642us/step - loss: 0.1248\n16/16 [==============================] - 0s 597us/step - loss: 2.2835\n16/16 [==============================] - 0s 629us/step - loss: 2.6774\n16/16 [==============================] - 0s 1ms/step - loss: 2.6863\n16/16 [==============================] - 0s 644us/step - loss: 2.6273\n16/16 [==============================] - 0s 1ms/step - loss: 2.5622\n16/16 [==============================] - 0s 956us/step - loss: 2.5114\n16/16 [==============================] - 0s 664us/step - loss: 2.4755\n16/16 [==============================] - 0s 875us/step - loss: 2.4643\n16/16 [==============================] - 0s 593us/step - loss: 2.4600\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 716us/step - loss: 0.1237\n16/16 [==============================] - 0s 626us/step - loss: 2.2727\n16/16 [==============================] - 0s 1ms/step - loss: 2.6608\n16/16 [==============================] - 0s 1ms/step - loss: 2.6688\n16/16 [==============================] - 0s 1ms/step - loss: 2.6110\n16/16 [==============================] - 0s 919us/step - loss: 2.5473\n16/16 [==============================] - 0s 1ms/step - loss: 2.4975\n16/16 [==============================] - 0s 780us/step - loss: 2.4622\n16/16 [==============================] - 0s 716us/step - loss: 2.4513\n16/16 [==============================] - 0s 638us/step - loss: 2.4470\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1213\n16/16 [==============================] - 0s 616us/step - loss: 2.3241\n16/16 [==============================] - 0s 618us/step - loss: 2.7152\n16/16 [==============================] - 0s 1ms/step - loss: 2.7211\n16/16 [==============================] - 0s 1ms/step - loss: 2.6613\n16/16 [==============================] - 0s 631us/step - loss: 2.5967\n16/16 [==============================] - 0s 741us/step - loss: 2.5461\n16/16 [==============================] - 0s 633us/step - loss: 2.5105\n16/16 [==============================] - 0s 2ms/step - loss: 2.4996\n16/16 [==============================] - 0s 599us/step - loss: 2.4952\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1217\n16/16 [==============================] - 0s 1ms/step - loss: 2.3310\n16/16 [==============================] - 0s 1ms/step - loss: 2.7333\n16/16 [==============================] - 0s 1ms/step - loss: 2.7466\n16/16 [==============================] - 0s 1ms/step - loss: 2.6903\n16/16 [==============================] - 0s 833us/step - loss: 2.6273\n16/16 [==============================] - 0s 608us/step - loss: 2.5776\n16/16 [==============================] - 0s 1ms/step - loss: 2.5424\n16/16 [==============================] - 0s 626us/step - loss: 2.5314\n16/16 [==============================] - 0s 709us/step - loss: 2.5270\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1211\n16/16 [==============================] - 0s 1ms/step - loss: 2.2989\n16/16 [==============================] - 0s 1ms/step - loss: 2.6855\n16/16 [==============================] - 0s 1ms/step - loss: 2.6923\n16/16 [==============================] - 0s 1ms/step - loss: 2.6322\n16/16 [==============================] - 0s 650us/step - loss: 2.5665\n16/16 [==============================] - 0s 1ms/step - loss: 2.5155\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 844us/step - loss: 2.4690\n16/16 [==============================] - 0s 593us/step - loss: 2.4647\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.996\nRecall: 0.941\nF1 Score: 0.967\n\n\n\nfourteen_bunny = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny-result",
    "title": "Class code for Comparison Study",
    "section": "Bunny Result",
    "text": "Bunny Result\n\nround(fourteen_bunny,4)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.9948\n      0.9954\n      0.9992\n      0.9973\n    \n    \n      LOF (Breunig et al., 2000)\n      0.9285\n      0.9569\n      0.9685\n      0.9627\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.9405\n      0.9960\n      0.9413\n      0.9679\n    \n    \n      CBLOF (He et al., 2003)\n      0.9776\n      0.9895\n      0.9870\n      0.9882\n    \n    \n      OCSVM (Sch ̈olkopf et al., 2001)\n      0.9321\n      0.9911\n      0.9371\n      0.9633\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.9349\n      0.9929\n      0.9383\n      0.9648\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.9149\n      0.9818\n      0.9278\n      0.9540\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.9768\n      0.9891\n      0.9866\n      0.9878\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.7942\n      0.9947\n      0.7881\n      0.8794\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.8953\n      0.9695\n      0.9190\n      0.9436\n    \n    \n      SOS (Janssens et al., 2012)\n      0.8953\n      0.9695\n      0.9190\n      0.9436\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.9521\n      0.9521\n      1.0000\n      0.9754\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.9521\n      0.9521\n      1.0000\n      0.9754\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.9397\n      0.9956\n      0.9408\n      0.9674"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html",
    "href": "posts/GODE/2022-09-02-paper_simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#imports",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#imports",
    "title": "Simulation",
    "section": "imports",
    "text": "imports\n\nimport rpy2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.graph_objects as go\n\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\nfrom plotly.subplots import make_subplots"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ebayesthresh",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ebayesthresh",
    "title": "Simulation",
    "section": "EbayesThresh",
    "text": "EbayesThresh\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\nR + python\n- R환경에 있던 x를 가지고 오기\n\n%R -o x \n\n- R환경에 있는 ebayesthresh 함수를 가지고 오기\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n#plt.plot(x)\n#plt.plot(xhat)"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#시도-1",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#시도-1",
    "title": "Simulation",
    "section": "시도 1",
    "text": "시도 1\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color 표현은 위핸 표준화\n        self.df = self.df.assign(differ = self.differ)\n        #with plt.style.context('seaborn-dark'):\n            #plt.figure(figsize=(16,10))\n            #plt.scatter(self.x,self.y,c=self.differ3,cmap='Purples',s=50)\n            #plt.plot(self.x,self.yhat, 'k--')\n    def vis(self,ref=60):\n        fig = go.Figure()\n        fig.add_scatter(x=self.x,y=self.y,mode=\"markers\",marker=dict(size=2, color=\"#9fc5e8\"),name='y',opacity=0.7)\n        fig.add_scatter(x=self.x,y=self.yhat,mode=\"markers\",marker=dict(size=2, color=\"#000000\"),name='yhat',opacity=0.7)\n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#0000FF',name='underline'))\n        fig.update_layout(width=1000,height=1000,autosize=False,margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def sub(self):\n        fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n        axs[0,0].plot(self.power)\n        axs[0,0].plot(self.power_threshed)\n        axs[0,0].set_title('power_threshed')\n\n        axs[0,1].plot(self.power[1:])\n        axs[0,1].plot(self.power_threshed[1:])\n        axs[0,1].set_title('power_threshed 1:')\n\n        axs[1,0].plot(self.power[2:])\n        axs[1,0].plot(self.power_threshed[2:])\n        axs[1,0].set_title('power_threshed 2:')\n\n        axs[1,1].plot((self.df.Residual)**2)\n        axs[1,1].set_title('Residual square')\n\n        plt.tight_layout()\n        plt.show()\n    def subvis(self,ref=60):\n        fig = make_subplots(rows=2, cols=2, subplot_titles=(\"y\", \"yhat\", \"Residual Square\", \"Graph\"))\n                            \n        fig.add_scatter(x=self.x,y=self.y, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='y',opacity=0.7,row=1,col=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=1,col=1)\n        \n        fig.add_scatter(x=self.x,y=self.yhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='yhat',opacity=0.7,row=1,col=2)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=1,col=2)\n        \n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=2,col=1)\n        \n        fig.add_scatter(x=self.x,y=self.y, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='y',opacity=0.7,row=2,col=2)        \n        fig.add_scatter(x=self.x,y=self.yhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='yhat',opacity=0.7,row=2,col=2)        \n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=2)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=2,col=2)\n        \n        fig.update_xaxes(range=[0, 2], row=1, col=1)\n        fig.update_yaxes(range=[-5, 15], row=1, col=1)\n        \n        fig.update_xaxes(range=[0, 2], row=1, col=2)\n        fig.update_yaxes(range=[-5, 15], row=1, col=2)\n        \n        fig.update_xaxes(range=[0, 2], row=2, col=1)\n        fig.update_yaxes(range=[-5, 15], row=2, col=1)\n        \n        fig.update_xaxes(range=[0, 2], row=2, col=2)\n        fig.update_yaxes(range=[-5, 15], row=2, col=2)\n        \n        fig.update_layout(width=1000,height=1000,autosize=False,showlegend=False,title_text=\"The result\")\n        \n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\nclass SIMUL2(SIMUL):\n    def fit2(self,sd=5,ref=60,cuts=0,cutf=995):\n        self.fit()\n        with plt.style.context('seaborn-dark'):\n            plt.figure(figsize=(16,10))\n            plt.scatter(self.x,self.y,c=self.differ3,cmap='Purples',s=50)\n            plt.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50)\n            plt.plot(self.x,self.y1,'b--')\n            plt.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k--')\n    def fit3(self,sd=5,ref=30,ymin=-5,ymax=20,cuts=0,cutf=995):\n        self.fit()\n        with plt.style.context('seaborn-dark'):\n            fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n            axs[0,0].scatter(self.x,self.y,c=self.differ,cmap='Purples',s=50)\n            axs[0,0].set_title('y')\n            axs[0,0].set_ylim([ymin,ymax])\n            \n\n            axs[0,1].plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k')\n            axs[0,1].plot(self.x[cuts:cutf],self.y1[cuts:cutf], 'b',alpha=0.5)\n            axs[0,1].set_title('yhat')\n            axs[0,1].set_ylim([ymin,ymax])\n\n            axs[1,0].scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50,marker='*')\n            axs[1,0].plot(self.x[cuts:cutf],self.y1[cuts:cutf], 'b',alpha=0.5)\n            axs[1,0].set_title('Residual square')\n            axs[1,0].set_ylim([ymin,ymax])\n\n            axs[1,1].scatter(self.x,self.y,c=self.differ,cmap='Purples',s=50)\n            axs[1,1].plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k')\n            axs[1,1].scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50,marker='*')\n            axs[1,1].set_title('Graph')\n            axs[1,1].set_ylim([ymin,ymax])\n\n            plt.tight_layout()\n            plt.show()\n\n\n_simul = SIMUL2(df1)\n\n\n_simul.fit3(sd=5,ref=20,ymin=-10,ymax=15)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#시도-2",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#시도-2",
    "title": "Simulation",
    "section": "시도 2",
    "text": "시도 2\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df2)\n\n\n_simul.fit3(sd=6,ref=20,ymin=-10,ymax=25)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#시도-3",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#시도-3",
    "title": "Simulation",
    "section": "시도 3",
    "text": "시도 3\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**3 \n_y = _y1 + x # x is epsilon\n\n\ndf3=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df3)\n\n\n_simul.fit3(ymin=-10,ymax=45)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#시도-4",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#시도-4",
    "title": "Simulation",
    "section": "시도 4",
    "text": "시도 4\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\n# _x = np.linspace(0,2,1000)\n# _y1 = 5*np.sin(_x) \n# _y = _y1 + x # x is epsilon\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df4)\n\n\n_simul.fit3(ref=10,ymin=-15,ymax=10)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#시도-5",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#시도-5",
    "title": "Simulation",
    "section": "시도 5",
    "text": "시도 5\n\n# _x = np.linspace(0,2,1000)\n# _y1 =  3*np.cos(_x) + 1*np.cos(_x**2) + 0.5*np.cos(5*_x) \n# _y = _y1 + x # x is epsilon\n\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df5)\n\n\n_simul.fit3(ref=15,ymin=-10,ymax=15,cuts=5)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-1",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-1",
    "title": "Simulation",
    "section": "3D 시도 1",
    "text": "3D 시도 1\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,6*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,3*pi,n))\nf = f1 + x\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=200)  # Make figure object \n\n# 2. \nax=p.add_subplot(1,1,1, projection='3d')\nax.grid(False)\nax.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = f\nbottom = np.zeros_like(top)\nwidth=depth=0.05\n#ax.bar3d(vx, vy, bottom, width, depth, top, shade=False)\nax.scatter3D(vx,vy,f,zdir='z',s=10,marker='.')\nax.scatter3D(vx,vy,f1,zdir='z',s=10,marker='.')\nax.bar3d(vx, vy, bottom, width, depth, 0, color='Black',shade=False)\nax.set_xlim(-3,3)\nax.set_ylim(-3,3)\nax.set_zlim(-10,10)\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig, axs = plt.subplots(2,2,figsize=(16,16),subplot_kw={\"projection\":\"3d\"})\n        axs[0,0].grid(False)\n        axs[0,0].scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[0,0].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[0,0].set_xlim(-3,3)\n        axs[0,0].set_ylim(-3,3)\n        axs[0,0].set_zlim(-10,10)\n        axs[0,0].view_init(elev=20., azim=40)\n        \n        axs[0,1].grid(False)\n        axs[0,1].scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[0,1].plot3D(self.x,self.y,self.f1,'blue')\n        axs[0,1].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[0,1].set_xlim(-3,3)\n        axs[0,1].set_ylim(-3,3)\n        axs[0,1].set_zlim(-10,10)\n        axs[0,1].view_init(elev=20., azim=40)\n        \n        axs[1,0].grid(False)\n        axs[1,0].scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        axs[1,0].plot3D(self.x,self.y,self.f1,'blue')\n        axs[1,0].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[1,0].set_xlim(-3,3)\n        axs[1,0].set_ylim(-3,3)\n        axs[1,0].set_zlim(-10,10)\n        axs[1,0].view_init(elev=20., azim=40)\n        \n        axs[1,1].grid(False)\n        axs[1,1].scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[1,1].scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[1,1].scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        axs[1,1].plot3D(self.x,self.y,self.f1,'black')\n        axs[1,1].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[1,1].set_xlim(-3,3)\n        axs[1,1].set_ylim(-3,3)\n        axs[1,1].set_zlim(-10,10)\n        axs[1,1].view_init(elev=20., azim=40)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # p = plt.figure(figsize=(16,16))\n        # ax = p.add_subplot(1,1,1, projection='3d')\n        # ax.grid(False)\n        # ax.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\n        # ax.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\n        # ax.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\n        # ax.scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        # ax.scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        # #ax.plot3D(self.x,self.y,self.fhat,'black')\n        # ax.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        # ax.plot3D(self.x,self.y,self.f1,'black')\n        # ax.plot3D(self.x,self.y,[0]*1000,'black')\n        # ax.set_xlim(-3,3)\n        # ax.set_ylim(-3,3)\n        # ax.set_zlim(-10,10)\n    def vis(self,ref=60):\n        fig = go.Figure()\n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2)\n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2)\n        #fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.fhat,mode='lines',line_color='#000000'))\n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'))\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'))\n        fig.update_layout(width=1000,height=1000,autosize=False,margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def sub(self):\n        fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n        axs[0,0].plot(_simul.power)\n        axs[0,0].plot(_simul.power_threshed)\n        axs[0,0].set_title('power_threshed')\n\n        axs[0,1].plot(_simul.power[1:])\n        axs[0,1].plot(_simul.power_threshed[1:])\n        axs[0,1].set_title('power_threshed 1:')\n\n        axs[1,0].plot(_simul.power[2:])\n        axs[1,0].plot(_simul.power_threshed[2:])\n        axs[1,0].set_title('power_threshed 2:')\n\n        axs[1,1].plot((_simul.df.Residual)**2)\n        axs[1,1].set_title('Residual square')\n\n        plt.tight_layout()\n        plt.show()\n    def subvis(self,ref=60):\n        fig = make_subplots(2,2,specs=[[{'type': 'surface'}, {'type': 'surface'}],[{'type': 'surface'}, {'type': 'surface'}]],subplot_titles=(\"f\", \"fhat\", \"Residual Square\", \"Graph\"))\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2,row=1,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=1,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=1,col=1)\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2,row=1,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=1,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=1,col=2)\n        \n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=2,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=2,col=1)\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2,row=2,col=2)        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2,row=2,col=2)        \n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=2,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=2,col=2)\n        \n        fig.update_layout(scene = dict(xaxis = dict(range=[-3,3],),\n                                         yaxis = dict(range=[-3,3],),\n                                         zaxis = dict(range=[-10,10],),),\n                                      width=1000,height=1000,autosize=False)\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\n_simul = SIMUL(df)\n\n\n_simul.get_distance()\n\n100%|██████████| 1000/1000 [00:01<00:00, 532.20it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6888234729389295\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 66308.,  64352.,  68358., 177302., 166964., 114648.,  94344.,\n        111136.,  75508.,  60080.]),\n array([0.00628415, 0.54637775, 1.08647135, 1.62656495, 2.16665855,\n        2.70675214, 3.24684574, 3.78693934, 4.32703294, 4.86712654,\n        5.40722013]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6888234729389295),kappa=2500) \n\n\n_simul.fit(sd=5,ref=20)\n\n\n\n\n\n#_simul.vis(ref=20)\n\n\n#_simul.subvis(ref=20)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-2",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-2",
    "title": "Simulation",
    "section": "3D 시도 2",
    "text": "3D 시도 2\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,8*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,3*pi,n))\nf = f1 + x\n\n\ndf1 = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f,'f1':f1})\n\n\n_simul = SIMUL(df1)\n\n\n_simul.get_distance()\n\n100%|██████████| 1000/1000 [00:01<00:00, 521.69it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6984753461932702\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 63450.,  64118., 146970., 169756., 138202., 126198., 162650.,\n         75642.,  28416.,  23598.]),\n array([0.0062838 , 0.60565122, 1.20501864, 1.80438605, 2.40375347,\n        3.00312089, 3.6024883 , 4.20185572, 4.80122314, 5.40059055,\n        5.99995797]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6984753461932702),kappa=2500) \n\n\n_simul.fit(sd=5,ref=30)\n\n\n\n\n\n#_simul.vis(ref=50)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-3",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-시도-3",
    "title": "Simulation",
    "section": "3D 시도 3",
    "text": "3D 시도 3\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,6*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf2 = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f,'f1':f1})\n\n\n_simul = SIMUL(df2)\n\n\n_simul.get_distance()\n\n100%|██████████| 1000/1000 [00:02<00:00, 463.80it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6888234729389295\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 66308.,  64352.,  68358., 177302., 166964., 114648.,  94344.,\n        111136.,  75508.,  60080.]),\n array([0.00628415, 0.54637775, 1.08647135, 1.62656495, 2.16665855,\n        2.70675214, 3.24684574, 3.78693934, 4.32703294, 4.86712654,\n        5.40722013]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6984753461932702),kappa=2500) \n\n\n_simul.fit(sd=5,ref=30)\n\n\n\n\n\n#_simul.vis(ref=50)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html",
    "title": "Earthquake",
    "section": "",
    "text": "Real analysis"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#imports",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#imports",
    "title": "Earthquake",
    "section": "imports",
    "text": "imports\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\nimport plotly.graph_objects as go\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#load-data-and-clean-it",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#load-data-and-clean-it",
    "title": "Earthquake",
    "section": "load data and clean it",
    "text": "load data and clean it\n- load\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n    \n  \n\n23412 rows × 4 columns\n\n\n\n\ndf_korea= pd.read_csv('earthquake_korea2.csv').iloc[:,[1,2,5,6]].rename(columns={'규모':'Magnitude'})\n\nhttps://www.weather.go.kr/w/eqk-vol/search/korea.do?schOption=&xls=0&startTm=2012-01-02&endTm=2022-06-17&startSize=2&endSize=&startLat=&endLat=&startLon=&endLon=&lat=&lon=&dist=&keyword=&dpType=m\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\nhttps://www.usgs.gov/programs/earthquake-hazards/lists-maps-and-statistics\n- cleaning\n\ndf.Date[df.Date == '1975-02-23T02:58:41.000Z']\n\n3378    1975-02-23T02:58:41.000Z\nName: Date, dtype: object\n\n\n\ndf.iloc[3378,0] = '02/03/1975'\n\n\ndf.Date[df.Date == '1985-04-28T02:53:41.530Z']\n\n7512    1985-04-28T02:53:41.530Z\nName: Date, dtype: object\n\n\n\ndf.iloc[7512,0] = '04/28/1985'\n\n\ndf.Date[df.Date == '2011-03-13T02:23:34.520Z']\n\n20650    2011-03-13T02:23:34.520Z\nName: Date, dtype: object\n\n\n\ndf.iloc[20650,0] = '03/13/2011'\n\n\ndf= df.assign(Year=list(map(lambda x: x.split('/')[-1], df.Date))).iloc[:,1:]\ndf\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows × 4 columns\n\n\n\n\ndf.Year = df.Year.astype(np.float64)\n\n\ndf_korea = df_korea.assign(Year=list(map(lambda x: x.split('/')[0], df_korea.발생시각))).iloc[:,1:]\ndf_korea = df_korea.assign(Latitude=list(map(lambda x: x.split(' ')[0], df_korea.위도))).iloc[:,[0,2,3,4]]\ndf_korea = df_korea.assign(Longitude=list(map(lambda x: x.split(' ')[0], df_korea.경도))).iloc[:,[0,2,3,4]]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_korea.Year = df_korea.Year.astype(np.float64)\ndf_korea.Latitude = df_korea.Latitude.astype(np.float64)\ndf_korea.Longitude = df_korea.Longitude.astype(np.float64)\ndf_global.Year = df_global.Year.astype(np.float64)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#define-class",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#define-class",
    "title": "Earthquake",
    "section": "define class",
    "text": "define class\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n        \n    def vis(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.4,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'red',\n                      opacity = 0.6\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.5\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visf(self):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visfhat(self):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='MagnitudeHat', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visres(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z=[0] * len(self.df), \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.7\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh 기능추가\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n        #plt.plot(self.f,'.')\n        #plt.plot(self.fhat,'x')\n\n#         fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n#         axs[0,0].plot(self.f,'b')\n#         axs[0,0].set_title('Magnitude')\n#         axs[0,0].set_ylim([4.5,9])\n\n#         axs[0,1].plot(self.fhat,'k')\n#         axs[0,1].set_title('MagnitudeHat')\n#         axs[0,1].set_ylim([4.5,9])\n\n#         axs[1,0].plot(self.con,'r*')\n#         axs[1,0].set_title('Residual square')\n\n#         axs[1,1].plot(self.f,'b')\n#         axs[1,1].plot(self.fhat,'k')\n#         axs[1,1].plot(self.con,'r*')\n#         axs[1,1].set_title('Graph')\n#         axs[1,1].set_ylim([4.5,9])\n\n#         plt.tight_layout()\n#         plt.show()\n\n\nclass MooYaHo3(MooYaHo2):\n    def vis(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=126), \n                        zoom=5.7,\n                        height=900,\n                        opacity = 0.3,\n                        mapbox_style=\"stamen-terrain\")\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'red',\n                      opacity = 0.5\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.5\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\n       ebayesthresh = importr('EbayesThresh').ebayesthresh"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20102015",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20102015",
    "title": "Earthquake",
    "section": "analysis_df_global(2010~2015)",
    "text": "analysis_df_global(2010~2015)\n- make instance for analysis\n\nmoo_global=MooYaHo2(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\nmoo_global.get_distance()\n\n100%|██████████| 10762/10762 [05:32<00:00, 32.36it/s] \n\n\n\nmoo_global.D[moo_global.D>0].mean()\n\n8746.68756693945\n\n\n\nplt.hist(moo_global.D[moo_global.D>0])\n\n(array([10857854., 11686138., 15883516., 16913862., 14592080., 12938904.,\n        11847394.,  9636694.,  9649504.,  1799146.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\nmoo_global.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\nmoo_global.fit2()\n\n\nmoo_global.df.sort_values(\"Residual\",ascending=False).iloc[:40,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      30311\n      38.2970\n      142.3730\n      9.1\n      2011.0\n      7.625067\n      1.474933\n    \n    \n      11094\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.638469\n      1.161531\n    \n    \n      32803\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.789231\n      1.010769\n    \n    \n      32436\n      -36.2170\n      -73.2570\n      6.7\n      2010.0\n      5.841501\n      0.858499\n    \n    \n      26564\n      14.1290\n      -92.1640\n      6.5\n      2012.0\n      5.653542\n      0.846458\n    \n    \n      27513\n      0.8020\n      92.4630\n      8.2\n      2012.0\n      7.368113\n      0.831887\n    \n    \n      30347\n      38.4350\n      142.8420\n      7.3\n      2011.0\n      6.490603\n      0.809397\n    \n    \n      30296\n      36.2810\n      141.1110\n      7.9\n      2011.0\n      7.156346\n      0.743654\n    \n    \n      10292\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.766319\n      0.733681\n    \n    \n      9193\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.667897\n      0.732103\n    \n    \n      32554\n      -36.6650\n      -73.3740\n      6.6\n      2010.0\n      5.873441\n      0.726559\n    \n    \n      30301\n      38.9690\n      143.3700\n      6.7\n      2011.0\n      5.984234\n      0.715766\n    \n    \n      32001\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.793936\n      0.706064\n    \n    \n      31229\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.100594\n      0.699406\n    \n    \n      28229\n      37.3650\n      141.3680\n      6.1\n      2011.0\n      5.403952\n      0.696048\n    \n    \n      9283\n      -56.4120\n      -25.7410\n      6.3\n      2010.0\n      5.607381\n      0.692619\n    \n    \n      9520\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.111591\n      0.688409\n    \n    \n      30827\n      -19.7020\n      167.9470\n      7.3\n      2010.0\n      6.615744\n      0.684256\n    \n    \n      30295\n      36.0230\n      142.2690\n      6.6\n      2011.0\n      5.917664\n      0.682336\n    \n    \n      27456\n      2.5810\n      90.2690\n      6.2\n      2012.0\n      5.521275\n      0.678725\n    \n    \n      30017\n      37.5940\n      142.6480\n      6.5\n      2011.0\n      5.828617\n      0.671383\n    \n    \n      10135\n      -22.1460\n      -68.2160\n      6.3\n      2010.0\n      5.631982\n      0.668018\n    \n    \n      24958\n      -60.2738\n      -46.4011\n      7.7\n      2013.0\n      7.041204\n      0.658796\n    \n    \n      10783\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.241810\n      0.658190\n    \n    \n      29019\n      -29.3370\n      -177.0510\n      6.0\n      2011.0\n      5.347355\n      0.652645\n    \n    \n      32492\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.250075\n      0.649925\n    \n    \n      30902\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.758872\n      0.641128\n    \n    \n      28931\n      52.8810\n      108.4400\n      5.3\n      2011.0\n      4.661692\n      0.638308\n    \n    \n      29004\n      38.0340\n      143.2640\n      7.0\n      2011.0\n      6.368649\n      0.631351\n    \n    \n      30992\n      -56.4120\n      -25.7410\n      6.3\n      2010.0\n      5.680727\n      0.619273\n    \n    \n      30893\n      27.2030\n      143.4550\n      5.3\n      2010.0\n      4.681926\n      0.618074\n    \n    \n      9665\n      -4.9630\n      133.7600\n      7.0\n      2010.0\n      6.382904\n      0.617096\n    \n    \n      29640\n      38.2760\n      141.5880\n      7.1\n      2011.0\n      6.485066\n      0.614934\n    \n    \n      26354\n      55.2280\n      -134.8591\n      7.5\n      2013.0\n      6.890518\n      0.609482\n    \n    \n      27527\n      2.3270\n      93.0630\n      8.6\n      2012.0\n      7.992761\n      0.607239\n    \n    \n      25452\n      -60.8570\n      -25.0700\n      7.3\n      2013.0\n      6.693727\n      0.606273\n    \n    \n      29536\n      -10.3750\n      161.2000\n      6.8\n      2011.0\n      6.197847\n      0.602153\n    \n    \n      26468\n      37.8900\n      143.9490\n      7.3\n      2012.0\n      6.698942\n      0.601058\n    \n    \n      32231\n      -15.2710\n      -173.2190\n      6.1\n      2010.0\n      5.502608\n      0.597392\n    \n    \n      26234\n      -11.1830\n      164.8820\n      7.1\n      2013.0\n      6.507029\n      0.592971\n    \n  \n\n\n\n\n(2010~2014 시도) - 21번째 Ouest Department, Haiti 아이티 지진 2010년 진도 7.0 - 24번째 Puchuncavi, Valparaíso, Chile 칠레 지진 2014년 진도 6.4 - 28번째 Baoxing County, Yaan, Sichuan, China 중국 쓰촨성 지진 2013년 진도 6.6\n(2010~2015 시도_결과 좋지 않음?!) - 23번째 2010년 West New Britain Province, Papua New Guinea 진도 7.3 - 24번째 2011년 Kuzawa Terayama, Tanagura, Higashishirakawa District, Fukushima 963-5671, Japan 진도 6.6 - 29번째 2015년 Kishim, Afghanistan 진도 7.5\n- vis\n\n#moo_global.visf()\n\n\n#moo_global.visfhat()\n\n\n#moo_global.visres()\n\n\n#moo_global.vis(MagThresh=6.9,ResThresh=0.5)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20152020",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20152020",
    "title": "Earthquake",
    "section": "analysis_df_global(2015~2020)",
    "text": "analysis_df_global(2015~2020)\n- make instance for analysis\n\nmoo_global=MooYaHo2(df_global.query(\"2015 <= Year <= 2020\"))\n\n- get distance\n\nmoo_global.get_distance()\n\n100%|██████████| 11239/11239 [04:35<00:00, 40.84it/s] \n\n\n\nmoo_global.D[moo_global.D>0].mean()\n\n8814.318793468068\n\n\n\nplt.hist(moo_global.D[moo_global.D>0])\n\n(array([10894274., 13618924., 16426520., 17583818., 16025000., 15684642.,\n        13794372., 10946494.,  9072574.,  2254138.]),\n array([2.54728455e-02, 2.00123511e+03, 4.00244475e+03, 6.00365439e+03,\n        8.00486402e+03, 1.00060737e+04, 1.20072833e+04, 1.40084929e+04,\n        1.60097026e+04, 1.80109122e+04, 2.00121218e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\nmoo_global.get_weightmatrix(theta=(8814.318793468068),kappa=2500) \n\n- fit\n\nmoo_global.fit2()\n\n\nmoo_global.df.sort_values(\"Residual\",ascending=False).iloc[:30,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      21952\n      -31.5729\n      -71.6744\n      8.3\n      2015.0\n      7.294011\n      1.005989\n    \n    \n      36363\n      -21.9496\n      169.4266\n      7.5\n      2018.0\n      6.523828\n      0.976172\n    \n    \n      36993\n      -18.1125\n      -178.1530\n      8.2\n      2018.0\n      7.311720\n      0.888280\n    \n    \n      39932\n      -42.7373\n      173.0540\n      7.8\n      2016.0\n      6.951928\n      0.848072\n    \n    \n      36263\n      55.0999\n      164.6993\n      7.3\n      2018.0\n      6.470796\n      0.829204\n    \n    \n      35004\n      -30.1733\n      -177.8625\n      6.1\n      2019.0\n      5.285797\n      0.814203\n    \n    \n      41015\n      -4.9521\n      94.3299\n      7.8\n      2016.0\n      6.993888\n      0.806112\n    \n    \n      21719\n      -8.3381\n      124.8754\n      6.5\n      2015.0\n      5.698526\n      0.801474\n    \n    \n      33404\n      54.6020\n      -159.6258\n      7.6\n      2020.0\n      6.819466\n      0.780534\n    \n    \n      41735\n      -31.5729\n      -71.6744\n      8.3\n      2015.0\n      7.547595\n      0.752405\n    \n    \n      40113\n      -19.7819\n      -178.2443\n      6.9\n      2016.0\n      6.148672\n      0.751328\n    \n    \n      41695\n      -31.5173\n      -71.8040\n      6.7\n      2015.0\n      5.951922\n      0.748078\n    \n    \n      37927\n      56.0039\n      -149.1658\n      7.9\n      2018.0\n      7.170056\n      0.729944\n    \n    \n      36848\n      -18.4743\n      179.3502\n      7.9\n      2018.0\n      7.173844\n      0.726156\n    \n    \n      21945\n      -31.5622\n      -71.4262\n      7.0\n      2015.0\n      6.291422\n      0.708578\n    \n    \n      41502\n      -8.3381\n      124.8754\n      6.5\n      2015.0\n      5.812161\n      0.687839\n    \n    \n      33896\n      -33.2927\n      -177.8571\n      7.4\n      2020.0\n      6.715142\n      0.684858\n    \n    \n      22560\n      -5.4912\n      151.8715\n      6.0\n      2015.0\n      5.316904\n      0.683096\n    \n    \n      39584\n      -43.4064\n      -73.9413\n      7.6\n      2016.0\n      6.921775\n      0.678225\n    \n    \n      36777\n      -25.4150\n      178.1991\n      6.5\n      2018.0\n      5.833282\n      0.666718\n    \n    \n      35487\n      -30.6441\n      -178.0995\n      7.3\n      2019.0\n      6.638342\n      0.661658\n    \n    \n      39771\n      -10.6812\n      161.3273\n      7.8\n      2016.0\n      7.145371\n      0.654629\n    \n    \n      38827\n      -30.5156\n      -178.0563\n      6.0\n      2017.0\n      5.351325\n      0.648675\n    \n    \n      41963\n      52.3760\n      -169.4458\n      6.9\n      2015.0\n      6.256523\n      0.643477\n    \n    \n      22488\n      27.8087\n      86.0655\n      7.3\n      2015.0\n      6.662980\n      0.637020\n    \n    \n      21795\n      -54.4856\n      -135.7080\n      6.1\n      2015.0\n      5.468025\n      0.631975\n    \n    \n      22839\n      -10.7598\n      164.1216\n      6.1\n      2015.0\n      5.468139\n      0.631861\n    \n    \n      41423\n      38.6700\n      20.6000\n      6.5\n      2015.0\n      5.874436\n      0.625564\n    \n    \n      36101\n      -30.0404\n      -71.3815\n      6.7\n      2019.0\n      6.081398\n      0.618602\n    \n    \n      36602\n      -21.7427\n      169.5217\n      6.5\n      2018.0\n      5.882525\n      0.617475\n    \n  \n\n\n\n\n바다 아닌 거 - 8번째 2016년 Rotherham, New Zealand 뉴질랜드 카이코우라 지진 진도 7.8 - 9번째 2015년 Langkuru Utara, Pureman, Alor Regency, East Nusa Tenggara, Indonesia 수마트라 진도 6.5 - 15번째 2018년 Hela Province, Papua New Guinea 파푸아뉴기니 진도 7.5 - 20번째 2015년 Kalinchok, Nepal 네팔 진도 7.3 - 26번째 2019년 Coquimbo, Chile 칠레 코킴보주 진도 6.7\n- vis\n\n#moo_global.vis(MagThresh=7,ResThresh=0.3)\n\n\n\npd.read_html('https://en.wikipedia.org/wiki/Lists_of_21st-century_earthquakes',encoding='utf-8')[0].query('Magnitude<=7')# List of deadliest earthquakes\n\n\npd.read_html('https://en.wikipedia.org/wiki/Lists_of_21st-century_earthquakes',encoding='utf-8')[3] # Deadliest earthquakes by year\n\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\neach_location.get_distance()\n\n100%|██████████| 12498/12498 [05:55<00:00, 35.16it/s] \n\n\n\neach_location.D[each_location.D>0].mean()\n\n8810.865423093777\n\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n(array([14176290., 16005894., 21186674., 22331128., 19394182., 17548252.,\n        16668048., 13316436., 12973260.,  2582550.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5)\n\n\n                                                \n\n\n\neach_location.lquique(MagThresh=8,ResThresh=0.4,adjzoom=4.3)\n\n\n                                                \n\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#칠레",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#칠레",
    "title": "Earthquake",
    "section": "칠레",
    "text": "칠레\n\ndf_chile_ex= pd.concat([pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_chile = df_chile_ex.assign(Year=list(map(lambda x: x.split('-')[0], df_chile_ex.time))).iloc[:,1:]\n\n\ndf_chile = df_chile.assign(Month=list(map(lambda x: x.split('-')[1], df_chile_ex.time)))\n\n\ndf_chile.Year = df_chile.Year.astype(np.float64)\ndf_chile.Month = df_chile.Month.astype(np.float64)\n\n\nchile_location=eachlocation(df_chile.query(\"2010 <= Year < 2015\"))\n\n\nchile_location.get_distance()\n\n100%|██████████| 12498/12498 [06:28<00:00, 32.19it/s] \n\n\n\nchile_location.get_weightmatrix(theta=(chile_location.D[chile_location.D>0].mean()),kappa=2500) \n\n\nchile_location.fit2()\n\n아이티\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().iloc[2324:2330,:]\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      2324\n      2324\n      18.463\n      -72.626\n      5.0\n      2010.0\n      1.0\n      5.105168\n      -0.105168\n      0.011060\n    \n    \n      2325\n      2325\n      18.387\n      -72.784\n      6.0\n      2010.0\n      1.0\n      5.703460\n      0.296540\n      0.087936\n    \n    \n      2326\n      2326\n      18.443\n      -72.571\n      7.0\n      2010.0\n      1.0\n      6.659386\n      0.340614\n      0.116018\n    \n    \n      2327\n      2327\n      -5.417\n      133.731\n      5.5\n      2010.0\n      1.0\n      5.604103\n      -0.104103\n      0.010837\n    \n    \n      2328\n      2328\n      15.437\n      -88.761\n      5.1\n      2010.0\n      1.0\n      4.964642\n      0.135358\n      0.018322\n    \n    \n      2329\n      2329\n      -16.861\n      -174.228\n      5.3\n      2010.0\n      1.0\n      5.340902\n      -0.040902\n      0.001673\n    \n  \n\n\n\n\n칠레\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().query(\"-56.5 < Latitude & Latitude <-17.4 & -81.5 < Longitude & Longitude < -61.5 & Year == 2014 & Month == 8\")\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      2997\n      14603\n      -32.6953\n      -71.4416\n      6.4\n      2014.0\n      8.0\n      6.088353\n      0.311647\n      0.097124\n    \n    \n      2999\n      14605\n      -20.1745\n      -69.0385\n      5.6\n      2014.0\n      8.0\n      5.553419\n      0.046581\n      0.002170\n    \n    \n      3032\n      14638\n      -20.1580\n      -70.0230\n      5.3\n      2014.0\n      8.0\n      5.251934\n      0.048066\n      0.002310\n    \n    \n      3046\n      14652\n      -23.9047\n      -66.7371\n      5.0\n      2014.0\n      8.0\n      5.210380\n      -0.210380\n      0.044260\n    \n    \n      3057\n      14663\n      -33.7770\n      -72.2030\n      5.2\n      2014.0\n      8.0\n      5.065422\n      0.134578\n      0.018111\n    \n  \n\n\n\n\n중국\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().iloc[5136:5142,:]\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      5136\n      16742\n      30.209\n      102.862\n      5.0\n      2013.0\n      4.0\n      4.943022\n      0.056978\n      0.003247\n    \n    \n      5137\n      16743\n      30.308\n      102.888\n      6.6\n      2013.0\n      4.0\n      5.904218\n      0.695782\n      0.484113\n    \n    \n      5138\n      16744\n      39.693\n      143.258\n      5.0\n      2013.0\n      4.0\n      5.118611\n      -0.118611\n      0.014068\n    \n    \n      5139\n      16745\n      49.965\n      157.652\n      6.1\n      2013.0\n      4.0\n      5.852776\n      0.247224\n      0.061120\n    \n    \n      5140\n      16746\n      -11.976\n      121.632\n      5.8\n      2013.0\n      4.0\n      5.809708\n      -0.009708\n      0.000094\n    \n    \n      5141\n      16747\n      -14.966\n      166.857\n      5.2\n      2013.0\n      4.0\n      5.145590\n      0.054410\n      0.002960"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html",
    "title": "Comparison Results on Real Data",
    "section": "",
    "text": "Comparison at real data"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html#load-data-and-clean-it",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html#load-data-and-clean-it",
    "title": "Comparison Results on Real Data",
    "section": "load data and clean it",
    "text": "load data and clean it\n- load\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n- cleaning\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\ndf_global_10 = df_global.copy()\ndf_global_10 = df_global_10.query(\"2010 <= Year < 2015\").reset_index().iloc[:,1:];df_global_10\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n    \n  \n\n12498 rows × 4 columns\n\n\n\n\nGODE\n\ngode_global = earthquake_func(df_global_10)\n\n- get distance\n\ngode_global.get_distance()\n\n100%|██████████| 12498/12498 [07:20<00:00, 28.35it/s] \n\n\n\ngode_global.D[gode_global.D>0].mean()\n\n8810.865423093777\n\n\n- weight matrix\n\ngode_global.get_weightmatrix(theta=(gode_global.D[gode_global.D>0].mean()),kappa=2500) \n\n- fit\n\ngode_global.fit()\n\n\n_df = gode_global.df.copy()\n\n\n_df.sort_values(\"Residual\",ascending=False).iloc[:40,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      2064\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.572545\n      1.227455\n    \n    \n      3752\n      -19.6097\n      -70.7691\n      8.2\n      2014.0\n      7.075499\n      1.124501\n    \n    \n      12167\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.742429\n      1.057571\n    \n    \n      9660\n      36.2810\n      141.1110\n      7.9\n      2011.0\n      6.912847\n      0.987153\n    \n    \n      6877\n      0.8020\n      92.4630\n      8.2\n      2012.0\n      7.353106\n      0.846894\n    \n    \n      7938\n      -21.6110\n      -179.5280\n      7.3\n      2011.0\n      6.497713\n      0.802287\n    \n    \n      10593\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.008107\n      0.791893\n    \n    \n      3835\n      -19.9807\n      -70.7022\n      6.7\n      2014.0\n      5.913563\n      0.786437\n    \n    \n      3281\n      -29.9772\n      -177.7247\n      6.9\n      2014.0\n      6.129969\n      0.770031\n    \n    \n      4997\n      -23.0090\n      -177.2320\n      7.4\n      2013.0\n      6.648946\n      0.751054\n    \n    \n      11365\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.759298\n      0.740702\n    \n    \n      3723\n      -20.5709\n      -70.4931\n      7.7\n      2014.0\n      6.991148\n      0.708852\n    \n    \n      490\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.092844\n      0.707156\n    \n    \n      11856\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.197441\n      0.702559\n    \n    \n      6443\n      -21.2220\n      -179.2870\n      5.6\n      2012.0\n      4.900729\n      0.699271\n    \n    \n      9598\n      36.5690\n      141.4860\n      6.2\n      2011.0\n      5.502811\n      0.697189\n    \n    \n      5137\n      30.3080\n      102.8880\n      6.6\n      2013.0\n      5.904218\n      0.695782\n    \n    \n      7772\n      -28.9930\n      -176.2380\n      7.4\n      2011.0\n      6.711309\n      0.688691\n    \n    \n      4881\n      10.7010\n      -42.5940\n      6.6\n      2013.0\n      5.915735\n      0.684265\n    \n    \n      6940\n      -35.2000\n      -72.2170\n      7.1\n      2012.0\n      6.422078\n      0.677922\n    \n    \n      4816\n      -60.8570\n      -25.0700\n      7.3\n      2013.0\n      6.626735\n      0.673265\n    \n    \n      6963\n      16.4930\n      -98.2310\n      7.4\n      2012.0\n      6.727272\n      0.672728\n    \n    \n      8207\n      36.9420\n      140.9550\n      6.3\n      2011.0\n      5.644833\n      0.655167\n    \n    \n      9675\n      38.2970\n      142.3730\n      9.1\n      2011.0\n      8.452726\n      0.647274\n    \n    \n      163\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.758782\n      0.641218\n    \n    \n      7365\n      -10.6170\n      165.1600\n      6.4\n      2012.0\n      5.760128\n      0.639872\n    \n    \n      19\n      -19.6610\n      168.1400\n      6.4\n      2010.0\n      5.761124\n      0.638876\n    \n    \n      7739\n      -17.9410\n      -179.5310\n      6.0\n      2011.0\n      5.361437\n      0.638563\n    \n    \n      8787\n      -20.1290\n      168.2570\n      5.3\n      2011.0\n      4.674700\n      0.625300\n    \n    \n      5447\n      -10.9940\n      165.7410\n      6.6\n      2013.0\n      5.975600\n      0.624400\n    \n    \n      8094\n      -18.3650\n      168.1430\n      7.2\n      2011.0\n      6.578651\n      0.621349\n    \n    \n      2699\n      -19.6903\n      -177.7587\n      7.1\n      2014.0\n      6.485400\n      0.614600\n    \n    \n      1751\n      -34.3260\n      -71.7990\n      7.0\n      2010.0\n      6.386349\n      0.613651\n    \n    \n      12429\n      18.4430\n      -72.5710\n      7.0\n      2010.0\n      6.386632\n      0.613368\n    \n    \n      6307\n      2.1900\n      126.8370\n      6.6\n      2012.0\n      5.993919\n      0.606081\n    \n    \n      9366\n      40.0820\n      143.2020\n      5.7\n      2011.0\n      5.096812\n      0.603188\n    \n    \n      9867\n      -7.1540\n      155.1840\n      6.4\n      2011.0\n      5.798634\n      0.601366\n    \n    \n      1753\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.310787\n      0.589213\n    \n    \n      9050\n      -16.5410\n      -177.5170\n      6.3\n      2011.0\n      5.717719\n      0.582281\n    \n    \n      11823\n      -37.5510\n      -73.4650\n      5.8\n      2010.0\n      5.219236\n      0.580764\n    \n  \n\n\n\n\n\noutlier_simul_one = (_df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 0.04 else 1,outlier_simul_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one)],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n    \n  \n\n12498 rows × 8 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_gode)\n\n\n_conf.conf(\"GODE\")\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\nlof_rst = clf.fit_predict(_df)\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n    \n  \n\n12498 rows × 9 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['Latitude', 'Longitude','Magnitude']])\n# _df['knn_clf'] = clf.labels_\n\nKNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n  radius=1.0)\n\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n    \n  \n\n12498 rows × 10 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(df_global_10[['Latitude', 'Longitude','Magnitude']])\ndf_global_10['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\noutlier_CBLOF_one_t = pd.DataFrame([outlier_CBLOF_one]).T.rename(columns={0:'CBLOF'});outlier_CBLOF_one_t\n\n\n\n\n\n  \n    \n      \n      CBLOF\n    \n  \n  \n    \n      0\n      1\n    \n    \n      1\n      1\n    \n    \n      2\n      1\n    \n    \n      3\n      1\n    \n    \n      4\n      1\n    \n    \n      ...\n      ...\n    \n    \n      12493\n      1\n    \n    \n      12494\n      1\n    \n    \n      12495\n      1\n    \n    \n      12496\n      1\n    \n    \n      12497\n      1\n    \n  \n\n12498 rows × 1 columns\n\n\n\n\n# outlier_CBLOF_one_t.to_csv('outlier_CBLOF_one.csv',index=False)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(_df)\n\nOneClassSVM(gamma=0.1, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(_df))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n    \n  \n\n12498 rows × 11 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch ̈olkopf et al., 2001)\")\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['MCD_clf'] = clf.labels_\n\nMCD(assume_centered=False, contamination=0.1, random_state=None,\n  store_precision=True, support_fraction=None)\n\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n    \n  \n\n12498 rows × 12 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['FeatureBagging_clf'] = clf.labels_\n\nFeatureBagging(base_estimator=None, bootstrap_features=False,\n        check_detector=True, check_estimator=False, combination='average',\n        contamination=0.1, estimator_params={}, max_features=1.0,\n        n_estimators=10, n_jobs=1, random_state=None, verbose=0)\n\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 13 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['ABOD_Clf'] = clf.labels_\n\nABOD(contamination=0.05, method='fast', n_neighbors=5)\n\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 14 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['Latitude','Longitude','Magnitude']])\n\n\npreds = od.predict(\n    _df[['Latitude','Longitude','Magnitude']],\n    return_instance_score=True\n)\n\n\n# _df['IF_alibi'] = preds['data']['is_outlier']\n\n\n# outlier_alibi_one = _df['IF_alibi']\noutlier_alibi_one = preds['data']['is_outlier']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 15 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['HBOS_clf'] = clf.labels_\n\nHBOS(alpha=0.1, contamination=0.1, n_bins=10, tol=0.5)\n\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 16 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['SOS_clf'] = clf.labels_\n\nSOS(contamination=0.1, eps=1e-05, metric='euclidean', perplexity=4.5)\n\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 17 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\n\nTesting for epoch 1 index 6:\n\nTesting for epoch 1 index 7:\n\nTesting for epoch 1 index 8:\n\nTesting for epoch 1 index 9:\n\nTesting for epoch 1 index 10:\n\nTesting for epoch 1 index 11:\n\nTesting for epoch 1 index 12:\n\nTesting for epoch 1 index 13:\n\nTesting for epoch 1 index 14:\n\nTesting for epoch 1 index 15:\n\nTesting for epoch 1 index 16:\n\nTesting for epoch 1 index 17:\n\nTesting for epoch 1 index 18:\n\nTesting for epoch 1 index 19:\n\nTesting for epoch 1 index 20:\n\nTesting for epoch 1 index 21:\n\nTesting for epoch 1 index 22:\n\nTesting for epoch 1 index 23:\n\nTesting for epoch 1 index 24:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\n\nTesting for epoch 2 index 6:\n\nTesting for epoch 2 index 7:\n\nTesting for epoch 2 index 8:\n\nTesting for epoch 2 index 9:\n\nTesting for epoch 2 index 10:\n\nTesting for epoch 2 index 11:\n\nTesting for epoch 2 index 12:\n\nTesting for epoch 2 index 13:\n\nTesting for epoch 2 index 14:\n\nTesting for epoch 2 index 15:\n\nTesting for epoch 2 index 16:\n\nTesting for epoch 2 index 17:\n\nTesting for epoch 2 index 18:\n\nTesting for epoch 2 index 19:\n\nTesting for epoch 2 index 20:\n\nTesting for epoch 2 index 21:\n\nTesting for epoch 2 index 22:\n\nTesting for epoch 2 index 23:\n\nTesting for epoch 2 index 24:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\n\nTesting for epoch 3 index 6:\n\nTesting for epoch 3 index 7:\n\nTesting for epoch 3 index 8:\n\nTesting for epoch 3 index 9:\n\nTesting for epoch 3 index 10:\n\nTesting for epoch 3 index 11:\n\nTesting for epoch 3 index 12:\n\nTesting for epoch 3 index 13:\n\nTesting for epoch 3 index 14:\n\nTesting for epoch 3 index 15:\n\nTesting for epoch 3 index 16:\n\nTesting for epoch 3 index 17:\n\nTesting for epoch 3 index 18:\n\nTesting for epoch 3 index 19:\n\nTesting for epoch 3 index 20:\n\nTesting for epoch 3 index 21:\n\nTesting for epoch 3 index 22:\n\nTesting for epoch 3 index 23:\n\nTesting for epoch 3 index 24:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\n\nTesting for epoch 4 index 6:\n\nTesting for epoch 4 index 7:\n\nTesting for epoch 4 index 8:\n\nTesting for epoch 4 index 9:\n\nTesting for epoch 4 index 10:\n\nTesting for epoch 4 index 11:\n\nTesting for epoch 4 index 12:\n\nTesting for epoch 4 index 13:\n\nTesting for epoch 4 index 14:\n\nTesting for epoch 4 index 15:\n\nTesting for epoch 4 index 16:\n\nTesting for epoch 4 index 17:\n\nTesting for epoch 4 index 18:\n\nTesting for epoch 4 index 19:\n\nTesting for epoch 4 index 20:\n\nTesting for epoch 4 index 21:\n\nTesting for epoch 4 index 22:\n\nTesting for epoch 4 index 23:\n\nTesting for epoch 4 index 24:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\n\nTesting for epoch 5 index 6:\n\nTesting for epoch 5 index 7:\n\nTesting for epoch 5 index 8:\n\nTesting for epoch 5 index 9:\n\nTesting for epoch 5 index 10:\n\nTesting for epoch 5 index 11:\n\nTesting for epoch 5 index 12:\n\nTesting for epoch 5 index 13:\n\nTesting for epoch 5 index 14:\n\nTesting for epoch 5 index 15:\n\nTesting for epoch 5 index 16:\n\nTesting for epoch 5 index 17:\n\nTesting for epoch 5 index 18:\n\nTesting for epoch 5 index 19:\n\nTesting for epoch 5 index 20:\n\nTesting for epoch 5 index 21:\n\nTesting for epoch 5 index 22:\n\nTesting for epoch 5 index 23:\n\nTesting for epoch 5 index 24:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\n\nTesting for epoch 6 index 6:\n\nTesting for epoch 6 index 7:\n\nTesting for epoch 6 index 8:\n\nTesting for epoch 6 index 9:\n\nTesting for epoch 6 index 10:\n\nTesting for epoch 6 index 11:\n\nTesting for epoch 6 index 12:\n\nTesting for epoch 6 index 13:\n\nTesting for epoch 6 index 14:\n\nTesting for epoch 6 index 15:\n\nTesting for epoch 6 index 16:\n\nTesting for epoch 6 index 17:\n\nTesting for epoch 6 index 18:\n\nTesting for epoch 6 index 19:\n\nTesting for epoch 6 index 20:\n\nTesting for epoch 6 index 21:\n\nTesting for epoch 6 index 22:\n\nTesting for epoch 6 index 23:\n\nTesting for epoch 6 index 24:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\n\nTesting for epoch 7 index 6:\n\nTesting for epoch 7 index 7:\n\nTesting for epoch 7 index 8:\n\nTesting for epoch 7 index 9:\n\nTesting for epoch 7 index 10:\n\nTesting for epoch 7 index 11:\n\nTesting for epoch 7 index 12:\n\nTesting for epoch 7 index 13:\n\nTesting for epoch 7 index 14:\n\nTesting for epoch 7 index 15:\n\nTesting for epoch 7 index 16:\n\nTesting for epoch 7 index 17:\n\nTesting for epoch 7 index 18:\n\nTesting for epoch 7 index 19:\n\nTesting for epoch 7 index 20:\n\nTesting for epoch 7 index 21:\n\nTesting for epoch 7 index 22:\n\nTesting for epoch 7 index 23:\n\nTesting for epoch 7 index 24:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\n\nTesting for epoch 8 index 6:\n\nTesting for epoch 8 index 7:\n\nTesting for epoch 8 index 8:\n\nTesting for epoch 8 index 9:\n\nTesting for epoch 8 index 10:\n\nTesting for epoch 8 index 11:\n\nTesting for epoch 8 index 12:\n\nTesting for epoch 8 index 13:\n\nTesting for epoch 8 index 14:\n\nTesting for epoch 8 index 15:\n\nTesting for epoch 8 index 16:\n\nTesting for epoch 8 index 17:\n\nTesting for epoch 8 index 18:\n\nTesting for epoch 8 index 19:\n\nTesting for epoch 8 index 20:\n\nTesting for epoch 8 index 21:\n\nTesting for epoch 8 index 22:\n\nTesting for epoch 8 index 23:\n\nTesting for epoch 8 index 24:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\n\nTesting for epoch 9 index 6:\n\nTesting for epoch 9 index 7:\n\nTesting for epoch 9 index 8:\n\nTesting for epoch 9 index 9:\n\nTesting for epoch 9 index 10:\n\nTesting for epoch 9 index 11:\n\nTesting for epoch 9 index 12:\n\nTesting for epoch 9 index 13:\n\nTesting for epoch 9 index 14:\n\nTesting for epoch 9 index 15:\n\nTesting for epoch 9 index 16:\n\nTesting for epoch 9 index 17:\n\nTesting for epoch 9 index 18:\n\nTesting for epoch 9 index 19:\n\nTesting for epoch 9 index 20:\n\nTesting for epoch 9 index 21:\n\nTesting for epoch 9 index 22:\n\nTesting for epoch 9 index 23:\n\nTesting for epoch 9 index 24:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\n\nTesting for epoch 10 index 6:\n\nTesting for epoch 10 index 7:\n\nTesting for epoch 10 index 8:\n\nTesting for epoch 10 index 9:\n\nTesting for epoch 10 index 10:\n\nTesting for epoch 10 index 11:\n\nTesting for epoch 10 index 12:\n\nTesting for epoch 10 index 13:\n\nTesting for epoch 10 index 14:\n\nTesting for epoch 10 index 15:\n\nTesting for epoch 10 index 16:\n\nTesting for epoch 10 index 17:\n\nTesting for epoch 10 index 18:\n\nTesting for epoch 10 index 19:\n\nTesting for epoch 10 index 20:\n\nTesting for epoch 10 index 21:\n\nTesting for epoch 10 index 22:\n\nTesting for epoch 10 index 23:\n\nTesting for epoch 10 index 24:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\n\nTesting for epoch 11 index 6:\n\nTesting for epoch 11 index 7:\n\nTesting for epoch 11 index 8:\n\nTesting for epoch 11 index 9:\n\nTesting for epoch 11 index 10:\n\nTesting for epoch 11 index 11:\n\nTesting for epoch 11 index 12:\n\nTesting for epoch 11 index 13:\n\nTesting for epoch 11 index 14:\n\nTesting for epoch 11 index 15:\n\nTesting for epoch 11 index 16:\n\nTesting for epoch 11 index 17:\n\nTesting for epoch 11 index 18:\n\nTesting for epoch 11 index 19:\n\nTesting for epoch 11 index 20:\n\nTesting for epoch 11 index 21:\n\nTesting for epoch 11 index 22:\n\nTesting for epoch 11 index 23:\n\nTesting for epoch 11 index 24:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\n\nTesting for epoch 12 index 6:\n\nTesting for epoch 12 index 7:\n\nTesting for epoch 12 index 8:\n\nTesting for epoch 12 index 9:\n\nTesting for epoch 12 index 10:\n\nTesting for epoch 12 index 11:\n\nTesting for epoch 12 index 12:\n\nTesting for epoch 12 index 13:\n\nTesting for epoch 12 index 14:\n\nTesting for epoch 12 index 15:\n\nTesting for epoch 12 index 16:\n\nTesting for epoch 12 index 17:\n\nTesting for epoch 12 index 18:\n\nTesting for epoch 12 index 19:\n\nTesting for epoch 12 index 20:\n\nTesting for epoch 12 index 21:\n\nTesting for epoch 12 index 22:\n\nTesting for epoch 12 index 23:\n\nTesting for epoch 12 index 24:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\n\nTesting for epoch 13 index 6:\n\nTesting for epoch 13 index 7:\n\nTesting for epoch 13 index 8:\n\nTesting for epoch 13 index 9:\n\nTesting for epoch 13 index 10:\n\nTesting for epoch 13 index 11:\n\nTesting for epoch 13 index 12:\n\nTesting for epoch 13 index 13:\n\nTesting for epoch 13 index 14:\n\nTesting for epoch 13 index 15:\n\nTesting for epoch 13 index 16:\n\nTesting for epoch 13 index 17:\n\nTesting for epoch 13 index 18:\n\nTesting for epoch 13 index 19:\n\nTesting for epoch 13 index 20:\n\nTesting for epoch 13 index 21:\n\nTesting for epoch 13 index 22:\n\nTesting for epoch 13 index 23:\n\nTesting for epoch 13 index 24:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\n\nTesting for epoch 14 index 6:\n\nTesting for epoch 14 index 7:\n\nTesting for epoch 14 index 8:\n\nTesting for epoch 14 index 9:\n\nTesting for epoch 14 index 10:\n\nTesting for epoch 14 index 11:\n\nTesting for epoch 14 index 12:\n\nTesting for epoch 14 index 13:\n\nTesting for epoch 14 index 14:\n\nTesting for epoch 14 index 15:\n\nTesting for epoch 14 index 16:\n\nTesting for epoch 14 index 17:\n\nTesting for epoch 14 index 18:\n\nTesting for epoch 14 index 19:\n\nTesting for epoch 14 index 20:\n\nTesting for epoch 14 index 21:\n\nTesting for epoch 14 index 22:\n\nTesting for epoch 14 index 23:\n\nTesting for epoch 14 index 24:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\n\nTesting for epoch 15 index 6:\n\nTesting for epoch 15 index 7:\n\nTesting for epoch 15 index 8:\n\nTesting for epoch 15 index 9:\n\nTesting for epoch 15 index 10:\n\nTesting for epoch 15 index 11:\n\nTesting for epoch 15 index 12:\n\nTesting for epoch 15 index 13:\n\nTesting for epoch 15 index 14:\n\nTesting for epoch 15 index 15:\n\nTesting for epoch 15 index 16:\n\nTesting for epoch 15 index 17:\n\nTesting for epoch 15 index 18:\n\nTesting for epoch 15 index 19:\n\nTesting for epoch 15 index 20:\n\nTesting for epoch 15 index 21:\n\nTesting for epoch 15 index 22:\n\nTesting for epoch 15 index 23:\n\nTesting for epoch 15 index 24:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\n\nTesting for epoch 16 index 6:\n\nTesting for epoch 16 index 7:\n\nTesting for epoch 16 index 8:\n\nTesting for epoch 16 index 9:\n\nTesting for epoch 16 index 10:\n\nTesting for epoch 16 index 11:\n\nTesting for epoch 16 index 12:\n\nTesting for epoch 16 index 13:\n\nTesting for epoch 16 index 14:\n\nTesting for epoch 16 index 15:\n\nTesting for epoch 16 index 16:\n\nTesting for epoch 16 index 17:\n\nTesting for epoch 16 index 18:\n\nTesting for epoch 16 index 19:\n\nTesting for epoch 16 index 20:\n\nTesting for epoch 16 index 21:\n\nTesting for epoch 16 index 22:\n\nTesting for epoch 16 index 23:\n\nTesting for epoch 16 index 24:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\n\nTesting for epoch 17 index 6:\n\nTesting for epoch 17 index 7:\n\nTesting for epoch 17 index 8:\n\nTesting for epoch 17 index 9:\n\nTesting for epoch 17 index 10:\n\nTesting for epoch 17 index 11:\n\nTesting for epoch 17 index 12:\n\nTesting for epoch 17 index 13:\n\nTesting for epoch 17 index 14:\n\nTesting for epoch 17 index 15:\n\nTesting for epoch 17 index 16:\n\nTesting for epoch 17 index 17:\n\nTesting for epoch 17 index 18:\n\nTesting for epoch 17 index 19:\n\nTesting for epoch 17 index 20:\n\nTesting for epoch 17 index 21:\n\nTesting for epoch 17 index 22:\n\nTesting for epoch 17 index 23:\n\nTesting for epoch 17 index 24:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\n\nTesting for epoch 18 index 6:\n\nTesting for epoch 18 index 7:\n\nTesting for epoch 18 index 8:\n\nTesting for epoch 18 index 9:\n\nTesting for epoch 18 index 10:\n\nTesting for epoch 18 index 11:\n\nTesting for epoch 18 index 12:\n\nTesting for epoch 18 index 13:\n\nTesting for epoch 18 index 14:\n\nTesting for epoch 18 index 15:\n\nTesting for epoch 18 index 16:\n\nTesting for epoch 18 index 17:\n\nTesting for epoch 18 index 18:\n\nTesting for epoch 18 index 19:\n\nTesting for epoch 18 index 20:\n\nTesting for epoch 18 index 21:\n\nTesting for epoch 18 index 22:\n\nTesting for epoch 18 index 23:\n\nTesting for epoch 18 index 24:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\n\nTesting for epoch 19 index 6:\n\nTesting for epoch 19 index 7:\n\nTesting for epoch 19 index 8:\n\nTesting for epoch 19 index 9:\n\nTesting for epoch 19 index 10:\n\nTesting for epoch 19 index 11:\n\nTesting for epoch 19 index 12:\n\nTesting for epoch 19 index 13:\n\nTesting for epoch 19 index 14:\n\nTesting for epoch 19 index 15:\n\nTesting for epoch 19 index 16:\n\nTesting for epoch 19 index 17:\n\nTesting for epoch 19 index 18:\n\nTesting for epoch 19 index 19:\n\nTesting for epoch 19 index 20:\n\nTesting for epoch 19 index 21:\n\nTesting for epoch 19 index 22:\n\nTesting for epoch 19 index 23:\n\nTesting for epoch 19 index 24:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\n\nTesting for epoch 20 index 6:\n\nTesting for epoch 20 index 7:\n\nTesting for epoch 20 index 8:\n\nTesting for epoch 20 index 9:\n\nTesting for epoch 20 index 10:\n\nTesting for epoch 20 index 11:\n\nTesting for epoch 20 index 12:\n\nTesting for epoch 20 index 13:\n\nTesting for epoch 20 index 14:\n\nTesting for epoch 20 index 15:\n\nTesting for epoch 20 index 16:\n\nTesting for epoch 20 index 17:\n\nTesting for epoch 20 index 18:\n\nTesting for epoch 20 index 19:\n\nTesting for epoch 20 index 20:\n\nTesting for epoch 20 index 21:\n\nTesting for epoch 20 index 22:\n\nTesting for epoch 20 index 23:\n\nTesting for epoch 20 index 24:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\n\nTesting for epoch 21 index 6:\n\nTesting for epoch 21 index 7:\n\nTesting for epoch 21 index 8:\n\nTesting for epoch 21 index 9:\n\nTesting for epoch 21 index 10:\n\nTesting for epoch 21 index 11:\n\nTesting for epoch 21 index 12:\n\nTesting for epoch 21 index 13:\n\nTesting for epoch 21 index 14:\n\nTesting for epoch 21 index 15:\n\nTesting for epoch 21 index 16:\n\nTesting for epoch 21 index 17:\n\nTesting for epoch 21 index 18:\n\nTesting for epoch 21 index 19:\n\nTesting for epoch 21 index 20:\n\nTesting for epoch 21 index 21:\n\nTesting for epoch 21 index 22:\n\nTesting for epoch 21 index 23:\n\nTesting for epoch 21 index 24:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8535\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8579\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8627\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8612\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8499\n\nTesting for epoch 22 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8604\n\nTesting for epoch 22 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8870\n\nTesting for epoch 22 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 4.8985\n\nTesting for epoch 22 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8793\n\nTesting for epoch 22 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 4.8671\n\nTesting for epoch 22 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8616\n\nTesting for epoch 22 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8623\n\nTesting for epoch 22 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8959\n\nTesting for epoch 22 index 14:\n16/16 [==============================] - 0s 5ms/step - loss: 4.8903\n\nTesting for epoch 22 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8863\n\nTesting for epoch 22 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9047\n\nTesting for epoch 22 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8914\n\nTesting for epoch 22 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9103\n\nTesting for epoch 22 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8898\n\nTesting for epoch 22 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8972\n\nTesting for epoch 22 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9112\n\nTesting for epoch 22 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8815\n\nTesting for epoch 22 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9102\n\nTesting for epoch 22 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9271\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9269\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9297\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9328\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9300\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9258\n\nTesting for epoch 23 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9478\n\nTesting for epoch 23 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9551\n\nTesting for epoch 23 index 8:\n16/16 [==============================] - 0s 6ms/step - loss: 4.9404\n\nTesting for epoch 23 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9310\n\nTesting for epoch 23 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9559\n\nTesting for epoch 23 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9254\n\nTesting for epoch 23 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9674\n\nTesting for epoch 23 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9145\n\nTesting for epoch 23 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9604\n\nTesting for epoch 23 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9518\n\nTesting for epoch 23 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9819\n\nTesting for epoch 23 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9684\n\nTesting for epoch 23 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9730\n\nTesting for epoch 23 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9850\n\nTesting for epoch 23 index 20:\n16/16 [==============================] - 0s 948us/step - loss: 4.9600\n\nTesting for epoch 23 index 21:\n16/16 [==============================] - 0s 971us/step - loss: 4.9775\n\nTesting for epoch 23 index 22:\n16/16 [==============================] - 0s 973us/step - loss: 4.9805\n\nTesting for epoch 23 index 23:\n16/16 [==============================] - 0s 964us/step - loss: 4.9943\n\nTesting for epoch 23 index 24:\n16/16 [==============================] - 0s 964us/step - loss: 4.9783\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 924us/step - loss: 4.9912\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 954us/step - loss: 5.0385\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 965us/step - loss: 5.0175\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 948us/step - loss: 4.9888\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 942us/step - loss: 4.9810\n\nTesting for epoch 24 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0312\n\nTesting for epoch 24 index 7:\n16/16 [==============================] - 0s 873us/step - loss: 5.0304\n\nTesting for epoch 24 index 8:\n16/16 [==============================] - 0s 988us/step - loss: 5.0057\n\nTesting for epoch 24 index 9:\n16/16 [==============================] - 0s 924us/step - loss: 5.0251\n\nTesting for epoch 24 index 10:\n16/16 [==============================] - 0s 963us/step - loss: 5.0155\n\nTesting for epoch 24 index 11:\n16/16 [==============================] - 0s 975us/step - loss: 5.0163\n\nTesting for epoch 24 index 12:\n16/16 [==============================] - 0s 941us/step - loss: 5.0397\n\nTesting for epoch 24 index 13:\n16/16 [==============================] - 0s 901us/step - loss: 5.0455\n\nTesting for epoch 24 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0304\n\nTesting for epoch 24 index 15:\n16/16 [==============================] - 0s 878us/step - loss: 5.0359\n\nTesting for epoch 24 index 16:\n16/16 [==============================] - 0s 900us/step - loss: 5.0382\n\nTesting for epoch 24 index 17:\n16/16 [==============================] - 0s 880us/step - loss: 5.0440\n\nTesting for epoch 24 index 18:\n16/16 [==============================] - 0s 916us/step - loss: 5.0342\n\nTesting for epoch 24 index 19:\n16/16 [==============================] - 0s 921us/step - loss: 5.0470\n\nTesting for epoch 24 index 20:\n16/16 [==============================] - 0s 853us/step - loss: 5.0636\n\nTesting for epoch 24 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0384\n\nTesting for epoch 24 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0632\n\nTesting for epoch 24 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0551\n\nTesting for epoch 24 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0674\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0658\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0720\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 5.0970\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1021\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0690\n\nTesting for epoch 25 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0667\n\nTesting for epoch 25 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.0819\n\nTesting for epoch 25 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0758\n\nTesting for epoch 25 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1001\n\nTesting for epoch 25 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1026\n\nTesting for epoch 25 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0995\n\nTesting for epoch 25 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0909\n\nTesting for epoch 25 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0748\n\nTesting for epoch 25 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1088\n\nTesting for epoch 25 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1024\n\nTesting for epoch 25 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1040\n\nTesting for epoch 25 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1178\n\nTesting for epoch 25 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1198\n\nTesting for epoch 25 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1089\n\nTesting for epoch 25 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1391\n\nTesting for epoch 25 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1187\n\nTesting for epoch 25 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0872\n\nTesting for epoch 25 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1059\n\nTesting for epoch 25 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1363\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1288\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1096\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1230\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1359\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1324\n\nTesting for epoch 26 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1345\n\nTesting for epoch 26 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1585\n\nTesting for epoch 26 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1325\n\nTesting for epoch 26 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1634\n\nTesting for epoch 26 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1488\n\nTesting for epoch 26 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1563\n\nTesting for epoch 26 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1734\n\nTesting for epoch 26 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1643\n\nTesting for epoch 26 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1657\n\nTesting for epoch 26 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1636\n\nTesting for epoch 26 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1958\n\nTesting for epoch 26 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1432\n\nTesting for epoch 26 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1720\n\nTesting for epoch 26 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1909\n\nTesting for epoch 26 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1622\n\nTesting for epoch 26 index 21:\n16/16 [==============================] - 0s 988us/step - loss: 5.1711\n\nTesting for epoch 26 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2015\n\nTesting for epoch 26 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1616\n\nTesting for epoch 26 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1611\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1688\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 973us/step - loss: 5.1927\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1881\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2126\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2083\n\nTesting for epoch 27 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1934\n\nTesting for epoch 27 index 7:\n16/16 [==============================] - 0s 736us/step - loss: 5.1712\n\nTesting for epoch 27 index 8:\n16/16 [==============================] - 0s 886us/step - loss: 5.2049\n\nTesting for epoch 27 index 9:\n16/16 [==============================] - 0s 910us/step - loss: 5.2330\n\nTesting for epoch 27 index 10:\n16/16 [==============================] - 0s 896us/step - loss: 5.2123\n\nTesting for epoch 27 index 11:\n16/16 [==============================] - 0s 831us/step - loss: 5.2265\n\nTesting for epoch 27 index 12:\n16/16 [==============================] - 0s 912us/step - loss: 5.1898\n\nTesting for epoch 27 index 13:\n16/16 [==============================] - 0s 917us/step - loss: 5.2358\n\nTesting for epoch 27 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2279\n\nTesting for epoch 27 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2258\n\nTesting for epoch 27 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2379\n\nTesting for epoch 27 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2032\n\nTesting for epoch 27 index 18:\n16/16 [==============================] - 0s 923us/step - loss: 5.2329\n\nTesting for epoch 27 index 19:\n16/16 [==============================] - 0s 876us/step - loss: 5.2238\n\nTesting for epoch 27 index 20:\n16/16 [==============================] - 0s 845us/step - loss: 5.2310\n\nTesting for epoch 27 index 21:\n16/16 [==============================] - 0s 866us/step - loss: 5.2555\n\nTesting for epoch 27 index 22:\n16/16 [==============================] - 0s 865us/step - loss: 5.2506\n\nTesting for epoch 27 index 23:\n16/16 [==============================] - 0s 861us/step - loss: 5.2298\n\nTesting for epoch 27 index 24:\n16/16 [==============================] - 0s 899us/step - loss: 5.2571\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 885us/step - loss: 5.2601\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2272\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2099\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2475\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2595\n\nTesting for epoch 28 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2686\n\nTesting for epoch 28 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2621\n\nTesting for epoch 28 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2553\n\nTesting for epoch 28 index 9:\n16/16 [==============================] - 0s 3ms/step - loss: 5.2640\n\nTesting for epoch 28 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2939\n\nTesting for epoch 28 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2480\n\nTesting for epoch 28 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2600\n\nTesting for epoch 28 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2769\n\nTesting for epoch 28 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2909\n\nTesting for epoch 28 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3053\n\nTesting for epoch 28 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2796\n\nTesting for epoch 28 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3058\n\nTesting for epoch 28 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2567\n\nTesting for epoch 28 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3181\n\nTesting for epoch 28 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2960\n\nTesting for epoch 28 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3114\n\nTesting for epoch 28 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3035\n\nTesting for epoch 28 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2829\n\nTesting for epoch 28 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3213\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3131\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2918\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3130\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3074\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3050\n\nTesting for epoch 29 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3056\n\nTesting for epoch 29 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3180\n\nTesting for epoch 29 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3132\n\nTesting for epoch 29 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3342\n\nTesting for epoch 29 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3181\n\nTesting for epoch 29 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3207\n\nTesting for epoch 29 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3322\n\nTesting for epoch 29 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3407\n\nTesting for epoch 29 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2953\n\nTesting for epoch 29 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3182\n\nTesting for epoch 29 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3612\n\nTesting for epoch 29 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3317\n\nTesting for epoch 29 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3261\n\nTesting for epoch 29 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3377\n\nTesting for epoch 29 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3426\n\nTesting for epoch 29 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3247\n\nTesting for epoch 29 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3645\n\nTesting for epoch 29 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3567\n\nTesting for epoch 29 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3648\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3892\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.3744\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3550\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 4ms/step - loss: 5.3625\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3735\n\nTesting for epoch 30 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3469\n\nTesting for epoch 30 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3726\n\nTesting for epoch 30 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3694\n\nTesting for epoch 30 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3997\n\nTesting for epoch 30 index 10:\n16/16 [==============================] - 0s 954us/step - loss: 5.3930\n\nTesting for epoch 30 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3818\n\nTesting for epoch 30 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3895\n\nTesting for epoch 30 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3934\n\nTesting for epoch 30 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3513\n\nTesting for epoch 30 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3578\n\nTesting for epoch 30 index 16:\n16/16 [==============================] - 0s 4ms/step - loss: 5.3932\n\nTesting for epoch 30 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3803\n\nTesting for epoch 30 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3644\n\nTesting for epoch 30 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3941\n\nTesting for epoch 30 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3916\n\nTesting for epoch 30 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4229\n\nTesting for epoch 30 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3823\n\nTesting for epoch 30 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3990\n\nTesting for epoch 30 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4237\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4052\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4002\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4178\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4004\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4048\n\nTesting for epoch 31 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4361\n\nTesting for epoch 31 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4403\n\nTesting for epoch 31 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4431\n\nTesting for epoch 31 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4361\n\nTesting for epoch 31 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 5.4131\n\nTesting for epoch 31 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4242\n\nTesting for epoch 31 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4213\n\nTesting for epoch 31 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4208\n\nTesting for epoch 31 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4083\n\nTesting for epoch 31 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4338\n\nTesting for epoch 31 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4388\n\nTesting for epoch 31 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4298\n\nTesting for epoch 31 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4476\n\nTesting for epoch 31 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4494\n\nTesting for epoch 31 index 20:\n16/16 [==============================] - 0s 895us/step - loss: 5.4731\n\nTesting for epoch 31 index 21:\n16/16 [==============================] - 0s 977us/step - loss: 5.4403\n\nTesting for epoch 31 index 22:\n16/16 [==============================] - 0s 836us/step - loss: 5.4519\n\nTesting for epoch 31 index 23:\n16/16 [==============================] - 0s 921us/step - loss: 5.4354\n\nTesting for epoch 31 index 24:\n16/16 [==============================] - 0s 822us/step - loss: 5.4255\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 839us/step - loss: 5.4622\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 864us/step - loss: 5.4706\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 849us/step - loss: 5.4524\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4741\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4610\n\nTesting for epoch 32 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.4661\n\nTesting for epoch 32 index 7:\n16/16 [==============================] - 0s 889us/step - loss: 5.4742\n\nTesting for epoch 32 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4768\n\nTesting for epoch 32 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4899\n\nTesting for epoch 32 index 10:\n16/16 [==============================] - 0s 836us/step - loss: 5.4828\n\nTesting for epoch 32 index 11:\n16/16 [==============================] - 0s 957us/step - loss: 5.4510\n\nTesting for epoch 32 index 12:\n16/16 [==============================] - 0s 836us/step - loss: 5.4928\n\nTesting for epoch 32 index 13:\n16/16 [==============================] - 0s 829us/step - loss: 5.5070\n\nTesting for epoch 32 index 14:\n16/16 [==============================] - 0s 823us/step - loss: 5.5029\n\nTesting for epoch 32 index 15:\n16/16 [==============================] - 0s 854us/step - loss: 5.4948\n\nTesting for epoch 32 index 16:\n16/16 [==============================] - 0s 828us/step - loss: 5.4771\n\nTesting for epoch 32 index 17:\n16/16 [==============================] - 0s 882us/step - loss: 5.4984\n\nTesting for epoch 32 index 18:\n16/16 [==============================] - 0s 857us/step - loss: 5.5006\n\nTesting for epoch 32 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5135\n\nTesting for epoch 32 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4983\n\nTesting for epoch 32 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5173\n\nTesting for epoch 32 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4870\n\nTesting for epoch 32 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5119\n\nTesting for epoch 32 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5019\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5101\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.4904\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4961\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5127\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5139\n\nTesting for epoch 33 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5097\n\nTesting for epoch 33 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5135\n\nTesting for epoch 33 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5580\n\nTesting for epoch 33 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5463\n\nTesting for epoch 33 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5466\n\nTesting for epoch 33 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5086\n\nTesting for epoch 33 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n\nTesting for epoch 33 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5444\n\nTesting for epoch 33 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5245\n\nTesting for epoch 33 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5179\n\nTesting for epoch 33 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5350\n\nTesting for epoch 33 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5319\n\nTesting for epoch 33 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5096\n\nTesting for epoch 33 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5171\n\nTesting for epoch 33 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5487\n\nTesting for epoch 33 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5386\n\nTesting for epoch 33 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5608\n\nTesting for epoch 33 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5531\n\nTesting for epoch 33 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5569\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5679\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5848\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5654\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5561\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5359\n\nTesting for epoch 34 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5381\n\nTesting for epoch 34 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5742\n\nTesting for epoch 34 index 8:\n16/16 [==============================] - 0s 974us/step - loss: 5.5597\n\nTesting for epoch 34 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5576\n\nTesting for epoch 34 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5693\n\nTesting for epoch 34 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5456\n\nTesting for epoch 34 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5895\n\nTesting for epoch 34 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5786\n\nTesting for epoch 34 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6051\n\nTesting for epoch 34 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5843\n\nTesting for epoch 34 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5701\n\nTesting for epoch 34 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6106\n\nTesting for epoch 34 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6000\n\nTesting for epoch 34 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5551\n\nTesting for epoch 34 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5947\n\nTesting for epoch 34 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5761\n\nTesting for epoch 34 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5775\n\nTesting for epoch 34 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6234\n\nTesting for epoch 34 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5912\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5936\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5926\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5801\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6047\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 5ms/step - loss: 5.6045\n\nTesting for epoch 35 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6162\n\nTesting for epoch 35 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5970\n\nTesting for epoch 35 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5918\n\nTesting for epoch 35 index 9:\n16/16 [==============================] - 0s 984us/step - loss: 5.6380\n\nTesting for epoch 35 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6081\n\nTesting for epoch 35 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6398\n\nTesting for epoch 35 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5785\n\nTesting for epoch 35 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5853\n\nTesting for epoch 35 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6186\n\nTesting for epoch 35 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6222\n\nTesting for epoch 35 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6164\n\nTesting for epoch 35 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6302\n\nTesting for epoch 35 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6211\n\nTesting for epoch 35 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6531\n\nTesting for epoch 35 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6420\n\nTesting for epoch 35 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6193\n\nTesting for epoch 35 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6251\n\nTesting for epoch 35 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6568\n\nTesting for epoch 35 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6580\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6132\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6358\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6630\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6440\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6226\n\nTesting for epoch 36 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6221\n\nTesting for epoch 36 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n\nTesting for epoch 36 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6482\n\nTesting for epoch 36 index 9:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6486\n\nTesting for epoch 36 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6605\n\nTesting for epoch 36 index 11:\n16/16 [==============================] - 0s 891us/step - loss: 5.6862\n\nTesting for epoch 36 index 12:\n16/16 [==============================] - 0s 909us/step - loss: 5.6638\n\nTesting for epoch 36 index 13:\n16/16 [==============================] - 0s 949us/step - loss: 5.6434\n\nTesting for epoch 36 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6738\n\nTesting for epoch 36 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6927\n\nTesting for epoch 36 index 16:\n16/16 [==============================] - 0s 908us/step - loss: 5.6958\n\nTesting for epoch 36 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6790\n\nTesting for epoch 36 index 18:\n16/16 [==============================] - 0s 851us/step - loss: 5.6752\n\nTesting for epoch 36 index 19:\n16/16 [==============================] - 0s 819us/step - loss: 5.6844\n\nTesting for epoch 36 index 20:\n16/16 [==============================] - 0s 6ms/step - loss: 5.6507\n\nTesting for epoch 36 index 21:\n16/16 [==============================] - 0s 864us/step - loss: 5.6467\n\nTesting for epoch 36 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6941\n\nTesting for epoch 36 index 23:\n16/16 [==============================] - 0s 874us/step - loss: 5.6967\n\nTesting for epoch 36 index 24:\n16/16 [==============================] - 0s 881us/step - loss: 5.6670\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 825us/step - loss: 5.7009\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 831us/step - loss: 5.6850\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 881us/step - loss: 5.6797\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 900us/step - loss: 5.6818\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 893us/step - loss: 5.6605\n\nTesting for epoch 37 index 6:\n16/16 [==============================] - 0s 870us/step - loss: 5.7199\n\nTesting for epoch 37 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6550\n\nTesting for epoch 37 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6696\n\nTesting for epoch 37 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6838\n\nTesting for epoch 37 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7124\n\nTesting for epoch 37 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7032\n\nTesting for epoch 37 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7217\n\nTesting for epoch 37 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7134\n\nTesting for epoch 37 index 14:\n16/16 [==============================] - 0s 4ms/step - loss: 5.6758\n\nTesting for epoch 37 index 15:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7049\n\nTesting for epoch 37 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7058\n\nTesting for epoch 37 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6949\n\nTesting for epoch 37 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7414\n\nTesting for epoch 37 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7083\n\nTesting for epoch 37 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7027\n\nTesting for epoch 37 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7252\n\nTesting for epoch 37 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7341\n\nTesting for epoch 37 index 23:\n16/16 [==============================] - 0s 4ms/step - loss: 5.6999\n\nTesting for epoch 37 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7178\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7195\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7255\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7030\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7160\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7259\n\nTesting for epoch 38 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7310\n\nTesting for epoch 38 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7167\n\nTesting for epoch 38 index 8:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7205\n\nTesting for epoch 38 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7377\n\nTesting for epoch 38 index 10:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7480\n\nTesting for epoch 38 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7311\n\nTesting for epoch 38 index 12:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7670\n\nTesting for epoch 38 index 13:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7334\n\nTesting for epoch 38 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7235\n\nTesting for epoch 38 index 15:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7380\n\nTesting for epoch 38 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7558\n\nTesting for epoch 38 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7787\n\nTesting for epoch 38 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7349\n\nTesting for epoch 38 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7661\n\nTesting for epoch 38 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7622\n\nTesting for epoch 38 index 21:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7841\n\nTesting for epoch 38 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7477\n\nTesting for epoch 38 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7299\n\nTesting for epoch 38 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7486\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7355\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7274\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7831\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7784\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7559\n\nTesting for epoch 39 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7877\n\nTesting for epoch 39 index 7:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7659\n\nTesting for epoch 39 index 8:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7575\n\nTesting for epoch 39 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7910\n\nTesting for epoch 39 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7704\n\nTesting for epoch 39 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7690\n\nTesting for epoch 39 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7950\n\nTesting for epoch 39 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7558\n\nTesting for epoch 39 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7891\n\nTesting for epoch 39 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7960\n\nTesting for epoch 39 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7617\n\nTesting for epoch 39 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7877\n\nTesting for epoch 39 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7571\n\nTesting for epoch 39 index 19:\n16/16 [==============================] - 0s 6ms/step - loss: 5.7956\n\nTesting for epoch 39 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7831\n\nTesting for epoch 39 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7889\n\nTesting for epoch 39 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8032\n\nTesting for epoch 39 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7833\n\nTesting for epoch 39 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8251\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7939\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7849\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7914\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8011\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7967\n\nTesting for epoch 40 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7908\n\nTesting for epoch 40 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8090\n\nTesting for epoch 40 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8014\n\nTesting for epoch 40 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7900\n\nTesting for epoch 40 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8104\n\nTesting for epoch 40 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8398\n\nTesting for epoch 40 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8279\n\nTesting for epoch 40 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7970\n\nTesting for epoch 40 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8229\n\nTesting for epoch 40 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8302\n\nTesting for epoch 40 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8061\n\nTesting for epoch 40 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8306\n\nTesting for epoch 40 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8196\n\nTesting for epoch 40 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8551\n\nTesting for epoch 40 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8235\n\nTesting for epoch 40 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8419\n\nTesting for epoch 40 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8338\n\nTesting for epoch 40 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8127\n\nTesting for epoch 40 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8348\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8301\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8534\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8247\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8221\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8441\n\nTesting for epoch 41 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8420\n\nTesting for epoch 41 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8326\n\nTesting for epoch 41 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8481\n\nTesting for epoch 41 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8424\n\nTesting for epoch 41 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8379\n\nTesting for epoch 41 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8776\n\nTesting for epoch 41 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8380\n\nTesting for epoch 41 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8470\n\nTesting for epoch 41 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8805\n\nTesting for epoch 41 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8361\n\nTesting for epoch 41 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8703\n\nTesting for epoch 41 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8674\n\nTesting for epoch 41 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8865\n\nTesting for epoch 41 index 19:\n16/16 [==============================] - 0s 4ms/step - loss: 5.8704\n\nTesting for epoch 41 index 20:\n16/16 [==============================] - 0s 5ms/step - loss: 5.9158\n\nTesting for epoch 41 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8653\n\nTesting for epoch 41 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8605\n\nTesting for epoch 41 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8391\n\nTesting for epoch 41 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8287\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8514\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8873\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8739\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8964\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9038\n\nTesting for epoch 42 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8840\n\nTesting for epoch 42 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8768\n\nTesting for epoch 42 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9105\n\nTesting for epoch 42 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9081\n\nTesting for epoch 42 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8595\n\nTesting for epoch 42 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8721\n\nTesting for epoch 42 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8720\n\nTesting for epoch 42 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8938\n\nTesting for epoch 42 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8642\n\nTesting for epoch 42 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8529\n\nTesting for epoch 42 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9287\n\nTesting for epoch 42 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8928\n\nTesting for epoch 42 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8888\n\nTesting for epoch 42 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8941\n\nTesting for epoch 42 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9118\n\nTesting for epoch 42 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9074\n\nTesting for epoch 42 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8974\n\nTesting for epoch 42 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9163\n\nTesting for epoch 42 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9176\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9020\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8887\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8954\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8828\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9241\n\nTesting for epoch 43 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9199\n\nTesting for epoch 43 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9037\n\nTesting for epoch 43 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9194\n\nTesting for epoch 43 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8892\n\nTesting for epoch 43 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9011\n\nTesting for epoch 43 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9293\n\nTesting for epoch 43 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9526\n\nTesting for epoch 43 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9206\n\nTesting for epoch 43 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9310\n\nTesting for epoch 43 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9005\n\nTesting for epoch 43 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9265\n\nTesting for epoch 43 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9172\n\nTesting for epoch 43 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9574\n\nTesting for epoch 43 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9223\n\nTesting for epoch 43 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9191\n\nTesting for epoch 43 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9312\n\nTesting for epoch 43 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9225\n\nTesting for epoch 43 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9196\n\nTesting for epoch 43 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9712\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9398\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9369\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9296\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9298\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9565\n\nTesting for epoch 44 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9331\n\nTesting for epoch 44 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9333\n\nTesting for epoch 44 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9800\n\nTesting for epoch 44 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9548\n\nTesting for epoch 44 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9907\n\nTesting for epoch 44 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9742\n\nTesting for epoch 44 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9679\n\nTesting for epoch 44 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9404\n\nTesting for epoch 44 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9540\n\nTesting for epoch 44 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9697\n\nTesting for epoch 44 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9573\n\nTesting for epoch 44 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9611\n\nTesting for epoch 44 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9501\n\nTesting for epoch 44 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9725\n\nTesting for epoch 44 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9704\n\nTesting for epoch 44 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9715\n\nTesting for epoch 44 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9377\n\nTesting for epoch 44 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9567\n\nTesting for epoch 44 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9600\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9695\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9845\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9872\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9660\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9648\n\nTesting for epoch 45 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0025\n\nTesting for epoch 45 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9845\n\nTesting for epoch 45 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9770\n\nTesting for epoch 45 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9950\n\nTesting for epoch 45 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9825\n\nTesting for epoch 45 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0264\n\nTesting for epoch 45 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9860\n\nTesting for epoch 45 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9844\n\nTesting for epoch 45 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9831\n\nTesting for epoch 45 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9743\n\nTesting for epoch 45 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9902\n\nTesting for epoch 45 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9655\n\nTesting for epoch 45 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9730\n\nTesting for epoch 45 index 19:\n16/16 [==============================] - 0s 4ms/step - loss: 5.9888\n\nTesting for epoch 45 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0239\n\nTesting for epoch 45 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9866\n\nTesting for epoch 45 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9779\n\nTesting for epoch 45 index 23:\n16/16 [==============================] - 0s 6ms/step - loss: 5.9982\n\nTesting for epoch 45 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0143\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0295\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9825\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0014\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0107\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0311\n\nTesting for epoch 46 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9898\n\nTesting for epoch 46 index 7:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0510\n\nTesting for epoch 46 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0030\n\nTesting for epoch 46 index 9:\n16/16 [==============================] - 0s 4ms/step - loss: 5.9883\n\nTesting for epoch 46 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0342\n\nTesting for epoch 46 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0171\n\nTesting for epoch 46 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0030\n\nTesting for epoch 46 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0223\n\nTesting for epoch 46 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0418\n\nTesting for epoch 46 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0316\n\nTesting for epoch 46 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0310\n\nTesting for epoch 46 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0164\n\nTesting for epoch 46 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0290\n\nTesting for epoch 46 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0211\n\nTesting for epoch 46 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0173\n\nTesting for epoch 46 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0238\n\nTesting for epoch 46 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0549\n\nTesting for epoch 46 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0234\n\nTesting for epoch 46 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0092\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0113\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0467\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0790\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0722\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0378\n\nTesting for epoch 47 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0637\n\nTesting for epoch 47 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0557\n\nTesting for epoch 47 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9965\n\nTesting for epoch 47 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0327\n\nTesting for epoch 47 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0582\n\nTesting for epoch 47 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0292\n\nTesting for epoch 47 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0484\n\nTesting for epoch 47 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0690\n\nTesting for epoch 47 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0508\n\nTesting for epoch 47 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0544\n\nTesting for epoch 47 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0439\n\nTesting for epoch 47 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0742\n\nTesting for epoch 47 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0572\n\nTesting for epoch 47 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0591\n\nTesting for epoch 47 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0431\n\nTesting for epoch 47 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0831\n\nTesting for epoch 47 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0684\n\nTesting for epoch 47 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0573\n\nTesting for epoch 47 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0923\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0847\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0703\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0454\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0552\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0849\n\nTesting for epoch 48 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0517\n\nTesting for epoch 48 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0866\n\nTesting for epoch 48 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0758\n\nTesting for epoch 48 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1111\n\nTesting for epoch 48 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0674\n\nTesting for epoch 48 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0838\n\nTesting for epoch 48 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1128\n\nTesting for epoch 48 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0590\n\nTesting for epoch 48 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0739\n\nTesting for epoch 48 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0620\n\nTesting for epoch 48 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0717\n\nTesting for epoch 48 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0845\n\nTesting for epoch 48 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0742\n\nTesting for epoch 48 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0991\n\nTesting for epoch 48 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0545\n\nTesting for epoch 48 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1073\n\nTesting for epoch 48 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0958\n\nTesting for epoch 48 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0572\n\nTesting for epoch 48 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1371\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1035\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0675\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0999\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1191\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1210\n\nTesting for epoch 49 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1135\n\nTesting for epoch 49 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1262\n\nTesting for epoch 49 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0831\n\nTesting for epoch 49 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1058\n\nTesting for epoch 49 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1090\n\nTesting for epoch 49 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1057\n\nTesting for epoch 49 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1088\n\nTesting for epoch 49 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1232\n\nTesting for epoch 49 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0894\n\nTesting for epoch 49 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1116\n\nTesting for epoch 49 index 16:\n16/16 [==============================] - 0s 5ms/step - loss: 6.1392\n\nTesting for epoch 49 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1318\n\nTesting for epoch 49 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1031\n\nTesting for epoch 49 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1547\n\nTesting for epoch 49 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0960\n\nTesting for epoch 49 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1555\n\nTesting for epoch 49 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1379\n\nTesting for epoch 49 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0967\n\nTesting for epoch 49 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1399\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0987\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1329\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1105\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1310\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0889\n\nTesting for epoch 50 index 6:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1469\n\nTesting for epoch 50 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1347\n\nTesting for epoch 50 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1192\n\nTesting for epoch 50 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1290\n\nTesting for epoch 50 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1286\n\nTesting for epoch 50 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1321\n\nTesting for epoch 50 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1555\n\nTesting for epoch 50 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1481\n\nTesting for epoch 50 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1589\n\nTesting for epoch 50 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1314\n\nTesting for epoch 50 index 16:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1347\n\nTesting for epoch 50 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1325\n\nTesting for epoch 50 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1575\n\nTesting for epoch 50 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1620\n\nTesting for epoch 50 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1571\n\nTesting for epoch 50 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0978\n\nTesting for epoch 50 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1696\n\nTesting for epoch 50 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1205\n\nTesting for epoch 50 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1326\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1536\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1668\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1308\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1492\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1592\n\nTesting for epoch 51 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1718\n\nTesting for epoch 51 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1811\n\nTesting for epoch 51 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1576\n\nTesting for epoch 51 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1344\n\nTesting for epoch 51 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1463\n\nTesting for epoch 51 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1708\n\nTesting for epoch 51 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1972\n\nTesting for epoch 51 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1650\n\nTesting for epoch 51 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1533\n\nTesting for epoch 51 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1549\n\nTesting for epoch 51 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1492\n\nTesting for epoch 51 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1474\n\nTesting for epoch 51 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1446\n\nTesting for epoch 51 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2000\n\nTesting for epoch 51 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1578\n\nTesting for epoch 51 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1328\n\nTesting for epoch 51 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1692\n\nTesting for epoch 51 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1752\n\nTesting for epoch 51 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1524\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2224\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1998\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1916\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1728\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1997\n\nTesting for epoch 52 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1800\n\nTesting for epoch 52 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1960\n\nTesting for epoch 52 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1573\n\nTesting for epoch 52 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1822\n\nTesting for epoch 52 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2128\n\nTesting for epoch 52 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2226\n\nTesting for epoch 52 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2022\n\nTesting for epoch 52 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1782\n\nTesting for epoch 52 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1693\n\nTesting for epoch 52 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1917\n\nTesting for epoch 52 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1940\n\nTesting for epoch 52 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1999\n\nTesting for epoch 52 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1842\n\nTesting for epoch 52 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1996\n\nTesting for epoch 52 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2104\n\nTesting for epoch 52 index 21:\n16/16 [==============================] - 0s 4ms/step - loss: 6.2201\n\nTesting for epoch 52 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1933\n\nTesting for epoch 52 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1899\n\nTesting for epoch 52 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1887\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2112\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2016\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2237\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1912\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1927\n\nTesting for epoch 53 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2141\n\nTesting for epoch 53 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2289\n\nTesting for epoch 53 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1993\n\nTesting for epoch 53 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2175\n\nTesting for epoch 53 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2142\n\nTesting for epoch 53 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2280\n\nTesting for epoch 53 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2100\n\nTesting for epoch 53 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2253\n\nTesting for epoch 53 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2261\n\nTesting for epoch 53 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2624\n\nTesting for epoch 53 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2173\n\nTesting for epoch 53 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2413\n\nTesting for epoch 53 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2174\n\nTesting for epoch 53 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1991\n\nTesting for epoch 53 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2263\n\nTesting for epoch 53 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2499\n\nTesting for epoch 53 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2003\n\nTesting for epoch 53 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2449\n\nTesting for epoch 53 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2249\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2472\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2382\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2188\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2338\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2704\n\nTesting for epoch 54 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2055\n\nTesting for epoch 54 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2565\n\nTesting for epoch 54 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2524\n\nTesting for epoch 54 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2573\n\nTesting for epoch 54 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2544\n\nTesting for epoch 54 index 11:\n16/16 [==============================] - 0s 5ms/step - loss: 6.2302\n\nTesting for epoch 54 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2331\n\nTesting for epoch 54 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2060\n\nTesting for epoch 54 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2518\n\nTesting for epoch 54 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2465\n\nTesting for epoch 54 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1940\n\nTesting for epoch 54 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2579\n\nTesting for epoch 54 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2417\n\nTesting for epoch 54 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2534\n\nTesting for epoch 54 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2519\n\nTesting for epoch 54 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2425\n\nTesting for epoch 54 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2399\n\nTesting for epoch 54 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2673\n\nTesting for epoch 54 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2722\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2730\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2662\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2780\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2703\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2788\n\nTesting for epoch 55 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2653\n\nTesting for epoch 55 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2738\n\nTesting for epoch 55 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2662\n\nTesting for epoch 55 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2842\n\nTesting for epoch 55 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2755\n\nTesting for epoch 55 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3159\n\nTesting for epoch 55 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2817\n\nTesting for epoch 55 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2706\n\nTesting for epoch 55 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2826\n\nTesting for epoch 55 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3087\n\nTesting for epoch 55 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2827\n\nTesting for epoch 55 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2835\n\nTesting for epoch 55 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2455\n\nTesting for epoch 55 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3109\n\nTesting for epoch 55 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3139\n\nTesting for epoch 55 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2777\n\nTesting for epoch 55 index 22:\n16/16 [==============================] - 0s 5ms/step - loss: 6.2460\n\nTesting for epoch 55 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3135\n\nTesting for epoch 55 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2767\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2638\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2505\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2844\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2828\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2526\n\nTesting for epoch 56 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2842\n\nTesting for epoch 56 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2845\n\nTesting for epoch 56 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2939\n\nTesting for epoch 56 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3070\n\nTesting for epoch 56 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2890\n\nTesting for epoch 56 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2758\n\nTesting for epoch 56 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2841\n\nTesting for epoch 56 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2826\n\nTesting for epoch 56 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3053\n\nTesting for epoch 56 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2991\n\nTesting for epoch 56 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3194\n\nTesting for epoch 56 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2705\n\nTesting for epoch 56 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3355\n\nTesting for epoch 56 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2967\n\nTesting for epoch 56 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3052\n\nTesting for epoch 56 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3010\n\nTesting for epoch 56 index 22:\n16/16 [==============================] - 0s 4ms/step - loss: 6.3093\n\nTesting for epoch 56 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2840\n\nTesting for epoch 56 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3039\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3050\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3247\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2988\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3270\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2958\n\nTesting for epoch 57 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3076\n\nTesting for epoch 57 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3457\n\nTesting for epoch 57 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3354\n\nTesting for epoch 57 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2985\n\nTesting for epoch 57 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3025\n\nTesting for epoch 57 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3405\n\nTesting for epoch 57 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2959\n\nTesting for epoch 57 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3136\n\nTesting for epoch 57 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2957\n\nTesting for epoch 57 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3203\n\nTesting for epoch 57 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3019\n\nTesting for epoch 57 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3213\n\nTesting for epoch 57 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3553\n\nTesting for epoch 57 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3161\n\nTesting for epoch 57 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3244\n\nTesting for epoch 57 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3466\n\nTesting for epoch 57 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3135\n\nTesting for epoch 57 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3334\n\nTesting for epoch 57 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3397\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3440\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2834\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3472\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3389\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3400\n\nTesting for epoch 58 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3246\n\nTesting for epoch 58 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3517\n\nTesting for epoch 58 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3424\n\nTesting for epoch 58 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3409\n\nTesting for epoch 58 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3381\n\nTesting for epoch 58 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3355\n\nTesting for epoch 58 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3424\n\nTesting for epoch 58 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3348\n\nTesting for epoch 58 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3517\n\nTesting for epoch 58 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3255\n\nTesting for epoch 58 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3588\n\nTesting for epoch 58 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3528\n\nTesting for epoch 58 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3602\n\nTesting for epoch 58 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3422\n\nTesting for epoch 58 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3357\n\nTesting for epoch 58 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3733\n\nTesting for epoch 58 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3791\n\nTesting for epoch 58 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3722\n\nTesting for epoch 58 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3484\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3491\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3330\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3484\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3475\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3823\n\nTesting for epoch 59 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3682\n\nTesting for epoch 59 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.4005\n\nTesting for epoch 59 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3112\n\nTesting for epoch 59 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3412\n\nTesting for epoch 59 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3998\n\nTesting for epoch 59 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3618\n\nTesting for epoch 59 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3380\n\nTesting for epoch 59 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3868\n\nTesting for epoch 59 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3758\n\nTesting for epoch 59 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3380\n\nTesting for epoch 59 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3763\n\nTesting for epoch 59 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3430\n\nTesting for epoch 59 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3584\n\nTesting for epoch 59 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3702\n\nTesting for epoch 59 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3720\n\nTesting for epoch 59 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3751\n\nTesting for epoch 59 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3632\n\nTesting for epoch 59 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3836\n\nTesting for epoch 59 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3873\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3778\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3940\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3929\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3982\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4078\n\nTesting for epoch 60 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4026\n\nTesting for epoch 60 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3660\n\nTesting for epoch 60 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4115\n\nTesting for epoch 60 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3733\n\nTesting for epoch 60 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3655\n\nTesting for epoch 60 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3825\n\nTesting for epoch 60 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4040\n\nTesting for epoch 60 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3846\n\nTesting for epoch 60 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4046\n\nTesting for epoch 60 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3785\n\nTesting for epoch 60 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3916\n\nTesting for epoch 60 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3746\n\nTesting for epoch 60 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.4338\n\nTesting for epoch 60 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4148\n\nTesting for epoch 60 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3923\n\nTesting for epoch 60 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4398\n\nTesting for epoch 60 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3963\n\nTesting for epoch 60 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3854\n\nTesting for epoch 60 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3949\n391/391 [==============================] - 1s 1ms/step\n\n\nSO_GAAL(contamination=0.1, lr_d=0.01, lr_g=0.0001, momentum=0.9,\n    stop_epochs=20)\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 18 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\nWARNING:tensorflow:5 out of the last 401 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f42a90bb9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f42a90bb8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n391/391 [==============================] - 1s 1ms/step\nWARNING:tensorflow:5 out of the last 1947 calls to <function Model.make_train_function.<locals>.train_function at 0x7f428c173040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 1948 calls to <function Model.make_train_function.<locals>.train_function at 0x7f42d2fba040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\nTesting for epoch 1 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 11:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 14:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 16:\n391/391 [==============================] - 0s 977us/step\n\nTesting for epoch 1 index 17:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 5:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 9:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 16:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 19:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 20:\n391/391 [==============================] - 0s 997us/step\n\nTesting for epoch 2 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n391/391 [==============================] - 0s 942us/step\n\nTesting for epoch 3 index 2:\n391/391 [==============================] - 0s 967us/step\n\nTesting for epoch 3 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 10:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 3 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 17:\n391/391 [==============================] - 0s 949us/step\n\nTesting for epoch 3 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 22:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 3 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 4:\n391/391 [==============================] - 0s 682us/step\n\nTesting for epoch 4 index 5:\n391/391 [==============================] - 0s 943us/step\n\nTesting for epoch 4 index 6:\n391/391 [==============================] - 0s 842us/step\n\nTesting for epoch 4 index 7:\n391/391 [==============================] - 0s 622us/step\n\nTesting for epoch 4 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 9:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 10:\n391/391 [==============================] - 0s 612us/step\n\nTesting for epoch 4 index 11:\n391/391 [==============================] - 0s 670us/step\n\nTesting for epoch 4 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 15:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 16:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 17:\n391/391 [==============================] - 0s 865us/step\n\nTesting for epoch 4 index 18:\n391/391 [==============================] - 0s 898us/step\n\nTesting for epoch 4 index 19:\n391/391 [==============================] - 0s 931us/step\n\nTesting for epoch 4 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 21:\n391/391 [==============================] - 0s 970us/step\n\nTesting for epoch 4 index 22:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 4 index 23:\n391/391 [==============================] - 0s 887us/step\n\nTesting for epoch 4 index 24:\n391/391 [==============================] - 0s 976us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 6:\n391/391 [==============================] - 0s 959us/step\n\nTesting for epoch 5 index 7:\n391/391 [==============================] - 0s 934us/step\n\nTesting for epoch 5 index 8:\n391/391 [==============================] - 0s 989us/step\n\nTesting for epoch 5 index 9:\n391/391 [==============================] - 0s 860us/step\n\nTesting for epoch 5 index 10:\n391/391 [==============================] - 0s 908us/step\n\nTesting for epoch 5 index 11:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 5 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 13:\n391/391 [==============================] - 0s 929us/step\n\nTesting for epoch 5 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 15:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 5 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 17:\n391/391 [==============================] - 0s 926us/step\n\nTesting for epoch 5 index 18:\n391/391 [==============================] - 0s 899us/step\n\nTesting for epoch 5 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 21:\n391/391 [==============================] - 0s 964us/step\n\nTesting for epoch 5 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 23:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 5 index 24:\n391/391 [==============================] - 0s 930us/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 2:\n391/391 [==============================] - 0s 958us/step\n\nTesting for epoch 6 index 3:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 6 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 5:\n391/391 [==============================] - 0s 904us/step\n\nTesting for epoch 6 index 6:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 6 index 7:\n391/391 [==============================] - 0s 903us/step\n\nTesting for epoch 6 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 18:\n391/391 [==============================] - 0s 987us/step\n\nTesting for epoch 6 index 19:\n391/391 [==============================] - 0s 978us/step\n\nTesting for epoch 6 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 21:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 6 index 22:\n391/391 [==============================] - 0s 956us/step\n\nTesting for epoch 6 index 23:\n391/391 [==============================] - 0s 994us/step\n\nTesting for epoch 6 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 3:\n391/391 [==============================] - 0s 846us/step\n\nTesting for epoch 7 index 4:\n391/391 [==============================] - 0s 991us/step\n\nTesting for epoch 7 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 16:\n391/391 [==============================] - 0s 901us/step\n\nTesting for epoch 7 index 17:\n391/391 [==============================] - 0s 920us/step\n\nTesting for epoch 7 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 21:\n391/391 [==============================] - 0s 715us/step\n\nTesting for epoch 7 index 22:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 23:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 24:\n391/391 [==============================] - 1s 1ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 4:\n391/391 [==============================] - 0s 972us/step\n\nTesting for epoch 8 index 5:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 8:\n391/391 [==============================] - 0s 851us/step\n\nTesting for epoch 8 index 9:\n391/391 [==============================] - 0s 946us/step\n\nTesting for epoch 8 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 11:\n391/391 [==============================] - 0s 848us/step\n\nTesting for epoch 8 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 14:\n391/391 [==============================] - 0s 938us/step\n\nTesting for epoch 8 index 15:\n391/391 [==============================] - 0s 993us/step\n\nTesting for epoch 8 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 17:\n391/391 [==============================] - 0s 823us/step\n\nTesting for epoch 8 index 18:\n391/391 [==============================] - 0s 783us/step\n\nTesting for epoch 8 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 9 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 3:\n391/391 [==============================] - 0s 894us/step\n\nTesting for epoch 9 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 12:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 14:\n391/391 [==============================] - 0s 916us/step\n\nTesting for epoch 9 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 16:\n391/391 [==============================] - 0s 964us/step\n\nTesting for epoch 9 index 17:\n391/391 [==============================] - 0s 951us/step\n\nTesting for epoch 9 index 18:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 19:\n391/391 [==============================] - 0s 985us/step\n\nTesting for epoch 9 index 20:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n391/391 [==============================] - 0s 999us/step\n\nTesting for epoch 10 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 3:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 10 index 4:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 10 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 10 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 20:\n391/391 [==============================] - 0s 945us/step\n\nTesting for epoch 10 index 21:\n391/391 [==============================] - 0s 880us/step\n\nTesting for epoch 10 index 22:\n391/391 [==============================] - 0s 875us/step\n\nTesting for epoch 10 index 23:\n391/391 [==============================] - 0s 959us/step\n\nTesting for epoch 10 index 24:\n391/391 [==============================] - 0s 987us/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 7:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 11 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 11 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 13:\n391/391 [==============================] - 0s 980us/step\n\nTesting for epoch 11 index 14:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 11 index 15:\n391/391 [==============================] - 0s 1000us/step\n\nTesting for epoch 11 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 17:\n391/391 [==============================] - 0s 832us/step\n\nTesting for epoch 11 index 18:\n391/391 [==============================] - 0s 890us/step\n\nTesting for epoch 11 index 19:\n391/391 [==============================] - 0s 921us/step\n\nTesting for epoch 11 index 20:\n391/391 [==============================] - 0s 996us/step\n\nTesting for epoch 11 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 7:\n391/391 [==============================] - 0s 901us/step\n\nTesting for epoch 12 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 15:\n391/391 [==============================] - 0s 956us/step\n\nTesting for epoch 12 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 18:\n391/391 [==============================] - 0s 902us/step\n\nTesting for epoch 12 index 19:\n391/391 [==============================] - 0s 976us/step\n\nTesting for epoch 12 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 5:\n391/391 [==============================] - 0s 938us/step\n\nTesting for epoch 13 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 8:\n391/391 [==============================] - 0s 876us/step\n\nTesting for epoch 13 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 10:\n391/391 [==============================] - 0s 912us/step\n\nTesting for epoch 13 index 11:\n391/391 [==============================] - 0s 930us/step\n\nTesting for epoch 13 index 12:\n391/391 [==============================] - 0s 980us/step\n\nTesting for epoch 13 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 14:\n391/391 [==============================] - 0s 940us/step\n\nTesting for epoch 13 index 15:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 16:\n391/391 [==============================] - 0s 843us/step\n\nTesting for epoch 13 index 17:\n391/391 [==============================] - 0s 870us/step\n\nTesting for epoch 13 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 20:\n391/391 [==============================] - 0s 918us/step\n\nTesting for epoch 13 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 22:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 13 index 23:\n391/391 [==============================] - 0s 644us/step\n\nTesting for epoch 13 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 14 index 2:\n391/391 [==============================] - 0s 867us/step\n\nTesting for epoch 14 index 3:\n391/391 [==============================] - 1s 2ms/step\n\nTesting for epoch 14 index 4:\n391/391 [==============================] - 0s 992us/step\n\nTesting for epoch 14 index 5:\n391/391 [==============================] - 0s 892us/step\n\nTesting for epoch 14 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 8:\n391/391 [==============================] - 0s 966us/step\n\nTesting for epoch 14 index 9:\n391/391 [==============================] - 0s 993us/step\n\nTesting for epoch 14 index 10:\n391/391 [==============================] - 0s 988us/step\n\nTesting for epoch 14 index 11:\n391/391 [==============================] - 0s 919us/step\n\nTesting for epoch 14 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 17:\n391/391 [==============================] - 0s 982us/step\n\nTesting for epoch 14 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 19:\n391/391 [==============================] - 0s 994us/step\n\nTesting for epoch 14 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 21:\n391/391 [==============================] - 0s 895us/step\n\nTesting for epoch 14 index 22:\n391/391 [==============================] - 0s 894us/step\n\nTesting for epoch 14 index 23:\n391/391 [==============================] - 0s 966us/step\n\nTesting for epoch 14 index 24:\n391/391 [==============================] - 0s 891us/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n391/391 [==============================] - 0s 999us/step\n\nTesting for epoch 15 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 3:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 15 index 4:\n391/391 [==============================] - 0s 967us/step\n\nTesting for epoch 15 index 5:\n391/391 [==============================] - 0s 928us/step\n\nTesting for epoch 15 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 10:\n391/391 [==============================] - 0s 951us/step\n\nTesting for epoch 15 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 12:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 15 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 14:\n391/391 [==============================] - 0s 982us/step\n\nTesting for epoch 15 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 19:\n391/391 [==============================] - 0s 963us/step\n\nTesting for epoch 15 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 21:\n391/391 [==============================] - 0s 978us/step\n\nTesting for epoch 15 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 24:\n391/391 [==============================] - 0s 969us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 2:\n391/391 [==============================] - 0s 998us/step\n\nTesting for epoch 16 index 3:\n391/391 [==============================] - 0s 897us/step\n\nTesting for epoch 16 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 11:\n391/391 [==============================] - 0s 933us/step\n\nTesting for epoch 16 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 13:\n391/391 [==============================] - 0s 987us/step\n\nTesting for epoch 16 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 20:\n391/391 [==============================] - 0s 895us/step\n\nTesting for epoch 16 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 22:\n391/391 [==============================] - 0s 882us/step\n\nTesting for epoch 16 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n391/391 [==============================] - 0s 992us/step\n\nTesting for epoch 17 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 3:\n391/391 [==============================] - 0s 916us/step\n\nTesting for epoch 17 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 7:\n391/391 [==============================] - 0s 854us/step\n\nTesting for epoch 17 index 8:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 17 index 9:\n391/391 [==============================] - 0s 931us/step\n\nTesting for epoch 17 index 10:\n391/391 [==============================] - 0s 615us/step\n\nTesting for epoch 17 index 11:\n391/391 [==============================] - 0s 636us/step\n\nTesting for epoch 17 index 12:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 17 index 13:\n391/391 [==============================] - 0s 645us/step\n\nTesting for epoch 17 index 14:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 17 index 15:\n391/391 [==============================] - 0s 638us/step\n\nTesting for epoch 17 index 16:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 17 index 17:\n391/391 [==============================] - 0s 632us/step\n\nTesting for epoch 17 index 18:\n391/391 [==============================] - 0s 620us/step\n\nTesting for epoch 17 index 19:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 17 index 20:\n391/391 [==============================] - 0s 612us/step\n\nTesting for epoch 17 index 21:\n391/391 [==============================] - 0s 613us/step\n\nTesting for epoch 17 index 22:\n391/391 [==============================] - 0s 601us/step\n\nTesting for epoch 17 index 23:\n391/391 [==============================] - 0s 608us/step\n\nTesting for epoch 17 index 24:\n391/391 [==============================] - 0s 598us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n391/391 [==============================] - 0s 781us/step\n\nTesting for epoch 18 index 2:\n391/391 [==============================] - 0s 656us/step\n\nTesting for epoch 18 index 3:\n391/391 [==============================] - 0s 604us/step\n\nTesting for epoch 18 index 4:\n391/391 [==============================] - 0s 611us/step\n\nTesting for epoch 18 index 5:\n391/391 [==============================] - 0s 619us/step\n\nTesting for epoch 18 index 6:\n391/391 [==============================] - 0s 613us/step\n\nTesting for epoch 18 index 7:\n391/391 [==============================] - 0s 645us/step\n\nTesting for epoch 18 index 8:\n391/391 [==============================] - 0s 625us/step\n\nTesting for epoch 18 index 9:\n391/391 [==============================] - 0s 619us/step\n\nTesting for epoch 18 index 10:\n391/391 [==============================] - 0s 603us/step\n\nTesting for epoch 18 index 11:\n391/391 [==============================] - 0s 606us/step\n\nTesting for epoch 18 index 12:\n391/391 [==============================] - 0s 662us/step\n\nTesting for epoch 18 index 13:\n391/391 [==============================] - 0s 643us/step\n\nTesting for epoch 18 index 14:\n391/391 [==============================] - 0s 826us/step\n\nTesting for epoch 18 index 15:\n391/391 [==============================] - 0s 638us/step\n\nTesting for epoch 18 index 16:\n391/391 [==============================] - 0s 631us/step\n\nTesting for epoch 18 index 17:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 18 index 18:\n391/391 [==============================] - 0s 688us/step\n\nTesting for epoch 18 index 19:\n391/391 [==============================] - 0s 603us/step\n\nTesting for epoch 18 index 20:\n391/391 [==============================] - 0s 633us/step\n\nTesting for epoch 18 index 21:\n391/391 [==============================] - 0s 630us/step\n\nTesting for epoch 18 index 22:\n391/391 [==============================] - 0s 655us/step\n\nTesting for epoch 18 index 23:\n391/391 [==============================] - 0s 608us/step\n\nTesting for epoch 18 index 24:\n391/391 [==============================] - 0s 602us/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n391/391 [==============================] - 0s 617us/step\n\nTesting for epoch 19 index 2:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 19 index 3:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 19 index 4:\n391/391 [==============================] - 0s 609us/step\n\nTesting for epoch 19 index 5:\n391/391 [==============================] - 0s 639us/step\n\nTesting for epoch 19 index 6:\n391/391 [==============================] - 0s 618us/step\n\nTesting for epoch 19 index 7:\n391/391 [==============================] - 0s 630us/step\n\nTesting for epoch 19 index 8:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 19 index 9:\n391/391 [==============================] - 0s 764us/step\n\nTesting for epoch 19 index 10:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 19 index 11:\n391/391 [==============================] - 0s 738us/step\n\nTesting for epoch 19 index 12:\n391/391 [==============================] - 0s 629us/step\n\nTesting for epoch 19 index 13:\n391/391 [==============================] - 0s 831us/step\n\nTesting for epoch 19 index 14:\n391/391 [==============================] - 0s 621us/step\n\nTesting for epoch 19 index 15:\n391/391 [==============================] - 0s 636us/step\n\nTesting for epoch 19 index 16:\n391/391 [==============================] - 0s 652us/step\n\nTesting for epoch 19 index 17:\n391/391 [==============================] - 0s 646us/step\n\nTesting for epoch 19 index 18:\n391/391 [==============================] - 0s 652us/step\n\nTesting for epoch 19 index 19:\n391/391 [==============================] - 0s 639us/step\n\nTesting for epoch 19 index 20:\n391/391 [==============================] - 0s 649us/step\n\nTesting for epoch 19 index 21:\n391/391 [==============================] - 0s 659us/step\n\nTesting for epoch 19 index 22:\n391/391 [==============================] - 0s 836us/step\n\nTesting for epoch 19 index 23:\n391/391 [==============================] - 0s 655us/step\n\nTesting for epoch 19 index 24:\n391/391 [==============================] - 0s 640us/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n391/391 [==============================] - 0s 618us/step\n\nTesting for epoch 20 index 2:\n391/391 [==============================] - 0s 649us/step\n\nTesting for epoch 20 index 3:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 4:\n391/391 [==============================] - 0s 688us/step\n\nTesting for epoch 20 index 5:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 20 index 6:\n391/391 [==============================] - 0s 622us/step\n\nTesting for epoch 20 index 7:\n391/391 [==============================] - 0s 654us/step\n\nTesting for epoch 20 index 8:\n391/391 [==============================] - 0s 634us/step\n\nTesting for epoch 20 index 9:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 10:\n391/391 [==============================] - 0s 667us/step\n\nTesting for epoch 20 index 11:\n391/391 [==============================] - 0s 673us/step\n\nTesting for epoch 20 index 12:\n391/391 [==============================] - 0s 672us/step\n\nTesting for epoch 20 index 13:\n391/391 [==============================] - 0s 646us/step\n\nTesting for epoch 20 index 14:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 15:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 20 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 17:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 19:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 20:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 24:\n391/391 [==============================] - 1s 1ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 21 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0053\n16/16 [==============================] - 0s 3ms/step - loss: 4.1893\n16/16 [==============================] - 0s 4ms/step - loss: 4.1896\n16/16 [==============================] - 0s 1ms/step - loss: 4.5660\n16/16 [==============================] - 0s 1ms/step - loss: 4.5671\n16/16 [==============================] - 0s 1ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 4ms/step - loss: 4.5671\n\nTesting for epoch 21 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0072\n16/16 [==============================] - 0s 3ms/step - loss: 4.2069\n16/16 [==============================] - 0s 3ms/step - loss: 4.2071\n16/16 [==============================] - 0s 5ms/step - loss: 4.5838\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 3ms/step - loss: 4.5849\n16/16 [==============================] - 0s 3ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n\nTesting for epoch 21 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0059\n16/16 [==============================] - 0s 3ms/step - loss: 4.1521\n16/16 [==============================] - 0s 930us/step - loss: 4.1524\n16/16 [==============================] - 0s 1ms/step - loss: 4.5355\n16/16 [==============================] - 0s 827us/step - loss: 4.5366\n16/16 [==============================] - 0s 907us/step - loss: 4.5366\n16/16 [==============================] - 0s 974us/step - loss: 4.5366\n16/16 [==============================] - 0s 1ms/step - loss: 4.5366\n16/16 [==============================] - 0s 987us/step - loss: 4.5366\n16/16 [==============================] - 0s 1ms/step - loss: 4.5366\n\nTesting for epoch 21 index 5:\n391/391 [==============================] - 0s 673us/step\n16/16 [==============================] - 0s 968us/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.1369\n16/16 [==============================] - 0s 1ms/step - loss: 4.1371\n16/16 [==============================] - 0s 1ms/step - loss: 4.5217\n16/16 [==============================] - 0s 1ms/step - loss: 4.5228\n16/16 [==============================] - 0s 1ms/step - loss: 4.5228\n16/16 [==============================] - 0s 997us/step - loss: 4.5228\n16/16 [==============================] - 0s 3ms/step - loss: 4.5228\n16/16 [==============================] - 0s 3ms/step - loss: 4.5228\n16/16 [==============================] - 0s 2ms/step - loss: 4.5228\n\nTesting for epoch 21 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0067\n16/16 [==============================] - 0s 3ms/step - loss: 4.1889\n16/16 [==============================] - 0s 2ms/step - loss: 4.1892\n16/16 [==============================] - 0s 2ms/step - loss: 4.5693\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 2ms/step - loss: 4.5704\n16/16 [==============================] - 0s 2ms/step - loss: 4.5704\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 4ms/step - loss: 4.5704\n\nTesting for epoch 21 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 4ms/step - loss: 4.1930\n16/16 [==============================] - 0s 2ms/step - loss: 4.1932\n16/16 [==============================] - 0s 3ms/step - loss: 4.5745\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 3ms/step - loss: 4.5756\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 3ms/step - loss: 4.5756\n16/16 [==============================] - 0s 5ms/step - loss: 4.5756\n\nTesting for epoch 21 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 4.1874\n16/16 [==============================] - 0s 2ms/step - loss: 4.1877\n16/16 [==============================] - 0s 2ms/step - loss: 4.5691\n16/16 [==============================] - 0s 3ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 4ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n\nTesting for epoch 21 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.1984\n16/16 [==============================] - 0s 2ms/step - loss: 4.1986\n16/16 [==============================] - 0s 2ms/step - loss: 4.5770\n16/16 [==============================] - 0s 3ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n16/16 [==============================] - 0s 1ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n16/16 [==============================] - 0s 1ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n\nTesting for epoch 21 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.1775\n16/16 [==============================] - 0s 2ms/step - loss: 4.1778\n16/16 [==============================] - 0s 3ms/step - loss: 4.5610\n16/16 [==============================] - 0s 1ms/step - loss: 4.5621\n16/16 [==============================] - 0s 3ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n16/16 [==============================] - 0s 1ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n\nTesting for epoch 21 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.1644\n16/16 [==============================] - 0s 2ms/step - loss: 4.1646\n16/16 [==============================] - 0s 2ms/step - loss: 4.5477\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 1ms/step - loss: 4.5488\n\nTesting for epoch 21 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.1831\n16/16 [==============================] - 0s 2ms/step - loss: 4.1833\n16/16 [==============================] - 0s 3ms/step - loss: 4.5658\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 4ms/step - loss: 4.5669\n16/16 [==============================] - 0s 1ms/step - loss: 4.5669\n\nTesting for epoch 21 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 4.2442\n16/16 [==============================] - 0s 3ms/step - loss: 4.2445\n16/16 [==============================] - 0s 1ms/step - loss: 4.6221\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 1ms/step - loss: 4.6232\n16/16 [==============================] - 0s 1ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n\nTesting for epoch 21 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0063\n16/16 [==============================] - 0s 1ms/step - loss: 4.2739\n16/16 [==============================] - 0s 2ms/step - loss: 4.2742\n16/16 [==============================] - 0s 2ms/step - loss: 4.6488\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 4ms/step - loss: 4.6499\n\nTesting for epoch 21 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0056\n16/16 [==============================] - 0s 3ms/step - loss: 4.2872\n16/16 [==============================] - 0s 2ms/step - loss: 4.2875\n16/16 [==============================] - 0s 2ms/step - loss: 4.6619\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 1ms/step - loss: 4.6629\n16/16 [==============================] - 0s 5ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n\nTesting for epoch 21 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 4.2823\n16/16 [==============================] - 0s 2ms/step - loss: 4.2825\n16/16 [==============================] - 0s 2ms/step - loss: 4.6577\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n\nTesting for epoch 21 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0051\n16/16 [==============================] - 0s 1ms/step - loss: 4.2732\n16/16 [==============================] - 0s 2ms/step - loss: 4.2735\n16/16 [==============================] - 0s 2ms/step - loss: 4.6472\n16/16 [==============================] - 0s 3ms/step - loss: 4.6483\n16/16 [==============================] - 0s 2ms/step - loss: 4.6483\n16/16 [==============================] - 0s 1ms/step - loss: 4.6483\n16/16 [==============================] - 0s 2ms/step - loss: 4.6483\n16/16 [==============================] - 0s 4ms/step - loss: 4.6483\n16/16 [==============================] - 0s 3ms/step - loss: 4.6483\n\nTesting for epoch 21 index 18:\n391/391 [==============================] - 0s 945us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3485\n16/16 [==============================] - 0s 2ms/step - loss: 4.3488\n16/16 [==============================] - 0s 2ms/step - loss: 4.7173\n16/16 [==============================] - 0s 2ms/step - loss: 4.7184\n16/16 [==============================] - 0s 3ms/step - loss: 4.7184\n16/16 [==============================] - 0s 1ms/step - loss: 4.7184\n16/16 [==============================] - 0s 1ms/step - loss: 4.7184\n16/16 [==============================] - 0s 4ms/step - loss: 4.7184\n16/16 [==============================] - 0s 2ms/step - loss: 4.7184\n\nTesting for epoch 21 index 19:\n391/391 [==============================] - 0s 983us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.3035\n16/16 [==============================] - 0s 2ms/step - loss: 4.3038\n16/16 [==============================] - 0s 2ms/step - loss: 4.6748\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n\nTesting for epoch 21 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 4.3505\n16/16 [==============================] - 0s 2ms/step - loss: 4.3507\n16/16 [==============================] - 0s 2ms/step - loss: 4.7176\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 2ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 2ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n\nTesting for epoch 21 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0064\n16/16 [==============================] - 0s 2ms/step - loss: 4.3991\n16/16 [==============================] - 0s 4ms/step - loss: 4.3993\n16/16 [==============================] - 0s 2ms/step - loss: 4.7654\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n\nTesting for epoch 21 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 4.3672\n16/16 [==============================] - 0s 3ms/step - loss: 4.3675\n16/16 [==============================] - 0s 2ms/step - loss: 4.7352\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 1ms/step - loss: 4.7362\n16/16 [==============================] - 0s 3ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n\nTesting for epoch 21 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 4.3807\n16/16 [==============================] - 0s 2ms/step - loss: 4.3810\n16/16 [==============================] - 0s 2ms/step - loss: 4.7456\n16/16 [==============================] - 0s 2ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 2ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n\nTesting for epoch 21 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.3179\n16/16 [==============================] - 0s 2ms/step - loss: 4.3181\n16/16 [==============================] - 0s 2ms/step - loss: 4.6918\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\n16/16 [==============================] - 0s 3ms/step - loss: 4.6929\n16/16 [==============================] - 0s 1ms/step - loss: 4.6929\n16/16 [==============================] - 0s 1ms/step - loss: 4.6929\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.3862\n16/16 [==============================] - 0s 2ms/step - loss: 4.3865\n16/16 [==============================] - 0s 2ms/step - loss: 4.7532\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n\nTesting for epoch 22 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3229\n16/16 [==============================] - 0s 2ms/step - loss: 4.3231\n16/16 [==============================] - 0s 2ms/step - loss: 4.6981\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 1ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n\nTesting for epoch 22 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.2999\n16/16 [==============================] - 0s 1ms/step - loss: 4.3002\n16/16 [==============================] - 0s 1ms/step - loss: 4.6792\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 3ms/step - loss: 4.6803\n16/16 [==============================] - 0s 3ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n\nTesting for epoch 22 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.2638\n16/16 [==============================] - 0s 2ms/step - loss: 4.2640\n16/16 [==============================] - 0s 2ms/step - loss: 4.6468\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 1ms/step - loss: 4.6479\n16/16 [==============================] - 0s 1ms/step - loss: 4.6479\n\nTesting for epoch 22 index 5:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 3ms/step - loss: 4.2638\n16/16 [==============================] - 0s 2ms/step - loss: 4.2641\n16/16 [==============================] - 0s 2ms/step - loss: 4.6476\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 1ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 1ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n\nTesting for epoch 22 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.2891\n16/16 [==============================] - 0s 1ms/step - loss: 4.2893\n16/16 [==============================] - 0s 2ms/step - loss: 4.6713\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n\nTesting for epoch 22 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.2911\n16/16 [==============================] - 0s 2ms/step - loss: 4.2914\n16/16 [==============================] - 0s 2ms/step - loss: 4.6719\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 1ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 1ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n\nTesting for epoch 22 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3165\n16/16 [==============================] - 0s 2ms/step - loss: 4.3168\n16/16 [==============================] - 0s 2ms/step - loss: 4.6965\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n\nTesting for epoch 22 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 1ms/step - loss: 4.3859\n16/16 [==============================] - 0s 2ms/step - loss: 4.3862\n16/16 [==============================] - 0s 3ms/step - loss: 4.7585\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 1ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 1ms/step - loss: 4.7596\n\nTesting for epoch 22 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.3127\n16/16 [==============================] - 0s 1ms/step - loss: 4.3130\n16/16 [==============================] - 0s 1ms/step - loss: 4.6926\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n16/16 [==============================] - 0s 1ms/step - loss: 4.6937\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n16/16 [==============================] - 0s 1ms/step - loss: 4.6937\n16/16 [==============================] - 0s 3ms/step - loss: 4.6937\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n\nTesting for epoch 22 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0052\n16/16 [==============================] - 0s 1ms/step - loss: 4.3202\n16/16 [==============================] - 0s 2ms/step - loss: 4.3205\n16/16 [==============================] - 0s 2ms/step - loss: 4.7029\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 3ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 3ms/step - loss: 4.7040\n\nTesting for epoch 22 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.2978\n16/16 [==============================] - 0s 2ms/step - loss: 4.2981\n16/16 [==============================] - 0s 2ms/step - loss: 4.6837\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n16/16 [==============================] - 0s 3ms/step - loss: 4.6848\n16/16 [==============================] - 0s 2ms/step - loss: 4.6848\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n16/16 [==============================] - 0s 2ms/step - loss: 4.6848\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n\nTesting for epoch 22 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.3087\n16/16 [==============================] - 0s 3ms/step - loss: 4.3090\n16/16 [==============================] - 0s 3ms/step - loss: 4.6928\n16/16 [==============================] - 0s 1ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 1ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n\nTesting for epoch 22 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3293\n16/16 [==============================] - 0s 3ms/step - loss: 4.3296\n16/16 [==============================] - 0s 2ms/step - loss: 4.7114\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n\nTesting for epoch 22 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3222\n16/16 [==============================] - 0s 2ms/step - loss: 4.3225\n16/16 [==============================] - 0s 2ms/step - loss: 4.7039\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 3ms/step - loss: 4.7050\n16/16 [==============================] - 0s 3ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n\nTesting for epoch 22 index 16:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.3243\n16/16 [==============================] - 0s 2ms/step - loss: 4.3246\n16/16 [==============================] - 0s 2ms/step - loss: 4.7087\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n\nTesting for epoch 22 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3615\n16/16 [==============================] - 0s 2ms/step - loss: 4.3617\n16/16 [==============================] - 0s 3ms/step - loss: 4.7409\n16/16 [==============================] - 0s 1ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 1ms/step - loss: 4.7420\n\nTesting for epoch 22 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 2ms/step - loss: 4.3704\n16/16 [==============================] - 0s 2ms/step - loss: 4.3707\n16/16 [==============================] - 0s 2ms/step - loss: 4.7505\n16/16 [==============================] - 0s 4ms/step - loss: 4.7516\n16/16 [==============================] - 0s 2ms/step - loss: 4.7516\n16/16 [==============================] - 0s 3ms/step - loss: 4.7516\n16/16 [==============================] - 0s 1ms/step - loss: 4.7516\n16/16 [==============================] - 0s 2ms/step - loss: 4.7516\n16/16 [==============================] - 0s 3ms/step - loss: 4.7516\n\nTesting for epoch 22 index 19:\n391/391 [==============================] - 0s 993us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.3239\n16/16 [==============================] - 0s 1ms/step - loss: 4.3242\n16/16 [==============================] - 0s 3ms/step - loss: 4.7060\n16/16 [==============================] - 0s 3ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 3ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n\nTesting for epoch 22 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.3742\n16/16 [==============================] - 0s 2ms/step - loss: 4.3744\n16/16 [==============================] - 0s 2ms/step - loss: 4.7507\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 3ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 2ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n\nTesting for epoch 22 index 21:\n391/391 [==============================] - 0s 918us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.4461\n16/16 [==============================] - 0s 1ms/step - loss: 4.4464\n16/16 [==============================] - 0s 2ms/step - loss: 4.8190\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 3ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 1ms/step - loss: 4.8201\n\nTesting for epoch 22 index 22:\n391/391 [==============================] - 0s 965us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.4383\n16/16 [==============================] - 0s 2ms/step - loss: 4.4386\n16/16 [==============================] - 0s 2ms/step - loss: 4.8103\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 3ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n\nTesting for epoch 22 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 4ms/step - loss: 4.4555\n16/16 [==============================] - 0s 1ms/step - loss: 4.4558\n16/16 [==============================] - 0s 2ms/step - loss: 4.8272\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 2ms/step - loss: 4.8283\n16/16 [==============================] - 0s 4ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n\nTesting for epoch 22 index 24:\n391/391 [==============================] - 0s 989us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.4925\n16/16 [==============================] - 0s 3ms/step - loss: 4.4928\n16/16 [==============================] - 0s 3ms/step - loss: 4.8605\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 1ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 3ms/step - loss: 4.4335\n16/16 [==============================] - 0s 1ms/step - loss: 4.4337\n16/16 [==============================] - 0s 2ms/step - loss: 4.8087\n16/16 [==============================] - 0s 2ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 2ms/step - loss: 4.8098\n\nTesting for epoch 23 index 2:\n391/391 [==============================] - 0s 951us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4281\n16/16 [==============================] - 0s 1ms/step - loss: 4.4284\n16/16 [==============================] - 0s 1ms/step - loss: 4.8030\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n\nTesting for epoch 23 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4436\n16/16 [==============================] - 0s 2ms/step - loss: 4.4439\n16/16 [==============================] - 0s 2ms/step - loss: 4.8185\n16/16 [==============================] - 0s 3ms/step - loss: 4.8196\n16/16 [==============================] - 0s 1ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n\nTesting for epoch 23 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.4666\n16/16 [==============================] - 0s 1ms/step - loss: 4.4669\n16/16 [==============================] - 0s 1ms/step - loss: 4.8390\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n16/16 [==============================] - 0s 4ms/step - loss: 4.8401\n16/16 [==============================] - 0s 3ms/step - loss: 4.8401\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n16/16 [==============================] - 0s 1ms/step - loss: 4.8401\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n\nTesting for epoch 23 index 5:\n391/391 [==============================] - 0s 997us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 1ms/step - loss: 4.4613\n16/16 [==============================] - 0s 2ms/step - loss: 4.4616\n16/16 [==============================] - 0s 1ms/step - loss: 4.8346\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n16/16 [==============================] - 0s 1ms/step - loss: 4.8357\n16/16 [==============================] - 0s 1ms/step - loss: 4.8357\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n16/16 [==============================] - 0s 3ms/step - loss: 4.8357\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n\nTesting for epoch 23 index 6:\n391/391 [==============================] - 0s 986us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.4197\n16/16 [==============================] - 0s 1ms/step - loss: 4.4200\n16/16 [==============================] - 0s 2ms/step - loss: 4.7974\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n\nTesting for epoch 23 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.4492\n16/16 [==============================] - 0s 2ms/step - loss: 4.4495\n16/16 [==============================] - 0s 2ms/step - loss: 4.8234\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 4ms/step - loss: 4.8245\n\nTesting for epoch 23 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.4667\n16/16 [==============================] - 0s 3ms/step - loss: 4.4670\n16/16 [==============================] - 0s 3ms/step - loss: 4.8407\n16/16 [==============================] - 0s 1ms/step - loss: 4.8418\n16/16 [==============================] - 0s 3ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n16/16 [==============================] - 0s 1ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n\nTesting for epoch 23 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 1ms/step - loss: 4.4875\n16/16 [==============================] - 0s 3ms/step - loss: 4.4878\n16/16 [==============================] - 0s 2ms/step - loss: 4.8594\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 3ms/step - loss: 4.8605\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 2ms/step - loss: 4.8605\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 5ms/step - loss: 4.8605\n\nTesting for epoch 23 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.4148\n16/16 [==============================] - 0s 2ms/step - loss: 4.4150\n16/16 [==============================] - 0s 2ms/step - loss: 4.7937\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 4ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 3ms/step - loss: 4.7948\n\nTesting for epoch 23 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3964\n16/16 [==============================] - 0s 2ms/step - loss: 4.3967\n16/16 [==============================] - 0s 1ms/step - loss: 4.7782\n16/16 [==============================] - 0s 1ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 4ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n\nTesting for epoch 23 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 3ms/step - loss: 4.4029\n16/16 [==============================] - 0s 2ms/step - loss: 4.4032\n16/16 [==============================] - 0s 1ms/step - loss: 4.7863\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 1ms/step - loss: 4.7874\n16/16 [==============================] - 0s 4ms/step - loss: 4.7874\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 1ms/step - loss: 4.7874\n\nTesting for epoch 23 index 13:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 4.4024\n16/16 [==============================] - 0s 2ms/step - loss: 4.4027\n16/16 [==============================] - 0s 2ms/step - loss: 4.7849\n16/16 [==============================] - 0s 1ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 1ms/step - loss: 4.7860\n\nTesting for epoch 23 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 1ms/step - loss: 4.4157\n16/16 [==============================] - 0s 2ms/step - loss: 4.4160\n16/16 [==============================] - 0s 2ms/step - loss: 4.7979\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n\nTesting for epoch 23 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.4537\n16/16 [==============================] - 0s 1ms/step - loss: 4.4539\n16/16 [==============================] - 0s 2ms/step - loss: 4.8338\n16/16 [==============================] - 0s 1ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 3ms/step - loss: 4.8349\n\nTesting for epoch 23 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 4.4932\n16/16 [==============================] - 0s 2ms/step - loss: 4.4934\n16/16 [==============================] - 0s 1ms/step - loss: 4.8687\n16/16 [==============================] - 0s 3ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 3ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n\nTesting for epoch 23 index 17:\n391/391 [==============================] - 0s 1000us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.4651\n16/16 [==============================] - 0s 1ms/step - loss: 4.4654\n16/16 [==============================] - 0s 1ms/step - loss: 4.8447\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 2ms/step - loss: 4.8458\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 3ms/step - loss: 4.8458\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 2ms/step - loss: 4.8458\n\nTesting for epoch 23 index 18:\n391/391 [==============================] - 0s 936us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4351\n16/16 [==============================] - 0s 1ms/step - loss: 4.4354\n16/16 [==============================] - 0s 2ms/step - loss: 4.8153\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n\nTesting for epoch 23 index 19:\n391/391 [==============================] - 0s 952us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5066\n16/16 [==============================] - 0s 2ms/step - loss: 4.5068\n16/16 [==============================] - 0s 2ms/step - loss: 4.8831\n16/16 [==============================] - 0s 1ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 3ms/step - loss: 4.8842\n\nTesting for epoch 23 index 20:\n391/391 [==============================] - 0s 939us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 4.4556\n16/16 [==============================] - 0s 2ms/step - loss: 4.4559\n16/16 [==============================] - 0s 2ms/step - loss: 4.8344\n16/16 [==============================] - 0s 3ms/step - loss: 4.8355\n16/16 [==============================] - 0s 3ms/step - loss: 4.8355\n16/16 [==============================] - 0s 2ms/step - loss: 4.8355\n16/16 [==============================] - 0s 1ms/step - loss: 4.8355\n16/16 [==============================] - 0s 1ms/step - loss: 4.8355\n16/16 [==============================] - 0s 2ms/step - loss: 4.8355\n\nTesting for epoch 23 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.5131\n16/16 [==============================] - 0s 1ms/step - loss: 4.5133\n16/16 [==============================] - 0s 728us/step - loss: 4.8877\n16/16 [==============================] - 0s 1ms/step - loss: 4.8887\n16/16 [==============================] - 0s 2ms/step - loss: 4.8887\n16/16 [==============================] - 0s 889us/step - loss: 4.8887\n16/16 [==============================] - 0s 772us/step - loss: 4.8887\n16/16 [==============================] - 0s 838us/step - loss: 4.8887\n16/16 [==============================] - 0s 849us/step - loss: 4.8887\n\nTesting for epoch 23 index 22:\n391/391 [==============================] - 0s 893us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 4.4867\n16/16 [==============================] - 0s 1ms/step - loss: 4.4870\n16/16 [==============================] - 0s 902us/step - loss: 4.8632\n16/16 [==============================] - 0s 2ms/step - loss: 4.8643\n16/16 [==============================] - 0s 1ms/step - loss: 4.8643\n16/16 [==============================] - 0s 3ms/step - loss: 4.8643\n16/16 [==============================] - 0s 3ms/step - loss: 4.8643\n16/16 [==============================] - 0s 2ms/step - loss: 4.8643\n16/16 [==============================] - 0s 928us/step - loss: 4.8643\n\nTesting for epoch 23 index 23:\n391/391 [==============================] - 0s 903us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 1ms/step - loss: 4.5020\n16/16 [==============================] - 0s 778us/step - loss: 4.5023\n16/16 [==============================] - 0s 851us/step - loss: 4.8761\n16/16 [==============================] - 0s 917us/step - loss: 4.8772\n16/16 [==============================] - 0s 969us/step - loss: 4.8772\n16/16 [==============================] - 0s 1ms/step - loss: 4.8772\n16/16 [==============================] - 0s 935us/step - loss: 4.8772\n16/16 [==============================] - 0s 4ms/step - loss: 4.8772\n16/16 [==============================] - 0s 3ms/step - loss: 4.8772\n\nTesting for epoch 23 index 24:\n391/391 [==============================] - 0s 647us/step\n16/16 [==============================] - 0s 955us/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.5345\n16/16 [==============================] - 0s 909us/step - loss: 4.5348\n16/16 [==============================] - 0s 2ms/step - loss: 4.9093\n16/16 [==============================] - 0s 867us/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 3ms/step - loss: 4.9104\n16/16 [==============================] - 0s 1ms/step - loss: 4.9104\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n391/391 [==============================] - 0s 672us/step\n16/16 [==============================] - 0s 927us/step - loss: 0.0042\n16/16 [==============================] - 0s 916us/step - loss: 4.5175\n16/16 [==============================] - 0s 913us/step - loss: 4.5178\n16/16 [==============================] - 0s 900us/step - loss: 4.8923\n16/16 [==============================] - 0s 892us/step - loss: 4.8934\n16/16 [==============================] - 0s 925us/step - loss: 4.8934\n16/16 [==============================] - 0s 879us/step - loss: 4.8934\n16/16 [==============================] - 0s 876us/step - loss: 4.8934\n16/16 [==============================] - 0s 881us/step - loss: 4.8934\n16/16 [==============================] - 0s 879us/step - loss: 4.8934\n\nTesting for epoch 24 index 2:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 902us/step - loss: 0.0049\n16/16 [==============================] - 0s 904us/step - loss: 4.5500\n16/16 [==============================] - 0s 916us/step - loss: 4.5503\n16/16 [==============================] - 0s 944us/step - loss: 4.9224\n16/16 [==============================] - 0s 910us/step - loss: 4.9234\n16/16 [==============================] - 0s 918us/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n16/16 [==============================] - 0s 6ms/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n\nTesting for epoch 24 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 5ms/step - loss: 4.5574\n16/16 [==============================] - 0s 2ms/step - loss: 4.5577\n16/16 [==============================] - 0s 2ms/step - loss: 4.9311\n16/16 [==============================] - 0s 3ms/step - loss: 4.9322\n16/16 [==============================] - 0s 2ms/step - loss: 4.9322\n16/16 [==============================] - 0s 3ms/step - loss: 4.9322\n16/16 [==============================] - 0s 2ms/step - loss: 4.9322\n16/16 [==============================] - 0s 1ms/step - loss: 4.9322\n16/16 [==============================] - 0s 994us/step - loss: 4.9322\n\nTesting for epoch 24 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 5ms/step - loss: 4.5304\n16/16 [==============================] - 0s 2ms/step - loss: 4.5307\n16/16 [==============================] - 0s 2ms/step - loss: 4.9069\n16/16 [==============================] - 0s 4ms/step - loss: 4.9079\n16/16 [==============================] - 0s 2ms/step - loss: 4.9079\n16/16 [==============================] - 0s 5ms/step - loss: 4.9079\n16/16 [==============================] - 0s 4ms/step - loss: 4.9079\n16/16 [==============================] - 0s 3ms/step - loss: 4.9079\n16/16 [==============================] - 0s 2ms/step - loss: 4.9079\n\nTesting for epoch 24 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 982us/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4956\n16/16 [==============================] - 0s 796us/step - loss: 4.4959\n16/16 [==============================] - 0s 758us/step - loss: 4.8745\n16/16 [==============================] - 0s 754us/step - loss: 4.8756\n16/16 [==============================] - 0s 768us/step - loss: 4.8756\n16/16 [==============================] - 0s 726us/step - loss: 4.8756\n16/16 [==============================] - 0s 842us/step - loss: 4.8756\n16/16 [==============================] - 0s 4ms/step - loss: 4.8756\n16/16 [==============================] - 0s 2ms/step - loss: 4.8756\n\nTesting for epoch 24 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 1ms/step - loss: 4.5620\n16/16 [==============================] - 0s 991us/step - loss: 4.5623\n16/16 [==============================] - 0s 1ms/step - loss: 4.9368\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n\nTesting for epoch 24 index 7:\n391/391 [==============================] - 0s 914us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5452\n16/16 [==============================] - 0s 2ms/step - loss: 4.5454\n16/16 [==============================] - 0s 2ms/step - loss: 4.9175\n16/16 [==============================] - 0s 3ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 1ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n\nTesting for epoch 24 index 8:\n391/391 [==============================] - 0s 881us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.5784\n16/16 [==============================] - 0s 3ms/step - loss: 4.5786\n16/16 [==============================] - 0s 3ms/step - loss: 4.9519\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 3ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n\nTesting for epoch 24 index 9:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.5186\n16/16 [==============================] - 0s 1ms/step - loss: 4.5188\n16/16 [==============================] - 0s 1ms/step - loss: 4.8953\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 3ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 4ms/step - loss: 4.8963\n\nTesting for epoch 24 index 10:\n391/391 [==============================] - 0s 903us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 4.4716\n16/16 [==============================] - 0s 2ms/step - loss: 4.4719\n16/16 [==============================] - 0s 1ms/step - loss: 4.8556\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n16/16 [==============================] - 0s 1ms/step - loss: 4.8567\n16/16 [==============================] - 0s 1ms/step - loss: 4.8567\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n16/16 [==============================] - 0s 3ms/step - loss: 4.8567\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n\nTesting for epoch 24 index 11:\n391/391 [==============================] - 0s 949us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5166\n16/16 [==============================] - 0s 3ms/step - loss: 4.5169\n16/16 [==============================] - 0s 2ms/step - loss: 4.8974\n16/16 [==============================] - 0s 1ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 3ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n\nTesting for epoch 24 index 12:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0044\n16/16 [==============================] - 0s 3ms/step - loss: 4.5020\n16/16 [==============================] - 0s 2ms/step - loss: 4.5023\n16/16 [==============================] - 0s 2ms/step - loss: 4.8845\n16/16 [==============================] - 0s 1ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n16/16 [==============================] - 0s 1ms/step - loss: 4.8856\n16/16 [==============================] - 0s 3ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n\nTesting for epoch 24 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0049\n16/16 [==============================] - 0s 3ms/step - loss: 4.5226\n16/16 [==============================] - 0s 2ms/step - loss: 4.5229\n16/16 [==============================] - 0s 1ms/step - loss: 4.9059\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n\nTesting for epoch 24 index 14:\n391/391 [==============================] - 0s 960us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.4661\n16/16 [==============================] - 0s 1ms/step - loss: 4.4663\n16/16 [==============================] - 0s 2ms/step - loss: 4.8525\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 1ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n\nTesting for epoch 24 index 15:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 1ms/step - loss: 4.5250\n16/16 [==============================] - 0s 1ms/step - loss: 4.5253\n16/16 [==============================] - 0s 2ms/step - loss: 4.9072\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 1ms/step - loss: 4.9083\n16/16 [==============================] - 0s 3ms/step - loss: 4.9083\n16/16 [==============================] - 0s 3ms/step - loss: 4.9083\n\nTesting for epoch 24 index 16:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.5276\n16/16 [==============================] - 0s 3ms/step - loss: 4.5278\n16/16 [==============================] - 0s 3ms/step - loss: 4.9098\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 3ms/step - loss: 4.9109\n16/16 [==============================] - 0s 3ms/step - loss: 4.9109\n\nTesting for epoch 24 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0050\n16/16 [==============================] - 0s 4ms/step - loss: 4.5145\n16/16 [==============================] - 0s 2ms/step - loss: 4.5148\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 4ms/step - loss: 4.8996\n16/16 [==============================] - 0s 1ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n16/16 [==============================] - 0s 1ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n\nTesting for epoch 24 index 18:\n391/391 [==============================] - 0s 969us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.5528\n16/16 [==============================] - 0s 2ms/step - loss: 4.5531\n16/16 [==============================] - 0s 2ms/step - loss: 4.9327\n16/16 [==============================] - 0s 4ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 4ms/step - loss: 4.9338\n16/16 [==============================] - 0s 2ms/step - loss: 4.9338\n\nTesting for epoch 24 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.5499\n16/16 [==============================] - 0s 4ms/step - loss: 4.5501\n16/16 [==============================] - 0s 3ms/step - loss: 4.9307\n16/16 [==============================] - 0s 1ms/step - loss: 4.9318\n16/16 [==============================] - 0s 3ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 3ms/step - loss: 4.9318\n\nTesting for epoch 24 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.5648\n16/16 [==============================] - 0s 4ms/step - loss: 4.5651\n16/16 [==============================] - 0s 4ms/step - loss: 4.9456\n16/16 [==============================] - 0s 1ms/step - loss: 4.9467\n16/16 [==============================] - 0s 4ms/step - loss: 4.9467\n16/16 [==============================] - 0s 2ms/step - loss: 4.9467\n16/16 [==============================] - 0s 1ms/step - loss: 4.9467\n16/16 [==============================] - 0s 3ms/step - loss: 4.9467\n16/16 [==============================] - 0s 2ms/step - loss: 4.9467\n\nTesting for epoch 24 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.5633\n16/16 [==============================] - 0s 2ms/step - loss: 4.5635\n16/16 [==============================] - 0s 2ms/step - loss: 4.9406\n16/16 [==============================] - 0s 3ms/step - loss: 4.9417\n16/16 [==============================] - 0s 4ms/step - loss: 4.9417\n16/16 [==============================] - 0s 1ms/step - loss: 4.9417\n16/16 [==============================] - 0s 2ms/step - loss: 4.9417\n16/16 [==============================] - 0s 4ms/step - loss: 4.9417\n16/16 [==============================] - 0s 2ms/step - loss: 4.9417\n\nTesting for epoch 24 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6313\n16/16 [==============================] - 0s 2ms/step - loss: 4.6316\n16/16 [==============================] - 0s 1ms/step - loss: 5.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.0056\n16/16 [==============================] - 0s 2ms/step - loss: 5.0056\n16/16 [==============================] - 0s 6ms/step - loss: 5.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.0056\n16/16 [==============================] - 0s 4ms/step - loss: 5.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.0056\n\nTesting for epoch 24 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 4ms/step - loss: 4.5705\n16/16 [==============================] - 0s 4ms/step - loss: 4.9485\n16/16 [==============================] - 0s 5ms/step - loss: 4.9496\n16/16 [==============================] - 0s 6ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n16/16 [==============================] - 0s 1ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n\nTesting for epoch 24 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 4ms/step - loss: 4.6156\n16/16 [==============================] - 0s 2ms/step - loss: 4.6158\n16/16 [==============================] - 0s 3ms/step - loss: 4.9893\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 3ms/step - loss: 4.9903\n16/16 [==============================] - 0s 3ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.5986\n16/16 [==============================] - 0s 1ms/step - loss: 4.5989\n16/16 [==============================] - 0s 2ms/step - loss: 4.9743\n16/16 [==============================] - 0s 4ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n16/16 [==============================] - 0s 1ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n16/16 [==============================] - 0s 3ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n\nTesting for epoch 25 index 2:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.6342\n16/16 [==============================] - 0s 3ms/step - loss: 4.6345\n16/16 [==============================] - 0s 2ms/step - loss: 5.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 4ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 3ms/step - loss: 5.0054\n\nTesting for epoch 25 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 3ms/step - loss: 4.5546\n16/16 [==============================] - 0s 2ms/step - loss: 4.5548\n16/16 [==============================] - 0s 2ms/step - loss: 4.9358\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 2ms/step - loss: 4.9369\n16/16 [==============================] - 0s 4ms/step - loss: 4.9369\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 2ms/step - loss: 4.9369\n\nTesting for epoch 25 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 4ms/step - loss: 4.5968\n16/16 [==============================] - 0s 2ms/step - loss: 4.5971\n16/16 [==============================] - 0s 2ms/step - loss: 4.9745\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 3ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 3ms/step - loss: 4.9755\n\nTesting for epoch 25 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.6556\n16/16 [==============================] - 0s 2ms/step - loss: 4.6558\n16/16 [==============================] - 0s 2ms/step - loss: 5.0294\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 3ms/step - loss: 5.0305\n16/16 [==============================] - 0s 4ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n\nTesting for epoch 25 index 6:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6253\n16/16 [==============================] - 0s 1ms/step - loss: 4.6255\n16/16 [==============================] - 0s 3ms/step - loss: 5.0007\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 4ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 4ms/step - loss: 5.0018\n\nTesting for epoch 25 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6650\n16/16 [==============================] - 0s 2ms/step - loss: 4.6652\n16/16 [==============================] - 0s 3ms/step - loss: 5.0360\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 3ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n\nTesting for epoch 25 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.6731\n16/16 [==============================] - 0s 2ms/step - loss: 4.6734\n16/16 [==============================] - 0s 2ms/step - loss: 5.0440\n16/16 [==============================] - 0s 4ms/step - loss: 5.0451\n16/16 [==============================] - 0s 2ms/step - loss: 5.0451\n16/16 [==============================] - 0s 2ms/step - loss: 5.0451\n16/16 [==============================] - 0s 1ms/step - loss: 5.0451\n16/16 [==============================] - 0s 1ms/step - loss: 5.0451\n16/16 [==============================] - 0s 3ms/step - loss: 5.0451\n\nTesting for epoch 25 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.6489\n16/16 [==============================] - 0s 2ms/step - loss: 4.6492\n16/16 [==============================] - 0s 3ms/step - loss: 5.0231\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 3ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n\nTesting for epoch 25 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.6536\n16/16 [==============================] - 0s 2ms/step - loss: 4.6538\n16/16 [==============================] - 0s 1ms/step - loss: 5.0274\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 4ms/step - loss: 5.0285\n16/16 [==============================] - 0s 3ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n\nTesting for epoch 25 index 11:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.6177\n16/16 [==============================] - 0s 3ms/step - loss: 4.6180\n16/16 [==============================] - 0s 2ms/step - loss: 4.9958\n16/16 [==============================] - 0s 1ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 2ms/step - loss: 4.9969\n16/16 [==============================] - 0s 2ms/step - loss: 4.9969\n\nTesting for epoch 25 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.5564\n16/16 [==============================] - 0s 2ms/step - loss: 4.5567\n16/16 [==============================] - 0s 2ms/step - loss: 4.9399\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 3ms/step - loss: 4.9410\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 5ms/step - loss: 4.9410\n16/16 [==============================] - 0s 1ms/step - loss: 4.9410\n\nTesting for epoch 25 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 4ms/step - loss: 4.5990\n16/16 [==============================] - 0s 1ms/step - loss: 4.5992\n16/16 [==============================] - 0s 2ms/step - loss: 4.9798\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n\nTesting for epoch 25 index 14:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.5691\n16/16 [==============================] - 0s 3ms/step - loss: 4.5694\n16/16 [==============================] - 0s 1ms/step - loss: 4.9532\n16/16 [==============================] - 0s 3ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 1ms/step - loss: 4.9543\n\nTesting for epoch 25 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.5771\n16/16 [==============================] - 0s 2ms/step - loss: 4.5773\n16/16 [==============================] - 0s 3ms/step - loss: 4.9612\n16/16 [==============================] - 0s 6ms/step - loss: 4.9623\n16/16 [==============================] - 0s 1ms/step - loss: 4.9623\n16/16 [==============================] - 0s 4ms/step - loss: 4.9623\n16/16 [==============================] - 0s 2ms/step - loss: 4.9623\n16/16 [==============================] - 0s 4ms/step - loss: 4.9623\n16/16 [==============================] - 0s 2ms/step - loss: 4.9623\n\nTesting for epoch 25 index 16:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.6363\n16/16 [==============================] - 0s 3ms/step - loss: 4.6366\n16/16 [==============================] - 0s 2ms/step - loss: 5.0167\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n16/16 [==============================] - 0s 4ms/step - loss: 5.0178\n16/16 [==============================] - 0s 4ms/step - loss: 5.0178\n16/16 [==============================] - 0s 3ms/step - loss: 5.0178\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n\nTesting for epoch 25 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.5898\n16/16 [==============================] - 0s 4ms/step - loss: 4.5900\n16/16 [==============================] - 0s 2ms/step - loss: 4.9764\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 5ms/step - loss: 4.9775\n\nTesting for epoch 25 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.6715\n16/16 [==============================] - 0s 1ms/step - loss: 4.6718\n16/16 [==============================] - 0s 4ms/step - loss: 5.0505\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 1ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n\nTesting for epoch 25 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.5936\n16/16 [==============================] - 0s 3ms/step - loss: 4.5939\n16/16 [==============================] - 0s 3ms/step - loss: 4.9759\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 3ms/step - loss: 4.9770\n16/16 [==============================] - 0s 3ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n\nTesting for epoch 25 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.6637\n16/16 [==============================] - 0s 2ms/step - loss: 4.6639\n16/16 [==============================] - 0s 1ms/step - loss: 5.0420\n16/16 [==============================] - 0s 1ms/step - loss: 5.0431\n16/16 [==============================] - 0s 3ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 3ms/step - loss: 5.0431\n\nTesting for epoch 25 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.6343\n16/16 [==============================] - 0s 2ms/step - loss: 4.6346\n16/16 [==============================] - 0s 2ms/step - loss: 5.0134\n16/16 [==============================] - 0s 2ms/step - loss: 5.0145\n16/16 [==============================] - 0s 3ms/step - loss: 5.0145\n16/16 [==============================] - 0s 5ms/step - loss: 5.0145\n16/16 [==============================] - 0s 4ms/step - loss: 5.0145\n16/16 [==============================] - 0s 2ms/step - loss: 5.0145\n16/16 [==============================] - 0s 3ms/step - loss: 5.0145\n\nTesting for epoch 25 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 5ms/step - loss: 4.6510\n16/16 [==============================] - 0s 1ms/step - loss: 4.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.0289\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 3ms/step - loss: 5.0300\n\nTesting for epoch 25 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6468\n16/16 [==============================] - 0s 2ms/step - loss: 4.6470\n16/16 [==============================] - 0s 2ms/step - loss: 5.0261\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 4ms/step - loss: 5.0272\n16/16 [==============================] - 0s 3ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n\nTesting for epoch 25 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.6585\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 3ms/step - loss: 5.0362\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6691\n16/16 [==============================] - 0s 4ms/step - loss: 4.6694\n16/16 [==============================] - 0s 1ms/step - loss: 5.0468\n16/16 [==============================] - 0s 3ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 4ms/step - loss: 5.0479\n\nTesting for epoch 26 index 2:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7218\n16/16 [==============================] - 0s 2ms/step - loss: 4.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.0958\n16/16 [==============================] - 0s 4ms/step - loss: 5.0969\n16/16 [==============================] - 0s 1ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 3ms/step - loss: 5.0969\n\nTesting for epoch 26 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7019\n16/16 [==============================] - 0s 2ms/step - loss: 4.7021\n16/16 [==============================] - 0s 2ms/step - loss: 5.0772\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n\nTesting for epoch 26 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.7218\n16/16 [==============================] - 0s 3ms/step - loss: 4.7220\n16/16 [==============================] - 0s 1ms/step - loss: 5.0965\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 4ms/step - loss: 5.0976\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 4ms/step - loss: 5.0976\n16/16 [==============================] - 0s 3ms/step - loss: 5.0976\n\nTesting for epoch 26 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 4.6918\n16/16 [==============================] - 0s 4ms/step - loss: 4.6921\n16/16 [==============================] - 0s 3ms/step - loss: 5.0687\n16/16 [==============================] - 0s 1ms/step - loss: 5.0698\n16/16 [==============================] - 0s 3ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 3ms/step - loss: 5.0698\n\nTesting for epoch 26 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.6579\n16/16 [==============================] - 0s 3ms/step - loss: 4.6582\n16/16 [==============================] - 0s 2ms/step - loss: 5.0385\n16/16 [==============================] - 0s 4ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 2ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 2ms/step - loss: 5.0396\n\nTesting for epoch 26 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.7216\n16/16 [==============================] - 0s 2ms/step - loss: 4.7219\n16/16 [==============================] - 0s 4ms/step - loss: 5.0961\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 4ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 4ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n\nTesting for epoch 26 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.7682\n16/16 [==============================] - 0s 2ms/step - loss: 4.7685\n16/16 [==============================] - 0s 2ms/step - loss: 5.1377\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 3ms/step - loss: 5.1387\n\nTesting for epoch 26 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.7503\n16/16 [==============================] - 0s 2ms/step - loss: 4.7506\n16/16 [==============================] - 0s 2ms/step - loss: 5.1235\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 3ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 3ms/step - loss: 5.1245\n\nTesting for epoch 26 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.7142\n16/16 [==============================] - 0s 4ms/step - loss: 4.7145\n16/16 [==============================] - 0s 2ms/step - loss: 5.0894\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 3ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n\nTesting for epoch 26 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.6726\n16/16 [==============================] - 0s 3ms/step - loss: 4.6729\n16/16 [==============================] - 0s 3ms/step - loss: 5.0553\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n\nTesting for epoch 26 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6940\n16/16 [==============================] - 0s 2ms/step - loss: 4.6943\n16/16 [==============================] - 0s 5ms/step - loss: 5.0759\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 1ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 1ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n\nTesting for epoch 26 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.6016\n16/16 [==============================] - 0s 4ms/step - loss: 4.6019\n16/16 [==============================] - 0s 2ms/step - loss: 4.9925\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n\nTesting for epoch 26 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7053\n16/16 [==============================] - 0s 1ms/step - loss: 5.0868\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 1ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n\nTesting for epoch 26 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.5845\n16/16 [==============================] - 0s 2ms/step - loss: 4.5848\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n16/16 [==============================] - 0s 3ms/step - loss: 4.9766\n16/16 [==============================] - 0s 2ms/step - loss: 4.9766\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n16/16 [==============================] - 0s 2ms/step - loss: 4.9766\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n\nTesting for epoch 26 index 16:\n391/391 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 4.6562\n16/16 [==============================] - 0s 2ms/step - loss: 4.6565\n16/16 [==============================] - 0s 2ms/step - loss: 5.0419\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 2ms/step - loss: 5.0430\n16/16 [==============================] - 0s 2ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n\nTesting for epoch 26 index 17:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.6432\n16/16 [==============================] - 0s 1ms/step - loss: 4.6435\n16/16 [==============================] - 0s 4ms/step - loss: 5.0313\n16/16 [==============================] - 0s 1ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n\nTesting for epoch 26 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.6592\n16/16 [==============================] - 0s 3ms/step - loss: 4.6595\n16/16 [==============================] - 0s 2ms/step - loss: 5.0458\n16/16 [==============================] - 0s 3ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n16/16 [==============================] - 0s 1ms/step - loss: 5.0469\n16/16 [==============================] - 0s 1ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n\nTesting for epoch 26 index 19:\n391/391 [==============================] - 0s 958us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.6840\n16/16 [==============================] - 0s 3ms/step - loss: 4.6842\n16/16 [==============================] - 0s 1ms/step - loss: 5.0688\n16/16 [==============================] - 0s 1ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 3ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n\nTesting for epoch 26 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.6582\n16/16 [==============================] - 0s 2ms/step - loss: 4.6584\n16/16 [==============================] - 0s 2ms/step - loss: 5.0441\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 3ms/step - loss: 5.0452\n16/16 [==============================] - 0s 1ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n\nTesting for epoch 26 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7166\n16/16 [==============================] - 0s 2ms/step - loss: 4.7169\n16/16 [==============================] - 0s 2ms/step - loss: 5.0947\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n\nTesting for epoch 26 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.7097\n16/16 [==============================] - 0s 1ms/step - loss: 4.7099\n16/16 [==============================] - 0s 2ms/step - loss: 5.0892\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 3ms/step - loss: 5.0903\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 1ms/step - loss: 5.0903\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 3ms/step - loss: 5.0903\n\nTesting for epoch 26 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.7441\n16/16 [==============================] - 0s 3ms/step - loss: 4.7444\n16/16 [==============================] - 0s 1ms/step - loss: 5.1225\n16/16 [==============================] - 0s 2ms/step - loss: 5.1236\n16/16 [==============================] - 0s 1ms/step - loss: 5.1236\n16/16 [==============================] - 0s 1ms/step - loss: 5.1236\n16/16 [==============================] - 0s 3ms/step - loss: 5.1236\n16/16 [==============================] - 0s 2ms/step - loss: 5.1236\n16/16 [==============================] - 0s 4ms/step - loss: 5.1236\n\nTesting for epoch 26 index 24:\n391/391 [==============================] - 0s 961us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.6765\n16/16 [==============================] - 0s 2ms/step - loss: 4.6768\n16/16 [==============================] - 0s 2ms/step - loss: 5.0600\n16/16 [==============================] - 0s 2ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 2ms/step - loss: 5.0611\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.7939\n16/16 [==============================] - 0s 1ms/step - loss: 4.7942\n16/16 [==============================] - 0s 2ms/step - loss: 5.1696\n16/16 [==============================] - 0s 1ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 1ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n\nTesting for epoch 27 index 2:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.7837\n16/16 [==============================] - 0s 1ms/step - loss: 4.7840\n16/16 [==============================] - 0s 1ms/step - loss: 5.1585\n16/16 [==============================] - 0s 1ms/step - loss: 5.1595\n16/16 [==============================] - 0s 2ms/step - loss: 5.1595\n16/16 [==============================] - 0s 3ms/step - loss: 5.1595\n16/16 [==============================] - 0s 2ms/step - loss: 5.1595\n16/16 [==============================] - 0s 3ms/step - loss: 5.1595\n16/16 [==============================] - 0s 1ms/step - loss: 5.1595\n\nTesting for epoch 27 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.7597\n16/16 [==============================] - 0s 2ms/step - loss: 4.7600\n16/16 [==============================] - 0s 2ms/step - loss: 5.1369\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n\nTesting for epoch 27 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.7954\n16/16 [==============================] - 0s 1ms/step - loss: 4.7957\n16/16 [==============================] - 0s 1ms/step - loss: 5.1705\n16/16 [==============================] - 0s 3ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n16/16 [==============================] - 0s 2ms/step - loss: 5.1716\n16/16 [==============================] - 0s 3ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n\nTesting for epoch 27 index 5:\n391/391 [==============================] - 0s 919us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 4.7403\n16/16 [==============================] - 0s 1ms/step - loss: 4.7406\n16/16 [==============================] - 0s 2ms/step - loss: 5.1187\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 3ms/step - loss: 5.1198\n16/16 [==============================] - 0s 3ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n\nTesting for epoch 27 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.7506\n16/16 [==============================] - 0s 3ms/step - loss: 4.7508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1292\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 1ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n\nTesting for epoch 27 index 7:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.8474\n16/16 [==============================] - 0s 1ms/step - loss: 4.8477\n16/16 [==============================] - 0s 2ms/step - loss: 5.2182\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 2ms/step - loss: 5.2193\n16/16 [==============================] - 0s 2ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n\nTesting for epoch 27 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7643\n16/16 [==============================] - 0s 2ms/step - loss: 4.7645\n16/16 [==============================] - 0s 3ms/step - loss: 5.1389\n16/16 [==============================] - 0s 3ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 3ms/step - loss: 5.1400\n16/16 [==============================] - 0s 1ms/step - loss: 5.1400\n\nTesting for epoch 27 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.8146\n16/16 [==============================] - 0s 2ms/step - loss: 4.8149\n16/16 [==============================] - 0s 2ms/step - loss: 5.1850\n16/16 [==============================] - 0s 4ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 3ms/step - loss: 5.1861\n\nTesting for epoch 27 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8055\n16/16 [==============================] - 0s 2ms/step - loss: 4.8058\n16/16 [==============================] - 0s 3ms/step - loss: 5.1807\n16/16 [==============================] - 0s 1ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n\nTesting for epoch 27 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 3ms/step - loss: 4.7670\n16/16 [==============================] - 0s 1ms/step - loss: 4.7673\n16/16 [==============================] - 0s 2ms/step - loss: 5.1448\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 1ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n\nTesting for epoch 27 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.7561\n16/16 [==============================] - 0s 1ms/step - loss: 4.7563\n16/16 [==============================] - 0s 2ms/step - loss: 5.1377\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 2ms/step - loss: 5.1388\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 2ms/step - loss: 5.1388\n16/16 [==============================] - 0s 3ms/step - loss: 5.1388\n\nTesting for epoch 27 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7256\n16/16 [==============================] - 0s 3ms/step - loss: 4.7259\n16/16 [==============================] - 0s 2ms/step - loss: 5.1121\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 2ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n\nTesting for epoch 27 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.7529\n16/16 [==============================] - 0s 2ms/step - loss: 4.7532\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 2ms/step - loss: 5.1398\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 3ms/step - loss: 5.1398\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 2ms/step - loss: 5.1398\n\nTesting for epoch 27 index 15:\n391/391 [==============================] - 0s 884us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.8032\n16/16 [==============================] - 0s 2ms/step - loss: 4.8035\n16/16 [==============================] - 0s 1ms/step - loss: 5.1820\n16/16 [==============================] - 0s 1ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 3ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 3ms/step - loss: 5.1831\n\nTesting for epoch 27 index 16:\n391/391 [==============================] - 0s 991us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7280\n16/16 [==============================] - 0s 1ms/step - loss: 4.7282\n16/16 [==============================] - 0s 3ms/step - loss: 5.1128\n16/16 [==============================] - 0s 1ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 1ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n\nTesting for epoch 27 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.7865\n16/16 [==============================] - 0s 3ms/step - loss: 4.7867\n16/16 [==============================] - 0s 3ms/step - loss: 5.1673\n16/16 [==============================] - 0s 3ms/step - loss: 5.1684\n16/16 [==============================] - 0s 1ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n\nTesting for epoch 27 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.7361\n16/16 [==============================] - 0s 1ms/step - loss: 4.7364\n16/16 [==============================] - 0s 5ms/step - loss: 5.1233\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 1ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 3ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n\nTesting for epoch 27 index 19:\n391/391 [==============================] - 0s 898us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.7381\n16/16 [==============================] - 0s 2ms/step - loss: 4.7384\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n16/16 [==============================] - 0s 1ms/step - loss: 5.1256\n16/16 [==============================] - 0s 3ms/step - loss: 5.1256\n16/16 [==============================] - 0s 1ms/step - loss: 5.1256\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n\nTesting for epoch 27 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.7522\n16/16 [==============================] - 0s 2ms/step - loss: 4.7525\n16/16 [==============================] - 0s 2ms/step - loss: 5.1390\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 3ms/step - loss: 5.1401\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 4ms/step - loss: 5.1401\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 4ms/step - loss: 5.1401\n\nTesting for epoch 27 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.7685\n16/16 [==============================] - 0s 2ms/step - loss: 4.7688\n16/16 [==============================] - 0s 3ms/step - loss: 5.1497\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 1ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n\nTesting for epoch 27 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 4.7937\n16/16 [==============================] - 0s 3ms/step - loss: 4.7940\n16/16 [==============================] - 0s 1ms/step - loss: 5.1733\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 4ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n\nTesting for epoch 27 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.8606\n16/16 [==============================] - 0s 2ms/step - loss: 4.8609\n16/16 [==============================] - 0s 2ms/step - loss: 5.2362\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 3ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n\nTesting for epoch 27 index 24:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 4ms/step - loss: 4.8014\n16/16 [==============================] - 0s 1ms/step - loss: 4.8016\n16/16 [==============================] - 0s 5ms/step - loss: 5.1823\n16/16 [==============================] - 0s 4ms/step - loss: 5.1834\n16/16 [==============================] - 0s 4ms/step - loss: 5.1834\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8199\n16/16 [==============================] - 0s 2ms/step - loss: 5.1984\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 2ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n\nTesting for epoch 28 index 2:\n391/391 [==============================] - 0s 888us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.8614\n16/16 [==============================] - 0s 2ms/step - loss: 4.8616\n16/16 [==============================] - 0s 2ms/step - loss: 5.2371\n16/16 [==============================] - 0s 2ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 3ms/step - loss: 5.2382\n16/16 [==============================] - 0s 2ms/step - loss: 5.2382\n\nTesting for epoch 28 index 3:\n391/391 [==============================] - 0s 943us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.8859\n16/16 [==============================] - 0s 1ms/step - loss: 4.8862\n16/16 [==============================] - 0s 3ms/step - loss: 5.2595\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n16/16 [==============================] - 0s 2ms/step - loss: 5.2606\n16/16 [==============================] - 0s 4ms/step - loss: 5.2606\n16/16 [==============================] - 0s 2ms/step - loss: 5.2606\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n\nTesting for epoch 28 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8116\n16/16 [==============================] - 0s 3ms/step - loss: 5.1907\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 1ms/step - loss: 5.1918\n\nTesting for epoch 28 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8099\n16/16 [==============================] - 0s 1ms/step - loss: 4.8102\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 1ms/step - loss: 5.1929\n16/16 [==============================] - 0s 4ms/step - loss: 5.1929\n16/16 [==============================] - 0s 3ms/step - loss: 5.1929\n\nTesting for epoch 28 index 6:\n391/391 [==============================] - 0s 792us/step\n16/16 [==============================] - 0s 858us/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8763\n16/16 [==============================] - 0s 1ms/step - loss: 4.8765\n16/16 [==============================] - 0s 1ms/step - loss: 5.2511\n16/16 [==============================] - 0s 868us/step - loss: 5.2522\n16/16 [==============================] - 0s 995us/step - loss: 5.2522\n16/16 [==============================] - 0s 1ms/step - loss: 5.2522\n16/16 [==============================] - 0s 1ms/step - loss: 5.2522\n16/16 [==============================] - 0s 923us/step - loss: 5.2522\n16/16 [==============================] - 0s 3ms/step - loss: 5.2522\n\nTesting for epoch 28 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8858\n16/16 [==============================] - 0s 2ms/step - loss: 4.8860\n16/16 [==============================] - 0s 2ms/step - loss: 5.2610\n16/16 [==============================] - 0s 3ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n16/16 [==============================] - 0s 3ms/step - loss: 5.2620\n16/16 [==============================] - 0s 4ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n\nTesting for epoch 28 index 8:\n391/391 [==============================] - 0s 989us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.9409\n16/16 [==============================] - 0s 3ms/step - loss: 4.9412\n16/16 [==============================] - 0s 2ms/step - loss: 5.3099\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n16/16 [==============================] - 0s 4ms/step - loss: 5.3110\n16/16 [==============================] - 0s 2ms/step - loss: 5.3110\n16/16 [==============================] - 0s 2ms/step - loss: 5.3110\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n\nTesting for epoch 28 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.9478\n16/16 [==============================] - 0s 2ms/step - loss: 4.9481\n16/16 [==============================] - 0s 3ms/step - loss: 5.3130\n16/16 [==============================] - 0s 4ms/step - loss: 5.3141\n16/16 [==============================] - 0s 1ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n16/16 [==============================] - 0s 3ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n\nTesting for epoch 28 index 10:\n391/391 [==============================] - 0s 923us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8533\n16/16 [==============================] - 0s 2ms/step - loss: 4.8535\n16/16 [==============================] - 0s 2ms/step - loss: 5.2304\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n16/16 [==============================] - 0s 3ms/step - loss: 5.2314\n16/16 [==============================] - 0s 2ms/step - loss: 5.2314\n16/16 [==============================] - 0s 2ms/step - loss: 5.2314\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n\nTesting for epoch 28 index 11:\n391/391 [==============================] - 0s 941us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8440\n16/16 [==============================] - 0s 2ms/step - loss: 4.8443\n16/16 [==============================] - 0s 1ms/step - loss: 5.2260\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 3ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 1ms/step - loss: 5.2271\n\nTesting for epoch 28 index 12:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.8436\n16/16 [==============================] - 0s 1ms/step - loss: 4.8439\n16/16 [==============================] - 0s 1ms/step - loss: 5.2253\n16/16 [==============================] - 0s 1ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n16/16 [==============================] - 0s 1ms/step - loss: 5.2264\n16/16 [==============================] - 0s 3ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n\nTesting for epoch 28 index 13:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8591\n16/16 [==============================] - 0s 3ms/step - loss: 4.8593\n16/16 [==============================] - 0s 3ms/step - loss: 5.2395\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 1ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n\nTesting for epoch 28 index 14:\n391/391 [==============================] - 0s 925us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.8373\n16/16 [==============================] - 0s 1ms/step - loss: 4.8376\n16/16 [==============================] - 0s 2ms/step - loss: 5.2207\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n\nTesting for epoch 28 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.7881\n16/16 [==============================] - 0s 3ms/step - loss: 4.7884\n16/16 [==============================] - 0s 2ms/step - loss: 5.1765\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 3ms/step - loss: 5.1777\n16/16 [==============================] - 0s 1ms/step - loss: 5.1777\n\nTesting for epoch 28 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7353\n16/16 [==============================] - 0s 2ms/step - loss: 4.7356\n16/16 [==============================] - 0s 2ms/step - loss: 5.1269\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 1ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 4ms/step - loss: 5.1280\n\nTesting for epoch 28 index 17:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8065\n16/16 [==============================] - 0s 1ms/step - loss: 4.8068\n16/16 [==============================] - 0s 2ms/step - loss: 5.1913\n16/16 [==============================] - 0s 1ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 4ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n\nTesting for epoch 28 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 4.7947\n16/16 [==============================] - 0s 2ms/step - loss: 4.7950\n16/16 [==============================] - 0s 2ms/step - loss: 5.1822\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n\nTesting for epoch 28 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8317\n16/16 [==============================] - 0s 2ms/step - loss: 4.8319\n16/16 [==============================] - 0s 2ms/step - loss: 5.2162\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 1ms/step - loss: 5.2173\n16/16 [==============================] - 0s 1ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n\nTesting for epoch 28 index 20:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.8778\n16/16 [==============================] - 0s 2ms/step - loss: 4.8781\n16/16 [==============================] - 0s 3ms/step - loss: 5.2583\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 4ms/step - loss: 5.2594\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 1ms/step - loss: 5.2594\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 4ms/step - loss: 5.2594\n\nTesting for epoch 28 index 21:\n391/391 [==============================] - 0s 947us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8472\n16/16 [==============================] - 0s 1ms/step - loss: 4.8475\n16/16 [==============================] - 0s 1ms/step - loss: 5.2298\n16/16 [==============================] - 0s 3ms/step - loss: 5.2309\n16/16 [==============================] - 0s 2ms/step - loss: 5.2309\n16/16 [==============================] - 0s 1ms/step - loss: 5.2309\n16/16 [==============================] - 0s 2ms/step - loss: 5.2309\n16/16 [==============================] - 0s 3ms/step - loss: 5.2309\n16/16 [==============================] - 0s 1ms/step - loss: 5.2309\n\nTesting for epoch 28 index 22:\n391/391 [==============================] - 0s 864us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 4.8267\n16/16 [==============================] - 0s 2ms/step - loss: 4.8270\n16/16 [==============================] - 0s 2ms/step - loss: 5.2118\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 5ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n\nTesting for epoch 28 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8366\n16/16 [==============================] - 0s 1ms/step - loss: 4.8369\n16/16 [==============================] - 0s 1ms/step - loss: 5.2208\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 1ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 1ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n\nTesting for epoch 28 index 24:\n391/391 [==============================] - 0s 872us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8866\n16/16 [==============================] - 0s 2ms/step - loss: 4.8869\n16/16 [==============================] - 0s 2ms/step - loss: 5.2674\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 1ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n391/391 [==============================] - 0s 999us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.9052\n16/16 [==============================] - 0s 1ms/step - loss: 4.9055\n16/16 [==============================] - 0s 2ms/step - loss: 5.2822\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 4ms/step - loss: 5.2833\n16/16 [==============================] - 0s 3ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n\nTesting for epoch 29 index 2:\n391/391 [==============================] - 0s 992us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0033\n16/16 [==============================] - 0s 1ms/step - loss: 4.8451\n16/16 [==============================] - 0s 3ms/step - loss: 4.8454\n16/16 [==============================] - 0s 3ms/step - loss: 5.2292\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n\nTesting for epoch 29 index 3:\n391/391 [==============================] - 0s 948us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 3ms/step - loss: 4.9049\n16/16 [==============================] - 0s 2ms/step - loss: 4.9052\n16/16 [==============================] - 0s 2ms/step - loss: 5.2825\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 2ms/step - loss: 5.2836\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 2ms/step - loss: 5.2836\n16/16 [==============================] - 0s 3ms/step - loss: 5.2836\n\nTesting for epoch 29 index 4:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.9077\n16/16 [==============================] - 0s 2ms/step - loss: 4.9080\n16/16 [==============================] - 0s 2ms/step - loss: 5.2864\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 3ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n\nTesting for epoch 29 index 5:\n391/391 [==============================] - 0s 978us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.9268\n16/16 [==============================] - 0s 2ms/step - loss: 4.9271\n16/16 [==============================] - 0s 1ms/step - loss: 5.3043\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 1ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n\nTesting for epoch 29 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 4.9045\n16/16 [==============================] - 0s 1ms/step - loss: 4.9048\n16/16 [==============================] - 0s 1ms/step - loss: 5.2824\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n\nTesting for epoch 29 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.9455\n16/16 [==============================] - 0s 2ms/step - loss: 4.9457\n16/16 [==============================] - 0s 2ms/step - loss: 5.3194\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 1ms/step - loss: 5.3205\n16/16 [==============================] - 0s 1ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n\nTesting for epoch 29 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 4.9236\n16/16 [==============================] - 0s 2ms/step - loss: 4.9239\n16/16 [==============================] - 0s 1ms/step - loss: 5.2999\n16/16 [==============================] - 0s 2ms/step - loss: 5.3009\n16/16 [==============================] - 0s 1ms/step - loss: 5.3009\n16/16 [==============================] - 0s 3ms/step - loss: 5.3009\n16/16 [==============================] - 0s 4ms/step - loss: 5.3009\n16/16 [==============================] - 0s 1ms/step - loss: 5.3009\n16/16 [==============================] - 0s 4ms/step - loss: 5.3009\n\nTesting for epoch 29 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 5.0180\n16/16 [==============================] - 0s 2ms/step - loss: 5.0183\n16/16 [==============================] - 0s 1ms/step - loss: 5.3855\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 2ms/step - loss: 5.3866\n\nTesting for epoch 29 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 4.9382\n16/16 [==============================] - 0s 2ms/step - loss: 4.9385\n16/16 [==============================] - 0s 2ms/step - loss: 5.3124\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 3ms/step - loss: 5.3135\n16/16 [==============================] - 0s 4ms/step - loss: 5.3135\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 3ms/step - loss: 5.3135\n\nTesting for epoch 29 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.8424\n16/16 [==============================] - 0s 1ms/step - loss: 4.8427\n16/16 [==============================] - 0s 1ms/step - loss: 5.2288\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 3ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 3ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n\nTesting for epoch 29 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8817\n16/16 [==============================] - 0s 2ms/step - loss: 4.8820\n16/16 [==============================] - 0s 2ms/step - loss: 5.2647\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 3ms/step - loss: 5.2658\n16/16 [==============================] - 0s 4ms/step - loss: 5.2658\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 2ms/step - loss: 5.2658\n\nTesting for epoch 29 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.9375\n16/16 [==============================] - 0s 2ms/step - loss: 4.9377\n16/16 [==============================] - 0s 2ms/step - loss: 5.3164\n16/16 [==============================] - 0s 3ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 3ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 1ms/step - loss: 5.3175\n\nTesting for epoch 29 index 14:\n391/391 [==============================] - 0s 973us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.8467\n16/16 [==============================] - 0s 1ms/step - loss: 4.8470\n16/16 [==============================] - 0s 1ms/step - loss: 5.2326\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 1ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n\nTesting for epoch 29 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.8782\n16/16 [==============================] - 0s 2ms/step - loss: 4.8785\n16/16 [==============================] - 0s 2ms/step - loss: 5.2636\n16/16 [==============================] - 0s 2ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 1ms/step - loss: 5.2647\n16/16 [==============================] - 0s 4ms/step - loss: 5.2647\n\nTesting for epoch 29 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7841\n16/16 [==============================] - 0s 3ms/step - loss: 4.7844\n16/16 [==============================] - 0s 2ms/step - loss: 5.1782\n16/16 [==============================] - 0s 3ms/step - loss: 5.1794\n16/16 [==============================] - 0s 3ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n\nTesting for epoch 29 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.8728\n16/16 [==============================] - 0s 2ms/step - loss: 4.8731\n16/16 [==============================] - 0s 2ms/step - loss: 5.2604\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 5ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n\nTesting for epoch 29 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.9268\n16/16 [==============================] - 0s 2ms/step - loss: 4.9271\n16/16 [==============================] - 0s 2ms/step - loss: 5.3090\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 1ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 1ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n\nTesting for epoch 29 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8500\n16/16 [==============================] - 0s 2ms/step - loss: 4.8503\n16/16 [==============================] - 0s 1ms/step - loss: 5.2378\n16/16 [==============================] - 0s 1ms/step - loss: 5.2389\n16/16 [==============================] - 0s 2ms/step - loss: 5.2389\n16/16 [==============================] - 0s 4ms/step - loss: 5.2389\n16/16 [==============================] - 0s 1ms/step - loss: 5.2389\n16/16 [==============================] - 0s 4ms/step - loss: 5.2389\n16/16 [==============================] - 0s 3ms/step - loss: 5.2389\n\nTesting for epoch 29 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8735\n16/16 [==============================] - 0s 1ms/step - loss: 4.8738\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 1ms/step - loss: 5.2643\n16/16 [==============================] - 0s 1ms/step - loss: 5.2643\n\nTesting for epoch 29 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.9486\n16/16 [==============================] - 0s 3ms/step - loss: 4.9489\n16/16 [==============================] - 0s 2ms/step - loss: 5.3304\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 1ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 1ms/step - loss: 5.3315\n\nTesting for epoch 29 index 22:\n391/391 [==============================] - 0s 926us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0035\n16/16 [==============================] - 0s 1ms/step - loss: 4.9416\n16/16 [==============================] - 0s 2ms/step - loss: 4.9419\n16/16 [==============================] - 0s 2ms/step - loss: 5.3233\n16/16 [==============================] - 0s 1ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 3ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 1ms/step - loss: 5.3244\n\nTesting for epoch 29 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 4.8742\n16/16 [==============================] - 0s 1ms/step - loss: 4.8745\n16/16 [==============================] - 0s 2ms/step - loss: 5.2621\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 1ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2632\n\nTesting for epoch 29 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.9565\n16/16 [==============================] - 0s 1ms/step - loss: 4.9568\n16/16 [==============================] - 0s 2ms/step - loss: 5.3350\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 2ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 1ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.8851\n16/16 [==============================] - 0s 2ms/step - loss: 4.8853\n16/16 [==============================] - 0s 2ms/step - loss: 5.2712\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 3ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 3ms/step - loss: 5.2723\n\nTesting for epoch 30 index 2:\n391/391 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 4.9527\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 5.3307\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 4ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 3ms/step - loss: 5.3318\n\nTesting for epoch 30 index 3:\n391/391 [==============================] - 0s 952us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.9269\n16/16 [==============================] - 0s 1ms/step - loss: 4.9272\n16/16 [==============================] - 0s 2ms/step - loss: 5.3092\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 4ms/step - loss: 5.3103\n16/16 [==============================] - 0s 1ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n\nTesting for epoch 30 index 4:\n391/391 [==============================] - 0s 916us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.0097\n16/16 [==============================] - 0s 1ms/step - loss: 5.0100\n16/16 [==============================] - 0s 3ms/step - loss: 5.3843\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n16/16 [==============================] - 0s 3ms/step - loss: 5.3854\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n16/16 [==============================] - 0s 1ms/step - loss: 5.3854\n16/16 [==============================] - 0s 1ms/step - loss: 5.3854\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n\nTesting for epoch 30 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 4.9155\n16/16 [==============================] - 0s 1ms/step - loss: 4.9158\n16/16 [==============================] - 0s 1ms/step - loss: 5.3003\n16/16 [==============================] - 0s 3ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 3ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n\nTesting for epoch 30 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0034\n16/16 [==============================] - 0s 3ms/step - loss: 4.9720\n16/16 [==============================] - 0s 2ms/step - loss: 4.9723\n16/16 [==============================] - 0s 1ms/step - loss: 5.3508\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 3ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 3ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n\nTesting for epoch 30 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 5ms/step - loss: 4.9881\n16/16 [==============================] - 0s 1ms/step - loss: 4.9884\n16/16 [==============================] - 0s 895us/step - loss: 5.3639\n16/16 [==============================] - 0s 931us/step - loss: 5.3650\n16/16 [==============================] - 0s 929us/step - loss: 5.3650\n16/16 [==============================] - 0s 928us/step - loss: 5.3650\n16/16 [==============================] - 0s 975us/step - loss: 5.3650\n16/16 [==============================] - 0s 988us/step - loss: 5.3650\n16/16 [==============================] - 0s 924us/step - loss: 5.3650\n\nTesting for epoch 30 index 8:\n391/391 [==============================] - 0s 649us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0030\n16/16 [==============================] - 0s 900us/step - loss: 4.9993\n16/16 [==============================] - 0s 3ms/step - loss: 4.9996\n16/16 [==============================] - 0s 1ms/step - loss: 5.3733\n16/16 [==============================] - 0s 962us/step - loss: 5.3744\n16/16 [==============================] - 0s 942us/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n16/16 [==============================] - 0s 993us/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n\nTesting for epoch 30 index 9:\n391/391 [==============================] - 0s 634us/step\n16/16 [==============================] - 0s 868us/step - loss: 0.0034\n16/16 [==============================] - 0s 809us/step - loss: 5.0234\n16/16 [==============================] - 0s 843us/step - loss: 5.0237\n16/16 [==============================] - 0s 669us/step - loss: 5.3964\n16/16 [==============================] - 0s 816us/step - loss: 5.3975\n16/16 [==============================] - 0s 780us/step - loss: 5.3975\n16/16 [==============================] - 0s 994us/step - loss: 5.3975\n16/16 [==============================] - 0s 959us/step - loss: 5.3975\n16/16 [==============================] - 0s 1ms/step - loss: 5.3975\n16/16 [==============================] - 0s 1ms/step - loss: 5.3975\n\nTesting for epoch 30 index 10:\n391/391 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0030\n16/16 [==============================] - 0s 710us/step - loss: 4.9789\n16/16 [==============================] - 0s 2ms/step - loss: 4.9791\n16/16 [==============================] - 0s 823us/step - loss: 5.3572\n16/16 [==============================] - 0s 2ms/step - loss: 5.3583\n16/16 [==============================] - 0s 816us/step - loss: 5.3583\n16/16 [==============================] - 0s 819us/step - loss: 5.3583\n16/16 [==============================] - 0s 854us/step - loss: 5.3583\n16/16 [==============================] - 0s 881us/step - loss: 5.3583\n16/16 [==============================] - 0s 793us/step - loss: 5.3583\n\nTesting for epoch 30 index 11:\n391/391 [==============================] - 0s 733us/step\n16/16 [==============================] - 0s 934us/step - loss: 0.0032\n16/16 [==============================] - 0s 887us/step - loss: 4.8994\n16/16 [==============================] - 0s 937us/step - loss: 4.8997\n16/16 [==============================] - 0s 920us/step - loss: 5.2879\n16/16 [==============================] - 0s 893us/step - loss: 5.2890\n16/16 [==============================] - 0s 936us/step - loss: 5.2890\n16/16 [==============================] - 0s 909us/step - loss: 5.2890\n16/16 [==============================] - 0s 970us/step - loss: 5.2890\n16/16 [==============================] - 0s 917us/step - loss: 5.2890\n16/16 [==============================] - 0s 974us/step - loss: 5.2890\n\nTesting for epoch 30 index 12:\n391/391 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 876us/step - loss: 0.0038\n16/16 [==============================] - 0s 852us/step - loss: 4.9208\n16/16 [==============================] - 0s 1ms/step - loss: 4.9210\n16/16 [==============================] - 0s 996us/step - loss: 5.3081\n16/16 [==============================] - 0s 977us/step - loss: 5.3092\n16/16 [==============================] - 0s 982us/step - loss: 5.3092\n16/16 [==============================] - 0s 999us/step - loss: 5.3092\n16/16 [==============================] - 0s 893us/step - loss: 5.3092\n16/16 [==============================] - 0s 1ms/step - loss: 5.3092\n16/16 [==============================] - 0s 1ms/step - loss: 5.3092\n\nTesting for epoch 30 index 13:\n391/391 [==============================] - 0s 766us/step\n16/16 [==============================] - 0s 898us/step - loss: 0.0038\n16/16 [==============================] - 0s 862us/step - loss: 4.9108\n16/16 [==============================] - 0s 888us/step - loss: 4.9111\n16/16 [==============================] - 0s 878us/step - loss: 5.2985\n16/16 [==============================] - 0s 874us/step - loss: 5.2997\n16/16 [==============================] - 0s 858us/step - loss: 5.2997\n16/16 [==============================] - 0s 1ms/step - loss: 5.2997\n16/16 [==============================] - 0s 1ms/step - loss: 5.2997\n16/16 [==============================] - 0s 965us/step - loss: 5.2997\n16/16 [==============================] - 0s 910us/step - loss: 5.2997\n\nTesting for epoch 30 index 14:\n391/391 [==============================] - 0s 678us/step\n16/16 [==============================] - 0s 979us/step - loss: 0.0037\n16/16 [==============================] - 0s 955us/step - loss: 4.8813\n16/16 [==============================] - 0s 872us/step - loss: 4.8816\n16/16 [==============================] - 0s 923us/step - loss: 5.2721\n16/16 [==============================] - 0s 918us/step - loss: 5.2732\n16/16 [==============================] - 0s 925us/step - loss: 5.2732\n16/16 [==============================] - 0s 896us/step - loss: 5.2732\n16/16 [==============================] - 0s 901us/step - loss: 5.2732\n16/16 [==============================] - 0s 963us/step - loss: 5.2732\n16/16 [==============================] - 0s 885us/step - loss: 5.2732\n\nTesting for epoch 30 index 15:\n391/391 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 869us/step - loss: 0.0046\n16/16 [==============================] - 0s 842us/step - loss: 4.9268\n16/16 [==============================] - 0s 858us/step - loss: 4.9271\n16/16 [==============================] - 0s 861us/step - loss: 5.3143\n16/16 [==============================] - 0s 861us/step - loss: 5.3154\n16/16 [==============================] - 0s 845us/step - loss: 5.3154\n16/16 [==============================] - 0s 885us/step - loss: 5.3154\n16/16 [==============================] - 0s 902us/step - loss: 5.3154\n16/16 [==============================] - 0s 888us/step - loss: 5.3154\n16/16 [==============================] - 0s 901us/step - loss: 5.3154\n\nTesting for epoch 30 index 16:\n391/391 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 853us/step - loss: 0.0037\n16/16 [==============================] - 0s 846us/step - loss: 4.8905\n16/16 [==============================] - 0s 831us/step - loss: 4.8908\n16/16 [==============================] - 0s 827us/step - loss: 5.2830\n16/16 [==============================] - 0s 847us/step - loss: 5.2841\n16/16 [==============================] - 0s 825us/step - loss: 5.2841\n16/16 [==============================] - 0s 832us/step - loss: 5.2841\n16/16 [==============================] - 0s 830us/step - loss: 5.2841\n16/16 [==============================] - 0s 850us/step - loss: 5.2841\n16/16 [==============================] - 0s 851us/step - loss: 5.2841\n\nTesting for epoch 30 index 17:\n391/391 [==============================] - 0s 615us/step\n16/16 [==============================] - 0s 865us/step - loss: 0.0042\n16/16 [==============================] - 0s 871us/step - loss: 4.9525\n16/16 [==============================] - 0s 841us/step - loss: 4.9528\n16/16 [==============================] - 0s 853us/step - loss: 5.3379\n16/16 [==============================] - 0s 864us/step - loss: 5.3391\n16/16 [==============================] - 0s 857us/step - loss: 5.3391\n16/16 [==============================] - 0s 842us/step - loss: 5.3391\n16/16 [==============================] - 0s 879us/step - loss: 5.3391\n16/16 [==============================] - 0s 839us/step - loss: 5.3391\n16/16 [==============================] - 0s 821us/step - loss: 5.3391\n\nTesting for epoch 30 index 18:\n391/391 [==============================] - 0s 609us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0038\n16/16 [==============================] - 0s 849us/step - loss: 4.9449\n16/16 [==============================] - 0s 1ms/step - loss: 4.9452\n16/16 [==============================] - 0s 844us/step - loss: 5.3284\n16/16 [==============================] - 0s 937us/step - loss: 5.3296\n16/16 [==============================] - 0s 866us/step - loss: 5.3296\n16/16 [==============================] - 0s 859us/step - loss: 5.3296\n16/16 [==============================] - 0s 840us/step - loss: 5.3296\n16/16 [==============================] - 0s 850us/step - loss: 5.3296\n16/16 [==============================] - 0s 851us/step - loss: 5.3296\n\nTesting for epoch 30 index 19:\n391/391 [==============================] - 0s 819us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.0042\n16/16 [==============================] - 0s 799us/step - loss: 4.9416\n16/16 [==============================] - 0s 793us/step - loss: 4.9419\n16/16 [==============================] - 0s 818us/step - loss: 5.3295\n16/16 [==============================] - 0s 1ms/step - loss: 5.3306\n16/16 [==============================] - 0s 768us/step - loss: 5.3306\n16/16 [==============================] - 0s 760us/step - loss: 5.3306\n16/16 [==============================] - 0s 761us/step - loss: 5.3306\n16/16 [==============================] - 0s 815us/step - loss: 5.3306\n16/16 [==============================] - 0s 973us/step - loss: 5.3306\n\nTesting for epoch 30 index 20:\n391/391 [==============================] - 0s 911us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.0039\n16/16 [==============================] - 0s 810us/step - loss: 4.8870\n16/16 [==============================] - 0s 810us/step - loss: 4.8872\n16/16 [==============================] - 0s 2ms/step - loss: 5.2787\n16/16 [==============================] - 0s 925us/step - loss: 5.2798\n16/16 [==============================] - 0s 4ms/step - loss: 5.2798\n16/16 [==============================] - 0s 681us/step - loss: 5.2798\n16/16 [==============================] - 0s 835us/step - loss: 5.2798\n16/16 [==============================] - 0s 2ms/step - loss: 5.2798\n16/16 [==============================] - 0s 779us/step - loss: 5.2798\n\nTesting for epoch 30 index 21:\n391/391 [==============================] - 0s 637us/step\n16/16 [==============================] - 0s 916us/step - loss: 0.0037\n16/16 [==============================] - 0s 917us/step - loss: 4.9127\n16/16 [==============================] - 0s 928us/step - loss: 4.9130\n16/16 [==============================] - 0s 925us/step - loss: 5.3022\n16/16 [==============================] - 0s 918us/step - loss: 5.3033\n16/16 [==============================] - 0s 920us/step - loss: 5.3033\n16/16 [==============================] - 0s 926us/step - loss: 5.3033\n16/16 [==============================] - 0s 917us/step - loss: 5.3033\n16/16 [==============================] - 0s 906us/step - loss: 5.3033\n16/16 [==============================] - 0s 906us/step - loss: 5.3033\n\nTesting for epoch 30 index 22:\n391/391 [==============================] - 0s 732us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.9835\n16/16 [==============================] - 0s 1ms/step - loss: 4.9838\n16/16 [==============================] - 0s 879us/step - loss: 5.3653\n16/16 [==============================] - 0s 891us/step - loss: 5.3664\n16/16 [==============================] - 0s 892us/step - loss: 5.3664\n16/16 [==============================] - 0s 900us/step - loss: 5.3664\n16/16 [==============================] - 0s 1ms/step - loss: 5.3664\n16/16 [==============================] - 0s 1ms/step - loss: 5.3664\n16/16 [==============================] - 0s 862us/step - loss: 5.3664\n\nTesting for epoch 30 index 23:\n391/391 [==============================] - 0s 648us/step\n16/16 [==============================] - 0s 889us/step - loss: 0.0037\n16/16 [==============================] - 0s 960us/step - loss: 4.9286\n16/16 [==============================] - 0s 895us/step - loss: 4.9289\n16/16 [==============================] - 0s 1ms/step - loss: 5.3178\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 902us/step - loss: 5.3189\n16/16 [==============================] - 0s 890us/step - loss: 5.3189\n16/16 [==============================] - 0s 871us/step - loss: 5.3189\n\nTesting for epoch 30 index 24:\n391/391 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 835us/step - loss: 0.0038\n16/16 [==============================] - 0s 882us/step - loss: 4.9576\n16/16 [==============================] - 0s 867us/step - loss: 4.9578\n16/16 [==============================] - 0s 1ms/step - loss: 5.3417\n16/16 [==============================] - 0s 906us/step - loss: 5.3428\n16/16 [==============================] - 0s 1ms/step - loss: 5.3428\n16/16 [==============================] - 0s 846us/step - loss: 5.3428\n16/16 [==============================] - 0s 884us/step - loss: 5.3428\n16/16 [==============================] - 0s 834us/step - loss: 5.3428\n16/16 [==============================] - 0s 904us/step - loss: 5.3428\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n391/391 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 854us/step - loss: 0.0035\n16/16 [==============================] - 0s 866us/step - loss: 4.9590\n16/16 [==============================] - 0s 876us/step - loss: 4.9593\n16/16 [==============================] - 0s 885us/step - loss: 5.3430\n16/16 [==============================] - 0s 887us/step - loss: 5.3441\n16/16 [==============================] - 0s 937us/step - loss: 5.3441\n16/16 [==============================] - 0s 894us/step - loss: 5.3441\n16/16 [==============================] - 0s 895us/step - loss: 5.3441\n16/16 [==============================] - 0s 923us/step - loss: 5.3441\n16/16 [==============================] - 0s 1ms/step - loss: 5.3441\n\nTesting for epoch 31 index 2:\n391/391 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 838us/step - loss: 0.0035\n16/16 [==============================] - 0s 848us/step - loss: 4.9721\n16/16 [==============================] - 0s 836us/step - loss: 4.9724\n16/16 [==============================] - 0s 850us/step - loss: 5.3553\n16/16 [==============================] - 0s 842us/step - loss: 5.3564\n16/16 [==============================] - 0s 867us/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n\nTesting for epoch 31 index 3:\n391/391 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.0038\n16/16 [==============================] - 0s 819us/step - loss: 5.0099\n16/16 [==============================] - 0s 796us/step - loss: 5.0102\n16/16 [==============================] - 0s 2ms/step - loss: 5.3919\n16/16 [==============================] - 0s 1ms/step - loss: 5.3930\n16/16 [==============================] - 0s 708us/step - loss: 5.3930\n16/16 [==============================] - 0s 764us/step - loss: 5.3930\n16/16 [==============================] - 0s 770us/step - loss: 5.3930\n16/16 [==============================] - 0s 771us/step - loss: 5.3930\n16/16 [==============================] - 0s 2ms/step - loss: 5.3930\n\nTesting for epoch 31 index 4:\n391/391 [==============================] - 0s 737us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0035\n16/16 [==============================] - 0s 822us/step - loss: 4.9931\n16/16 [==============================] - 0s 2ms/step - loss: 4.9933\n16/16 [==============================] - 0s 2ms/step - loss: 5.3732\n16/16 [==============================] - 0s 2ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 860us/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n\nTesting for epoch 31 index 5:\n391/391 [==============================] - 0s 731us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 872us/step - loss: 5.0456\n16/16 [==============================] - 0s 874us/step - loss: 5.0459\n16/16 [==============================] - 0s 862us/step - loss: 5.4229\n16/16 [==============================] - 0s 880us/step - loss: 5.4240\n16/16 [==============================] - 0s 893us/step - loss: 5.4240\n16/16 [==============================] - 0s 872us/step - loss: 5.4240\n16/16 [==============================] - 0s 1ms/step - loss: 5.4240\n16/16 [==============================] - 0s 844us/step - loss: 5.4240\n16/16 [==============================] - 0s 856us/step - loss: 5.4240\n\nTesting for epoch 31 index 6:\n391/391 [==============================] - 0s 657us/step\n16/16 [==============================] - 0s 900us/step - loss: 0.0033\n16/16 [==============================] - 0s 918us/step - loss: 5.0333\n16/16 [==============================] - 0s 868us/step - loss: 5.0336\n16/16 [==============================] - 0s 872us/step - loss: 5.4113\n16/16 [==============================] - 0s 885us/step - loss: 5.4124\n16/16 [==============================] - 0s 873us/step - loss: 5.4124\n16/16 [==============================] - 0s 893us/step - loss: 5.4124\n16/16 [==============================] - 0s 892us/step - loss: 5.4124\n16/16 [==============================] - 0s 875us/step - loss: 5.4124\n16/16 [==============================] - 0s 859us/step - loss: 5.4124\n\nTesting for epoch 31 index 7:\n391/391 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 877us/step - loss: 0.0036\n16/16 [==============================] - 0s 883us/step - loss: 5.0652\n16/16 [==============================] - 0s 900us/step - loss: 5.0655\n16/16 [==============================] - 0s 910us/step - loss: 5.4405\n16/16 [==============================] - 0s 849us/step - loss: 5.4416\n16/16 [==============================] - 0s 867us/step - loss: 5.4416\n16/16 [==============================] - 0s 840us/step - loss: 5.4416\n16/16 [==============================] - 0s 872us/step - loss: 5.4416\n16/16 [==============================] - 0s 876us/step - loss: 5.4416\n16/16 [==============================] - 0s 891us/step - loss: 5.4416\n\nTesting for epoch 31 index 8:\n391/391 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0031\n16/16 [==============================] - 0s 892us/step - loss: 5.0470\n16/16 [==============================] - 0s 894us/step - loss: 5.0473\n16/16 [==============================] - 0s 873us/step - loss: 5.4234\n16/16 [==============================] - 0s 883us/step - loss: 5.4245\n16/16 [==============================] - 0s 885us/step - loss: 5.4245\n16/16 [==============================] - 0s 874us/step - loss: 5.4245\n16/16 [==============================] - 0s 871us/step - loss: 5.4245\n16/16 [==============================] - 0s 876us/step - loss: 5.4245\n16/16 [==============================] - 0s 851us/step - loss: 5.4245\n\nTesting for epoch 31 index 9:\n391/391 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0037\n16/16 [==============================] - 0s 879us/step - loss: 5.1318\n16/16 [==============================] - 0s 910us/step - loss: 5.1321\n16/16 [==============================] - 0s 1ms/step - loss: 5.5008\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n\nTesting for epoch 31 index 10:\n391/391 [==============================] - 0s 624us/step\n16/16 [==============================] - 0s 908us/step - loss: 0.0035\n16/16 [==============================] - 0s 889us/step - loss: 5.0184\n16/16 [==============================] - 0s 907us/step - loss: 5.0186\n16/16 [==============================] - 0s 906us/step - loss: 5.3973\n16/16 [==============================] - 0s 913us/step - loss: 5.3984\n16/16 [==============================] - 0s 958us/step - loss: 5.3984\n16/16 [==============================] - 0s 895us/step - loss: 5.3984\n16/16 [==============================] - 0s 856us/step - loss: 5.3984\n16/16 [==============================] - 0s 897us/step - loss: 5.3984\n16/16 [==============================] - 0s 880us/step - loss: 5.3984\n\nTesting for epoch 31 index 11:\n391/391 [==============================] - 0s 981us/step\n16/16 [==============================] - 0s 823us/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.0033\n16/16 [==============================] - 0s 1ms/step - loss: 5.3850\n16/16 [==============================] - 0s 849us/step - loss: 5.3861\n16/16 [==============================] - 0s 842us/step - loss: 5.3861\n16/16 [==============================] - 0s 784us/step - loss: 5.3861\n16/16 [==============================] - 0s 660us/step - loss: 5.3861\n16/16 [==============================] - 0s 2ms/step - loss: 5.3861\n16/16 [==============================] - 0s 656us/step - loss: 5.3861\n\nTesting for epoch 31 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 932us/step - loss: 5.0029\n16/16 [==============================] - 0s 1ms/step - loss: 5.0032\n16/16 [==============================] - 0s 1ms/step - loss: 5.3889\n16/16 [==============================] - 0s 803us/step - loss: 5.3900\n16/16 [==============================] - 0s 2ms/step - loss: 5.3900\n16/16 [==============================] - 0s 897us/step - loss: 5.3900\n16/16 [==============================] - 0s 895us/step - loss: 5.3900\n16/16 [==============================] - 0s 884us/step - loss: 5.3900\n16/16 [==============================] - 0s 887us/step - loss: 5.3900\n\nTesting for epoch 31 index 13:\n391/391 [==============================] - 0s 691us/step\n16/16 [==============================] - 0s 933us/step - loss: 0.0038\n16/16 [==============================] - 0s 901us/step - loss: 4.9968\n16/16 [==============================] - 0s 891us/step - loss: 4.9970\n16/16 [==============================] - 0s 892us/step - loss: 5.3825\n16/16 [==============================] - 0s 905us/step - loss: 5.3836\n16/16 [==============================] - 0s 866us/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n\nTesting for epoch 31 index 14:\n391/391 [==============================] - 0s 725us/step\n16/16 [==============================] - 0s 875us/step - loss: 0.0045\n16/16 [==============================] - 0s 858us/step - loss: 4.9823\n16/16 [==============================] - 0s 854us/step - loss: 4.9826\n16/16 [==============================] - 0s 897us/step - loss: 5.3690\n16/16 [==============================] - 0s 884us/step - loss: 5.3701\n16/16 [==============================] - 0s 886us/step - loss: 5.3701\n16/16 [==============================] - 0s 907us/step - loss: 5.3701\n16/16 [==============================] - 0s 899us/step - loss: 5.3701\n16/16 [==============================] - 0s 864us/step - loss: 5.3701\n16/16 [==============================] - 0s 875us/step - loss: 5.3701\n\nTesting for epoch 31 index 15:\n391/391 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 861us/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.9342\n16/16 [==============================] - 0s 917us/step - loss: 4.9344\n16/16 [==============================] - 0s 860us/step - loss: 5.3283\n16/16 [==============================] - 0s 855us/step - loss: 5.3294\n16/16 [==============================] - 0s 857us/step - loss: 5.3294\n16/16 [==============================] - 0s 854us/step - loss: 5.3294\n16/16 [==============================] - 0s 849us/step - loss: 5.3294\n16/16 [==============================] - 0s 842us/step - loss: 5.3294\n16/16 [==============================] - 0s 1ms/step - loss: 5.3294\n\nTesting for epoch 31 index 16:\n391/391 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 878us/step - loss: 4.9532\n16/16 [==============================] - 0s 858us/step - loss: 4.9535\n16/16 [==============================] - 0s 858us/step - loss: 5.3453\n16/16 [==============================] - 0s 864us/step - loss: 5.3464\n16/16 [==============================] - 0s 832us/step - loss: 5.3464\n16/16 [==============================] - 0s 886us/step - loss: 5.3464\n16/16 [==============================] - 0s 876us/step - loss: 5.3464\n16/16 [==============================] - 0s 856us/step - loss: 5.3464\n16/16 [==============================] - 0s 856us/step - loss: 5.3464\n\nTesting for epoch 31 index 17:\n391/391 [==============================] - 0s 651us/step\n16/16 [==============================] - 0s 895us/step - loss: 0.0042\n16/16 [==============================] - 0s 901us/step - loss: 4.9573\n16/16 [==============================] - 0s 910us/step - loss: 4.9576\n16/16 [==============================] - 0s 910us/step - loss: 5.3480\n16/16 [==============================] - 0s 902us/step - loss: 5.3491\n16/16 [==============================] - 0s 883us/step - loss: 5.3491\n16/16 [==============================] - 0s 885us/step - loss: 5.3491\n16/16 [==============================] - 0s 840us/step - loss: 5.3491\n16/16 [==============================] - 0s 853us/step - loss: 5.3491\n16/16 [==============================] - 0s 860us/step - loss: 5.3491\n\nTesting for epoch 31 index 18:\n391/391 [==============================] - 0s 627us/step\n16/16 [==============================] - 0s 928us/step - loss: 0.0043\n16/16 [==============================] - 0s 888us/step - loss: 5.0424\n16/16 [==============================] - 0s 864us/step - loss: 5.0427\n16/16 [==============================] - 0s 876us/step - loss: 5.4280\n16/16 [==============================] - 0s 884us/step - loss: 5.4291\n16/16 [==============================] - 0s 928us/step - loss: 5.4291\n16/16 [==============================] - 0s 882us/step - loss: 5.4291\n16/16 [==============================] - 0s 880us/step - loss: 5.4291\n16/16 [==============================] - 0s 928us/step - loss: 5.4291\n16/16 [==============================] - 0s 885us/step - loss: 5.4291\n\nTesting for epoch 31 index 19:\n391/391 [==============================] - 0s 693us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.0043\n16/16 [==============================] - 0s 783us/step - loss: 4.9765\n16/16 [==============================] - 0s 781us/step - loss: 4.9768\n16/16 [==============================] - 0s 1ms/step - loss: 5.3659\n16/16 [==============================] - 0s 2ms/step - loss: 5.3670\n16/16 [==============================] - 0s 749us/step - loss: 5.3670\n16/16 [==============================] - 0s 837us/step - loss: 5.3670\n16/16 [==============================] - 0s 1ms/step - loss: 5.3670\n16/16 [==============================] - 0s 665us/step - loss: 5.3670\n16/16 [==============================] - 0s 2ms/step - loss: 5.3670\n\nTesting for epoch 31 index 20:\n391/391 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 821us/step - loss: 4.9601\n16/16 [==============================] - 0s 819us/step - loss: 4.9603\n16/16 [==============================] - 0s 821us/step - loss: 5.3521\n16/16 [==============================] - 0s 781us/step - loss: 5.3532\n16/16 [==============================] - 0s 1ms/step - loss: 5.3532\n16/16 [==============================] - 0s 953us/step - loss: 5.3532\n16/16 [==============================] - 0s 1ms/step - loss: 5.3532\n16/16 [==============================] - 0s 2ms/step - loss: 5.3532\n16/16 [==============================] - 0s 767us/step - loss: 5.3532\n\nTesting for epoch 31 index 21:\n391/391 [==============================] - 0s 621us/step\n16/16 [==============================] - 0s 908us/step - loss: 0.0042\n16/16 [==============================] - 0s 874us/step - loss: 4.9714\n16/16 [==============================] - 0s 1ms/step - loss: 4.9717\n16/16 [==============================] - 0s 1ms/step - loss: 5.3639\n16/16 [==============================] - 0s 1ms/step - loss: 5.3651\n16/16 [==============================] - 0s 895us/step - loss: 5.3651\n16/16 [==============================] - 0s 888us/step - loss: 5.3651\n16/16 [==============================] - 0s 886us/step - loss: 5.3651\n16/16 [==============================] - 0s 1ms/step - loss: 5.3651\n16/16 [==============================] - 0s 883us/step - loss: 5.3651\n\nTesting for epoch 31 index 22:\n391/391 [==============================] - 0s 783us/step\n16/16 [==============================] - 0s 873us/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 5.0220\n16/16 [==============================] - 0s 894us/step - loss: 5.0223\n16/16 [==============================] - 0s 1ms/step - loss: 5.4104\n16/16 [==============================] - 0s 1ms/step - loss: 5.4115\n16/16 [==============================] - 0s 1ms/step - loss: 5.4115\n16/16 [==============================] - 0s 862us/step - loss: 5.4115\n16/16 [==============================] - 0s 873us/step - loss: 5.4115\n16/16 [==============================] - 0s 877us/step - loss: 5.4115\n16/16 [==============================] - 0s 865us/step - loss: 5.4115\n\nTesting for epoch 31 index 23:\n391/391 [==============================] - 0s 670us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0040\n16/16 [==============================] - 0s 914us/step - loss: 5.0154\n16/16 [==============================] - 0s 904us/step - loss: 5.0157\n16/16 [==============================] - 0s 929us/step - loss: 5.4035\n16/16 [==============================] - 0s 920us/step - loss: 5.4046\n16/16 [==============================] - 0s 899us/step - loss: 5.4046\n16/16 [==============================] - 0s 881us/step - loss: 5.4046\n16/16 [==============================] - 0s 884us/step - loss: 5.4046\n16/16 [==============================] - 0s 930us/step - loss: 5.4046\n16/16 [==============================] - 0s 937us/step - loss: 5.4046\n\nTesting for epoch 31 index 24:\n391/391 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 891us/step - loss: 0.0037\n16/16 [==============================] - 0s 870us/step - loss: 5.0249\n16/16 [==============================] - 0s 891us/step - loss: 5.0252\n16/16 [==============================] - 0s 888us/step - loss: 5.4131\n16/16 [==============================] - 0s 880us/step - loss: 5.4142\n16/16 [==============================] - 0s 857us/step - loss: 5.4142\n16/16 [==============================] - 0s 844us/step - loss: 5.4142\n16/16 [==============================] - 0s 881us/step - loss: 5.4142\n16/16 [==============================] - 0s 853us/step - loss: 5.4142\n16/16 [==============================] - 0s 864us/step - loss: 5.4142\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n391/391 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 832us/step - loss: 0.0037\n16/16 [==============================] - 0s 900us/step - loss: 5.0944\n16/16 [==============================] - 0s 884us/step - loss: 5.0947\n16/16 [==============================] - 0s 925us/step - loss: 5.4751\n16/16 [==============================] - 0s 917us/step - loss: 5.4762\n16/16 [==============================] - 0s 907us/step - loss: 5.4762\n16/16 [==============================] - 0s 922us/step - loss: 5.4762\n16/16 [==============================] - 0s 929us/step - loss: 5.4762\n16/16 [==============================] - 0s 910us/step - loss: 5.4762\n16/16 [==============================] - 0s 911us/step - loss: 5.4762\n\nTesting for epoch 32 index 2:\n391/391 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.0033\n16/16 [==============================] - 0s 858us/step - loss: 5.0400\n16/16 [==============================] - 0s 866us/step - loss: 5.0403\n16/16 [==============================] - 0s 862us/step - loss: 5.4251\n16/16 [==============================] - 0s 860us/step - loss: 5.4262\n16/16 [==============================] - 0s 874us/step - loss: 5.4262\n16/16 [==============================] - 0s 844us/step - loss: 5.4262\n16/16 [==============================] - 0s 931us/step - loss: 5.4262\n16/16 [==============================] - 0s 883us/step - loss: 5.4262\n16/16 [==============================] - 0s 842us/step - loss: 5.4262\n\nTesting for epoch 32 index 3:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 859us/step - loss: 0.0034\n16/16 [==============================] - 0s 1ms/step - loss: 5.0175\n16/16 [==============================] - 0s 857us/step - loss: 5.0178\n16/16 [==============================] - 0s 1ms/step - loss: 5.4025\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 949us/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n\nTesting for epoch 32 index 4:\n391/391 [==============================] - 0s 639us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 682us/step - loss: 5.0523\n16/16 [==============================] - 0s 793us/step - loss: 5.0525\n16/16 [==============================] - 0s 798us/step - loss: 5.4323\n16/16 [==============================] - 0s 1ms/step - loss: 5.4334\n16/16 [==============================] - 0s 762us/step - loss: 5.4334\n16/16 [==============================] - 0s 931us/step - loss: 5.4334\n16/16 [==============================] - 0s 936us/step - loss: 5.4334\n16/16 [==============================] - 0s 910us/step - loss: 5.4334\n16/16 [==============================] - 0s 798us/step - loss: 5.4334\n\nTesting for epoch 32 index 5:\n391/391 [==============================] - 0s 735us/step\n16/16 [==============================] - 0s 770us/step - loss: 0.0036\n16/16 [==============================] - 0s 1ms/step - loss: 5.1095\n16/16 [==============================] - 0s 2ms/step - loss: 5.1098\n16/16 [==============================] - 0s 2ms/step - loss: 5.4870\n16/16 [==============================] - 0s 874us/step - loss: 5.4881\n16/16 [==============================] - 0s 2ms/step - loss: 5.4881\n16/16 [==============================] - 0s 789us/step - loss: 5.4881\n16/16 [==============================] - 0s 1ms/step - loss: 5.4881\n16/16 [==============================] - 0s 809us/step - loss: 5.4881\n16/16 [==============================] - 0s 2ms/step - loss: 5.4881\n\nTesting for epoch 32 index 6:\n391/391 [==============================] - 0s 735us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0034\n16/16 [==============================] - 0s 755us/step - loss: 5.0918\n16/16 [==============================] - 0s 817us/step - loss: 5.0921\n16/16 [==============================] - 0s 815us/step - loss: 5.4724\n16/16 [==============================] - 0s 716us/step - loss: 5.4735\n16/16 [==============================] - 0s 739us/step - loss: 5.4735\n16/16 [==============================] - 0s 722us/step - loss: 5.4735\n16/16 [==============================] - 0s 873us/step - loss: 5.4735\n16/16 [==============================] - 0s 885us/step - loss: 5.4735\n16/16 [==============================] - 0s 929us/step - loss: 5.4735\n\nTesting for epoch 32 index 7:\n391/391 [==============================] - 0s 652us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0031\n16/16 [==============================] - 0s 903us/step - loss: 5.0698\n16/16 [==============================] - 0s 929us/step - loss: 5.0701\n16/16 [==============================] - 0s 922us/step - loss: 5.4505\n16/16 [==============================] - 0s 889us/step - loss: 5.4516\n16/16 [==============================] - 0s 888us/step - loss: 5.4516\n16/16 [==============================] - 0s 884us/step - loss: 5.4516\n16/16 [==============================] - 0s 866us/step - loss: 5.4516\n16/16 [==============================] - 0s 941us/step - loss: 5.4516\n16/16 [==============================] - 0s 926us/step - loss: 5.4516\n\nTesting for epoch 32 index 8:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 945us/step - loss: 0.0030\n16/16 [==============================] - 0s 926us/step - loss: 5.0715\n16/16 [==============================] - 0s 940us/step - loss: 5.0718\n16/16 [==============================] - 0s 933us/step - loss: 5.4501\n16/16 [==============================] - 0s 938us/step - loss: 5.4512\n16/16 [==============================] - 0s 908us/step - loss: 5.4512\n16/16 [==============================] - 0s 902us/step - loss: 5.4512\n16/16 [==============================] - 0s 876us/step - loss: 5.4512\n16/16 [==============================] - 0s 959us/step - loss: 5.4512\n16/16 [==============================] - 0s 935us/step - loss: 5.4512\n\nTesting for epoch 32 index 9:\n391/391 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 919us/step - loss: 0.0030\n16/16 [==============================] - 0s 852us/step - loss: 5.1353\n16/16 [==============================] - 0s 870us/step - loss: 5.1356\n16/16 [==============================] - 0s 880us/step - loss: 5.5097\n16/16 [==============================] - 0s 894us/step - loss: 5.5107\n16/16 [==============================] - 0s 904us/step - loss: 5.5107\n16/16 [==============================] - 0s 878us/step - loss: 5.5107\n16/16 [==============================] - 0s 939us/step - loss: 5.5107\n16/16 [==============================] - 0s 889us/step - loss: 5.5107\n16/16 [==============================] - 0s 907us/step - loss: 5.5107\n\nTesting for epoch 32 index 10:\n391/391 [==============================] - 0s 641us/step\n16/16 [==============================] - 0s 919us/step - loss: 0.0031\n16/16 [==============================] - 0s 918us/step - loss: 5.0857\n16/16 [==============================] - 0s 894us/step - loss: 5.0860\n16/16 [==============================] - 0s 895us/step - loss: 5.4657\n16/16 [==============================] - 0s 904us/step - loss: 5.4668\n16/16 [==============================] - 0s 900us/step - loss: 5.4668\n16/16 [==============================] - 0s 900us/step - loss: 5.4668\n16/16 [==============================] - 0s 905us/step - loss: 5.4668\n16/16 [==============================] - 0s 868us/step - loss: 5.4668\n16/16 [==============================] - 0s 884us/step - loss: 5.4668\n\nTesting for epoch 32 index 11:\n391/391 [==============================] - 0s 689us/step\n16/16 [==============================] - 0s 932us/step - loss: 0.0037\n16/16 [==============================] - 0s 928us/step - loss: 5.0737\n16/16 [==============================] - 0s 928us/step - loss: 5.0740\n16/16 [==============================] - 0s 949us/step - loss: 5.4543\n16/16 [==============================] - 0s 899us/step - loss: 5.4553\n16/16 [==============================] - 0s 908us/step - loss: 5.4553\n16/16 [==============================] - 0s 898us/step - loss: 5.4553\n16/16 [==============================] - 0s 893us/step - loss: 5.4553\n16/16 [==============================] - 0s 903us/step - loss: 5.4553\n16/16 [==============================] - 0s 877us/step - loss: 5.4553\n\nTesting for epoch 32 index 12:\n391/391 [==============================] - 0s 614us/step\n16/16 [==============================] - 0s 952us/step - loss: 0.0037\n16/16 [==============================] - 0s 841us/step - loss: 5.0692\n16/16 [==============================] - 0s 876us/step - loss: 5.0694\n16/16 [==============================] - 0s 866us/step - loss: 5.4520\n16/16 [==============================] - 0s 863us/step - loss: 5.4531\n16/16 [==============================] - 0s 855us/step - loss: 5.4531\n16/16 [==============================] - 0s 969us/step - loss: 5.4531\n16/16 [==============================] - 0s 917us/step - loss: 5.4531\n16/16 [==============================] - 0s 937us/step - loss: 5.4531\n16/16 [==============================] - 0s 959us/step - loss: 5.4531\n\nTesting for epoch 32 index 13:\n391/391 [==============================] - 0s 886us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 777us/step - loss: 5.0091\n16/16 [==============================] - 0s 771us/step - loss: 5.0094\n16/16 [==============================] - 0s 787us/step - loss: 5.3983\n16/16 [==============================] - 0s 2ms/step - loss: 5.3994\n16/16 [==============================] - 0s 1ms/step - loss: 5.3994\n16/16 [==============================] - 0s 687us/step - loss: 5.3994\n16/16 [==============================] - 0s 2ms/step - loss: 5.3994\n16/16 [==============================] - 0s 775us/step - loss: 5.3994\n16/16 [==============================] - 0s 759us/step - loss: 5.3994\n\nTesting for epoch 32 index 14:\n391/391 [==============================] - 0s 829us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 761us/step - loss: 5.0421\n16/16 [==============================] - 0s 1ms/step - loss: 5.0424\n16/16 [==============================] - 0s 910us/step - loss: 5.4300\n16/16 [==============================] - 0s 905us/step - loss: 5.4311\n16/16 [==============================] - 0s 918us/step - loss: 5.4311\n16/16 [==============================] - 0s 916us/step - loss: 5.4311\n16/16 [==============================] - 0s 913us/step - loss: 5.4311\n16/16 [==============================] - 0s 904us/step - loss: 5.4311\n16/16 [==============================] - 0s 903us/step - loss: 5.4311\n\nTesting for epoch 32 index 15:\n391/391 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 872us/step - loss: 5.0083\n16/16 [==============================] - 0s 922us/step - loss: 5.0085\n16/16 [==============================] - 0s 854us/step - loss: 5.3998\n16/16 [==============================] - 0s 843us/step - loss: 5.4009\n16/16 [==============================] - 0s 925us/step - loss: 5.4009\n16/16 [==============================] - 0s 917us/step - loss: 5.4009\n16/16 [==============================] - 0s 963us/step - loss: 5.4009\n16/16 [==============================] - 0s 927us/step - loss: 5.4009\n16/16 [==============================] - 0s 922us/step - loss: 5.4009\n\nTesting for epoch 32 index 16:\n391/391 [==============================] - 0s 654us/step\n16/16 [==============================] - 0s 921us/step - loss: 0.0042\n16/16 [==============================] - 0s 906us/step - loss: 5.0189\n16/16 [==============================] - 0s 924us/step - loss: 5.0192\n16/16 [==============================] - 0s 919us/step - loss: 5.4121\n16/16 [==============================] - 0s 933us/step - loss: 5.4133\n16/16 [==============================] - 0s 932us/step - loss: 5.4133\n16/16 [==============================] - 0s 910us/step - loss: 5.4133\n16/16 [==============================] - 0s 876us/step - loss: 5.4133\n16/16 [==============================] - 0s 899us/step - loss: 5.4133\n16/16 [==============================] - 0s 901us/step - loss: 5.4133\n\nTesting for epoch 32 index 17:\n391/391 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 923us/step - loss: 0.0043\n16/16 [==============================] - 0s 904us/step - loss: 5.0400\n16/16 [==============================] - 0s 935us/step - loss: 5.0403\n16/16 [==============================] - 0s 900us/step - loss: 5.4291\n16/16 [==============================] - 0s 956us/step - loss: 5.4302\n16/16 [==============================] - 0s 921us/step - loss: 5.4302\n16/16 [==============================] - 0s 908us/step - loss: 5.4302\n16/16 [==============================] - 0s 892us/step - loss: 5.4302\n16/16 [==============================] - 0s 903us/step - loss: 5.4302\n16/16 [==============================] - 0s 877us/step - loss: 5.4302\n\nTesting for epoch 32 index 18:\n391/391 [==============================] - 0s 638us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.0041\n16/16 [==============================] - 0s 858us/step - loss: 5.0363\n16/16 [==============================] - 0s 912us/step - loss: 5.0366\n16/16 [==============================] - 0s 869us/step - loss: 5.4261\n16/16 [==============================] - 0s 872us/step - loss: 5.4272\n16/16 [==============================] - 0s 876us/step - loss: 5.4272\n16/16 [==============================] - 0s 868us/step - loss: 5.4272\n16/16 [==============================] - 0s 881us/step - loss: 5.4272\n16/16 [==============================] - 0s 887us/step - loss: 5.4272\n16/16 [==============================] - 0s 885us/step - loss: 5.4272\n\nTesting for epoch 32 index 19:\n391/391 [==============================] - 0s 643us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0042\n16/16 [==============================] - 0s 890us/step - loss: 5.0048\n16/16 [==============================] - 0s 889us/step - loss: 5.0051\n16/16 [==============================] - 0s 911us/step - loss: 5.3996\n16/16 [==============================] - 0s 904us/step - loss: 5.4007\n16/16 [==============================] - 0s 904us/step - loss: 5.4007\n16/16 [==============================] - 0s 880us/step - loss: 5.4007\n16/16 [==============================] - 0s 912us/step - loss: 5.4007\n16/16 [==============================] - 0s 913us/step - loss: 5.4007\n16/16 [==============================] - 0s 892us/step - loss: 5.4007\n\nTesting for epoch 32 index 20:\n391/391 [==============================] - 0s 680us/step\n16/16 [==============================] - 0s 963us/step - loss: 0.0041\n16/16 [==============================] - 0s 913us/step - loss: 4.9931\n16/16 [==============================] - 0s 979us/step - loss: 4.9934\n16/16 [==============================] - 0s 943us/step - loss: 5.3873\n16/16 [==============================] - 0s 928us/step - loss: 5.3884\n16/16 [==============================] - 0s 938us/step - loss: 5.3884\n16/16 [==============================] - 0s 932us/step - loss: 5.3884\n16/16 [==============================] - 0s 908us/step - loss: 5.3884\n16/16 [==============================] - 0s 926us/step - loss: 5.3884\n16/16 [==============================] - 0s 931us/step - loss: 5.3884\n\nTesting for epoch 32 index 21:\n391/391 [==============================] - 0s 856us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 778us/step - loss: 5.0216\n16/16 [==============================] - 0s 798us/step - loss: 5.0219\n16/16 [==============================] - 0s 751us/step - loss: 5.4141\n16/16 [==============================] - 0s 790us/step - loss: 5.4152\n16/16 [==============================] - 0s 834us/step - loss: 5.4152\n16/16 [==============================] - 0s 764us/step - loss: 5.4152\n16/16 [==============================] - 0s 761us/step - loss: 5.4152\n16/16 [==============================] - 0s 769us/step - loss: 5.4152\n16/16 [==============================] - 0s 617us/step - loss: 5.4152\n\nTesting for epoch 32 index 22:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.0627\n16/16 [==============================] - 0s 2ms/step - loss: 5.0629\n16/16 [==============================] - 0s 773us/step - loss: 5.4517\n16/16 [==============================] - 0s 774us/step - loss: 5.4528\n16/16 [==============================] - 0s 2ms/step - loss: 5.4528\n16/16 [==============================] - 0s 1ms/step - loss: 5.4528\n16/16 [==============================] - 0s 855us/step - loss: 5.4528\n16/16 [==============================] - 0s 973us/step - loss: 5.4528\n16/16 [==============================] - 0s 925us/step - loss: 5.4528\n\nTesting for epoch 32 index 23:\n391/391 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0040\n16/16 [==============================] - 0s 903us/step - loss: 5.0166\n16/16 [==============================] - 0s 904us/step - loss: 5.0168\n16/16 [==============================] - 0s 845us/step - loss: 5.4091\n16/16 [==============================] - 0s 918us/step - loss: 5.4103\n16/16 [==============================] - 0s 947us/step - loss: 5.4103\n16/16 [==============================] - 0s 914us/step - loss: 5.4103\n16/16 [==============================] - 0s 1ms/step - loss: 5.4103\n16/16 [==============================] - 0s 843us/step - loss: 5.4103\n16/16 [==============================] - 0s 844us/step - loss: 5.4103\n\nTesting for epoch 32 index 24:\n391/391 [==============================] - 0s 664us/step\n16/16 [==============================] - 0s 909us/step - loss: 0.0043\n16/16 [==============================] - 0s 881us/step - loss: 5.0208\n16/16 [==============================] - 0s 886us/step - loss: 5.0211\n16/16 [==============================] - 0s 885us/step - loss: 5.4131\n16/16 [==============================] - 0s 861us/step - loss: 5.4143\n16/16 [==============================] - 0s 891us/step - loss: 5.4143\n16/16 [==============================] - 0s 860us/step - loss: 5.4143\n16/16 [==============================] - 0s 897us/step - loss: 5.4143\n16/16 [==============================] - 0s 866us/step - loss: 5.4143\n16/16 [==============================] - 0s 885us/step - loss: 5.4143\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n391/391 [==============================] - 0s 655us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0040\n16/16 [==============================] - 0s 926us/step - loss: 5.1051\n16/16 [==============================] - 0s 908us/step - loss: 5.1053\n16/16 [==============================] - 0s 943us/step - loss: 5.4884\n16/16 [==============================] - 0s 960us/step - loss: 5.4895\n16/16 [==============================] - 0s 932us/step - loss: 5.4895\n16/16 [==============================] - 0s 930us/step - loss: 5.4895\n16/16 [==============================] - 0s 932us/step - loss: 5.4895\n16/16 [==============================] - 0s 914us/step - loss: 5.4895\n16/16 [==============================] - 0s 909us/step - loss: 5.4895\n\nTesting for epoch 33 index 2:\n391/391 [==============================] - 0s 677us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0038\n16/16 [==============================] - 0s 891us/step - loss: 5.0842\n16/16 [==============================] - 0s 864us/step - loss: 5.0845\n16/16 [==============================] - 0s 885us/step - loss: 5.4717\n16/16 [==============================] - 0s 949us/step - loss: 5.4729\n16/16 [==============================] - 0s 882us/step - loss: 5.4729\n16/16 [==============================] - 0s 899us/step - loss: 5.4729\n16/16 [==============================] - 0s 900us/step - loss: 5.4729\n16/16 [==============================] - 0s 884us/step - loss: 5.4729\n16/16 [==============================] - 0s 879us/step - loss: 5.4729\n\nTesting for epoch 33 index 3:\n391/391 [==============================] - 0s 667us/step\n16/16 [==============================] - 0s 956us/step - loss: 0.0039\n16/16 [==============================] - 0s 895us/step - loss: 5.1186\n16/16 [==============================] - 0s 935us/step - loss: 5.1189\n16/16 [==============================] - 0s 926us/step - loss: 5.5018\n16/16 [==============================] - 0s 925us/step - loss: 5.5029\n16/16 [==============================] - 0s 921us/step - loss: 5.5029\n16/16 [==============================] - 0s 939us/step - loss: 5.5029\n16/16 [==============================] - 0s 914us/step - loss: 5.5029\n16/16 [==============================] - 0s 940us/step - loss: 5.5029\n16/16 [==============================] - 0s 897us/step - loss: 5.5029\n\nTesting for epoch 33 index 4:\n391/391 [==============================] - 0s 675us/step\n16/16 [==============================] - 0s 910us/step - loss: 0.0035\n16/16 [==============================] - 0s 892us/step - loss: 5.1270\n16/16 [==============================] - 0s 904us/step - loss: 5.1273\n16/16 [==============================] - 0s 908us/step - loss: 5.5075\n16/16 [==============================] - 0s 851us/step - loss: 5.5086\n16/16 [==============================] - 0s 862us/step - loss: 5.5086\n16/16 [==============================] - 0s 923us/step - loss: 5.5086\n16/16 [==============================] - 0s 917us/step - loss: 5.5086\n16/16 [==============================] - 0s 941us/step - loss: 5.5086\n16/16 [==============================] - 0s 921us/step - loss: 5.5086\n\nTesting for epoch 33 index 5:\n391/391 [==============================] - 0s 625us/step\n16/16 [==============================] - 0s 672us/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1427\n16/16 [==============================] - 0s 2ms/step - loss: 5.1430\n16/16 [==============================] - 0s 774us/step - loss: 5.5224\n16/16 [==============================] - 0s 775us/step - loss: 5.5235\n16/16 [==============================] - 0s 763us/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n\nTesting for epoch 33 index 6:\n391/391 [==============================] - 0s 683us/step\n16/16 [==============================] - 0s 781us/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1995\n16/16 [==============================] - 0s 2ms/step - loss: 5.1998\n16/16 [==============================] - 0s 2ms/step - loss: 5.5734\n16/16 [==============================] - 0s 1ms/step - loss: 5.5745\n16/16 [==============================] - 0s 876us/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n16/16 [==============================] - 0s 811us/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n\nTesting for epoch 33 index 7:\n391/391 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 848us/step - loss: 0.0032\n16/16 [==============================] - 0s 854us/step - loss: 5.1523\n16/16 [==============================] - 0s 888us/step - loss: 5.1526\n16/16 [==============================] - 0s 830us/step - loss: 5.5310\n16/16 [==============================] - 0s 824us/step - loss: 5.5321\n16/16 [==============================] - 0s 840us/step - loss: 5.5321\n16/16 [==============================] - 0s 842us/step - loss: 5.5321\n16/16 [==============================] - 0s 831us/step - loss: 5.5321\n16/16 [==============================] - 0s 828us/step - loss: 5.5321\n16/16 [==============================] - 0s 828us/step - loss: 5.5321\n\nTesting for epoch 33 index 8:\n391/391 [==============================] - 0s 626us/step\n16/16 [==============================] - 0s 914us/step - loss: 0.0033\n16/16 [==============================] - 0s 878us/step - loss: 5.1870\n16/16 [==============================] - 0s 905us/step - loss: 5.1873\n16/16 [==============================] - 0s 905us/step - loss: 5.5616\n16/16 [==============================] - 0s 905us/step - loss: 5.5626\n16/16 [==============================] - 0s 933us/step - loss: 5.5626\n16/16 [==============================] - 0s 903us/step - loss: 5.5626\n16/16 [==============================] - 0s 894us/step - loss: 5.5626\n16/16 [==============================] - 0s 899us/step - loss: 5.5626\n16/16 [==============================] - 0s 880us/step - loss: 5.5626\n\nTesting for epoch 33 index 9:\n391/391 [==============================] - 0s 631us/step\n16/16 [==============================] - 0s 869us/step - loss: 0.0037\n16/16 [==============================] - 0s 881us/step - loss: 5.2072\n16/16 [==============================] - 0s 885us/step - loss: 5.2075\n16/16 [==============================] - 0s 895us/step - loss: 5.5808\n16/16 [==============================] - 0s 943us/step - loss: 5.5819\n16/16 [==============================] - 0s 904us/step - loss: 5.5819\n16/16 [==============================] - 0s 927us/step - loss: 5.5819\n16/16 [==============================] - 0s 930us/step - loss: 5.5819\n16/16 [==============================] - 0s 921us/step - loss: 5.5819\n16/16 [==============================] - 0s 884us/step - loss: 5.5819\n\nTesting for epoch 33 index 10:\n391/391 [==============================] - 0s 632us/step\n16/16 [==============================] - 0s 894us/step - loss: 0.0033\n16/16 [==============================] - 0s 879us/step - loss: 5.1693\n16/16 [==============================] - 0s 874us/step - loss: 5.1695\n16/16 [==============================] - 0s 906us/step - loss: 5.5473\n16/16 [==============================] - 0s 860us/step - loss: 5.5483\n16/16 [==============================] - 0s 875us/step - loss: 5.5483\n16/16 [==============================] - 0s 866us/step - loss: 5.5483\n16/16 [==============================] - 0s 924us/step - loss: 5.5483\n16/16 [==============================] - 0s 939us/step - loss: 5.5483\n16/16 [==============================] - 0s 911us/step - loss: 5.5483\n\nTesting for epoch 33 index 11:\n391/391 [==============================] - 0s 662us/step\n16/16 [==============================] - 0s 890us/step - loss: 0.0031\n16/16 [==============================] - 0s 892us/step - loss: 5.0956\n16/16 [==============================] - 0s 907us/step - loss: 5.0958\n16/16 [==============================] - 0s 898us/step - loss: 5.4831\n16/16 [==============================] - 0s 893us/step - loss: 5.4842\n16/16 [==============================] - 0s 922us/step - loss: 5.4842\n16/16 [==============================] - 0s 940us/step - loss: 5.4842\n16/16 [==============================] - 0s 927us/step - loss: 5.4842\n16/16 [==============================] - 0s 936us/step - loss: 5.4842\n16/16 [==============================] - 0s 965us/step - loss: 5.4842\n\nTesting for epoch 33 index 12:\n391/391 [==============================] - 0s 672us/step\n16/16 [==============================] - 0s 890us/step - loss: 0.0036\n16/16 [==============================] - 0s 900us/step - loss: 5.1193\n16/16 [==============================] - 0s 946us/step - loss: 5.1196\n16/16 [==============================] - 0s 911us/step - loss: 5.5051\n16/16 [==============================] - 0s 931us/step - loss: 5.5062\n16/16 [==============================] - 0s 935us/step - loss: 5.5062\n16/16 [==============================] - 0s 925us/step - loss: 5.5062\n16/16 [==============================] - 0s 938us/step - loss: 5.5062\n16/16 [==============================] - 0s 951us/step - loss: 5.5062\n16/16 [==============================] - 0s 876us/step - loss: 5.5062\n\nTesting for epoch 33 index 13:\n391/391 [==============================] - 0s 662us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 941us/step - loss: 5.1050\n16/16 [==============================] - 0s 938us/step - loss: 5.1052\n16/16 [==============================] - 0s 895us/step - loss: 5.4916\n16/16 [==============================] - 0s 826us/step - loss: 5.4927\n16/16 [==============================] - 0s 912us/step - loss: 5.4927\n16/16 [==============================] - 0s 886us/step - loss: 5.4927\n16/16 [==============================] - 0s 649us/step - loss: 5.4927\n16/16 [==============================] - 0s 2ms/step - loss: 5.4927\n16/16 [==============================] - 0s 804us/step - loss: 5.4927\n\nTesting for epoch 33 index 14:\n391/391 [==============================] - 0s 696us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 5.0968\n16/16 [==============================] - 0s 689us/step - loss: 5.0971\n16/16 [==============================] - 0s 774us/step - loss: 5.4853\n16/16 [==============================] - 0s 764us/step - loss: 5.4864\n16/16 [==============================] - 0s 806us/step - loss: 5.4864\n16/16 [==============================] - 0s 2ms/step - loss: 5.4864\n16/16 [==============================] - 0s 2ms/step - loss: 5.4864\n16/16 [==============================] - 0s 805us/step - loss: 5.4864\n16/16 [==============================] - 0s 984us/step - loss: 5.4864\n\nTesting for epoch 33 index 15:\n391/391 [==============================] - 0s 780us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 755us/step - loss: 5.0582\n16/16 [==============================] - 0s 834us/step - loss: 5.0585\n16/16 [==============================] - 0s 861us/step - loss: 5.4500\n16/16 [==============================] - 0s 858us/step - loss: 5.4511\n16/16 [==============================] - 0s 871us/step - loss: 5.4511\n16/16 [==============================] - 0s 860us/step - loss: 5.4511\n16/16 [==============================] - 0s 886us/step - loss: 5.4511\n16/16 [==============================] - 0s 854us/step - loss: 5.4511\n16/16 [==============================] - 0s 916us/step - loss: 5.4511\n\nTesting for epoch 33 index 16:\n391/391 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 852us/step - loss: 0.0038\n16/16 [==============================] - 0s 852us/step - loss: 5.0006\n16/16 [==============================] - 0s 843us/step - loss: 5.0009\n16/16 [==============================] - 0s 848us/step - loss: 5.3994\n16/16 [==============================] - 0s 851us/step - loss: 5.4005\n16/16 [==============================] - 0s 847us/step - loss: 5.4005\n16/16 [==============================] - 0s 847us/step - loss: 5.4005\n16/16 [==============================] - 0s 853us/step - loss: 5.4005\n16/16 [==============================] - 0s 890us/step - loss: 5.4005\n16/16 [==============================] - 0s 883us/step - loss: 5.4005\n\nTesting for epoch 33 index 17:\n391/391 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0042\n16/16 [==============================] - 0s 868us/step - loss: 5.0322\n16/16 [==============================] - 0s 841us/step - loss: 5.0325\n16/16 [==============================] - 0s 824us/step - loss: 5.4265\n16/16 [==============================] - 0s 879us/step - loss: 5.4276\n16/16 [==============================] - 0s 893us/step - loss: 5.4276\n16/16 [==============================] - 0s 879us/step - loss: 5.4276\n16/16 [==============================] - 0s 894us/step - loss: 5.4276\n16/16 [==============================] - 0s 902us/step - loss: 5.4276\n16/16 [==============================] - 0s 896us/step - loss: 5.4276\n\nTesting for epoch 33 index 18:\n391/391 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0043\n16/16 [==============================] - 0s 882us/step - loss: 5.0743\n16/16 [==============================] - 0s 940us/step - loss: 5.0745\n16/16 [==============================] - 0s 893us/step - loss: 5.4673\n16/16 [==============================] - 0s 891us/step - loss: 5.4684\n16/16 [==============================] - 0s 908us/step - loss: 5.4684\n16/16 [==============================] - 0s 875us/step - loss: 5.4684\n16/16 [==============================] - 0s 885us/step - loss: 5.4684\n16/16 [==============================] - 0s 888us/step - loss: 5.4684\n16/16 [==============================] - 0s 860us/step - loss: 5.4684\n\nTesting for epoch 33 index 19:\n391/391 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 860us/step - loss: 0.0040\n16/16 [==============================] - 0s 852us/step - loss: 5.0430\n16/16 [==============================] - 0s 885us/step - loss: 5.0433\n16/16 [==============================] - 0s 843us/step - loss: 5.4392\n16/16 [==============================] - 0s 855us/step - loss: 5.4403\n16/16 [==============================] - 0s 844us/step - loss: 5.4403\n16/16 [==============================] - 0s 851us/step - loss: 5.4403\n16/16 [==============================] - 0s 853us/step - loss: 5.4403\n16/16 [==============================] - 0s 875us/step - loss: 5.4403\n16/16 [==============================] - 0s 847us/step - loss: 5.4403\n\nTesting for epoch 33 index 20:\n391/391 [==============================] - 0s 707us/step\n16/16 [==============================] - 0s 971us/step - loss: 0.0042\n16/16 [==============================] - 0s 968us/step - loss: 5.0666\n16/16 [==============================] - 0s 901us/step - loss: 5.0669\n16/16 [==============================] - 0s 886us/step - loss: 5.4589\n16/16 [==============================] - 0s 870us/step - loss: 5.4600\n16/16 [==============================] - 0s 860us/step - loss: 5.4600\n16/16 [==============================] - 0s 857us/step - loss: 5.4600\n16/16 [==============================] - 0s 870us/step - loss: 5.4600\n16/16 [==============================] - 0s 860us/step - loss: 5.4600\n16/16 [==============================] - 0s 842us/step - loss: 5.4600\n\nTesting for epoch 33 index 21:\n391/391 [==============================] - 0s 644us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0048\n16/16 [==============================] - 0s 858us/step - loss: 5.0766\n16/16 [==============================] - 0s 873us/step - loss: 5.0768\n16/16 [==============================] - 0s 877us/step - loss: 5.4688\n16/16 [==============================] - 0s 893us/step - loss: 5.4699\n16/16 [==============================] - 0s 956us/step - loss: 5.4699\n16/16 [==============================] - 0s 955us/step - loss: 5.4699\n16/16 [==============================] - 0s 921us/step - loss: 5.4699\n16/16 [==============================] - 0s 885us/step - loss: 5.4699\n16/16 [==============================] - 0s 847us/step - loss: 5.4699\n\nTesting for epoch 33 index 22:\n391/391 [==============================] - 0s 704us/step\n16/16 [==============================] - 0s 928us/step - loss: 0.0043\n16/16 [==============================] - 0s 912us/step - loss: 5.0861\n16/16 [==============================] - 0s 908us/step - loss: 5.0863\n16/16 [==============================] - 0s 653us/step - loss: 5.4772\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n16/16 [==============================] - 0s 703us/step - loss: 5.4783\n16/16 [==============================] - 0s 697us/step - loss: 5.4783\n16/16 [==============================] - 0s 707us/step - loss: 5.4783\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n\nTesting for epoch 33 index 23:\n391/391 [==============================] - 0s 570us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.0048\n16/16 [==============================] - 0s 802us/step - loss: 5.1277\n16/16 [==============================] - 0s 790us/step - loss: 5.1280\n16/16 [==============================] - 0s 978us/step - loss: 5.5173\n16/16 [==============================] - 0s 2ms/step - loss: 5.5185\n16/16 [==============================] - 0s 2ms/step - loss: 5.5185\n16/16 [==============================] - 0s 832us/step - loss: 5.5185\n16/16 [==============================] - 0s 958us/step - loss: 5.5185\n16/16 [==============================] - 0s 804us/step - loss: 5.5185\n16/16 [==============================] - 0s 828us/step - loss: 5.5185\n\nTesting for epoch 33 index 24:\n391/391 [==============================] - 0s 756us/step\n16/16 [==============================] - 0s 883us/step - loss: 0.0042\n16/16 [==============================] - 0s 871us/step - loss: 5.1430\n16/16 [==============================] - 0s 851us/step - loss: 5.1432\n16/16 [==============================] - 0s 931us/step - loss: 5.5293\n16/16 [==============================] - 0s 854us/step - loss: 5.5304\n16/16 [==============================] - 0s 930us/step - loss: 5.5304\n16/16 [==============================] - 0s 857us/step - loss: 5.5304\n16/16 [==============================] - 0s 906us/step - loss: 5.5304\n16/16 [==============================] - 0s 907us/step - loss: 5.5304\n16/16 [==============================] - 0s 843us/step - loss: 5.5304\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n391/391 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 851us/step - loss: 0.0043\n16/16 [==============================] - 0s 871us/step - loss: 5.1314\n16/16 [==============================] - 0s 844us/step - loss: 5.1317\n16/16 [==============================] - 0s 856us/step - loss: 5.5177\n16/16 [==============================] - 0s 843us/step - loss: 5.5188\n16/16 [==============================] - 0s 865us/step - loss: 5.5188\n16/16 [==============================] - 0s 845us/step - loss: 5.5188\n16/16 [==============================] - 0s 891us/step - loss: 5.5188\n16/16 [==============================] - 0s 891us/step - loss: 5.5188\n16/16 [==============================] - 0s 913us/step - loss: 5.5188\n\nTesting for epoch 34 index 2:\n391/391 [==============================] - 0s 689us/step\n16/16 [==============================] - 0s 993us/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.1465\n16/16 [==============================] - 0s 1ms/step - loss: 5.1467\n16/16 [==============================] - 0s 1ms/step - loss: 5.5313\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 991us/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 988us/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n\nTesting for epoch 34 index 3:\n391/391 [==============================] - 0s 627us/step\n16/16 [==============================] - 0s 917us/step - loss: 0.0037\n16/16 [==============================] - 0s 11ms/step - loss: 5.1429\n16/16 [==============================] - 0s 3ms/step - loss: 5.1432\n16/16 [==============================] - 0s 2ms/step - loss: 5.5281\n16/16 [==============================] - 0s 2ms/step - loss: 5.5292\n16/16 [==============================] - 0s 4ms/step - loss: 5.5292\n16/16 [==============================] - 0s 2ms/step - loss: 5.5292\n16/16 [==============================] - 0s 5ms/step - loss: 5.5292\n16/16 [==============================] - 0s 4ms/step - loss: 5.5292\n16/16 [==============================] - 0s 5ms/step - loss: 5.5292\n\nTesting for epoch 34 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2030\n16/16 [==============================] - 0s 1ms/step - loss: 5.2033\n16/16 [==============================] - 0s 4ms/step - loss: 5.5839\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n\nTesting for epoch 34 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 5.2007\n16/16 [==============================] - 0s 2ms/step - loss: 5.2010\n16/16 [==============================] - 0s 5ms/step - loss: 5.5812\n16/16 [==============================] - 0s 4ms/step - loss: 5.5823\n16/16 [==============================] - 0s 5ms/step - loss: 5.5823\n16/16 [==============================] - 0s 2ms/step - loss: 5.5823\n16/16 [==============================] - 0s 1ms/step - loss: 5.5823\n16/16 [==============================] - 0s 1ms/step - loss: 5.5823\n16/16 [==============================] - 0s 2ms/step - loss: 5.5823\n\nTesting for epoch 34 index 6:\n391/391 [==============================] - 0s 961us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0030\n16/16 [==============================] - 0s 4ms/step - loss: 5.1687\n16/16 [==============================] - 0s 4ms/step - loss: 5.1690\n16/16 [==============================] - 0s 3ms/step - loss: 5.5517\n16/16 [==============================] - 0s 9ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n\nTesting for epoch 34 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.2596\n16/16 [==============================] - 0s 2ms/step - loss: 5.2599\n16/16 [==============================] - 0s 1ms/step - loss: 5.6327\n16/16 [==============================] - 0s 1ms/step - loss: 5.6338\n16/16 [==============================] - 0s 5ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 3ms/step - loss: 5.6338\n\nTesting for epoch 34 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.2214\n16/16 [==============================] - 0s 3ms/step - loss: 5.2217\n16/16 [==============================] - 0s 2ms/step - loss: 5.5986\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 3ms/step - loss: 5.5997\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 4ms/step - loss: 5.5997\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 1ms/step - loss: 5.5997\n\nTesting for epoch 34 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0032\n16/16 [==============================] - 0s 2ms/step - loss: 5.2985\n16/16 [==============================] - 0s 3ms/step - loss: 5.2988\n16/16 [==============================] - 0s 2ms/step - loss: 5.6699\n16/16 [==============================] - 0s 5ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 3ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 1ms/step - loss: 5.6710\n\nTesting for epoch 34 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 5.1981\n16/16 [==============================] - 0s 3ms/step - loss: 5.1983\n16/16 [==============================] - 0s 6ms/step - loss: 5.5782\n16/16 [==============================] - 0s 1ms/step - loss: 5.5793\n16/16 [==============================] - 0s 6ms/step - loss: 5.5793\n16/16 [==============================] - 0s 6ms/step - loss: 5.5793\n16/16 [==============================] - 0s 2ms/step - loss: 5.5793\n16/16 [==============================] - 0s 4ms/step - loss: 5.5793\n16/16 [==============================] - 0s 2ms/step - loss: 5.5793\n\nTesting for epoch 34 index 11:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1648\n16/16 [==============================] - 0s 3ms/step - loss: 5.1651\n16/16 [==============================] - 0s 3ms/step - loss: 5.5503\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n\nTesting for epoch 34 index 12:\n391/391 [==============================] - 0s 561us/step\n16/16 [==============================] - 0s 851us/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 5.0803\n16/16 [==============================] - 0s 3ms/step - loss: 5.0806\n16/16 [==============================] - 0s 1ms/step - loss: 5.4738\n16/16 [==============================] - 0s 917us/step - loss: 5.4750\n16/16 [==============================] - 0s 877us/step - loss: 5.4750\n16/16 [==============================] - 0s 902us/step - loss: 5.4750\n16/16 [==============================] - 0s 884us/step - loss: 5.4750\n16/16 [==============================] - 0s 880us/step - loss: 5.4750\n16/16 [==============================] - 0s 854us/step - loss: 5.4750\n\nTesting for epoch 34 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.1099\n16/16 [==============================] - 0s 1ms/step - loss: 5.1101\n16/16 [==============================] - 0s 2ms/step - loss: 5.5011\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n16/16 [==============================] - 0s 1ms/step - loss: 5.5023\n16/16 [==============================] - 0s 1ms/step - loss: 5.5023\n16/16 [==============================] - 0s 3ms/step - loss: 5.5023\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n\nTesting for epoch 34 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.1171\n16/16 [==============================] - 0s 2ms/step - loss: 5.1174\n16/16 [==============================] - 0s 3ms/step - loss: 5.5125\n16/16 [==============================] - 0s 1ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n16/16 [==============================] - 0s 4ms/step - loss: 5.5136\n16/16 [==============================] - 0s 3ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n\nTesting for epoch 34 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 5.0741\n16/16 [==============================] - 0s 2ms/step - loss: 5.0744\n16/16 [==============================] - 0s 2ms/step - loss: 5.4716\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 1ms/step - loss: 5.4728\n\nTesting for epoch 34 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 5.1080\n16/16 [==============================] - 0s 2ms/step - loss: 5.1082\n16/16 [==============================] - 0s 2ms/step - loss: 5.5019\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 1ms/step - loss: 5.5031\n\nTesting for epoch 34 index 17:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0043\n16/16 [==============================] - 0s 3ms/step - loss: 5.0988\n16/16 [==============================] - 0s 2ms/step - loss: 5.0991\n16/16 [==============================] - 0s 2ms/step - loss: 5.4935\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 3ms/step - loss: 5.4946\n16/16 [==============================] - 0s 3ms/step - loss: 5.4946\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 4ms/step - loss: 5.4946\n\nTesting for epoch 34 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 5.1042\n16/16 [==============================] - 0s 2ms/step - loss: 5.1045\n16/16 [==============================] - 0s 2ms/step - loss: 5.4982\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 1ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 3ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n\nTesting for epoch 34 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.1307\n16/16 [==============================] - 0s 3ms/step - loss: 5.1310\n16/16 [==============================] - 0s 2ms/step - loss: 5.5242\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n\nTesting for epoch 34 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0048\n16/16 [==============================] - 0s 5ms/step - loss: 5.1453\n16/16 [==============================] - 0s 1ms/step - loss: 5.1456\n16/16 [==============================] - 0s 2ms/step - loss: 5.5352\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 1ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n\nTesting for epoch 34 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.0928\n16/16 [==============================] - 0s 4ms/step - loss: 5.0931\n16/16 [==============================] - 0s 3ms/step - loss: 5.4911\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n\nTesting for epoch 34 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 5.1369\n16/16 [==============================] - 0s 3ms/step - loss: 5.1372\n16/16 [==============================] - 0s 2ms/step - loss: 5.5283\n16/16 [==============================] - 0s 3ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 3ms/step - loss: 5.5294\n\nTesting for epoch 34 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.1408\n16/16 [==============================] - 0s 2ms/step - loss: 5.1411\n16/16 [==============================] - 0s 1ms/step - loss: 5.5335\n16/16 [==============================] - 0s 3ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n\nTesting for epoch 34 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 3ms/step - loss: 5.1474\n16/16 [==============================] - 0s 2ms/step - loss: 5.1477\n16/16 [==============================] - 0s 2ms/step - loss: 5.5387\n16/16 [==============================] - 0s 3ms/step - loss: 5.5398\n16/16 [==============================] - 0s 4ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\n16/16 [==============================] - 0s 1ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1018\n16/16 [==============================] - 0s 2ms/step - loss: 5.1021\n16/16 [==============================] - 0s 2ms/step - loss: 5.4957\n16/16 [==============================] - 0s 3ms/step - loss: 5.4968\n16/16 [==============================] - 0s 2ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n\nTesting for epoch 35 index 2:\n391/391 [==============================] - 0s 988us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1292\n16/16 [==============================] - 0s 2ms/step - loss: 5.1295\n16/16 [==============================] - 0s 2ms/step - loss: 5.5215\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n\nTesting for epoch 35 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 5.2224\n16/16 [==============================] - 0s 3ms/step - loss: 5.2227\n16/16 [==============================] - 0s 5ms/step - loss: 5.6059\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 3ms/step - loss: 5.6070\n16/16 [==============================] - 0s 1ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n\nTesting for epoch 35 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 5.2198\n16/16 [==============================] - 0s 3ms/step - loss: 5.2201\n16/16 [==============================] - 0s 3ms/step - loss: 5.6026\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n\nTesting for epoch 35 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2748\n16/16 [==============================] - 0s 2ms/step - loss: 5.2751\n16/16 [==============================] - 0s 2ms/step - loss: 5.6519\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 1ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n\nTesting for epoch 35 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3099\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.6837\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 3ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 1ms/step - loss: 5.6848\n\nTesting for epoch 35 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0032\n16/16 [==============================] - 0s 3ms/step - loss: 5.2094\n16/16 [==============================] - 0s 1ms/step - loss: 5.2097\n16/16 [==============================] - 0s 1ms/step - loss: 5.5912\n16/16 [==============================] - 0s 3ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n\nTesting for epoch 35 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0033\n16/16 [==============================] - 0s 2ms/step - loss: 5.2987\n16/16 [==============================] - 0s 1ms/step - loss: 5.2989\n16/16 [==============================] - 0s 1ms/step - loss: 5.6727\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n\nTesting for epoch 35 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 5.2803\n16/16 [==============================] - 0s 4ms/step - loss: 5.2806\n16/16 [==============================] - 0s 2ms/step - loss: 5.6550\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n\nTesting for epoch 35 index 10:\n391/391 [==============================] - 0s 969us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3117\n16/16 [==============================] - 0s 3ms/step - loss: 5.3120\n16/16 [==============================] - 0s 2ms/step - loss: 5.6855\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 3ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n\nTesting for epoch 35 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 4ms/step - loss: 5.2815\n16/16 [==============================] - 0s 2ms/step - loss: 5.2818\n16/16 [==============================] - 0s 4ms/step - loss: 5.6609\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 1ms/step - loss: 5.6620\n\nTesting for epoch 35 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 1ms/step - loss: 5.1691\n16/16 [==============================] - 0s 1ms/step - loss: 5.1694\n16/16 [==============================] - 0s 2ms/step - loss: 5.5604\n16/16 [==============================] - 0s 3ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n16/16 [==============================] - 0s 1ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n16/16 [==============================] - 0s 3ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n\nTesting for epoch 35 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1483\n16/16 [==============================] - 0s 3ms/step - loss: 5.1486\n16/16 [==============================] - 0s 1ms/step - loss: 5.5406\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 1ms/step - loss: 5.5417\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 5ms/step - loss: 5.5417\n16/16 [==============================] - 0s 1ms/step - loss: 5.5417\n\nTesting for epoch 35 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 5.1045\n16/16 [==============================] - 0s 2ms/step - loss: 5.1048\n16/16 [==============================] - 0s 1ms/step - loss: 5.5010\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n\nTesting for epoch 35 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 5.1899\n16/16 [==============================] - 0s 2ms/step - loss: 5.1902\n16/16 [==============================] - 0s 1ms/step - loss: 5.5811\n16/16 [==============================] - 0s 4ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n\nTesting for epoch 35 index 16:\n391/391 [==============================] - 0s 987us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.1636\n16/16 [==============================] - 0s 1ms/step - loss: 5.1639\n16/16 [==============================] - 0s 2ms/step - loss: 5.5574\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 3ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n\nTesting for epoch 35 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.0845\n16/16 [==============================] - 0s 4ms/step - loss: 5.0848\n16/16 [==============================] - 0s 2ms/step - loss: 5.4835\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 1ms/step - loss: 5.4846\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 4ms/step - loss: 5.4846\n16/16 [==============================] - 0s 1ms/step - loss: 5.4846\n\nTesting for epoch 35 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.1642\n16/16 [==============================] - 0s 3ms/step - loss: 5.1645\n16/16 [==============================] - 0s 1ms/step - loss: 5.5587\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 1ms/step - loss: 5.5599\n16/16 [==============================] - 0s 1ms/step - loss: 5.5599\n16/16 [==============================] - 0s 3ms/step - loss: 5.5599\n\nTesting for epoch 35 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.2019\n16/16 [==============================] - 0s 2ms/step - loss: 5.2022\n16/16 [==============================] - 0s 2ms/step - loss: 5.5945\n16/16 [==============================] - 0s 4ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n\nTesting for epoch 35 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1390\n16/16 [==============================] - 0s 2ms/step - loss: 5.5356\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n\nTesting for epoch 35 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.2111\n16/16 [==============================] - 0s 2ms/step - loss: 5.2114\n16/16 [==============================] - 0s 2ms/step - loss: 5.6002\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 3ms/step - loss: 5.6014\n\nTesting for epoch 35 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.1603\n16/16 [==============================] - 0s 2ms/step - loss: 5.1606\n16/16 [==============================] - 0s 2ms/step - loss: 5.5549\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n\nTesting for epoch 35 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 5.2077\n16/16 [==============================] - 0s 2ms/step - loss: 5.2080\n16/16 [==============================] - 0s 3ms/step - loss: 5.6009\n16/16 [==============================] - 0s 4ms/step - loss: 5.6021\n16/16 [==============================] - 0s 3ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n\nTesting for epoch 35 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.1479\n16/16 [==============================] - 0s 1ms/step - loss: 5.1481\n16/16 [==============================] - 0s 3ms/step - loss: 5.5449\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 4ms/step - loss: 5.5460\n16/16 [==============================] - 0s 4ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n391/391 [==============================] - 0s 992us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 5.1958\n16/16 [==============================] - 0s 1ms/step - loss: 5.1961\n16/16 [==============================] - 0s 2ms/step - loss: 5.5883\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 1ms/step - loss: 5.5895\n16/16 [==============================] - 0s 3ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n\nTesting for epoch 36 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 5.1905\n16/16 [==============================] - 0s 1ms/step - loss: 5.1907\n16/16 [==============================] - 0s 1ms/step - loss: 5.5819\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 2ms/step - loss: 5.5830\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 3ms/step - loss: 5.5830\n16/16 [==============================] - 0s 2ms/step - loss: 5.5830\n\nTesting for epoch 36 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 5.2484\n16/16 [==============================] - 0s 4ms/step - loss: 5.2486\n16/16 [==============================] - 0s 2ms/step - loss: 5.6346\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 1ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 1ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n\nTesting for epoch 36 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2164\n16/16 [==============================] - 0s 4ms/step - loss: 5.2167\n16/16 [==============================] - 0s 2ms/step - loss: 5.6083\n16/16 [==============================] - 0s 3ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 1ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 3ms/step - loss: 5.6095\n\nTesting for epoch 36 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0034\n16/16 [==============================] - 0s 1ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2340\n16/16 [==============================] - 0s 3ms/step - loss: 5.6202\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 4ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n\nTesting for epoch 36 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 4ms/step - loss: 5.2283\n16/16 [==============================] - 0s 2ms/step - loss: 5.2286\n16/16 [==============================] - 0s 4ms/step - loss: 5.6135\n16/16 [==============================] - 0s 3ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 3ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n\nTesting for epoch 36 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0033\n16/16 [==============================] - 0s 2ms/step - loss: 5.3007\n16/16 [==============================] - 0s 5ms/step - loss: 5.3010\n16/16 [==============================] - 0s 2ms/step - loss: 5.6787\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n\nTesting for epoch 36 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0032\n16/16 [==============================] - 0s 3ms/step - loss: 5.3333\n16/16 [==============================] - 0s 2ms/step - loss: 5.3335\n16/16 [==============================] - 0s 2ms/step - loss: 5.7093\n16/16 [==============================] - 0s 2ms/step - loss: 5.7104\n16/16 [==============================] - 0s 6ms/step - loss: 5.7104\n16/16 [==============================] - 0s 1ms/step - loss: 5.7104\n16/16 [==============================] - 0s 4ms/step - loss: 5.7104\n16/16 [==============================] - 0s 3ms/step - loss: 5.7104\n16/16 [==============================] - 0s 1ms/step - loss: 5.7104\n\nTesting for epoch 36 index 9:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 5.3853\n16/16 [==============================] - 0s 3ms/step - loss: 5.3856\n16/16 [==============================] - 0s 2ms/step - loss: 5.7582\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n\nTesting for epoch 36 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 5.3235\n16/16 [==============================] - 0s 2ms/step - loss: 5.3238\n16/16 [==============================] - 0s 2ms/step - loss: 5.7020\n16/16 [==============================] - 0s 5ms/step - loss: 5.7031\n16/16 [==============================] - 0s 4ms/step - loss: 5.7031\n16/16 [==============================] - 0s 2ms/step - loss: 5.7031\n16/16 [==============================] - 0s 3ms/step - loss: 5.7031\n16/16 [==============================] - 0s 4ms/step - loss: 5.7031\n16/16 [==============================] - 0s 1ms/step - loss: 5.7031\n\nTesting for epoch 36 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.2989\n16/16 [==============================] - 0s 2ms/step - loss: 5.2992\n16/16 [==============================] - 0s 2ms/step - loss: 5.6815\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 2ms/step - loss: 5.6826\n\nTesting for epoch 36 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2041\n16/16 [==============================] - 0s 2ms/step - loss: 5.5978\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 1ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 1ms/step - loss: 5.5989\n\nTesting for epoch 36 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 5.2300\n16/16 [==============================] - 0s 2ms/step - loss: 5.2302\n16/16 [==============================] - 0s 2ms/step - loss: 5.6212\n16/16 [==============================] - 0s 8ms/step - loss: 5.6223\n16/16 [==============================] - 0s 4ms/step - loss: 5.6223\n16/16 [==============================] - 0s 4ms/step - loss: 5.6223\n16/16 [==============================] - 0s 2ms/step - loss: 5.6223\n16/16 [==============================] - 0s 2ms/step - loss: 5.6223\n16/16 [==============================] - 0s 3ms/step - loss: 5.6223\n\nTesting for epoch 36 index 14:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.2473\n16/16 [==============================] - 0s 2ms/step - loss: 5.2476\n16/16 [==============================] - 0s 2ms/step - loss: 5.6383\n16/16 [==============================] - 0s 2ms/step - loss: 5.6394\n16/16 [==============================] - 0s 3ms/step - loss: 5.6394\n16/16 [==============================] - 0s 2ms/step - loss: 5.6394\n16/16 [==============================] - 0s 8ms/step - loss: 5.6394\n16/16 [==============================] - 0s 5ms/step - loss: 5.6394\n16/16 [==============================] - 0s 1ms/step - loss: 5.6394\n\nTesting for epoch 36 index 15:\n391/391 [==============================] - 0s 998us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.1690\n16/16 [==============================] - 0s 1ms/step - loss: 5.1693\n16/16 [==============================] - 0s 2ms/step - loss: 5.5663\n16/16 [==============================] - 0s 4ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 3ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n\nTesting for epoch 36 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 5.1451\n16/16 [==============================] - 0s 2ms/step - loss: 5.1454\n16/16 [==============================] - 0s 2ms/step - loss: 5.5470\n16/16 [==============================] - 0s 3ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 3ms/step - loss: 5.5482\n\nTesting for epoch 36 index 17:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.2356\n16/16 [==============================] - 0s 3ms/step - loss: 5.2359\n16/16 [==============================] - 0s 2ms/step - loss: 5.6304\n16/16 [==============================] - 0s 4ms/step - loss: 5.6315\n16/16 [==============================] - 0s 2ms/step - loss: 5.6315\n16/16 [==============================] - 0s 5ms/step - loss: 5.6315\n16/16 [==============================] - 0s 5ms/step - loss: 5.6315\n16/16 [==============================] - 0s 3ms/step - loss: 5.6315\n16/16 [==============================] - 0s 2ms/step - loss: 5.6315\n\nTesting for epoch 36 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 5.1895\n16/16 [==============================] - 0s 2ms/step - loss: 5.1898\n16/16 [==============================] - 0s 2ms/step - loss: 5.5869\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n16/16 [==============================] - 0s 2ms/step - loss: 5.5880\n16/16 [==============================] - 0s 1ms/step - loss: 5.5880\n16/16 [==============================] - 0s 1ms/step - loss: 5.5880\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n\nTesting for epoch 36 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.1761\n16/16 [==============================] - 0s 2ms/step - loss: 5.1764\n16/16 [==============================] - 0s 2ms/step - loss: 5.5768\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 3ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n\nTesting for epoch 36 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 3ms/step - loss: 5.1661\n16/16 [==============================] - 0s 3ms/step - loss: 5.1664\n16/16 [==============================] - 0s 2ms/step - loss: 5.5653\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 3ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 3ms/step - loss: 5.5665\n\nTesting for epoch 36 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.1874\n16/16 [==============================] - 0s 2ms/step - loss: 5.1877\n16/16 [==============================] - 0s 3ms/step - loss: 5.5857\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 3ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n\nTesting for epoch 36 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2376\n16/16 [==============================] - 0s 2ms/step - loss: 5.6301\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 3ms/step - loss: 5.6312\n16/16 [==============================] - 0s 1ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n\nTesting for epoch 36 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.1576\n16/16 [==============================] - 0s 2ms/step - loss: 5.1579\n16/16 [==============================] - 0s 2ms/step - loss: 5.5571\n16/16 [==============================] - 0s 5ms/step - loss: 5.5582\n16/16 [==============================] - 0s 2ms/step - loss: 5.5582\n16/16 [==============================] - 0s 2ms/step - loss: 5.5582\n16/16 [==============================] - 0s 4ms/step - loss: 5.5582\n16/16 [==============================] - 0s 3ms/step - loss: 5.5582\n16/16 [==============================] - 0s 1ms/step - loss: 5.5582\n\nTesting for epoch 36 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 5.1952\n16/16 [==============================] - 0s 2ms/step - loss: 5.1955\n16/16 [==============================] - 0s 2ms/step - loss: 5.5931\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 1ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.2008\n16/16 [==============================] - 0s 2ms/step - loss: 5.2011\n16/16 [==============================] - 0s 1ms/step - loss: 5.6013\n16/16 [==============================] - 0s 1ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n\nTesting for epoch 37 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.2213\n16/16 [==============================] - 0s 2ms/step - loss: 5.2216\n16/16 [==============================] - 0s 1ms/step - loss: 5.6126\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 3ms/step - loss: 5.6138\n16/16 [==============================] - 0s 3ms/step - loss: 5.6138\n\nTesting for epoch 37 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 5.2441\n16/16 [==============================] - 0s 2ms/step - loss: 5.2444\n16/16 [==============================] - 0s 2ms/step - loss: 5.6347\n16/16 [==============================] - 0s 4ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 1ms/step - loss: 5.6358\n\nTesting for epoch 37 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 5.3030\n16/16 [==============================] - 0s 2ms/step - loss: 5.3032\n16/16 [==============================] - 0s 2ms/step - loss: 5.6918\n16/16 [==============================] - 0s 3ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n\nTesting for epoch 37 index 5:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 5.3149\n16/16 [==============================] - 0s 3ms/step - loss: 5.3152\n16/16 [==============================] - 0s 2ms/step - loss: 5.7013\n16/16 [==============================] - 0s 2ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 4ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 2ms/step - loss: 5.7024\n\nTesting for epoch 37 index 6:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 4ms/step - loss: 5.3506\n16/16 [==============================] - 0s 3ms/step - loss: 5.3509\n16/16 [==============================] - 0s 2ms/step - loss: 5.7317\n16/16 [==============================] - 0s 4ms/step - loss: 5.7328\n16/16 [==============================] - 0s 4ms/step - loss: 5.7328\n16/16 [==============================] - 0s 2ms/step - loss: 5.7328\n16/16 [==============================] - 0s 2ms/step - loss: 5.7328\n16/16 [==============================] - 0s 3ms/step - loss: 5.7328\n16/16 [==============================] - 0s 3ms/step - loss: 5.7328\n\nTesting for epoch 37 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3807\n16/16 [==============================] - 0s 4ms/step - loss: 5.3810\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 4ms/step - loss: 5.7592\n\nTesting for epoch 37 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 5.3407\n16/16 [==============================] - 0s 2ms/step - loss: 5.3410\n16/16 [==============================] - 0s 2ms/step - loss: 5.7210\n16/16 [==============================] - 0s 5ms/step - loss: 5.7221\n16/16 [==============================] - 0s 2ms/step - loss: 5.7221\n16/16 [==============================] - 0s 4ms/step - loss: 5.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.7221\n16/16 [==============================] - 0s 4ms/step - loss: 5.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.7221\n\nTesting for epoch 37 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0032\n16/16 [==============================] - 0s 2ms/step - loss: 5.3797\n16/16 [==============================] - 0s 3ms/step - loss: 5.3799\n16/16 [==============================] - 0s 3ms/step - loss: 5.7570\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 4ms/step - loss: 5.7581\n16/16 [==============================] - 0s 4ms/step - loss: 5.7581\n16/16 [==============================] - 0s 3ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n\nTesting for epoch 37 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.3347\n16/16 [==============================] - 0s 2ms/step - loss: 5.3350\n16/16 [==============================] - 0s 2ms/step - loss: 5.7160\n16/16 [==============================] - 0s 3ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 3ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n\nTesting for epoch 37 index 11:\n391/391 [==============================] - 0s 948us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2534\n16/16 [==============================] - 0s 1ms/step - loss: 5.2537\n16/16 [==============================] - 0s 2ms/step - loss: 5.6468\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 3ms/step - loss: 5.6479\n16/16 [==============================] - 0s 3ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n\nTesting for epoch 37 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 5.2714\n16/16 [==============================] - 0s 2ms/step - loss: 5.2717\n16/16 [==============================] - 0s 4ms/step - loss: 5.6632\n16/16 [==============================] - 0s 1ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n\nTesting for epoch 37 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0047\n16/16 [==============================] - 0s 3ms/step - loss: 5.2741\n16/16 [==============================] - 0s 3ms/step - loss: 5.2744\n16/16 [==============================] - 0s 2ms/step - loss: 5.6662\n16/16 [==============================] - 0s 4ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n16/16 [==============================] - 0s 4ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n16/16 [==============================] - 0s 7ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n\nTesting for epoch 37 index 14:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0050\n16/16 [==============================] - 0s 3ms/step - loss: 5.2619\n16/16 [==============================] - 0s 2ms/step - loss: 5.2622\n16/16 [==============================] - 0s 2ms/step - loss: 5.6577\n16/16 [==============================] - 0s 4ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n\nTesting for epoch 37 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.2003\n16/16 [==============================] - 0s 2ms/step - loss: 5.2006\n16/16 [==============================] - 0s 2ms/step - loss: 5.6010\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n\nTesting for epoch 37 index 16:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.2178\n16/16 [==============================] - 0s 2ms/step - loss: 5.2181\n16/16 [==============================] - 0s 4ms/step - loss: 5.6178\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 2ms/step - loss: 5.6190\n16/16 [==============================] - 0s 2ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n\nTesting for epoch 37 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 5.2434\n16/16 [==============================] - 0s 2ms/step - loss: 5.2437\n16/16 [==============================] - 0s 2ms/step - loss: 5.6415\n16/16 [==============================] - 0s 1ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 5ms/step - loss: 5.6426\n\nTesting for epoch 37 index 18:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 3ms/step - loss: 5.2580\n16/16 [==============================] - 0s 2ms/step - loss: 5.2583\n16/16 [==============================] - 0s 4ms/step - loss: 5.6514\n16/16 [==============================] - 0s 2ms/step - loss: 5.6525\n16/16 [==============================] - 0s 3ms/step - loss: 5.6525\n16/16 [==============================] - 0s 2ms/step - loss: 5.6525\n16/16 [==============================] - 0s 1ms/step - loss: 5.6525\n16/16 [==============================] - 0s 5ms/step - loss: 5.6525\n16/16 [==============================] - 0s 3ms/step - loss: 5.6525\n\nTesting for epoch 37 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 5.1768\n16/16 [==============================] - 0s 3ms/step - loss: 5.1771\n16/16 [==============================] - 0s 2ms/step - loss: 5.5801\n16/16 [==============================] - 0s 5ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 1ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n\nTesting for epoch 37 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0059\n16/16 [==============================] - 0s 1ms/step - loss: 5.2710\n16/16 [==============================] - 0s 3ms/step - loss: 5.2713\n16/16 [==============================] - 0s 4ms/step - loss: 5.6685\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 3ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n\nTesting for epoch 37 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0060\n16/16 [==============================] - 0s 2ms/step - loss: 5.2523\n16/16 [==============================] - 0s 1ms/step - loss: 5.2526\n16/16 [==============================] - 0s 2ms/step - loss: 5.6502\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n\nTesting for epoch 37 index 22:\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows × 19 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n\n\nLSCP(contamination=0.1,\n   detector_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n  metric_params=None, n_jobs=1, n_neighbors=20, novelty=True, p=2), OCSVM(cache_size=200, coef0=0.0, contamination=0.1, degree=3, gamma='auto',\n   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n   verbose=False)],\n   local_max_features=1.0, local_region_size=30, n_bins=3,\n   random_state=RandomState(MT19937) at 0x7F44245B8240)\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'}),\n          pd.DataFrame(outlier_LSCP_one).rename(columns={0:'LSCP'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL',\n                         'LSCP':'LSCP'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n    \n  \n\n12498 rows × 20 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\nfourteen_orbit = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html#result",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html#result",
    "title": "Comparison Results on Real Data",
    "section": "Result",
    "text": "Result\n\n_df_rst = pd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'}),\n          pd.DataFrame(outlier_LSCP_one).rename(columns={0:'LSCP'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL',\n                         'LSCP':'LSCP'})\n\n\n_df_compa = _df_rst.copy()\n\n\ncmp = pd.concat([pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ncmp\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      2010-12-31T16:30:54.520Z\n      0.663\n      -26.045\n      5.5\n    \n    \n      1\n      2010-12-31T04:11:03.180Z\n      -19.209\n      167.902\n      5.1\n    \n    \n      2\n      2010-12-30T23:47:03.930Z\n      -31.830\n      -178.135\n      5.0\n    \n    \n      3\n      2010-12-30T21:22:30.350Z\n      -19.984\n      168.353\n      5.0\n    \n    \n      4\n      2010-12-30T19:56:36.380Z\n      50.380\n      153.964\n      5.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      24099\n      2010-01-01T14:31:10.130Z\n      -22.874\n      69.345\n      5.2\n    \n    \n      24100\n      2010-01-01T09:37:11.290Z\n      42.360\n      -30.462\n      5.0\n    \n    \n      24101\n      2010-01-01T02:34:56.050Z\n      40.726\n      51.925\n      5.0\n    \n    \n      24102\n      2010-01-01T02:22:23.820Z\n      30.646\n      83.791\n      5.2\n    \n    \n      24103\n      2010-01-01T02:08:21.900Z\n      26.290\n      99.866\n      5.0\n    \n  \n\n24104 rows × 4 columns\n\n\n\n\npd.read_csv('outlier_CBLOF_one.csv')\n\n\n_df_compa.to_csv('earthquake_comparison.csv')\n\n\nHaiti\n\n_df_compa[_df_compa['Latitude']==18.443] # Haiti(lat=18.4430, lon=-72.5710)\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      2326\n      18.443\n      -72.571\n      7.0\n      2010.0\n      6.659386\n      0.340614\n      0.116018\n      -1\n      -1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      12429\n      18.443\n      -72.571\n      7.0\n      2010.0\n      6.386632\n      0.613368\n      0.376220\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==18.443]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      2326\n      2010-01-12T21:53:10.060Z\n      18.443\n      -72.571\n      7.0\n    \n    \n      24035\n      2010-01-12T21:53:10.060Z\n      18.443\n      -72.571\n      7.0\n    \n  \n\n\n\n\n\n\nIquique\n\n_df_compa[_df_compa['Latitude']==-32.6953] # Iquiqeu lat=-32.6953, lon=-71.4416\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      2997\n      -32.6953\n      -71.4416\n      6.4\n      2014.0\n      6.088353\n      0.311647\n      0.097124\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==-32.6953]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      14603\n      2014-08-23T22:32:23.320Z\n      -32.6953\n      -71.4416\n      6.4\n    \n  \n\n\n\n\n\n_df_compa[_df_compa['Latitude']==-20.5709] # Iquiqeu lat=-32.6953, lon=-71.4416\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      3723\n      -20.5709\n      -70.4931\n      7.7\n      2014.0\n      6.991148\n      0.708852\n      0.502471\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==-20.5709]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      15329\n      2014-04-03T02:43:13.110Z\n      -20.5709\n      -70.4931\n      7.7\n    \n  \n\n\n\n\n\n\nSichan\n\n_df_compa[_df_compa['Latitude']==30.3080] # sichan(lat=30.3080, lon=102.8880)\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      5137\n      30.308\n      102.888\n      6.6\n      2013.0\n      5.904218\n      0.695782\n      0.484113\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==30.3080]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      16743\n      2013-04-20T00:02:47.540Z\n      30.308\n      102.888\n      6.6\n    \n  \n\n\n\n\n\n_df_compa.sort_values('Anomalious Score',ascending=False).iloc[:50,:].reset_index()\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      ...\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      0\n      2064\n      -36.122000\n      -72.898000\n      8.8\n      2010.0\n      7.572545\n      1.227455\n      1.506646\n      -1\n      -1\n      ...\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      1\n      3752\n      -19.609700\n      -70.769100\n      8.2\n      2014.0\n      7.075499\n      1.124501\n      1.264504\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      2\n      12167\n      -36.122000\n      -72.898000\n      8.8\n      2010.0\n      7.742429\n      1.057571\n      1.118457\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      3\n      9660\n      36.281000\n      141.111000\n      7.9\n      2011.0\n      6.912847\n      0.987153\n      0.974470\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      4\n      6877\n      0.802000\n      92.463000\n      8.2\n      2012.0\n      7.353106\n      0.846894\n      0.717230\n      -1\n      1\n      ...\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      5\n      7938\n      -21.611000\n      -179.528000\n      7.3\n      2011.0\n      6.497713\n      0.802287\n      0.643665\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      6\n      10593\n      -3.487000\n      100.082000\n      7.8\n      2010.0\n      7.008107\n      0.791893\n      0.627095\n      -1\n      -1\n      ...\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      7\n      3835\n      -19.980700\n      -70.702200\n      6.7\n      2014.0\n      5.913563\n      0.786437\n      0.618483\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      8\n      3281\n      -29.977200\n      -177.724700\n      6.9\n      2014.0\n      6.129969\n      0.770031\n      0.592947\n      -1\n      1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      1\n    \n    \n      9\n      4997\n      -23.009000\n      -177.232000\n      7.4\n      2013.0\n      6.648946\n      0.751054\n      0.564082\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      10\n      11365\n      7.881000\n      91.936000\n      7.5\n      2010.0\n      6.759298\n      0.740702\n      0.548640\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      11\n      3723\n      -20.570900\n      -70.493100\n      7.7\n      2014.0\n      6.991148\n      0.708852\n      0.502471\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      12\n      490\n      -3.487000\n      100.082000\n      7.8\n      2010.0\n      7.092844\n      0.707156\n      0.500069\n      -1\n      -1\n      ...\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      13\n      11856\n      -34.290000\n      -71.891000\n      6.9\n      2010.0\n      6.197441\n      0.702559\n      0.493590\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      14\n      6443\n      -21.222000\n      -179.287000\n      5.6\n      2012.0\n      4.900729\n      0.699271\n      0.488980\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      15\n      9598\n      36.569000\n      141.486000\n      6.2\n      2011.0\n      5.502811\n      0.697189\n      0.486072\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      16\n      5137\n      30.308000\n      102.888000\n      6.6\n      2013.0\n      5.904218\n      0.695782\n      0.484113\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      17\n      7772\n      -28.993000\n      -176.238000\n      7.4\n      2011.0\n      6.711309\n      0.688691\n      0.474295\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      18\n      4881\n      10.701000\n      -42.594000\n      6.6\n      2013.0\n      5.915735\n      0.684265\n      0.468219\n      -1\n      -1\n      ...\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      1\n    \n    \n      19\n      4330\n      39.306700\n      142.095400\n      5.0\n      2013.0\n      5.682094\n      -0.682094\n      0.465252\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      20\n      7768\n      -55.261000\n      -28.106000\n      5.0\n      2011.0\n      5.680237\n      -0.680237\n      0.462723\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      21\n      6940\n      -35.200000\n      -72.217000\n      7.1\n      2012.0\n      6.422078\n      0.677922\n      0.459578\n      -1\n      1\n      ...\n      1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      22\n      4816\n      -60.857000\n      -25.070000\n      7.3\n      2013.0\n      6.626735\n      0.673265\n      0.453286\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      23\n      6963\n      16.493000\n      -98.231000\n      7.4\n      2012.0\n      6.727272\n      0.672728\n      0.452563\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      24\n      8207\n      36.942000\n      140.955000\n      6.3\n      2011.0\n      5.644833\n      0.655167\n      0.429243\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      25\n      2670\n      -23.393700\n      -179.852400\n      5.0\n      2014.0\n      5.647693\n      -0.647693\n      0.419507\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      26\n      9675\n      38.297000\n      142.373000\n      9.1\n      2011.0\n      8.452726\n      0.647274\n      0.418963\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      27\n      163\n      26.901000\n      143.698000\n      7.4\n      2010.0\n      6.758782\n      0.641218\n      0.411160\n      -1\n      1\n      ...\n      -1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      28\n      7365\n      -10.617000\n      165.160000\n      6.4\n      2012.0\n      5.760128\n      0.639872\n      0.409436\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      29\n      19\n      -19.661000\n      168.140000\n      6.4\n      2010.0\n      5.761124\n      0.638876\n      0.408163\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      30\n      7739\n      -17.941000\n      -179.531000\n      6.0\n      2011.0\n      5.361437\n      0.638563\n      0.407763\n      -1\n      -1\n      ...\n      1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      31\n      8787\n      -20.129000\n      168.257000\n      5.3\n      2011.0\n      4.674700\n      0.625300\n      0.391000\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      32\n      5447\n      -10.994000\n      165.741000\n      6.6\n      2013.0\n      5.975600\n      0.624400\n      0.389875\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      33\n      8094\n      -18.365000\n      168.143000\n      7.2\n      2011.0\n      6.578651\n      0.621349\n      0.386075\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      34\n      2699\n      -19.690300\n      -177.758700\n      7.1\n      2014.0\n      6.485400\n      0.614600\n      0.377733\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      35\n      1751\n      -34.326000\n      -71.799000\n      7.0\n      2010.0\n      6.386349\n      0.613651\n      0.376567\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      36\n      12429\n      18.443000\n      -72.571000\n      7.0\n      2010.0\n      6.386632\n      0.613368\n      0.376220\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      37\n      6307\n      2.190000\n      126.837000\n      6.6\n      2012.0\n      5.993919\n      0.606081\n      0.367334\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      38\n      9366\n      40.082000\n      143.202000\n      5.7\n      2011.0\n      5.096812\n      0.603188\n      0.363836\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      39\n      9867\n      -7.154000\n      155.184000\n      6.4\n      2011.0\n      5.798634\n      0.601366\n      0.361641\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      40\n      581\n      29.715000\n      69.587000\n      5.2\n      2010.0\n      5.794321\n      -0.594321\n      0.353217\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      41\n      1753\n      -34.290000\n      -71.891000\n      6.9\n      2010.0\n      6.310787\n      0.589213\n      0.347172\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      42\n      9050\n      -16.541000\n      -177.517000\n      6.3\n      2011.0\n      5.717719\n      0.582281\n      0.339052\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      43\n      11823\n      -37.551000\n      -73.465000\n      5.8\n      2010.0\n      5.219236\n      0.580764\n      0.337287\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      44\n      11689\n      32.286167\n      -115.295333\n      7.2\n      2010.0\n      6.620076\n      0.579924\n      0.336312\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      45\n      1439\n      -23.067000\n      169.426000\n      5.0\n      2010.0\n      5.579354\n      -0.579354\n      0.335651\n      -1\n      1\n      ...\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      46\n      8456\n      36.261000\n      137.679000\n      5.0\n      2011.0\n      5.576525\n      -0.576525\n      0.332381\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      47\n      3164\n      37.005200\n      142.452500\n      6.5\n      2014.0\n      5.923529\n      0.576471\n      0.332319\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      48\n      6349\n      35.661000\n      82.518000\n      6.2\n      2012.0\n      5.623699\n      0.576301\n      0.332123\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      49\n      11803\n      -35.802000\n      -73.158000\n      6.2\n      2010.0\n      5.624964\n      0.575036\n      0.330667\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n50 rows × 21 columns"
  },
  {
    "objectID": "posts/GODE/2022-12-27-DFT_study.html",
    "href": "posts/GODE/2022-12-27-DFT_study.html",
    "title": "Discrete Fourier Transform",
    "section": "",
    "text": "DFT\nhttps://miruetoto.quarto.pub/yechan/posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#fnref1\nhttps://miruetoto.github.io/yechan/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88/2019/11/24/(%EB%85%B8%ED%8A%B8)-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%EC%B6%94%EB%A1%A0-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88.html"
  },
  {
    "objectID": "posts/GODE/2022-12-27-DFT_study.html#import",
    "href": "posts/GODE/2022-12-27-DFT_study.html#import",
    "title": "Discrete Fourier Transform",
    "section": "import",
    "text": "import\n\nimport numpy as np\n\n\nForward operator A\n\nA = np.array([[0, 0, 0, 0, 1],\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 0, 1, 0]])\nA\n\narray([[0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0]])\n\n\n\nnp.transpose(A)@A\n\narray([[1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 1]])\n\n\n\nnote: A is orthogonal matrix\n\n\ns = np.array([[1],[22],[333],[4444],[55555]])\ns\n\narray([[    1],\n       [   22],\n       [  333],\n       [ 4444],\n       [55555]])\n\n\n\nA@s\n\narray([[55555],\n       [    1],\n       [   22],\n       [  333],\n       [ 4444]])\n\n\n\nA@A@s\n\narray([[ 4444],\n       [55555],\n       [    1],\n       [   22],\n       [  333]])\n\n\n\nA@A@A@s\n\narray([[  333],\n       [ 4444],\n       [55555],\n       [    1],\n       [   22]])\n\n\n\nnote : thus A is a forward operator,A* is a backward operator.\n\n\n\nDFT\n\\(A = DFT^* \\Lambda DFT\\)\n\nλ, ψ = np.linalg.eig(A)\nλ, ψ\n\n(array([-0.80901699+0.58778525j, -0.80901699-0.58778525j,\n         0.30901699+0.95105652j,  0.30901699-0.95105652j,\n         1.        +0.j        ]),\n array([[-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n         -0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.4472136+0.j        ],\n        [ 0.4472136+0.j        ,  0.4472136-0.j        ,\n         -0.3618034+0.26286556j, -0.3618034-0.26286556j,\n          0.4472136+0.j        ],\n        [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.1381966+0.4253254j ,  0.1381966-0.4253254j ,\n          0.4472136+0.j        ],\n        [ 0.1381966+0.4253254j ,  0.1381966-0.4253254j ,\n          0.4472136+0.j        ,  0.4472136-0.j        ,\n          0.4472136+0.j        ],\n        [ 0.1381966-0.4253254j ,  0.1381966+0.4253254j ,\n          0.1381966-0.4253254j ,  0.1381966+0.4253254j ,\n          0.4472136+0.j        ]]))\n\n\n\nλ.shape, ψ.shape\n\n((5,), (5, 5))\n\n\n\nA \n\narray([[0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0]])\n\n\n\n(ψ @ np.diag(λ) @ ψ.transpose()).round(2)\n\narray([[-0.  +0.j,  0.45+0.j,  0.28+0.j,  0.72+0.j, -0.45+0.j],\n       [ 0.45+0.j,  0.28+0.j,  0.72+0.j, -0.45+0.j, -0.  +0.j],\n       [ 0.28+0.j,  0.72+0.j, -0.45+0.j,  0.  +0.j,  0.45+0.j],\n       [ 0.72+0.j, -0.45+0.j,  0.  +0.j,  0.45+0.j,  0.28+0.j],\n       [-0.45+0.j, -0.  +0.j,  0.45+0.j,  0.28+0.j,  0.72+0.j]])\n\n\n?\ndefine \\(\\psi^* = DFT\\)\n\nDFT = np.transpose(ψ)\nDFT\n\narray([[-0.3618034+0.26286556j,  0.4472136+0.j        ,\n        -0.3618034-0.26286556j,  0.1381966+0.4253254j ,\n         0.1381966-0.4253254j ],\n       [-0.3618034-0.26286556j,  0.4472136-0.j        ,\n        -0.3618034+0.26286556j,  0.1381966-0.4253254j ,\n         0.1381966+0.4253254j ],\n       [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n         0.1381966+0.4253254j ,  0.4472136+0.j        ,\n         0.1381966-0.4253254j ],\n       [-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n         0.1381966-0.4253254j ,  0.4472136-0.j        ,\n         0.1381966+0.4253254j ],\n       [ 0.4472136+0.j        ,  0.4472136+0.j        ,\n         0.4472136+0.j        ,  0.4472136+0.j        ,\n         0.4472136+0.j        ]])\n\n\n\nλ[3,]\n\n(0.30901699437494734-0.9510565162951535j)\n\n\n\na=np.array([1,2,3,4])\nnp.diag(np.diag(a))\n\narray([1, 2, 3, 4])\n\n\n\nλ\n\narray([-0.80901699+0.58778525j, -0.80901699-0.58778525j,\n        0.30901699+0.95105652j,  0.30901699-0.95105652j,\n        1.        +0.j        ])\n\n\n\n(np.matrix(ψ)@np.matrix(np.diag(λ))@np.matrix(ψ).H).round(3)\n\nmatrix([[-0.+0.j,  0.+0.j, -0.+0.j,  0.+0.j,  1.+0.j],\n        [ 1.+0.j, -0.+0.j,  0.+0.j, -0.+0.j, -0.+0.j],\n        [-0.+0.j,  1.+0.j, -0.+0.j,  0.+0.j,  0.+0.j],\n        [ 0.+0.j, -0.+0.j,  1.+0.j,  0.+0.j, -0.+0.j],\n        [-0.+0.j, -0.+0.j,  0.+0.j,  1.+0.j, -0.+0.j]])\n\n\n\nnp.matrix(ψ).H\n\nmatrix([[-0.3618034-0.26286556j,  0.4472136-0.j        ,\n         -0.3618034+0.26286556j,  0.1381966-0.4253254j ,\n          0.1381966+0.4253254j ],\n        [-0.3618034+0.26286556j,  0.4472136+0.j        ,\n         -0.3618034-0.26286556j,  0.1381966+0.4253254j ,\n          0.1381966-0.4253254j ],\n        [-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n          0.1381966-0.4253254j ,  0.4472136-0.j        ,\n          0.1381966+0.4253254j ],\n        [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.1381966+0.4253254j ,  0.4472136+0.j        ,\n          0.1381966-0.4253254j ],\n        [ 0.4472136-0.j        ,  0.4472136-0.j        ,\n          0.4472136-0.j        ,  0.4472136-0.j        ,\n          0.4472136-0.j        ]])\n\n\n\n\nSpectral components and Frequencies\n\\[\\{ 1,\\psi_1, \\psi_2, \\psi_3,\\dots, \\psi_{N-1} \\}\\]\nThese vectors are called spectral components.\nIn Physics and in operator theory, these eigenvalues are the frequencies of the signal.\nEigenvalues of \\(A\\)"
  },
  {
    "objectID": "posts/GODE/Untitled.html",
    "href": "posts/GODE/Untitled.html",
    "title": "Seoyeon's Blog for study",
    "section": "",
    "text": "import numpy as np\n\n\na=10\nb=20\nn=200\n\n\narr1 = np.array([a+(b-a)/(n-1) * (i-1) for i in range(1,n+1)])\n\n\\[a+\\frac{(b-a)i}{n-1}\\] for \\(i=1,2,3,\\dots, n\\)\n\narr2 = np.linspace(a,b,n)\n\n\narr1[:5]\n\narray([10.        , 10.05025126, 10.10050251, 10.15075377, 10.20100503])\n\n\n\narr2[:5]\n\narray([10.        , 10.05025126, 10.10050251, 10.15075377, 10.20100503])"
  },
  {
    "objectID": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html",
    "href": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html",
    "title": "Linear Graph code for Paper",
    "section": "",
    "text": "None\n%%R set.seed(1) epsilon = rnorm(1000) signal = sample(c(runif(25,-7,-2.5), runif(25,2.5,7), rep(0,950))) index_of_trueoutlier = which(signal!=0) index_of_trueoutlier_bool = signal!=0\nx=signal+epsilon plot(1:1000,x) points(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)"
  },
  {
    "objectID": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html#linear1",
    "href": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html#linear1",
    "title": "Linear Graph code for Paper",
    "section": "Linear(1)",
    "text": "Linear(1)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5,ref=20,ymin=-5,ymax=20,cuts=0,cutf=995): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color 표현은 위핸 표준화\n        self.df = self.df.assign(differ = self.differ)\n        \n        fig,ax = plt.subplots(figsize=(10,10))\n        ax.scatter(self.x,self.y,color='gray',s=50,alpha=0.7)\n        ax.scatter(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],color='red',s=50)\n        ax.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], '--k',lw=3)\n        ax.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=550,facecolors='none', edgecolors='r')\n        fig.tight_layout()\n        fig.savefig('fig1.eps',format='eps')\n\n\n_simul = SIMUL(df1)\n\n\n_simul.fit(sd=20,ref=9.8)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n\n\n\n\n\n\noutlier_simul_one = (_simul.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 9.8 else 1,outlier_simul_one))\n\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\n_signal = list(map(lambda x: -1 if x!=0 else 1,signal))\n\n\n_conf = Conf_matrx(_signal,outlier_simul_one,tab_linear)\n\n\nfrom sklearn.metrics import confusion_matrix\n\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\n\n\n\n\n\n\n\n\n\n## Linear(2)\n\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul2 = SIMUL(df2)\n\n\n_simul2.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\n\n## COS\n\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul4 = SIMUL(df4)\n\n\n_simul4.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\n\n## SIN\n\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul5 = SIMUL(df5)\n\n\n_simul5.fit(ref=15,ymin=-10,ymax=15,cuts=5)\n\n\n## 1D manifold\n\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n#         fig = plt.figure(figsize=(10,10))\n        # ax = fig.add_subplot(1,1,1, projection='3d')\n        #\n        fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,15),subplot_kw={\"projection\":\"3d\"})\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax1.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red')\n        ax1.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax1.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=60)\n        \n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax2.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax2.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax2.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=40)\n        \n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax3.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax3.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax3.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax3.view_init(elev=30., azim=10)\n        \n        fig.savefig('fig2.eps',format='eps')\n\n\n_simul3d = SIMUL(df)\n\n\n_simul3d.get_distance()\n\n\n_simul3d.get_weightmatrix(theta=(_simul3d.D[_simul3d.D>0].mean()),kappa=2500) \n\n\n(_simul3d.D[_simul3d.D>0].mean())\n\n\n%%capture --no-display\n_simul3d.fit(sd=15,ref=20)\n\n\n## Bunny\n\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) # 꼬리부분의 빨간신호를 퍼지게하는 정도\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\n\n\nindex_of_trueoutlier_bool = (unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n\nW = G.W.toarray()\nx = G.coords[:,0]\ny = G.coords[:,1]\nz = -G.coords[:,2]\n\n\ndf = pd.DataFrame({'x' : x, 'y' : y, 'z' : z, 'f' : f, 'noise' : noise})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=2.5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig = plt.figure(figsize=(30,12),dpi=400)\n        ax1 = fig.add_subplot(251, projection='3d')\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax1.view_init(elev=60., azim=-90)\n\n        ax2= fig.add_subplot(252, projection='3d')\n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax2.view_init(elev=60., azim=-90)\n\n        ax3= fig.add_subplot(253, projection='3d')\n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax3.view_init(elev=60., azim=-90)\n        \n        ax4= fig.add_subplot(254, projection='3d')\n        ax4.grid(False)\n        ax4.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax4.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax4.view_init(elev=60., azim=-90)\n\n        ax5= fig.add_subplot(255, projection='3d')\n        ax5.grid(False)\n        ax5.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax5.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax5.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax5.view_init(elev=60., azim=-90)\n        \n        ax6 = fig.add_subplot(256, projection='3d')\n        ax6.grid(False)\n        ax6.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax6.view_init(elev=-60., azim=-90)\n\n        ax7= fig.add_subplot(257, projection='3d')\n        ax7.grid(False)\n        ax7.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax7.view_init(elev=-60., azim=-90)\n\n        ax8= fig.add_subplot(258, projection='3d')\n        ax8.grid(False)\n        ax8.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax8.view_init(elev=-60., azim=-90)\n        \n        ax9= fig.add_subplot(259, projection='3d')\n        ax9.grid(False)\n        ax9.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax9.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax9.view_init(elev=-60., azim=-90)\n\n        ax10= fig.add_subplot(2,5,10, projection='3d')\n        ax10.grid(False)\n        ax10.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax10.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax10.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax10.view_init(elev=-60., azim=-90)        \n        fig.savefig('fig_bunny.eps',format='eps')\n\n\n_simul = SIMUL(df)\n\n\nmax(_simul.f),max(_simul.fnoise)\n\n\nmin(_simul.f),min(_simul.fnoise)\n\n\n%%capture --no-display\n_simul.fit(sd=20,ref=10)\n\n\n## Earthquake\n\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\n\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh 기능추가\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n\n`-` get distance \n\n\neach_location.get_distance()\n\n\neach_location.D[each_location.D>0].mean()\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n\n`-` weight matrix\n\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n\n`-` fit\n\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig = each_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig.write_image('fig_haiti.png',scale=3)\n\n\neach_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_lquique.svg',scale=3)\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_sichuan.svg',scale=3)"
  },
  {
    "objectID": "posts/RESEARCHES/index.html",
    "href": "posts/RESEARCHES/index.html",
    "title": "RESEARCHES",
    "section": "",
    "text": "About RESEARCHES"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html",
    "title": "Stock on Graph",
    "section": "",
    "text": "import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\nimport plotly.graph_objects as go\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#korea",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#korea",
    "title": "Stock on Graph",
    "section": "Korea",
    "text": "Korea\n\ndf_korea = pd.read_csv('./dataset/korea_kospi.csv')\n\n\ndf_korea = pd.concat([df_korea,pd.DataFrame({'Country': \"Korea\",\n                                             'Value':(df_korea['Close'] - df_korea['Close'].mean())/df_korea['Close'].std()})],axis=1)\n\n\ndf_korea_add = df_korea.assign(Year = list(map(lambda x: x.split('-')[0],df_korea['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_korea['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_korea['Date'])))\n\n\ndf_korea_add.Year = df_korea_add.Year.astype(np.float64)\ndf_korea_add.Mon = df_korea_add.Mon.astype(np.float64)\ndf_korea_add.Day = df_korea_add.Day.astype(np.float64)\n\n\ndf_korea_covid = df_korea_add.query(\"Year>=2020 and Year <= 2022\");df_korea_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      364\n      2020-01-02\n      2201.209961\n      2202.320068\n      2171.840088\n      2175.169922\n      2175.169922\n      494700\n      Korea\n      -0.719054\n      2020.0\n      1.0\n      2.0\n    \n    \n      365\n      2020-01-03\n      2192.580078\n      2203.379883\n      2165.389893\n      2176.459961\n      2176.459961\n      631600\n      Korea\n      -0.715806\n      2020.0\n      1.0\n      3.0\n    \n    \n      366\n      2020-01-06\n      2154.969971\n      2164.419922\n      2149.949951\n      2155.070068\n      2155.070068\n      592700\n      Korea\n      -0.769651\n      2020.0\n      1.0\n      6.0\n    \n    \n      367\n      2020-01-07\n      2166.600098\n      2181.620117\n      2164.270020\n      2175.540039\n      2175.540039\n      568200\n      Korea\n      -0.718122\n      2020.0\n      1.0\n      7.0\n    \n    \n      368\n      2020-01-08\n      2156.270020\n      2162.320068\n      2137.719971\n      2151.310059\n      2151.310059\n      913800\n      Korea\n      -0.779116\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1099\n      2022-12-23\n      2325.860107\n      2333.080078\n      2311.899902\n      2313.689941\n      2313.689941\n      367000\n      Korea\n      -0.370356\n      2022.0\n      12.0\n      23.0\n    \n    \n      1100\n      2022-12-26\n      2312.540039\n      2321.919922\n      2304.199951\n      2317.139893\n      2317.139893\n      427600\n      Korea\n      -0.361672\n      2022.0\n      12.0\n      26.0\n    \n    \n      1101\n      2022-12-27\n      2327.520020\n      2335.989990\n      2321.479980\n      2332.790039\n      2332.790039\n      448300\n      Korea\n      -0.322276\n      2022.0\n      12.0\n      27.0\n    \n    \n      1102\n      2022-12-28\n      2296.449951\n      2296.449951\n      2276.899902\n      2280.449951\n      2280.449951\n      405700\n      Korea\n      -0.454032\n      2022.0\n      12.0\n      28.0\n    \n    \n      1103\n      2022-12-29\n      2265.729980\n      2272.669922\n      2236.379883\n      2236.399902\n      2236.399902\n      361000\n      Korea\n      -0.564919\n      2022.0\n      12.0\n      29.0\n    \n  \n\n740 rows × 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('Korea (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_korea_covid['Date'], df_korea_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#us",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#us",
    "title": "Stock on Graph",
    "section": "US",
    "text": "US\n\ndf_us = pd.read_csv('./dataset/us_nasdaq.csv')\n\n\ndf_us = pd.concat([df_us,pd.DataFrame({'Country': 'United States of America',\n                                             'Value':(df_us['Close'] - df_us['Close'].mean())/df_us['Close'].std()})],axis=1)\n\n\ndf_us_add = df_us.assign(Year = list(map(lambda x: x.split('-')[0],df_us['Date'])),\\\n                            Mon = list(map(lambda x: x.split('-')[1],df_us['Date'])),\\\n                            Day = list(map(lambda x: x.split('-')[2],df_us['Date'])))\n\n\ndf_us_add.Year = df_us_add.Year.astype(np.float64)\ndf_us_add.Mon = df_us_add.Mon.astype(np.float64)\ndf_us_add.Day = df_us_add.Day.astype(np.float64)\n\n\ndf_us_covid = df_us_add.query(\"Year>=2020 and Year <=2022\");df_us_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      374\n      2020-01-02\n      9039.459961\n      9093.429688\n      9010.889648\n      9092.190430\n      9092.190430\n      2862700000\n      United States of America\n      -0.695392\n      2020.0\n      1.0\n      2.0\n    \n    \n      375\n      2020-01-03\n      8976.429688\n      9065.759766\n      8976.429688\n      9020.769531\n      9020.769531\n      2586520000\n      United States of America\n      -0.722486\n      2020.0\n      1.0\n      3.0\n    \n    \n      376\n      2020-01-06\n      8943.500000\n      9072.410156\n      8943.500000\n      9071.469727\n      9071.469727\n      2810450000\n      United States of America\n      -0.703253\n      2020.0\n      1.0\n      6.0\n    \n    \n      377\n      2020-01-07\n      9076.639648\n      9091.929688\n      9042.549805\n      9068.580078\n      9068.580078\n      2381740000\n      United States of America\n      -0.704349\n      2020.0\n      1.0\n      7.0\n    \n    \n      378\n      2020-01-08\n      9068.030273\n      9168.889648\n      9059.379883\n      9129.240234\n      9129.240234\n      2472620000\n      United States of America\n      -0.681336\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1125\n      2022-12-23\n      10437.750000\n      10514.759766\n      10361.820313\n      10497.860352\n      10497.860352\n      3544680000\n      United States of America\n      -0.162131\n      2022.0\n      12.0\n      23.0\n    \n    \n      1126\n      2022-12-27\n      10462.190430\n      10472.320313\n      10340.730469\n      10353.230469\n      10353.230469\n      3827290000\n      United States of America\n      -0.216999\n      2022.0\n      12.0\n      27.0\n    \n    \n      1127\n      2022-12-28\n      10339.200195\n      10414.820313\n      10207.469727\n      10213.290039\n      10213.290039\n      3842970000\n      United States of America\n      -0.270087\n      2022.0\n      12.0\n      28.0\n    \n    \n      1128\n      2022-12-29\n      10321.459961\n      10502.080078\n      10301.059570\n      10478.089844\n      10478.089844\n      4154100000\n      United States of America\n      -0.169631\n      2022.0\n      12.0\n      29.0\n    \n    \n      1129\n      2022-12-30\n      10368.370117\n      10468.309570\n      10324.700195\n      10466.480469\n      10466.480469\n      3959030000\n      United States of America\n      -0.174036\n      2022.0\n      12.0\n      30.0\n    \n  \n\n756 rows × 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('US (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_us_covid['Date'], df_us_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#china",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#china",
    "title": "Stock on Graph",
    "section": "China",
    "text": "China\n\ndf_china = pd.read_csv('./dataset/china_ssec.csv')\n\n\ndf_china = pd.concat([df_china,pd.DataFrame({'Country': 'China',\n                                             'Value':(df_china['Close'] - df_china['Close'].mean())/df_china['Close'].std()})],axis=1)\n\n\ndf_china_add = df_china.assign(Year = list(map(lambda x: x.split('-')[0],df_china['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_china['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_china['Date'])))\n\n\ndf_china_add.Year = df_china_add.Year.astype(np.float64)\ndf_china_add.Mon = df_china_add.Mon.astype(np.float64)\ndf_china_add.Day = df_china_add.Day.astype(np.float64)\n\n\ndf_china_covid = df_china_add.query(\"Year>=2020 and Year <=2022\");df_china_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      361\n      2020-01-02\n      3066.335938\n      3098.100098\n      3066.335938\n      3085.197998\n      3085.197998\n      292500\n      China\n      -0.244680\n      2020.0\n      1.0\n      2.0\n    \n    \n      362\n      2020-01-03\n      3089.021973\n      3093.819092\n      3074.518066\n      3083.785889\n      3083.785889\n      261500\n      China\n      -0.249433\n      2020.0\n      1.0\n      3.0\n    \n    \n      363\n      2020-01-06\n      3070.908936\n      3107.202881\n      3065.309082\n      3083.407959\n      3083.407959\n      312600\n      China\n      -0.250705\n      2020.0\n      1.0\n      6.0\n    \n    \n      364\n      2020-01-07\n      3085.488037\n      3105.450928\n      3084.329102\n      3104.802002\n      3104.802002\n      276600\n      China\n      -0.178700\n      2020.0\n      1.0\n      7.0\n    \n    \n      365\n      2020-01-08\n      3094.239014\n      3094.239014\n      3059.131104\n      3066.893066\n      3066.893066\n      297900\n      China\n      -0.306289\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1084\n      2022-12-26\n      3048.196045\n      3071.835938\n      3047.349121\n      3065.562988\n      3065.562988\n      206500\n      China\n      -0.310766\n      2022.0\n      12.0\n      26.0\n    \n    \n      1085\n      2022-12-27\n      3077.750000\n      3098.080078\n      3074.310059\n      3095.570068\n      3095.570068\n      222200\n      China\n      -0.209771\n      2022.0\n      12.0\n      27.0\n    \n    \n      1086\n      2022-12-28\n      3088.620117\n      3098.649902\n      3079.429932\n      3087.399902\n      3087.399902\n      224600\n      China\n      -0.237270\n      2022.0\n      12.0\n      28.0\n    \n    \n      1087\n      2022-12-29\n      3076.729980\n      3086.000000\n      3064.459961\n      3073.699951\n      3073.699951\n      215600\n      China\n      -0.283379\n      2022.0\n      12.0\n      29.0\n    \n    \n      1088\n      2022-12-30\n      3084.520020\n      3096.310059\n      3082.199951\n      3089.260010\n      3089.260010\n      217500\n      China\n      -0.231009\n      2022.0\n      12.0\n      30.0\n    \n  \n\n728 rows × 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('China (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_china_covid['Date'], df_china_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#japan",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#japan",
    "title": "Stock on Graph",
    "section": "Japan",
    "text": "Japan\n\ndf_japan = pd.read_csv('./dataset/japan_n225.csv')\n\n\ndf_japan = pd.concat([df_japan,pd.DataFrame({'Country': 'Japan',\n                                             'Value':(df_japan['Close'] - df_japan['Close'].mean())/df_japan['Close'].std()})],axis=1)\n\n\ndf_japan_add = df_japan.assign(Year = list(map(lambda x: x.split('-')[0],df_japan['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_japan['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_japan['Date'])))\n\n\ndf_japan_add.Year = df_japan_add.Year.astype(np.float64)\ndf_japan_add.Mon = df_japan_add.Mon.astype(np.float64)\ndf_japan_add.Day = df_japan_add.Day.astype(np.float64)\n\n\ndf_japan_covid = df_japan_add.query(\"Year>=2020 and Year<=2022\");df_japan_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      367\n      2020-01-06\n      23319.759766\n      23365.359375\n      23148.529297\n      23204.859375\n      23204.859375\n      72800000.0\n      Japan\n      -0.604658\n      2020.0\n      1.0\n      6.0\n    \n    \n      368\n      2020-01-07\n      23320.119141\n      23577.439453\n      23299.919922\n      23575.720703\n      23575.720703\n      64300000.0\n      Japan\n      -0.496240\n      2020.0\n      1.0\n      7.0\n    \n    \n      369\n      2020-01-08\n      23217.490234\n      23303.210938\n      22951.179688\n      23204.759766\n      23204.759766\n      79400000.0\n      Japan\n      -0.604687\n      2020.0\n      1.0\n      8.0\n    \n    \n      370\n      2020-01-09\n      23530.289063\n      23767.089844\n      23506.150391\n      23739.869141\n      23739.869141\n      62200000.0\n      Japan\n      -0.448252\n      2020.0\n      1.0\n      9.0\n    \n    \n      371\n      2020-01-10\n      23813.279297\n      23903.289063\n      23761.080078\n      23850.570313\n      23850.570313\n      55900000.0\n      Japan\n      -0.415890\n      2020.0\n      1.0\n      10.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1093\n      2022-12-26\n      26299.539063\n      26438.650391\n      26294.849609\n      26405.869141\n      26405.869141\n      47300000.0\n      Japan\n      0.331131\n      2022.0\n      12.0\n      26.0\n    \n    \n      1094\n      2022-12-27\n      26570.779297\n      26620.490234\n      26447.869141\n      26447.869141\n      26447.869141\n      50200000.0\n      Japan\n      0.343410\n      2022.0\n      12.0\n      27.0\n    \n    \n      1095\n      2022-12-28\n      26309.339844\n      26354.269531\n      26199.669922\n      26340.500000\n      26340.500000\n      61500000.0\n      Japan\n      0.312021\n      2022.0\n      12.0\n      28.0\n    \n    \n      1096\n      2022-12-29\n      26074.900391\n      26126.699219\n      25953.919922\n      26093.669922\n      26093.669922\n      63100000.0\n      Japan\n      0.239862\n      2022.0\n      12.0\n      29.0\n    \n    \n      1097\n      2022-12-30\n      26288.000000\n      26321.369141\n      26067.919922\n      26094.500000\n      26094.500000\n      52700000.0\n      Japan\n      0.240105\n      2022.0\n      12.0\n      30.0\n    \n  \n\n731 rows × 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('Japan (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_japan_covid['Date'], df_japan_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(30,15))\n#     ax1.plot(df_korea_covid['Date'], df_korea_covid['Close'])\n#     ax2.plot(df_us_covid['Date'], df_us_covid['Close'])\n#     ax3.plot(df_china_covid['Date'], df_china_covid['Close'])\n#     ax4.plot(df_japan_covid['Date'], df_japan_covid['Close'])\n\n\ndf = pd.concat([df_korea_covid,df_us_covid,df_china_covid,df_japan_covid]);df\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      364\n      2020-01-02\n      2201.209961\n      2202.320068\n      2171.840088\n      2175.169922\n      2175.169922\n      494700.0\n      Korea\n      -0.719054\n      2020.0\n      1.0\n      2.0\n    \n    \n      365\n      2020-01-03\n      2192.580078\n      2203.379883\n      2165.389893\n      2176.459961\n      2176.459961\n      631600.0\n      Korea\n      -0.715806\n      2020.0\n      1.0\n      3.0\n    \n    \n      366\n      2020-01-06\n      2154.969971\n      2164.419922\n      2149.949951\n      2155.070068\n      2155.070068\n      592700.0\n      Korea\n      -0.769651\n      2020.0\n      1.0\n      6.0\n    \n    \n      367\n      2020-01-07\n      2166.600098\n      2181.620117\n      2164.270020\n      2175.540039\n      2175.540039\n      568200.0\n      Korea\n      -0.718122\n      2020.0\n      1.0\n      7.0\n    \n    \n      368\n      2020-01-08\n      2156.270020\n      2162.320068\n      2137.719971\n      2151.310059\n      2151.310059\n      913800.0\n      Korea\n      -0.779116\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1093\n      2022-12-26\n      26299.539063\n      26438.650391\n      26294.849609\n      26405.869141\n      26405.869141\n      47300000.0\n      Japan\n      0.331131\n      2022.0\n      12.0\n      26.0\n    \n    \n      1094\n      2022-12-27\n      26570.779297\n      26620.490234\n      26447.869141\n      26447.869141\n      26447.869141\n      50200000.0\n      Japan\n      0.343410\n      2022.0\n      12.0\n      27.0\n    \n    \n      1095\n      2022-12-28\n      26309.339844\n      26354.269531\n      26199.669922\n      26340.500000\n      26340.500000\n      61500000.0\n      Japan\n      0.312021\n      2022.0\n      12.0\n      28.0\n    \n    \n      1096\n      2022-12-29\n      26074.900391\n      26126.699219\n      25953.919922\n      26093.669922\n      26093.669922\n      63100000.0\n      Japan\n      0.239862\n      2022.0\n      12.0\n      29.0\n    \n    \n      1097\n      2022-12-30\n      26288.000000\n      26321.369141\n      26067.919922\n      26094.500000\n      26094.500000\n      52700000.0\n      Japan\n      0.240105\n      2022.0\n      12.0\n      30.0\n    \n  \n\n2955 rows × 12 columns\n\n\n\n\ndf['Country'].unique()\n\narray(['Korea', 'United States of America', 'China', 'Japan'],\n      dtype=object)"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result",
    "title": "Stock on Graph",
    "section": "Result",
    "text": "Result\n\nrst.df.merge(covid_final_add,on='Date').sort_values(\"Residual\",ascending=False).iloc[:30,:]"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result-1",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result-1",
    "title": "Stock on Graph",
    "section": "Result",
    "text": "Result\n\ncovid_final_add"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-07-Stock_Crawling.html",
    "href": "posts/RESEARCHES/2023-07-07-Stock_Crawling.html",
    "title": "Stock Crawling",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport requests\nfrom datetime import datetime\nfrom matplotlib import dates as mdates\nfrom bs4 import BeautifulSoup as bs\n\n\n\nKorea(KOSPI)\n\nurl = 'https://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=1'\n\n\nheaders = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}\nresponse = requests.get(url, headers=headers)\n\n\nresponse.text\n\n'<html lang=\"ko\">\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=euc-kr\">\\n<title>네이버 증권</title>\\n\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/common.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/layout.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/main.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock2.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock3.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/world.css\">\\n</head>\\n<body>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindo.min.ns.1.5.3.euckr.js\"></script>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/lcslog.js\"></script>\\n\\t\\t\\t\\t<!-- 일별시세 -->\\n\\t\\t\\t\\t<div class=\"box_type_m\">\\n\\t\\t\\t\\t\\t<h4 class=\"top_tlt\" style=\"text-align:left;\"><em>일별</em>시세</h4>\\n\\t\\t\\t\\t\\t<table summary=\"일별 시세표:날짜에 따른 체결가 전일비 등락률 거래량 거래대금 정보를 제공합니다.\" cellpadding=\"0\" cellspacing=\"0\" class=\"type_1\">\\n\\t\\t\\t\\t\\t<caption>일별시세</caption>\\n\\t\\t\\t\\t\\t<col width=\"15%\"><col width=\"14%\"><col width=\"18%\"><col width=\"14%\"><col width=\"*\"><col width=\"18%\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<th>날짜</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>체결가</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>전일비</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>등락률</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>거래량<span class=\"add_txt\">(천주)</span></th>\\n\\t\\t\\t\\t\\t\\t\\t<th>거래대금<span class=\"add_txt\">(백만)</span></th>\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_07\"></td></tr>\\n\\n\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.07</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,526.71</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"하락\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t29.58\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-1.16%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">613,265</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,367,353</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.06</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,556.29</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"하락\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t22.71\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.88%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">531,900</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,291,029</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.05</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,579.00</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"하락\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t14.31\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.55%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">601,089</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,257,664</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_08\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"division_line\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_08\"></td></tr>\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.04</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,593.31</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"하락\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t9.16\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.35%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">674,411</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">9,160,796</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.03</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,602.47</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"상승\"><span class=\"tah p11 red02\">\\n\\t\\t\\t\\t38.19\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 red01\">\\n\\t\\t\\t\\t+1.49%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">618,006</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">8,973,590</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.06.30</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,564.28</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"상승\"><span class=\"tah p11 red02\">\\n\\t\\t\\t\\t14.26\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 red01\">\\n\\t\\t\\t\\t+0.56%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">510,934</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">8,209,121</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_09\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"division_line\"></td></tr>\\n\\t\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<!--- 페이지 네비게이션 시작--->\\n\\t\\t\\t\\t<table summary=\"페이지 네비게이션 리스트\" class=\"Nnavi\" align=\"center\">\\n\\t\\t\\t\\t<caption>페이지 네비게이션</caption>\\n\\t\\t\\t\\t<tr>\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n                \\n                <td class=\"on\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=1\"  >1</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=2\"  >2</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=3\"  >3</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=4\"  >4</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=5\"  >5</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=6\"  >6</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=7\"  >7</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=8\"  >8</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=9\"  >9</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=10\"  >10</a>\\n\\t\\t\\t\\t</td>\\n\\n                <td class=\"pgR\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=11\"  >\\n\\t\\t\\t\\t다음<img src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarR.gif\" width=\"3\" height=\"5\" alt=\"\" border=\"0\">\\n\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t</td>\\n\\n                <td class=\"pgRR\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=1449\"  >맨뒤\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarRR.gif\" width=\"8\" height=\"5\" alt=\"\" border=\"0\">\\n\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t</td>\\n\\n            \\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<!--- 페이지 네비게이션 끝--->\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<!-- //일별시세 -->\\n\\t\\t\\t\\t\\n<script type=\"text/javascript\">\\n    ;(function(){\\n        var eventType = \"onpageshow\" in window ? \"pageshow\" : \"load\";\\n        jindo.$Fn(function(){\\n            lcs_do();\\n        }).attach(window, eventType);\\n    })();\\n</script>\\n\\n</body>\\n</html>\\n'\n\n\n\nhtml = bs(response.text, 'html.parser')\nhtml_table = html.select(\"table\")\ntable = pd.read_html(str(html_table))\nprint('파싱된 테이블의 개수 :', len(table))\n\n파싱된 테이블의 개수 : 2\n\n\n\ntable[0]\n\n\n\n\n\n  \n    \n      \n      날짜\n      체결가\n      전일비\n      등락률\n      거래량(천주)\n      거래대금(백만)\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      6\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      7\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      10\n      2023.06.30\n      2564.28\n      14.26\n      +0.56%\n      510934.0\n      8209121.0\n    \n    \n      11\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      12\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ntable[1]\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n      11\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n      다음\n      맨뒤\n    \n  \n\n\n\n\n\ntable[0].dropna()\n\n\n\n\n\n  \n    \n      \n      날짜\n      체결가\n      전일비\n      등락률\n      거래량(천주)\n      거래대금(백만)\n    \n  \n  \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      10\n      2023.06.30\n      2564.28\n      14.26\n      +0.56%\n      510934.0\n      8209121.0\n    \n  \n\n\n\n\n\ndf = pd.DataFrame()\nsise_url = 'https://finance.naver.com/sise/sise_index_day.naver?code=KOSPI'  \nfor page in range(1, 500):\n    page_url = '{}&page={}'.format(sise_url, page)\n    print(page_url)\n\n    # 위에서 했던 일련의 과정들을 각 url에 대해서 (99페이지에 대해서 반복)\n    response = requests.get(page_url, headers=headers)\n    html = bs(response.text, 'html.parser')\n    html_table = html.select(\"table\")\n    table = pd.read_html(str(html_table))\n\n    # 현재 얻은 데이터프레임을 기존 데이터프레임에 누적.\n    df = df.append(table[0].dropna())\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=1\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=2\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=3\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=4\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=5\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=6\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=7\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=8\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=9\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=10\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=11\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=12\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=13\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=14\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=15\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=16\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=17\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=18\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=19\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=20\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=21\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=22\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=23\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=24\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=25\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=26\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=27\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=28\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=29\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=30\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=31\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=32\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=33\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=34\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=35\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=36\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=37\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=38\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=39\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=40\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=41\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=42\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=43\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=44\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=45\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=46\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=47\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=48\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=49\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=50\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=51\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=52\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=53\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=54\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=55\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=56\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=57\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=58\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=59\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=60\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=61\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=62\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=63\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=64\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=65\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=66\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=67\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=68\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=69\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=70\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=71\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=72\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=73\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=74\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=75\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=76\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=77\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=78\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=79\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=80\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=81\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=82\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=83\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=84\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=85\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=86\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=87\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=88\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=89\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=90\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=91\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=92\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=93\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=94\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=95\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=96\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=97\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=98\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=99\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=100\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=101\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=102\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=103\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=104\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=105\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=106\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=107\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=108\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=109\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=110\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=111\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=112\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=113\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=114\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=115\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=116\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=117\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=118\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=119\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=120\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=121\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=122\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=123\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=124\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=125\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=126\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=127\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=128\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=129\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=130\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=131\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=132\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=133\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=134\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=135\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=136\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=137\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=138\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=139\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=140\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=141\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=142\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=143\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=144\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=145\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=146\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=147\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=148\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=149\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=150\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=151\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=152\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=153\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=154\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=155\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=156\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=157\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=158\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=159\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=160\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=161\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=162\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=163\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=164\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=165\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=166\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=167\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=168\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=169\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=170\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=171\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=172\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=173\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=174\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=175\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=176\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=177\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=178\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=179\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=180\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=181\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=182\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=183\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=184\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=185\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=186\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=187\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=188\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=189\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=190\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=191\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=192\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=193\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=194\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=195\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=196\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=197\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=198\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=199\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=200\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=201\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=202\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=203\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=204\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=205\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=206\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=207\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=208\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=209\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=210\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=211\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=212\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=213\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=214\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=215\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=216\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=217\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=218\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=219\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=220\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=221\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=222\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=223\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=224\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=225\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=226\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=227\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=228\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=229\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=230\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=231\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=232\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=233\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=234\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=235\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=236\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=237\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=238\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=239\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=240\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=241\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=242\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=243\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=244\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=245\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=246\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=247\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=248\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=249\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=250\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=251\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=252\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=253\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=254\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=255\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=256\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=257\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=258\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=259\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=260\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=261\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=262\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=263\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=264\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=265\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=266\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=267\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=268\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=269\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=270\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=271\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=272\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=273\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=274\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=275\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=276\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=277\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=278\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=279\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=280\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=281\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=282\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=283\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=284\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=285\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=286\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=287\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=288\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=289\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=290\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=291\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=292\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=293\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=294\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=295\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=296\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=297\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=298\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=299\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=300\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=301\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=302\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=303\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=304\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=305\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=306\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=307\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=308\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=309\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=310\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=311\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=312\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=313\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=314\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=315\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=316\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=317\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=318\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=319\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=320\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=321\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=322\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=323\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=324\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=325\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=326\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=327\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=328\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=329\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=330\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=331\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=332\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=333\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=334\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=335\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=336\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=337\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=338\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=339\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=340\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=341\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=342\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=343\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=344\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=345\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=346\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=347\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=348\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=349\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=350\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=351\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=352\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=353\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=354\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=355\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=356\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=357\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=358\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=359\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=360\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=361\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=362\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=363\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=364\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=365\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=366\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=367\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=368\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=369\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=370\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=371\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=372\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=373\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=374\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=375\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=376\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=377\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=378\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=379\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=380\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=381\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=382\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=383\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=384\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=385\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=386\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=387\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=388\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=389\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=390\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=391\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=392\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=393\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=394\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=395\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=396\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=397\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=398\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=399\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=400\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=401\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=402\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=403\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=404\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=405\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=406\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=407\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=408\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=409\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=410\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=411\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=412\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=413\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=414\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=415\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=416\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=417\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=418\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=419\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=420\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=421\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=422\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=423\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=424\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=425\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=426\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=427\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=428\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=429\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=430\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=431\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=432\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=433\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=434\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=435\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=436\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=437\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=438\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=439\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=440\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=441\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=442\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=443\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=444\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=445\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=446\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=447\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=448\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=449\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=450\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=451\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=452\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=453\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=454\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=455\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=456\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=457\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=458\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=459\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=460\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=461\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=462\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=463\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=464\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=465\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=466\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=467\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=468\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=469\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=470\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=471\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=472\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=473\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=474\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=475\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=476\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=477\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=478\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=479\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=480\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=481\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=482\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=483\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=484\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=485\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=486\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=487\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=488\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=489\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=490\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=491\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=492\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=493\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=494\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=495\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=496\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=497\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=498\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=499\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      날짜\n      체결가\n      전일비\n      등락률\n      거래량(천주)\n      거래대금(백만)\n    \n  \n  \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2\n      2011.05.24\n      2061.76\n      6.05\n      +0.29%\n      261949.0\n      6012138.0\n    \n    \n      3\n      2011.05.23\n      2055.71\n      55.79\n      -2.64%\n      289835.0\n      6239214.0\n    \n    \n      8\n      2011.05.20\n      2111.50\n      15.99\n      +0.76%\n      280007.0\n      6096860.0\n    \n    \n      9\n      2011.05.19\n      2095.51\n      40.27\n      -1.89%\n      278726.0\n      7779617.0\n    \n    \n      10\n      2011.05.18\n      2135.78\n      33.37\n      +1.59%\n      255798.0\n      7102533.0\n    \n  \n\n2994 rows × 6 columns\n\n\n\n\ndf = df.dropna()\n# df = df.iloc[0:30] \ndf = df.sort_values(by='날짜')\ndf\n\n\n\n\n\n  \n    \n      \n      날짜\n      체결가\n      전일비\n      등락률\n      거래량(천주)\n      거래대금(백만)\n    \n  \n  \n    \n      10\n      2011.05.18\n      2135.78\n      33.37\n      +1.59%\n      255798.0\n      7102533.0\n    \n    \n      9\n      2011.05.19\n      2095.51\n      40.27\n      -1.89%\n      278726.0\n      7779617.0\n    \n    \n      8\n      2011.05.20\n      2111.50\n      15.99\n      +0.76%\n      280007.0\n      6096860.0\n    \n    \n      3\n      2011.05.23\n      2055.71\n      55.79\n      -2.64%\n      289835.0\n      6239214.0\n    \n    \n      2\n      2011.05.24\n      2061.76\n      6.05\n      +0.29%\n      261949.0\n      6012138.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n  \n\n2994 rows × 6 columns\n\n\n\n\nplt.figure(figsize=(15, 5)) \nplt.title('Celltrion (close)')\nplt.xticks(rotation=45) \nplt.plot(df['날짜'], df['체결가'], 'co-')\nplt.grid(color='gray', linestyle='--')\nplt.show()\n\n\n\n\n\ndf.to_csv('korea_kospi.csv')\n\n\n\nUS(NASDAQ)\n\nurl = 'https://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=1'\n\n\nheaders = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}\nresponse = requests.get(url, headers=headers)\n\n\nresponse.text\n\n'<script language=javascript>\\nvar nsc=\"finance.world\";\\nfunction select_chart(pst)\\n{\\n\\tfor(var i=0 ; i<4 ; i++)\\n\\t{\\n\\t\\tif (i == pst)\\n\\t\\t\\tdocument.getElementById(\\'chart_\\'+pst).className = \\'on\\';\\n\\t\\telse\\n\\t\\t\\tdocument.getElementById(\\'chart_\\'+i).className = \"\";\\n\\t}\\n}\\n</script>\\n\\n<!--  global include -->\\n\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n<html lang=\\'ko\\'>\\n<head>\\n\\n\\n\\t\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t<title>나스닥 종합 : 네이버 증권</title>\\n\\t\\t\\t\\n\\t\\t\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\\n\\t\\n\\n\\n<meta http-equiv=\"Content-Script-Type\" content=\"text/javascript\">\\n<meta http-equiv=\"Content-Style-Type\" content=\"text/css\">\\n<meta name=\"apple-mobile-web-app-title\" content=\"네이버 증권\" />\\n\\n\\n\\n\\n\\n\\t\\n    \\n        <meta property=\"og:url\" content=\"http://finance.naver.com/world/sise.naver?symbol=NAS@IXIC\"/>\\n        \\n\\t\\t\\t\\n\\t\\t    \\n\\t\\t    \\t<meta property=\"og:title\" content=\"나스닥 종합 : 네이버 증권\"/>\\n\\t\\t     \\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t   <meta property=\"og:description\" content=\"관심종목의 실시간 주가를 가장 빠르게 확인하는 곳\"/>\\n\\t\\t    \\n\\t\\t    \\n\\t\\t\\n\\t\\t \\n\\t\\t\\t\\n\\t\\t    \\n\\t\\t        <meta property=\"og:image\" content=\"https://ssl.pstatic.net/imgfinance/chart/mobile/world/day/NAS@IXIC_end_up.png\"/>\\n\\t\\t    \\n\\t\\t\\n    \\n\\n<meta property=\"og:type\" content=\"article\"/>\\n<meta property=\"og:article:thumbnailUrl\" content=\"\"/>\\n<meta property=\"og:article:author\" content=\"네이버 증권\"/>\\n<meta property=\"og:article:author:url\" content=\"http://FINANCE.NAVER.COM\"/>\\n\\n\\n\\n\\n\\n\\n<link rel=\\'stylesheet\\' type=\\'text/css\\' href=\\'https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/finance_header.css\\'>\\n\\n\\t\\n\\t\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/finance.css\">\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock3.css\">\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindo.min.ns.1.5.3.euckr.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/release/common.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindoComponent/jindo.Component.1.0.3.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/nhn.autocomplete.stock.js\"></script>\\n\\t\\n\\t\\n\\t\\n\\n<script>\\n\\tvar ieVersion = (function () {\\n        var version = -1;\\n        if (\\n          navigator.appName == \\'Microsoft Internet Explorer\\' &&\\n          navigator.userAgent.toLowerCase().indexOf(\\'msie\\') != -1 &&\\n          new RegExp(\\'MSIE ([0-9]{1,}[\\\\./0-9]{0,})\\').exec(navigator.userAgent) != null\\n        ) {\\n          version = parseInt(RegExp.$1);\\n        }\\n        return version;\\n      })();\\n</script>\\n\\t\\n\\t<!-- smart channel 광고 -->\\n\\t<script async src=\"https://ssl.pstatic.net/tveta/libs/glad/prod/gfp-core.js\">\\n\\t\\t</script>\\n\\t<script type=\"text/javascript\">\\n\\t\\t(function(){\\n\\t\\t\\tif (ieVersion === -1 || ieVersion > 10) {\\n\\t\\t\\t\\twindow.gladsdk = window.gladsdk || { cmd: [] };\\n\\n\\t\\t\\t\\tgladsdk.cmd.push(function() {\\n\\t\\t\\t\\t\\t\\tgladsdk.defineAdSlot({\\n\\t\\t\\t\\t\\t\\t\\tadUnitId: \"p_nf_stock\",\\n\\t\\t\\t\\t\\t\\t\\tadSlotElementId: \"_SmartChannelTopBanner\",\\n\\t\\t\\t\\t\\t\\t\\tuct: \"KR\",\\n\\t\\t\\t\\t\\t\\t\\tcustomParam: {\\n\\t\\t\\t\\t\\t\\t\\t\\tcalp: \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\"abroad\"\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t});\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_LOADED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_LOADED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_CLICKED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_CLICKED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_IMPRESSED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_IMPRESSED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.ERROR, function(ad, error) {\\n\\t\\t\\t\\t\\t\\t\\t//TODO: 오류 로깅처리\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.ERROR);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t});\\n\\t\\t\\t}\\n\\t\\t})();\\n\\t</script>\\n\\t\\n\\n\\t<link rel=\"shortcut icon\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon.ico\" type=\"image/x-icon\">\\n\\t\\n\\t<script type=\"text/javascript\">\\n    (function(){\\n\\t\\tdocument.write(\\n\\t\\t\\t\\t[\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-96x96.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" sizes=\"180x180\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-180x180.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" sizes=\"192x192\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-192x192.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-16x16.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-32x32.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"96x96\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-96x96.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-192x192.png\"/>\\'\\n\\t\\t\\t\\t]\\n\\t\\t\\t.join(\\'\\\\n\\')\\n\\t\\t);\\n    })();\\n    </script>\\n</head>\\n\\n\\n\\n\\n<body onload=\\'getGNB();\\'>\\n\\n\\n\\n<script type=\"text/javascript\">\\n\\n\\tvar nclk_evt = 3;\\n\\tnclk_do();\\n</script>\\n\\n\\n<script type=\"text/javascript\">\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nvar nsc=\"finance.world\";\\n\\n\\n\\n\\n\\nvar ccsrv=\"cc.naver.com\";\\n\\n\\n\\t\\n\\t\\n\\tvar gnb_service=\\'finance\\';\\n\\t\\n\\n\\nvar gnb_logout=document.URL; //GNB에서 로그아웃 후 redirect 될 URL\\nvar gnb_searchbox=\\'off\\'; //미니 검색창을 on 할지 off 할지. default는 off\\nvar gnb_shortnick=\\'off\\'; //닉네임 말줄임(10자)을 on할지 off 할지. default는 off.\\n\\n\\nvar gnb_naverme_layer_open_callback = function(){\\n\\t   var naverLayerSize = gnbNaverMeLayer.getLayerSize();\\n\\t\\t\\n\\t\\tvar me_layers = document.getElementById(\"me_layers\");\\n\\t\\tme_layers.width=naverLayerSize.width;\\n\\t\\tme_layers.height=naverLayerSize.height;};\\n\\nvar gnb_naverme_layer_close_callback = function(){\\n\\t\\t\\n\\t\\t\\tvar me_layers = document.getElementById(\"me_layers\");\\n\\t\\t\\tme_layers.width=\"0\";\\n\\t\\t\\tme_layers.height=\"0\";};\\n</script>\\n\\n\\n<div id=\"u_skip\">\\n\\t<a href=\"#menu\" tabindex=\"1\"><span>메인 메뉴로 바로가기</span></a>\\n\\n\\t\\n\\t\\n\\t\\t<a href=\"#start\" tabindex=\"2\"><span>본문으로 바로가기</span></a>\\n\\t\\n\\n</div>\\n\\n\\n<div id=\"header\">\\n\\t<div class=\"snb_area\">\\n\\t\\t<div class=\"snb_inner\">\\n\\t\\t\\t<div id=\"gnb_area\">\\n\\t\\t\\t\\t<div id=\"gnb\">\\n\\t\\t\\t\\t\\t<script charset=\"EUC-KR\" type=\"text/javascript\">\\n\\t\\t\\t\\t\\tvar gnb_service = \"gnbtest\";\\n                    var gnb_template = location.protocol == \"http:\" ? \"gnb_quirks_euckr\" : \"gnb_utf8\" ;\\n\\t\\t\\t\\t\\tvar gnb_dark = false;\\n\\t\\t\\t\\t\\tvar gnb_brightness = 1;\\n\\t\\t\\t\\t\\tvar gnb_logout=encodeURIComponent(location.href);\\n\\t\\t\\t\\t\\tvar gnb_one_naver = 1;\\n\\t\\t\\t\\t\\t</script>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<script type=\"text/javascript\" charset=\"utf-8\" src=\"https://ssl.pstatic.net/static.gn/templates/gnb_utf8.nhn?20230707\">\\n                    \\t\\t</script>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\n\\t\\t\\t<div class=\"sta\">\\n\\t\\t\\t\\t<h1 class=\"logo\"> <a href=\"https://www.naver.com/\" class=\"logo_naver\" onClick=\"clickcr(this, \\'STA.naver\\', \\'\\', \\'\\', event);\"><span class=\"blind\">네이버</span></a>\\n\\t\\t\\t\\t<a href=\"/\" class=\"logo_service\" onClick=\"clickcr(this, \\'STA.finance\\', \\'\\', \\'\\', event);\"><span class=\"blind\">증권</span></a> </h1>\\n\\t\\t\\t\\t<form name=\"search\" action=\"/search/search.naver\"  method=\"get\"\\n\\t\\t\\t\\t\\tonsubmit=\"return delayed_submit(this)\" style=\"margin:0; padding:0;\">\\n\\t\\t\\t\\t<fieldset>\\n\\t\\t\\t\\t\\t<legend>검색</legend>\\n\\t\\t\\t\\t\\t<div class=\"snb_search_box\">\\n\\t\\t\\t\\t\\t\\t<div class=\"snb_search_box_sub\">\\n\\t\\t\\t\\t\\t\\t\\t<input id=\"stock_items\" type=\"text\" title=\"검색\" name=\"query\" value=\"종목명&middot;지수명 입력\" accesskey=\"s\" class=\"snb_search_text snb_default\" autocomplete=\"off\">\\n\\t\\t\\t\\t\\t\\t\\t<a id=\"nautocomplete\" href=\"#\" onclick=\"return false\" class=\"btn_arrow\"><span class=\"blind\">자동완성 펼치기</span></a>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t<div class=\"auto_area\">\\n\\t\\t\\t\\t\\t\\t\\t<h2 class=\"blind\">자동완성</h2>\\n\\t\\t\\t\\t\\t\\t\\t<div id=\"autoFrame\" style=\"display: none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmp\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<ul class=\"_resultBox\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'AUT.list\\', \\'\\', \\'\\', event); return false;\" class=\"_au_real_list\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"num _au_real_list\">@code@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"_au_real_list\">@txt@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"type _au_real_list\">@market@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_full\">@full_txt@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_code\">@in_code@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_name\">@in_name@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_link\">@in_link@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_market\">@in_market@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\" onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\" >기능끄기</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t<!-- 현재 자동완성 기능을 사용하고 계십니다 -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmpIng\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"msg\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현재 자동완성 기능을 사용하고 계십니다.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\" onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\">기능끄기</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t<!--// 현재 자동완성 기능을 사용하고 계십니다 -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<!-- 자동완성 기능이 활성화 -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmpStart\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"msg\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t자동완성 기능이 활성화되었습니다.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\"  onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\">기능끄기</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t<button type=\"submit\" class=\"snb_search_btn\" onclick=\"clickcr(this, \\'STA.search\\', \\'\\', \\'\\', event);\" alt=\"검색\"><span class=\"blind\">검색</span></button>\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" target=\"_blank\" class=\"snb_search_btn-total\" onclick=\"itegrationSearch();clickcr(this, \\'STA.nx\\', \\'\\', \\'\\', event);return false;\">통합검색</a>\\n\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t</fieldset>\\n\\t\\t\\t\\t</form>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\t<div class=\"lnb_area \">\\n\\t\\t<div class=\"lnb_inner\">\\n\\t\\t\\t<div id=\"menu\">\\n\\t\\t\\t\\t<ul class=\"menu\">\\n\\t\\t\\t\\t\\t<li class=\"m1 first \"><a href=\"/\" onClick=\"clickcr(this, \\'LNB.home\\', \\'\\', \\'\\', event);\"><span class=\"tx\">증권 홈</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m2 \"><a href=\"/sise/\" onClick=\"clickcr(this, \\'LNB.sise\\', \\'\\', \\'\\', event);\"><span class=\"tx\">국내증시</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m3 on\"><a href=\"/world/\" onClick=\"clickcr(this, \\'LNB.world\\', \\'\\', \\'\\', event);\"><span class=\"tx\">해외증시</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m4 \"><a href=\"/marketindex/\" onClick=\"clickcr(this, \\'LNB.market\\', \\'\\', \\'\\', event);\"><span class=\"tx\">시장지표</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m6 \"><a href=\"/research/\" onClick=\"clickcr(this, \\'LNB.research\\', \\'\\', \\'\\', event);\"><span class=\"tx\">리서치</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m7 \"><a href=\"/news/\"><span class=\"tx\">뉴스</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m8 \"><a href=\"/mystock/\" onClick=\"clickcr(this, \\'LNB.mystock\\', \\'\\', \\'\\', event);\"><span class=\"tx\">MY</span></a></li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t<script type=\"text/JavaScript\">\\n\\t\\tfunction overSubmenu(e) {\\n\\t\\t\\tvar curElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\t\\tcurElement.addClass(\"on\");\\n\\t\\t}\\n\\n\\t\\tfunction outSubmenu(e) {\\n\\t\\t\\tvar curElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\t\\tcurElement.removeClass(\"on\");\\n\\t\\t}\\n\\n\\t\\twindow.onload=function(){\\n\\t\\t\\t// 해외증시홈, 해외증시뉴스는 mouseover 이벤트가 발생하면 안된다.\\n\\t\\t\\tvar liMenuElement = jindo.$A(jindo.$$(\\'ul.lnb2 li\\')).slice(2, 6);\\n\\t\\t\\tvar liMenuElementValue = liMenuElement.$value();\\n\\t\\t\\tjindo.$Fn(function(e){overSubmenu(e);}).attach(liMenuElementValue,\\'mouseover\\');\\n\\t\\t\\tjindo.$Fn(function(e){outSubmenu(e);}).attach(liMenuElementValue,\\'mouseout\\');\\n\\t\\t\\tgetGNB();\\n\\t\\t}\\n\\t</script>\\n\\t\\n\\n\\t\\n\\t<script type=\"text/JavaScript\">\\n\\t\\t/* lcs 집계 */\\n        ;(function(){\\n            var eventType = \"onpageshow\" in window ? \"pageshow\" : \"load\";\\n            jindo.$Fn(function(){\\n                lcs_do();\\n            }).attach(window, eventType);\\n        })();\\n\\n\\t\\t/* 검색 자동완성 [ 인자1 : 검색input의 ID, 인자2 : iframe 태그 ID ]   */\\n\\t\\t// AutoComplete 생성\\n\\t\\tvar acDomain = \"ac.finance.naver.com\";\\n        if (location.hostname.indexOf(\"staging-\") > -1) {\\n            acDomain = \"staging-\" + acDomain;\\n        } else if (location.hostname.indexOf(\"dev-\") > -1 || location.hostname.indexOf(\"localhost\") > -1 || location.hostname.indexOf(\"local-\") > -1) {\\n\\t\\t\\tacDomain = \"dev-\" + acDomain;\\n\\t\\t}\\n\\n        var acUrl = \"https://\" + acDomain + \"/ac\";\\n\\n\\t\\tsmartSearch = new nhn.Autocomplete(\\n\\t\\t\\t// InputManager 생성\\n\\t\\t\\tnew nhn.AcInputManager(jindo.$(\"stock_items\")),\\n\\t\\t\\t// DataManager 생성\\n\\t\\t\\tnew nhn.AcDataManager(acUrl, \"jsonp\", \"get\", {\\n                    st: \"111\",\\n                    r_lt : \"111\",\\n                    q_enc : \"euc-kr\",\\n                    r_enc : \"euc-kr\",\\n                    frm: \"stock\"}),\\n\\t\\t\\t// ViewManager 생성\\n\\t\\t\\tnew nhn.AcStockViewManager(jindo.$(\"autoFrame\"), jindo.$(\"nautocomplete\"), {\\n                                        strMax: 200,\\n                                        listMax: [7, 2, 2],\\n                                        aRedirectUrl : [\\n                            \\t\\t\\t\"https://finance.naver.com\",\\n                            \\t\\t\\t\"https://finance.naver.com\",\\n                            \\t\\t\\t\"https://finance.naver.com\"]}),\\n\\t\\t\\t// Autocomplete Option\\n            {formId:\"search\", cookieDomain:location.hostname, cookieName:\"NaverCommonStock\"});\\n\\n\\t\\t\\tsmartSearch.attach({\\n\\t            onFocus: function () {\\n\\t                var weInput = jindo.$Element(\\'stock_items\\');\\n\\t                if (weInput && weInput.hasClass(\"snb_default\")) {\\n\\t                        weInput.text(\"\");\\n\\t                        weInput.removeClass(\\'snb_default\\');\\n\\t                }\\n\\t            }\\n\\t        });\\n\\n\\t\\t/* 통합검색  start ----->  */\\n\\t\\t//document.domain = \\'naver.com\\';\\n\\t\\tvar sSearchHintText = \\'종목명·지수명·환율명·원자재명 입력\\';\\n\\t\\tfunction itegrationSearch() {\\n\\t\\t\\tvar query = jindo.$(\\'stock_items\\').value;\\n\\n\\t\\t\\tif ( query == \\'\\'  || encodeURIComponent(query) == encodeURIComponent(sSearchHintText))\\n\\t\\t\\t{\\n\\t\\t\\t\\talert ( \\'검색어를 입력해 주세요.\\' );\\n\\t\\t\\t\\treturn;\\n\\t\\t\\t}\\n\\n            var url = location.protocol + \"//search.naver.com/search.naver?sm=sta_hty.finance&where=nexearch&ie=UTF8&query=\" + encodeURIComponent(query);\\n            window.open(url, \"_blank\");\\n\\n\\t\\t\\treturn false;\\n\\t\\t}\\n\\n\\t\\tfunction delayed_submit(object) {\\n\\t\\t\\tif (navigator.userAgent.indexOf(\\'MSIE\\') == -1) {\\n\\t\\t\\t\\twindow.setTimeout(function() {stock_search(object)}, 300);\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tstock_search(object);\\n\\t\\t\\t}\\n\\t\\t\\treturn false;\\n\\t\\t}\\n\\n\\t\\tfunction stock_search (object)\\n\\t\\t{\\n\\t\\t\\tquery = object.query.value.replace(/^\\\\s*/,\\'\\').replace(/\\\\s*$/,\\'\\');\\t// trim\\n\\t\\t\\tobject.query.value=query;\\n\\n\\t\\t\\tif ( query == \\'\\' || query == sSearchHintText.replace(/^\\\\s*/,\\'\\').replace(/\\\\s*$/,\\'\\'))\\n\\t\\t\\t{\\n\\t\\t\\t\\talert ( \\'검색어를 입력해 주세요.\\' );\\n\\t\\t\\t\\treturn;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tobject.submit();\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t/* <---------- 통합검색  end */\\n\\n\\t\\tfunction popup()\\n\\t\\t{\\n\\t\\t\\twin = window.open(\\'/template/group_limit_pop.jsp\\',\\'finan_popup\\',\\'width=569 height=278 scrollbars=no status=no\\');\\n\\t\\t\\twin.focus();\\n\\t\\t}\\n\\t</script>\\n\\n\\t<iframe id=\"me_layers\" name=\"test\" title=\"네이버미 영역\" width=\"0\" height=\"0\" scrolling=\"no\" frameborder=\"0\" style=\"display:block;top: 22px; right: 209px; position: absolute; z-index: 15;\"></iframe>\\n</div>\\n<div id=\"wrap\"  >\\n\\t\\n\\t\\t<div class=\"banner_smart\">\\n\\t\\t\\t<div id=\"_SmartChannelTopBanner\">\\n\\t\\t\\t\\t<script type=\"text/javascript\">\\n\\t\\t\\t\\tif (ieVersion === -1 || ieVersion > 10) {\\n\\t\\t\\t\\t\\tgladsdk.cmd.push(function() {\\n\\t\\t\\t\\t\\t\\tgladsdk.displayAd(\"_SmartChannelTopBanner\");\\n\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t</script>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\n\\n<!-- //  global include -->\\n\\t<!-- [D] 이 라인부터 Footer 전까지는 전부 새로 마크업된 영역입니다. 기존 레이아웃을 걷어내 주세요.\\n\\t\\tclass=\"섹션고유네이밍\" 을 추가합니다.\\n\\t\\t(해외증시 섹션 > end 페이지 : section_world section_world_end)\\n\\t\\t다음 마크업담당자님 : 기존 finance.css 에서 #container 를 사용하고 있기 때문에, 사이드이펙트를 고려해서 id=\"container\" 를 제외했습니다 -->\\n\\t<div class=\"section_world section_world_end\">\\n\\t\\t<!-- 상단 제목영역 -->\\n\\n\\t\\t<div class=\"group_h\">\\n\\t\\t\\t<div class=\"h_area\">\\n\\t\\t\\t\\t<h2>나스닥 종합</h2>\\n\\t\\t\\t\\t<em class=\"quot\">NAS@IXIC</em>\\n\\t\\t\\t\\t<span class=\"state\">미국</span>\\n\\t\\t\\t\\t<span class=\"date\"><em>2023.07.07 10:42</em> \\n\\t\\t\\t\\t현지시간 기준\\n\\t\\t\\t\\t<span>|</span>15분 지연제공 </span>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\t<!-- //상단 제목영역 -->\\n\\t\\t<div id=\"content\">\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t<!-- 현재 시세 -->\\n\\t\\t\\t<!-- [D] 펀드 end 와 동일한 구조입니다 -->\\n\\t\\t\\t<div class=\"rate_info\">\\n\\t\\t\\t\\t<div class=\"today\">\\n\\t\\t\\t\\t\\t<p class=\"no_today\">\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no8\">8</span><span class=\"no1\">1</span><span class=\"jum\">.</span><span class=\"no6\">6</span><span class=\"no1\">1</span>\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t<p class=\"no_exday\">\\n\\t\\t\\t\\t\\t\\t<span class=\"txt_comparison\">전일대비</span>\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\"\">\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"ico up\"></span>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no2\">2</span><span class=\"jum\">.</span><span class=\"no5\">5</span><span class=\"no7\">7</span>\\n\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"parenthesis1\">(</span><span class=\"ico plus\">+</span>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no0\">0</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no2\">2</span><span class=\"per\">%</span>\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"parenthesis2\">)</span>\\n\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<table summary=\"주요 시세(전일종가, 시고저가, 거래량, 거래대금)을 제공합니다.\" class=\"no_info\">\\n\\t\\t\\t\\t<caption>주요 시세</caption>\\n\\t\\t\\t\\t<colgroup><col width=\"150\"><col><col width=\"154\"></colgroup>\\n\\t\\t\\t\\t<tbody>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail7\">전일</span>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no7\">7</span><span class=\"no9\">9</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no4\">4</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail8\">고가</span>\\n\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no7\">7</span><span class=\"no3\">3</span><span class=\"no0\">0</span><span class=\"jum\">.</span><span class=\"no7\">7</span><span class=\"no2\">2</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail9\">52주 최고</span>\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no8\">8</span><span class=\"no6\">6</span><span class=\"no4\">4</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no6\">6</span>\\n\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail10\">시가</span>\\n\\t\\t\\t\\t\\t<em class=\"no_down\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no6\">6</span><span class=\"no8\">8</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no7\">7</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail11\">저가</span>\\n\\t\\t\\t\\t\\t<em class=\"no_down\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no5\">5</span><span class=\"no7\">7</span><span class=\"jum\">.</span><span class=\"no7\">7</span><span class=\"no2\">2</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail12\">52주 최저</span>\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no0\">0</span><span class=\"shim\">,</span><span class=\"no0\">0</span><span class=\"no8\">8</span><span class=\"no8\">8</span><span class=\"jum\">.</span><span class=\"no8\">8</span><span class=\"no3\">3</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</tbody>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<!-- 미니 일차트 -->\\n\\t\\t\\t\\t<div class=\"aside_section\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<!-- [D] 130x53 -->\\n\\t\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgfinance/chart/mobile/world/mini/NAS@IXIC.png?sidcode=1365666030675\" class=\"img_graph\" title=\"미니 일차트\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<!-- //미니 일차트 -->\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- 차트 컨트롤 영역 -->\\n\\t\\t\\t<div class=\"chart_control_area\">\\n\\t\\t\\t\\t<dl class=\"line\">\\n\\n\\t\\t\\t\\t<dt>선차트</dt>\\n\\t\\t\\t\\t<dd>\\n\\t\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li class=\"month3\"><a href=\"#\" class=\"on\" onclick=\"showChart(\\'month3\\');\">3개월</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year\"><a href=\"#\" onclick=\"showChart(\\'year\\');\">1년</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year3\"><a href=\"#\" onclick=\"showChart(\\'year3\\');\">3년</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year5\"><a href=\"#\" onclick=\"showChart(\\'year5\\');\">5년</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year10\"><a href=\"#\" onclick=\"showChart(\\'year10\\');\">10년</a></li>\\n\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</dd>\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t\\t<dl class=\"bar\">\\n\\t\\t\\t\\t<dt>봉차트</dt>\\n\\t\\t\\t\\t<dd>\\n\\t\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li class=\"day\"><a href=\"#\" onclick=\"showBarChart(\\'day\\');\">일봉</a></li>\\n\\t\\t\\t\\t\\t<li class=\"week\"><a href=\"#\" onclick=\"showBarChart(\\'week\\');\">주봉</a></li>\\n\\t\\t\\t\\t\\t<li class=\"month\"><a href=\"#\" onclick=\"showBarChart(\\'month\\');\">월봉</a></li>\\n\\t\\t\\t\\t\\t</ul>\\n\\n\\t\\t\\t\\t</dd>\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //차트 컨트롤 영역 -->\\n\\t\\t\\t<!-- 차트 -->\\n\\t\\t\\t<div class=\"flash_area\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgfinance/chart/world/month3/NAS@IXIC.png?1688741844631\" width=\"700\" alt=\"차트\" onerror=\"this.src=\\'https://ssl.pstatic.net/imgstock/chart3/world2008/error_700x243.gif\\'\" />\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //차트 -->\\n\\n\\t\\t\\t<!-- //현재 시세 -->\\n\\t\\t\\t<!-- 일별,시간별시세 -->\\n\\t\\t\\t<div class=\"section_quot\">\\n\\t\\t\\t\\t<h3 class=\"h_sise_day\">일별시세</h3>\\n\\t\\t\\t\\t<!-- [D] 일별시세 : 마지막 tr 에 .last 추가 -->\\n\\t\\t\\t\\t<table sumary=\"일별시세 리스트\" cellpadding=\"0\" cellspacing=\"0\" class=\"tb_status2 tb_status2_t2\" id=\"dayTable\">\\n\\t\\t\\t\\t<caption>일별시세</caption>\\n\\n\\t\\t\\t\\t<col width=\"87\"><col width=\"124\"><col width=\"118\"><col width=\"124\"><col width=\"124\"><col width=\"124\">\\n\\t\\t\\t\\t<thead>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td\"><span class=\"blind\">일자</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td2\"><span class=\"blind\">종가</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td3\"><span class=\"blind\">전일대비</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td4\"><span class=\"blind\">시가</span></th>\\n\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td5\"><span class=\"blind\">고가</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td6\"><span class=\"blind\">저가</span></th>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</thead>\\n\\t\\t\\t\\t<tbody>\\n\\t\\t\\t\\t<!-- 종가데이터가 안들어왔을시 처리 -->\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr class=\"point_up\">\\n\\t\\n\\t\\t\\t\\t\\t<td class=\"tb_td\">2023.07.07</td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,681.61</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">2.57</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,668.07</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,730.72</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,657.72</span></td>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.06</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,679.04</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">112.61</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,653.17</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,689.52</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,567.26</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.05</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,791.65</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">25.12</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,772.10</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,844.50</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,764.25</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.03</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,816.77</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">28.85</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,798.70</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,839.09</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,773.41</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.30</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,787.92</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">196.59</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,719.98</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,816.68</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,716.16</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.29</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,591.33</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">0.42</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,592.36</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,618.53</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,540.26</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.28</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,591.75</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">36.08</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,506.02</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,654.14</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,495.73</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.27</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,555.67</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">219.89</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,389.25</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,578.80</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,366.97</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.26</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,335.78</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">156.74</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,468.75</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,573.57</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,334.42</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn last\">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.23</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,492.52</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">138.09</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,484.10</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,572.19</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,442.65</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t</tbody>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<div class=\"paging\" id=\"dayPaging\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink1\" class=\"on\" onClick=\"moveDayPaging(1, false, event); return false\">1</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink2\"  onClick=\"moveDayPaging(2, false, event); return false\">2</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink3\"  onClick=\"moveDayPaging(3, false, event); return false\">3</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink4\"  onClick=\"moveDayPaging(4, false, event); return false\">4</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink5\"  onClick=\"moveDayPaging(5, false, event); return false\">5</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink6\"  onClick=\"moveDayPaging(6, false, event); return false\">6</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink7\"  onClick=\"moveDayPaging(7, false, event); return false\">7</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink8\"  onClick=\"moveDayPaging(8, false, event); return false\">8</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink9\"  onClick=\"moveDayPaging(9, false, event); return false\">9</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink10\"  onClick=\"moveDayPaging(10, false, event); return false\">10</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t <a href=\"#\" class=\"next\" onClick=\"moveDayPaging(11, true, event); return false\">다음 <img src=\"https://ssl.pstatic.net/static/nfinance/bu_pgarR.gif\" width=\"3\" height=\"5\" alt=\"다음\"></a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //일별,시간별시세 -->\\n\\t\\t</div>\\n\\t\\t<!-- [D] 미니 일차트가 있을 경우 아래와 같이 style 추가 -->\\n\\t\\t<div id=\"world_end\" class=\"aside\" style=\"padding-top:99px\">\\n\\t\\t\\t<div class=\"aside_world_end\">\\n\\t\\t\\t\\t<h3 class=\"h_info_relative\"><span>관련정보</span></h3>\\n\\t\\t\\t\\t<dl class=\"info_aside\">\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<!-- 종목의 경우에만 편입지수를 보여준다. -->\\n\\t\\t\\t\\t\\n\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<dt class=\"dt5\"><span class=\"blind\">거래소</span></dt>\\n\\t\\t\\t\\t<dd><span>NASDAQ Stock Market</span></dd>\\n\\t\\t\\t\\t<dt class=\"dt7\"><span class=\"blind\">기준통화</span></dt>\\n\\t\\t\\t\\t<dd><span>USD</span></dd>\\n\\t\\t\\t\\t<dt class=\"dt6\"><span class=\"blind\">거래시간(한국시간 기준)</span></dt>\\n\\t\\t\\t\\t<dd><span>23:30~06:00<br>서머타임 22:30~05:00</span></dd>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t \\n\\t\\t\\t\\t<dt class=\"dt8\"><span class=\"blind\">지수 설명</span></dt>\\n\\t\\t\\t\\t<dd class=\"dd3\">하이테크·중소기업의 주식을 장외에서 거래하는 나스닥 시장의 종합지수<br><a href=\"http://terms.naver.com/entry.nhn?docId=1192561&cid=200000000&categoryId=200000418\" target=\"blank\">\\n\\t\\t\\t\\t네이버 지식백과\\n\\t\\t\\t\\t</a></dd>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t</div>\\n\\t\\t\\t\\n\\t\\t\\t<script>\\nfunction fnShowOn(onId){\\n\\tdocument.getElementById(onId).style.display=\"block\";\\n}\\nfunction fnShowOff(offId){\\n\\tdocument.getElementById(offId).style.display=\"none\";\\n}\\n</script>\\n\\n\\t\\n\\t\\n\\n\\n\\t\\n\\n\\t\\n\\t<!-- Type3 [해외증시 종목페이지] -->\\n\\t\\t<!-- 최근조회종목 -->\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/util.js\"></script>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/myStock.js\"></script>\\n\\n\\t\\n\\t\\n\\t\\t\\n\\t\\n\\n\\n<div class=\"section_aside\">\\n\\t<div class=\"tab_search search3\">\\n\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.1\\', \\'\\', \\'\\', event); return false;\"><span>최근조회</span></a>\\n\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.3\\', \\'\\', \\'\\', event); return false;\"><span>MY STOCK</span></a>\\n\\t</div>\\n\\t<table class=\"tbl_search\" summary=\"최근조회 리스트\">\\n\\t\\t<caption>최근조회</caption>\\n\\t\\t<colgroup>\\n\\t\\t\\t<col width=\"65\">\\n\\t\\t\\t<col width=\"55\">\\n\\t\\t\\t<col width=\"80\">\\n\\t\\t</colgroup>\\n\\t\\t<thead>\\n\\t\\t<tr>\\n\\t\\t\\t<th>업체명</th>\\n\\t\\t\\t<th>거래량</th>\\n\\t\\t\\t<th>전일비</th>\\n\\t\\t</tr>\\n\\t\\t</thead>\\n\\t\\t<tbody>\\n\\t\\t</tbody>\\n\\t</table>\\n\\t<div class=\"more_info\">\\n\\t\\t<span>\\n\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.5\\', \\'\\', \\'\\', event); return false;\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_prev2.gif\" width=\"17\" height=\"15\" alt=\"이전\"></a>\\n\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.6\\', \\'\\', \\'\\', event); return false;\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_next2.gif\" width=\"17\" height=\"15\" alt=\"다음\"></a>\\n\\t\\t</span>\\n\\t\\t<a href=\"#\" onclick=\"javascript:openMyitemNew(\\'https://finance.naver.com\\'); clickcr(this, \\'rch.7\\', \\'\\', \\'\\', event);\" class=\"btn_more _mystock_more_info\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_more5.gif\" width=\"33\" height=\"10\" alt=\"더보기\"></a>\\n\\t</div>\\n</div>\\n\\n<script type=\"text/javascript\" language=\"javascript\">\\n\\tfunction initMyStock() {\\n\\t\\tgetStockRightMenuData(\\'000000\\', \\'recent\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\');\\n\\n\\t\\tvar tabSearchArea = jindo.$$.getSingle(\\'.tab_search\\');\\n\\t\\tvar moreInfoArea = jindo.$Element(jindo.$$.getSingle(\\'.tbl_search\\')).next().$value();\\n\\n\\t\\tjindo.$Fn(function(e) {toggleTabSearch(e); getStockRightMenuData(\\'000000\\', \\'recent\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$.getSingle(\\'a\\' ,tabSearchArea), \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {toggleTabSearch(e); getStockRightMenuData(\\'000000\\', \\'mystock\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$(\\'a\\' ,tabSearchArea)[1], \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {updatePageForPaging (currentType, \\'up\\', \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$.getSingle(\\'a\\', moreInfoArea), \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {updatePageForPaging (currentType, \\'down\\', \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$(\\'a\\', moreInfoArea)[1], \\'click\\');\\n\\t}\\n\\n\\tfunction toggleTabSearch(e){\\n\\t\\tvar currentElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\tvar parentElement = currentElement.parent();\\n\\t\\tvar id = currentElement.className();\\n\\t\\tvar order = parentElement.indexOf(currentElement) + 3;\\n\\t\\tparentElement.className(\"tab_search search\"+ order);\\n\\n\\t\\t// 페이징을 위해서 order값에 따라 최근조회인지 mystock인지 type을 저장\\n\\t\\tif (order == 1) {\\n\\t\\t\\tcurrentType = \"recent\";\\n\\t\\t} else {\\n\\t\\t\\tcurrentType = \"mystock\";\\n\\t\\t}\\n\\t}\\n\\n\\tjindo.$Fn(initMyStock).attach(document, \"domready\");\\n\\n\\tfunction openMyitemNew(stockHost) {\\n\\t\\tvar selectedElement = jindo.$Element(jindo.$$.getSingle(\".tab_search\"));\\n\\t\\tif (selectedElement != null) {\\n\\t\\t\\tif (selectedElement.hasClass(\"search1\")) {\\n\\t\\t\\t\\tdocument.location.href = stockHost + \\'/mystock/recentSearchItemList.naver\\';\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tdocument.location.href = stockHost + \\'/mystock/itemList.naver\\';\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n\\t//initMyStock();\\n</script>\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\t\\n\\n\\n\\t\\t</div>\\n\\t</div>\\n<script language=\"javascript\" type=\"text/JavaScript\" src=\"/js/worldIndex.js\"></script>\\n<script language=\"javascript\" type=\"text/JavaScript\">\\nvar sSymbol = \"NAS@IXIC\";\\nvar sFdtc = \"0\";\\nvar nMaxTimePage = 0;\\nvar nMaxDayPage = 542;\\nvar nMaxIncludePage = 0;\\nvar sIncludeItemMenuId = \"\";\\n\\nvar nCurTimePage = 1;\\nvar nCurDayPage = 1;\\nvar nCurIncludePage = 1;\\nvar sCurIncludeDirection = \"up\";\\nvar sCurIncludeSort = \"knam\";\\nvar sDayHtmlFormat = \"<td class=\\\\\"tb_td\\\\\">%s</td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td2\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td3\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td4\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td5\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td6\\\\\"><span>%s</span></td>\";\\nvar sDefaultDayHtml = null;\\nvar sDefaultDayPointClass = null;\\n\\nfunction initWorld() {\\n\\t\\n}\\n\\nfunction initsDefaultDayHtml() {\\n\\tvar nDiff = 2.57;\\n\\tvar sDiff = formatNumberForFinance(\"2.57\", false);\\n\\tvar sXymd = \"20230707\".substr(0, 4) + \".\" + \"20230707\".substr(4, 2) + \".\" + \"20230707\".substr(6, 2);\\n\\tvar sClos = formatNumberForFinance(\"13681.61\", false);\\n\\tvar sOpen = formatNumberForFinance(\"13668.07\", false);\\n\\tvar sHigh = formatNumberForFinance(\"13730.72\", false);\\n\\tvar sLow = formatNumberForFinance(\"13657.72\", false);\\n\\t\\n\\tsDefaultDayPointClass = \"\";\\n\\t\\n\\tif (nDiff > 0) {\\n\\t\\tsDefaultDayPointClass = \"point_up\";\\n\\t} else if (nDiff < 0) {\\n\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\tsDefaultDayPointClass = \"point_dn\";\\n\\t}\\n\\t\\n\\tsDefaultDayHtml = jindo.$S(sDayHtmlFormat).format(sXymd, sClos, sDiff, sOpen, sHigh, sLow);\\n}\\n\\njindo.$Fn(initWorld).attach(document, \"domready\");\\n\\n// 일별시세 페이징 이동\\nfunction moveDayPaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\tif (sDefaultDayHtml == null) {\\n\\t\\tinitsDefaultDayHtml();\\n\\t}\\n\\n\\t// 현재페이지와 다른 링크를 눌렀을 경우에만 Ajax로 데이터를 받아온다.\\n\\tif (nCurDayPage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\tvar url = \"/world/worldDayListJson.naver?symbol=\" + sSymbol + \"&fdtc=\" + sFdtc + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"dayTable\");\\n\\t\\t\\t\\t\\n\\t\\t\\t// tr 전부 삭제\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sXymd = v.xymd.substr(0, 4) + \".\" + v.xymd.substr(4, 2) + \".\" + v.xymd.substr(6, 2);\\n\\t\\t\\t\\tvar sClos = formatNumberForFinance(v.clos, false);\\n\\t\\t\\t\\tvar sOpen = formatNumberForFinance(v.open, false);\\n\\t\\t\\t\\tvar sHigh = formatNumberForFinance(v.high, false);\\n\\t\\t\\t\\tvar sLow = formatNumberForFinance(v.low, false);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sDayHtmlFormat).format(sXymd, sClos, sDiff, sOpen, sHigh, sLow);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\n\\t\\t\\tif (nPage == 1 && jindo.$A(json).length() < 10) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tjindo.$Element(elTr).html(sDefaultDayHtml);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sDefaultDayPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sDefaultDayPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// 새로 페이징을 제작\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"dayPaging\", \"dayLink\", moveDayPaging, nPage, nMaxDayPage);\\n\\t\\tnCurDayPage = nPage;\\n\\t} else {\\n\\t\\tjindo.$Element(\"dayLink\" + nCurDayPage).removeClass(\"on\");\\n\\t\\tjindo.$Element(\"dayLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurDayPage = nPage;\\n\\t}\\n}\\n\\n// 시간별 시세 페이징 이동\\nfunction moveTimePaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\t// 현재페이지와 다른 링크를 눌렀을 경우에만 Ajax로 데이터를 받아온다.\\n\\tif (nCurTimePage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\tvar url = \"/world/worldTimeListJson.naver?symbol=\" + sSymbol + \"&fdtc=\" + sFdtc + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"timeTable\");\\n\\t\\t\\tvar sHtmlFormat = \"<td class=\\\\\"tb_td11\\\\\">%s</td><td class=\\\\\"tb_td12\\\\\"><span>%s</span></td><td class=\\\\\"tb_td13\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td14\\\\\"><span class=\\\\\"point_status\\\\\">%s%</span></td><td class=\\\\\"tb_td15\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\n\\t\\t\\t// tr 전부 삭제\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sXhms = v.xhms.substr(0, 2) + \":\" + v.xhms.substr(2, 2);\\n\\t\\t\\t\\tvar sLast = formatNumberForFinance(v.last, false);\\n\\t\\t\\t\\tvar sRate = formatNumberForFinance(v.rate, true);\\n\\t\\t\\t\\tvar sGvol = formatNumberForFinance(v.gvol, false);\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tsGvol = sGvol.substr(0, sGvol.length - 3);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sHtmlFormat).format(sXhms, sLast, sDiff, sRate, sGvol);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// 새로 페이징을 제작\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"timePaging\", \"timeLink\", moveTimePaging, nPage, nMaxTimePage);\\n\\t\\tnCurTimePage = nPage;\\n\\t} else {\\n\\t\\tjindo.$Element(\"timeLink\" + nCurTimePage).removeClass(\"on\");\\n\\t\\tjindo.$Element(\"timeLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurTimePage = nPage;\\n\\t}\\n}\\n\\t\\nfunction sortInclude(sOrdering, sDirection, sBtnId, e) {\\n\\tsCurIncludeDirection = sDirection;\\n\\tsCurIncludeSort = sOrdering;\\n\\tvar elSelectedBtn = jindo.$(sBtnId);\\n\\t\\n\\tjindo.$A(jindo.$$(\"table th button\")).forEach(function (v, i) {\\n\\t\\tvar welCurBtn = jindo.$Element(v);\\n\\t\\t\\n\\t\\tif (welCurBtn.attr(\"id\").indexOf(sBtnId) != -1) {\\n\\t\\t\\twelCurBtn.removeClass(\"asc\");\\n\\t\\t\\twelCurBtn.removeClass(\"desc\");\\n\\t\\t} else {\\n\\t\\t\\twelCurBtn.removeClass(\"asc\");\\n\\t\\t\\twelCurBtn.removeClass(\"desc\");\\n\\t\\t}\\n\\t});\\n\\t\\n\\tvar sToggledDirection;\\n\\tif (sDirection.indexOf(\"up\") != -1) {\\n\\t\\tjindo.$Element(elSelectedBtn).addClass(\"asc\");\\n\\t\\tsToggledDirection = \"down\";\\n\\t} else {\\n\\t\\tjindo.$Element(elSelectedBtn).addClass(\"desc\");\\n\\t\\tsToggledDirection = \"up\";\\n\\t}\\n\\t\\n\\tjindo.$Fn.freeElement(elSelectedBtn);\\n\\tjindo.$Fn(jindo.$Fn(sortInclude, this).bind(sOrdering, sToggledDirection, sBtnId)).attach(elSelectedBtn, \"click\");\\n\\t\\n\\tif (nCurIncludePage < 11) {\\n\\t\\tif (nCurIncludePage == 1) {\\n\\t\\t\\tnCurIncludePage = 2;\\n\\t\\t}\\n\\t\\tmoveIncludePaging(1, false, e);\\n\\t} else {\\n\\t\\tmoveIncludePaging(1, true, e);\\n\\t}\\n\\t\\n}\\n\\n// 편입지수 페이징 이동\\nfunction moveIncludePaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\t// 현재페이지와 다른 링크를 눌렀을 경우에만 Ajax로 데이터를 받아온다.\\n\\tif (nCurIncludePage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\n\\tvar url = \"/world/worldIncludeListJson.naver?includeItemMenuId=\" + sIncludeItemMenuId + \"&direction=\" + sCurIncludeDirection + \"&ordering=\" + sCurIncludeSort + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"includeTable\");\\n\\t\\t\\tvar sHtmlFormat = \"<td class=\\\\\"tb_td\\\\\"><a href=\\\\\"/world/sise.naver?symbol=%s\\\\\">%s</a></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td2\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td3\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td4\\\\\"><span class=\\\\\"point_status\\\\\">%s%</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td5\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td6\\\\\"><span>%s</span></td>\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t// tr 전부 삭제\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar sSymb = v.symb;\\n\\t\\t\\t\\tvar sKnam = v.knam;\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sRate = formatNumberForFinance(v.rate, true);\\n\\t\\t\\t\\tvar sLast = formatNumberForFinance(v.last, false);\\n\\t\\t\\t\\tvar sGvol = formatNumberForFinance(v.gvol, false);\\n\\t\\t\\t\\tvar sTotAmt = formatNumberForFinance(v.totAmt, false);\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tsGvol = sGvol.substr(0, sGvol.length - 3);\\n\\t\\t\\t\\tsTotAmt = sTotAmt.substr(0, sTotAmt.length - 3);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sHtmlFormat).format(sSymb, sKnam, sLast, sDiff, sRate, sGvol, sTotAmt);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// 새로 페이징을 제작\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"includePaging\", \"includeLink\", moveIncludePaging, nPage, nMaxIncludePage);\\n\\t\\tnCurIncludePage = nPage;\\n\\t} else {\\n\\t\\tvar welCurLink = jindo.$Element(\"includeLink\" + nCurIncludePage);\\n\\t\\tif (welCurLink != null) {\\n\\t\\t\\twelCurLink.removeClass(\"on\");\\n\\t\\t}\\n\\t\\tjindo.$Element(\"includeLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurIncludePage = nPage;\\n\\t}\\n}\\n\\t\\n// 페이징을 새로 생성해주는 공통함수\\nfunction makePaging(pagingId, linkId, func, nPage, nMax) {\\n\\tvar welPaging = jindo.$Element(pagingId);\\n\\tvar sPrevFormat = \"<img src=\\\\\"https://ssl.pstatic.net/static/nfinance/bu_pgarL.gif\\\\\" width=\\\\\"3\\\\\" height=\\\\\"5\\\\\" alt=\\\\\"이전\\\\\"> 이전\";\\n\\tvar sNextFormat = \"다음 <img src=\\\\\"https://ssl.pstatic.net/static/nfinance/bu_pgarR.gif\\\\\" width=\\\\\"3\\\\\" height=\\\\\"5\\\\\" alt=\\\\\"다음\\\\\">\";\\n\\n\\t// 삭제 후 삽입\\n\\twelPaging.html(\"\");\\n\\t\\n\\t// 이전\\n\\tif (nPage > 10) {\\n\\t\\tvar welPrev = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelPrev.addClass(\"prev\");\\n\\t\\twelPrev.attr(\"href\", \"#\");\\n\\t\\tvar nPrevPage;\\n\\t\\tif (nPage % 10 == 0) {\\n\\t\\t\\tnPrevPage = nPage - 10;\\n\\t\\t} else {\\n\\t\\t\\tnPrevPage = nPage - 1;\\n\\t\\t}\\n\\n\\t\\tjindo.$Fn(jindo.$Fn(func).bind(nPrevPage, true)).attach(welPrev, \"click\");\\n\\t\\twelPrev.html(jindo.$S(sPrevFormat).format());\\n\\t\\t\\n\\t\\twelPaging.append(welPrev);\\n\\t}\\n\\t\\n\\t// 페이지\\n\\tvar nStart;\\n\\tvar nEnd;\\n\\t\\n\\tif (nPage % 10 == 0) {\\n\\t\\tnStart = nPage - 9;\\n\\t} else {\\n\\t\\tnStart = nPage; \\n\\t}\\n\\t\\n\\tif (nMax - nStart > 9) {\\n\\t\\tnEnd = nStart + 9;\\n\\t} else {\\n\\t\\tnEnd = nMax;\\n\\t}\\n\\t\\n\\tfor (var i = nStart; i <= nEnd; i++) {\\n\\t\\tvar welPage = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelPage.text(i + \"\");\\n\\t\\twelPage.attr(\"href\", \"#\");\\n\\t\\twelPage.attr(\"id\", linkId + i);\\n\\t\\twelPage.attr(\"tojson\", \"\");\\n\\t\\tjindo.$Fn(jindo.$Fn(func, this).bind(i, false), this).attach(welPage, \"click\");\\n\\t\\t\\n\\t\\tif (i == nPage) {\\n\\t\\t\\twelPage.addClass(\"on\");\\n\\t\\t}\\n\\t\\t\\n\\t\\twelPaging.append(welPage);\\n\\t}\\n\\t\\n\\t// 다음\\n\\tvar bMakeNext = false;\\n\\tif (nPage % 10 == 1) {\\n\\t\\tbMakeNext = nMax >= nPage + 10;\\n\\t} else if (nPage % 10 == 0){\\n\\t\\tbMakeNext = nMax - nPage > 0;\\n\\t}\\n\\t\\n\\tif (bMakeNext) {\\n\\t\\tvar welNext = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelNext.addClass(\"next\");\\n\\t\\twelNext.attr(\"href\", \"#\");\\n\\t\\tvar nNextPage;\\n\\t\\tif (nPage % 10 == 0) {\\n\\t\\t\\tnNextPage = nPage + 1;\\n\\t\\t} else {\\n\\t\\t\\tnNextPage = nPage + 10;\\n\\t\\t}\\n\\n\\t\\tjindo.$Fn(jindo.$Fn(func).bind(nNextPage, true)).attach(welNext, \"click\");\\n\\t\\twelNext.html(jindo.$S(sNextFormat).format());\\n\\n\\t\\twelPaging.append(welNext);\\t\\n\\t}\\n}\\n\\n// 일별시세 노출\\nfunction showDayQuoteList() {\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_day a\")).addClass(\"on\");\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_time a\")).removeClass(\"on\");\\n\\tjindo.$Element(\"dayTable\").show();\\n\\tjindo.$Element(\"timeTable\").hide();\\n\\tjindo.$Element(\"dayPaging\").show();\\n\\tjindo.$Element(\"timePaging\").hide();\\n}\\n\\n// 시간별시세 노출\\nfunction showTimeQuoteList() {\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_day a\")).removeClass(\"on\");\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_time a\")).addClass(\"on\");\\n\\tjindo.$Element(\"dayTable\").hide();\\n\\tjindo.$Element(\"timeTable\").show();\\n\\tjindo.$Element(\"dayPaging\").hide();\\n\\tjindo.$Element(\"timePaging\").show();\\n}\\n\\n// 선 차트 노출\\nfunction showChart(target) {\\n\\tvar directory = \"\";\\n\\t\\n\\tif (target == \"day\") {\\n\\t\\tdirectory = \"daily\";\\n\\t} else if (target == \"week\") {\\n\\t\\tdirectory = \"weekly\";\\n\\t} else if (target.indexOf(\"month\") == 0 || target.indexOf(\"year\") == 0) {\\n\\t\\tdirectory = target;\\n\\t}\\n\\t\\n\\tjindo.$A(jindo.$$(\"dl.line dd ul li\")).forEach(function(v) {\\n\\t\\tif (jindo.$Element(v).className() == target) {\\n\\t\\t\\tjindo.$Element(v).child()[0].addClass(\"on\");\\n\\t\\t\\tvar welChart = jindo.$Element(jindo.$$.getSingle(\"div.flash_area img\"));\\n\\t\\t\\twelChart.attr(\"src\", \"https://ssl.pstatic.net/imgfinance/chart/world/\" + directory + \"/NAS@IXIC.png?1688741844631\");\\n\\t\\t} else {\\n\\t\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t\\t}\\n\\t});\\n\\n\\tjindo.$A(jindo.$$(\"dl.bar dd ul li\")).forEach(function(v) {\\n\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t});\\n\\t\\n}\\n\\n// 봉 차트 노출\\nfunction showBarChart(target) {\\n\\tjindo.$A(jindo.$$(\"dl.bar dd ul li\")).forEach(function(v) {\\n\\t\\tif (jindo.$Element(v).className() == target) {\\n\\t\\t\\tjindo.$Element(v).child()[0].addClass(\"on\");\\n\\t\\t\\tvar welChart = jindo.$Element(jindo.$$.getSingle(\"div.flash_area img\"));\\n\\t\\t\\twelChart.attr(\"src\", \"https://ssl.pstatic.net/imgfinance/chart/world/candle/\" + target + \"/NAS@IXIC.png?1688741844631\");\\n\\t\\t} else {\\n\\t\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t\\t}\\n\\t});\\n\\n\\tjindo.$A(jindo.$$(\"dl.line dd ul li\")).forEach(function(v) {\\n\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t});\\n}\\n</script>\\n\\t<!-- Footer -->\\n\\t<div id=\"footer\">\\n\\t<ul>\\n\\t\\t<li class=\"first\">\\n\\t\\t\\t<a href=\"https://new-m.pay.naver.com/member/terms-policy/naver-financial-service\" onClick=\"clickcr(this, \\'fot.service\\', \\'\\', \\'\\', event);\" target=\"_blank\">이용약관</a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"https://new-m.pay.naver.com/member/terms-policy/privacy\" onClick=\"clickcr(this, \\'fot.privacy\\', \\'\\', \\'\\', event);\" target=\"_blank\"><strong>개인정보처리방침</strong></a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"/rules.naver\" onClick=\"clickcr(this, \\'fot.policy\\', \\'\\', \\'\\', event);\" target=\"_blank\">게시판 운영원칙</a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"https://help.naver.com/service/5617/category/bookmark?lang=ko\" onClick=\"clickcr(this, \\'fot.help\\', \\'\\', \\'\\', event);\" target=\"_blank\">증권 고객센터</a>\\n\\t\\t</li>\\n\\t</ul>\\n\\t<p class=\"desc\">\\n\\t\\t네이버파이낸셜(주)이 제공하는 금융 정보는 <a href=\"javascript:;\" onclick=\"togglePanelFooter(\\'footerPanel0\\');\" class=\"desc_help\">콘텐츠 제공업체</a>로부터 받는 투자 참고사항이며, 오류가 발생하거나 지연될 수 있습니다.<br/>\\n\\t\\t네이버파이낸셜(주)과 콘텐츠 제공업체는 제공된 정보에 의한 투자 결과에 법적인 책임을 지지 않습니다. 게시된 정보는 무단으로 배포할 수 없습니다.\\n\\t</p>\\n\\t<div id=\"footerPanel0\" class=\"provider_layer\" style=\"display:none\" tabindex=\"0\" onblur=\"hidePannel(\\'footerPanel0\\')\">\\n\\t\\t<strong class=\"provider_layer__tit\">네이버파이낸셜에 콘텐츠 제공</strong>\\n\\t\\t<div class=\"provider_layer__txt\">\\n\\t\\t\\t<strong>에프앤가이드</strong> 기업 및 재무정보<br>\\n\\t\\t\\t<strong>KG제로인</strong> 해외 시세, 시장지표 정보<br>\\n\\t\\t\\t<strong>한국예탁결제원</strong> 주주총회일, 전자투표 정보<br>\\n\\t\\t\\t<strong>인포스탁</strong> 국내 테마 정보\\n\\t\\t</div>\\n\\t\\t<div class=\"provider_layer__info\">\\n\\t\\t\\t<strong class=\"provider_layer__tit\">네이버에 콘텐츠 제공</strong>\\n\\t\\t\\t<div class=\"provider_layer__txt\">\\n\\t\\t\\t\\t<strong>코스콤</strong> 국내 시세 정보\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\t<button type=\"button\" class=\"button_close\" onclick=\"hidePannel(\\'footerPanel0\\')\">\\n\\t\\t\\t<img src=\"https://ssl.pstatic.net/static/nfinance/2022/footer_close.png\" width=\"20\" height=\"20\" alt=\"닫기\">\\n\\t\\t</button>\\n\\t</div>\\n\\t<address>\\n\\t\\t<a href=\"http://www.navercorp.com/\" target=\"_blank\" class=\"logo\" onClick=\"clickcr(this, \\'fot.nhn\\', \\'\\', \\'\\', event);\"><img src=\"https://ssl.pstatic.net/static/nfinance/img/logo_financial.png\" width=\"160\" height=\"12\" alt=\"NAVER FINANCIAL\"></a>\\n\\t</address>\\n\\t\\n\\t\\n\\t\\n</div>\\n\\n<script type=\"text/javascript\">\\nfunction isVisible(obj) {\\n    if (obj == document) return true\\n \\n    if (!obj) return false\\n    if (!obj.parentNode) return false\\n    if (obj.style) {\\n        if (obj.style.display == \\'none\\') return false\\n        if (obj.style.visibility == \\'hidden\\') return false\\n    }\\n \\n    if (window.getComputedStyle) {\\n        var style = window.getComputedStyle(obj, \"\")\\n        if (style.display == \\'none\\') return false\\n        if (style.visibility == \\'hidden\\') return false\\n    }\\n \\n    var style = obj.currentStyle\\n    if (style) {\\n        if (style[\\'display\\'] == \\'none\\') return false\\n        if (style[\\'visibility\\'] == \\'hidden\\') return false\\n    }\\n \\n    return isVisible(obj.parentNode)\\n}\\n\\nfunction isChildOf(myobj, containerObj) {\\n\\twhile(myobj != undefined) {\\n\\t\\tif (myobj == document.body) {\\n\\t\\t\\tbreak;\\n\\t\\t} \\n\\t\\tif (myobj == containerObj) {\\n\\t\\t\\treturn true;\\n\\t\\t}\\n\\t\\tmyobj = myobj.parentElement;\\n\\t}\\n\\treturn false;\\t\\n}\\n\\nfunction gnbLayerClose(e){\\n\\tvar target = e.target ? e.target : e.srcElement;\\n\\tif (isVisible(document.getElementById(\\'gnb_service_lyr\\')) || isVisible(document.getElementById(\\'gnb_notice_lyr\\')) ||isVisible(document.getElementById(\\'gnb_my_lyr\\')) ) {\\n\\t\\tif (!isChildOf(target, document.getElementById(\\'gnb\\'))) {\\n\\t\\t\\tgnbAllLayerClose();\\n\\t\\t}\\n\\t}\\t\\n}\\n\\nfunction showPannel(layerId){\\n\\tvar layer = jindo.$(layerId);\\n\\tlayer.style.display=\\'block\\';\\n\\n\\tif (layerId == \"summary_lyr\") {\\n\\t\\tvar layerHeight = jindo.$Element(layer).height();\\n\\t\\tjindo.$Element(\"summary_ifr\").height(layerHeight);\\n\\t}\\n}\\n\\nfunction hidePannel(layerId){\\n\\tvar layer = jindo.$(layerId);\\n\\tlayer.style.display=\\'none\\';\\n}\\n\\nfunction togglePanelFooter(layerId) {\\n\\tvar elTargetLayer = jindo.$Element(jindo.$$.getSingle(\"#\" + layerId));\\n\\n\\tif (elTargetLayer != null) {\\n\\t\\tif (elTargetLayer.visible()) {\\n\\t\\t\\thidePannel(layerId);\\n\\t\\t} else {\\n\\t\\t\\tshowPannel(layerId);\\n\\t\\t}\\n\\t}\\n}\\n\\nvar isIE = (navigator.userAgent.toLowerCase().indexOf(\"msie\")!=-1 && window.document.all) ? true:false;\\nif (isIE) {\\n\\tdocument.attachEvent(\\'onmousedown\\', gnbLayerClose);\\n} else {\\n\\twindow.addEventListener(\\'mousedown\\', gnbLayerClose);\\n}\\n</script>\\n\\n\\n\\n</div>  \\n</body>\\n</html>\\n'\n\n\n\nhtml = bs(response.text, 'html.parser')\nhtml_table = html.select(\"table\")\ntable = pd.read_html(str(html_table))\nprint('파싱된 테이블의 개수 :', len(table))\n\n파싱된 테이블의 개수 : 3\n\n\n\ntable[0]\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      전일 13,679.04\n      고가 13,730.72\n      52주 최고 13,864.06\n    \n    \n      1\n      시가 13,668.07\n      저가 13,657.72\n      52주 최저 10,088.83\n    \n  \n\n\n\n\n\ntable[1]\n\n\n\n\n\n  \n    \n      \n      일자\n      종가\n      전일대비\n      시가\n      고가\n      저가\n    \n  \n  \n    \n      0\n      2023.07.07\n      13681.61\n      2.57\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      1\n      2023.07.06\n      13679.04\n      112.61\n      13653.17\n      13689.52\n      13567.26\n    \n    \n      2\n      2023.07.05\n      13791.65\n      25.12\n      13772.10\n      13844.50\n      13764.25\n    \n    \n      3\n      2023.07.03\n      13816.77\n      28.85\n      13798.70\n      13839.09\n      13773.41\n    \n    \n      4\n      2023.06.30\n      13787.92\n      196.59\n      13719.98\n      13816.68\n      13716.16\n    \n    \n      5\n      2023.06.29\n      13591.33\n      0.42\n      13592.36\n      13618.53\n      13540.26\n    \n    \n      6\n      2023.06.28\n      13591.75\n      36.08\n      13506.02\n      13654.14\n      13495.73\n    \n    \n      7\n      2023.06.27\n      13555.67\n      219.89\n      13389.25\n      13578.80\n      13366.97\n    \n    \n      8\n      2023.06.26\n      13335.78\n      156.74\n      13468.75\n      13573.57\n      13334.42\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n  \n\n\n\n\n\ntable[2]\n\n\n\n\n\n  \n    \n      \n      업체명\n      거래량\n      전일비\n    \n  \n  \n  \n\n\n\n\n\ntable[1].dropna()\n\n\n\n\n\n  \n    \n      \n      일자\n      종가\n      전일대비\n      시가\n      고가\n      저가\n    \n  \n  \n    \n      0\n      2023.07.07\n      13681.61\n      2.57\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      1\n      2023.07.06\n      13679.04\n      112.61\n      13653.17\n      13689.52\n      13567.26\n    \n    \n      2\n      2023.07.05\n      13791.65\n      25.12\n      13772.10\n      13844.50\n      13764.25\n    \n    \n      3\n      2023.07.03\n      13816.77\n      28.85\n      13798.70\n      13839.09\n      13773.41\n    \n    \n      4\n      2023.06.30\n      13787.92\n      196.59\n      13719.98\n      13816.68\n      13716.16\n    \n    \n      5\n      2023.06.29\n      13591.33\n      0.42\n      13592.36\n      13618.53\n      13540.26\n    \n    \n      6\n      2023.06.28\n      13591.75\n      36.08\n      13506.02\n      13654.14\n      13495.73\n    \n    \n      7\n      2023.06.27\n      13555.67\n      219.89\n      13389.25\n      13578.80\n      13366.97\n    \n    \n      8\n      2023.06.26\n      13335.78\n      156.74\n      13468.75\n      13573.57\n      13334.42\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n  \n\n\n\n\n\ndf = pd.DataFrame()\nsise_url = 'https://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#'  \nfor page in range(1, 500):\n    page_url = '{}&page={}'.format(sise_url, page)\n    print(page_url)\n\n    # 위에서 했던 일련의 과정들을 각 url에 대해서 (99페이지에 대해서 반복)\n    response = requests.get(page_url, headers=headers)\n    html = bs(response.text, 'html.parser')\n    html_table = html.select(\"table\")\n    table = pd.read_html(str(html_table))\n\n    # 현재 얻은 데이터프레임을 기존 데이터프레임에 누적.\n    df = df.append(table[1].dropna())\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=1\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=2\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=3\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=4\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=5\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=6\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=7\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=8\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=9\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=10\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=11\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=12\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=13\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=14\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=15\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=16\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=17\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=18\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=19\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=20\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=21\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=22\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=23\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=24\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=25\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=26\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=27\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=28\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=29\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=30\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=31\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=32\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=33\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=34\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=35\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=36\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=37\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=38\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=39\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=40\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=41\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=42\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=43\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=44\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=45\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=46\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=47\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=48\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=49\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=50\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=51\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=52\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=53\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=54\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=55\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=56\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=57\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=58\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=59\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=60\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=61\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=62\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=63\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=64\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=65\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=66\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=67\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=68\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=69\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=70\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=71\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=72\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=73\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=74\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=75\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=76\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=77\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=78\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=79\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=80\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=81\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=82\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=83\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=84\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=85\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=86\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=87\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=88\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=89\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=90\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=91\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=92\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=93\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=94\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=95\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=96\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=97\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=98\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=99\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=100\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=101\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=102\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=103\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=104\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=105\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=106\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=107\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=108\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=109\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=110\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=111\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=112\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=113\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=114\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=115\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=116\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=117\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=118\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=119\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=120\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=121\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=122\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=123\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=124\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=125\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=126\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=127\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=128\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=129\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=130\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=131\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=132\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=133\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=134\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=135\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=136\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=137\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=138\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=139\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=140\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=141\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=142\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=143\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=144\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=145\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=146\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=147\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=148\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=149\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=150\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=151\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=152\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=153\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=154\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=155\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=156\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=157\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=158\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=159\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=160\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=161\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=162\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=163\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=164\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=165\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=166\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=167\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=168\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=169\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=170\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=171\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=172\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=173\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=174\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=175\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=176\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=177\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=178\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=179\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=180\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=181\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=182\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=183\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=184\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=185\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=186\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=187\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=188\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=189\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=190\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=191\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=192\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=193\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=194\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=195\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=196\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=197\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=198\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=199\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=200\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=201\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=202\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=203\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=204\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=205\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=206\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=207\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=208\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=209\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=210\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=211\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=212\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=213\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=214\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=215\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=216\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=217\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=218\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=219\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=220\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=221\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=222\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=223\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=224\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=225\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=226\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=227\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=228\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=229\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=230\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=231\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=232\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=233\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=234\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=235\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=236\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=237\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=238\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=239\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=240\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=241\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=242\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=243\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=244\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=245\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=246\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=247\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=248\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=249\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=250\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=251\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=252\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=253\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=254\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=255\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=256\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=257\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=258\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=259\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=260\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=261\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=262\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=263\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=264\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=265\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=266\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=267\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=268\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=269\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=270\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=271\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=272\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=273\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=274\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=275\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=276\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=277\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=278\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=279\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=280\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=281\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=282\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=283\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=284\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=285\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=286\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=287\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=288\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=289\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=290\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=291\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=292\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=293\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=294\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=295\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=296\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=297\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=298\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=299\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=300\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=301\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=302\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=303\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=304\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=305\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=306\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=307\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=308\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=309\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=310\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=311\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=312\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=313\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=314\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=315\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=316\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=317\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=318\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=319\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=320\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=321\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=322\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=323\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=324\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=325\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=326\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=327\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=328\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=329\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=330\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=331\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=332\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=333\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=334\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=335\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=336\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=337\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=338\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=339\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=340\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=341\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=342\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=343\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=344\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=345\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=346\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=347\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=348\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=349\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=350\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=351\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=352\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=353\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=354\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=355\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=356\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=357\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=358\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=359\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=360\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=361\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=362\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=363\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=364\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=365\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=366\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=367\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=368\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=369\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=370\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=371\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=372\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=373\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=374\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=375\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=376\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=377\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=378\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=379\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=380\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=381\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=382\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=383\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=384\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=385\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=386\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=387\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=388\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=389\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=390\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=391\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=392\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=393\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=394\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=395\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=396\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=397\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=398\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=399\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=400\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=401\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=402\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=403\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=404\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=405\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=406\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=407\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=408\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=409\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=410\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=411\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=412\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=413\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=414\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=415\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=416\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=417\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=418\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=419\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=420\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=421\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=422\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=423\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=424\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=425\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=426\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=427\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=428\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=429\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=430\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=431\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=432\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=433\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=434\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=435\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=436\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=437\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=438\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=439\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=440\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=441\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=442\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=443\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=444\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=445\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=446\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=447\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=448\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=449\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=450\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=451\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=452\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=453\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=454\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=455\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=456\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=457\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=458\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=459\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=460\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=461\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=462\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=463\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=464\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=465\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=466\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=467\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=468\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=469\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=470\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=471\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=472\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=473\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=474\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=475\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=476\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=477\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=478\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=479\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=480\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=481\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=482\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=483\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=484\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=485\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=486\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=487\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=488\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=489\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=490\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=491\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=492\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=493\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=494\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=495\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=496\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=497\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=498\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=499\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      일자\n      종가\n      전일대비\n      시가\n      고가\n      저가\n    \n  \n  \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n  \n\n100 rows × 6 columns\n\n\n\n\ndf = df.dropna()\n# df = df.iloc[0:30] \ndf = df.sort_values(by='일자')\ndf\n\n\n\n\n\n  \n    \n      \n      일자\n      종가\n      전일대비\n      시가\n      고가\n      저가\n    \n  \n  \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      0\n      2023.07.07\n      13683.99\n      4.95\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13687.15\n      8.11\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13683.99\n      4.95\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13687.06\n      8.02\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13684.51\n      5.47\n      13668.07\n      13730.72\n      13657.72\n    \n  \n\n4990 rows × 6 columns\n\n\n\n\nplt.figure(figsize=(15, 5)) \nplt.title('Celltrion (close)')\nplt.xticks(rotation=45) \nplt.plot(df['일자'], df['종가'], 'co-')\nplt.grid(color='gray', linestyle='--')\nplt.show()"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html",
    "title": "PyG lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "",
    "text": "import torch_geometric\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport torch"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#정보",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#정보",
    "title": "PyG lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "정보",
    "text": "정보\n- 기본정보: ENZYMES dataset\n\n(ChatGPT) ENZYMES는 그래프 분류를 위한 벤치마크 데이터셋 중 하나입니다. 이 데이터셋은 600개의 그래프로 구성되어 있으며, 6개의 클래스로 분류됩니다. 각 그래프는 효소(enzyme) 분자의 구조를 나타내며, 그래프의 노드는 원자(atom)를 나타내고, 엣지(edge)는 원자 간의 연결을 나타냅니다. ENZYMES 데이터셋은 화학 및 생물 정보학 분야에서 그래프 분류 알고리즘의 성능을 평가하기 위해 사용될 수 있습니다. 그래프 분류 알고리즘은 주어진 그래프를 특정 클래스 레이블로 분류하는 작업을 수행하는데 사용됩니다. 예를 들어, ENZYMES 데이터셋의 그래프는 특정 효소 종류를 나타내며, 그래프 분류 알고리즘은 주어진 효소 그래프가 어떤 종류의 효소인지 예측할 수 있습니다. PyG를 사용하여 ENZYMES 데이터셋을 초기화하면 해당 데이터셋을 다운로드하고 필요한 전처리를 자동으로 수행할 수 있습니다. 그래프 데이터를 다루는 머신 러닝 모델을 구축하고 훈련시키기 위해 ENZYMES 데이터셋을 사용할 수 있습니다.\n\n\ndataset # 데이터셋 이름\n\nENZYMES(600)\n\n\n\nlen(dataset) # 이 데이터셋에는 600개의 그래프가 있음\n\n600\n\n\n\ndataset.num_classes # 6개의 클래스\n\n6\n\n\n\ndataset.num_node_features # 각 노드에는 3개의 피처가 있음\n\n3\n\n\n- 600개의 그래프중 첫번째 그래프에 접근\n\ndataset[0]\n\nData(edge_index=[2, 168], x=[37, 3], y=[1])\n\n\n\nx=[37, 3]: \\(|{\\cal V}|=37\\), \\(f \\in \\mathbb{R}^3\\)\nedge_index=[2, 168]: \\(|{\\cal E}|=168\\)"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-분리",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-분리",
    "title": "PyG lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "Train/Test 분리",
    "text": "Train/Test 분리\n- 600개의 그래프중 540를 train으로, 60개를 test로\n\ntrain_dataset = dataset[:540]\ntest_dataset = dataset[540:]"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#정보-1",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#정보-1",
    "title": "PyG lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "정보",
    "text": "정보\n\nChatGPT: Cora는 그래프 분류를 위한 벤치마크 데이터셋 중 하나로, PyG에서도 사용할 수 있습니다. 이 데이터셋은 기계 학습 및 정보 검색 분야에서 널리 사용되는 학술 논문들의 인용 네트워크를 나타냅니다. Cora 데이터셋은 컴퓨터 과학 분야의 논문을 대상으로 합니다. 각 논문은 그래프의 노드로 표현되며, 노드는 논문을 나타냅니다. 노드 간의 엣지는 논문들 사이의 인용 관계를 나타냅니다. 따라서 Cora 데이터셋은 논문의 텍스트 기반 정보와 인용 관계에 대한 그래프 구조를 제공합니다. Cora 데이터셋은 7개의 클래스로 분류되며, 각 논문은 특성 벡터(feature vector)로 표현됩니다. 이 특성 벡터에는 논문의 단어 등 다양한 정보가 포함될 수 있습니다. PyG를 사용하여 Cora 데이터셋을 초기화하면 해당 데이터셋을 다운로드하고 전처리를 자동으로 수행할 수 있습니다. 이를 통해 머신 러닝 모델을 훈련시켜 Cora 데이터셋의 논문을 분류하거나 다양한 작업을 수행할 수 있습니다.\n\n- 기본정보\n\nlen(dataset) # 하나의 그래프가 있음\n\n1\n\n\n\ndataset.num_classes # 7개의 클래스가 있음\n\n7\n\n\n\ndataset.num_node_features # 각 노드는 1433개의 특징이 있음. (논문에 포함된 단어등 다양한 특성이 담겨있을 수 있음) \n\n1433\n\n\n- 그래프에 접근\n\ndataset[0] # 기본정보\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n\n\n\nx=[2708, 1433]: 2708개의 논문이 있고, 각 논문은 1433개의 특징벡터들로 이루어져 있음.\nedge_index=[2, 10556]: 논문간의 인용은 약 10556.\ny=[2708]:\n\n\ndataset[0].x.shape # 2708개의 논문이 있고 1433개의 특징벡터를 가짐\n\ntorch.Size([2708, 1433])\n\n\n\ndataset[0].y.unique() # 논문이 7개의 카테고리로 분류되는듯\n\ntensor([0, 1, 2, 3, 4, 5, 6])"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-이미-분리되어-있음",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-이미-분리되어-있음",
    "title": "PyG lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "Train/Test (이미 분리되어 있음)",
    "text": "Train/Test (이미 분리되어 있음)\n\ndataset[0].train_mask \n# dataset[0].train_mask 는 True, False로 이루어져 있는 길이가 2708(=노드수=논문수)인 벡터\n# 여기에서 True인 노드만 훈련함\n\ntensor([ True,  True,  True,  ..., False, False, False])\n\n\n\ndataset[0].train_mask.sum() # 140개의 노드만 훈련함? \n\ntensor(140)\n\n\n\ndataset[0].val_mask.sum() # val은 500개의 노드?\n\ntensor(500)\n\n\n\ndataset[0].test_mask.sum() # test set은 1000?\n\ntensor(1000)\n\n\n\ndataset.edge_index\n\ntensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-20-LLM.html",
    "href": "posts/RESEARCHES/2023-07-20-LLM.html",
    "title": "LLM",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport torch\nfrom transformers import GPT2Tokenizer, TFGPT2LMHeadModel\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nimport copy\n\n\nimport os\nimport re\nimport string\nimport json\nimport numpy as np\nfrom sklearn import metrics\nfrom bs4 import BeautifulSoup\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option(\"display.max_columns\", None)\n\n\n\nData\nref: kaggle\n\ndf2 = pd.read_csv('./dataset/twitter_MBTI.csv').iloc[:,1:]\n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      text\n      label\n    \n  \n  \n    \n      0\n      @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n      intj\n    \n    \n      1\n      @Hispanthicckk Being you makes you look cute||...\n      intj\n    \n    \n      2\n      @Alshymi Les balles sont réelles et sont tirée...\n      intj\n    \n    \n      3\n      I'm like entp but idiotic|||Hey boy, do you wa...\n      intj\n    \n    \n      4\n      @kaeshurr1 Give it to @ZargarShanif ... He has...\n      intj\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      7806\n      @sobsjjun God,,pls take care 😕|||@sobsjjun Hir...\n      intp\n    \n    \n      7807\n      @Ignis_02 wow last time i got intp https://t.c...\n      intp\n    \n    \n      7808\n      @akupilled A 100%|||@akupilled That SOMEONE wi...\n      entp\n    \n    \n      7809\n      If you’re #INTJ this one is for you | What is ...\n      infj\n    \n    \n      7810\n      @harry__lambert @gucci hey can you dm me a pic...\n      istp\n    \n  \n\n7811 rows × 2 columns\n\n\n\n\ndf_t = pd.read_csv('./dataset/mbti_1.csv')\n\n\ndf_t\n\n\n\n\n\n  \n    \n      \n      type\n      posts\n    \n  \n  \n    \n      0\n      INFJ\n      'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n    \n    \n      1\n      ENTP\n      'I'm finding the lack of me in these posts ver...\n    \n    \n      2\n      INTP\n      'Good one  _____   https://www.youtube.com/wat...\n    \n    \n      3\n      INTJ\n      'Dear INTP,   I enjoyed our conversation the o...\n    \n    \n      4\n      ENTJ\n      'You're fired.|||That's another silly misconce...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      8670\n      ISFP\n      'https://www.youtube.com/watch?v=t8edHB_h908||...\n    \n    \n      8671\n      ENFP\n      'So...if this thread already exists someplace ...\n    \n    \n      8672\n      INTP\n      'So many questions when i do these things.  I ...\n    \n    \n      8673\n      INFP\n      'I am very conflicted right now when it comes ...\n    \n    \n      8674\n      INFP\n      'It has been too long since I have been on per...\n    \n  \n\n8675 rows × 2 columns\n\n\n\n\ndf_t.iloc[1,:]\n\ntype                                                  ENTP\nposts    'I'm finding the lack of me in these posts ver...\nName: 1, dtype: object\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df2['label'],color='grey', align='left', rwidth=0.8,bins=16)\n\n(array([ 781.,  811.,  279.,  577., 1057., 1282.,  518.,  729.,  259.,\n         364.,   81.,  105.,  327.,  367.,  100.,  174.]),\n array([ 0.    ,  0.9375,  1.875 ,  2.8125,  3.75  ,  4.6875,  5.625 ,\n         6.5625,  7.5   ,  8.4375,  9.375 , 10.3125, 11.25  , 12.1875,\n        13.125 , 14.0625, 15.    ]),\n <BarContainer object of 16 artists>)\n\n\n\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df_t['type'],color='grey', align='left', rwidth=0.8,bins=16)\n\n(array([1470.,  685., 1304., 1091.,  231.,  190., 1832.,  675.,  271.,\n         337.,  166.,  205.,   89.,   48.,   39.,   42.]),\n array([ 0.    ,  0.9375,  1.875 ,  2.8125,  3.75  ,  4.6875,  5.625 ,\n         6.5625,  7.5   ,  8.4375,  9.375 , 10.3125, 11.25  , 12.1875,\n        13.125 , 14.0625, 15.    ]),\n <BarContainer object of 16 artists>)\n\n\n\n\n\n\ndf2['word_count'] = df2['text'].apply(lambda x: len(x.split()))\n\n\ndf_t['word_count'] = df_t['posts'].apply(lambda x: len(x.split()))\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df2['word_count'],color='lightblue', align='left', rwidth=0.8,bins=100)\n\n(array([109.,  94.,  89.,  99.,  99., 102., 153., 106., 124., 149., 151.,\n        162., 140., 161., 155., 221., 229., 218., 210., 202., 220., 209.,\n        192., 240., 207., 188., 184., 186., 182., 187., 185., 160., 174.,\n        155., 133., 116., 121., 123., 130., 118.,  99.,  90.,  91.,  84.,\n         88.,  68.,  64.,  57.,  70.,  58.,  42.,  44.,  53.,  43.,  47.,\n         42.,  30.,  37.,  42.,  15.,  21.,  27.,  26.,  14.,  18.,   9.,\n         13.,  19.,  14.,  20.,   7.,  12.,   3.,  11.,   4.,   3.,   4.,\n          4.,   1.,   4.,   5.,   3.,   3.,   5.,   2.,   4.,   2.,   0.,\n          1.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   1.,\n          1.]),\n array([ 201.  ,  242.43,  283.86,  325.29,  366.72,  408.15,  449.58,\n         491.01,  532.44,  573.87,  615.3 ,  656.73,  698.16,  739.59,\n         781.02,  822.45,  863.88,  905.31,  946.74,  988.17, 1029.6 ,\n        1071.03, 1112.46, 1153.89, 1195.32, 1236.75, 1278.18, 1319.61,\n        1361.04, 1402.47, 1443.9 , 1485.33, 1526.76, 1568.19, 1609.62,\n        1651.05, 1692.48, 1733.91, 1775.34, 1816.77, 1858.2 , 1899.63,\n        1941.06, 1982.49, 2023.92, 2065.35, 2106.78, 2148.21, 2189.64,\n        2231.07, 2272.5 , 2313.93, 2355.36, 2396.79, 2438.22, 2479.65,\n        2521.08, 2562.51, 2603.94, 2645.37, 2686.8 , 2728.23, 2769.66,\n        2811.09, 2852.52, 2893.95, 2935.38, 2976.81, 3018.24, 3059.67,\n        3101.1 , 3142.53, 3183.96, 3225.39, 3266.82, 3308.25, 3349.68,\n        3391.11, 3432.54, 3473.97, 3515.4 , 3556.83, 3598.26, 3639.69,\n        3681.12, 3722.55, 3763.98, 3805.41, 3846.84, 3888.27, 3929.7 ,\n        3971.13, 4012.56, 4053.99, 4095.42, 4136.85, 4178.28, 4219.71,\n        4261.14, 4302.57, 4344.  ]),\n <BarContainer object of 100 artists>)\n\n\n\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df_t['word_count'],color='lightblue', align='left', rwidth=0.8,bins=100)\n\n(array([  2.,   1.,   4.,   2.,   1.,   1.,   3.,   3.,   2.,   9.,   4.,\n          7.,   4.,   8.,   9.,   9.,  10.,  13.,   8.,  17.,  13.,  17.,\n         18.,  22.,  28.,  16.,  22.,  24.,  31.,  30.,  36.,  35.,  31.,\n         26.,  42.,  38.,  51.,  43.,  43.,  53.,  70.,  53.,  70.,  89.,\n         66.,  88.,  85.,  67., 104., 100., 111., 116.,  96., 139., 108.,\n        135., 138., 128., 167., 145., 156., 187., 185., 161., 211., 207.,\n        211., 249., 224., 203., 243., 235., 220., 206., 260., 239., 212.,\n        210., 206., 227., 211., 180., 157., 179., 155., 153., 107., 126.,\n         84.,  66.,  52.,  37.,  39.,  33.,  12.,   8.,   5.,   4.,   3.,\n          1.]),\n array([   4.  ,   22.77,   41.54,   60.31,   79.08,   97.85,  116.62,\n         135.39,  154.16,  172.93,  191.7 ,  210.47,  229.24,  248.01,\n         266.78,  285.55,  304.32,  323.09,  341.86,  360.63,  379.4 ,\n         398.17,  416.94,  435.71,  454.48,  473.25,  492.02,  510.79,\n         529.56,  548.33,  567.1 ,  585.87,  604.64,  623.41,  642.18,\n         660.95,  679.72,  698.49,  717.26,  736.03,  754.8 ,  773.57,\n         792.34,  811.11,  829.88,  848.65,  867.42,  886.19,  904.96,\n         923.73,  942.5 ,  961.27,  980.04,  998.81, 1017.58, 1036.35,\n        1055.12, 1073.89, 1092.66, 1111.43, 1130.2 , 1148.97, 1167.74,\n        1186.51, 1205.28, 1224.05, 1242.82, 1261.59, 1280.36, 1299.13,\n        1317.9 , 1336.67, 1355.44, 1374.21, 1392.98, 1411.75, 1430.52,\n        1449.29, 1468.06, 1486.83, 1505.6 , 1524.37, 1543.14, 1561.91,\n        1580.68, 1599.45, 1618.22, 1636.99, 1655.76, 1674.53, 1693.3 ,\n        1712.07, 1730.84, 1749.61, 1768.38, 1787.15, 1805.92, 1824.69,\n        1843.46, 1862.23, 1881.  ]),\n <BarContainer object of 100 artists>)\n\n\n\n\n\nhttps://wikidocs.net/152922\nhttps://dacon.io/codeshare/5619\nhttps://www.kaggle.com/code/debarshichanda/bert-multi-label-text-classification\nhttps://www.kaggle.com/datasets/datasnaek/mbti-type?select=mbti_1.csv\n\none = pd.get_dummies(df2['label'], prefix='label')\n\n\none_t = pd.get_dummies(df_t['type'], prefix='type')\n\n\ndf3 = pd.concat([df2,one],axis=1)\n\n\ndf_t1 = pd.concat([df_t,one_t],axis=1)\n\n\ndf3.head()\n\n\n\n\n\n  \n    \n      \n      text\n      label\n      word_count\n      label_enfj\n      label_enfp\n      label_entj\n      label_entp\n      label_esfj\n      label_esfp\n      label_estj\n      label_estp\n      label_infj\n      label_infp\n      label_intj\n      label_intp\n      label_isfj\n      label_isfp\n      label_istj\n      label_istp\n    \n  \n  \n    \n      0\n      @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n      intj\n      2351\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      @Hispanthicckk Being you makes you look cute||...\n      intj\n      943\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      @Alshymi Les balles sont réelles et sont tirée...\n      intj\n      1646\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      I'm like entp but idiotic|||Hey boy, do you wa...\n      intj\n      923\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      @kaeshurr1 Give it to @ZargarShanif ... He has...\n      intj\n      1024\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndf_t1.head()\n\n\n\n\n\n  \n    \n      \n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      INFJ\n      'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      ENTP\n      'I'm finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      INTP\n      'Good one  _____   https://www.youtube.com/wat...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      INTJ\n      'Dear INTP,   I enjoyed our conversation the o...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      ENTJ\n      'You're fired.|||That's another silly misconce...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndef clean_text(text):\n    text = re.sub(r'\\:(.*?)\\:','',text)\n    text = str(text).lower()    #Making Text Lowercase\n    text = re.sub('\\[.*?\\]', '', text)\n    #The next 2 lines remove html text\n    text = BeautifulSoup(text, 'lxml').get_text()\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n    return text\n\ndef clean_contractions(text, mapping):\n    '''Clean contraction using contraction mapping'''    \n    specials = [\"’\", \"‘\", \"´\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    for word in mapping.keys():\n        if \"\"+word+\"\" in text:\n            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n    #Remove Punctuations\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n    text = re.sub(r'[\" \"]+', \" \", text)\n    return text\n\ndef clean_special_chars(text, punct, mapping):\n    '''Cleans special characters present(if any)'''   \n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    \n    for p in punct:\n        text = text.replace(p, f' {p} ')\n    \n    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n    for s in specials:\n        text = text.replace(s, specials[s])\n    \n    return text\n\ndef correct_spelling(x, dic):\n    '''Corrects common spelling errors'''   \n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x\n\ndef remove_space(text):\n    '''Removes awkward spaces'''   \n    #Removes awkward spaces \n    text = text.strip()\n    text = text.split()\n    return \" \".join(text)\n\ndef text_preprocessing_pipeline(text):\n    '''Cleaning and parsing the text.'''\n    text = clean_text(text)\n    text = clean_contractions(text, contraction_mapping)\n    text = clean_special_chars(text, punct, punct_mapping)\n    text = correct_spelling(text, mispell_dict)\n    text = remove_space(text)\n    return text\n\n\ndf_t2 = df_t1.copy().reset_index()\n\n\ncontraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n\npunct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\npunct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n                'demonetisation': 'demonetization'}\n\n\ndf_t2['posts'] = df_t2['posts'].apply(text_preprocessing_pipeline)\n\n\ndf_t2.head()\n\n\n\n\n\n  \n    \n      \n      index\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      INFJ\n      http mediatumblrcom jpg enfp and intj moments ...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENTP\n      i am finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INTP\n      good one https dozens of different plant speci...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      INTJ\n      dear intp i enjoyed our conversation the other...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      you are fired that is another silly misconcept...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\nlen(df_t2) * 0.6\n\n5205.0\n\n\n\nlen(df_t2) - len(df_t2) * 0.2\n\n6940.0\n\n\n\ndf_t_train = df_t2[:5205].reset_index().iloc[:,1:].rename(columns={'index':'ids'})\ndf_t_valid = df_t2[5205:6240].reset_index().iloc[:,2:].reset_index().rename(columns={'index':'ids'})\ndf_t_test = df_t2[6240:].reset_index().iloc[:,2:].reset_index().rename(columns={'index':'ids'})\n\n\ndf_t_train.head()\n\n\n\n\n\n  \n    \n      \n      ids\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      INFJ\n      http mediatumblrcom jpg enfp and intj moments ...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENTP\n      i am finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INTP\n      good one https dozens of different plant speci...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      INTJ\n      dear intp i enjoyed our conversation the other...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      you are fired that is another silly misconcept...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndf_t_valid.head()\n\n\n\n\n\n  \n    \n      \n      ids\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      ENFP\n      people attempt to label anything as a disorder...\n      1067\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENFP\n      well this would be consistent with my forums n...\n      1342\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INFP\n      why i feel like this todays world is full of c...\n      952\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      ENFP\n      hi leaves long time no see my advice would be ...\n      1204\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      velcome my husband is intj we get along very w...\n      838\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\nprint(df_t_train.shape)\nprint(df_t_valid.shape)\nprint(df_t_test.shape)\n\n(5205, 20)\n(1035, 20)\n(2435, 20)\n\n\n\nMAX_LEN = 1000\nTRAIN_BATCH_SIZE = 64\nVALID_BATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 0.01\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\n\n\ntarget_cols = [col for col in df_t_train.columns if col not in ['ids','posts','type','word_count']]\n\n\n# target_cols = [text.replace('type_', '') for text in target_cols]\n\n\nclass BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.posts\n        self.tokenizer = tokenizer\n        self.targets = df[target_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }\n\n\ntrain_dataset = BERTDataset(df_t_train, tokenizer, MAX_LEN)\ntest_dataset = BERTDataset(df_t_test, tokenizer, MAX_LEN)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, \n                          num_workers=4, shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, \n                          num_workers=4, shuffle=False, pin_memory=True)\n\n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.roberta = AutoModel.from_pretrained('roberta-base')\n#         self.l2 = torch.nn.Dropout(0.3)\n        self.fc = torch.nn.Linear(768,16)\n    \n    def forward(self, index, mask, token_type_ids):\n        _, features = self.roberta(index, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n#         output_2 = self.l2(output_1)\n        output = self.fc(features)\n        return output\n\nmodel = BERTClass()\nmodel.to(device);\n\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\ndef loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\n\noptimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE, weight_decay=1e-6)\n\n\ndef train(epoch):\n    model.train()\n    for _,data in enumerate(train_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        if _%500 == 0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor epoch in range(EPOCHS):\n    train(epoch)\n\nIndexError: index out of range in self\n\n\n\ndef validation():\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(valid_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets\n\n\noutputs, targets = validation()\n\n\nnp.array(outputs)[:10]\n\n\nnp.array(outputs) >= 0.1\n\n\ndef one_hot_to_integer(one_hot_data):\n    return np.argmax(one_hot_data) + 1\n\n\nret = [one_hot_to_integer(sample) for sample in targets]\n\n\nret[:10]\n\n\ntst = [0.05589867, 0.01052203, 0.13754041, 0.0588008 , 0.01005199,\n        0.0295825 , 0.00209739, 0.02436998, 0.07758361, 0.10916023,\n        0.07828864, 0.23720771, 0.00276894, 0.02201499, 0.08916565,\n        0.01853185]\n\n\nsum(tst)\n\n\nnp.argmax([0.05589867, 0.01052203, 0.13754041, 0.0588008 , 0.01005199,\n        0.0295825 , 0.00209739, 0.02436998, 0.07758361, 0.10916023,\n        0.07828864, 0.23720771, 0.00276894, 0.02201499, 0.08916565,\n        0.01853185])\n\n\nnp.array(outputs).shape\n\n\nplt.hist(np.argmax(outputs,axis=1))\n\n\n\noutputs1 = np.array(outputs) >= 0.5\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score (Micro) = {f1_score_micro}\")\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, there ;)\n참고\n\nsudo reeboot 로 재부팅 후\njupyter notebook & 입력 후\nenter 로 나가서\nexit 하기\n재부팅시 drop box open ~ (~/.dropbox-dist/dropboxd)\n\n\nnvidia-smi 로 GPU 상태 확인 ! 안 켜져 있다면? (sudo ./NVIDIA-Linux-x86_64-495.46.run(tab누르면 나옴))\n\nterminal check\n\ntop\nnvidia-smi\nps aux | grep jupyter-lab\n필요없는 거 ’kill 0000’로 프로세스 끄기"
  }
]
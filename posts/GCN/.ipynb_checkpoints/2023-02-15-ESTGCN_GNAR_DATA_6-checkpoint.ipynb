{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6c8f0bf9-e110-4e30-8596-b2dd384e79e0",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"GNAR lag 1 Randomly Missing comparison Table by Missing Rate\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-02-15\"\n",
    "categories:\n",
    "  - ST-GCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf50ae2-58ec-4c6e-9cc8-393c473767eb",
   "metadata": {},
   "source": [
    "> GNAR fiveNet,fivenodes lag 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463f6e7-0b6c-490d-b7ee-4022ce4345a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90af573-4bc0-4c9e-ad94-e9739160055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "# scipy \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import rpy2.robjects.numpy2ri as rpyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbe91df-66c9-46da-abf9-379f37061d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f9f9-20fb-489c-9a8d-0f47cf681b1e",
   "metadata": {},
   "source": [
    "# my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227faf0a-4609-4fb1-bb57-f72308e2b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'rb') as outfile:\n",
    "        data_dict = pickle.load(outfile)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a159f970-32cf-4719-b3b7-d16eeb939f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict,fname):\n",
    "    with open(fname,'wb') as outfile:\n",
    "        pickle.dump(data_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b2f8de-d7db-4a8a-8b56-68987ea54c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f,*args,t=None,h=2.5,**kwargs):\n",
    "    T,N = f.shape\n",
    "    if t == None: t = range(T)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots(N,1)\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "        ax[n].set_title('node='+str(n))\n",
    "    fig.set_figheight(N*h)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd30cd2-1daf-474d-b132-7b41af02e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_add(fig,f,*args,t=None,**kwargs):\n",
    "    T = f.shape[0]\n",
    "    N = f.shape[1] \n",
    "    if t == None: t = range(T)   \n",
    "    ax = fig.get_axes()\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5422d968-a917-483b-8e82-4ab2bf569bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Psi(T):\n",
    "    W = np.zeros((T,T))\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            if i==j :\n",
    "                W[i,j] = 0\n",
    "            elif np.abs(i-j) <= 1 : \n",
    "                W[i,j] = 1\n",
    "    d = np.array(W.sum(axis=1))\n",
    "    D = np.diag(d)\n",
    "    L = np.array(np.diag(1/np.sqrt(d)) @ (D-W) @ np.diag(1/np.sqrt(d)))\n",
    "    lamb, Psi = np.linalg.eigh(L)\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdbd67c-4d90-4d7f-9a4f-2f73dac5485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da0eb4f-5518-4e35-b392-9762da230d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(f):\n",
    "    f = np.array(f)\n",
    "    if len(f.shape)==1: f = f.reshape(-1,1)\n",
    "    T,N = f.shape\n",
    "    Psi = make_Psi(T)\n",
    "    fbar = Psi.T @ f # apply dft \n",
    "    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n",
    "    fhat = Psi @ fbar_threshed # inverse dft \n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3036d47a-8211-4f46-9cd3-c316e01e5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_freq_domain(signal, missing_index):\n",
    "    signal = np.array(signal)\n",
    "    T,N = signal.shape \n",
    "    signal_trimed = trim(signal)\n",
    "    for i in range(N):\n",
    "        signal[missing_index[i],i] = signal_trimed[missing_index[i],i]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8381f21a-b8da-4ed7-befb-a308868ad854",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2acf2d-e0ae-4857-99a4-7b9d174fae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: igraph\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: wordcloud\n",
      "\n",
      "R[write to console]: Loading required package: RColorBrewer\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(GNAR)\n",
    "library(igraph)\n",
    "library(zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d054b87d-a1a2-471d-98df-15012606960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fiveNet_m <- as.matrix(fiveNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3966f3d-fcc4-4568-a2b1-ba12e653ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o fiveNet_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6da55e-9f1a-4e73-b7cc-111ee5c36d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNAR = importr('GNAR') # import GNAR \n",
    "igraph = importr('igraph') # import igraph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c101-5cff-4aec-9f7b-fe41c9c16b47",
   "metadata": {},
   "source": [
    "# data 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4e297-0e68-4b57-adc2-2abafc28cc03",
   "metadata": {},
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bcaefae-0b23-4dbd-b35b-30a36b84095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('./data/fivenodes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d881f0-65fc-49c4-acab-1c7b4d371a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_tensor = torch.tensor(data['edges'])\n",
    "fiveVTS = np.array(data['f'])\n",
    "nonzero_indices = edges_tensor.nonzero()\n",
    "fiveNet_edge = np.array(nonzero_indices).T\n",
    "T = 200\n",
    "N = 5 # number of Nodes\n",
    "E = fiveNet_edge\n",
    "V = np.array([1,2,3,4,5])\n",
    "t = np.arange(0,T)\n",
    "node_features = 1\n",
    "edge_index = torch.tensor(E)\n",
    "edge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed58fa-3cd6-428b-a6d0-52e3460d9e1f",
   "metadata": {},
   "source": [
    "`-` train / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef13f89-df0c-467f-b856-7145f554e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveVTS_train = fiveVTS[:int(len(fiveVTS)*0.8)]\n",
    "fiveVTS_test = fiveVTS[int(len(fiveVTS)*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ecff-ebeb-4d3f-97de-297aa69aa487",
   "metadata": {},
   "source": [
    "# Random Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c2d697-7649-4ed0-a0c7-e4b66c4fd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Missing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.N = N\n",
    "        self.number = []\n",
    "    def miss(self,percent=0.5):\n",
    "        self.missing = self.df.copy()\n",
    "        self.percent = percent\n",
    "        for i in range(self.N):\n",
    "            #self.seed = np.random.choice(1000,1,replace=False)\n",
    "            #np.random.seed(self.seed)\n",
    "            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n",
    "            self.missing[self.number[i],i] = float('nan')\n",
    "    def first_mean(self):\n",
    "        self.train_mean = self.missing.copy()\n",
    "        for i in range(self.N):\n",
    "            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n",
    "    def second_linear(self):\n",
    "        self.train_linear = pd.DataFrame(self.missing)\n",
    "        self.train_linear.interpolate(method='linear', inplace=True)\n",
    "        self.train_linear = self.train_linear.fillna(0)\n",
    "        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79dda18e-9e34-4227-806c-431a07403290",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n",
    "\n",
    "rate = [i/10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5832fea-151e-43ca-8ef9-8d12b18a2655",
   "metadata": {},
   "source": [
    "# Class code by Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90619301-0663-4e78-8d2e-926f0efc8482",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e4cefbf-1ffb-481f-9084-42d90689956f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_Missing:\n",
    "    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "\n",
    "        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            for epoch in range(50):\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):\n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n",
    "            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset, \n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74841d2a-f372-4543-8f78-a22b5ba83d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "532d3cd3-ba47-4747-9933-98dfd5d44bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESTGCN_Missing:\n",
    "    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "\n",
    "        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            signal = interpolated_signal.copy()\n",
    "            for epoch in range(50):\n",
    "                signal = update_from_freq_domain(signal,missing_index)\n",
    "                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):        \n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n",
    "            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f20fc1-21ff-4b9e-afd8-007ac8a4c77b",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff49ecf4-a1a8-43fe-b72f-71f407ffdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9195dd3-fa73-4ac3-bde9-632666258ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNAR_Missing:\n",
    "    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n",
    "\n",
    "            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n",
    "            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n",
    "\n",
    "\n",
    "            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n",
    "            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368d41a-7279-4d48-befb-1499a42eb5d5",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45f09158-75e2-4333-a3b3-2a6badfe5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'stgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485dd96-fb2d-4990-8c98-09c8b0c55de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stgcn= pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058eb399-56aa-420c-b93f-63eb5f05f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    stgcn.iter()\n",
    "    df_add = stgcn.df.copy()\n",
    "    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fdacf-ec1c-48a6-beb5-fd11a796f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4c955-0ab9-4080-8847-4734afbd1540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cd97c-8222-495f-8db5-677bf8f3daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'estgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31e136-0a49-4458-886c-58d0c9c1df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estgcn = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45666064-15c0-4f38-a1da-137c089457d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    estgcn.iter()\n",
    "    df_add = estgcn.df.copy()\n",
    "    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1125a4-a55b-472d-a728-dcc5103e24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62c348-e220-41b7-a01e-cc74ec52231d",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1797d2-bb65-408e-bcd1-044aa6dbe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'gnar' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Number_of_filters = None # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6c8cb-49ec-4557-8b57-2485caacd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnar = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49336ba8-01d4-457e-b241-405a4f686a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    gnar.iter()\n",
    "    df_add = gnar.df.copy()\n",
    "    df_gnar = pd.concat([df_gnar,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d3d89-680d-4286-b32f-322839759320",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e041f-bb1d-445f-bfb9-e5872fe1bdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

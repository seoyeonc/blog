<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2023-07-03">

<title>Seoyeon’s Blog for study - Other Outlier Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for study</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/blog/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Other Outlier Detection</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Other Outlier Detection</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">GODE</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GCN/index.html" class="sidebar-item-text sidebar-link">GCN</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-29-STGCN-tutorial.html" class="sidebar-item-text sidebar-link"><strong>[IT-STGCN]</strong> STGCN 튜토리얼</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html" class="sidebar-item-text sidebar-link">1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-20-Algorithm_traintest.html" class="sidebar-item-text sidebar-link">1st ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html" class="sidebar-item-text sidebar-link">2nd ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-18-Algorithm_traintest_2.html" class="sidebar-item-text sidebar-link">2nd ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html" class="sidebar-item-text sidebar-link">Adding the RecurrentGCN models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-guebin.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-21-Class.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1 80% Missing repeat</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-20-data load, data save as pickle.html" class="sidebar-item-text sidebar-link">data load, data save as pickle</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-20-EbayesThresh toy ex.html" class="sidebar-item-text sidebar-link">EbayesThresh Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-11-Algorithm_EX_1.html" class="sidebar-item-text sidebar-link">GCN Algorithm Example 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Boxplot_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-05-GNAR.html" class="sidebar-item-text sidebar-link">GNAR data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-05-31-Other Method.html" class="sidebar-item-text sidebar-link">ITSTGCN add Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-06-article_refer.html" class="sidebar-item-text sidebar-link">ITSTGCN Article Refernece</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-17-ITSTGCN-Tutorial.html" class="sidebar-item-text sidebar-link">ITSTGCN-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-06-METRLADatasetLoader.html" class="sidebar-item-text sidebar-link">METRLADatasetLoader-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-25-note_matrix.html" class="sidebar-item-text sidebar-link">Note_weight amatrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-29-pedalme_GSO_st.html" class="sidebar-item-text sidebar-link">Padalme GSO_st</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-CPUvsGPU.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal CPU vs GPU</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-PyGGeometricTemporalEx.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal Examples</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-21-ST-GCN_Dataset.html" class="sidebar-item-text sidebar-link">PyTorch ST-GCN Dataset</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">Questions of PyTorch Geometric Temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-18-Self Consistency toy ex.html" class="sidebar-item-text sidebar-link">Self Consistency Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation_boxplot.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-28-gcn_simulation.html" class="sidebar-item-text sidebar-link">Simulation of geometric-temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-simulation_table.html" class="sidebar-item-text sidebar-link">Simulation Tables</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-04-Sparse_matrix.html" class="sidebar-item-text sidebar-link">Sparse matrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html" class="sidebar-item-text sidebar-link">SY 1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-07-torchgcn.html" class="sidebar-item-text sidebar-link">TORCH_GEOMETRIC.NN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_figure.html" class="sidebar-item-text sidebar-link">Toy Example Figure(Intro)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_notes.html" class="sidebar-item-text sidebar-link">Toy Example Note</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GODE/index.html" class="sidebar-item-text sidebar-link">GODE</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-11-19-class_code_for_paper.html" class="sidebar-item-text sidebar-link">Class code for Comparison Study</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-22-comparison_earthquake.html" class="sidebar-item-text sidebar-link">Comparison Results on Real Data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-27-DFT_study.html" class="sidebar-item-text sidebar-link">Discrete Fourier Transform</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-10-02-Earthquake_real.html" class="sidebar-item-text sidebar-link">Earthquake</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-01-graph_code_guebin.html" class="sidebar-item-text sidebar-link">Graph code</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-27-Linear_graph_code_for_paper.html" class="sidebar-item-text sidebar-link">Linear Graph code for Paper</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-07-03-other_outlier_detection.html" class="sidebar-item-text sidebar-link active">Other Outlier Detection</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-09-02-paper_simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/Untitled.html" class="sidebar-item-text sidebar-link">Untitled</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a>
  <ul class="collapse">
  <li><a href="#class-code" id="toc-class-code" class="nav-link" data-scroll-target="#class-code">Class Code</a></li>
  <li><a href="#linear-ebayesthresh" id="toc-linear-ebayesthresh" class="nav-link" data-scroll-target="#linear-ebayesthresh">Linear EbayesThresh</a></li>
  <li><a href="#linear" id="toc-linear" class="nav-link" data-scroll-target="#linear">Linear</a>
  <ul class="collapse">
  <li><a href="#gode" id="toc-gode" class="nav-link" data-scroll-target="#gode">GODE</a></li>
  <li><a href="#lofbreunig2000lofstar" id="toc-lofbreunig2000lofstar" class="nav-link" data-scroll-target="#lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(Breunig et al. 2000)</span><span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">KNN</a></li>
  <li><a href="#cblof오류" id="toc-cblof오류" class="nav-link" data-scroll-target="#cblof오류">CBLOF(오류)</a></li>
  <li><a href="#ocsvm" id="toc-ocsvm" class="nav-link" data-scroll-target="#ocsvm">OCSVM</a></li>
  <li><a href="#mcdstar" id="toc-mcdstar" class="nav-link" data-scroll-target="#mcdstar">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar" id="toc-feature-baggingstar" class="nav-link" data-scroll-target="#feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar" id="toc-abodstar" class="nav-link" data-scroll-target="#abodstar">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar" id="toc-iforeststar" class="nav-link" data-scroll-target="#iforeststar">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar" id="toc-hbosstar" class="nav-link" data-scroll-target="#hbosstar">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar" id="toc-sosstar" class="nav-link" data-scroll-target="#sosstar">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaal" id="toc-so_gaal" class="nav-link" data-scroll-target="#so_gaal">SO_GAAL</a></li>
  <li><a href="#mo_gaalstar" id="toc-mo_gaalstar" class="nav-link" data-scroll-target="#mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar" id="toc-lscpstar" class="nav-link" data-scroll-target="#lscpstar">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#linear-result" id="toc-linear-result" class="nav-link" data-scroll-target="#linear-result">Linear Result</a></li>
  <li><a href="#orbit-ebayesthresh" id="toc-orbit-ebayesthresh" class="nav-link" data-scroll-target="#orbit-ebayesthresh">Orbit EbayesThresh</a></li>
  <li><a href="#orbit" id="toc-orbit" class="nav-link" data-scroll-target="#orbit">Orbit</a>
  <ul class="collapse">
  <li><a href="#gode-1" id="toc-gode-1" class="nav-link" data-scroll-target="#gode-1">GODE</a></li>
  <li><a href="#lofstar" id="toc-lofstar" class="nav-link" data-scroll-target="#lofstar">LOF<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn-1" id="toc-knn-1" class="nav-link" data-scroll-target="#knn-1">KNN</a></li>
  <li><a href="#cblof" id="toc-cblof" class="nav-link" data-scroll-target="#cblof">CBLOF</a></li>
  <li><a href="#ocsvm-1" id="toc-ocsvm-1" class="nav-link" data-scroll-target="#ocsvm-1">OCSVM</a></li>
  <li><a href="#mcdstar-1" id="toc-mcdstar-1" class="nav-link" data-scroll-target="#mcdstar-1">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar-1" id="toc-feature-baggingstar-1" class="nav-link" data-scroll-target="#feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar-1" id="toc-abodstar-1" class="nav-link" data-scroll-target="#abodstar-1">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar-1" id="toc-iforeststar-1" class="nav-link" data-scroll-target="#iforeststar-1">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar-1" id="toc-hbosstar-1" class="nav-link" data-scroll-target="#hbosstar-1">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar-1" id="toc-sosstar-1" class="nav-link" data-scroll-target="#sosstar-1">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaalstar" id="toc-so_gaalstar" class="nav-link" data-scroll-target="#so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#mo_gaalstar-1" id="toc-mo_gaalstar-1" class="nav-link" data-scroll-target="#mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar-1" id="toc-lscpstar-1" class="nav-link" data-scroll-target="#lscpstar-1">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#orbit-result" id="toc-orbit-result" class="nav-link" data-scroll-target="#orbit-result">Orbit Result</a>
  <ul class="collapse">
  <li><a href="#bunny-저장용" id="toc-bunny-저장용" class="nav-link" data-scroll-target="#bunny-저장용">bunny 저장용</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>knn, cblof, ocsvm 을 제외한 이상치 탐지 기법들에 데이터 집합에서 이상치 비율을 지정할 수 있는 옵션이 존재하였음.</p>
<p>default값은 10%인데, ABOD 방법에서는 5로 지정해주었고, 다른 방법들은 default인 10%가 들어갔다.</p>
<p>일단 우리 방법이랑 비교해서 좋은지 보기</p>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.930</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.889</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.883</td>
<td style="text-align: center;">0.938</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.896</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.997</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.926</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.999</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.984</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.885</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.936</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.943</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.970</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.998</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.886</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.892</td>
<td style="text-align: center;">0.937</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.918</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.958</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.866</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.903</td>
<td style="text-align: center;">0.928</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.979</td>
<td style="text-align: center;">0.927</td>
<td style="text-align: center;">0.952</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.378</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.514</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.876</td>
<td style="text-align: center;">0.959</td>
<td style="text-align: center;">0.908</td>
<td style="text-align: center;">0.933</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.999</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>[</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.978</span> ,  <span class="fl">0.989</span> ,  <span class="fl">0.987</span> ,  <span class="fl">0.988</span> ],</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.932</span> ,  <span class="fl">0.991</span> ,  <span class="fl">0.937</span> ,  <span class="fl">0.963</span> ],</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.935</span> ,  <span class="fl">0.993</span> ,  <span class="fl">0.938</span> ,  <span class="fl">0.965</span> ],</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.915</span> ,  <span class="fl">0.982</span> ,  <span class="fl">0.928</span> ,  <span class="fl">0.965</span> ],</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.977</span> ,  <span class="fl">0.989</span> ,  <span class="fl">0.987</span> ,  <span class="fl">0.988</span> ],</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>[<span class="fl">0.794</span> ,  <span class="fl">0.995</span> ,  <span class="fl">0.788</span> ,  <span class="fl">0.879</span> ],</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>[</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>Stanford Bunny 논문<span class="op">|</span>Accuracy<span class="op">|</span>Precision<span class="op">|</span>Recall<span class="op">|</span>F1<span class="op">|</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>:<span class="op">--</span>:<span class="op">|</span>:<span class="op">--</span>:<span class="op">|</span>:<span class="op">--</span>:<span class="op">|</span>:<span class="op">--</span>:<span class="op">|</span>:<span class="op">--</span>:<span class="op">|</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>GODE<span class="op">|</span>[<span class="fl">0.995</span><span class="op">|</span><span class="fl">0.995</span><span class="op">|</span><span class="fl">0.999</span><span class="op">|</span><span class="fl">0.997</span><span class="op">|</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>LOF (Breunig et al., <span class="dv">2000</span>)<span class="op">|</span><span class="fl">0.928</span><span class="op">|</span><span class="fl">0.957</span><span class="op">|</span><span class="fl">0.869</span><span class="op">|</span><span class="fl">0.963</span><span class="op">|</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>kNN (Ramaswamy et al., <span class="dv">2000</span>)<span class="op">|</span><span class="fl">0.948</span><span class="op">|</span><span class="fl">0.999</span><span class="op">|</span><span class="fl">0.946</span><span class="op">|</span><span class="fl">0.972</span><span class="op">|</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>CBLOF (He et al., <span class="dv">2003</span>)<span class="op">|</span><span class="fl">0.918</span><span class="op">|</span><span class="fl">0.957</span><span class="op">|</span><span class="fl">0.9</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>OCSVM (Sch ̈olkopf et al., <span class="dv">2001</span>)<span class="op">|</span><span class="fl">0.923</span><span class="op">|</span><span class="fl">0.9</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>MCD (Hardin <span class="kw">and</span> Rocke, <span class="dv">2004</span>)<span class="op">|</span><span class="fl">0.866</span><span class="op">|</span><span class="fl">0.953</span><span class="op">|</span><span class="dv">0</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>Feature Bagging (Lazarevic <span class="kw">and</span> Kumar, <span class="dv">2005</span>)<span class="op">|</span><span class="fl">0.912.952</span><span class="op">|</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>ABOD (Kriegel et al., <span class="dv">2008</span>)<span class="op">|</span><span class="fl">0.988</span><span class="op">|</span><span class="fl">0.994</span><span class="op">|</span><span class="fl">0.99</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>Isolation Forest (Liu et al., <span class="dv">2008</span>)<span class="op">|</span><span class="fl">0.378</span><span class="op">|</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>HBOS (Goldstein <span class="kw">and</span> Dengel, <span class="dv">2012</span>)<span class="op">|</span><span class="fl">0.895</span><span class="op">|</span><span class="fl">0.969</span><span class="op">|</span><span class="fl">0.919</span><span class="op">|</span><span class="fl">0.944</span><span class="op">|</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>SOS (Janssens et al., <span class="dv">2012</span>)<span class="op">|</span><span class="fl">0.895</span><span class="op">|</span><span class="fl">0.969</span><span class="op">|</span><span class="fl">0.919</span><span class="op">|</span><span class="fl">0.944</span><span class="op">|</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>SO<span class="op">-</span>GAAL (Liu et al., <span class="dv">2019</span>)<span class="op">|</span><span class="fl">0.952</span><span class="op">|</span><span class="fl">0.952</span><span class="op">|</span><span class="fl">1.000</span><span class="op">|</span><span class="fl">0.975</span><span class="op">|</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>MO<span class="op">-</span>GAAL (Liu et al., <span class="dv">2019</span>)<span class="op">|</span><span class="fl">0.952</span><span class="op">|</span><span class="fl">0.952</span><span class="op">|</span><span class="fl">1.000</span><span class="op">|</span><span class="fl">0.975</span><span class="op">|</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="op">|</span>LSCP (Zhao et al., <span class="dv">2019</span>)<span class="op">|</span><span class="fl">0.940</span><span class="op">|</span><span class="fl">0.996</span><span class="op">|</span><span class="fl">0.941</span><span class="op">|</span><span class="fl">0.967</span><span class="op">|</span></span></code></pre></div>
</div>
<section id="import" class="level1">
<h1>Import</h1>
<div class="cell" data-execution_count="397">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDOneClassSVM</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> Nystroem</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2.robjects <span class="im">as</span> ro </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.vectors <span class="im">import</span> FloatVector </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.packages <span class="im">import</span> importr</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_kddcup99, fetch_covtype, fetch_openml</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tqdm</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score, accuracy_score</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.covariance <span class="im">import</span> EmpiricalCovariance, MinCovDet</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> alibi_detect.od <span class="im">import</span> IForest</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># from pyod.models.iforest import IForest</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.abod <span class="im">import</span> ABOD</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.cblof <span class="im">import</span> CBLOF</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PyNomaly <span class="im">import</span> loop</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lscp <span class="im">import</span> LSCP</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.hbos <span class="im">import</span> HBOS</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.so_gaal <span class="im">import</span> SO_GAAL</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mcd <span class="im">import</span> MCD</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mo_gaal <span class="im">import</span> MO_GAAL</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lof <span class="im">import</span> LOF</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.ocsvm <span class="im">import</span> OCSVM</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.feature_bagging <span class="im">import</span> FeatureBagging</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.sos <span class="im">import</span> SOS</span></code></pre></div>
</div>
<div class="cell" data-execution_count="398">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<section id="class-code" class="level2">
<h2 class="anchored" data-anchor-id="class-code">Class Code</h2>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>tab_linear <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>tab_orbit <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>tab_bunny <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="254">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conf_matrx:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,original,compare,tab):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original <span class="op">=</span> original</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compare <span class="op">=</span> compare</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> tab</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> conf(<span class="va">self</span>,name):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conf_matrix <span class="op">=</span> confusion_matrix(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        ax.matshow(<span class="va">self</span>.conf_matrix, cmap<span class="op">=</span>plt.cm.Oranges, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span><span class="va">self</span>.conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Confusion Matrix'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.acc <span class="op">=</span> accuracy_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pre <span class="op">=</span> precision_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rec <span class="op">=</span> recall_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f1 <span class="op">=</span> f1_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.acc)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Precision: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.pre)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Recall: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.rec)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'F1 Score: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.f1)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> <span class="va">self</span>.tab.append(pd.DataFrame({<span class="st">"Accuracy"</span>:[<span class="va">self</span>.acc],<span class="st">"Precision"</span>:[<span class="va">self</span>.pre],<span class="st">"Recall"</span>:[<span class="va">self</span>.rec],<span class="st">"F1"</span>:[<span class="va">self</span>.f1]},index <span class="op">=</span> [name]))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="255">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.y1 = df.y1.to_numpy()</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> w</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)      </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.y <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.ybar,<span class="dv">0</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.yhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.ybar_threshed</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(yHat <span class="op">=</span> <span class="va">self</span>.yhat)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.y<span class="op">-</span> <span class="va">self</span>.df.yHat)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="256">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Orbit:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_distance(<span class="va">self</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> np.zeros([<span class="va">self</span>.n,<span class="va">self</span>.n])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        locations <span class="op">=</span> np.stack([<span class="va">self</span>.x, <span class="va">self</span>.y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm.tqdm(<span class="bu">range</span>(<span class="va">self</span>.n)):</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i,<span class="va">self</span>.n):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.D[i,j]<span class="op">=</span>np.linalg.norm(locations[i]<span class="op">-</span>locations[j])</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> <span class="va">self</span>.D <span class="op">+</span> <span class="va">self</span>.D.T</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_weightmatrix(<span class="va">self</span>,theta<span class="op">=</span><span class="dv">1</span>,beta<span class="op">=</span><span class="fl">0.5</span>,kappa<span class="op">=</span><span class="dv">4000</span>):</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta <span class="op">=</span> theta</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.where(<span class="va">self</span>.D <span class="op">&lt;</span> kappa,<span class="va">self</span>.D,<span class="dv">0</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.exp(<span class="op">-</span>(dist<span class="op">/</span><span class="va">self</span>.theta)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.f <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f<span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="257">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BUNNY:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z <span class="op">=</span> df.z.to_numpy()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.noise <span class="op">=</span> df.noise.to_numpy()</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fnoise <span class="op">=</span> <span class="va">self</span>.f <span class="op">+</span> <span class="va">self</span>.noise</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> _W</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">6</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.fnoise <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fnoise <span class="op">=</span> <span class="va">self</span>.fnoise)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f <span class="op">+</span> <span class="va">self</span>.df.noise <span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
</section>
<section id="linear-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="linear-ebayesthresh">Linear EbayesThresh</h2>
<div class="cell" data-execution_count="258">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>signal_1 <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1 <span class="op">=</span> which(signal_1<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>x_1<span class="op">=</span>signal_1<span class="op">+</span>epsilon</span></code></pre></div>
</div>
<div class="cell" data-execution_count="276">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x_1</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier_1</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="277">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="278">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index_1 <span class="op">=</span> index_of_trueoutlier_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="279">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value_1 <span class="op">=</span> x_1[index_of_trueoutlier_1]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="280">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> signal_1.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="281">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_1))</span></code></pre></div>
</div>
</section>
<section id="linear" class="level2">
<h2 class="anchored" data-anchor-id="linear">Linear</h2>
<div class="cell" data-tags="[]" data-execution_count="403">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>_x_1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1000</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>_y1_1 <span class="op">=</span> <span class="dv">5</span><span class="op">*</span>_x_1</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>_y_1 <span class="op">=</span> _y1_1 <span class="op">+</span> x_1 <span class="co"># x is epsilon</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="404">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>_df<span class="op">=</span>pd.DataFrame({<span class="st">'x'</span>:_x_1, <span class="st">'y'</span>:_y_1})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="405">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<section id="gode" class="level3">
<h3 class="anchored" data-anchor-id="gode">GODE</h3>
<div class="cell" data-execution_count="406">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span>np.zeros((<span class="dv">1000</span>,<span class="dv">1000</span>))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="407">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">==</span>j :</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> np.<span class="bu">abs</span>(i<span class="op">-</span>j) <span class="op">&lt;=</span> <span class="dv">1</span> : </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="408">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>_Linear <span class="op">=</span> Linear(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="409">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>_Linear.fit(sd<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="507">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Linear.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="508">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">10.7</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="509">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="510">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="510">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="511">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="511">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="513">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.994
Precision: 0.997
Recall: 0.997
F1 Score: 0.997</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="514">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="514">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.994</td>
      <td>0.996842</td>
      <td>0.996842</td>
      <td>0.996842</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lofbreunig2000lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(<a href="#ref-breunig2000lof" role="doc-biblioref">Breunig et al. 2000</a>)</span><span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="301">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<p>Lof 논문 원문에 따라 LOF를 계산하고, min-max 범위를 넘으면 이상치</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figs/lof.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure: LOF’s outliers detection method</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="302">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="303">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-34-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.926
Precision: 0.961
Recall: 0.961
F1 Score: 0.961</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="306">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>tab_linear.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  tab_linear.append(_conf.tab)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="306">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.926</td>
      <td>0.961053</td>
      <td>0.961053</td>
      <td>0.961053</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="knn" class="level3">
<h3 class="anchored" data-anchor-id="knn">KNN</h3>
<div class="cell" data-execution_count="307">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="308">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p>k번째 이상은 outlier로 본다.</p>
<p><strong>이상치 비율 정하지 않음</strong></p>
<p>Three kNN detectors are supported:</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the outlier score</li>
</ul>
<div class="cell" data-execution_count="309">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="310">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="311">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="969">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="cblof오류" class="level3">
<h3 class="anchored" data-anchor-id="cblof오류">CBLOF(오류)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="971">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="972">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="973">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="975">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>four <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="ocsvm" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm">OCSVM</h3>
<p>default=10%</p>
<div class="cell" data-execution_count="313">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="314">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="314">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="315">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="316">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="317">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-53-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.991
Recall: 0.940
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="318">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="318">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.991121</td>
      <td>0.94</td>
      <td>0.964884</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mcdstar" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="320">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="321">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="322">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="323">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="324">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-59-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="325">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="325">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="feature-baggingstar" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<p>default값은 10%로 설정되어 있었고, 5%로 지정한 결과, 평가지표값이 전반적으로 1%이상 낮아졌다.</p>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="326">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="327">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="328">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="329">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="330">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-65-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.984
Precision: 0.992
Recall: 0.992
F1 Score: 0.992</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="331">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="331">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.984</td>
      <td>0.991579</td>
      <td>0.991579</td>
      <td>0.991579</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="abodstar" class="level3">
<h3 class="anchored" data-anchor-id="abodstar">ABOD<span class="math inline">\(\star\)</span></h3>
<p>default 값이 5%이며, 이미 지정된 채려 시뮬레이션 돌림</p>
<div class="cell" data-execution_count="332">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p><strong>contamination</strong> : float in (0., 0.5), optional (default=0.1)</p>
<ul>
<li>The amount of contamination of the data set, i.e.</li>
<li>the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.</li>
</ul>
<div class="cell" data-execution_count="333">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="334">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="335">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="336">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-71-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="337">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="337">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="iforeststar" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar">IForest<span class="math inline">\(\star\)</span></h3>
<p>n_estimators Number of base estimators in the ensemble.</p>
<ul>
<li>n이 총 1000개니까 5%인 50 지정해줄 수 있음</li>
</ul>
<div class="cell" data-execution_count="338">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="339">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="340">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>]],</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="341">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="342">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="343">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="344">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="345">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-80-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.885
Precision: 0.999
Recall: 0.880
F1 Score: 0.936</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="346">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="346">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.885</td>
      <td>0.998805</td>
      <td>0.88</td>
      <td>0.935646</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="hbosstar" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar">HBOS<span class="math inline">\(\star\)</span></h3>
<p>default값은 이상치값을 10%로 지정하였으며, 5%로 지정한 결과 값 다 작아짐</p>
<div class="cell" data-execution_count="384">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="385">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="386">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="387">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="388">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-86-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.960
Precision: 0.978
Recall: 0.980
F1 Score: 0.979</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="389">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="389">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.96</td>
      <td>0.977941</td>
      <td>0.98</td>
      <td>0.97897</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sosstar" class="level3">
<h3 class="anchored" data-anchor-id="sosstar">SOS<span class="math inline">\(\star\)</span></h3>
<p>default 는 10%</p>
<div class="cell" data-execution_count="355">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="356">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="357">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="358">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="359">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-92-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="360">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="360">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.916</td>
      <td>0.955789</td>
      <td>0.955789</td>
      <td>0.955789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="so_gaal" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal">SO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="361">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 862us/step - loss: 1.0640

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 827us/step - loss: 1.0818
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 853us/step - loss: 1.0984

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 846us/step - loss: 1.1023
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 851us/step - loss: 1.1116

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 830us/step - loss: 1.1127
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 815us/step - loss: 1.1359

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 812us/step - loss: 1.1429
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 808us/step - loss: 1.1177

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 785us/step - loss: 1.1457
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 805us/step - loss: 1.1468

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 802us/step - loss: 1.1501
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.1816

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 797us/step - loss: 1.1725
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 796us/step - loss: 1.1822

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 798us/step - loss: 1.1752
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 868us/step - loss: 1.1898

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 805us/step - loss: 1.2337
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 819us/step - loss: 1.2280

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.2237
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 816us/step - loss: 1.2403

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.2572
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.2652

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 809us/step - loss: 1.2678
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.2597

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 801us/step - loss: 1.2931
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 804us/step - loss: 1.2927

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 815us/step - loss: 1.3224
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 808us/step - loss: 1.3126

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 812us/step - loss: 1.3397
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.3516

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 798us/step - loss: 1.3297
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 800us/step - loss: 1.3493

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 826us/step - loss: 1.3447
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 803us/step - loss: 1.3573

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 799us/step - loss: 1.3643
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 809us/step - loss: 1.3702

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 800us/step - loss: 1.4059
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.4023

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 875us/step - loss: 1.3997
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 796us/step - loss: 1.4110

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 796us/step - loss: 1.4132
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 791us/step - loss: 1.4308

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 804us/step - loss: 1.4205
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.4429

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 785us/step - loss: 1.4500
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 813us/step - loss: 1.4560

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4629
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.4531

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4627
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 868us/step - loss: 1.4971

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 871us/step - loss: 1.5024
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.4855

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 877us/step - loss: 1.5128
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 872us/step - loss: 1.5061

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 872us/step - loss: 1.5104
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 871us/step - loss: 1.5186

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 890us/step - loss: 1.5191
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 690us/step - loss: 1.5765

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 802us/step - loss: 1.5212
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5610

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5390
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 822us/step - loss: 1.5472

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.5762
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5946

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 988us/step - loss: 1.6020
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6007

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5847
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5918

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 795us/step - loss: 1.6119
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6314

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6356
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 959us/step - loss: 1.6195

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6137
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 848us/step - loss: 1.6543

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6529
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 790us/step - loss: 1.6446

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6672
32/32 [==============================] - 0s 572us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="362">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="363">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="364">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="365">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-98-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.936
Precision: 0.966
Recall: 0.966
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="366">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="366">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.936</td>
      <td>0.966316</td>
      <td>0.966316</td>
      <td>0.966316</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mo_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="367">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 578us/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 588us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 830us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 560us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 947us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 568us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 601us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 635us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 617us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 616us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 620us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 696us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 620us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 696us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 696us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 598us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 844us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 627us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 869us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 615us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 826us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 614us/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 872us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 622us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 614us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 702us/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 616us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 623us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 631us/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 629us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 831us/step - loss: 0.2442
16/16 [==============================] - 0s 830us/step - loss: 0.7355
16/16 [==============================] - 0s 827us/step - loss: 1.0992
16/16 [==============================] - 0s 896us/step - loss: 1.3980
16/16 [==============================] - 0s 876us/step - loss: 1.5344
16/16 [==============================] - 0s 844us/step - loss: 1.6077
16/16 [==============================] - 0s 849us/step - loss: 1.6388
16/16 [==============================] - 0s 808us/step - loss: 1.6578
16/16 [==============================] - 0s 829us/step - loss: 1.6642
16/16 [==============================] - 0s 805us/step - loss: 1.6662
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 622us/step
16/16 [==============================] - 0s 817us/step - loss: 0.2554
16/16 [==============================] - 0s 831us/step - loss: 0.7341
16/16 [==============================] - 0s 812us/step - loss: 1.0999
16/16 [==============================] - 0s 849us/step - loss: 1.3911
16/16 [==============================] - 0s 828us/step - loss: 1.5222
16/16 [==============================] - 0s 819us/step - loss: 1.5852
16/16 [==============================] - 0s 800us/step - loss: 1.6118
16/16 [==============================] - 0s 808us/step - loss: 1.6276
16/16 [==============================] - 0s 799us/step - loss: 1.6324
16/16 [==============================] - 0s 825us/step - loss: 1.6339

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 843us/step - loss: 0.2366
16/16 [==============================] - 0s 797us/step - loss: 0.7465
16/16 [==============================] - 0s 819us/step - loss: 1.1457
16/16 [==============================] - 0s 786us/step - loss: 1.4587
16/16 [==============================] - 0s 824us/step - loss: 1.5968
16/16 [==============================] - 0s 841us/step - loss: 1.6577
16/16 [==============================] - 0s 827us/step - loss: 1.6835
16/16 [==============================] - 0s 808us/step - loss: 1.6982
16/16 [==============================] - 0s 807us/step - loss: 1.7024
16/16 [==============================] - 0s 835us/step - loss: 1.7036
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2361
16/16 [==============================] - 0s 793us/step - loss: 0.7428
16/16 [==============================] - 0s 794us/step - loss: 1.1534
16/16 [==============================] - 0s 814us/step - loss: 1.4658
16/16 [==============================] - 0s 800us/step - loss: 1.5961
16/16 [==============================] - 0s 807us/step - loss: 1.6504
16/16 [==============================] - 0s 820us/step - loss: 1.6722
16/16 [==============================] - 0s 793us/step - loss: 1.6837
16/16 [==============================] - 0s 795us/step - loss: 1.6869
16/16 [==============================] - 0s 798us/step - loss: 1.6878

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2431
16/16 [==============================] - 0s 805us/step - loss: 0.7496
16/16 [==============================] - 0s 800us/step - loss: 1.1677
16/16 [==============================] - 0s 789us/step - loss: 1.4776
16/16 [==============================] - 0s 793us/step - loss: 1.6030
16/16 [==============================] - 0s 797us/step - loss: 1.6522
16/16 [==============================] - 0s 803us/step - loss: 1.6718
16/16 [==============================] - 0s 819us/step - loss: 1.6812
16/16 [==============================] - 0s 804us/step - loss: 1.6837
16/16 [==============================] - 0s 804us/step - loss: 1.6843
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 813us/step - loss: 0.2415
16/16 [==============================] - 0s 799us/step - loss: 0.7505
16/16 [==============================] - 0s 876us/step - loss: 1.1814
16/16 [==============================] - 0s 808us/step - loss: 1.4910
16/16 [==============================] - 0s 803us/step - loss: 1.6103
16/16 [==============================] - 0s 797us/step - loss: 1.6554
16/16 [==============================] - 0s 813us/step - loss: 1.6721
16/16 [==============================] - 0s 808us/step - loss: 1.6797
16/16 [==============================] - 0s 883us/step - loss: 1.6816
16/16 [==============================] - 0s 904us/step - loss: 1.6819

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 800us/step - loss: 0.2375
16/16 [==============================] - 0s 785us/step - loss: 0.7587
16/16 [==============================] - 0s 786us/step - loss: 1.2044
16/16 [==============================] - 0s 795us/step - loss: 1.5185
16/16 [==============================] - 0s 795us/step - loss: 1.6332
16/16 [==============================] - 0s 809us/step - loss: 1.6752
16/16 [==============================] - 0s 876us/step - loss: 1.6902
16/16 [==============================] - 0s 784us/step - loss: 1.6965
16/16 [==============================] - 0s 787us/step - loss: 1.6980
16/16 [==============================] - 0s 783us/step - loss: 1.6981
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2494
16/16 [==============================] - 0s 781us/step - loss: 0.7594
16/16 [==============================] - 0s 781us/step - loss: 1.1934
16/16 [==============================] - 0s 802us/step - loss: 1.5007
16/16 [==============================] - 0s 776us/step - loss: 1.6008
16/16 [==============================] - 0s 783us/step - loss: 1.6370
16/16 [==============================] - 0s 775us/step - loss: 1.6496
16/16 [==============================] - 0s 871us/step - loss: 1.6543
16/16 [==============================] - 0s 855us/step - loss: 1.6554
16/16 [==============================] - 0s 793us/step - loss: 1.6554

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2409
16/16 [==============================] - 0s 780us/step - loss: 0.7635
16/16 [==============================] - 0s 794us/step - loss: 1.2141
16/16 [==============================] - 0s 780us/step - loss: 1.5226
16/16 [==============================] - 0s 777us/step - loss: 1.6196
16/16 [==============================] - 0s 773us/step - loss: 1.6527
16/16 [==============================] - 0s 795us/step - loss: 1.6639
16/16 [==============================] - 0s 779us/step - loss: 1.6678
16/16 [==============================] - 0s 774us/step - loss: 1.6685
16/16 [==============================] - 0s 794us/step - loss: 1.6684
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 787us/step - loss: 0.2487
16/16 [==============================] - 0s 778us/step - loss: 0.7632
16/16 [==============================] - 0s 781us/step - loss: 1.2111
16/16 [==============================] - 0s 790us/step - loss: 1.5075
16/16 [==============================] - 0s 770us/step - loss: 1.5966
16/16 [==============================] - 0s 779us/step - loss: 1.6256
16/16 [==============================] - 0s 799us/step - loss: 1.6345
16/16 [==============================] - 0s 783us/step - loss: 1.6375
16/16 [==============================] - 0s 772us/step - loss: 1.6379
16/16 [==============================] - 0s 778us/step - loss: 1.6377

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 806us/step - loss: 0.2401
16/16 [==============================] - 0s 792us/step - loss: 0.7722
16/16 [==============================] - 0s 801us/step - loss: 1.2335
16/16 [==============================] - 0s 796us/step - loss: 1.5382
16/16 [==============================] - 0s 797us/step - loss: 1.6241
16/16 [==============================] - 0s 826us/step - loss: 1.6522
16/16 [==============================] - 0s 861us/step - loss: 1.6602
16/16 [==============================] - 0s 862us/step - loss: 1.6627
16/16 [==============================] - 0s 866us/step - loss: 1.6629
16/16 [==============================] - 0s 885us/step - loss: 1.6627
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 668us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2333
16/16 [==============================] - 0s 782us/step - loss: 0.7913
16/16 [==============================] - 0s 794us/step - loss: 1.2768
16/16 [==============================] - 0s 782us/step - loss: 1.5948
16/16 [==============================] - 0s 778us/step - loss: 1.6772
16/16 [==============================] - 0s 777us/step - loss: 1.7041
16/16 [==============================] - 0s 778us/step - loss: 1.7113
16/16 [==============================] - 0s 867us/step - loss: 1.7133
16/16 [==============================] - 0s 863us/step - loss: 1.7134
16/16 [==============================] - 0s 883us/step - loss: 1.7131

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 803us/step - loss: 0.2502
16/16 [==============================] - 0s 776us/step - loss: 0.7807
16/16 [==============================] - 0s 788us/step - loss: 1.2273
16/16 [==============================] - 0s 788us/step - loss: 1.5163
16/16 [==============================] - 0s 783us/step - loss: 1.5878
16/16 [==============================] - 0s 764us/step - loss: 1.6098
16/16 [==============================] - 0s 803us/step - loss: 1.6156
16/16 [==============================] - 0s 782us/step - loss: 1.6169
16/16 [==============================] - 0s 773us/step - loss: 1.6168
16/16 [==============================] - 0s 790us/step - loss: 1.6165
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 873us/step - loss: 0.2442
16/16 [==============================] - 0s 783us/step - loss: 0.7980
16/16 [==============================] - 0s 790us/step - loss: 1.2739
16/16 [==============================] - 0s 859us/step - loss: 1.5676
16/16 [==============================] - 0s 870us/step - loss: 1.6381
16/16 [==============================] - 0s 857us/step - loss: 1.6591
16/16 [==============================] - 0s 778us/step - loss: 1.6644
16/16 [==============================] - 0s 783us/step - loss: 1.6654
16/16 [==============================] - 0s 783us/step - loss: 1.6653
16/16 [==============================] - 0s 880us/step - loss: 1.6649

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 796us/step - loss: 0.2358
16/16 [==============================] - 0s 810us/step - loss: 0.7929
16/16 [==============================] - 0s 795us/step - loss: 1.2759
16/16 [==============================] - 0s 791us/step - loss: 1.5708
16/16 [==============================] - 0s 887us/step - loss: 1.6388
16/16 [==============================] - 0s 860us/step - loss: 1.6583
16/16 [==============================] - 0s 800us/step - loss: 1.6629
16/16 [==============================] - 0s 804us/step - loss: 1.6637
16/16 [==============================] - 0s 793us/step - loss: 1.6635
16/16 [==============================] - 0s 797us/step - loss: 1.6631
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 866us/step - loss: 0.2461
16/16 [==============================] - 0s 870us/step - loss: 0.8010
16/16 [==============================] - 0s 879us/step - loss: 1.2778
16/16 [==============================] - 0s 786us/step - loss: 1.5659
16/16 [==============================] - 0s 785us/step - loss: 1.6292
16/16 [==============================] - 0s 778us/step - loss: 1.6467
16/16 [==============================] - 0s 773us/step - loss: 1.6507
16/16 [==============================] - 0s 783us/step - loss: 1.6512
16/16 [==============================] - 0s 781us/step - loss: 1.6509
16/16 [==============================] - 0s 881us/step - loss: 1.6505

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 816us/step - loss: 0.2467
16/16 [==============================] - 0s 871us/step - loss: 0.8035
16/16 [==============================] - 0s 808us/step - loss: 1.2758
16/16 [==============================] - 0s 788us/step - loss: 1.5587
16/16 [==============================] - 0s 793us/step - loss: 1.6187
16/16 [==============================] - 0s 821us/step - loss: 1.6348
16/16 [==============================] - 0s 804us/step - loss: 1.6383
16/16 [==============================] - 0s 799us/step - loss: 1.6386
16/16 [==============================] - 0s 811us/step - loss: 1.6383
16/16 [==============================] - 0s 849us/step - loss: 1.6378
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 801us/step - loss: 0.2443
16/16 [==============================] - 0s 797us/step - loss: 0.8144
16/16 [==============================] - 0s 784us/step - loss: 1.2987
16/16 [==============================] - 0s 807us/step - loss: 1.5808
16/16 [==============================] - 0s 793us/step - loss: 1.6388
16/16 [==============================] - 0s 781us/step - loss: 1.6542
16/16 [==============================] - 0s 803us/step - loss: 1.6573
16/16 [==============================] - 0s 814us/step - loss: 1.6575
16/16 [==============================] - 0s 785us/step - loss: 1.6570
16/16 [==============================] - 0s 805us/step - loss: 1.6566

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 626us/step
16/16 [==============================] - 0s 780us/step - loss: 0.2401
16/16 [==============================] - 0s 786us/step - loss: 0.8137
16/16 [==============================] - 0s 767us/step - loss: 1.3065
16/16 [==============================] - 0s 777us/step - loss: 1.5921
16/16 [==============================] - 0s 777us/step - loss: 1.6496
16/16 [==============================] - 0s 772us/step - loss: 1.6646
16/16 [==============================] - 0s 774us/step - loss: 1.6676
16/16 [==============================] - 0s 774us/step - loss: 1.6676
16/16 [==============================] - 0s 771us/step - loss: 1.6672
16/16 [==============================] - 0s 1ms/step - loss: 1.6668
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 852us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2448
16/16 [==============================] - 0s 1ms/step - loss: 0.8181
16/16 [==============================] - 0s 1ms/step - loss: 1.3169
16/16 [==============================] - 0s 1ms/step - loss: 1.6009
16/16 [==============================] - 0s 1ms/step - loss: 1.6568
16/16 [==============================] - 0s 1ms/step - loss: 1.6712
16/16 [==============================] - 0s 1ms/step - loss: 1.6738
16/16 [==============================] - 0s 1ms/step - loss: 1.6738
16/16 [==============================] - 0s 1ms/step - loss: 1.6733
16/16 [==============================] - 0s 1ms/step - loss: 1.6729

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 799us/step - loss: 0.2406
16/16 [==============================] - 0s 806us/step - loss: 0.8169
16/16 [==============================] - 0s 790us/step - loss: 1.3234
16/16 [==============================] - 0s 784us/step - loss: 1.6093
16/16 [==============================] - 0s 791us/step - loss: 1.6646
16/16 [==============================] - 0s 1ms/step - loss: 1.6786
16/16 [==============================] - 0s 1ms/step - loss: 1.6810
16/16 [==============================] - 0s 785us/step - loss: 1.6809
16/16 [==============================] - 0s 796us/step - loss: 1.6804
16/16 [==============================] - 0s 1ms/step - loss: 1.6799
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 856us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2314
16/16 [==============================] - 0s 798us/step - loss: 0.8227
16/16 [==============================] - 0s 771us/step - loss: 1.3532
16/16 [==============================] - 0s 771us/step - loss: 1.6509
16/16 [==============================] - 0s 1ms/step - loss: 1.7075
16/16 [==============================] - 0s 1ms/step - loss: 1.7219
16/16 [==============================] - 0s 1ms/step - loss: 1.7243
16/16 [==============================] - 0s 779us/step - loss: 1.7241
16/16 [==============================] - 0s 780us/step - loss: 1.7236
16/16 [==============================] - 0s 1ms/step - loss: 1.7232

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2430
16/16 [==============================] - 0s 782us/step - loss: 0.8187
16/16 [==============================] - 0s 772us/step - loss: 1.3371
16/16 [==============================] - 0s 800us/step - loss: 1.6239
16/16 [==============================] - 0s 776us/step - loss: 1.6777
16/16 [==============================] - 0s 773us/step - loss: 1.6911
16/16 [==============================] - 0s 779us/step - loss: 1.6933
16/16 [==============================] - 0s 812us/step - loss: 1.6930
16/16 [==============================] - 0s 782us/step - loss: 1.6925
16/16 [==============================] - 0s 780us/step - loss: 1.6920
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 829us/step - loss: 0.2215
16/16 [==============================] - 0s 781us/step - loss: 0.8192
16/16 [==============================] - 0s 816us/step - loss: 1.3681
16/16 [==============================] - 0s 778us/step - loss: 1.6695
16/16 [==============================] - 0s 806us/step - loss: 1.7252
16/16 [==============================] - 0s 772us/step - loss: 1.7389
16/16 [==============================] - 0s 774us/step - loss: 1.7410
16/16 [==============================] - 0s 1ms/step - loss: 1.7407
16/16 [==============================] - 0s 1ms/step - loss: 1.7401
16/16 [==============================] - 0s 802us/step - loss: 1.7396

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2442
16/16 [==============================] - 0s 778us/step - loss: 0.8062
16/16 [==============================] - 0s 781us/step - loss: 1.3207
16/16 [==============================] - 0s 775us/step - loss: 1.6016
16/16 [==============================] - 0s 788us/step - loss: 1.6528
16/16 [==============================] - 0s 790us/step - loss: 1.6652
16/16 [==============================] - 0s 1ms/step - loss: 1.6669
16/16 [==============================] - 0s 1ms/step - loss: 1.6666
16/16 [==============================] - 0s 1ms/step - loss: 1.6660
16/16 [==============================] - 0s 796us/step - loss: 1.6655
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 870us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2375
16/16 [==============================] - 0s 795us/step - loss: 0.8257
16/16 [==============================] - 0s 780us/step - loss: 1.3547
16/16 [==============================] - 0s 1ms/step - loss: 1.6472
16/16 [==============================] - 0s 1ms/step - loss: 1.6999
16/16 [==============================] - 0s 1ms/step - loss: 1.7126
16/16 [==============================] - 0s 776us/step - loss: 1.7144
16/16 [==============================] - 0s 804us/step - loss: 1.7139
16/16 [==============================] - 0s 803us/step - loss: 1.7134
16/16 [==============================] - 0s 807us/step - loss: 1.7129

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 850us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2315
16/16 [==============================] - 0s 774us/step - loss: 0.8231
16/16 [==============================] - 0s 812us/step - loss: 1.3534
16/16 [==============================] - 0s 777us/step - loss: 1.6488
16/16 [==============================] - 0s 772us/step - loss: 1.7017
16/16 [==============================] - 0s 1ms/step - loss: 1.7143
16/16 [==============================] - 0s 808us/step - loss: 1.7160
16/16 [==============================] - 0s 1ms/step - loss: 1.7156
16/16 [==============================] - 0s 1ms/step - loss: 1.7150
16/16 [==============================] - 0s 1ms/step - loss: 1.7145
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 791us/step - loss: 0.2183
16/16 [==============================] - 0s 1ms/step - loss: 0.8358
16/16 [==============================] - 0s 816us/step - loss: 1.3978
16/16 [==============================] - 0s 785us/step - loss: 1.7101
16/16 [==============================] - 0s 770us/step - loss: 1.7654
16/16 [==============================] - 0s 766us/step - loss: 1.7786
16/16 [==============================] - 0s 798us/step - loss: 1.7803
16/16 [==============================] - 0s 773us/step - loss: 1.7798
16/16 [==============================] - 0s 777us/step - loss: 1.7792
16/16 [==============================] - 0s 788us/step - loss: 1.7787

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 799us/step - loss: 0.2312
16/16 [==============================] - 0s 791us/step - loss: 0.8347
16/16 [==============================] - 0s 789us/step - loss: 1.3870
16/16 [==============================] - 0s 1ms/step - loss: 1.6952
16/16 [==============================] - 0s 1ms/step - loss: 1.7499
16/16 [==============================] - 0s 777us/step - loss: 1.7629
16/16 [==============================] - 0s 1ms/step - loss: 1.7646
16/16 [==============================] - 0s 1ms/step - loss: 1.7642
16/16 [==============================] - 0s 772us/step - loss: 1.7636
16/16 [==============================] - 0s 1ms/step - loss: 1.7631
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 832us/step
16/16 [==============================] - 0s 792us/step - loss: 0.2219
16/16 [==============================] - 0s 809us/step - loss: 0.8349
16/16 [==============================] - 0s 774us/step - loss: 1.4016
16/16 [==============================] - 0s 776us/step - loss: 1.7174
16/16 [==============================] - 0s 781us/step - loss: 1.7730
16/16 [==============================] - 0s 777us/step - loss: 1.7861
16/16 [==============================] - 0s 806us/step - loss: 1.7878
16/16 [==============================] - 0s 785us/step - loss: 1.7873
16/16 [==============================] - 0s 849us/step - loss: 1.7867
16/16 [==============================] - 0s 797us/step - loss: 1.7862

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 778us/step - loss: 0.2198
16/16 [==============================] - 0s 797us/step - loss: 0.8154
16/16 [==============================] - 0s 775us/step - loss: 1.3622
16/16 [==============================] - 0s 787us/step - loss: 1.6691
16/16 [==============================] - 0s 791us/step - loss: 1.7227
16/16 [==============================] - 0s 768us/step - loss: 1.7352
16/16 [==============================] - 0s 818us/step - loss: 1.7367
16/16 [==============================] - 0s 794us/step - loss: 1.7362
16/16 [==============================] - 0s 805us/step - loss: 1.7356
16/16 [==============================] - 0s 778us/step - loss: 1.7351
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2221
16/16 [==============================] - 0s 812us/step - loss: 0.8290
16/16 [==============================] - 0s 775us/step - loss: 1.3930
16/16 [==============================] - 0s 766us/step - loss: 1.6988
16/16 [==============================] - 0s 843us/step - loss: 1.7532
16/16 [==============================] - 0s 815us/step - loss: 1.7658
16/16 [==============================] - 0s 808us/step - loss: 1.7673
16/16 [==============================] - 0s 776us/step - loss: 1.7667
16/16 [==============================] - 0s 809us/step - loss: 1.7661
16/16 [==============================] - 0s 805us/step - loss: 1.7656

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2237
16/16 [==============================] - 0s 813us/step - loss: 0.8281
16/16 [==============================] - 0s 788us/step - loss: 1.4075
16/16 [==============================] - 0s 781us/step - loss: 1.7080
16/16 [==============================] - 0s 790us/step - loss: 1.7636
16/16 [==============================] - 0s 785us/step - loss: 1.7765
16/16 [==============================] - 0s 824us/step - loss: 1.7781
16/16 [==============================] - 0s 779us/step - loss: 1.7776
16/16 [==============================] - 0s 832us/step - loss: 1.7770
16/16 [==============================] - 0s 846us/step - loss: 1.7765
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 815us/step - loss: 0.2216
16/16 [==============================] - 0s 778us/step - loss: 0.8257
16/16 [==============================] - 0s 767us/step - loss: 1.4080
16/16 [==============================] - 0s 779us/step - loss: 1.7093
16/16 [==============================] - 0s 779us/step - loss: 1.7644
16/16 [==============================] - 0s 1ms/step - loss: 1.7769
16/16 [==============================] - 0s 1ms/step - loss: 1.7784
16/16 [==============================] - 0s 1ms/step - loss: 1.7778
16/16 [==============================] - 0s 1ms/step - loss: 1.7772
16/16 [==============================] - 0s 1ms/step - loss: 1.7767

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2256
16/16 [==============================] - 0s 827us/step - loss: 0.8196
16/16 [==============================] - 0s 816us/step - loss: 1.3982
16/16 [==============================] - 0s 798us/step - loss: 1.6984
16/16 [==============================] - 0s 784us/step - loss: 1.7537
16/16 [==============================] - 0s 821us/step - loss: 1.7663
16/16 [==============================] - 0s 1ms/step - loss: 1.7678
16/16 [==============================] - 0s 1ms/step - loss: 1.7672
16/16 [==============================] - 0s 1ms/step - loss: 1.7666
16/16 [==============================] - 0s 1ms/step - loss: 1.7661
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 849us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2225
16/16 [==============================] - 0s 811us/step - loss: 0.8187
16/16 [==============================] - 0s 808us/step - loss: 1.4016
16/16 [==============================] - 0s 778us/step - loss: 1.7034
16/16 [==============================] - 0s 1ms/step - loss: 1.7582
16/16 [==============================] - 0s 734us/step - loss: 1.7706
16/16 [==============================] - 0s 1ms/step - loss: 1.7720
16/16 [==============================] - 0s 792us/step - loss: 1.7713
16/16 [==============================] - 0s 786us/step - loss: 1.7707
16/16 [==============================] - 0s 775us/step - loss: 1.7702

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2222
16/16 [==============================] - 0s 763us/step - loss: 0.8215
16/16 [==============================] - 0s 769us/step - loss: 1.4169
16/16 [==============================] - 0s 758us/step - loss: 1.7273
16/16 [==============================] - 0s 1ms/step - loss: 1.7844
16/16 [==============================] - 0s 772us/step - loss: 1.7973
16/16 [==============================] - 0s 760us/step - loss: 1.7988
16/16 [==============================] - 0s 764us/step - loss: 1.7983
16/16 [==============================] - 0s 1ms/step - loss: 1.7976
16/16 [==============================] - 0s 798us/step - loss: 1.7971
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 844us/step
16/16 [==============================] - 0s 783us/step - loss: 0.2152
16/16 [==============================] - 0s 784us/step - loss: 0.8201
16/16 [==============================] - 0s 1ms/step - loss: 1.4240
16/16 [==============================] - 0s 1ms/step - loss: 1.7393
16/16 [==============================] - 0s 1ms/step - loss: 1.7968
16/16 [==============================] - 0s 1ms/step - loss: 1.8097
16/16 [==============================] - 0s 775us/step - loss: 1.8111
16/16 [==============================] - 0s 787us/step - loss: 1.8105
16/16 [==============================] - 0s 803us/step - loss: 1.8099
16/16 [==============================] - 0s 809us/step - loss: 1.8093

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 842us/step - loss: 0.2151
16/16 [==============================] - 0s 802us/step - loss: 0.8166
16/16 [==============================] - 0s 813us/step - loss: 1.4138
16/16 [==============================] - 0s 793us/step - loss: 1.7288
16/16 [==============================] - 0s 823us/step - loss: 1.7865
16/16 [==============================] - 0s 814us/step - loss: 1.7994
16/16 [==============================] - 0s 804us/step - loss: 1.8008
16/16 [==============================] - 0s 783us/step - loss: 1.8002
16/16 [==============================] - 0s 801us/step - loss: 1.7996
16/16 [==============================] - 0s 808us/step - loss: 1.7991
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 818us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2050
16/16 [==============================] - 0s 795us/step - loss: 0.8289
16/16 [==============================] - 0s 791us/step - loss: 1.4504
16/16 [==============================] - 0s 790us/step - loss: 1.7804
16/16 [==============================] - 0s 775us/step - loss: 1.8405
16/16 [==============================] - 0s 778us/step - loss: 1.8539
16/16 [==============================] - 0s 806us/step - loss: 1.8554
16/16 [==============================] - 0s 1ms/step - loss: 1.8548
16/16 [==============================] - 0s 1ms/step - loss: 1.8541
16/16 [==============================] - 0s 1ms/step - loss: 1.8536

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2105
16/16 [==============================] - 0s 793us/step - loss: 0.8226
16/16 [==============================] - 0s 1ms/step - loss: 1.4313
16/16 [==============================] - 0s 806us/step - loss: 1.7525
16/16 [==============================] - 0s 818us/step - loss: 1.8117
16/16 [==============================] - 0s 789us/step - loss: 1.8248
16/16 [==============================] - 0s 818us/step - loss: 1.8263
16/16 [==============================] - 0s 792us/step - loss: 1.8257
16/16 [==============================] - 0s 809us/step - loss: 1.8250
16/16 [==============================] - 0s 836us/step - loss: 1.8245
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 795us/step - loss: 0.2015
16/16 [==============================] - 0s 806us/step - loss: 0.8330
16/16 [==============================] - 0s 789us/step - loss: 1.4669
16/16 [==============================] - 0s 769us/step - loss: 1.8040
16/16 [==============================] - 0s 811us/step - loss: 1.8662
16/16 [==============================] - 0s 819us/step - loss: 1.8801
16/16 [==============================] - 0s 819us/step - loss: 1.8817
16/16 [==============================] - 0s 804us/step - loss: 1.8811
16/16 [==============================] - 0s 767us/step - loss: 1.8804
16/16 [==============================] - 0s 773us/step - loss: 1.8799

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2090
16/16 [==============================] - 0s 2ms/step - loss: 0.8199
16/16 [==============================] - 0s 2ms/step - loss: 1.4259
16/16 [==============================] - 0s 1ms/step - loss: 1.7494
16/16 [==============================] - 0s 752us/step - loss: 1.8087
16/16 [==============================] - 0s 775us/step - loss: 1.8217
16/16 [==============================] - 0s 790us/step - loss: 1.8231
16/16 [==============================] - 0s 772us/step - loss: 1.8224
16/16 [==============================] - 0s 2ms/step - loss: 1.8217
16/16 [==============================] - 0s 2ms/step - loss: 1.8212
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 936us/step
16/16 [==============================] - 0s 819us/step - loss: 0.2074
16/16 [==============================] - 0s 2ms/step - loss: 0.8283
16/16 [==============================] - 0s 2ms/step - loss: 1.4517
16/16 [==============================] - 0s 2ms/step - loss: 1.7854
16/16 [==============================] - 0s 770us/step - loss: 1.8463
16/16 [==============================] - 0s 2ms/step - loss: 1.8597
16/16 [==============================] - 0s 2ms/step - loss: 1.8611
16/16 [==============================] - 0s 2ms/step - loss: 1.8605
16/16 [==============================] - 0s 797us/step - loss: 1.8598
16/16 [==============================] - 0s 813us/step - loss: 1.8593

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2030
16/16 [==============================] - 0s 2ms/step - loss: 0.8287
16/16 [==============================] - 0s 2ms/step - loss: 1.4616
16/16 [==============================] - 0s 947us/step - loss: 1.8025
16/16 [==============================] - 0s 766us/step - loss: 1.8622
16/16 [==============================] - 0s 981us/step - loss: 1.8755
16/16 [==============================] - 0s 2ms/step - loss: 1.8769
16/16 [==============================] - 0s 1ms/step - loss: 1.8762
16/16 [==============================] - 0s 2ms/step - loss: 1.8755
16/16 [==============================] - 0s 833us/step - loss: 1.8750
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2062
16/16 [==============================] - 0s 2ms/step - loss: 0.8221
16/16 [==============================] - 0s 2ms/step - loss: 1.4472
16/16 [==============================] - 0s 2ms/step - loss: 1.7832
16/16 [==============================] - 0s 2ms/step - loss: 1.8412
16/16 [==============================] - 0s 2ms/step - loss: 1.8542
16/16 [==============================] - 0s 798us/step - loss: 1.8555
16/16 [==============================] - 0s 2ms/step - loss: 1.8548
16/16 [==============================] - 0s 827us/step - loss: 1.8541
16/16 [==============================] - 0s 1ms/step - loss: 1.8536

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 805us/step - loss: 0.2065
16/16 [==============================] - 0s 798us/step - loss: 0.8351
16/16 [==============================] - 0s 1ms/step - loss: 1.4656
16/16 [==============================] - 0s 2ms/step - loss: 1.8095
16/16 [==============================] - 0s 2ms/step - loss: 1.8689
16/16 [==============================] - 0s 2ms/step - loss: 1.8821
16/16 [==============================] - 0s 2ms/step - loss: 1.8835
16/16 [==============================] - 0s 2ms/step - loss: 1.8828
16/16 [==============================] - 0s 798us/step - loss: 1.8821
16/16 [==============================] - 0s 815us/step - loss: 1.8816
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1969
16/16 [==============================] - 0s 799us/step - loss: 0.8283
16/16 [==============================] - 0s 2ms/step - loss: 1.4682
16/16 [==============================] - 0s 2ms/step - loss: 1.8167
16/16 [==============================] - 0s 806us/step - loss: 1.8761
16/16 [==============================] - 0s 846us/step - loss: 1.8893
16/16 [==============================] - 0s 1ms/step - loss: 1.8905
16/16 [==============================] - 0s 802us/step - loss: 1.8898
16/16 [==============================] - 0s 1ms/step - loss: 1.8891
16/16 [==============================] - 0s 805us/step - loss: 1.8885

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 715us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2048
16/16 [==============================] - 0s 794us/step - loss: 0.8273
16/16 [==============================] - 0s 1ms/step - loss: 1.4605
16/16 [==============================] - 0s 893us/step - loss: 1.8055
16/16 [==============================] - 0s 2ms/step - loss: 1.8641
16/16 [==============================] - 0s 2ms/step - loss: 1.8770
16/16 [==============================] - 0s 808us/step - loss: 1.8782
16/16 [==============================] - 0s 1ms/step - loss: 1.8774
16/16 [==============================] - 0s 752us/step - loss: 1.8767
16/16 [==============================] - 0s 2ms/step - loss: 1.8762
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1993
16/16 [==============================] - 0s 2ms/step - loss: 0.8345
16/16 [==============================] - 0s 1ms/step - loss: 1.4813
16/16 [==============================] - 0s 801us/step - loss: 1.8351
16/16 [==============================] - 0s 762us/step - loss: 1.8942
16/16 [==============================] - 0s 801us/step - loss: 1.9073
16/16 [==============================] - 0s 2ms/step - loss: 1.9085
16/16 [==============================] - 0s 2ms/step - loss: 1.9077
16/16 [==============================] - 0s 2ms/step - loss: 1.9070
16/16 [==============================] - 0s 2ms/step - loss: 1.9065

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2034
16/16 [==============================] - 0s 2ms/step - loss: 0.8315
16/16 [==============================] - 0s 2ms/step - loss: 1.4620
16/16 [==============================] - 0s 799us/step - loss: 1.8092
16/16 [==============================] - 0s 1ms/step - loss: 1.8668
16/16 [==============================] - 0s 889us/step - loss: 1.8794
16/16 [==============================] - 0s 2ms/step - loss: 1.8805
16/16 [==============================] - 0s 867us/step - loss: 1.8796
16/16 [==============================] - 0s 939us/step - loss: 1.8789
16/16 [==============================] - 0s 843us/step - loss: 1.8784
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 570us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2014
16/16 [==============================] - 0s 819us/step - loss: 0.8300
16/16 [==============================] - 0s 788us/step - loss: 1.4568
16/16 [==============================] - 0s 828us/step - loss: 1.8020
16/16 [==============================] - 0s 2ms/step - loss: 1.8579
16/16 [==============================] - 0s 2ms/step - loss: 1.8700
16/16 [==============================] - 0s 2ms/step - loss: 1.8709
16/16 [==============================] - 0s 780us/step - loss: 1.8700
16/16 [==============================] - 0s 788us/step - loss: 1.8693
16/16 [==============================] - 0s 826us/step - loss: 1.8688

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 829us/step - loss: 0.2047
16/16 [==============================] - 0s 791us/step - loss: 0.8333
16/16 [==============================] - 0s 1ms/step - loss: 1.4539
16/16 [==============================] - 0s 827us/step - loss: 1.7984
16/16 [==============================] - 0s 837us/step - loss: 1.8540
16/16 [==============================] - 0s 826us/step - loss: 1.8659
16/16 [==============================] - 0s 2ms/step - loss: 1.8668
16/16 [==============================] - 0s 1ms/step - loss: 1.8659
16/16 [==============================] - 0s 1ms/step - loss: 1.8652
16/16 [==============================] - 0s 2ms/step - loss: 1.8646
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 779us/step - loss: 0.2034
16/16 [==============================] - 0s 853us/step - loss: 0.8267
16/16 [==============================] - 0s 2ms/step - loss: 1.4422
16/16 [==============================] - 0s 1ms/step - loss: 1.7828
16/16 [==============================] - 0s 868us/step - loss: 1.8365
16/16 [==============================] - 0s 1ms/step - loss: 1.8479
16/16 [==============================] - 0s 802us/step - loss: 1.8486
16/16 [==============================] - 0s 2ms/step - loss: 1.8477
16/16 [==============================] - 0s 1ms/step - loss: 1.8469
16/16 [==============================] - 0s 796us/step - loss: 1.8464

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 659us/step
16/16 [==============================] - 0s 857us/step - loss: 0.1954
16/16 [==============================] - 0s 850us/step - loss: 0.8554
16/16 [==============================] - 0s 763us/step - loss: 1.5063
16/16 [==============================] - 0s 847us/step - loss: 1.8737
16/16 [==============================] - 0s 774us/step - loss: 1.9321
16/16 [==============================] - 0s 773us/step - loss: 1.9449
16/16 [==============================] - 0s 786us/step - loss: 1.9459
16/16 [==============================] - 0s 769us/step - loss: 1.9451
16/16 [==============================] - 0s 775us/step - loss: 1.9444
16/16 [==============================] - 0s 781us/step - loss: 1.9439
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2032
16/16 [==============================] - 0s 770us/step - loss: 0.8365
16/16 [==============================] - 0s 851us/step - loss: 1.4474
16/16 [==============================] - 0s 779us/step - loss: 1.7883
16/16 [==============================] - 0s 761us/step - loss: 1.8403
16/16 [==============================] - 0s 771us/step - loss: 1.8511
16/16 [==============================] - 0s 766us/step - loss: 1.8516
16/16 [==============================] - 0s 766us/step - loss: 1.8506
16/16 [==============================] - 0s 762us/step - loss: 1.8498
16/16 [==============================] - 0s 775us/step - loss: 1.8493

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 762us/step - loss: 0.1946
16/16 [==============================] - 0s 781us/step - loss: 0.8535
16/16 [==============================] - 0s 813us/step - loss: 1.4905
16/16 [==============================] - 0s 795us/step - loss: 1.8507
16/16 [==============================] - 0s 818us/step - loss: 1.9058
16/16 [==============================] - 0s 1ms/step - loss: 1.9174
16/16 [==============================] - 0s 1ms/step - loss: 1.9180
16/16 [==============================] - 0s 787us/step - loss: 1.9171
16/16 [==============================] - 0s 785us/step - loss: 1.9163
16/16 [==============================] - 0s 789us/step - loss: 1.9158
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1920
16/16 [==============================] - 0s 1ms/step - loss: 0.8667
16/16 [==============================] - 0s 1ms/step - loss: 1.5162
16/16 [==============================] - 0s 1ms/step - loss: 1.8831
16/16 [==============================] - 0s 1ms/step - loss: 1.9383
16/16 [==============================] - 0s 1ms/step - loss: 1.9498
16/16 [==============================] - 0s 882us/step - loss: 1.9504
16/16 [==============================] - 0s 867us/step - loss: 1.9494
16/16 [==============================] - 0s 860us/step - loss: 1.9486
16/16 [==============================] - 0s 886us/step - loss: 1.9481

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1961
16/16 [==============================] - 0s 875us/step - loss: 0.8599
16/16 [==============================] - 0s 784us/step - loss: 1.4982
16/16 [==============================] - 0s 870us/step - loss: 1.8590
16/16 [==============================] - 0s 875us/step - loss: 1.9127
16/16 [==============================] - 0s 877us/step - loss: 1.9239
16/16 [==============================] - 0s 780us/step - loss: 1.9244
16/16 [==============================] - 0s 870us/step - loss: 1.9234
16/16 [==============================] - 0s 900us/step - loss: 1.9226
16/16 [==============================] - 0s 885us/step - loss: 1.9221
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1906
16/16 [==============================] - 0s 833us/step - loss: 0.8721
16/16 [==============================] - 0s 785us/step - loss: 1.5320
16/16 [==============================] - 0s 1ms/step - loss: 1.9031
16/16 [==============================] - 0s 1ms/step - loss: 1.9574
16/16 [==============================] - 0s 1ms/step - loss: 1.9686
16/16 [==============================] - 0s 1ms/step - loss: 1.9690
16/16 [==============================] - 0s 794us/step - loss: 1.9679
16/16 [==============================] - 0s 784us/step - loss: 1.9671
16/16 [==============================] - 0s 787us/step - loss: 1.9666

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1942
16/16 [==============================] - 0s 784us/step - loss: 0.8684
16/16 [==============================] - 0s 781us/step - loss: 1.5212
16/16 [==============================] - 0s 795us/step - loss: 1.8875
16/16 [==============================] - 0s 786us/step - loss: 1.9405
16/16 [==============================] - 0s 781us/step - loss: 1.9512
16/16 [==============================] - 0s 781us/step - loss: 1.9515
16/16 [==============================] - 0s 793us/step - loss: 1.9504
16/16 [==============================] - 0s 784us/step - loss: 1.9496
16/16 [==============================] - 0s 782us/step - loss: 1.9491
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1894
16/16 [==============================] - 0s 792us/step - loss: 0.8742
16/16 [==============================] - 0s 790us/step - loss: 1.5435
16/16 [==============================] - 0s 788us/step - loss: 1.9175
16/16 [==============================] - 0s 783us/step - loss: 1.9711
16/16 [==============================] - 0s 786us/step - loss: 1.9818
16/16 [==============================] - 0s 787us/step - loss: 1.9820
16/16 [==============================] - 0s 792us/step - loss: 1.9810
16/16 [==============================] - 0s 791us/step - loss: 1.9802
16/16 [==============================] - 0s 799us/step - loss: 1.9796

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1939
16/16 [==============================] - 0s 787us/step - loss: 0.8649
16/16 [==============================] - 0s 779us/step - loss: 1.5200
16/16 [==============================] - 0s 785us/step - loss: 1.8842
16/16 [==============================] - 0s 1ms/step - loss: 1.9357
16/16 [==============================] - 0s 1ms/step - loss: 1.9457
16/16 [==============================] - 0s 1ms/step - loss: 1.9458
16/16 [==============================] - 0s 1ms/step - loss: 1.9446
16/16 [==============================] - 0s 1ms/step - loss: 1.9438
16/16 [==============================] - 0s 1ms/step - loss: 1.9433
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 633us/step
16/16 [==============================] - 0s 846us/step - loss: 0.2051
16/16 [==============================] - 0s 793us/step - loss: 0.8592
16/16 [==============================] - 0s 840us/step - loss: 1.4964
16/16 [==============================] - 0s 794us/step - loss: 1.8473
16/16 [==============================] - 0s 812us/step - loss: 1.8961
16/16 [==============================] - 0s 792us/step - loss: 1.9052
16/16 [==============================] - 0s 815us/step - loss: 1.9052
16/16 [==============================] - 0s 812us/step - loss: 1.9040
16/16 [==============================] - 0s 830us/step - loss: 1.9033
16/16 [==============================] - 0s 807us/step - loss: 1.9027

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 794us/step - loss: 0.1899
16/16 [==============================] - 0s 809us/step - loss: 0.8706
16/16 [==============================] - 0s 808us/step - loss: 1.5429
16/16 [==============================] - 0s 823us/step - loss: 1.9137
16/16 [==============================] - 0s 816us/step - loss: 1.9652
16/16 [==============================] - 0s 787us/step - loss: 1.9749
16/16 [==============================] - 0s 784us/step - loss: 1.9749
16/16 [==============================] - 0s 817us/step - loss: 1.9737
16/16 [==============================] - 0s 779us/step - loss: 1.9729
16/16 [==============================] - 0s 818us/step - loss: 1.9724
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 620us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1924
16/16 [==============================] - 0s 802us/step - loss: 0.8632
16/16 [==============================] - 0s 819us/step - loss: 1.5266
16/16 [==============================] - 0s 1ms/step - loss: 1.8876
16/16 [==============================] - 0s 808us/step - loss: 1.9365
16/16 [==============================] - 0s 831us/step - loss: 1.9453
16/16 [==============================] - 0s 989us/step - loss: 1.9451
16/16 [==============================] - 0s 1ms/step - loss: 1.9439
16/16 [==============================] - 0s 1ms/step - loss: 1.9430
16/16 [==============================] - 0s 1ms/step - loss: 1.9425

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 805us/step - loss: 0.1927
16/16 [==============================] - 0s 887us/step - loss: 0.8685
16/16 [==============================] - 0s 811us/step - loss: 1.5446
16/16 [==============================] - 0s 805us/step - loss: 1.9131
16/16 [==============================] - 0s 819us/step - loss: 1.9631
16/16 [==============================] - 0s 811us/step - loss: 1.9722
16/16 [==============================] - 0s 811us/step - loss: 1.9721
16/16 [==============================] - 0s 827us/step - loss: 1.9708
16/16 [==============================] - 0s 821us/step - loss: 1.9700
16/16 [==============================] - 0s 798us/step - loss: 1.9695
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 804us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1900
16/16 [==============================] - 0s 794us/step - loss: 0.8666
16/16 [==============================] - 0s 829us/step - loss: 1.5422
16/16 [==============================] - 0s 799us/step - loss: 1.9066
16/16 [==============================] - 0s 789us/step - loss: 1.9549
16/16 [==============================] - 0s 821us/step - loss: 1.9633
16/16 [==============================] - 0s 797us/step - loss: 1.9630
16/16 [==============================] - 0s 806us/step - loss: 1.9617
16/16 [==============================] - 0s 1ms/step - loss: 1.9609
16/16 [==============================] - 0s 796us/step - loss: 1.9603

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 793us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1893
16/16 [==============================] - 0s 798us/step - loss: 0.8677
16/16 [==============================] - 0s 812us/step - loss: 1.5436
16/16 [==============================] - 0s 810us/step - loss: 1.9078
16/16 [==============================] - 0s 791us/step - loss: 1.9554
16/16 [==============================] - 0s 791us/step - loss: 1.9636
16/16 [==============================] - 0s 794us/step - loss: 1.9632
16/16 [==============================] - 0s 787us/step - loss: 1.9618
16/16 [==============================] - 0s 788us/step - loss: 1.9610
16/16 [==============================] - 0s 797us/step - loss: 1.9604
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1920
16/16 [==============================] - 0s 866us/step - loss: 0.8652
16/16 [==============================] - 0s 861us/step - loss: 1.5393
16/16 [==============================] - 0s 897us/step - loss: 1.8998
16/16 [==============================] - 0s 861us/step - loss: 1.9463
16/16 [==============================] - 0s 885us/step - loss: 1.9543
16/16 [==============================] - 0s 871us/step - loss: 1.9538
16/16 [==============================] - 0s 850us/step - loss: 1.9525
16/16 [==============================] - 0s 794us/step - loss: 1.9517
16/16 [==============================] - 0s 786us/step - loss: 1.9511

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1924
16/16 [==============================] - 0s 797us/step - loss: 0.8578
16/16 [==============================] - 0s 784us/step - loss: 1.5246
16/16 [==============================] - 0s 852us/step - loss: 1.8795
16/16 [==============================] - 0s 822us/step - loss: 1.9246
16/16 [==============================] - 0s 1ms/step - loss: 1.9321
16/16 [==============================] - 0s 1ms/step - loss: 1.9315
16/16 [==============================] - 0s 1ms/step - loss: 1.9302
16/16 [==============================] - 0s 849us/step - loss: 1.9293
16/16 [==============================] - 0s 797us/step - loss: 1.9288
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1912
16/16 [==============================] - 0s 793us/step - loss: 0.8643
16/16 [==============================] - 0s 786us/step - loss: 1.5409
16/16 [==============================] - 0s 839us/step - loss: 1.8974
16/16 [==============================] - 0s 825us/step - loss: 1.9422
16/16 [==============================] - 0s 783us/step - loss: 1.9491
16/16 [==============================] - 0s 785us/step - loss: 1.9485
16/16 [==============================] - 0s 1ms/step - loss: 1.9471
16/16 [==============================] - 0s 1ms/step - loss: 1.9462
16/16 [==============================] - 0s 1ms/step - loss: 1.9457

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1941
16/16 [==============================] - 0s 790us/step - loss: 0.8572
16/16 [==============================] - 0s 817us/step - loss: 1.5258
16/16 [==============================] - 0s 790us/step - loss: 1.8769
16/16 [==============================] - 0s 809us/step - loss: 1.9209
16/16 [==============================] - 0s 801us/step - loss: 1.9274
16/16 [==============================] - 0s 768us/step - loss: 1.9267
16/16 [==============================] - 0s 806us/step - loss: 1.9253
16/16 [==============================] - 0s 793us/step - loss: 1.9245
16/16 [==============================] - 0s 1ms/step - loss: 1.9239
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1994
16/16 [==============================] - 0s 790us/step - loss: 0.8588
16/16 [==============================] - 0s 783us/step - loss: 1.5245
16/16 [==============================] - 0s 789us/step - loss: 1.8703
16/16 [==============================] - 0s 783us/step - loss: 1.9128
16/16 [==============================] - 0s 803us/step - loss: 1.9189
16/16 [==============================] - 0s 804us/step - loss: 1.9181
16/16 [==============================] - 0s 792us/step - loss: 1.9167
16/16 [==============================] - 0s 808us/step - loss: 1.9159
16/16 [==============================] - 0s 1ms/step - loss: 1.9153

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1935
16/16 [==============================] - 0s 1ms/step - loss: 0.8608
16/16 [==============================] - 0s 1ms/step - loss: 1.5410
16/16 [==============================] - 0s 1ms/step - loss: 1.8951
16/16 [==============================] - 0s 1ms/step - loss: 1.9378
16/16 [==============================] - 0s 1ms/step - loss: 1.9441
16/16 [==============================] - 0s 1ms/step - loss: 1.9434
16/16 [==============================] - 0s 1ms/step - loss: 1.9420
16/16 [==============================] - 0s 1ms/step - loss: 1.9411
16/16 [==============================] - 0s 1ms/step - loss: 1.9406
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1915
16/16 [==============================] - 0s 1ms/step - loss: 0.8815
16/16 [==============================] - 0s 1ms/step - loss: 1.5885
16/16 [==============================] - 0s 1ms/step - loss: 1.9539
16/16 [==============================] - 0s 1ms/step - loss: 1.9968
16/16 [==============================] - 0s 1ms/step - loss: 2.0031
16/16 [==============================] - 0s 1ms/step - loss: 2.0023
16/16 [==============================] - 0s 1ms/step - loss: 2.0008
16/16 [==============================] - 0s 1ms/step - loss: 2.0000
16/16 [==============================] - 0s 855us/step - loss: 1.9994

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1896
16/16 [==============================] - 0s 794us/step - loss: 0.8657
16/16 [==============================] - 0s 822us/step - loss: 1.5564
16/16 [==============================] - 0s 1ms/step - loss: 1.9111
16/16 [==============================] - 0s 1ms/step - loss: 1.9520
16/16 [==============================] - 0s 862us/step - loss: 1.9577
16/16 [==============================] - 0s 866us/step - loss: 1.9567
16/16 [==============================] - 0s 876us/step - loss: 1.9552
16/16 [==============================] - 0s 871us/step - loss: 1.9543
16/16 [==============================] - 0s 806us/step - loss: 1.9538
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 652us/step
16/16 [==============================] - 0s 831us/step - loss: 0.1877
16/16 [==============================] - 0s 805us/step - loss: 0.8748
16/16 [==============================] - 0s 827us/step - loss: 1.5801
16/16 [==============================] - 0s 990us/step - loss: 1.9404
16/16 [==============================] - 0s 1ms/step - loss: 1.9818
16/16 [==============================] - 0s 825us/step - loss: 1.9875
16/16 [==============================] - 0s 1ms/step - loss: 1.9865
16/16 [==============================] - 0s 1ms/step - loss: 1.9850
16/16 [==============================] - 0s 1ms/step - loss: 1.9841
16/16 [==============================] - 0s 1ms/step - loss: 1.9836

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1924
16/16 [==============================] - 0s 1ms/step - loss: 0.8726
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
16/16 [==============================] - 0s 1ms/step - loss: 1.9322
16/16 [==============================] - 0s 833us/step - loss: 1.9733
16/16 [==============================] - 0s 820us/step - loss: 1.9790
16/16 [==============================] - 0s 768us/step - loss: 1.9780
16/16 [==============================] - 0s 836us/step - loss: 1.9766
16/16 [==============================] - 0s 1ms/step - loss: 1.9757
16/16 [==============================] - 0s 1ms/step - loss: 1.9752
32/32 [==============================] - 0s 595us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="368">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="369">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="370">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="371">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-104-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.943
Precision: 0.966
Recall: 0.975
F1 Score: 0.970</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="372">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="372">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.943</td>
      <td>0.965589</td>
      <td>0.974737</td>
      <td>0.970141</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lscpstar" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar">LSCP<span class="math inline">\(\star\)</span></h3>
<p>default=10%</p>
<div class="cell" data-execution_count="373">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="374">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="375">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="376">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="377">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-110-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.992
Precision: 0.996
Recall: 0.996
F1 Score: 0.996</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="378">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="378">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.992</td>
      <td>0.995789</td>
      <td>0.995789</td>
      <td>0.995789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="linear-result" class="level2">
<h2 class="anchored" data-anchor-id="linear-result">Linear Result</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen_linear,<span class="dv">3</span>)</span></code></pre></div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.926</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.984</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.885</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.936</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.943</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.970</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
</tr>
</tbody>
</table>
</section>
<section id="orbit-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="orbit-ebayesthresh">Orbit EbayesThresh</h2>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier <span class="op">=</span> which(signal<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier</span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>signal<span class="op">+</span>epsilon</span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a>plot(<span class="dv">1</span>:<span class="dv">1000</span>,x)</span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>points(index_of_trueoutlier,x[index_of_trueoutlier],col<span class="op">=</span><span class="dv">2</span>,cex<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-12"><a href="#cb148-12" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(x,type='l')</span></span>
<span id="cb148-13"><a href="#cb148-13" aria-hidden="true" tabindex="-1"></a><span class="co">#mu &lt;- EbayesThresh::ebayesthresh(x,sdev=2)</span></span>
<span id="cb148-14"><a href="#cb148-14" aria-hidden="true" tabindex="-1"></a><span class="co">#lines(mu,col=2,lty=2,lwd=2)</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-114-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="515">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier</span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal</span></code></pre></div>
</div>
<div class="cell" data-execution_count="516">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="517">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>xhat <span class="op">=</span> np.array(ebayesthresh(FloatVector(x)))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="518">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(x)</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(xhat)</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="519">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index <span class="op">=</span> index_of_trueoutlier</span></code></pre></div>
</div>
<div class="cell" data-execution_count="520">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value <span class="op">=</span> x[index_of_trueoutlier]</span></code></pre></div>
</div>
<p>package와 비교를 위해 outlier는 -1, inlier는 1로 표시</p>
<div class="cell" data-execution_count="521">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> signal.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="522">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one))</span></code></pre></div>
</div>
</section>
<section id="orbit" class="level2">
<h2 class="anchored" data-anchor-id="orbit">Orbit</h2>
<div class="cell" data-execution_count="523">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">777</span>)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>pi<span class="op">=</span>np.pi</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>ang<span class="op">=</span>np.linspace(<span class="op">-</span>pi,pi<span class="op">-</span><span class="dv">2</span><span class="op">*</span>pi<span class="op">/</span>n,n)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>r<span class="op">=</span><span class="dv">5</span><span class="op">+</span>np.cos(np.linspace(<span class="dv">0</span>,<span class="dv">12</span><span class="op">*</span>pi,n))</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>vx<span class="op">=</span>r<span class="op">*</span>np.cos(ang)</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>vy<span class="op">=</span>r<span class="op">*</span>np.sin(ang)</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span><span class="dv">10</span><span class="op">*</span>np.sin(np.linspace(<span class="dv">0</span>,<span class="dv">6</span><span class="op">*</span>pi,n))</span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f1 <span class="op">+</span> x</span></code></pre></div>
</div>
<div class="cell" data-execution_count="524">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span> : vx, <span class="st">'y'</span> : vy, <span class="st">'f'</span> : f})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="525">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<section id="gode-1" class="level3">
<h3 class="anchored" data-anchor-id="gode-1">GODE</h3>
<div class="cell" data-execution_count="526">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>_Orbit <span class="op">=</span> Orbit(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="527">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_distance()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1000/1000 [00:02&lt;00:00, 384.08it/s]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="528">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_weightmatrix(theta<span class="op">=</span>(_Orbit.D[_Orbit.D<span class="op">&gt;</span><span class="dv">0</span>].mean()),kappa<span class="op">=</span><span class="dv">2500</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="529">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>_Orbit.fit(sd<span class="op">=</span><span class="dv">15</span>,ref<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="558">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Orbit.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="559">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">13</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="560">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="560">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="561">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="561">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="562">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="563">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-135-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="565">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="565">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofstar">LOF<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-139-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.976
Recall: 0.976
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="169">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.954</td>
      <td>0.975789</td>
      <td>0.975789</td>
      <td>0.975789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="knn-1" class="level3">
<h3 class="anchored" data-anchor-id="knn-1">KNN</h3>
<div class="cell" data-tags="[]" data-execution_count="134">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="cblof" class="level3">
<h3 class="anchored" data-anchor-id="cblof">CBLOF</h3>
<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>four <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="ocsvm-1" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-1">OCSVM</h3>
<div class="cell" data-execution_count="170">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="171">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-157-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.908
Precision: 0.977
Recall: 0.925
F1 Score: 0.950</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="176">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.908</td>
      <td>0.976667</td>
      <td>0.925263</td>
      <td>0.95027</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mcdstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar-1">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="177">
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb202-2"><a href="#cb202-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb202-3"><a href="#cb202-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-163-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.916</td>
      <td>0.955789</td>
      <td>0.955789</td>
      <td>0.955789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="feature-baggingstar-1" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="184">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="185">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-169-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.969
Recall: 0.969
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="189">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.942</td>
      <td>0.969474</td>
      <td>0.969474</td>
      <td>0.969474</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="abodstar-1" class="level3">
<h3 class="anchored" data-anchor-id="abodstar-1">ABOD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="190">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-175-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="195">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="iforeststar-1" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar-1">IForest<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]],</span>
<span id="cb228-3"><a href="#cb228-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb228-4"><a href="#cb228-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="201">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="202">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="203">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-184-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.443
Precision: 0.992
Recall: 0.417
F1 Score: 0.587</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="204">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="204">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.443</td>
      <td>0.992481</td>
      <td>0.416842</td>
      <td>0.587102</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="hbosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar-1">HBOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="205">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb237-3"><a href="#cb237-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="206">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="207">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="208">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="209">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-190-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.960
Recall: 0.973
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="210">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="210">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.935</td>
      <td>0.959502</td>
      <td>0.972632</td>
      <td>0.966022</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="sosstar-1">SOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="211">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb245-2"><a href="#cb245-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb245-3"><a href="#cb245-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="212">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="213">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="214">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="215">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-196-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.974
Recall: 0.974
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="216">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="216">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.95</td>
      <td>0.973684</td>
      <td>0.973684</td>
      <td>0.973684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="so_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="217">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb253-2"><a href="#cb253-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb253-3"><a href="#cb253-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.2463

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.2638
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.2803

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.3116
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3359

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3306
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3703

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3762
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.3821

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4154
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.4274

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4426
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4476

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4723
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4929

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4871
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5141

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 932us/step - loss: 1.5047
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5151

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5108
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.5223

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5451
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5592

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5583
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.5766

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5713
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5877

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6025
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6303

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6321
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6358

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6567
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6791

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6957
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7147

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7083
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.7201

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7494
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7608

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7744
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7782

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8041
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.8156

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8259
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8290

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8340
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8584

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8740
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9041

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 898us/step - loss: 1.8801
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9261

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9211
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9269

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.9367
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9587

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 971us/step - loss: 1.9549
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9729

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9807
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 926us/step - loss: 2.0082

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0105
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 792us/step - loss: 2.0273

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 797us/step - loss: 2.0485
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 784us/step - loss: 2.0468

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 781us/step - loss: 2.0672
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 787us/step - loss: 2.0739

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 806us/step - loss: 2.0657
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 806us/step - loss: 2.0858

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 798us/step - loss: 2.0947
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1176

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 811us/step - loss: 2.1461
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 673us/step - loss: 2.1360

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 787us/step - loss: 2.1514
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1614

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 808us/step - loss: 2.1548
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 791us/step - loss: 2.1811

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 802us/step - loss: 2.1819
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 782us/step - loss: 2.2201

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 775us/step - loss: 2.2222
32/32 [==============================] - 0s 599us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="218">
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="219">
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="220">
<div class="sourceCode cell-code" id="cb258"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="221">
<div class="sourceCode cell-code" id="cb259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-202-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="222">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="222">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.95</td>
      <td>0.95</td>
      <td>1.0</td>
      <td>0.974359</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mo_gaalstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="223">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb263-2"><a href="#cb263-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb263-3"><a href="#cb263-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 612us/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 864us/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 646us/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 608us/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 609us/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 600us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 819us/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 615us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 617us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 650us/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 622us/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 851us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 602us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 861us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 605us/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 644us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 639us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 636us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 878us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 872us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 646us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 639us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 664us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 631us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 655us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 599us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 744us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 641us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 646us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 647us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 637us/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 641us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 873us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 586us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 573us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 829us/step - loss: 0.5766
16/16 [==============================] - 0s 1ms/step - loss: 1.0464
16/16 [==============================] - 0s 858us/step - loss: 1.0938
16/16 [==============================] - 0s 857us/step - loss: 1.1020
16/16 [==============================] - 0s 861us/step - loss: 1.1044
16/16 [==============================] - 0s 842us/step - loss: 1.1049
16/16 [==============================] - 0s 1ms/step - loss: 1.1050
16/16 [==============================] - 0s 862us/step - loss: 1.1050
16/16 [==============================] - 0s 851us/step - loss: 1.1050
16/16 [==============================] - 0s 871us/step - loss: 1.1050
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5693
16/16 [==============================] - 0s 1ms/step - loss: 1.0560
16/16 [==============================] - 0s 975us/step - loss: 1.1040
16/16 [==============================] - 0s 2ms/step - loss: 1.1121
16/16 [==============================] - 0s 2ms/step - loss: 1.1143
16/16 [==============================] - 0s 2ms/step - loss: 1.1148
16/16 [==============================] - 0s 1ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5640
16/16 [==============================] - 0s 1ms/step - loss: 1.0682
16/16 [==============================] - 0s 2ms/step - loss: 1.1167
16/16 [==============================] - 0s 2ms/step - loss: 1.1247
16/16 [==============================] - 0s 1ms/step - loss: 1.1269
16/16 [==============================] - 0s 874us/step - loss: 1.1274
16/16 [==============================] - 0s 865us/step - loss: 1.1274
16/16 [==============================] - 0s 1ms/step - loss: 1.1275
16/16 [==============================] - 0s 1ms/step - loss: 1.1275
16/16 [==============================] - 0s 2ms/step - loss: 1.1275
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 947us/step - loss: 0.5556
16/16 [==============================] - 0s 859us/step - loss: 1.0762
16/16 [==============================] - 0s 830us/step - loss: 1.1295
16/16 [==============================] - 0s 1ms/step - loss: 1.1374
16/16 [==============================] - 0s 863us/step - loss: 1.1397
16/16 [==============================] - 0s 1ms/step - loss: 1.1402
16/16 [==============================] - 0s 831us/step - loss: 1.1403
16/16 [==============================] - 0s 2ms/step - loss: 1.1403
16/16 [==============================] - 0s 2ms/step - loss: 1.1403
16/16 [==============================] - 0s 821us/step - loss: 1.1403

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5506
16/16 [==============================] - 0s 2ms/step - loss: 1.0873
16/16 [==============================] - 0s 2ms/step - loss: 1.1408
16/16 [==============================] - 0s 2ms/step - loss: 1.1487
16/16 [==============================] - 0s 1ms/step - loss: 1.1510
16/16 [==============================] - 0s 1ms/step - loss: 1.1515
16/16 [==============================] - 0s 1ms/step - loss: 1.1516
16/16 [==============================] - 0s 854us/step - loss: 1.1516
16/16 [==============================] - 0s 2ms/step - loss: 1.1516
16/16 [==============================] - 0s 889us/step - loss: 1.1516
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5415
16/16 [==============================] - 0s 2ms/step - loss: 1.1038
16/16 [==============================] - 0s 861us/step - loss: 1.1591
16/16 [==============================] - 0s 922us/step - loss: 1.1674
16/16 [==============================] - 0s 864us/step - loss: 1.1696
16/16 [==============================] - 0s 2ms/step - loss: 1.1701
16/16 [==============================] - 0s 2ms/step - loss: 1.1701
16/16 [==============================] - 0s 854us/step - loss: 1.1701
16/16 [==============================] - 0s 1ms/step - loss: 1.1701
16/16 [==============================] - 0s 1ms/step - loss: 1.1701

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5350
16/16 [==============================] - 0s 2ms/step - loss: 1.1180
16/16 [==============================] - 0s 2ms/step - loss: 1.1748
16/16 [==============================] - 0s 825us/step - loss: 1.1831
16/16 [==============================] - 0s 856us/step - loss: 1.1853
16/16 [==============================] - 0s 2ms/step - loss: 1.1858
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 833us/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 906us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5264
16/16 [==============================] - 0s 808us/step - loss: 1.1314
16/16 [==============================] - 0s 937us/step - loss: 1.1900
16/16 [==============================] - 0s 824us/step - loss: 1.1986
16/16 [==============================] - 0s 833us/step - loss: 1.2009
16/16 [==============================] - 0s 1ms/step - loss: 1.2014
16/16 [==============================] - 0s 811us/step - loss: 1.2014
16/16 [==============================] - 0s 2ms/step - loss: 1.2015
16/16 [==============================] - 0s 2ms/step - loss: 1.2015
16/16 [==============================] - 0s 2ms/step - loss: 1.2015

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 567us/step
16/16 [==============================] - 0s 841us/step - loss: 0.5216
16/16 [==============================] - 0s 1ms/step - loss: 1.1457
16/16 [==============================] - 0s 1ms/step - loss: 1.2047
16/16 [==============================] - 0s 679us/step - loss: 1.2133
16/16 [==============================] - 0s 666us/step - loss: 1.2156
16/16 [==============================] - 0s 833us/step - loss: 1.2161
16/16 [==============================] - 0s 802us/step - loss: 1.2162
16/16 [==============================] - 0s 786us/step - loss: 1.2162
16/16 [==============================] - 0s 797us/step - loss: 1.2162
16/16 [==============================] - 0s 788us/step - loss: 1.2162
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 865us/step - loss: 0.5150
16/16 [==============================] - 0s 870us/step - loss: 1.1494
16/16 [==============================] - 0s 774us/step - loss: 1.2095
16/16 [==============================] - 0s 775us/step - loss: 1.2182
16/16 [==============================] - 0s 824us/step - loss: 1.2205
16/16 [==============================] - 0s 788us/step - loss: 1.2210
16/16 [==============================] - 0s 773us/step - loss: 1.2211
16/16 [==============================] - 0s 774us/step - loss: 1.2211
16/16 [==============================] - 0s 776us/step - loss: 1.2211
16/16 [==============================] - 0s 861us/step - loss: 1.2211

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 785us/step - loss: 0.5109
16/16 [==============================] - 0s 812us/step - loss: 1.1619
16/16 [==============================] - 0s 1ms/step - loss: 1.2235
16/16 [==============================] - 0s 871us/step - loss: 1.2321
16/16 [==============================] - 0s 773us/step - loss: 1.2344
16/16 [==============================] - 0s 799us/step - loss: 1.2349
16/16 [==============================] - 0s 768us/step - loss: 1.2350
16/16 [==============================] - 0s 770us/step - loss: 1.2350
16/16 [==============================] - 0s 771us/step - loss: 1.2350
16/16 [==============================] - 0s 780us/step - loss: 1.2350
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 793us/step - loss: 0.5029
16/16 [==============================] - 0s 785us/step - loss: 1.1787
16/16 [==============================] - 0s 788us/step - loss: 1.2438
16/16 [==============================] - 0s 791us/step - loss: 1.2527
16/16 [==============================] - 0s 800us/step - loss: 1.2551
16/16 [==============================] - 0s 793us/step - loss: 1.2556
16/16 [==============================] - 0s 783us/step - loss: 1.2557
16/16 [==============================] - 0s 807us/step - loss: 1.2557
16/16 [==============================] - 0s 828us/step - loss: 1.2557
16/16 [==============================] - 0s 798us/step - loss: 1.2557

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 801us/step - loss: 0.5025
16/16 [==============================] - 0s 785us/step - loss: 1.1809
16/16 [==============================] - 0s 793us/step - loss: 1.2452
16/16 [==============================] - 0s 812us/step - loss: 1.2538
16/16 [==============================] - 0s 807us/step - loss: 1.2560
16/16 [==============================] - 0s 828us/step - loss: 1.2566
16/16 [==============================] - 0s 785us/step - loss: 1.2566
16/16 [==============================] - 0s 789us/step - loss: 1.2566
16/16 [==============================] - 0s 800us/step - loss: 1.2566
16/16 [==============================] - 0s 788us/step - loss: 1.2566
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 797us/step - loss: 0.4954
16/16 [==============================] - 0s 1ms/step - loss: 1.1997
16/16 [==============================] - 0s 1ms/step - loss: 1.2662
16/16 [==============================] - 0s 1ms/step - loss: 1.2750
16/16 [==============================] - 0s 1ms/step - loss: 1.2773
16/16 [==============================] - 0s 1ms/step - loss: 1.2778
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 826us/step
16/16 [==============================] - 0s 799us/step - loss: 0.4926
16/16 [==============================] - 0s 774us/step - loss: 1.2188
16/16 [==============================] - 0s 812us/step - loss: 1.2854
16/16 [==============================] - 0s 798us/step - loss: 1.2941
16/16 [==============================] - 0s 816us/step - loss: 1.2964
16/16 [==============================] - 0s 822us/step - loss: 1.2969
16/16 [==============================] - 0s 797us/step - loss: 1.2969
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 830us/step - loss: 0.4909
16/16 [==============================] - 0s 788us/step - loss: 1.2161
16/16 [==============================] - 0s 817us/step - loss: 1.2819
16/16 [==============================] - 0s 844us/step - loss: 1.2906
16/16 [==============================] - 0s 808us/step - loss: 1.2927
16/16 [==============================] - 0s 791us/step - loss: 1.2932
16/16 [==============================] - 0s 988us/step - loss: 1.2932
16/16 [==============================] - 0s 787us/step - loss: 1.2933
16/16 [==============================] - 0s 797us/step - loss: 1.2933
16/16 [==============================] - 0s 1ms/step - loss: 1.2933

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 802us/step - loss: 0.4908
16/16 [==============================] - 0s 803us/step - loss: 1.2300
16/16 [==============================] - 0s 801us/step - loss: 1.2947
16/16 [==============================] - 0s 783us/step - loss: 1.3035
16/16 [==============================] - 0s 1ms/step - loss: 1.3056
16/16 [==============================] - 0s 822us/step - loss: 1.3061
16/16 [==============================] - 0s 803us/step - loss: 1.3061
16/16 [==============================] - 0s 780us/step - loss: 1.3062
16/16 [==============================] - 0s 806us/step - loss: 1.3062
16/16 [==============================] - 0s 788us/step - loss: 1.3062
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4860
16/16 [==============================] - 0s 1ms/step - loss: 1.2481
16/16 [==============================] - 0s 1ms/step - loss: 1.3139
16/16 [==============================] - 0s 1ms/step - loss: 1.3229
16/16 [==============================] - 0s 833us/step - loss: 1.3251
16/16 [==============================] - 0s 1ms/step - loss: 1.3256
16/16 [==============================] - 0s 1ms/step - loss: 1.3256
16/16 [==============================] - 0s 1ms/step - loss: 1.3257
16/16 [==============================] - 0s 790us/step - loss: 1.3257
16/16 [==============================] - 0s 1ms/step - loss: 1.3257

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 852us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4867
16/16 [==============================] - 0s 1ms/step - loss: 1.2636
16/16 [==============================] - 0s 780us/step - loss: 1.3284
16/16 [==============================] - 0s 1ms/step - loss: 1.3373
16/16 [==============================] - 0s 1ms/step - loss: 1.3394
16/16 [==============================] - 0s 1ms/step - loss: 1.3399
16/16 [==============================] - 0s 1ms/step - loss: 1.3399
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 784us/step - loss: 0.4869
16/16 [==============================] - 0s 782us/step - loss: 1.2596
16/16 [==============================] - 0s 791us/step - loss: 1.3232
16/16 [==============================] - 0s 772us/step - loss: 1.3319
16/16 [==============================] - 0s 793us/step - loss: 1.3339
16/16 [==============================] - 0s 795us/step - loss: 1.3344
16/16 [==============================] - 0s 774us/step - loss: 1.3344
16/16 [==============================] - 0s 772us/step - loss: 1.3345
16/16 [==============================] - 0s 783us/step - loss: 1.3345
16/16 [==============================] - 0s 1ms/step - loss: 1.3345

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 788us/step - loss: 0.4871
16/16 [==============================] - 0s 788us/step - loss: 1.2850
16/16 [==============================] - 0s 785us/step - loss: 1.3492
16/16 [==============================] - 0s 776us/step - loss: 1.3579
16/16 [==============================] - 0s 1ms/step - loss: 1.3599
16/16 [==============================] - 0s 1ms/step - loss: 1.3604
16/16 [==============================] - 0s 1ms/step - loss: 1.3605
16/16 [==============================] - 0s 1ms/step - loss: 1.3605
16/16 [==============================] - 0s 780us/step - loss: 1.3605
16/16 [==============================] - 0s 776us/step - loss: 1.3605
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 847us/step
16/16 [==============================] - 0s 778us/step - loss: 0.4859
16/16 [==============================] - 0s 776us/step - loss: 1.2906
16/16 [==============================] - 0s 772us/step - loss: 1.3553
16/16 [==============================] - 0s 775us/step - loss: 1.3638
16/16 [==============================] - 0s 793us/step - loss: 1.3658
16/16 [==============================] - 0s 1ms/step - loss: 1.3663
16/16 [==============================] - 0s 820us/step - loss: 1.3664
16/16 [==============================] - 0s 811us/step - loss: 1.3664
16/16 [==============================] - 0s 782us/step - loss: 1.3664
16/16 [==============================] - 0s 1ms/step - loss: 1.3664

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 785us/step - loss: 0.4911
16/16 [==============================] - 0s 1ms/step - loss: 1.2887
16/16 [==============================] - 0s 1ms/step - loss: 1.3521
16/16 [==============================] - 0s 791us/step - loss: 1.3601
16/16 [==============================] - 0s 1ms/step - loss: 1.3620
16/16 [==============================] - 0s 815us/step - loss: 1.3625
16/16 [==============================] - 0s 804us/step - loss: 1.3625
16/16 [==============================] - 0s 777us/step - loss: 1.3625
16/16 [==============================] - 0s 767us/step - loss: 1.3625
16/16 [==============================] - 0s 780us/step - loss: 1.3625
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 781us/step - loss: 0.4892
16/16 [==============================] - 0s 770us/step - loss: 1.3080
16/16 [==============================] - 0s 781us/step - loss: 1.3727
16/16 [==============================] - 0s 773us/step - loss: 1.3807
16/16 [==============================] - 0s 773us/step - loss: 1.3826
16/16 [==============================] - 0s 1ms/step - loss: 1.3831
16/16 [==============================] - 0s 1ms/step - loss: 1.3832
16/16 [==============================] - 0s 1ms/step - loss: 1.3832
16/16 [==============================] - 0s 766us/step - loss: 1.3832
16/16 [==============================] - 0s 1ms/step - loss: 1.3832

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 855us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4938
16/16 [==============================] - 0s 798us/step - loss: 1.3114
16/16 [==============================] - 0s 785us/step - loss: 1.3752
16/16 [==============================] - 0s 790us/step - loss: 1.3827
16/16 [==============================] - 0s 783us/step - loss: 1.3846
16/16 [==============================] - 0s 810us/step - loss: 1.3851
16/16 [==============================] - 0s 788us/step - loss: 1.3852
16/16 [==============================] - 0s 834us/step - loss: 1.3852
16/16 [==============================] - 0s 768us/step - loss: 1.3852
16/16 [==============================] - 0s 775us/step - loss: 1.3852
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 780us/step - loss: 0.4942
16/16 [==============================] - 0s 778us/step - loss: 1.3220
16/16 [==============================] - 0s 789us/step - loss: 1.3861
16/16 [==============================] - 0s 785us/step - loss: 1.3935
16/16 [==============================] - 0s 775us/step - loss: 1.3954
16/16 [==============================] - 0s 814us/step - loss: 1.3958
16/16 [==============================] - 0s 777us/step - loss: 1.3959
16/16 [==============================] - 0s 767us/step - loss: 1.3959
16/16 [==============================] - 0s 785us/step - loss: 1.3959
16/16 [==============================] - 0s 772us/step - loss: 1.3959

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 805us/step - loss: 0.4983
16/16 [==============================] - 0s 786us/step - loss: 1.3372
16/16 [==============================] - 0s 774us/step - loss: 1.4013
16/16 [==============================] - 0s 802us/step - loss: 1.4084
16/16 [==============================] - 0s 775us/step - loss: 1.4103
16/16 [==============================] - 0s 804us/step - loss: 1.4108
16/16 [==============================] - 0s 781us/step - loss: 1.4108
16/16 [==============================] - 0s 781us/step - loss: 1.4108
16/16 [==============================] - 0s 782us/step - loss: 1.4108
16/16 [==============================] - 0s 789us/step - loss: 1.4108
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 786us/step - loss: 0.5005
16/16 [==============================] - 0s 778us/step - loss: 1.3357
16/16 [==============================] - 0s 777us/step - loss: 1.3989
16/16 [==============================] - 0s 773us/step - loss: 1.4057
16/16 [==============================] - 0s 771us/step - loss: 1.4076
16/16 [==============================] - 0s 798us/step - loss: 1.4080
16/16 [==============================] - 0s 870us/step - loss: 1.4081
16/16 [==============================] - 0s 799us/step - loss: 1.4081
16/16 [==============================] - 0s 788us/step - loss: 1.4081
16/16 [==============================] - 0s 798us/step - loss: 1.4081

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 786us/step - loss: 0.5063
16/16 [==============================] - 0s 780us/step - loss: 1.3477
16/16 [==============================] - 0s 785us/step - loss: 1.4105
16/16 [==============================] - 0s 808us/step - loss: 1.4171
16/16 [==============================] - 0s 775us/step - loss: 1.4189
16/16 [==============================] - 0s 813us/step - loss: 1.4193
16/16 [==============================] - 0s 784us/step - loss: 1.4194
16/16 [==============================] - 0s 791us/step - loss: 1.4194
16/16 [==============================] - 0s 823us/step - loss: 1.4195
16/16 [==============================] - 0s 827us/step - loss: 1.4195
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 646us/step
16/16 [==============================] - 0s 884us/step - loss: 0.5084
16/16 [==============================] - 0s 826us/step - loss: 1.3507
16/16 [==============================] - 0s 857us/step - loss: 1.4129
16/16 [==============================] - 0s 806us/step - loss: 1.4193
16/16 [==============================] - 0s 899us/step - loss: 1.4210
16/16 [==============================] - 0s 890us/step - loss: 1.4214
16/16 [==============================] - 0s 897us/step - loss: 1.4215
16/16 [==============================] - 0s 911us/step - loss: 1.4215
16/16 [==============================] - 0s 882us/step - loss: 1.4215
16/16 [==============================] - 0s 886us/step - loss: 1.4215

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 831us/step - loss: 0.5137
16/16 [==============================] - 0s 847us/step - loss: 1.3616
16/16 [==============================] - 0s 806us/step - loss: 1.4231
16/16 [==============================] - 0s 777us/step - loss: 1.4294
16/16 [==============================] - 0s 894us/step - loss: 1.4309
16/16 [==============================] - 0s 807us/step - loss: 1.4314
16/16 [==============================] - 0s 895us/step - loss: 1.4314
16/16 [==============================] - 0s 854us/step - loss: 1.4315
16/16 [==============================] - 0s 817us/step - loss: 1.4315
16/16 [==============================] - 0s 824us/step - loss: 1.4315
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 816us/step
16/16 [==============================] - 0s 825us/step - loss: 0.5156
16/16 [==============================] - 0s 1ms/step - loss: 1.3670
16/16 [==============================] - 0s 884us/step - loss: 1.4273
16/16 [==============================] - 0s 786us/step - loss: 1.4336
16/16 [==============================] - 0s 1ms/step - loss: 1.4351
16/16 [==============================] - 0s 812us/step - loss: 1.4355
16/16 [==============================] - 0s 874us/step - loss: 1.4356
16/16 [==============================] - 0s 797us/step - loss: 1.4356
16/16 [==============================] - 0s 799us/step - loss: 1.4356
16/16 [==============================] - 0s 815us/step - loss: 1.4356

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 719us/step
16/16 [==============================] - 0s 876us/step - loss: 0.5224
16/16 [==============================] - 0s 797us/step - loss: 1.3726
16/16 [==============================] - 0s 884us/step - loss: 1.4310
16/16 [==============================] - 0s 817us/step - loss: 1.4370
16/16 [==============================] - 0s 817us/step - loss: 1.4385
16/16 [==============================] - 0s 808us/step - loss: 1.4389
16/16 [==============================] - 0s 788us/step - loss: 1.4390
16/16 [==============================] - 0s 810us/step - loss: 1.4390
16/16 [==============================] - 0s 833us/step - loss: 1.4390
16/16 [==============================] - 0s 781us/step - loss: 1.4390
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 730us/step
16/16 [==============================] - 0s 876us/step - loss: 0.5231
16/16 [==============================] - 0s 865us/step - loss: 1.3945
16/16 [==============================] - 0s 863us/step - loss: 1.4537
16/16 [==============================] - 0s 866us/step - loss: 1.4598
16/16 [==============================] - 0s 892us/step - loss: 1.4613
16/16 [==============================] - 0s 878us/step - loss: 1.4617
16/16 [==============================] - 0s 859us/step - loss: 1.4618
16/16 [==============================] - 0s 856us/step - loss: 1.4618
16/16 [==============================] - 0s 858us/step - loss: 1.4618
16/16 [==============================] - 0s 860us/step - loss: 1.4618

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 797us/step - loss: 0.5304
16/16 [==============================] - 0s 808us/step - loss: 1.3896
16/16 [==============================] - 0s 785us/step - loss: 1.4472
16/16 [==============================] - 0s 788us/step - loss: 1.4530
16/16 [==============================] - 0s 826us/step - loss: 1.4543
16/16 [==============================] - 0s 812us/step - loss: 1.4547
16/16 [==============================] - 0s 786us/step - loss: 1.4547
16/16 [==============================] - 0s 784us/step - loss: 1.4547
16/16 [==============================] - 0s 794us/step - loss: 1.4547
16/16 [==============================] - 0s 790us/step - loss: 1.4547
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 838us/step - loss: 0.5317
16/16 [==============================] - 0s 795us/step - loss: 1.4114
16/16 [==============================] - 0s 826us/step - loss: 1.4698
16/16 [==============================] - 0s 797us/step - loss: 1.4756
16/16 [==============================] - 0s 798us/step - loss: 1.4770
16/16 [==============================] - 0s 814us/step - loss: 1.4774
16/16 [==============================] - 0s 828us/step - loss: 1.4775
16/16 [==============================] - 0s 841us/step - loss: 1.4775
16/16 [==============================] - 0s 833us/step - loss: 1.4775
16/16 [==============================] - 0s 788us/step - loss: 1.4775

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 693us/step
16/16 [==============================] - 0s 873us/step - loss: 0.5384
16/16 [==============================] - 0s 859us/step - loss: 1.4133
16/16 [==============================] - 0s 865us/step - loss: 1.4700
16/16 [==============================] - 0s 869us/step - loss: 1.4756
16/16 [==============================] - 0s 865us/step - loss: 1.4769
16/16 [==============================] - 0s 883us/step - loss: 1.4773
16/16 [==============================] - 0s 798us/step - loss: 1.4774
16/16 [==============================] - 0s 823us/step - loss: 1.4774
16/16 [==============================] - 0s 799us/step - loss: 1.4774
16/16 [==============================] - 0s 791us/step - loss: 1.4774
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 841us/step - loss: 0.5404
16/16 [==============================] - 0s 812us/step - loss: 1.4280
16/16 [==============================] - 0s 839us/step - loss: 1.4849
16/16 [==============================] - 0s 846us/step - loss: 1.4905
16/16 [==============================] - 0s 804us/step - loss: 1.4919
16/16 [==============================] - 0s 793us/step - loss: 1.4923
16/16 [==============================] - 0s 794us/step - loss: 1.4924
16/16 [==============================] - 0s 788us/step - loss: 1.4924
16/16 [==============================] - 0s 798us/step - loss: 1.4924
16/16 [==============================] - 0s 799us/step - loss: 1.4924

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 674us/step
16/16 [==============================] - 0s 806us/step - loss: 0.5472
16/16 [==============================] - 0s 791us/step - loss: 1.4360
16/16 [==============================] - 0s 792us/step - loss: 1.4914
16/16 [==============================] - 0s 788us/step - loss: 1.4970
16/16 [==============================] - 0s 787us/step - loss: 1.4983
16/16 [==============================] - 0s 782us/step - loss: 1.4987
16/16 [==============================] - 0s 783us/step - loss: 1.4988
16/16 [==============================] - 0s 806us/step - loss: 1.4988
16/16 [==============================] - 0s 789us/step - loss: 1.4988
16/16 [==============================] - 0s 806us/step - loss: 1.4988
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 806us/step - loss: 0.5490
16/16 [==============================] - 0s 800us/step - loss: 1.4384
16/16 [==============================] - 0s 808us/step - loss: 1.4933
16/16 [==============================] - 0s 802us/step - loss: 1.4988
16/16 [==============================] - 0s 804us/step - loss: 1.5001
16/16 [==============================] - 0s 840us/step - loss: 1.5005
16/16 [==============================] - 0s 792us/step - loss: 1.5006
16/16 [==============================] - 0s 798us/step - loss: 1.5006
16/16 [==============================] - 0s 824us/step - loss: 1.5006
16/16 [==============================] - 0s 801us/step - loss: 1.5006

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 803us/step - loss: 0.5552
16/16 [==============================] - 0s 798us/step - loss: 1.4452
16/16 [==============================] - 0s 812us/step - loss: 1.4995
16/16 [==============================] - 0s 803us/step - loss: 1.5049
16/16 [==============================] - 0s 834us/step - loss: 1.5061
16/16 [==============================] - 0s 797us/step - loss: 1.5065
16/16 [==============================] - 0s 804us/step - loss: 1.5066
16/16 [==============================] - 0s 797us/step - loss: 1.5066
16/16 [==============================] - 0s 801us/step - loss: 1.5066
16/16 [==============================] - 0s 782us/step - loss: 1.5066
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 811us/step - loss: 0.5568
16/16 [==============================] - 0s 791us/step - loss: 1.4605
16/16 [==============================] - 0s 874us/step - loss: 1.5154
16/16 [==============================] - 0s 796us/step - loss: 1.5208
16/16 [==============================] - 0s 789us/step - loss: 1.5220
16/16 [==============================] - 0s 787us/step - loss: 1.5224
16/16 [==============================] - 0s 783us/step - loss: 1.5225
16/16 [==============================] - 0s 793us/step - loss: 1.5225
16/16 [==============================] - 0s 808us/step - loss: 1.5225
16/16 [==============================] - 0s 821us/step - loss: 1.5225

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 793us/step - loss: 0.5636
16/16 [==============================] - 0s 788us/step - loss: 1.4727
16/16 [==============================] - 0s 785us/step - loss: 1.5280
16/16 [==============================] - 0s 866us/step - loss: 1.5334
16/16 [==============================] - 0s 859us/step - loss: 1.5346
16/16 [==============================] - 0s 882us/step - loss: 1.5350
16/16 [==============================] - 0s 856us/step - loss: 1.5350
16/16 [==============================] - 0s 886us/step - loss: 1.5351
16/16 [==============================] - 0s 857us/step - loss: 1.5351
16/16 [==============================] - 0s 860us/step - loss: 1.5351
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 692us/step
16/16 [==============================] - 0s 851us/step - loss: 0.5649
16/16 [==============================] - 0s 812us/step - loss: 1.4776
16/16 [==============================] - 0s 678us/step - loss: 1.5327
16/16 [==============================] - 0s 1ms/step - loss: 1.5382
16/16 [==============================] - 0s 791us/step - loss: 1.5393
16/16 [==============================] - 0s 780us/step - loss: 1.5397
16/16 [==============================] - 0s 763us/step - loss: 1.5398
16/16 [==============================] - 0s 675us/step - loss: 1.5398
16/16 [==============================] - 0s 741us/step - loss: 1.5398
16/16 [==============================] - 0s 1ms/step - loss: 1.5398

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 676us/step
16/16 [==============================] - 0s 880us/step - loss: 0.5713
16/16 [==============================] - 0s 788us/step - loss: 1.4905
16/16 [==============================] - 0s 804us/step - loss: 1.5460
16/16 [==============================] - 0s 785us/step - loss: 1.5514
16/16 [==============================] - 0s 803us/step - loss: 1.5526
16/16 [==============================] - 0s 788us/step - loss: 1.5530
16/16 [==============================] - 0s 780us/step - loss: 1.5530
16/16 [==============================] - 0s 804us/step - loss: 1.5531
16/16 [==============================] - 0s 781us/step - loss: 1.5531
16/16 [==============================] - 0s 780us/step - loss: 1.5531
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 770us/step
16/16 [==============================] - 0s 849us/step - loss: 0.5726
16/16 [==============================] - 0s 794us/step - loss: 1.4976
16/16 [==============================] - 0s 797us/step - loss: 1.5531
16/16 [==============================] - 0s 801us/step - loss: 1.5585
16/16 [==============================] - 0s 798us/step - loss: 1.5597
16/16 [==============================] - 0s 787us/step - loss: 1.5601
16/16 [==============================] - 0s 806us/step - loss: 1.5602
16/16 [==============================] - 0s 798us/step - loss: 1.5602
16/16 [==============================] - 0s 822us/step - loss: 1.5602
16/16 [==============================] - 0s 797us/step - loss: 1.5602

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 800us/step - loss: 0.5787
16/16 [==============================] - 0s 782us/step - loss: 1.5036
16/16 [==============================] - 0s 794us/step - loss: 1.5586
16/16 [==============================] - 0s 783us/step - loss: 1.5639
16/16 [==============================] - 0s 790us/step - loss: 1.5650
16/16 [==============================] - 0s 780us/step - loss: 1.5654
16/16 [==============================] - 0s 802us/step - loss: 1.5655
16/16 [==============================] - 0s 876us/step - loss: 1.5655
16/16 [==============================] - 0s 866us/step - loss: 1.5655
16/16 [==============================] - 0s 798us/step - loss: 1.5655
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 700us/step
16/16 [==============================] - 0s 873us/step - loss: 0.5799
16/16 [==============================] - 0s 868us/step - loss: 1.5106
16/16 [==============================] - 0s 798us/step - loss: 1.5655
16/16 [==============================] - 0s 810us/step - loss: 1.5708
16/16 [==============================] - 0s 792us/step - loss: 1.5719
16/16 [==============================] - 0s 783us/step - loss: 1.5723
16/16 [==============================] - 0s 791us/step - loss: 1.5724
16/16 [==============================] - 0s 784us/step - loss: 1.5724
16/16 [==============================] - 0s 789us/step - loss: 1.5724
16/16 [==============================] - 0s 790us/step - loss: 1.5724

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 799us/step - loss: 0.5865
16/16 [==============================] - 0s 793us/step - loss: 1.5229
16/16 [==============================] - 0s 798us/step - loss: 1.5778
16/16 [==============================] - 0s 800us/step - loss: 1.5830
16/16 [==============================] - 0s 793us/step - loss: 1.5841
16/16 [==============================] - 0s 778us/step - loss: 1.5846
16/16 [==============================] - 0s 775us/step - loss: 1.5847
16/16 [==============================] - 0s 784us/step - loss: 1.5847
16/16 [==============================] - 0s 768us/step - loss: 1.5847
16/16 [==============================] - 0s 783us/step - loss: 1.5847
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 597us/step
16/16 [==============================] - 0s 862us/step - loss: 0.5874
16/16 [==============================] - 0s 777us/step - loss: 1.5260
16/16 [==============================] - 0s 805us/step - loss: 1.5806
16/16 [==============================] - 0s 791us/step - loss: 1.5858
16/16 [==============================] - 0s 796us/step - loss: 1.5869
16/16 [==============================] - 0s 771us/step - loss: 1.5874
16/16 [==============================] - 0s 774us/step - loss: 1.5874
16/16 [==============================] - 0s 783us/step - loss: 1.5875
16/16 [==============================] - 0s 800us/step - loss: 1.5875
16/16 [==============================] - 0s 800us/step - loss: 1.5875

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 802us/step - loss: 0.5942
16/16 [==============================] - 0s 812us/step - loss: 1.5376
16/16 [==============================] - 0s 788us/step - loss: 1.5921
16/16 [==============================] - 0s 788us/step - loss: 1.5972
16/16 [==============================] - 0s 792us/step - loss: 1.5983
16/16 [==============================] - 0s 783us/step - loss: 1.5987
16/16 [==============================] - 0s 780us/step - loss: 1.5988
16/16 [==============================] - 0s 808us/step - loss: 1.5988
16/16 [==============================] - 0s 781us/step - loss: 1.5988
16/16 [==============================] - 0s 778us/step - loss: 1.5988
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 820us/step - loss: 0.5951
16/16 [==============================] - 0s 863us/step - loss: 1.5463
16/16 [==============================] - 0s 794us/step - loss: 1.6008
16/16 [==============================] - 0s 802us/step - loss: 1.6059
16/16 [==============================] - 0s 877us/step - loss: 1.6070
16/16 [==============================] - 0s 873us/step - loss: 1.6075
16/16 [==============================] - 0s 869us/step - loss: 1.6076
16/16 [==============================] - 0s 881us/step - loss: 1.6076
16/16 [==============================] - 0s 874us/step - loss: 1.6076
16/16 [==============================] - 0s 803us/step - loss: 1.6076

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 873us/step - loss: 0.6017
16/16 [==============================] - 0s 876us/step - loss: 1.5594
16/16 [==============================] - 0s 859us/step - loss: 1.6138
16/16 [==============================] - 0s 791us/step - loss: 1.6189
16/16 [==============================] - 0s 799us/step - loss: 1.6199
16/16 [==============================] - 0s 783us/step - loss: 1.6204
16/16 [==============================] - 0s 803us/step - loss: 1.6204
16/16 [==============================] - 0s 794us/step - loss: 1.6204
16/16 [==============================] - 0s 790us/step - loss: 1.6204
16/16 [==============================] - 0s 769us/step - loss: 1.6204
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 655us/step
16/16 [==============================] - 0s 899us/step - loss: 0.6031
16/16 [==============================] - 0s 10ms/step - loss: 1.5670
16/16 [==============================] - 0s 5ms/step - loss: 1.6213
16/16 [==============================] - 0s 2ms/step - loss: 1.6263
16/16 [==============================] - 0s 3ms/step - loss: 1.6274
16/16 [==============================] - 0s 2ms/step - loss: 1.6279
16/16 [==============================] - 0s 2ms/step - loss: 1.6280
16/16 [==============================] - 0s 5ms/step - loss: 1.6280
16/16 [==============================] - 0s 2ms/step - loss: 1.6280
16/16 [==============================] - 0s 1ms/step - loss: 1.6280

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.6099
16/16 [==============================] - 0s 6ms/step - loss: 1.5795
16/16 [==============================] - 0s 3ms/step - loss: 1.6337
16/16 [==============================] - 0s 3ms/step - loss: 1.6386
16/16 [==============================] - 0s 1ms/step - loss: 1.6397
16/16 [==============================] - 0s 2ms/step - loss: 1.6401
16/16 [==============================] - 0s 5ms/step - loss: 1.6402
16/16 [==============================] - 0s 6ms/step - loss: 1.6402
16/16 [==============================] - 0s 5ms/step - loss: 1.6402
16/16 [==============================] - 0s 3ms/step - loss: 1.6402
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6110
16/16 [==============================] - 0s 2ms/step - loss: 1.5866
16/16 [==============================] - 0s 3ms/step - loss: 1.6408
16/16 [==============================] - 0s 2ms/step - loss: 1.6457
16/16 [==============================] - 0s 2ms/step - loss: 1.6468
16/16 [==============================] - 0s 4ms/step - loss: 1.6472
16/16 [==============================] - 0s 4ms/step - loss: 1.6472
16/16 [==============================] - 0s 5ms/step - loss: 1.6473
16/16 [==============================] - 0s 2ms/step - loss: 1.6473
16/16 [==============================] - 0s 5ms/step - loss: 1.6473

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6166
16/16 [==============================] - 0s 2ms/step - loss: 1.5886
16/16 [==============================] - 0s 2ms/step - loss: 1.6420
16/16 [==============================] - 0s 3ms/step - loss: 1.6468
16/16 [==============================] - 0s 2ms/step - loss: 1.6479
16/16 [==============================] - 0s 2ms/step - loss: 1.6484
16/16 [==============================] - 0s 1ms/step - loss: 1.6485
16/16 [==============================] - 0s 2ms/step - loss: 1.6485
16/16 [==============================] - 0s 5ms/step - loss: 1.6485
16/16 [==============================] - 0s 2ms/step - loss: 1.6485
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.6181
16/16 [==============================] - 0s 2ms/step - loss: 1.5963
16/16 [==============================] - 0s 4ms/step - loss: 1.6496
16/16 [==============================] - 0s 3ms/step - loss: 1.6544
16/16 [==============================] - 0s 2ms/step - loss: 1.6555
16/16 [==============================] - 0s 1ms/step - loss: 1.6559
16/16 [==============================] - 0s 2ms/step - loss: 1.6560
16/16 [==============================] - 0s 2ms/step - loss: 1.6560
16/16 [==============================] - 0s 1ms/step - loss: 1.6560
16/16 [==============================] - 0s 1ms/step - loss: 1.6560

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6242
16/16 [==============================] - 0s 2ms/step - loss: 1.5993
16/16 [==============================] - 0s 4ms/step - loss: 1.6519
16/16 [==============================] - 0s 2ms/step - loss: 1.6566
16/16 [==============================] - 0s 1ms/step - loss: 1.6577
16/16 [==============================] - 0s 2ms/step - loss: 1.6581
16/16 [==============================] - 0s 4ms/step - loss: 1.6582
16/16 [==============================] - 0s 2ms/step - loss: 1.6582
16/16 [==============================] - 0s 1ms/step - loss: 1.6582
16/16 [==============================] - 0s 4ms/step - loss: 1.6582
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6275
16/16 [==============================] - 0s 2ms/step - loss: 1.6267
16/16 [==============================] - 0s 3ms/step - loss: 1.6803
16/16 [==============================] - 0s 4ms/step - loss: 1.6852
16/16 [==============================] - 0s 2ms/step - loss: 1.6863
16/16 [==============================] - 0s 2ms/step - loss: 1.6867
16/16 [==============================] - 0s 2ms/step - loss: 1.6868
16/16 [==============================] - 0s 4ms/step - loss: 1.6868
16/16 [==============================] - 0s 2ms/step - loss: 1.6868
16/16 [==============================] - 0s 3ms/step - loss: 1.6868

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 4ms/step
16/16 [==============================] - 0s 6ms/step - loss: 0.6335
16/16 [==============================] - 0s 3ms/step - loss: 1.6307
16/16 [==============================] - 0s 2ms/step - loss: 1.6837
16/16 [==============================] - 0s 2ms/step - loss: 1.6884
16/16 [==============================] - 0s 3ms/step - loss: 1.6894
16/16 [==============================] - 0s 2ms/step - loss: 1.6898
16/16 [==============================] - 0s 2ms/step - loss: 1.6899
16/16 [==============================] - 0s 4ms/step - loss: 1.6899
16/16 [==============================] - 0s 3ms/step - loss: 1.6899
16/16 [==============================] - 0s 5ms/step - loss: 1.6899
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6328
16/16 [==============================] - 0s 2ms/step - loss: 1.6231
16/16 [==============================] - 0s 4ms/step - loss: 1.6753
16/16 [==============================] - 0s 1ms/step - loss: 1.6798
16/16 [==============================] - 0s 2ms/step - loss: 1.6808
16/16 [==============================] - 0s 4ms/step - loss: 1.6812
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 6ms/step - loss: 0.6413
16/16 [==============================] - 0s 2ms/step - loss: 1.6429
16/16 [==============================] - 0s 1ms/step - loss: 1.6952
16/16 [==============================] - 0s 2ms/step - loss: 1.6998
16/16 [==============================] - 0s 2ms/step - loss: 1.7008
16/16 [==============================] - 0s 4ms/step - loss: 1.7012
16/16 [==============================] - 0s 3ms/step - loss: 1.7013
16/16 [==============================] - 0s 3ms/step - loss: 1.7013
16/16 [==============================] - 0s 5ms/step - loss: 1.7013
16/16 [==============================] - 0s 7ms/step - loss: 1.7013
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 902us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6435
16/16 [==============================] - 0s 1ms/step - loss: 1.6565
16/16 [==============================] - 0s 1ms/step - loss: 1.7091
16/16 [==============================] - 0s 1ms/step - loss: 1.7136
16/16 [==============================] - 0s 1ms/step - loss: 1.7147
16/16 [==============================] - 0s 2ms/step - loss: 1.7151
16/16 [==============================] - 0s 944us/step - loss: 1.7152
16/16 [==============================] - 0s 1ms/step - loss: 1.7153
16/16 [==============================] - 0s 1ms/step - loss: 1.7153
16/16 [==============================] - 0s 1ms/step - loss: 1.7153

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 760us/step
16/16 [==============================] - 0s 965us/step - loss: 0.6498
16/16 [==============================] - 0s 1ms/step - loss: 1.6572
16/16 [==============================] - 0s 973us/step - loss: 1.7090
16/16 [==============================] - 0s 816us/step - loss: 1.7135
16/16 [==============================] - 0s 964us/step - loss: 1.7145
16/16 [==============================] - 0s 964us/step - loss: 1.7150
16/16 [==============================] - 0s 1ms/step - loss: 1.7151
16/16 [==============================] - 0s 863us/step - loss: 1.7151
16/16 [==============================] - 0s 840us/step - loss: 1.7151
16/16 [==============================] - 0s 819us/step - loss: 1.7151
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6535
16/16 [==============================] - 0s 1ms/step - loss: 1.6806
16/16 [==============================] - 0s 3ms/step - loss: 1.7330
16/16 [==============================] - 0s 1ms/step - loss: 1.7376
16/16 [==============================] - 0s 1ms/step - loss: 1.7386
16/16 [==============================] - 0s 1ms/step - loss: 1.7390
16/16 [==============================] - 0s 3ms/step - loss: 1.7391
16/16 [==============================] - 0s 2ms/step - loss: 1.7391
16/16 [==============================] - 0s 4ms/step - loss: 1.7391
16/16 [==============================] - 0s 1ms/step - loss: 1.7391

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6593
16/16 [==============================] - 0s 2ms/step - loss: 1.6769
16/16 [==============================] - 0s 6ms/step - loss: 1.7284
16/16 [==============================] - 0s 4ms/step - loss: 1.7328
16/16 [==============================] - 0s 4ms/step - loss: 1.7338
16/16 [==============================] - 0s 4ms/step - loss: 1.7342
16/16 [==============================] - 0s 2ms/step - loss: 1.7343
16/16 [==============================] - 0s 4ms/step - loss: 1.7343
16/16 [==============================] - 0s 2ms/step - loss: 1.7344
16/16 [==============================] - 0s 3ms/step - loss: 1.7344
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6622
16/16 [==============================] - 0s 3ms/step - loss: 1.6888
16/16 [==============================] - 0s 2ms/step - loss: 1.7403
16/16 [==============================] - 0s 2ms/step - loss: 1.7447
16/16 [==============================] - 0s 2ms/step - loss: 1.7457
16/16 [==============================] - 0s 1ms/step - loss: 1.7462
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6714
16/16 [==============================] - 0s 3ms/step - loss: 1.7059
16/16 [==============================] - 0s 3ms/step - loss: 1.7574
16/16 [==============================] - 0s 5ms/step - loss: 1.7618
16/16 [==============================] - 0s 3ms/step - loss: 1.7628
16/16 [==============================] - 0s 2ms/step - loss: 1.7632
16/16 [==============================] - 0s 2ms/step - loss: 1.7633
16/16 [==============================] - 0s 2ms/step - loss: 1.7633
16/16 [==============================] - 0s 3ms/step - loss: 1.7634
16/16 [==============================] - 0s 2ms/step - loss: 1.7634
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6699
16/16 [==============================] - 0s 2ms/step - loss: 1.6914
16/16 [==============================] - 0s 3ms/step - loss: 1.7418
16/16 [==============================] - 0s 2ms/step - loss: 1.7460
16/16 [==============================] - 0s 3ms/step - loss: 1.7469
16/16 [==============================] - 0s 2ms/step - loss: 1.7473
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 1ms/step - loss: 1.7474

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6793
16/16 [==============================] - 0s 2ms/step - loss: 1.7090
16/16 [==============================] - 0s 3ms/step - loss: 1.7595
16/16 [==============================] - 0s 3ms/step - loss: 1.7637
16/16 [==============================] - 0s 2ms/step - loss: 1.7646
16/16 [==============================] - 0s 2ms/step - loss: 1.7651
16/16 [==============================] - 0s 3ms/step - loss: 1.7652
16/16 [==============================] - 0s 2ms/step - loss: 1.7652
16/16 [==============================] - 0s 2ms/step - loss: 1.7652
16/16 [==============================] - 0s 3ms/step - loss: 1.7652
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6800
16/16 [==============================] - 0s 2ms/step - loss: 1.7117
16/16 [==============================] - 0s 2ms/step - loss: 1.7619
16/16 [==============================] - 0s 2ms/step - loss: 1.7660
16/16 [==============================] - 0s 6ms/step - loss: 1.7669
16/16 [==============================] - 0s 3ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7674
16/16 [==============================] - 0s 2ms/step - loss: 1.7674

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6897
16/16 [==============================] - 0s 3ms/step - loss: 1.7319
16/16 [==============================] - 0s 2ms/step - loss: 1.7822
16/16 [==============================] - 0s 2ms/step - loss: 1.7863
16/16 [==============================] - 0s 3ms/step - loss: 1.7872
16/16 [==============================] - 0s 2ms/step - loss: 1.7877
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6918
16/16 [==============================] - 0s 2ms/step - loss: 1.7417
16/16 [==============================] - 0s 2ms/step - loss: 1.7920
16/16 [==============================] - 0s 2ms/step - loss: 1.7960
16/16 [==============================] - 0s 2ms/step - loss: 1.7970
16/16 [==============================] - 0s 2ms/step - loss: 1.7974
16/16 [==============================] - 0s 2ms/step - loss: 1.7975
16/16 [==============================] - 0s 2ms/step - loss: 1.7975
16/16 [==============================] - 0s 3ms/step - loss: 1.7975
16/16 [==============================] - 0s 3ms/step - loss: 1.7975

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6990
16/16 [==============================] - 0s 2ms/step - loss: 1.7482
16/16 [==============================] - 0s 2ms/step - loss: 1.7981
16/16 [==============================] - 0s 3ms/step - loss: 1.8021
16/16 [==============================] - 0s 5ms/step - loss: 1.8030
16/16 [==============================] - 0s 3ms/step - loss: 1.8035
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.7001
16/16 [==============================] - 0s 2ms/step - loss: 1.7518
16/16 [==============================] - 0s 2ms/step - loss: 1.8013
16/16 [==============================] - 0s 3ms/step - loss: 1.8052
16/16 [==============================] - 0s 2ms/step - loss: 1.8062
16/16 [==============================] - 0s 2ms/step - loss: 1.8066
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 3ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8067

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.7091
16/16 [==============================] - 0s 2ms/step - loss: 1.7639
16/16 [==============================] - 0s 2ms/step - loss: 1.8133
16/16 [==============================] - 0s 4ms/step - loss: 1.8171
16/16 [==============================] - 0s 2ms/step - loss: 1.8180
16/16 [==============================] - 0s 2ms/step - loss: 1.8184
16/16 [==============================] - 0s 2ms/step - loss: 1.8185
16/16 [==============================] - 0s 2ms/step - loss: 1.8185
16/16 [==============================] - 0s 3ms/step - loss: 1.8185
16/16 [==============================] - 0s 4ms/step - loss: 1.8185
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.7096
16/16 [==============================] - 0s 2ms/step - loss: 1.7645
16/16 [==============================] - 0s 2ms/step - loss: 1.8135
16/16 [==============================] - 0s 2ms/step - loss: 1.8172
16/16 [==============================] - 0s 2ms/step - loss: 1.8182
16/16 [==============================] - 0s 5ms/step - loss: 1.8186
16/16 [==============================] - 0s 2ms/step - loss: 1.8187
16/16 [==============================] - 0s 2ms/step - loss: 1.8187
16/16 [==============================] - 0s 3ms/step - loss: 1.8187
16/16 [==============================] - 0s 3ms/step - loss: 1.8187

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.7180
16/16 [==============================] - 0s 5ms/step - loss: 1.7741
16/16 [==============================] - 0s 3ms/step - loss: 1.8228
16/16 [==============================] - 0s 2ms/step - loss: 1.8265
16/16 [==============================] - 0s 2ms/step - loss: 1.8275
16/16 [==============================] - 0s 3ms/step - loss: 1.8280
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="224">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="225">
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="226">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb269"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-208-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="228">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.95</td>
      <td>0.95</td>
      <td>1.0</td>
      <td>0.974359</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lscpstar-1" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar-1">LSCP<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb273"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb273-2"><a href="#cb273-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb273-3"><a href="#cb273-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb273-4"><a href="#cb273-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="231">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb277"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-214-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="234">
<div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="234">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="orbit-result" class="level2">
<h2 class="anchored" data-anchor-id="orbit-result">Orbit Result</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen_orbit,<span class="dv">4</span>)</span></code></pre></div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
<hr>
<section id="bunny-저장용" class="level3">
<h3 class="anchored" data-anchor-id="bunny-저장용">bunny 저장용</h3>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> graphs.Bunny()</span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> G.N</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb285"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> filters.Heat(G, tau<span class="op">=</span><span class="dv">75</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>normal <span class="op">=</span> np.random.randn(n)</span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> np.concatenate([np.random.uniform(low<span class="op">=</span><span class="dv">3</span>,high<span class="op">=</span><span class="dv">7</span>,size<span class="op">=</span><span class="dv">60</span>), np.random.uniform(low<span class="op">=-</span><span class="dv">7</span>,high<span class="op">=-</span><span class="dv">3</span>,size<span class="op">=</span><span class="dv">60</span>),np.zeros(n<span class="op">-</span><span class="dv">120</span>)])<span class="op">;</span> np.random.shuffle(unif)</span>
<span id="cb286-3"><a href="#cb286-3" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> normal <span class="op">+</span> unif</span>
<span id="cb286-4"><a href="#cb286-4" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier2 <span class="op">=</span> np.where(unif<span class="op">!=</span><span class="dv">0</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.zeros(n)</span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">1000</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3234</span></span>
<span id="cb287-3"><a href="#cb287-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> g.<span class="bu">filter</span>(f, method<span class="op">=</span><span class="st">'chebyshev'</span>) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-07-04 06:25:44,241:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb289"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb289-1"><a href="#cb289-1" aria-hidden="true" tabindex="-1"></a>G.coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(2503, 3)</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="9">
<div class="sourceCode cell-code" id="cb291"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> G.W.toarray()</span>
<span id="cb291-2"><a href="#cb291-2" aria-hidden="true" tabindex="-1"></a>_x <span class="op">=</span> G.coords[:,<span class="dv">0</span>]</span>
<span id="cb291-3"><a href="#cb291-3" aria-hidden="true" tabindex="-1"></a>_y <span class="op">=</span> G.coords[:,<span class="dv">1</span>]</span>
<span id="cb291-4"><a href="#cb291-4" aria-hidden="true" tabindex="-1"></a>_z <span class="op">=</span> <span class="op">-</span>G.coords[:,<span class="dv">2</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb292"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> {<span class="st">'W'</span>:_W,<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_data(data_dict,fname):</span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname,<span class="st">'wb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb295-3"><a href="#cb295-3" aria-hidden="true" tabindex="-1"></a>        pickle.dump(data_dict,outfile)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb296"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a>save_data(_df,<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname):</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname, <span class="st">'rb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb297-3"><a href="#cb297-3" aria-hidden="true" tabindex="-1"></a>        data_dict <span class="op">=</span> pickle.load(outfile)</span>
<span id="cb297-4"><a href="#cb297-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_dict</span></code></pre></div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb298"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a>_a <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-breunig2000lof" class="csl-entry" role="doc-biblioentry">
Breunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. <span>“LOF: Identifying Density-Based Local Outliers.”</span> In <em>Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</em>, 93–104.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
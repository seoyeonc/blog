[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ":)",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2099\n\n\nITSTGCN add Model\n\n\nSEOYEON CHOI\n\n\n\n\nJul 20, 2023\n\n\nData management Figure for ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nJul 20, 2023\n\n\nLLM\n\n\nSEOYEON CHOI\n\n\n\n\nJul 18, 2023\n\n\nSelf Consistency Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nJul 18, 2023\n\n\nEbayesThresh Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nJul 10, 2023\n\n\nFraud data\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nToy example using GNAR\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nToy example using GNAR\n\n\nSEOYEON CHOI\n\n\n\n\nJul 8, 2023\n\n\nStock on Graph\n\n\nSEOYEON CHOI\n\n\n\n\nJul 7, 2023\n\n\nStock Crawling\n\n\nSEOYEON CHOI\n\n\n\n\nJul 7, 2023\n\n\nPyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)\n\n\nì‹ ë¡ì˜ˆì°¬\n\n\n\n\nJul 5, 2023\n\n\nData management for ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nJul 5, 2023\n\n\nRESEARCHES\n\n\nSEOYEON CHOI\n\n\n\n\nJul 4, 2023\n\n\nToy Example Figure(Intro)\n\n\nSEOYEON CHOI\n\n\n\n\nJul 3, 2023\n\n\nOther Outlier Detection\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nEvolveGCNH_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJul 1, 2023\n\n\nEvolveGCNH_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 28, 2023\n\n\nDYGRENCODER_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 28, 2023\n\n\nDYGRENCODER_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 27, 2023\n\n\nLinear Graph code for Paper\n\n\nSEOYEON CHOI\n\n\n\n\nJun 25, 2023\n\n\nEvolveGCNO_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 25, 2023\n\n\nEvolveGCNO_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 22, 2023\n\n\nComparison Results on Real Data\n\n\nSEOYEON CHOI\n\n\n\n\nJun 20, 2023\n\n\nTGCN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 20, 2023\n\n\nTGCN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 13, 2023\n\n\nDCRNN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 13, 2023\n\n\nLRGCN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 13, 2023\n\n\nLRGCN_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 13, 2023\n\n\nDCRNN_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nJun 6, 2023\n\n\nGCLSTM_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nJun 6, 2023\n\n\nGCLSTM_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 30, 2023\n\n\nGConvLSTM_Simulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 30, 2023\n\n\nGConvLSTM_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 27, 2023\n\n\nAdding the RecurrentGCN models\n\n\nSEOYEON CHOI\n\n\n\n\nMay 25, 2023\n\n\nGConvGRU_Simulation Boxplot_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 25, 2023\n\n\nGConvGRU_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\n\nMay 17, 2023\n\n\nGConvGRU and GNAR_Simulation Tables_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nMay 11, 2023\n\n\nPyG Geometric Temporal CPU vs GPU\n\n\nSEOYEON CHOI\n\n\n\n\nMay 11, 2023\n\n\nPyG Geometric Temporal Examples\n\n\nSEOYEON CHOI\n\n\n\n\nMay 6, 2023\n\n\nITSTGCN Article Refernece\n\n\nSEOYEON CHOI\n\n\n\n\nMay 4, 2023\n\n\nQuestions of PyTorch Geometric Temporal\n\n\nSEOYEON CHOI\n\n\n\n\nApr 29, 2023\n\n\nPadalme GSO_st\n\n\nSEOYEON CHOI\n\n\n\n\n\nApr 27, 2023\n\n\nSimulation Tables\n\n\nSEOYEON CHOI\n\n\n\n\nApr 27, 2023\n\n\nToy Example Note\n\n\nGUEBIN CHOI\n\n\n\n\nApr 25, 2023\n\n\nNote_weight amatrix\n\n\nGUEBIN CHOI\n\n\n\n\nApr 6, 2023\n\n\nMETRLADatasetLoader-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation_reshape\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nApr 5, 2023\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nMar 22, 2023\n\n\nSimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 20, 2023\n\n\ndata load, data save as pickle\n\n\nSEOYEON CHOI\n\n\n\n\nMar 18, 2023\n\n\nSimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\nITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 3, 2023\n\n\nSY 1st ITSTGCN\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 15, 2023\n\n\n2nd ITSTGCN\n\n\nGUEBIN CHOI\n\n\n\n\nFeb 15, 2023\n\n\n1st ITSTGCN\n\n\nGUEBIN CHOI\n\n\n\n\nFeb 7, 2023\n\n\nClass of Method(WikiMath) lag 1\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 6, 2023\n\n\nClass of Method(GNAR) lag 1 80% Missing repeat\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 6, 2023\n\n\nClass of Method(GNAR) lag 2\n\n\nSEOYEON CHOI\n\n\n\n\nJan 28, 2023\n\n\nClass of Method(GNAR) lag 1\n\n\nSEOYEON CHOI\n\n\n\n\nJan 28, 2023\n\n\nClass of Method(WikiMath) lag 4\n\n\nSEOYEON CHOI\n\n\n\n\nJan 26, 2023\n\n\nClass of Method\n\n\nGuebin Choi\n\n\n\n\nJan 21, 2023\n\n\nClass of Method\n\n\nSEOYEON CHOI\n\n\n\n\nJan 20, 2023\n\n\n1st ST-GCN Example dividing train and test\n\n\nSEOYEON CHOI\n\n\n\n\nJan 17, 2023\n\n\n2nd ST-GCN Example dividing train and test\n\n\nSEOYEON CHOI\n\n\n\n\nJan 11, 2023\n\n\nGCN Algorithm Example 1\n\n\nSEOYEON CHOI\n\n\n\n\nJan 5, 2023\n\n\nGNAR data\n\n\nSEOYEON CHOI\n\n\n\n\nDec 29, 2022\n\n\n[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼\n\n\nì‹ ë¡ì˜ˆì°¬, SEOYEON CHOI\n\n\n\n\nDec 28, 2022\n\n\nSimulation of geometric-temporal\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2022\n\n\nDiscrete Fourier Transform\n\n\nSEOYEON CHOI\n\n\n\n\nDec 21, 2022\n\n\nPyTorch ST-GCN Dataset\n\n\nSEOYEON CHOI\n\n\n\n\nDec 5, 2022\n\n\nGCN\n\n\nSEOYEON CHOI\n\n\n\n\nDec 5, 2022\n\n\nTORCH_GEOMETRIC.NN\n\n\nSEOYEON CHOI\n\n\n\n\nDec 1, 2022\n\n\nGraph code\n\n\nSEOYEON CHOI\n\n\n\n\nNov 24, 2022\n\n\nClass code for Comparison Study\n\n\nSEOYEON CHOI\n\n\n\n\nNov 24, 2022\n\n\nEarthquake\n\n\nSEOYEON CHOI\n\n\n\n\nSep 2, 2022\n\n\nSimulation\n\n\nSEOYEON CHOI\n\n\n\n\nSep 1, 2022\n\n\nGODE\n\n\nSEOYEON CHOI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/GCN/2023-07-18-Self Consistency toy ex.html",
    "href": "posts/GCN/2023-07-18-Self Consistency toy ex.html",
    "title": "Self Consistency Toy ex",
    "section": "",
    "text": "Self Consistency\nRef: Self Consistency: A General Recipe for Wavelet Estimation With Irregularly-spaced and/or Incomplete Data\n\\[\\mathbb{E}(\\hat{f}_{com} | f = \\hat{f}_{obs}) = \\hat{f}_{obs}\\]"
  },
  {
    "objectID": "posts/GCN/2023-07-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "href": "posts/GCN/2023-07-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "title": "Self Consistency Toy ex",
    "section": "2 Self Consistency: How Does It Work?",
    "text": "2 Self Consistency: How Does It Work?\n\n2.1 Self-consistency: An Intuitive Principle\nì±…ì—ì„œì˜ ê°€ì •\n\n\\(x = 0,1,2,3,\\dots,16\\)ìœ¼ë¡œ fixed ë˜ì–´ ìˆìŒ.\n\\(y_0,\\dots, y_{13}\\)ê¹Œì§€ì˜ ê°’ì„ ì•Œê³  ìˆëŠ”ë° \\(y_{14},y_{15},y_{16}\\)ì˜ ê°’ì€ ëª¨ë¥¸ë‹¤.\n\n\\(y_i=\\beta x_i + \\epsilon_i, i=1,\\dots,n, \\epsilon_i \\sim \\text{i.i.d.}F(0,\\sigma^2)\\)\n\n\\(\\beta\\)ì˜ ìµœì†Œì œê³±ì¶”ì •ì¹˜\n\n\\(\\hat{\\beta}_n = \\hat{\\beta}_n(y_1 ,\\dots,y_n) = \\frac{\\sum^n_{i=1} y_i x_i}{\\sum^n_{i=1} x_i^2}\\)\n\në‹¨, \\(m<n\\) ì´ê³ , \\(\\sum ^n_{m+1} x_i^2 > 0\\) ì¼ ë•Œ,\n\n\\(E(\\hat{\\beta}_n|y_a, \\dots,y_m,;\\beta = \\hat{\\beta}_m) = \\hat{\\beta}_m\\)\nthe least-squares estimator has a (Martingale-like property)1, and reaches a perfect equilibrium in its projective properties1Â í™•ë¥  ê³¼ì • ì¤‘ ê³¼ê±°ì˜ ì •ë³´ë¥¼ ì•Œê³  ìˆë‹¤ë©´ ë¯¸ë˜ì˜ ê¸°ëŒ“ê°’ì´ í˜„ì¬ê°’ê³¼ ë™ì¼í•œ ê³¼ì •\nì°¸ê³ ;(ìœ„í‚¤ë°±ê³¼)[https://ko.wikipedia.org/wiki/%EB%A7%88%ED%8C%85%EA%B2%8C%EC%9D%BC]\n\n\\(\\beta_n\\)ì„ êµ¬í•œë‹¤.\n\\(\\beta_n \\times x\\) ë¥¼ êµ¬í•œë‹¤.\nmissing ê°’ì´ ìˆëŠ” indexë§Œ ëŒ€ì²´í•œë‹¤.\në‹¤ì‹œ \\(\\beta_n\\)ì„ êµ¬í•œë‹¤.\n.. ë°˜ë³µ\n\n\\(\\beta\\)ì˜ ì„ í˜•ì„± ë•Œë¬¸ì— ê°€ëŠ¥í•œ ì´ë¡ \nì•„ë˜ ê³„ì‚°í•˜ë©´ ë§ì•„ì•¼ í•¨\n\\(\\hat{\\beta}_n = \\frac{\\sum_{i=1}^m y_i x_i + \\hat{\\beta}_m \\sum_{i=m+1}^n x_i^2}{\\sum_{i=1}^n x_i^2}\\)\n\n\n2.2 A Selfâ€“consistent Regression Estimator\nëª©ì ì€ ìµœì ì˜ \\(\\hat{f}_{com}\\) ì°¾ëŠ” ê²ƒ, ì¼ë‹¨ ì´ paperëŠ” ì›¨ì´ë¸”ë¦¿ì— ì¤‘ì ì„ ë‘ê³  ë¹„ëª¨ìˆ˜, ì¤€ëª¨ìˆ˜ íšŒê·€ë¡œ í™•ì¥ ê°€ëŠ¥ ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ CDF ì°¾ëŠ” ê²ƒì´ ëª©ì "
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html",
    "title": "PyTorch ST-GCN Dataset",
    "section": "",
    "text": "PyTorch Geometric Temporal Dataset\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\në…¼ë¬¸\n|Dataset|Signal|Graph|Frequency|ğ‘‡|ã…£ğ‘‰ã…£ | |:â€“:|:â€“:||:â€“:||:â€“:| |Chickenpox Hungary|Temporal|Static|Weekly|522|20| |Windmill Large|Temporal|Static|Hourly|17,472|319| |Windmill Medium|Temporal|Static|Hourly|17,472|26| |Windmill Small|Temporal|Static|Hourly|17,472|11| |Pedal Me Deliveries|Temporal|Static|Weekly|36|15| |Wikipedia Math|Temporal|Static|Daily|731|1,068| |Twitter Tennis RG|Static|Dynamic|Hourly|120|1000| |Twitter Tennis UO|Static|Dynamic|Hourly|112|1000| |Covid19 England|Temporal|Dynamic|Daily|61|129| |Montevideo Buses|Temporal|Static|Hourly|744|675| |MTM-1 Hand Motions|Temporal|Static|1/24 Seconds|14,469|21|"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#chickenpoxdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#chickenpoxdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "ChickenpoxDatasetLoader",
    "text": "ChickenpoxDatasetLoader\nChickenpox Hungary\n\nA spatiotemporal dataset about the officially reported cases of chickenpox in Hungary. The nodes are counties and edges describe direct neighbourhood relationships. The dataset covers the weeks between 2005 and 2015 without missingness.\n\në°ì´í„°ì •ë¦¬\n\nT = 519\nN = 20 # number of nodes\nE = 102 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,)\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n519\n\n\n\n(data[0][1]).x.type,(data[0][1]).edge_index.type,(data[0][1]).edge_attr.type,(data[0][1]).y.type\n\n(<function Tensor.type>,\n <function Tensor.type>,\n <function Tensor.type>,\n <function Tensor.type>)\n\n\n\nmax((data[4][1]).x[0])\n\ntensor(2.1339)\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(20)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[519, Data(x=[20, 1], edge_index=[2, 102], edge_attr=[102], y=[20])]\n\n\n\nlen(data[0][1].edge_index[0])\n\n102\n\n\n\nedge_list=[]\nfor i in range(519):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(20, 61)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  ChickenpoxDatasetLoader\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.0011,  0.0286,  0.3547,  0.2954]), tensor(0.7106))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0]\n\ntensor([0.0286, 0.3547, 0.2954, 0.7106])\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0]\n\ntensor([ 0.3547,  0.2954,  0.7106, -0.6831])\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 20ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{20}\\}, t=1,2,\\dots,519\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:52<00:00,  1.05s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([20, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 102])\n\n\n\n_edge_attr.shape\n\ntorch.Size([102])\n\n\n\n_y.shape\n\ntorch.Size([20])\n\n\n\n_x.shape\n\ntorch.Size([20, 4])\n\n\nx\n\nVertex features are lagged weekly counts of the chickenpox cases (we included 4 lags). y\nThe target is the weekly number of cases for the upcoming week\n\n\n_x\n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n_y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pedalmedatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pedalmedatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "PedalMeDatasetLoader",
    "text": "PedalMeDatasetLoader\nPedal Me Deliveries\n\nA dataset about the number of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.\n\në°ì´í„°ì •ë¦¬\n\nT = 33\nV = ì§€ì—­ì˜ ì§‘í•©\nN = 15 # number of nodes\nE = 225 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # number of deliveries\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (15,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (15,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 15\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  PedalMeDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = PedalMeDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n33\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([15, 1]), torch.Size([2, 225]), torch.Size([225]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(15)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[33, Data(x=[15, 1], edge_index=[2, 225], edge_attr=[225], y=[15])]\n\n\n\nedge_list=[]\nfor i in range(33):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(15, 120)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  PedalMeDatasetLoader\nloader = PedalMeDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([ 3.0574, -0.0477, -0.3076,  0.2437]), tensor(-0.2710))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0], (data[1][1]).y[0]\n\n(tensor([-0.0477, -0.3076,  0.2437, -0.2710]), tensor(0.2490))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0], (data[2][1]).y[0]\n\n(tensor([-0.3076,  0.2437, -0.2710,  0.2490]), tensor(-0.0357))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 15ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{15}\\}, t=1,2,\\dots,33\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 16.04it/s]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([15, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 225])\n\n\n\n_edge_attr.shape\n\ntorch.Size([225])\n\n\n\n_y.shape\n\ntorch.Size([15])\n\n\n\n_x.shape\n\ntorch.Size([15, 4])\n\n\nx\n\nVertex features are lagged weekly counts of the delivery demands (we included 4 lags).\nì£¼ë§ˆë‹¤ ë°°ë‹¬ ìˆ˜ìš”ì˜ ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ë ì§€ percentageë¡œ, t-4ì‹œì ê¹Œì§€?\n\ny\n\nThe target is the weekly number of deliveries the upcoming week. Our dataset consist of more than 30 snapshots (weeks).\nê·¸ ë‹¤ìŒì£¼ì— ë°°ë‹¬ì˜ ìˆ˜ê°€ ëª‡ í¼ì„¼íŠ¸ë¡œ ë°œìƒí• ì§€?\n\n\n_x[0:3]\n\ntensor([[ 3.0574, -0.0477, -0.3076,  0.2437],\n        [ 3.2126,  0.1240,  0.0764,  0.5582],\n        [ 1.9071, -0.8883,  1.5280, -0.7184]])\n\n\n\n_y\n\ntensor([-0.2710,  0.0888,  0.4733,  0.0907, -0.3129,  0.1184,  0.5886, -0.6571,\n         0.2647,  0.2338,  0.1720,  0.5720, -0.9568, -0.4138, -0.5271])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#wikimathsdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#wikimathsdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WikiMathsDatasetLoader",
    "text": "WikiMathsDatasetLoader\nWikipedia Math\n\nContains Wikipedia pages about popular mathematics topics and edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.\n\në°ì´í„°ì •ë¦¬\n\nT = 722\nV = ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€\nN = 1068 # number of nodes\nE = 27079 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # í•´ë‹¹í˜ì´ì§€ë¥¼ ìœ ì €ê°€ ë°©ë¬¸í•œ íšŸìˆ˜\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (1068,8) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3),f(v,t_4),f(v,t_5),f(v,t_6),f(v,t_7)\\)\ny: (1068,) (N,), \\(f(v,t_8)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 1068\n\nvertices are Wikipedia pages\n\n-Edges : 27079\n\nedges are links between them\n\n- Time : 722\n\nWikipedia pages between March 16th 2019 and March 15th 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import  WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n722\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([1068, 8]), torch.Size([2, 27079]), torch.Size([27079]))\n\n\n\n(data[10][1]).x\n\ntensor([[ 0.4972,  0.6838,  0.7211,  ..., -0.8513,  0.1881,  1.3820],\n        [ 0.5457,  0.6016,  0.7071,  ..., -0.4599, -0.6089, -0.0626],\n        [ 0.6305,  1.1404,  0.8779,  ..., -0.5370,  0.7422,  0.3862],\n        ...,\n        [ 0.8699,  0.5451,  1.9254,  ..., -0.8351,  0.3828,  0.3828],\n        [ 0.2451,  0.9629,  1.0526,  ..., -0.9213,  0.8731, -0.1138],\n        [ 0.0200, -0.0871,  0.2342,  ..., -0.4712,  0.0717,  0.2859]])\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(1068)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(722):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(1068, 27079)\n\n\n\nnx.draw(G,node_color='green',node_size=100,width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nnp.where(data[11][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nnp.where(data[11][1].edge_index != data[20][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\nhttps://www.kaggle.com/code/mapologo/loading-wikipedia-math-essentials\n\nfrom torch_geometric_temporal.dataset import  WikiMathsDatasetLoader\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=8)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.4323, -0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617]),\n tensor(-0.4067))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3,,x_4,x_5,x_6,x_7\\)\ny:= \\(x_9\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617, -0.4067]),\n tensor(0.3064))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8\\)\ny:= \\(x_9\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617, -0.4067,  0.3064]),\n tensor(0.4972))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9\\)\ny:=\\(x_{10}\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 1068ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7) \\to (x_8)\\)\n\\((x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8) \\to (x_9)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{1068}\\}, t=1,2,\\dots,722\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=8, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [09:28<00:00, 11.37s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 8])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\nì–´ë–¤ í˜ì´ì§€ì— referê°€ ë˜ì—ˆëŠ”ì§€\n\n_edge_index[0][:5],_edge_index[1][:5]\n\n(tensor([0, 0, 0, 0, 0]), tensor([1, 2, 3, 4, 5]))\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_edge_attr[:5]\n\ntensor([1., 4., 2., 2., 5.])\n\n\n\nWeights represent the number of links found at the source Wikipedia page linking to the target Wikipedia page.\n\nê°€ì¤‘ì¹˜ëŠ” ì—£ì§€ë³„ í•œ í˜ì´ì§€ì— referë˜ì—ˆëŠ”ì§€, ëª‡ ë²ˆ ë˜ì—ˆë‚˜ ìˆ˜ ë‚˜ì˜´\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n_x.shape\n\ntorch.Size([1068, 8])\n\n\nx\n\nlag ë¥¼ ëª‡ìœ¼ë¡œ ì§€ì •í•˜ëŠëƒì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì¶”ì¶œ\n\ny\n\nThe target is the daily user visits to the Wikipedia pages between March 16th 2019 and March 15th 2021 which results in 731 periods.\në§¤ì¼ ìœ„í‚¤í”¼ë””ì•„ í•´ë‹¹ í˜ì´ì§€ì— ëª‡ ëª…ì˜ ìœ ì €ê°€ ë°©ë¬¸í•˜ëŠ”ì§€!\nìŒìˆ˜ê°€ ì™œ ë‚˜ì˜¤ì§€..\n\n\n_x[0:3]\n\ntensor([[-0.4323, -0.4739,  0.2659,  0.4844,  0.5367,  0.6412,  0.2179, -0.7617],\n        [-0.4041, -0.4165, -0.0751,  0.1484,  0.4153,  0.4464, -0.3916, -0.8137],\n        [-0.3892,  0.0634,  0.5913,  0.5370,  0.4646,  0.2776, -0.0724, -0.8116]])\n\n\n\n_y[:3]\n\ntensor([-0.4067, -0.1620, -0.4043])\n\n\n\ny_hat[:3].data\n\ntensor([[-0.0648],\n        [ 0.0314],\n        [-1.0724]])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputlargedatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputlargedatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputLargeDatasetLoader",
    "text": "WindmillOutputLargeDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 319 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\në°ì´í„°ì •ë¦¬\n\nT = 17470\nV = í’ë ¥ë°œì „ì†Œ\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 319\n\nvertices represent 319 windmills\n\n-Edges : 101761\n\nweighted edges describe the strength of relationships.\n\n- Time : 17470\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputLargeDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputLargeDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17470\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([319, 1]), torch.Size([2, 101761]), torch.Size([101761]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(319)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[17470, Data(x=[319, 1], edge_index=[2, 101761], edge_attr=[101761], y=[319])]\n\n\ntimeì´ ë„ˆë¬´ ë§ì•„ì„œ ì¼ë¶€ë§Œ ì‹œê°í™”í•¨!!\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(319, 51040)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputLargeDatasetLoader\nloader = WindmillOutputLargeDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.5711, -0.7560,  2.6278, -0.8674]), tensor(-0.9877))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0], (data[1][1]).y[0]\n\n(tensor([-0.7560,  2.6278, -0.8674, -0.9877]), tensor(-0.8583))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 2.6278, -0.8674, -0.9877, -0.8583]), tensor(0.4282))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 319ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{319}\\}, t=1,2,\\dots,17470\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [1:06:03<00:00, 792.70s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([319, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 101761])\n\n\n\n_edge_attr.shape\n\ntorch.Size([101761])\n\n\n\n_y.shape\n\ntorch.Size([319])\n\n\n\n_x.shape\n\ntorch.Size([319, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[-0.5711, -0.7560,  2.6278, -0.8674],\n        [-0.6936, -0.7264,  2.4113, -0.6052],\n        [-0.8666, -0.7785,  2.2759, -0.6759]])\n\n\n\n_y[0]\n\ntensor(-0.9877)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputmediumdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputmediumdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputMediumDatasetLoader",
    "text": "WindmillOutputMediumDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 26 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\në°ì´í„°ì •ë¦¬\n\nT = 17470\nV = í’ë ¥ë°œì „ì†Œ\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 26\n\nvertices represent 26 windmills\n\n-Edges : 225\n\nweighted edges describe the strength of relationships\n\n- Time : 676\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputMediumDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputMediumDatasetLoader()\n\ndataset = loader.get_dataset(lags=1)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17470\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([26, 1]), torch.Size([2, 676]), torch.Size([676]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(26)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[17470, Data(x=[26, 1], edge_index=[2, 676], edge_attr=[676], y=[26])]\n\n\n\nedge_list=[]\nfor i in range(17463):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(26, 351)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import  WindmillOutputMediumDatasetLoader\nloader = WindmillOutputMediumDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.2170, -0.2055, -0.1587, -0.1930]), tensor(-0.2149))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.2055, -0.1587, -0.1930, -0.2149]), tensor(-0.2336))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-0.1587, -0.1930, -0.2149, -0.2336]), tensor(-0.1785))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 26ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{26}\\}, t=1,2,\\dots,177470\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:23<00:00, 40.73s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([26, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 676])\n\n\n\n_edge_attr.shape\n\ntorch.Size([676])\n\n\n\n_y.shape\n\ntorch.Size([26])\n\n\n\n_x.shape\n\ntorch.Size([26, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[-0.2170, -0.2055, -0.1587, -0.1930],\n        [-0.1682, -0.2708, -0.1051,  1.1786],\n        [ 1.1540, -0.6707, -0.8291, -0.6823]])\n\n\n\n_y[0]\n\ntensor(-0.2149)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputsmalldatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#windmilloutputsmalldatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "WindmillOutputSmallDatasetLoader",
    "text": "WindmillOutputSmallDatasetLoader\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 11 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\në°ì´í„°ì •ë¦¬\n\nT = 17470\nV = í’ë ¥ë°œì „ì†Œ\nN = 11 # number of nodes\nE = 121 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (11,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (11,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 11\n\nvertices represent 11 windmills\n\n-Edges : 121\n\nweighted edges describe the strength of relationships\n\n- Time : 17470\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WindmillOutputSmallDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n17463\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([11, 8]), torch.Size([2, 121]), torch.Size([121]))\n\n\n\ndata[-1]\n\n[17463, Data(x=[11, 8], edge_index=[2, 121], edge_attr=[121], y=[11])]\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(11)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(17463):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(11, 66)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader = WindmillOutputSmallDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([ 0.8199, -0.4972,  0.4923, -0.8299]), tensor(-0.6885))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4972,  0.4923, -0.8299, -0.6885]), tensor(0.7092))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([ 0.4923, -0.8299, -0.6885,  0.7092]), tensor(-0.9356))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 11ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{11}\\}, t=1,2,\\dots,17463\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(5)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:55<00:00, 35.01s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([11, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 121])\n\n\n\n_edge_attr.shape\n\ntorch.Size([121])\n\n\n\n_y.shape\n\ntorch.Size([11])\n\n\n\n_x.shape\n\ntorch.Size([11, 4])\n\n\nx\n\n\n\ny\n\nThe target variable allows for regression tasks.\n\n\n_x[0:3]\n\ntensor([[ 0.8199, -0.4972,  0.4923, -0.8299],\n        [ 1.1377, -0.3742,  0.3668, -0.8333],\n        [ 0.9979, -0.5643,  0.4070, -0.8918]])\n\n\n\n_y\n\ntensor([-0.6885, -0.6594, -0.6303, -0.6983, -0.5416, -0.6186, -0.6031, -0.7580,\n        -0.6659, -0.5948, -0.5088])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#metrladatasetloader_real-world-traffic-dataset",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#metrladatasetloader_real-world-traffic-dataset",
    "title": "PyTorch ST-GCN Dataset",
    "section": "METRLADatasetLoader_real world traffic dataset",
    "text": "METRLADatasetLoader_real world traffic dataset\nA traffic forecasting dataset based on Los Angeles Metropolitan traffic conditions. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County in aggregated 5 minute intervals for 4 months between March 2012 to June 2012.\në°ì´í„°ì •ë¦¬\n\nT = 33\nV = êµ¬ì—­\nN = 207 # number of nodes\nE = 225\n\\(f(v,t)\\)ì˜ ì°¨ì›? (3,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (207,4) (N,2,12), \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny: (207,) (N,), \\((x_{12})\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\nhttps://arxiv.org/pdf/1707.01926.pdf\n- Nodes : 207\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = METRLADatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n34248\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([207, 2, 12]), torch.Size([2, 1722]), torch.Size([1722]))\n\n\n\ndata[-1]\n\n[34248,\n Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])]\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(20)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(207, 1520)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\në…¼ë¬¸ ë‚´ìš© ì¤‘\n\n\n\nimage.png\n\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nloader = METRLADatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\n\n\n\n\n\nNote\n\n\n\nlags option ì—†ì–´ì„œ error ëœ¸ : get_dataset() got an unexpected keyword argument â€˜lagsâ€™\n\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[ 0.5332,  0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,\n           0.7497,  0.4899,  0.5751,  0.4280],\n         [-1.7292, -1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448,\n          -1.6328, -1.6207, -1.6087, -1.5966]]),\n tensor([0.3724, 0.2452, 0.4961, 0.6521, 0.1126, 0.5311, 0.5091, 0.4713, 0.4218,\n         0.3909, 0.4761, 0.5641]))\n\n\n\\(t=0\\)ì—ì„œ \\(X,Z\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\nZ:= \\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny:= \\(x_{12}\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[ 0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,  0.7497,\n           0.4899,  0.5751,  0.4280,  0.3724],\n         [-1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448, -1.6328,\n          -1.6207, -1.6087, -1.5966, -1.5846]]),\n tensor([ 0.2452,  0.4961,  0.6521,  0.1126,  0.5311,  0.5091,  0.4713,  0.4218,\n          0.3909,  0.4761,  0.5641, -0.0022]))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12}\\)\nZ:= \\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12}\\)\ny:= \\(x_{13}\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([[ 0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,  0.7497,  0.4899,\n           0.5751,  0.4280,  0.3724,  0.2452],\n         [-1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448, -1.6328, -1.6207,\n          -1.6087, -1.5966, -1.5846, -1.5725]]),\n tensor([ 0.4961,  0.6521,  0.1126,  0.5311,  0.5091,  0.4713,  0.4218,  0.3909,\n          0.4761,  0.5641, -0.0022,  0.4218]))\n\n\n\nX:= \\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},x_{13}\\)\nZ:= \\(z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12},z_{13}\\)\ny:= \\(x_{14}\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 207ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11} \\to (x_{12})\\)\n\\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12} \\to (x_{13})\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{207}\\}, t=1,2,\\dots,34248\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=1, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([207, 2, 12])\n\n\n\nnode 207ê°œ, traffic sensor 2ê°œ\n\n\n_edge_index.shape\n\ntorch.Size([2, 1722])\n\n\n\n_edge_attr.shape\n\ntorch.Size([1722])\n\n\n\n_y.shape\n\ntorch.Size([207, 12])\n\n\n\n_x.shape\n\ntorch.Size([207, 2, 12])\n\n\ny\n\ntraffic speed\n\n\n_x[0]\n\ntensor([[ 0.5332,  0.4486,  0.5146, -2.6522, -2.6522,  0.1847,  0.6383,  0.4961,\n          0.7497,  0.4899,  0.5751,  0.4280],\n        [-1.7292, -1.7171, -1.7051, -1.6930, -1.6810, -1.6689, -1.6569, -1.6448,\n         -1.6328, -1.6207, -1.6087, -1.5966]])\n\n\n\n_y[0]\n\ntensor([0.3724, 0.2452, 0.4961, 0.6521, 0.1126, 0.5311, 0.5091, 0.4713, 0.4218,\n        0.3909, 0.4761, 0.5641])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pemsbaydatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#pemsbaydatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "PemsBayDatasetLoader",
    "text": "PemsBayDatasetLoader\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12644\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nThis traffic dataset is collected by California Transportation Agencies (CalTrans) Performance Measurement System (PeMS). It is represented by a network of 325 traffic sensors in the Bay Area with 6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals.\në°ì´í„°ì •ë¦¬\n\nT = 17470\nV = í’ë ¥ë°œì „ì†Œ\nN = 325 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (325,2,12) (N,2,12),\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\n\ny: (325,) (N,2,12),\n\n\\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 325\n\nvertices are sensors\n\n-Edges : 2694\n\nweighted edges are between seonsor paris measured by the road nretwork distance\n\n- Time : 52081\n\n6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = PemsBayDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n52081\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([325, 2, 12]), torch.Size([2, 2694]), torch.Size([2694]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(325)).tolist()\n\n\ndata[-1]\n\n[52081,\n Data(x=[325, 2, 12], edge_index=[2, 2694], edge_attr=[2694], y=[325, 2, 12])]\n\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(1000):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(325, 2404)\n\n\n\nnx.draw(G,node_color='green',node_size=50,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nloader = PemsBayDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[ 0.9821,  0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,\n           1.0143,  0.9928,  0.9498,  0.9821],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275,\n          -1.5153, -1.5032, -1.4910, -1.4788]]),\n tensor([[ 1.0143,  0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,\n           0.9928,  0.9928,  0.9498,  0.9928],\n         [-1.4667, -1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815,\n          -1.3694, -1.3572, -1.3450, -1.3329]]))\n\n\n\\(t=0\\)ì—ì„œ \\(X,Z\\)ì™€ \\(y,s\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\nZ:= \\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny:= \\(x_{12},x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23}\\)\ns:= \\(z_{12},z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23}\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[ 0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,  1.0143,\n           0.9928,  0.9498,  0.9821,  1.0143],\n         [-1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275, -1.5153,\n          -1.5032, -1.4910, -1.4788, -1.4667]]),\n tensor([[ 0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,  0.9928,\n           0.9928,  0.9498,  0.9928,  0.9821],\n         [-1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815, -1.3694,\n          -1.3572, -1.3450, -1.3329, -1.3207]]))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12}\\)\nZ:= \\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12}\\)\ny:= \\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\ns:= \\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([[ 1.0251,  1.0574,  1.0466,  1.0681,  0.9821,  1.0251,  1.0143,  0.9928,\n           0.9498,  0.9821,  1.0143,  0.9821],\n         [-1.5883, -1.5762, -1.5640, -1.5518, -1.5397, -1.5275, -1.5153, -1.5032,\n          -1.4910, -1.4788, -1.4667, -1.4545]]),\n tensor([[ 0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,  0.9928,  0.9928,\n           0.9498,  0.9928,  0.9821,  1.0143],\n         [-1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815, -1.3694, -1.3572,\n          -1.3450, -1.3329, -1.3207, -1.3085]]))\n\n\n\nX:= \\(x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12},x_{13}\\)\nZ:= \\(z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12},z_{13}\\)\ny:= \\(x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24},x_{25}\\)\ns:= \\(z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24},z_{25}\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 325ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11} \\to x_{12},x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11} \\to z_{12},z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23}\\)\n\\(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12} \\to x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11},z_{12} \\to z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{325}\\}, t=1,2,\\dots,52081\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([325, 2, 12])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 2694])\n\n\n\n_edge_attr.shape\n\ntorch.Size([2694])\n\n\n\n_y.shape\n\ntorch.Size([325, 2, 12])\n\n\n\n_x.shape\n\ntorch.Size([325, 2, 12])\n\n\nx\n\n.!\n\ny\n\ncapturing temporal dependencies..?\n\nedges connect sensors\nFor instance, the traffic conditions on one road on Wednesday at 3:00 p.m. are similar to the traffic conditions on Thursday at the same time.\n\n_x[0:3]\n\ntensor([[[ 0.9821,  0.9928,  1.0251,  1.0574,  1.0466,  1.0681,  0.9821,\n           1.0251,  1.0143,  0.9928,  0.9498,  0.9821],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]],\n\n        [[ 0.6054,  0.5839,  0.6592,  0.6269,  0.6808,  0.6377,  0.6700,\n           0.6054,  0.6162,  0.6162,  0.5839,  0.5947],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]],\n\n        [[ 0.9390,  0.9175,  0.8960,  0.9175,  0.9067,  0.9175,  0.9175,\n           0.8852,  0.9283,  0.8960,  0.9067,  0.8960],\n         [-1.6127, -1.6005, -1.5883, -1.5762, -1.5640, -1.5518, -1.5397,\n          -1.5275, -1.5153, -1.5032, -1.4910, -1.4788]]])\n\n\n\n_y[0]\n\ntensor([[ 1.0143,  0.9821,  0.9821,  1.0036,  1.0143,  0.9605,  0.9498,  1.0251,\n          0.9928,  0.9928,  0.9498,  0.9928],\n        [-1.4667, -1.4545, -1.4423, -1.4302, -1.4180, -1.4058, -1.3937, -1.3815,\n         -1.3694, -1.3572, -1.3450, -1.3329]])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#englandcoviddatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#englandcoviddatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "EnglandCovidDatasetLoader",
    "text": "EnglandCovidDatasetLoader\nCovid19 England\n\nA dataset about mass mobility between regions in England and the number of confirmed COVID-19 cases from March to May 2020 [38]. Each day contains a different mobility graph and node features corresponding to the number of cases in the previous days. Mobility stems from Facebook Data For Good 1 and cases from gov.uk 2\n\nhttps://arxiv.org/pdf/2009.08388.pdf\në°ì´í„°ì •ë¦¬\n\nT = 52\nV = ì§€ì—­\nN = 129 # number of nodes\nE = 2158\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # ì½”ë¡œë‚˜í™•ì§„ììˆ˜\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 129\n\nvertices are correspond to the number of COVID-19 cases in the region in the past window days.\n\n-Edges : 2158\n\nthe spatial edges capture county-to-county movement at a specific date, and a county is connected to a number of past instances of itself with temporal edges.\n\n- Time : 52\n\nfrom 3 March to 12 of May\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = EnglandCovidDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n52\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([129, 8]), torch.Size([2, 2158]), torch.Size([2158]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(129)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\ndata[-1]\n\n[52, Data(x=[129, 8], edge_index=[2, 1424], edge_attr=[1424], y=[129])]\n\n\n\nlen(data[0][1].edge_index[0])\n\n2158\n\n\n\nedge_list=[]\nfor i in range(52):\n    for j in range(100):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(129, 1230)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[2][1].edge_index !=data[2][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nloader = EnglandCovidDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-1.4697, -1.9283, -1.6990, -1.8137]), tensor(-1.8137))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-1.9283, -1.6990, -1.8137, -1.8137]), tensor(-0.8965))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-1.6990, -1.8137, -1.8137, -0.8965]), tensor(-1.1258))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 129ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{129}\\}, t=1,2,\\dots,52\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:07<00:00,  6.30it/s]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([129, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 2158])\n\n\n\n_edge_attr.shape\n\ntorch.Size([2158])\n\n\n\n_y.shape\n\ntorch.Size([129])\n\n\n\ny_hat.shape\n\ntorch.Size([129, 1])\n\n\n\n_x.shape\n\ntorch.Size([129, 4])\n\n\nx\n\n\n\ny\n\n\n\nThe node features correspond to the number of COVID-19 cases in the region in the past window days.\nThe task is to predict the number of cases in each node after 1 day\n\n_x[0:3]\n\ntensor([[-1.4697, -1.9283, -1.6990, -1.8137],\n        [-1.2510, -1.1812, -1.3208, -1.1812],\n        [-1.0934, -1.0934, -1.0934, -1.0934]])\n\n\n\n_y[:3]\n\ntensor([-1.8137, -1.3208, -1.0934])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#montevideobusdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#montevideobusdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "MontevideoBusDatasetLoader",
    "text": "MontevideoBusDatasetLoader\nhttps://www.fing.edu.uy/~renzom/msc/uploads/msc-thesis.pdf\nMontevideo Buses\n\nA dataset about the hourly passenger inflow at bus stop level for eleven bus lines from the city of Montevideo. Nodes are bus stops and edges represent connections between the stops; the dataset covers a whole month of traffic patterns.\n\në°ì´í„°ì •ë¦¬\n\nT = 739\nV = ë²„ìŠ¤ì •ë¥˜ì¥\nN = 675 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # passenger inflow\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nX: (675,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (675,,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 675\n\nvertices are bus stops\n\n-Edges : 690\n\nedges are links between bus stops when a bus line connects them and the weight represent the road distance\n\n- Time : 739\n\nhourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay).\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = MontevideoBusDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n739\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([675, 4]), torch.Size([2, 690]), torch.Size([690]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(675)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(739):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(675, 690)\n\n\n\nnx.draw(G,node_color='green',node_size=50,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[10][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader = MontevideoBusDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\\(t=0\\)ì—ì„œ \\(X\\)ì™€ \\(y\\)ë¥¼ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ.\n\nX:= \\(x_0,x_1,x_2,x_3\\)\ny:= \\(x_4\\)\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\nX:= \\(x_1,x_2,x_3,x_4\\)\ny:= \\(x_5\\)\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([-0.4200, -0.4200, -0.4200, -0.4200]), tensor(-0.4200))\n\n\n\nX:=\\(x_2,x_3,x_4,x_5\\)\ny:=\\(x_6\\)\n\ní•˜ë‚˜ì˜ ë…¸ë“œì— ê¸¸ì´ê°€ \\(T\\)ì¸ ì‹œê³„ì—´ì´ ë§µí•‘ë˜ì–´ ìˆìŒ. (ë…¸ë“œëŠ” ì´ 675ê°œ)\nê° ë…¸ë“œë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì˜ˆì¸¡ì´ ë¨\n\n\\((x_0,x_1,x_2,x_3) \\to (x_4)\\)\n\\((x_1,x_2,x_3,x_4) \\to (x_5)\\)\n\n\\(f(v,t), v \\in \\{v_1,\\dots,v_{675}\\}, t=1,2,\\dots,739\\)\n\\[{\\bf X}_{t=1} = \\begin{bmatrix}\nf(v_1,t=1) & f(v_1,t=2) & f(v_1,t=3)&  f(v_1,t=4) \\\\\nf(v_2,t=1) & f(v_2,t=2) & f(v_2,t=3)&  f(v_2,t=4) \\\\\n\\dots & \\dots  & \\dots & \\dots  \\\\\nf(v_{20},t=1) & f(v_{20},t=2) & f(v_{20},t=3)&  f(v_{20},t=4)\n\\end{bmatrix}\\]\n\\[{\\bf y}_{t=1} = \\begin{bmatrix}\nf(v_1,t=5) \\\\\nf(v_2,t=5) \\\\\n\\dots  \\\\\nf(v_{20},t=5)\n\\end{bmatrix}\\]\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:51<00:00,  2.23s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([675, 4])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 690])\n\n\n\n_edge_attr.shape\n\ntorch.Size([690])\n\n\n\n_y.shape\n\ntorch.Size([675])\n\n\n\n_x.shape\n\ntorch.Size([675, 4])\n\n\nx\n\n\n\ny\n\nThe target is the passenger inflow.\nThis is a curated dataset made from different data sources of the Metropolitan Transportation System (STM) of Montevide\n\n\n_x[0:3]\n\ntensor([[-0.4200, -0.4200, -0.4200, -0.4200],\n        [-0.0367, -0.0367, -0.0367, -0.0367],\n        [-0.2655, -0.2655, -0.2655, -0.2655]])\n\n\n\n_y[:3]\n\ntensor([-0.4200, -0.0367, -0.2655])"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#twittertennisdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#twittertennisdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "TwitterTennisDatasetLoader",
    "text": "TwitterTennisDatasetLoader\nhttps://appliednetsci.springeropen.com/articles/10.1007/s41109-018-0080-5?ref=https://githubhelp.com\nTwitter Tennis RG and UO\n\nTwitter mention graphs of major tennis tournaments from 2017. Each snapshot contains the graph of popular player or sport news accounts and mentions between them [5, 6]. Node labels encode the number of mentions received and vertex features are structural properties\n\në°ì´í„°ì •ë¦¬\n\nT = 52081\nV = íŠ¸ìœ„í„°ê³„ì •\n\nN = 1000 # number of nodes\nE = 119 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # passenger inflow\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? ??\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? True\nX: ?\ny: ?\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 1000\n\nvertices are Twitter accounts\n\n-Edges : 119\n\nedges are mentions between them\n\n- Time : 52081\n\nTwitter mention graphs related to major tennis tournaments from 2017\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = TwitterTennisDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n119\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([1000, 16]), torch.Size([2, 89]), torch.Size([89]))\n\n\n\ndata[0][1].x[0]\n\ntensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\ndata[0][1].edge_index[0]\n\ntensor([ 42, 909, 909, 909, 233, 233, 450, 256, 256, 256, 256, 256, 434, 434,\n        434, 233, 233, 233, 233, 233, 233, 233,   9,   9, 355,  84,  84,  84,\n         84, 140, 140, 140, 140,   0, 140, 238, 238, 238, 649, 875, 875, 234,\n         73,  73, 341, 341, 341, 341, 341, 417, 293, 991,  74, 581, 282, 162,\n        144, 383, 383, 135, 135, 910, 910, 910, 910, 910,  87,  87,  87,  87,\n          9,   9, 934, 934, 162, 225,  42, 911, 911, 911, 911, 911, 911, 911,\n        911, 498, 498,  64, 435])\n\n\n\ndata[0][1].edge_attr\n\ntensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 3., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 3.])\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(1000)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(119):\n    for j in range(40):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(1000, 2819)\n\n\n\nnx.draw(G,node_color='green',node_size=50,width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nlen(data[2][1].edge_index[0])\n\n67\n\n\n\nlen(data[0][1].edge_index[0])\n\n89\n\n\në‹¤ë¦„..\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nloader = TwitterTennisDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(4.8363))\n\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(4.9200))\n\n\n\n(data[2][1]).x[0],(data[2][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(6.5539))\n\n\n\n(data[3][1]).x[0],(data[3][1]).y[0]\n\n(tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor(6.9651))\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1000, 16])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 89])\n\n\n\n_edge_attr.shape\n\ntorch.Size([89])\n\n\n\n_y.shape\n\ntorch.Size([1000])\n\n\n\n_x.shape\n\ntorch.Size([1000, 16])\n\n\nx\n\n\n\ny\n\n\n\n\n_x[0:3]\n\ntensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n_y[0]\n\ntensor(4.8363)"
  },
  {
    "objectID": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#mtmdatasetloader",
    "href": "posts/GCN/2022-12-21-ST-GCN_Dataset.html#mtmdatasetloader",
    "title": "PyTorch ST-GCN Dataset",
    "section": "MTMDatasetLoader",
    "text": "MTMDatasetLoader\nMTM-1 Hand Motions\n\nA temporal dataset of MethodsTime Measurement-1 [36] motions, signalled as consecutive graph frames of 21 3D hand key points that were acquired via MediaPipe Hands [64] from original RGB-Video material. Node features encode the normalized xyz-coordinates of each finger joint and the vertices are connected according to the human hand structure.\n\në°ì´í„°ì •ë¦¬\n\nT = 14452\nV = ì†ì˜ shapeì— ëŒ€ì‘í•˜ëŠ” dot\n\nN = 325 # number of nodes\nE = 19 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (Grasp, Release, Move, Reach, Poision, -1)\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? ??\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? ??\nX: ?\ny: ?\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 325\n\nvertices are are the finger joints of the human hand\n\n-Edges : 19\n\nedges are the bones connecting them\n\n- Time : 14452\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = MTMDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=1)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\ntime\n\n14452\n\n\n\n(data[0][1]).x.shape,(data[0][1]).edge_index.shape,(data[0][1]).edge_attr.shape\n\n(torch.Size([3, 21, 16]), torch.Size([2, 19]), torch.Size([19]))\n\n\n\nG = nx.Graph()\n\n\nnode_list = torch.tensor(range(21)).tolist()\n\n\nG.add_nodes_from(node_list)\n\n\nedge_list=[]\nfor i in range(14452):\n    for j in range(len(data[0][1].edge_index[0])):\n        edge_list.append([data[i][1].edge_index[0][j].tolist(),data[i][1].edge_index[1][j].tolist()])\n\n\nG.add_edges_from(edge_list)\n\n\nG.number_of_nodes(),G.number_of_edges()\n\n(21, 19)\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\ntimeë³„ ê°™ì€ edge ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ í™•ì¸\n\nnp.where(data[0][1].edge_index != data[12][1].edge_index)\n\n(array([], dtype=int64), array([], dtype=int64))\n\n\n\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nloader = MTMDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\ndata=[]\nfor time, snapshot in enumerate(train_dataset):\n    data.append([time,snapshot])\n\n\n(data[0][1]).x[0], (data[0][1]).y[0]\n\n(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n tensor([0., 0., 1., 0., 0., 0.]))\n\n\n\n(data[1][1]).x[0],(data[1][1]).y[0]\n\n(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n tensor([0., 0., 1., 0., 0., 0.]))\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([3, 21, 16])\n\n\n\n_edge_index.shape\n\ntorch.Size([2, 19])\n\n\n\n_edge_attr.shape\n\ntorch.Size([19])\n\n\n\n_y.shape\n\ntorch.Size([16, 6])\n\n\n\n_x.shape\n\ntorch.Size([3, 21, 16])\n\n\nx\n\nThe data x is returned in shape (3, 21, T),\n\ny\n\nThe targets are manually labeled for each frame, according to one of the five MTM-1 motions (classes ): Grasp, Release, Move, Reach, Position plus a negative class for frames without graph signals (no hand present).\nthe target is returned one-hot-encoded in shape (T, 6).\n\n\n_x[0]\n\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n_y[0]\n\ntensor([0., 0., 1., 0., 0., 0.])"
  },
  {
    "objectID": "posts/GCN/index.html",
    "href": "posts/GCN/index.html",
    "title": "GCN",
    "section": "",
    "text": "About GCN Study"
  },
  {
    "objectID": "posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html",
    "href": "posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html",
    "title": "Adding the RecurrentGCN models",
    "section": "",
    "text": "RecurrentGCN\n\n\nImport\n\nimport itstgcntry\nimport torch\nimport itstgcntry.planner \n\nTry\n\nimport pandas as pd\n\n\npd.read_csv('./simulation_results/2023-05-29_11-18-32.csv').groupby(['RecurrentGCN','method','mrate'])['mse'].mean().reset_index()\n\n\n\n\n\n  \n    \n      \n      RecurrentGCN\n      method\n      mrate\n      mse\n    \n  \n  \n    \n      0\n      DCRNN\n      IT-STGCN\n      0.8\n      1.517346\n    \n    \n      1\n      DCRNN\n      STGCN\n      0.8\n      1.521906\n    \n    \n      2\n      EvolveGCNH\n      IT-STGCN\n      0.8\n      1.338225\n    \n    \n      3\n      EvolveGCNH\n      STGCN\n      0.8\n      1.337022\n    \n    \n      4\n      EvolveGCNO\n      IT-STGCN\n      0.8\n      1.370455\n    \n    \n      5\n      EvolveGCNO\n      STGCN\n      0.8\n      1.326990\n    \n    \n      6\n      GCLSTM\n      IT-STGCN\n      0.8\n      1.529536\n    \n    \n      7\n      GCLSTM\n      STGCN\n      0.8\n      1.600452\n    \n    \n      8\n      GConvGRU\n      IT-STGCN\n      0.8\n      1.567661\n    \n    \n      9\n      GConvGRU\n      STGCN\n      0.8\n      1.654162\n    \n    \n      10\n      GConvLSTM\n      IT-STGCN\n      0.8\n      1.494284\n    \n    \n      11\n      GConvLSTM\n      STGCN\n      0.8\n      1.633645\n    \n    \n      12\n      LRGCN\n      IT-STGCN\n      0.8\n      1.512042\n    \n    \n      13\n      LRGCN\n      STGCN\n      0.8\n      1.604186\n    \n    \n      14\n      MPNNLSTM\n      IT-STGCN\n      0.8\n      1.386678\n    \n    \n      15\n      MPNNLSTM\n      STGCN\n      0.8\n      1.351526\n    \n    \n      16\n      TGCN\n      IT-STGCN\n      0.8\n      1.279269\n    \n    \n      17\n      TGCN\n      STGCN\n      0.8\n      1.278411\n    \n  \n\n\n\n\n\npd.read_csv('./simulation_results/2023-05-29_12-31-06.csv').groupby(['RecurrentGCN','method','mrate'])['mse'].mean().reset_index()\n\n\n\n\n\n  \n    \n      \n      RecurrentGCN\n      method\n      mrate\n      mse\n    \n  \n  \n    \n      0\n      DCRNN\n      IT-STGCN\n      0.6\n      1.457874\n    \n    \n      1\n      DCRNN\n      STGCN\n      0.6\n      1.523312\n    \n    \n      2\n      EvolveGCNH\n      IT-STGCN\n      0.6\n      1.265695\n    \n    \n      3\n      EvolveGCNH\n      STGCN\n      0.6\n      1.290008\n    \n    \n      4\n      EvolveGCNO\n      IT-STGCN\n      0.6\n      1.288295\n    \n    \n      5\n      EvolveGCNO\n      STGCN\n      0.6\n      1.308886\n    \n    \n      6\n      GCLSTM\n      IT-STGCN\n      0.6\n      1.304539\n    \n    \n      7\n      GCLSTM\n      STGCN\n      0.6\n      1.537681\n    \n    \n      8\n      GConvGRU\n      IT-STGCN\n      0.6\n      1.402607\n    \n    \n      9\n      GConvGRU\n      STGCN\n      0.6\n      1.582745\n    \n    \n      10\n      GConvLSTM\n      IT-STGCN\n      0.6\n      1.299263\n    \n    \n      11\n      GConvLSTM\n      STGCN\n      0.6\n      1.534498\n    \n    \n      12\n      LRGCN\n      IT-STGCN\n      0.6\n      1.295239\n    \n    \n      13\n      LRGCN\n      STGCN\n      0.6\n      1.527917\n    \n    \n      14\n      MPNNLSTM\n      IT-STGCN\n      0.6\n      1.287649\n    \n    \n      15\n      MPNNLSTM\n      STGCN\n      0.6\n      1.307589\n    \n    \n      16\n      TGCN\n      IT-STGCN\n      0.6\n      1.276318\n    \n    \n      17\n      TGCN\n      STGCN\n      0.6\n      1.262256\n    \n  \n\n\n\n\n\n\nGConvGRU\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcntry/utils.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GConvGRU_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr.learn(model,epoch=5)\n\n5/5\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GConvGRU_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr1.learn(model1,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nDCRNN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.DCRNN_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.DCRNN_RecurrentGCN(train_dataset_padded,filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nEvolveGCNH\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.EvolveGCNH_RecurrentGCN(train_dataset_padded)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.EvolveGCNH_RecurrentGCN(train_dataset_padded)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nEvolveGCNO\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.EvolveGCNO_RecurrentGCN(train_dataset_padded)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.EvolveGCNO_RecurrentGCN(train_dataset_padded)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nGCLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GCLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GCLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nGConvLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.GConvLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.GConvLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nLRGCN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.LRGCN_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.LRGCN_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nMPNNLSTM\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.MPNNLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.MPNNLSTM_RecurrentGCN(train_dataset_padded, filters=1)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nTGCN\n\ndata_dict = itstgcntry.load_data('./data/fivenodes.pkl')\nloader = itstgcntry.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcntry.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nmindex = itstgcntry.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcntry.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcntry.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcntry.StgcnLearner(train_dataset_padded)\n\n\nmodel = itstgcntry.TGCN_RecurrentGCN(train_dataset_padded, filters=32)\n\n\nlrnr.learn(model,epoch=50)\n\n50/50\n\n\n\nlrnr1 = itstgcntry.ITStgcnLearner(train_dataset_padded)\n\n\nmodel1 = itstgcntry.TGCN_RecurrentGCN(train_dataset_padded, filters=32)\n\n\nlrnr1.learn(model1,epoch=50)\n\n50/50\n\n\n- ì í•©ê°’\n\n# lrnr(train_dataset_padded) \n# lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcntry.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor1 = itstgcntry.Evaluator(lrnr1,train_dataset_padded,test_dataset)\n\n\nfig = evtor1.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.set_figheight(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html",
    "href": "posts/GCN/2023-01-26-guebin.html",
    "title": "Class of Method",
    "section": "",
    "text": "Class"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "href": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "title": "Class of Method",
    "section": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)",
    "text": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)\nì‹œë‚˜ë¦¬ì˜¤1\n\nmissing rate: 0%\në³´ê°„ë°©ë²•: None\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:39<00:00,  2.00s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}'.format(i,train_mse_eachnode[i],test_mse_eachnode[i]))\n    a.plot(range(1,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test[:,i],label='STCGCN (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n\".format(train_mse_total,test_mse_total),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "href": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "title": "Class of Method",
    "section": "ì‹œë‚˜ë¦¬ì˜¤2",
    "text": "ì‹œë‚˜ë¦¬ì˜¤2\nì‹œë‚˜ë¦¬ì˜¤2\n\nmissing rate: 50%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:31<00:00,  1.82s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:29<00:00,  1.80s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "href": "posts/GCN/2023-01-26-guebin.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "title": "Class of Method",
    "section": "ì‹œë‚˜ë¦¬ì˜¤3",
    "text": "ì‹œë‚˜ë¦¬ì˜¤3\nì‹œë‚˜ë¦¬ì˜¤3\n\nmissing rate: 80%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:27<00:00,  1.76s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:32<00:00,  1.86s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(161,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html",
    "title": "Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='RecurrentGCN',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\n# df1 = pd.read_csv('./simulation_results/2023-04-30_13-00-12.csv')\n# df2 = pd.read_csv('./simulation_results/2023-04-30_13-31-32.csv')\n# df3 = pd.read_csv('./simulation_results/2023-04-30_14-01-49.csv')\n# df4 = pd.read_csv('./simulation_results/2023-04-30_14-31-56.csv')\n# df5 = pd.read_csv('./simulation_results/2023-04-30_15-02-23.csv')\n# df6 = pd.read_csv('./simulation_results/2023-04-30_15-33-03.csv')\n# df7 = pd.read_csv('./simulation_results/2023-04-30_16-07-43.csv')\n# df8 = pd.read_csv('./simulation_results/2023-04-30_16-41-35.csv')\n# df9 = pd.read_csv('./simulation_results/2023-04-30_17-14-51.csv')\n# df10 = pd.read_csv('./simulation_results/2023-04-30_17-49-34.csv')\n# df11 = pd.read_csv('./simulation_results/2023-04-30_18-21-29.csv')\n# df12 = pd.read_csv('./simulation_results/2023-04-30_18-50-24.csv')\n# df13 = pd.read_csv('./simulation_results/2023-04-30_20-33-28.csv')\n# df14 = pd.read_csv('./simulation_results/2023-05-04_16-40-05.csv')\n# df15 = pd.read_csv('./simulation_results/2023-05-04_17-34-00.csv')\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype!='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1000)\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-1",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-1",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-1",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-05-24_00-26-51.csv')\n# df2 = pd.read_csv('./simulation_results/2023-04-27_22-09-07.csv')\n# df3 = pd.read_csv('./simulation_results/2023-04-28_14-40-59.csv')\n# df4 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n# df5 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n\n\ndata = pd.concat([df1],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_block.csv')\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\n# df1 = pd.read_csv('./simulation_results/2023-04-29_03-57-07.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-04-29_20-15-46.csv') # STGCN IT-STGCN\n# df3 = pd.read_csv('./simulation_results/2023-04-30_16-19-58.csv') # STGCN IT-STGCN\n# # 60% í™•ì¸í•˜ê³  ë‹¤ì‹œ ëŒë¦¬ê¸°\n# df4 = pd.read_csv('./simulation_results/2023-05-05_04-21-57.csv') # STGCN IT-STGCN 60%\n# df5 = pd.read_csv('./simulation_results/2023-05-06_11-34-46.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-05-06_23-43-35.csv') # STGCN IT-STGCN\n# df7 = pd.read_csv('./simulation_results/2023-05-07_14-06-44.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-2",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata = pd.concat([df1,df2,df3,df4,df5,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,\n                 df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,\n                 df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,\n                 df51,df52,df53,df54,df55,df56,df57,df58,df59,df60,df61],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/windmillsmall.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/windmillsmall.csv')\n\n\ndata.query(\"method=='GNAR' and mrate ==0\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-2",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR' and mrate !=0\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-2",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\n# df1 = pd.read_csv('./simulation_results/2023-04-24_02-48-08.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-04-24_10-57-10.csv') # STGCN IT-STGCN\n# df3 = pd.read_csv('./simulation_results/2023-04-24_18-53-34.csv') # STGCN IT-STGCN\n# df4 = pd.read_csv('./simulation_results/2023-04-25_02-30-27.csv') # STGCN IT-STGCN\n# df5 = pd.read_csv('./simulation_results/2023-04-25_10-48-46.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-04-25_10-53-14.csv') # GNAR \n# df7 = pd.read_csv('./simulation_results/2023-04-25_18-40-53.csv') # STGCN IT-STGCN\n# df8 = pd.read_csv('./simulation_results/2023-04-25_23-30-08.csv') # STGCN IT-STGCN\n# df9 = pd.read_csv('./simulation_results/2023-04-26_04-15-00.csv') # STGCN IT-STGCN\n# df10 = pd.read_csv('./simulation_results/2023-04-27_07-59-36.csv') # STGCN IT-STGCN\n# df11 = pd.read_csv('./simulation_results/2023-04-27_15-29-00.csv') # STGCN IT-STGCN\n# df12 = pd.read_csv('./simulation_results/2023-04-27_23-37-18.csv') # STGCN IT-STGCN\n# df13 = pd.read_csv('./simulation_results/2023-04-28_08-21-54.csv') # STGCN IT-STGCN\n# df14 = pd.read_csv('./simulation_results/2023-04-28_16-06-55.csv') # STGCN IT-STGCN\n# df15 = pd.read_csv('./simulation_results/2023-04-28_21-19-37.csv') # STGCN IT-STGCN\n# df16 = pd.read_csv('./simulation_results/2023-04-29_03-07-03.csv') # STGCN IT-STGCN\n# df17 = pd.read_csv('./simulation_results/2023-04-29_09-00-42.csv') # STGCN IT-STGCN\n# df18 = pd.read_csv('./simulation_results/2023-04-29_19-07-49.csv') # STGCN IT-STGCN\n# df19 = pd.read_csv('./simulation_results/2023-04-30_05-14-07.csv') # STGCN IT-STGCN\n# df20 = pd.read_csv('./simulation_results/2023-04-30_15-23-16.csv') # STGCN IT-STGCN\n# df21 = pd.read_csv('./simulation_results/2023-05-01_00-16-37.csv') # STGCN IT-STGCN\n# df22 = pd.read_csv('./simulation_results/2023-05-01_07-41-52.csv') # STGCN IT-STGCN\n# df23 = pd.read_csv('./simulation_results/2023-05-01_16-21-41.csv') # STGCN IT-STGCN\n# df24 = pd.read_csv('./simulation_results/2023-05-01_23-38-23.csv') # STGCN IT-STGCN\n# df25 = pd.read_csv('./simulation_results/2023-05-02_13-51-13.csv') # STGCN IT-STGCN\n# df26 = pd.read_csv('./simulation_results/2023-05-02_21-43-26.csv') # STGCN IT-STGCN\n# df27 = pd.read_csv('./simulation_results/2023-05-03_06-04-32.csv') # STGCN IT-STGCN\n# df28 = pd.read_csv('./simulation_results/2023-05-03_13-43-11.csv') # STGCN IT-STGCN\n# df29 = pd.read_csv('./simulation_results/2023-05-03_21-58-04.csv') # STGCN IT-STGCN\n# df30 = pd.read_csv('./simulation_results/2023-05-04_04-39-00.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,\n                 df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/windmillsmall_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/windmillsmall_block.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#baseline-3",
    "title": "Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#random-3",
    "title": "Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.3 and mrate!=0.4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='RecurrentGCN',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html#block-3",
    "title": "Simulation_reshape",
    "section": "block",
    "text": "block\n\n# df1 = pd.read_csv('./simulation_results/2023-05-04_21-03-21.csv')\n# df2 = pd.read_csv('./simulation_results/2023-05-05_12-10-44.csv')\n# df3 = pd.read_csv('./simulation_results/2023-05-06_12-42-22.csv')\n# df4 = pd.read_csv('./simulation_results/2023-05-06_15-40-47.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/monte_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/monte_block.csv')\n\n\ndata.query(\"mtype=='block' and method=='GNAR'\")['mse'].mean()\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-1",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-2",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-27_00-26-15.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-27_00-42-14.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-3",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-29_18-21-43.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-29_13-25-16.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-29_15-50-57.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNO_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-4",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#baseline-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#random-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html#block-5",
    "title": "EvolveGCNO_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-06-METRLADatasetLoader.html",
    "href": "posts/GCN/2023-04-06-METRLADatasetLoader.html",
    "title": "METRLADatasetLoader-Tutorial",
    "section": "",
    "text": "METRLADatasetLoader\n\n\nimport torch\nfrom IPython.display import clear_output\npt_version = torch.__version__\nprint(pt_version)\n\n1.10.1\n\n\n\nimport numpy as np\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import StaticGraphTemporalSignal\n\nloader = METRLADatasetLoader()\ndataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\n#print(\"Dataset type:  \", dataset)\n#print(\"Number of samples / sequences: \",  len(set(dataset)))\n\n\nimport seaborn as sns\n# Visualize traffic over time\nsensor_number = 1\nhours = 24\nsensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\nsns.lineplot(data=sensor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n#print(\"Number of train buckets: \", len(set(train_dataset)))\n#print(\"Number of test buckets: \", len(set(test_dataset)))\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import A3TGCN\n\nclass TemporalGNN(torch.nn.Module):\n    def __init__(self, node_features, periods):\n        super(TemporalGNN, self).__init__()\n        # Attention Temporal Graph Convolutional Cell\n        self.tgnn = A3TGCN(in_channels=node_features, \n                           out_channels=32, \n                           periods=periods)\n        # Equals single-shot prediction\n        self.linear = torch.nn.Linear(32, periods)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        x = Node features for T time steps\n        edge_index = Graph edge indices\n        \"\"\"\n        h = self.tgnn(x, edge_index)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\nTemporalGNN(node_features=2, periods=12)\n\nTemporalGNN(\n  (tgnn): A3TGCN(\n    (_base_tgcn): TGCN(\n      (conv_z): GCNConv(2, 32)\n      (linear_z): Linear(in_features=64, out_features=32, bias=True)\n      (conv_r): GCNConv(2, 32)\n      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n      (conv_h): GCNConv(2, 32)\n      (linear_h): Linear(in_features=64, out_features=32, bias=True)\n    )\n  )\n  (linear): Linear(in_features=32, out_features=12, bias=True)\n)\n\n\n\n# GPU support\ndevice = torch.device('cpu') # cuda\nsubset = 2000\n\n# Create model and optimizers\nmodel = TemporalGNN(node_features=2, periods=12).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nprint(\"Running training...\")\nfor epoch in range(10): \n    loss = 0\n    step = 0\n    for snapshot in train_dataset:\n        snapshot = snapshot.to(device)\n        # Get model predictions\n        y_hat = model(snapshot.x, snapshot.edge_index)\n        # Mean squared error\n        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n        step += 1\n        if step > subset:\n          break\n\n    loss = loss / (step + 1)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))\n\nRunning training...\nEpoch 0 train MSE: 0.7596\nEpoch 1 train MSE: 0.7398\nEpoch 2 train MSE: 0.7205\nEpoch 3 train MSE: 0.6996\nEpoch 4 train MSE: 0.6759\nEpoch 5 train MSE: 0.6495\nEpoch 6 train MSE: 0.6221\nEpoch 7 train MSE: 0.5963\nEpoch 8 train MSE: 0.5743\nEpoch 9 train MSE: 0.5573\n\n\n\nmodel.eval()\nloss = 0\nstep = 0\nhorizon = 288\n\n# Store for analysis\npredictions = []\nlabels = []\n\nfor snapshot in test_dataset:\n    snapshot = snapshot.to(device)\n    # Get predictions\n    y_hat = model(snapshot.x, snapshot.edge_index)\n    # Mean squared error\n    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n    # Store for analysis below\n    labels.append(snapshot.y)\n    predictions.append(y_hat)\n    step += 1\n    if step > horizon:\n          break\n\nloss = loss / (step+1)\nloss = loss.item()\nprint(\"Test MSE: {:.4f}\".format(loss))\n\nTest MSE: 0.6738"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html",
    "href": "posts/GCN/2023-04-27-simulation_table.html",
    "title": "Simulation Tables",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"dataset=='fivenodes' and mtype!='block'\")['mrate'].unique()\n\narray([0.7 , 0.75, 0.8 , 0.85, 0.  ])\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12.0\n      IT-STGCN\n      2\n      1.168\n      0.030\n    \n    \n      1\n      12.0\n      STGCN\n      2\n      1.173\n      0.036\n    \n    \n      2\n      16.0\n      IT-STGCN\n      2\n      1.166\n      0.039\n    \n    \n      3\n      16.0\n      STGCN\n      2\n      1.165\n      0.040\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].std().reset_index(),\n         on=['nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12.0\n      2\n      1.170\n      0.033\n    \n    \n      1\n      16.0\n      2\n      1.165\n      0.039\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].mean().reset_index(),\n         data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','lags'])['mse'].std().reset_index(),\n         on=['nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      2\n      1.247\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='fivenodes' and mtype=='rand'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.407])\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.70\n      12.0\n      IT-STGCN\n      2\n      1.200\n      0.070\n    \n    \n      1\n      0.70\n      12.0\n      STGCN\n      2\n      1.213\n      0.083\n    \n    \n      4\n      0.75\n      12.0\n      IT-STGCN\n      2\n      1.188\n      0.060\n    \n    \n      5\n      0.75\n      12.0\n      STGCN\n      2\n      1.239\n      0.102\n    \n    \n      8\n      0.80\n      12.0\n      IT-STGCN\n      2\n      1.221\n      0.083\n    \n    \n      9\n      0.80\n      12.0\n      STGCN\n      2\n      1.226\n      0.105\n    \n    \n      12\n      0.85\n      12.0\n      IT-STGCN\n      2\n      1.227\n      0.085\n    \n    \n      13\n      0.85\n      12.0\n      STGCN\n      2\n      1.291\n      0.252\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters!=12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      2\n      0.70\n      16.0\n      IT-STGCN\n      2\n      1.201\n      0.068\n    \n    \n      3\n      0.70\n      16.0\n      STGCN\n      2\n      1.227\n      0.094\n    \n    \n      6\n      0.75\n      16.0\n      IT-STGCN\n      2\n      1.231\n      0.110\n    \n    \n      7\n      0.75\n      16.0\n      STGCN\n      2\n      1.201\n      0.072\n    \n    \n      10\n      0.80\n      16.0\n      IT-STGCN\n      2\n      1.232\n      0.092\n    \n    \n      11\n      0.80\n      16.0\n      STGCN\n      2\n      1.292\n      0.148\n    \n    \n      14\n      0.85\n      16.0\n      IT-STGCN\n      2\n      1.286\n      0.297\n    \n    \n      15\n      0.85\n      16.0\n      STGCN\n      2\n      1.362\n      0.239\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data_DCRNN_fivenodes.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters!=12 and mrate!=0.3\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      2\n      0.8\n      16\n      IT-STGCN\n      2\n      1.478\n      1.245\n    \n    \n      3\n      0.8\n      16\n      STGCN\n      2\n      1.491\n      0.302"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\ndata.query(\"dataset=='fivenodes' and mtype=='block'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.407])\n\n\n\ndata.query(\"dataset=='fivenodes' and mtype=='block'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      600\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      601\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      linear\n      NaN\n      1.406830\n    \n    \n      602\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      603\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      linear\n      NaN\n      1.406830\n    \n    \n      604\n      fivenodes\n      GNAR\n      GConvGRU\n      0.125\n      block\n      2\n      NaN\n      cubic\n      NaN\n      1.406830\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      967\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.135442\n    \n    \n      968\n      fivenodes\n      STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      12.0\n      linear\n      150.0\n      1.203593\n    \n    \n      969\n      fivenodes\n      STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.220799\n    \n    \n      970\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      12.0\n      linear\n      150.0\n      1.111655\n    \n    \n      971\n      fivenodes\n      IT-STGCN\n      GConvGRU\n      0.300\n      block\n      2\n      16.0\n      linear\n      150.0\n      1.197438\n    \n  \n\n372 rows Ã— 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12.0\n      IT-STGCN\n      4.308\n      3.333\n    \n    \n      1\n      0.125\n      12.0\n      STGCN\n      6.722\n      5.755\n    \n    \n      2\n      0.125\n      16.0\n      IT-STGCN\n      4.633\n      3.737\n    \n    \n      3\n      0.125\n      16.0\n      STGCN\n      6.858\n      5.814\n    \n    \n      4\n      0.300\n      12.0\n      IT-STGCN\n      1.178\n      0.032\n    \n    \n      5\n      0.300\n      12.0\n      STGCN\n      1.232\n      0.040\n    \n    \n      6\n      0.300\n      16.0\n      IT-STGCN\n      1.163\n      0.050\n    \n    \n      7\n      0.300\n      16.0\n      STGCN\n      1.232\n      0.053\n    \n  \n\n\n\n\n\nepoch ë³„ ë³´ê¸°\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch200.csv')\n\n\ndf_gnar = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_random.csv')\n\n\ndata_temp = pd.concat([df1,df2,df3,df4,df_gnar],axis=0)\n\nSTGCNì€ nearestì—ì„œ mseê°€ ë‚®ì•˜ë‹¤.\n\ndata_temp.query(\"method=='STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].mean()\n\n1.182556539773941\n\n\n\ndata_temp.query(\"method=='STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].std()\n\n0.012169932740213692\n\n\n\ndata_temp.query(\"method=='IT-STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].mean()\n\n1.1747438261906304\n\n\n\ndata_temp.query(\"method=='IT-STGCN' and mtype=='rand' and mrate==0.8 and lags==2 and inter_method=='linear' and nof_filters==4\").\\\ngroupby(['method','epoch','mrate','lags','nof_filters','inter_method'])['mse'].mean().reset_index()['mse'].std()\n\n0.007602895892378366"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-1",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16.0\n      IT-STGCN\n      1.008\n      0.010\n    \n    \n      1\n      16.0\n      STGCN\n      1.009\n      0.008\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.953\n      0.005\n    \n    \n      1\n      16\n      STGCN\n      0.953\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-1",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='chickenpox' and mtype=='rand'and method=='GNAR'\")['mse'].unique().round(3)\n\narray([1.427])\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      cubic\n      16.0\n      IT-STGCN\n      1.019\n      0.011\n    \n    \n      1\n      0.3\n      cubic\n      16.0\n      STGCN\n      1.059\n      0.013\n    \n    \n      6\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      1.015\n      0.009\n    \n    \n      7\n      0.3\n      linear\n      16.0\n      STGCN\n      1.040\n      0.014\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      cubic\n      16\n      IT-STGCN\n      0.985\n      0.008\n    \n    \n      1\n      0.3\n      cubic\n      16\n      STGCN\n      1.053\n      0.008\n    \n    \n      2\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.983\n      0.007\n    \n    \n      3\n      0.3\n      linear\n      16\n      STGCN\n      1.028\n      0.012\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      0.4\n      cubic\n      16\n      IT-STGCN\n      0.995\n      0.009\n    \n    \n      5\n      0.4\n      cubic\n      16\n      STGCN\n      1.069\n      0.011\n    \n    \n      6\n      0.4\n      linear\n      16\n      IT-STGCN\n      0.994\n      0.008\n    \n    \n      7\n      0.4\n      linear\n      16\n      STGCN\n      1.038\n      0.011\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.4\n      cubic\n      16.0\n      IT-STGCN\n      1.021\n      0.009\n    \n    \n      13\n      0.4\n      cubic\n      16.0\n      STGCN\n      1.084\n      0.025\n    \n    \n      18\n      0.4\n      linear\n      16.0\n      IT-STGCN\n      1.020\n      0.009\n    \n    \n      19\n      0.4\n      linear\n      16.0\n      STGCN\n      1.051\n      0.014\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      24\n      0.5\n      cubic\n      16.0\n      IT-STGCN\n      1.027\n      0.012\n    \n    \n      25\n      0.5\n      cubic\n      16.0\n      STGCN\n      1.128\n      0.042\n    \n    \n      30\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.026\n      0.014\n    \n    \n      31\n      0.5\n      linear\n      16.0\n      STGCN\n      1.071\n      0.016\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      8\n      0.5\n      cubic\n      16\n      IT-STGCN\n      1.011\n      0.007\n    \n    \n      9\n      0.5\n      cubic\n      16\n      STGCN\n      1.080\n      0.019\n    \n    \n      10\n      0.5\n      linear\n      16\n      IT-STGCN\n      1.008\n      0.007\n    \n    \n      11\n      0.5\n      linear\n      16\n      STGCN\n      1.055\n      0.010\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      36\n      0.8\n      cubic\n      16.0\n      IT-STGCN\n      1.206\n      0.117\n    \n    \n      37\n      0.8\n      cubic\n      16.0\n      STGCN\n      1.266\n      0.152\n    \n    \n      42\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.101\n      0.034\n    \n    \n      43\n      0.8\n      linear\n      16.0\n      STGCN\n      1.166\n      0.059\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.8\n      cubic\n      16\n      IT-STGCN\n      1.181\n      0.142\n    \n    \n      13\n      0.8\n      cubic\n      16\n      STGCN\n      1.417\n      0.663\n    \n    \n      14\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.058\n      0.015\n    \n    \n      15\n      0.8\n      linear\n      16\n      STGCN\n      1.102\n      0.027\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.9 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      48\n      0.9\n      cubic\n      16.0\n      IT-STGCN\n      1.228\n      0.199\n    \n    \n      49\n      0.9\n      cubic\n      16.0\n      STGCN\n      1.283\n      0.222\n    \n    \n      54\n      0.9\n      linear\n      16.0\n      IT-STGCN\n      1.251\n      0.106\n    \n    \n      55\n      0.9\n      linear\n      16.0\n      STGCN\n      1.265\n      0.148\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_chickenpox.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.9 and nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      16\n      0.9\n      cubic\n      16\n      IT-STGCN\n      2.372\n      1.841\n    \n    \n      17\n      0.9\n      cubic\n      16\n      STGCN\n      1.596\n      0.648\n    \n    \n      18\n      0.9\n      linear\n      16\n      IT-STGCN\n      1.090\n      0.045\n    \n    \n      19\n      0.9\n      linear\n      16\n      STGCN\n      1.179\n      0.127"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-1",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-1",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\ndata.query(\"dataset=='chickenpox' and mtype=='block'and method=='GNAR'\")['mse'].unique()\n\narray([1.42749429])\n\n\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      cubic\n      0.288\n      16.0\n      IT-STGCN\n      1.052\n      0.028\n    \n    \n      1\n      cubic\n      0.288\n      16.0\n      STGCN\n      1.052\n      0.023\n    \n    \n      6\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      1.008\n      0.005\n    \n    \n      7\n      linear\n      0.288\n      16.0\n      STGCN\n      1.011\n      0.008"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-2",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12.0\n      IT-STGCN\n      1.241\n      0.04\n    \n    \n      1\n      4\n      12.0\n      STGCN\n      1.271\n      0.04\n    \n  \n\n\n\n\n\n(1.241+1.271)/2\n\n1.256\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.204\n      0.020\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.203\n      0.022\n    \n  \n\n\n\n\n\n(1.204+1.203)/2\n\n1.2035"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-2",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='pedalme' and method=='GNAR' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index().query(\" lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mse\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      1\n      0.3\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      2\n      0.4\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      3\n      0.4\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      4\n      0.5\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      5\n      0.5\n      4\n      linear\n      GNAR\n      1.302679\n    \n    \n      6\n      0.6\n      4\n      cubic\n      GNAR\n      1.302679\n    \n    \n      7\n      0.6\n      4\n      linear\n      GNAR\n      1.302679\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      1\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.314\n      0.109\n    \n    \n      2\n      0.3\n      4\n      cubic\n      STGCN\n      1.363\n      0.115\n    \n    \n      3\n      0.3\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      4\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.323\n      0.094\n    \n    \n      5\n      0.3\n      4\n      linear\n      STGCN\n      1.380\n      0.127\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3 and  lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.223\n      0.031\n    \n    \n      1\n      0.3\n      4\n      cubic\n      STGCN\n      1.248\n      0.039\n    \n    \n      2\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.227\n      0.026\n    \n    \n      3\n      0.3\n      4\n      linear\n      STGCN\n      1.242\n      0.031\n    \n    \n      4\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.032\n    \n    \n      5\n      0.3\n      4\n      nearest\n      STGCN\n      1.229\n      0.032\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.4 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      10\n      0.4\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      11\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.331\n      0.112\n    \n    \n      12\n      0.4\n      4\n      cubic\n      STGCN\n      1.342\n      0.108\n    \n    \n      13\n      0.4\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      14\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.375\n      0.154\n    \n    \n      15\n      0.4\n      4\n      linear\n      STGCN\n      1.397\n      0.193\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\" mrate==0.4 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.230\n      0.030\n    \n    \n      7\n      0.4\n      4\n      cubic\n      STGCN\n      1.257\n      0.051\n    \n    \n      8\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.231\n      0.032\n    \n    \n      9\n      0.4\n      4\n      linear\n      STGCN\n      1.251\n      0.040\n    \n    \n      10\n      0.4\n      4\n      nearest\n      IT-STGCN\n      1.235\n      0.031\n    \n    \n      11\n      0.4\n      4\n      nearest\n      STGCN\n      1.241\n      0.033\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.5 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      20\n      0.5\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      21\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.328\n      0.108\n    \n    \n      22\n      0.5\n      4\n      cubic\n      STGCN\n      1.367\n      0.114\n    \n    \n      23\n      0.5\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      24\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.377\n      0.138\n    \n    \n      25\n      0.5\n      4\n      linear\n      STGCN\n      1.326\n      0.129\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\" mrate==0.5 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      12\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.251\n      0.034\n    \n    \n      13\n      0.5\n      4\n      cubic\n      STGCN\n      1.279\n      0.095\n    \n    \n      14\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.037\n    \n    \n      15\n      0.5\n      4\n      linear\n      STGCN\n      1.268\n      0.052\n    \n    \n      16\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.034\n    \n    \n      17\n      0.5\n      4\n      nearest\n      STGCN\n      1.256\n      0.043\n    \n  \n\n\n\n\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.6 and lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      30\n      0.6\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      31\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.300\n      0.063\n    \n    \n      32\n      0.6\n      4\n      cubic\n      STGCN\n      1.352\n      0.106\n    \n    \n      33\n      0.6\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      34\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.416\n      0.169\n    \n    \n      35\n      0.6\n      4\n      linear\n      STGCN\n      1.326\n      0.106\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_DCRNN_pedalme.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.6 and  lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      18\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.259\n      0.052\n    \n    \n      19\n      0.6\n      4\n      cubic\n      STGCN\n      1.313\n      0.193\n    \n    \n      20\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.036\n    \n    \n      21\n      0.6\n      4\n      linear\n      STGCN\n      1.280\n      0.064\n    \n    \n      22\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.254\n      0.037\n    \n    \n      23\n      0.6\n      4\n      nearest\n      STGCN\n      1.271\n      0.050"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-2",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-2",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      0.143\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      5\n      0.143\n      4\n      cubic\n      IT-STGCN\n      1.284\n      0.053\n    \n    \n      6\n      0.143\n      4\n      cubic\n      STGCN\n      1.288\n      0.071\n    \n    \n      7\n      0.143\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      14\n      0.286\n      4\n      cubic\n      GNAR\n      1.303\n      0.000\n    \n    \n      15\n      0.286\n      4\n      cubic\n      IT-STGCN\n      1.304\n      0.050\n    \n    \n      16\n      0.286\n      4\n      cubic\n      STGCN\n      1.377\n      0.061\n    \n    \n      17\n      0.286\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      18\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.335\n      0.062\n    \n    \n      19\n      0.286\n      4\n      linear\n      STGCN\n      1.350\n      0.056"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#w_st",
    "href": "posts/GCN/2023-04-27-simulation_table.html#w_st",
    "title": "Simulation Tables",
    "section": "W_st",
    "text": "W_st\n\ndata_pedalme_wst = pd.read_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv')\n\n\npd.merge(data_pedalme_wst.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedalme_wst.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      cubic\n      IT-STGCN\n      1.353\n      0.141\n    \n    \n      1\n      0.3\n      4\n      cubic\n      STGCN\n      1.360\n      0.131\n    \n    \n      2\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.337\n      0.122\n    \n    \n      3\n      0.3\n      4\n      linear\n      STGCN\n      1.353\n      0.117\n    \n    \n      4\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.316\n      0.122\n    \n    \n      5\n      0.3\n      4\n      nearest\n      STGCN\n      1.403\n      0.134\n    \n    \n      12\n      0.4\n      4\n      cubic\n      IT-STGCN\n      1.332\n      0.166\n    \n    \n      13\n      0.4\n      4\n      cubic\n      STGCN\n      1.344\n      0.123\n    \n    \n      14\n      0.4\n      4\n      linear\n      IT-STGCN\n      1.355\n      0.139\n    \n    \n      15\n      0.4\n      4\n      linear\n      STGCN\n      1.393\n      0.168\n    \n    \n      16\n      0.4\n      4\n      nearest\n      IT-STGCN\n      1.386\n      0.128\n    \n    \n      17\n      0.4\n      4\n      nearest\n      STGCN\n      1.341\n      0.129\n    \n    \n      24\n      0.5\n      4\n      cubic\n      IT-STGCN\n      1.312\n      0.152\n    \n    \n      25\n      0.5\n      4\n      cubic\n      STGCN\n      1.362\n      0.129\n    \n    \n      26\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.344\n      0.177\n    \n    \n      27\n      0.5\n      4\n      linear\n      STGCN\n      1.335\n      0.117\n    \n    \n      28\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.335\n      0.153\n    \n    \n      29\n      0.5\n      4\n      nearest\n      STGCN\n      1.350\n      0.129\n    \n    \n      36\n      0.6\n      4\n      cubic\n      IT-STGCN\n      1.346\n      0.151\n    \n    \n      37\n      0.6\n      4\n      cubic\n      STGCN\n      1.398\n      0.103\n    \n    \n      38\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.365\n      0.177\n    \n    \n      39\n      0.6\n      4\n      linear\n      STGCN\n      1.353\n      0.087\n    \n    \n      40\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.402\n      0.269\n    \n    \n      41\n      0.6\n      4\n      nearest\n      STGCN\n      1.339\n      0.111\n    \n    \n      48\n      0.7\n      4\n      cubic\n      IT-STGCN\n      1.377\n      0.173\n    \n    \n      49\n      0.7\n      4\n      cubic\n      STGCN\n      1.363\n      0.097\n    \n    \n      50\n      0.7\n      4\n      linear\n      IT-STGCN\n      1.355\n      0.144\n    \n    \n      51\n      0.7\n      4\n      linear\n      STGCN\n      1.288\n      0.063\n    \n    \n      52\n      0.7\n      4\n      nearest\n      IT-STGCN\n      1.383\n      0.157\n    \n    \n      53\n      0.7\n      4\n      nearest\n      STGCN\n      1.334\n      0.124\n    \n  \n\n\n\n\n\npd.merge(data_pedalme_wst.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedalme_wst.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.286\n      4\n      cubic\n      IT-STGCN\n      1.260\n      0.063\n    \n    \n      7\n      0.286\n      4\n      cubic\n      STGCN\n      1.417\n      0.065\n    \n    \n      8\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.276\n      0.065\n    \n    \n      9\n      0.286\n      4\n      linear\n      STGCN\n      1.288\n      0.055\n    \n    \n      10\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.275\n      0.061\n    \n    \n      11\n      0.286\n      4\n      nearest\n      STGCN\n      1.312\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-3",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index().round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mse\n    \n  \n  \n    \n      4\n      8\n      12.0\n      IT-STGCN\n      0.771\n    \n    \n      5\n      8\n      12.0\n      STGCN\n      0.772\n    \n  \n\n\n\n\n\ndata_DCRNN_wikimath.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index().round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mse\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.778\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.759"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-3",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      0.3\n      8\n      IT-STGCN\n      0.781\n      0.012\n    \n    \n      7\n      0.3\n      8\n      STGCN\n      0.779\n      0.013\n    \n    \n      14\n      0.5\n      8\n      IT-STGCN\n      0.802\n      0.041\n    \n    \n      15\n      0.5\n      8\n      STGCN\n      0.806\n      0.020\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_wikimath.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_wikimath.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==8\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.759\n      0.021\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.774\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-3",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-3",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003841\n      2\n      IT-STGCN\n      0.810475\n      0.033897\n    \n    \n      1\n      0.003841\n      2\n      STGCN\n      0.801502\n      0.015510\n    \n    \n      2\n      0.003841\n      4\n      IT-STGCN\n      0.779852\n      0.013188\n    \n    \n      3\n      0.003841\n      4\n      STGCN\n      0.779816\n      0.019309"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-04-27-simulation_table.html#missing-values-on-the-same-nodes",
    "title": "Simulation Tables",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndata_wikimath_st = pd.read_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv')\n\n\npd.merge(data_wikimath_st.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wikimath_st.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.123\n      4\n      IT-STGCN\n      0.774\n      0.008\n    \n    \n      1\n      0.123\n      4\n      STGCN\n      0.766\n      0.010\n    \n    \n      2\n      0.738\n      4\n      IT-STGCN\n      0.851\n      0.029\n    \n    \n      3\n      0.738\n      4\n      STGCN\n      0.831\n      0.031"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-4",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      8\n      IT-STGCN\n      1.006\n      0.006\n    \n    \n      2\n      8\n      STGCN\n      1.001\n      0.003\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.000\n      NaN\n    \n    \n      1\n      8\n      STGCN\n      1.001\n      NaN"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-4",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='windmillsmall' and mtype=='rand'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      7097\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.436077\n    \n    \n      7098\n      windmillsmall\n      IT-STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.290896\n    \n    \n      7099\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.410098\n    \n    \n      7100\n      windmillsmall\n      IT-STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.176981\n    \n    \n      7101\n      windmillsmall\n      STGCN\n      GConvGRU\n      0.7\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.447851\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7180\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7181\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7182\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7183\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n    \n      7184\n      windmillsmall\n      GNAR\n      GConvGRU\n      0.7\n      rand\n      8\n      NaN\n      linear\n      NaN\n      1.649230\n    \n  \n\n88 rows Ã— 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      0.7\n      8\n      IT-STGCN\n      1.178\n      0.054\n    \n    \n      2\n      0.7\n      8\n      STGCN\n      1.410\n      0.075\n    \n  \n\n\n\n\n\npd.merge(data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data_DCRNN_windmillsmall.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-4",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-4",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.325\n      8\n      GNAR\n      1.649\n      0.000\n    \n    \n      1\n      0.325\n      8\n      IT-STGCN\n      1.015\n      0.009\n    \n    \n      2\n      0.325\n      8\n      STGCN\n      1.017\n      0.008"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#baseline-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#baseline-5",
    "title": "Simulation Tables",
    "section": "Baseline",
    "text": "Baseline\n\nround(data.query(\"dataset=='monte' and mrate==0\")['mse'].mean(),3),round(data_monte.query(\"mrate==0\")['mse'].std(),3)\n\n(0.97, 0.024)"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#random-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#random-5",
    "title": "Simulation Tables",
    "section": "Random",
    "text": "Random\n\ndata.query(\"dataset=='monte' and mtype=='rand'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      RecurrentGCN\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      7307\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.972491\n    \n    \n      7308\n      monte\n      IT-STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.974410\n    \n    \n      7309\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.968628\n    \n    \n      7310\n      monte\n      IT-STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.976796\n    \n    \n      7311\n      monte\n      STGCN\n      GConvGRU\n      0.3\n      rand\n      8\n      12.0\n      linear\n      50.0\n      0.973314\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7872\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.030140\n    \n    \n      7873\n      monte\n      STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.040731\n    \n    \n      7874\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.041819\n    \n    \n      7875\n      monte\n      STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.023531\n    \n    \n      7876\n      monte\n      IT-STGCN\n      GConvGRU\n      0.9\n      rand\n      8\n      12.0\n      linear\n      50.0\n      1.032515\n    \n  \n\n504 rows Ã— 10 columns\n\n\n\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      1\n      0.3\n      4\n      IT-STGCN\n      0.971925\n      0.001871\n    \n    \n      2\n      0.3\n      4\n      STGCN\n      0.965885\n      0.002552\n    \n    \n      3\n      0.3\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      4\n      0.3\n      8\n      IT-STGCN\n      0.974867\n      0.003233\n    \n    \n      5\n      0.3\n      8\n      STGCN\n      0.972051\n      0.002383\n    \n    \n      6\n      0.4\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      7\n      0.4\n      4\n      IT-STGCN\n      0.976348\n      0.001374\n    \n    \n      8\n      0.4\n      4\n      STGCN\n      0.967480\n      0.002974\n    \n    \n      9\n      0.4\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      10\n      0.4\n      8\n      IT-STGCN\n      0.978809\n      0.002110\n    \n    \n      11\n      0.4\n      8\n      STGCN\n      0.973098\n      0.002613\n    \n    \n      12\n      0.8\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      13\n      0.8\n      4\n      IT-STGCN\n      1.006583\n      0.003297\n    \n    \n      14\n      0.8\n      4\n      STGCN\n      0.999715\n      0.006909\n    \n    \n      15\n      0.8\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      16\n      0.8\n      8\n      IT-STGCN\n      1.004450\n      0.002953\n    \n    \n      17\n      0.8\n      8\n      STGCN\n      1.005238\n      0.005777\n    \n    \n      18\n      0.9\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      19\n      0.9\n      4\n      IT-STGCN\n      1.034162\n      0.005611\n    \n    \n      20\n      0.9\n      4\n      STGCN\n      1.034995\n      0.006551\n    \n    \n      21\n      0.9\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      22\n      0.9\n      8\n      IT-STGCN\n      1.030283\n      0.007979\n    \n    \n      23\n      0.9\n      8\n      STGCN\n      1.031538\n      0.009285"
  },
  {
    "objectID": "posts/GCN/2023-04-27-simulation_table.html#block-5",
    "href": "posts/GCN/2023-04-27-simulation_table.html#block-5",
    "title": "Simulation Tables",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      GNAR\n      1.061937\n      0.000000\n    \n    \n      1\n      0.149142\n      4\n      IT-STGCN\n      0.963990\n      0.002194\n    \n    \n      2\n      0.149142\n      4\n      STGCN\n      0.965297\n      0.001611\n    \n    \n      3\n      0.149142\n      8\n      GNAR\n      1.068464\n      0.000000\n    \n    \n      4\n      0.149142\n      8\n      IT-STGCN\n      0.971647\n      0.002860\n    \n    \n      5\n      0.149142\n      8\n      STGCN\n      0.971700\n      0.001672"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.113\n      0.037\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.115\n      0.038"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.258\n      0.069\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.494\n      0.133\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.322\n      0.070\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.508\n      0.137"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.126\n      0.033\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.154\n      0.040"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      0.910\n      0.042\n    \n    \n      1\n      12\n      STGCN\n      0.902\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      12\n      IT-STGCN\n      0.868\n      0.028\n    \n    \n      1\n      0.3\n      linear\n      12\n      STGCN\n      1.080\n      0.037\n    \n    \n      2\n      0.8\n      linear\n      12\n      IT-STGCN\n      1.399\n      0.063\n    \n    \n      3\n      0.8\n      linear\n      12\n      STGCN\n      2.127\n      0.240"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-1",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      12\n      IT-STGCN\n      0.898825\n      0.034600\n    \n    \n      1\n      linear\n      0.28777\n      12\n      STGCN\n      0.912353\n      0.043433\n    \n    \n      2\n      nearest\n      0.28777\n      12\n      IT-STGCN\n      0.908500\n      0.043167\n    \n    \n      3\n      nearest\n      0.28777\n      12\n      STGCN\n      0.930462\n      0.035268"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.197\n      0.052\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.182\n      0.041"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.207\n      0.046\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.279\n      0.061\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.205\n      0.075\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.289\n      0.096\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.294\n      0.056\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.526\n      0.078\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.285\n      0.051\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.083"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-2",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.167\n      0.040\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.222\n      0.054\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#w_st",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.222\n      0.083\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.276\n      0.058\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.091\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.281\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.305\n      0.131\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.073\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.204\n      0.063\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.563\n      0.030\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.560\n      0.029"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.578\n      0.031\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.562\n      0.016\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.606\n      0.017\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.770\n      0.045"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-3",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-4",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#baseline-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.008\n      0.044\n    \n    \n      1\n      4\n      STGCN\n      0.983\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#random-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.215692\n      0.117963\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.357897\n      0.148740"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html#block-5",
    "title": "DYGRENCODER_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.005486\n      0.046063\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.030326\n      0.044023"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html",
    "title": "DCRNN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random",
    "title": "DCRNN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block",
    "title": "DCRNN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-1",
    "title": "DCRNN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-2",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "DCRNN_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-16_21-09-11.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-16_21-30-17.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/DCRNN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/DCRNN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-3",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "DCRNN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-19_15-43-50.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-19_18-35-04.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-19_22-00-09.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/DCRNN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/DCRNN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-4",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#random-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html#block-5",
    "title": "DCRNN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-1",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-2",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-07-02_07-01-12.csv')\ndf2 = pd.read_csv('./simulation_results/2023-07-02_07-19-21.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-3",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-07-03_13-39-23.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-07-03_16-17-40.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-07-03_19-00-05.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/EvolveGCNH_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-4",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#baseline-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#random-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html#block-5",
    "title": "EvolveGCNH_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.174\n      0.074\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.175\n      0.062"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.197\n      0.057\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.217\n      0.064\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.210\n      0.060\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.217\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.170\n      0.055\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.189\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      32\n      IT-STGCN\n      0.996\n      0.019\n    \n    \n      1\n      32\n      STGCN\n      1.004\n      0.021"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      32\n      IT-STGCN\n      1.011\n      0.019\n    \n    \n      1\n      0.3\n      linear\n      32\n      STGCN\n      1.058\n      0.015\n    \n    \n      2\n      0.8\n      linear\n      32\n      IT-STGCN\n      1.140\n      0.042\n    \n    \n      3\n      0.8\n      linear\n      32\n      STGCN\n      1.203\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-1",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      32\n      IT-STGCN\n      1.007400\n      0.020847\n    \n    \n      1\n      linear\n      0.28777\n      32\n      STGCN\n      1.027340\n      0.022523\n    \n    \n      2\n      nearest\n      0.28777\n      32\n      IT-STGCN\n      1.011141\n      0.017937\n    \n    \n      3\n      nearest\n      0.28777\n      32\n      STGCN\n      1.030143\n      0.016657"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.223\n      0.053\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.204\n      0.060"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.245\n      0.069\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.273\n      0.057\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.238\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.244\n      0.054\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.279\n      0.057\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.301\n      0.061\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.091\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.284\n      0.066"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-2",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.259\n      0.085\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.246\n      0.073\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#w_st",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.218\n      0.058\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.237\n      0.051\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.068\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.237\n      0.058\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.246\n      0.067\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.291\n      0.063\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.037\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.240\n      0.062"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.784\n      0.027\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.771\n      0.028"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.775\n      0.021\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.787\n      0.024\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.877\n      0.045\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.915\n      0.063"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-3",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.775854\n      0.027860\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.773374\n      0.020599"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.794\n      0.031\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.818\n      0.031\n    \n  \n\n\n\n\n\n# WindmillOutputSmallDatasetLoader (lags=8)"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-4",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#baseline-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.358\n      0.107\n    \n    \n      1\n      4\n      STGCN\n      1.006\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#random-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.845349\n      0.504113\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      2.158357\n      0.545361"
  },
  {
    "objectID": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html#block-5",
    "title": "EvolveGCNH_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.391881\n      0.110351\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.612466\n      0.216224"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html",
    "href": "posts/GCN/2023-01-05-GNAR.html",
    "title": "GNAR data",
    "section": "",
    "text": "GNAR\nGNAR"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#gnar-network-example",
    "href": "posts/GCN/2023-01-05-GNAR.html#gnar-network-example",
    "title": "GNAR data",
    "section": "2.3 GNAR network example",
    "text": "2.3 GNAR network example\n\nedge(list)\ndist(list)\n\n\n%%R\nplot(fiveNet, vertex.label = c(\"A\", \"B\", \"C\", \"D\", \"E\"))\n\n\n\n\n\n%%R\nsummary(\"fiveNet\")\n\n   Length     Class      Mode \n        1 character character \n\n\nother examples\n\nigraphtoGNAR or GNARtoigraphì“°ëŠ” ì˜ˆì œ\n\n\n%%R\nfiveNet2 <- GNARtoigraph(net = fiveNet)\nsummary(fiveNet2)\n\nIGRAPH 2b4460d U-W- 5 5 -- \n+ attr: weight (e/n)\n\n\n\n%%R\nfiveNet3 <- igraphtoGNAR(fiveNet2)\nall.equal(fiveNet, fiveNet3)\n\n[1] TRUE\n\n\n\n%%R\nprint(igraphtoGNAR(fiveNet2))\n\nGNARnet with 5 nodes \nedges:1--4 1--5 2--3 2--4 3--2 3--4 4--1 4--2 4--3 5--1 \n     \n edges of each of length  1 \n\n\nedgeë“¤ ë³´ê³  ì‹¶ì„ ë•Œ\nwhereas the reverse conversion would be performed as\n\n%%R\ng <- make_ring(10)\nprint(igraphtoGNAR(g))\n\nGNARnet with 10 nodes \nedges:1--2 1--10 2--1 2--3 3--2 3--4 4--3 4--5 5--4 5--6 \n     6--5 6--7 7--6 7--8 8--7 8--9 9--8 9--10 10--1 10--9 \n     \n edges of each of length  1 \n\n\n\n%%R\nmake_ring(10)\n\nIGRAPH 22f6be5 U--- 10 10 -- Ring graph\n+ attr: name (g/c), mutual (g/l), circular (g/l)\n+ edges from 22f6be5:\n [1] 1-- 2 2-- 3 3-- 4 4-- 5 5-- 6 6-- 7 7-- 8 8-- 9 9--10 1--10\n\n\nì´ì–´ì§„ ë°©í–¥ìœ¼ë¡œ ê°ê°ì˜ edgeë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê²Œ igrapphtoGNARì´ë‹¤\nGNARtoigraph functionìœ¼ë¡œ ë†’ì€ ìˆ˜ì¤€ì˜ ì´ì›ƒ êµ¬ì¡°ë¥¼ í¬í•¨í•œ ê·¸ë˜í”„ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤.\n\nas.matrix or matrixtoGNARë¡œ ì¸ì ‘ í–‰ë ¬ êµ¬í•  ìˆ˜ ìˆìŒ\n\nwe can prosucean adjacency matrix for the fiveNet obeject with\n\n%%R\nas.matrix(fiveNet)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\nand an example converting a weighted adjacency matrix to a GNARnet object is\n\n%%R\nadj <- matrix(runif(9), ncol = 3, nrow = 3)\nadj[adj < 0.3] <- 0\nprint(matrixtoGNAR(adj))\n\nWARNING: diagonal entries present in original matrix, these will be removed\nGNARnet with 3 nodes \nedges:1--2 1--3 2--1 2--3 3--1 3--2 \n edges of unequal lengths"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#example-gnar-model-fitting",
    "href": "posts/GCN/2023-01-05-GNAR.html#example-gnar-model-fitting",
    "title": "GNAR data",
    "section": "2.4. Example: GNAR model fitting",
    "text": "2.4. Example: GNAR model fitting\n\nGNARë¡œ fitê³¼ predict ê°€ëŠ¥\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\níŒŒë¼ë©”í„° 4ê°œ ê°€ì§€ê³  ìˆìŒ\n\n\n%%R\nlayout(matrix(c(1, 2), 2, 1))\nplot(fiveVTS[, 1], ylab = \"Node A Time Series\")\nlines(fitted(answer)[, 1], col = 2)\nplot(fiveVTS[, 2], ylab = \"Node B Time Series\")\nlines(fitted(answer)[, 2], col = 2)\n\n\n\n\n\n%%R\nlayout(matrix(c(1, 2), 2, 1))\nplot(fiveVTS[, 3], ylab = \"Node C Time Series\")\nlines(fitted(answer)[, 3], col = 2)\nplot(fiveVTS[, 4], ylab = \"Node D Time Series\")\nlines(fitted(answer)[, 4], col = 2)\n\n\n\n\n\nê° ë…¸ë“œì˜ time series(ê²€ì •), fitted values from â€˜answerâ€™ model overlaid in red\n\n\n%%R\nmyresiduals <- residuals(answer)[, 1]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 1], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 2]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 2], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 3]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 3], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\n%%R\nmyresiduals <- residuals(answer)[, 4]\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(residuals(answer)[, 1]), ylab = \"`answer' model residuals\")\nhist(residuals(answer)[, 4], main = \"\", xlab = \"`answer' model residuals\")\n\n\n\n\n\nresidual plots from â€˜answerâ€™ model fit. Top: time sereies, Bottom: Histogram"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#example-gnar-data-simulation-on-a-given-network",
    "href": "posts/GCN/2023-01-05-GNAR.html#example-gnar-data-simulation-on-a-given-network",
    "title": "GNAR data",
    "section": "2.5. Example: GNAR data simulation on a given network",
    "text": "2.5. Example: GNAR data simulation on a given network\n\nfiveNet ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ì‹œê³„ì—´ ì‹œë®¬ë ˆì´ì…˜ ì§„í–‰\në‘ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë‘ sigma argumentë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œì¤€ í¸ì°¨ê°€ ì œì–´ë˜ëŠ” í‘œì¤€ ì •ê·œ ë…¸ì´ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœë‹¤.\n\n\n%%R\nset.seed(10)\nfiveVTS2 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(c(0.4, 0, -0.6, 0, 0)), betaParams = list(c(0.3)))\n\n\nfiveVTS2 ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ ëœ ê²ƒì´ë‹¤ë³´ë‹ˆ íŒŒë¼ë©”í„° ê³„ìˆ˜ ë¹„ìŠ·\n\n\n%%R\nprint(GNARfit(vts = fiveVTS2, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE))\n\nModel: \nGNAR(1,[1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\ndmatalpha1node1  dmatalpha1node2  dmatalpha1node3  dmatalpha1node4  \n        0.45902          0.13133         -0.49166          0.03828  \ndmatalpha1node5      dmatbeta1.1  \n        0.02249          0.24848  \n\n\n\n\n%%R\nset.seed(10)\nfiveVTS3 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(rep(0.2, 5), rep(0.3, 5)), betaParams = list(c(0.2, 0.3), c(0)))\nprint(GNARfit(vts = fiveVTS3, net = fiveNet, alphaOrder = 2, betaOrder = c(2,0)))\n\nModel: \nGNAR(2,[2,0]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1  dmatbeta1.2   dmatalpha2  \n     0.2537       0.1049       0.3146       0.2907  \n\n\n\n\n%%R\nfiveVTS4 <- simulate(GNARfit(vts = fiveVTS2, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE), n = 200)\nprint(GNARfit(vts = fiveVTS4, net = fiveNet, alphaOrder = 1, betaOrder = 1, globalalpha = FALSE))\n\nModel: \nGNAR(1,[1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\ndmatalpha1node1  dmatalpha1node2  dmatalpha1node3  dmatalpha1node4  \n      0.4478300       -0.0008695       -0.4822675        0.0523652  \ndmatalpha1node5      dmatbeta1.1  \n     -0.0063702        0.2249530  \n\n\n\n\nìœ„ì™€ ê°™ì´ GNAR ëª¨ë¸ì— ìˆëŠ” ì‹œê³„ì—´ì„ simulateí•˜ê¸° ìœ„í•´ GNARfit objectì— ëŒ€í•´ simulate S3 method ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#missing-data-and-changing-connection-weights-with-gnar-models",
    "href": "posts/GCN/2023-01-05-GNAR.html#missing-data-and-changing-connection-weights-with-gnar-models",
    "title": "GNAR data",
    "section": "2.6 Missing data and changing connection weights with GNAR models",
    "text": "2.6 Missing data and changing connection weights with GNAR models\n\nThe flexibility of GNAR modellingì´ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ì—°ê²° ê°€ì¤‘ì¹˜ë¥¼ ë°”ê¾¸ì§€ ì•Šê³  ë³€í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¡œ missing data ë¥¼ ëª¨ë¸ë§ í•  ìˆ˜ ìˆë‹¤.\ní•œ ë…¸ë“œê°€ missing data êµ¬ê°„ì´ ìƒê¸°ë©´ ê·¸ êµ¬ê°„ì—ì„œë§Œ ë„¤íŠ¸ì›Œí¬ë¥¼ ë³€í™”í•˜ì—¬ weightê°€ ë³€ê²½ëœë‹¤.\n\n\n%%R\nfiveVTS0 <- fiveVTS\nfiveVTS0[50:150, 3] <- NA\nnafit <- GNARfit(vts = fiveVTS0, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nlayout(matrix(c(1, 2), 2, 1))\nplot(ts(fitted(nafit)[, 3]), ylab = \"Node C fitted values\")\nplot(ts(fitted(nafit)[, 4]), ylab = \"Node D fitted values\")\n\n\n\n\nA key advantage of our parsimonious GNAR model is that it models via neighborhoods across the entire data set. If a node is missing for a given time, then it does not contribute to the estimation of neighborhood parameters that the network structure suggests it should, and there are plenty of other nodes that do contribute, generally resulting in a high number of observations to estimate each coefficient. In GNAR models, missing data of this kind is not a problem.\n\nìš°ë¦¬ì˜ ê°„ê²°í•œ GNAR ëª¨ë¸ì˜ ì£¼ìš” ì¥ì ì€ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì— ê±¸ì³ ì´ì›ƒì„ í†µí•´ ëª¨ë¸ë§í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë…¸ë“œê°€ íŠ¹ì • ì‹œê°„ ë™ì•ˆ ëˆ„ë½ë˜ë©´ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ ì œì•ˆí•˜ëŠ” ì¸ì ‘ ë§¤ê°œ ë³€ìˆ˜ì˜ ì¶”ì •ì— ê¸°ì—¬í•˜ì§€ ì•Šìœ¼ë©°, ê¸°ì—¬í•˜ëŠ” ë‹¤ë¥¸ ë…¸ë“œë„ ë§ì•„ ì¼ë°˜ì ìœ¼ë¡œ ê° ê³„ìˆ˜ë¥¼ ì¶”ì •í•˜ê¸° ìœ„í•œ ê´€ì¸¡ì¹˜ ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤. GNAR ëª¨ë¸ì—ì„œëŠ” ì´ëŸ° ì¢…ë¥˜ì˜ ë°ì´í„°ê°€ ëˆ„ë½ë˜ëŠ” ê²ƒì€ ë¬¸ì œê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#stationary-conditions-for-a-gnar-process-with-fixed-network",
    "href": "posts/GCN/2023-01-05-GNAR.html#stationary-conditions-for-a-gnar-process-with-fixed-network",
    "title": "GNAR data",
    "section": "2.7. Stationary conditions for a GNAR process with fixed network",
    "text": "2.7. Stationary conditions for a GNAR process with fixed network\nTheorem 1\n\nGiven an unchanging network, \\(\\mathcal{G}\\) a sufficient condition for the GNAT model (1) to be stationary is\n\n\\[\\sum^p_{j=1}(|\\alpha_{i,j}| + \\sum^{C}_{c=1} \\sum^{s_j}_{r=1} |\\beta_{j,t,c}|)<1 , \\forall_i \\in 1,\\dots, N\\]\nìœ„ ì¡°ê±´ì„ GNARsimì„ ì´ìš©í•˜ì—¬ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.\n\n%%R\nset.seed(10)\nfiveVTS4 <- GNARsim(n = 200, net = fiveNet, alphaParams = list(rep(0.2, 5)), betaParams = list(c(0.85)))\nc(mean(fiveVTS4[1:50, ]), mean(fiveVTS4[51:100, ]), mean(fiveVTS4[101:150, ]), mean(fiveVTS4[151:200, ]))\n\n[1]    -120.511   -1370.216  -15725.884 -180319.140\n\n\n\nThe mean increases rapidly indicating nonstationarity.\ní‰ê· ì´ ë¹ ë¥´ê²Œ ì¦ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ ì •ìƒì„±ì„ ë„ê³  ìˆì§€ ì•Šë‹¤."
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#benefits-of-our-model-and-comparisons-to-others",
    "href": "posts/GCN/2023-01-05-GNAR.html#benefits-of-our-model-and-comparisons-to-others",
    "title": "GNAR data",
    "section": "2.8. Benefits of our model and comparisons to others",
    "text": "2.8. Benefits of our model and comparisons to others"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#order-selection",
    "href": "posts/GCN/2023-01-05-GNAR.html#order-selection",
    "title": "GNAR data",
    "section": "3.1. Order selection",
    "text": "3.1. Order selection\nBayesian information criterion\n\\[BIC(p,s) = ln|\\sum^{\\hat{}}_{p,s}| + T^{-1} M ln(T)\\]\n\n%%R\nBIC(GNARfit())\n\n[1] -0.003953124\n\n\n\n%%R\nBIC(GNARfit(betaOrder = c(2, 1)))\n\n[1] 0.02251406\n\n\nAkaike information criterion\n\\[AIC(p,s) = ln|\\sum^{\\hat{}}_{p,s}| + 2T^{-1} M\\]\n\n%%R\nAIC(GNARfit())\n\n[1] -0.06991947\n\n\n\n%%R\nAIC(GNARfit(betaOrder = c(2, 1)))\n\n[1] -0.05994387"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#model-selection-on-a-wind-network-time-series",
    "href": "posts/GCN/2023-01-05-GNAR.html#model-selection-on-a-wind-network-time-series",
    "title": "GNAR data",
    "section": "3.2. Model selection on a wind network time series",
    "text": "3.2. Model selection on a wind network time series\nthe data suite vswind that contains a number of R objects pertaining to 721 wind speeds taken at each of 102 weather stations in England and Wales. The suite contains the vector time series vswindts, the associated network vswindnet, a character vector of the weather station location names in vswindnames and coordinates of the stations in the two column matrix vswindcoords. The data originate from the UK Met Office site http://wow.metoffice.gov.uk and full details can be found in the vswind help file in the GNAR package.\n\nnodes : 102\ntime step : 721\n\n\n%%R\noldpar <- par(cex = 0.75)\nwindnetplot()\npar(oldpar)\n\n\n\n\nPlot of the wind speed network\n\nblue numbers are relative distance between sites\nlabels are the site name\n\n\n%%R\nBIC(GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 1, betaOrder = 0))\n\n[1] -233.3848\n\n\n\n%%R \nfiveFit <- GNARfit(fiveVTS[1:160,],net=fiveNet, alphaOrder=2, betaOrder=c(2,0)) #learn \ndim(fitted(fiveFit))\n\n[1] 158   5\n\n\n\n%%R\ndummyFit <- GNARfit(fiveVTS,net=fiveNet, alphaOrder=2, betaOrder=c(2,0)) #learn \ndummyFit$mod$coefficients <- fiveFit$mod$coefficients\n\n\n%%R\nfitted(dummyFit)[161:200]\n\n [1]  0.01093152  0.07611113  0.50989356  0.84380803  0.90488185 -0.12703505\n [7] -0.57721780 -0.36681689 -0.26281975 -0.47712098 -0.62293008 -0.58121816\n[13] -0.81149078 -0.45403821 -0.60487041  0.28617606  0.20580455  0.19341988\n[19]  0.35296420  0.15628117  0.68350847  0.49043974  0.29627168 -0.35666858\n[25] -0.47565960  0.06692171 -0.14924170 -0.36616239 -0.49994894  0.22625500\n[31] -0.08023045  0.25371268 -0.47415540 -0.99390660 -1.16821429 -0.18438203\n[37] -1.10766872 -0.76969390  0.71828989  0.69737474\n\n\n\n%%R\nfitted(fiveFit)\n\n               [,1]         [,2]         [,3]          [,4]         [,5]\n  [1,]  0.300764573  0.731759572  0.645747192  0.6590441235  0.329408573\n  [2,]  0.584155581  0.709939766  0.504838042  0.4006542005  0.002404727\n  [3,]  0.248206643 -0.053672929  0.089912292  0.3569760840  0.886027241\n  [4,]  0.431422029 -0.596332784 -0.445500333 -0.1950437084  0.998677531\n  [5,]  0.369251545 -0.131646096 -0.151852774 -0.0307057532  0.602574799\n  [6,] -0.281163998  0.372761568  0.470612441  0.0640593261 -0.793452225\n  [7,] -0.629184394  0.122210560 -0.064188223  0.2614228537  0.027403171\n  [8,]  0.176102146  0.054605602  0.001654112 -0.0679337406 -0.041235943\n  [9,] -0.168610998 -0.212095723 -0.204125726 -0.2125261302 -0.010579734\n [10,] -0.161421278 -0.007465513  0.149274060 -0.0249484567 -0.327041759\n [11,]  0.359655447 -0.077039236 -0.039580520 -0.0457447866  0.112500734\n [12,] -0.015390804 -0.224700395 -0.236137628 -0.1566997305 -0.032236173\n [13,] -0.254595294 -0.052425427 -0.222029463 -0.1955623614 -0.090852345\n [14,] -0.133378083 -0.231175869 -0.262111004 -0.4557269171 -0.613390251\n [15,] -0.299492590 -1.329777415 -1.157380728 -0.7395871328  0.367735930\n [16,] -0.092939379 -0.649485715 -0.649077093 -0.5677985865  0.018220159\n [17,] -0.197734475  0.006055154  0.003767933  0.0142878952  0.017169293\n [18,] -0.593128663 -0.029057099  0.019930836 -0.1995170085 -0.699678586\n [19,] -0.406803183 -0.080878255 -0.076916012 -0.0142207300  0.084031465\n [20,]  0.195661742  0.636973567  0.514808183  0.1521298877 -0.565262518\n [21,] -0.646798007  0.034595763 -0.038468526 -0.2844049647 -1.200687294\n [22,] -0.858660467 -0.279197317 -0.100300563 -0.1774862659 -0.600631944\n [23,]  0.072500668  0.171516441  0.137895886  0.1253750409  0.109017776\n [24,]  0.361169443 -0.134591857 -0.172907391 -0.0276254736  0.454886946\n [25,] -0.555837928  0.021772877  0.086135588 -0.5401601843 -1.758757275\n [26,] -0.907025497 -0.516889787 -0.601369437 -0.4907248867 -0.518976355\n [27,] -0.577788165 -0.883706611 -0.990274375 -0.5655498386  0.219126828\n [28,] -0.381253476 -1.020667212 -0.974967606 -0.8163078225 -0.224880458\n [29,] -0.418889129 -1.136651964 -1.192973176 -0.8278078873  0.075705061\n [30,] -0.430848760 -0.711242749 -0.645456670 -0.7835485785 -0.902099485\n [31,] -0.408762558 -0.330133901 -0.313267801 -0.2950574688 -0.516672981\n [32,] -0.397456978 -0.177503203 -0.123190622  0.0851676997  0.175790185\n [33,] -0.321504797  0.137826136  0.185516044 -0.0469442492 -0.541534195\n [34,] -0.446890348  0.425984103  0.440639199  0.0859296090 -0.911239457\n [35,] -0.409664931  0.661582101  0.615592428  0.4648149587 -0.620671093\n [36,] -0.178853576  1.134703079  1.170584884  0.7788603566 -0.614547790\n [37,] -0.187107405  0.975055141  0.894986103  0.7556786981  0.299963760\n [38,] -0.421512891  0.230443777  0.311288224  0.3783662241  0.481463020\n [39,]  0.551866636  0.010017627 -0.031712684 -0.0291730137  0.299117468\n [40,] -0.415705371 -0.084974037 -0.102059950  0.0729357811 -0.004680301\n [41,] -0.596582277 -0.181138675 -0.037759798 -0.0710576429 -0.300907209\n [42,] -0.264388277  0.136784757  0.077185718  0.0270845136 -0.311590329\n [43,]  0.413516614  0.932841430  0.935079115  0.7161523403 -0.158898407\n [44,]  0.095801809  0.920995408  0.955252555  0.8459697803 -0.127453246\n [45,]  0.975373534  1.209886345  1.185240223  1.0015804496  0.169827608\n [46,]  0.618868253 -0.058442807 -0.058935046  0.2370795943  0.914954875\n [47,]  0.366854292  0.267881271  0.247344186  0.2400219950  0.479987689\n [48,] -0.150157867 -0.777932308 -0.717286974 -0.5794468369  0.195377648\n [49,]  0.075029321 -0.299959011 -0.355342761 -0.1920419709  0.334423437\n [50,]  0.386593451 -0.135877992 -0.072542184  0.2518678243  0.984484742\n [51,]  0.697822864 -0.311896474 -0.295669625 -0.2502382955  0.585030936\n [52,]  0.062654477 -0.191584061 -0.107314176  0.2208996954  1.056837103\n [53,]  0.728773427 -0.477836693 -0.494169917 -0.4843342717  0.451358938\n [54,]  0.585069845  0.665543312  0.719452401  0.5820396956  0.545931719\n [55,]  1.079661317  0.127297862  0.038038488  0.0677187351  0.907180658\n [56,]  0.651000271  0.443573833  0.461237609  0.2318123507  0.355931847\n [57,]  0.047340441  0.061483244 -0.142562719 -0.0074741198  0.203598849\n [58,]  0.020722674 -0.855956709 -0.772986200 -0.7280158105 -0.072139463\n [59,] -0.197216261 -0.894976325 -0.740954981 -0.7972459012 -0.237856418\n [60,] -0.335837112 -0.488349114 -0.651565734 -0.7163113371 -0.703717928\n [61,] -0.573434288 -1.566963776 -1.470953366 -0.9358838106  0.340002593\n [62,] -0.019967493 -1.006103326 -1.203028246 -0.7206978782  0.426166645\n [63,]  0.289165755 -0.676589963 -0.529091393 -0.3863962807  0.580747013\n [64,] -0.063683833 -0.320450285 -0.325613255 -0.2974046265 -0.105675029\n [65,] -0.112032969 -0.527479112 -0.523398055 -0.1590403400  0.496544412\n [66,] -0.286173235 -0.053400092  0.018863005 -0.0124208740 -0.118724115\n [67,] -0.499744957  0.041067235  0.076504951 -0.2048682261 -0.787362589\n [68,] -0.547870145 -0.732546310 -0.770409578 -0.7369449312 -0.331821251\n [69,] -0.905056316 -0.829491825 -0.850502405 -0.7607730212 -0.656264847\n [70,] -0.246440697 -0.279850678 -0.269853546 -0.5660758221 -1.111827018\n [71,] -0.186335645  0.010799425 -0.077495418  0.0601490253  0.102437820\n [72,]  0.010493539 -0.479453043 -0.453954591 -0.3426073144 -0.040090049\n [73,] -0.673580794 -0.734494634 -0.564315445 -0.8190023610 -1.019947630\n [74,] -0.640032299 -0.558498277 -0.596977420 -0.5456733025 -0.090276605\n [75,] -0.464960459 -0.529199551 -0.552331950 -0.8884973812 -1.066744453\n [76,] -0.887182659 -0.141258133 -0.110786546  0.0237603066  0.003998690\n [77,] -0.073105627 -0.207336194 -0.187193599 -0.6930066146 -1.105251019\n [78,] -0.689981040  0.027486354  0.151691133  0.2650861359 -0.203709649\n [79,]  0.258382277  0.652801148  0.545006830  0.3925781271 -0.249181067\n [80,]  0.751377138  0.239900459  0.276168396  0.6057405726  1.262601102\n [81,]  0.631390471  0.411822991  0.543334476  0.2438621480  0.112347717\n [82,] -0.034969641 -0.104184784 -0.097705561  0.1498464790  0.895833940\n [83,]  0.120113065  0.049356967  0.046034277 -0.0721309377  0.217972070\n [84,] -0.200386785 -0.203495710 -0.239586254 -0.1172887981  0.323191787\n [85,]  0.185644181 -0.395187380 -0.370733604 -0.5009300085 -0.211102667\n [86,] -0.237732516  0.276454796  0.287754635  0.2080093644 -0.223951494\n [87,]  0.216163467  0.192130141  0.177949800 -0.0753244143 -0.351364565\n [88,] -0.142649364 -0.186692214 -0.168987298 -0.1166303744  0.011404103\n [89,]  0.548618117  0.747707315  0.770581155  0.5221810333  0.172075628\n [90,]  0.028104354  0.688465275  0.636215214  0.5500772784  0.059464762\n [91,] -0.495363724 -0.071919605 -0.008154852 -0.4353087653 -1.271143508\n [92,] -1.107134875 -0.172815824 -0.303687490 -0.0844525666 -0.236711607\n [93,] -0.149354271  0.009431534  0.092873697 -0.4137230613 -1.079758945\n [94,] -0.480127162 -0.759207617 -0.733556252 -0.1155717520  0.856016011\n [95,] -0.068768871 -0.262250231 -0.276510238 -0.4068034977 -0.281317568\n [96,] -0.204766674 -0.466093264 -0.516820813 -0.4012743931 -0.036227691\n [97,]  0.450365055 -0.345449271 -0.277951368 -0.0735386028  0.626942400\n [98,]  0.825252322 -0.102070954  0.029346323  0.2224587296  0.891243876\n [99,]  0.918255191  0.974393754  0.785132509  0.9588950601  0.747082329\n[100,]  1.161471681  0.803193156  1.046464965  1.2474096963  1.536524225\n[101,]  0.796513581  0.943461644  0.698756745  0.5968311778  0.275247231\n[102,]  0.189772234  0.088167353  0.193522913 -0.1055246595 -0.205361362\n[103,] -0.486312684  0.528260131  0.609425778  0.4533837262 -0.448633125\n[104,] -0.780106474  0.619638040  0.487082196  0.2699333424 -1.074329863\n[105,]  0.001495171  0.043686101  0.071429149 -0.0068869393  0.109059794\n[106,]  0.412811020  0.589258087  0.534530373  0.1827023688 -0.169191222\n[107,]  0.230033356  0.369815780  0.441499631  0.4808802972  0.619074058\n[108,]  0.887957665  0.299276196  0.242694214  0.2120811348  0.437908215\n[109,] -0.003445154 -0.934051132 -0.730038077 -0.3220444395  0.707556500\n[110,] -0.138607950 -0.723059594 -0.801323554 -0.7383525593 -0.366013353\n[111,] -0.761794858 -0.776583246 -0.767390838 -0.6281202398 -0.286591883\n[112,] -0.143995206 -0.994654745 -0.891931956 -0.8145750541  0.194529857\n[113,] -0.158840376 -0.789802525 -0.720611341 -0.3434589195  0.705106074\n[114,]  0.213701938  0.094954893 -0.066337346 -0.1715778242 -0.301015012\n[115,]  0.353147878 -0.162438159 -0.035453134  0.2417453098  0.692188468\n[116,] -0.259026322 -0.062564122 -0.069539905  0.0494333669  0.016725122\n[117,]  0.439567933  0.334238798  0.123452083  0.2899531832  0.536404389\n[118,]  0.243694767 -0.136731679 -0.062368473 -0.0505163356  0.329751821\n[119,] -0.221760052 -0.034088224 -0.073079140 -0.0719693132  0.080492952\n[120,] -0.639870092 -0.346958117 -0.350162454 -0.6158933852 -1.052705642\n[121,]  0.191514800  0.198936857  0.188570749  0.0576140540 -0.098783032\n[122,]  0.497040376  0.104911046  0.183534206  0.3233013200  0.725368718\n[123,]  0.912741276  0.906110114  0.847102372  0.9050828507  0.840894148\n[124,]  0.761509505  0.486180954  0.657445208  0.6485641139  0.813518998\n[125,]  0.316821416 -0.083720193 -0.173493262 -0.1007134067  0.356082268\n[126,] -0.067185056 -0.753094489 -0.702750670 -0.2621385119  1.046954137\n[127,] -0.091228436 -0.675109353 -0.703565297 -0.5564405787  0.258988050\n[128,] -0.109253436 -0.444143304 -0.399640932 -0.3580561559 -0.035762392\n[129,] -0.232521560 -0.039990247 -0.095241200 -0.0443450553 -0.430664437\n[130,]  0.123446724  0.200420996  0.173518282  0.5184071044  0.313636742\n[131,]  0.285159008 -0.032242166  0.027550780  0.1048459050 -0.132334038\n[132,] -0.029094326  0.291860928  0.394652562  0.4297945912  0.077465921\n[133,]  0.607314455  0.854271821  0.946947611  0.7446008823  0.229008010\n[134,]  0.114274696  0.395094364  0.372741933  0.2933528915  0.073135295\n[135,]  0.058334948  0.020883512 -0.064495939 -0.0002935146  0.194116690\n[136,] -0.485203794  0.162128088  0.243616443  0.0173331790 -0.588154182\n[137,]  0.361414229  0.497203208  0.361158226  0.5018799742  0.573470360\n[138,]  0.819903948  0.366313425  0.363516294  0.3796662479  0.699684917\n[139,] -0.216165855 -0.335708047 -0.251520773 -0.2682301442  0.062768414\n[140,] -0.454294227 -0.359066363 -0.294969357 -0.4097376437 -0.479590775\n[141,] -0.062418172  0.009466708 -0.051169781  0.1398314442  0.275918751\n[142,]  0.546927988  0.424770686  0.388169659  0.1288546957 -0.347653081\n[143,] -0.311508529  0.345041027  0.500511866  0.3303953879 -0.189245985\n[144,]  0.156321321  0.623518356  0.518171727  0.4513620372  0.284295098\n[145,]  0.039622964  0.299954776  0.356381605  0.3469508290  0.326305082\n[146,]  0.579791654  0.695810253  0.652099702  0.5011115910  0.023065334\n[147,]  0.554655907  0.093490122  0.153079897  0.4182759318  0.767121199\n[148,]  0.384057236 -0.065678272 -0.023948715  0.0451867298  0.454508452\n[149,]  0.447874514  0.392017250  0.266888939  0.3039632644  0.540801889\n[150,]  0.497810670  0.980726335  1.014061377  0.9632510637  0.560362395\n[151,]  0.044270389  0.550595322  0.526083974  0.5090146051 -0.039702900\n[152,]  0.128989148  0.501717816  0.494582107  0.2658346703 -0.283886186\n[153,]  0.003640933  0.471547028  0.593579063  0.5105159483  0.179982706\n[154,]  0.207081614  0.420074580  0.265684904  0.2159979026 -0.161101019\n[155,] -0.478137997  0.240399554  0.349195339  0.3926704926 -0.290283502\n[156,] -0.368038032  0.588505317  0.539132547  0.2403574312 -0.831187194\n[157,] -0.452959327  0.212753187  0.402307299  0.1713284561 -0.415735323\n[158,]  0.013726373  0.132970935  0.077022243  0.0243587773 -0.211000744\n\n\n\n%%R \nfiveVTS\n#gdpVTSn2[52,]\n\n               [,1]         [,2]         [,3]         [,4]        [,5]\n  [1,] -0.106526553  1.077613724 -0.244694569  0.933710066  0.44443593\n  [2,]  0.664495737  0.935476457  1.402823610  0.826656526  0.02097885\n  [3,] -0.255977521 -1.478171940  2.160938890  1.746276180  0.80188586\n  [4,]  1.684436464  0.180662387  0.398879113 -0.418094544  0.28037722\n  [5,]  1.451205104  0.584157057 -1.700218367 -1.219724913  1.63810802\n  [6,]  0.728846398  0.536253148 -0.730310794 -0.297010221  1.04864255\n  [7,] -1.526780869  1.957817106 -0.506088728  0.470747730 -0.63167929\n  [8,]  1.269035583 -0.519870107  0.773038576 -0.176065931 -3.13354575\n  [9,] -0.403340381 -0.398760476  1.358212255 -0.755544421  1.58592625\n [10,] -0.057805476 -0.932876792  0.163580296 -0.299486667 -0.31232748\n [11,] -0.498505318  1.005323196 -0.762045202  0.136725053 -0.43412619\n [12,]  0.057551667  0.252414834 -1.585146661  0.892773199  0.64534882\n [13,] -0.235969810  0.168738145 -0.927906887 -0.201182245  0.28394360\n [14,] -0.574265201 -0.451671164  1.523378623 -1.466113999  0.88143283\n [15,] -1.120369546 -2.167955049 -0.290951250  0.951438750 -0.63430591\n [16,]  0.734315543 -1.074175821 -2.550164018 -1.843026440  0.16372069\n [17,] -0.300708705 -0.215965234 -1.251829204 -1.147084336  0.81200151\n [18,]  0.168111491  0.617846030 -0.067553835 -0.316813889 -0.57552628\n [19,] -1.130660662  1.049382642 -0.219923688 -0.838450813 -0.84289855\n [20,]  0.491603006  0.911202204 -0.037939755 -1.146905077 -0.70878526\n [21,] -1.282680651 -0.037695723  1.273889958  1.222120228  0.48792144\n [22,] -1.977860407 -1.476586870  0.618312041  0.541447907 -1.59494685\n [23,] -0.566157633  1.007129193 -0.421914435 -1.255494830 -1.57780757\n [24,]  0.427751755  0.446864227 -0.006556415  0.235046101 -0.13251371\n [25,]  0.588963964 -0.510977075 -0.208215798 -0.038859202  1.03505405\n [26,] -3.577108873  0.063814248 -0.764773488  0.750897963 -0.57677829\n [27,] -0.762998219 -0.715903539  0.070974165 -1.767866460 -0.85886671\n [28,]  1.154873570 -2.505711766 -0.235496918 -1.464120269 -1.74689908\n [29,] -0.272693870 -1.857460255 -1.012583601 -1.478438760 -0.20065611\n [30,]  0.395708110 -2.601309968 -1.102332663 -1.418525692 -0.67074519\n [31,] -1.632021790 -1.389226367 -1.406639927 -0.164463613 -0.57992151\n [32,] -0.593868925 -0.604746854 -0.889344852  0.170550009 -1.19152282\n [33,]  0.902385866  0.859337939 -0.216488189 -1.019066503 -1.20331830\n [34,] -0.755599082  1.205454399 -0.315142793 -0.182216870 -0.76219579\n [35,] -1.402617202  1.327218071  0.030109089  0.508358610 -1.19204930\n [36,] -0.248901260  0.835443000  0.673836075  1.249100802 -2.50681088\n [37,] -0.821889741  2.683690391  1.991361276  0.628557722 -0.63183483\n [38,]  0.509052231  2.387571425  3.198218488 -1.313720751  0.41614740\n [39,]  1.760264680  1.329747672  0.589082315 -0.959062662 -2.17248032\n [40,]  0.407692882 -0.494160904 -0.336544078  0.518871030  1.17098422\n [41,]  0.529542953 -0.109371157  0.276546799 -0.441917032 -1.77465267\n [42,]  0.071422121  1.390859571 -0.656166400 -1.112883997 -1.53889722\n [43,] -0.038685141  0.343631869 -0.121075284  0.189519172 -1.28519302\n [44,]  0.032507365  1.105775541  0.745569895  2.313785056 -0.54606867\n [45,]  0.326298291  1.672376452  0.867801558  1.596593083 -1.38530798\n [46,]  0.493735214  0.828445070  0.665517459  3.545540325  0.17892418\n [47,]  1.046193130  0.182022439  0.076358398 -0.564071723  2.31894117\n [48,]  0.487801423  0.402192928  0.660265277  0.160859127  0.85916399\n [49,]  0.012036883 -0.575802156 -1.375502706 -1.555497631  0.78253503\n [50,]  0.566249612 -0.679123506 -0.342116629 -0.293370938  0.16791547\n [51,]  1.983899460  0.325870466 -0.462247924 -0.144103964  0.20428669\n [52,]  0.082477869 -0.015707410 -0.827420937 -0.533338717  3.03848854\n [53,]  2.025321199  1.260059506 -0.667274520 -0.983423623 -0.25069462\n [54,] -0.182207953 -0.492329932 -1.572486971 -0.318050791  3.11590615\n [55,]  0.310016519  2.163157480  0.539075569  0.775034293  1.55599197\n [56,]  0.344219807 -0.289984010  0.019376746  0.352604618  3.88803701\n [57,] -0.628460347  0.908826573  0.839215153  0.387888048  2.79852674\n [58,]  0.219514752 -1.949662023  1.297952270  0.245509848 -0.10715958\n [59,] -0.703231049 -1.872499373 -0.948118550 -0.956147553  1.46327573\n [60,] -1.037484518 -0.353586885 -2.197040404 -1.022195776  1.03019923\n [61,] -1.671104120 -1.807816077 -0.456726722 -0.275561042  0.23349098\n [62,]  1.082454650 -2.163914674 -2.772699788 -1.867484810 -1.15276058\n [63,]  0.733526181 -2.901286567 -0.144692022 -1.533368920  0.64538823\n [64,]  0.607622782 -0.564034684 -1.024446572 -0.860302664  1.46464103\n [65,] -0.249447697 -0.622497600 -0.860157861  0.059602510 -0.28629810\n [66,]  1.242991882 -0.553213122 -0.784868076 -0.866755329 -0.50726271\n [67,]  0.025808026  1.134045937 -0.194833475 -0.766397319 -0.66714031\n [68,] -1.280038469  0.969797971 -0.529341149 -0.274648131 -0.88451275\n [69,] -0.899437152 -0.455454165 -0.889218336 -2.081201461  0.63782940\n [70,] -0.485225451 -1.579881065 -1.542956678 -0.728773133 -2.63529295\n [71,] -2.232840088 -0.666470900 -0.802215707  0.306471316  0.36000506\n [72,]  0.263283350 -0.473210196  0.858443996 -0.330691066 -0.23528971\n [73,]  0.194868023 -1.673792947 -1.157081284  0.464290012 -0.67196384\n [74,] -2.374209088  0.746939110 -1.641811447 -1.805924541  0.66216561\n [75,] -0.319164807  0.368646446 -0.675529010 -2.103798682  0.06414596\n [76,] -2.347006749 -0.926133386 -1.280596322 -0.435692565  0.21824222\n [77,]  0.446994651  1.473521493  0.734103122 -2.231131628 -1.36931119\n [78,] -2.402766578 -0.673636271 -1.514644362  0.766704957  0.57180703\n [79,]  0.591165442  1.638210347 -0.954659887  0.008337226 -2.90507678\n [80,] -0.284550885  0.812008860  0.745209777  1.099796776  0.12632330\n [81,]  2.404372924  0.494780967 -0.137672593  0.738809147  0.71597343\n [82,] -0.732204526  2.210038243 -0.355431422  0.339909653  2.46725315\n [83,]  1.437145004  1.547713162 -0.345952409 -1.578834604  0.52850356\n [84,] -0.084957358  1.234464257 -0.032386550 -0.956802127  1.29018233\n [85,]  0.630013261  0.172600953 -0.127816246 -1.056826347 -0.23795324\n [86,] -0.893457396 -0.660542921 -1.265061454  0.015612038  1.27234265\n [87,] -0.287301062  0.963686285  0.359594848  0.203580641 -0.80393259\n [88,] -1.133229025  0.151632482 -0.040554491  0.515841576  1.28839412\n [89,] -0.023953670 -0.117144878 -0.537169309 -0.192949617 -0.19885872\n [90,] -0.238994400  1.725878556  1.063475592  0.828811176  1.72692730\n [91,]  0.299232378  0.799624873  1.181753039  0.831726730 -0.84857446\n [92,] -2.481179710  0.113529319 -0.650053446  0.011672273 -0.33558946\n [93,]  0.312713660 -0.079515578  1.502108851 -2.180229770 -2.24161884\n [94,] -1.996496328 -0.407588562 -0.652585366  0.923280995 -0.15832811\n [95,]  2.250167112 -0.220512659 -0.805730284 -2.066199413 -1.28057608\n [96,] -0.763689773 -0.031020794 -0.208759418 -0.867474784  0.72626616\n [97,]  0.014431435 -1.336163148 -0.640654650 -0.333381100 -0.44435745\n [98,]  0.957691513 -0.361694475 -0.967050395  0.060214711  1.10246612\n [99,]  1.469745730  0.554733531 -1.990318074  1.277950650  0.91469843\n[100,]  1.356192755  0.363980993  1.646543813  2.153855538  0.49502358\n[101,]  3.001712443  2.666746291 -0.368684582  1.849950555  0.63675201\n[102,] -0.281234965  0.456235005  2.292473984  0.854928226  2.22619190\n[103,] -1.140727890  0.202030354 -0.219402824  0.310787559  1.38376301\n[104,] -0.101523413  1.693526806  0.088496042  0.849098718 -2.58113447\n[105,] -1.122014513  0.674017745  1.696074464  0.065284585 -2.46042966\n[106,] -0.050503692  0.476461163  0.741019471 -1.033544711  1.30742678\n[107,] -0.977589842  0.119899249  1.188456997  1.081889577  1.41965239\n[108,]  0.909422801  1.255343375  0.842509208 -0.192153747  0.71392520\n[109,]  0.441028047 -0.896440332 -0.270300473  1.985698469  1.24604331\n[110,]  1.237351903  0.285784091 -2.573210003 -1.364613642  0.30715435\n[111,] -0.812621272 -1.216797535 -1.946208168 -0.293442424  0.01613793\n[112,] -0.569590223 -0.000629766 -0.657769831 -2.422099355 -0.23850071\n[113,]  0.013135413 -0.269047393 -2.386679520 -1.612243344  1.04220642\n[114,]  1.497050345  0.473005141 -2.121414725 -1.449151157 -0.36453856\n[115,] -0.826489548 -0.635578799  0.160746530  0.588310936  0.64139235\n[116,]  1.714414681 -0.069917852 -1.565924860  1.120471391 -0.78042307\n[117,]  0.090005879  1.200734542  0.270198304 -1.404710351 -0.03628579\n[118,]  1.236752409 -1.518803758  1.237344754  1.129076932 -0.20967169\n[119,] -0.087766705  0.109758177  0.830463404 -1.215657793  2.10369911\n[120,]  0.171155851 -0.458798255  0.673636072 -0.491339577 -0.55057403\n[121,] -2.015292503 -0.870762059 -0.029309395 -0.793820162 -0.46857349\n[122,] -0.362231614 -0.364385616  0.389845581  0.862317056  0.58137591\n[123,]  1.134908449  0.528983153 -0.215140490  0.381732812  0.95051905\n[124,]  1.457741194  0.847372382  1.281677103  1.882417946  0.73169697\n[125,]  1.108355891  2.153722703 -0.310021511  0.663789759  1.50520899\n[126,]  0.071438586 -0.058006918 -0.325876606 -0.374044712  1.44845100\n[127,]  1.793527240  0.106114670 -0.893934806 -2.276541783  0.63834022\n[128,]  0.315117203 -0.717323756 -0.955019446 -1.370627155  0.39051426\n[129,] -0.043340209 -0.312945747 -1.197591049 -0.317055511 -0.20153262\n[130,] -0.102618844 -0.880170227 -0.604543790  1.138606188 -2.06784587\n[131,]  1.740909147 -0.637353850 -0.010562729  1.561563247 -2.32157478\n[132,]  0.188345255 -0.469433386 -0.998242748  1.333047029 -0.61688863\n[133,]  0.478267920  1.814870921 -0.214383410  0.211463195 -0.68793981\n[134,]  0.520210151  2.448452650 -0.463708150  1.952197392  0.18188706\n[135,] -0.269362229  1.911952464  0.242272223 -0.444547682  1.07677467\n[136,]  0.423190923 -0.410880998 -0.195993929  0.257239829 -0.28741994\n[137,] -1.026903990  1.526871656  0.360358335 -0.772639199 -0.55385790\n[138,]  1.450078506 -0.349330702  1.034884543  1.105119122 -0.44915787\n[139,]  0.550436921  0.247527774  1.257978907  0.192344787  2.62949378\n[140,] -0.191655801  0.134136826 -0.521197521 -1.048113725  0.16877213\n[141,] -0.791900380  0.321889000 -1.170523314 -0.640876817 -0.67475039\n[142,]  0.971146450  0.021298110 -0.039896748  0.046666821 -0.88362522\n[143,] -0.982608481 -0.377262589  0.171316614  1.854723760  0.99834845\n[144,] -0.495627812  2.483176264  0.354246741 -0.684488580 -0.02501307\n[145,]  0.561938527  0.993967044  1.211151634  0.257789007  0.12399797\n[146,]  0.709311790  1.260796758  0.500729309 -0.317030392 -0.10472747\n[147,]  0.242781056  0.024085820  0.200161589  2.499565048 -0.35615091\n[148,]  1.391448147  0.433674956 -0.406153463  0.535043661  0.73457838\n[149,]  0.412636662  0.657392857 -0.602350630 -0.222007914  1.28589205\n[150,]  0.464724442  0.241309629  1.384164088 -0.007823340  1.51425328\n[151,]  1.387500492  1.166650199  1.425112356  1.867514447 -0.82096695\n[152,]  0.324362289  0.546923900  1.123115609  0.598062895 -0.86820404\n[153,] -0.642847662  0.488927474  1.005998211  0.623605903  0.36832761\n[154,]  0.580613501  1.826643913  0.215912542  0.360628058 -0.61370894\n[155,] -0.144307876 -0.646151661  0.724633376  1.186826797 -0.31028196\n[156,]  0.546715317  0.754951418 -0.046634000  0.644574743 -3.02529497\n[157,] -1.292512590  1.254904828  1.493495999 -0.128867226 -0.51111891\n[158,] -0.178360098  1.914596966 -0.981080025  0.228541535 -1.75337640\n[159,] -0.292207540  0.598820101 -0.516651587  0.274304089  0.03373131\n[160,] -2.308524149  0.208852278  1.461230272 -0.500911249 -2.27810147\n[161,] -1.379791032  0.145882158  0.915799429  1.484776097 -3.50041126\n[162,] -0.687780533 -0.916656103  1.270414228  1.016692379 -0.33067553\n[163,]  0.719998169  2.802816864  1.671148575 -0.623046401  0.58186844\n[164,]  0.720895216 -0.441022235  1.355521153  0.169312739  1.37392204\n[165,]  1.255917246  1.237433250 -1.261445845  1.156903886  1.34803048\n[166,]  1.705742677 -2.082080117  1.178644006  0.035092003  2.31810280\n[167,] -1.241297515 -1.810899663  0.429577096 -1.605573403  1.82238571\n[168,] -1.733594362 -1.512615033 -0.660630798 -0.541034771 -0.51548359\n[169,]  0.792480615  1.111823458 -0.087410649 -0.471304848 -1.46894677\n[170,] -1.308490289 -0.820921717 -1.060340478 -0.848828375  0.61581232\n[171,] -0.151371781 -1.755296255 -2.178401224 -1.133293893 -0.73148664\n[172,] -1.440949271 -1.701461336  0.086620787 -0.574783622 -0.96759066\n[173,] -0.602659336  0.088764382 -1.505800731 -1.165425847 -0.71480221\n[174,]  1.275259704 -0.410086120  0.494580410 -2.991666233 -1.27793672\n[175,] -1.404478046 -0.271241519  0.442854733 -0.222198583 -0.71844124\n[176,] -0.656202533  1.203821570  0.978017687  0.126331498 -1.96978752\n[177,] -0.394150009 -0.161910841  2.176312978  0.695232617  0.89852498\n[178,]  0.942635640  0.627373149  1.433906899 -0.365531957  0.60603188\n[179,] -0.023229999  1.377273430 -0.409007667  1.061813530 -0.29478037\n[180,]  0.365704922  1.211613739 -1.923486162  0.212759987  0.96275639\n[181,] -0.005420862 -0.765759383 -1.517079711  0.902219156 -0.34235656\n[182,]  0.024961781  0.098786009 -0.242548348  0.230247435  2.58670863\n[183,]  0.827409379 -0.019279260  1.645100501 -0.517327835  1.97867114\n[184,]  0.446528306 -0.641671765  0.183926490  0.194955794  0.61934460\n[185,] -0.852794309 -0.150650614 -1.175556623 -0.749290811 -0.16935739\n[186,]  0.545053341 -0.164000579 -0.705192833 -2.243859141 -0.09017822\n[187,] -1.237547900  0.639970678 -0.071693146  0.802596589  0.36885061\n[188,] -0.400597906 -0.490175656  1.285472941  0.566619402 -0.76045074\n[189,] -0.346030030 -0.031140831  0.468958960 -0.626935003 -0.58954715\n[190,] -0.242598074 -0.643482354  0.637618122  0.729482578 -2.59565491\n[191,]  1.906927330  1.295421628 -0.473359922  0.009433931 -0.45087521\n[192,]  0.247556013  0.380624945  0.511373051 -0.303734068 -0.35216521\n[193,]  0.109182478 -1.095266046 -1.117244679  0.260695357  0.63022764\n[194,] -0.428068355  0.957493744  1.147709215 -1.806721502  0.20508136\n[195,] -2.391696093  1.006982896  0.469035946 -1.029263987 -1.23612823\n[196,] -2.210774865 -1.403493412  0.556772208 -0.600485513 -2.42048578\n[197,] -0.722601932 -0.414053540  0.988636770 -0.610321642  0.58772892\n[198,] -2.938590715 -0.559749691  0.078615069  0.010633188 -2.36841490\n[199,] -0.985951916  0.215394351 -0.119048423  0.779733910 -2.98799845\n[200,]  0.447242609  0.404155027  0.719959458 -0.442525233 -1.78159592\n\n\n\n%%R\nBIC(GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 1, betaOrder = 0, globalalpha = FALSE))\n\n[1] -233.1697\n\n\n\n%%R\nBIC.Alpha2.Beta <- matrix(0, ncol = 15, nrow = 15)\nfor(b1 in 0:14)\n    for(b2 in 0:14)\n        BIC.Alpha2.Beta[b1 + 1, b2 + 1] <- BIC(GNARfit(vts = vswindts,\n                    net = vswindnet, alphaOrder = 2, betaOrder = c(b1, b2)))\ncontour(0:14, 0:14, log(251 + BIC.Alpha2.Beta), xlab = \"Lag 1 Neighbour Order\", ylab = \"Lag 2 Neighbour Order\")\n\nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \nException ignored from cffi callback <function _processevents at 0x7f1829767f70>:\nTraceback (most recent call last):\n  File \"/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n    try:\nKeyboardInterrupt: \n\n\n\na set of GNAR(2,[b1,b2]) models with b1, b2 ranging from zero to 14\nContour plot of BIC values for the two-lag autoregressive model incorporating b1-stage and b2-stage neighbours at time lags one and two. Values shown are log(251 + BIC) to display clearer contours.\n\nì´í•´ ëœ ë¨..\n\nincreasing the lag two neighbour sets beyond first stage neighbours would appear to increase the BIC for those lag one neighbour stages greater than five\n\nchatGPT\nì´ ë¬¸ì¥ì„ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•˜ë©´, BIC(Bayesian Information Criterion)ëŠ” ëª¨ë¸ì„ ì„ íƒí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì§€í‘œë¡œì„œ, ìš°ë¦¬ê°€ ì„ íƒí•œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì í•©í•œì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ ë¬¸ì¥ì—ì„œëŠ”, ì´ì›ƒ ì§‘í•©ì˜ ëŒ€ê¸° ì‹œê°„ì´ ì¦ê°€í• ìˆ˜ë¡ BIC ê°’ì´ ì¦ê°€í•  ê²ƒì´ë¼ê³  ì–¸ê¸‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ê°€ ì„ íƒí•œ ëª¨ë¸ì´ ì í•©í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ê·¸ë˜í”„ë¥¼ ë³´ê³  ìˆì„ ë•Œ, ìˆ˜í‰ ìœ¤ê³½ì„ ì€ BIC ê°’ì´ 0ì¸ ìŠ¤í…Œì´ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ê°€ ì„ íƒí•œ ëª¨ë¸ì´ ì™„ë²½í•˜ê²Œ ì í•©í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n\n%%R\ngoodmod <- GNARfit(vts = vswindts, net = vswindnet, alphaOrder = 2, betaOrder = c(5, 1))\ngoodmod\n\nModel: \nGNAR(2,[5,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1  dmatbeta1.2  dmatbeta1.3  dmatbeta1.4  dmatbeta1.5  \n    0.56911      0.10932      0.03680      0.02332      0.02937      0.04709  \n dmatalpha2  dmatbeta2.1  \n    0.23424     -0.04872"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#constructing-a-network-to-aid-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#constructing-a-network-to-aid-prediction",
    "title": "GNAR data",
    "section": "3.3. Constructing a network to aid prediction",
    "text": "3.3. Constructing a network to aid prediction\nWe propose a network construction method that uses prediction error, but note here that our scope is not to estimate an underlying network, but merely to find a structure that is useful in the task of prediction.\nwe use a prediction error measure, understood as the sum of squared differences between the observations and the estimates:\n\\[\\sum^N_{i=1} (X_{i,t} - \\hat{X}_{i,t})^2\\]\n\n%%R\nprediction <- predict(GNARfit(vts = fiveVTS[1:199,], net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1)))\nprediction\n\nTime Series:\nStart = 1 \nEnd = 1 \nFrequency = 1 \n    Series 1  Series 2  Series 3  Series 4   Series 5\n1 -0.6427718 0.2060671 0.2525534 0.1228404 -0.8231921"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#oecd-gdp-network-structure-aids-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#oecd-gdp-network-structure-aids-prediction",
    "title": "GNAR data",
    "section": "4. OECD GDP: Network structure aids prediction",
    "text": "4. OECD GDP: Network structure aids prediction\nGOP growth rate time series\n\n35 countries from the OECD website\ntime series : 1961 - 2013\nT = 52\nNodes = 35\nIn this data set 20.8% (379 out of 1820) of the observations were missing due to some nodes not being included from the start.\nwe do not uese covariate information, so C=1\n\n\n%%R\nlibrary(\"fields\")\nlayout(matrix(c(1, 2), nrow = 1, ncol = 2), widths = c(4.5, 1))\nimage(t(apply(gdpVTS, 1, rev)), xaxt = \"n\", yaxt = \"n\", col = gray.colors(14), xlab = \"Year\", ylab = \"Country\")\naxis(side = 1, at = seq(from = 0, to = 1, length = 52), labels = FALSE, col.ticks = \"grey\")\naxis(side = 1, at = seq(from = 0, to = 1, length = 52)[5*(1:11)], labels = (1:52)[5*(1:11)])\naxis(side = 2, at = seq(from = 1, to = 0, length = 35), labels = colnames(gdpVTS), las = 1, cex = 0.8)\nlayout(matrix(1))\nimage.plot(zlim = range(gdpVTS, na.rm = TRUE), legend.only = TRUE, col = gray.colors(14))\n\nR[write to console]: Loading required package: spam\n\nR[write to console]: Spam version 2.8-0 (2022-01-05) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\nR[write to console]: \nAttaching package: â€˜spamâ€™\n\n\nR[write to console]: The following objects are masked from â€˜package:baseâ€™:\n\n    backsolve, forwardsolve\n\n\nR[write to console]: Loading required package: viridis\n\nR[write to console]: Loading required package: viridisLite\n\nR[write to console]: \nTry help(fields) to get started.\n\n\n\n\n\n\nHeat plot(grey scale) of the differenced time series,\n\nwhite space indicates missing time series observations"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#finding-a-network-to-aid-prediction",
    "href": "posts/GCN/2023-01-05-GNAR.html#finding-a-network-to-aid-prediction",
    "title": "GNAR data",
    "section": "4.1. Finding a network to aid prediction",
    "text": "4.1. Finding a network to aid prediction\n\n%%R\nnet1 <- seedToNet(seed.no = seed.nos[1], nnodes = 35, graph.prob = 0.15)\nnet2 <- seedToNet(seed.no = seed.nos[2], nnodes = 35, graph.prob = 0.15)\n\n\n%%R\nlayout(matrix(c(2, 1), 1, 2))\npar(mar=c(0,1,0,1))\nplot(net1, vertex.label = colnames(gdpVTS), vertex.size = 0)\nplot(net2, vertex.label = colnames(gdpVTS), vertex.size = 0)\n\n\n\n\n\nErdos-Renyi random graphs xonstructed from the first two elements of the seed.nos variable with 35 nodes and connection probability 0.15.\nìê¸°íšŒê·€ ëª¨ë¸ì¸ GNAR ëª¨ë¸ì„ ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë•Œ, ì–´ë–¤ ë„¤íŠ¸ì›Œí¬ê°€ ê°€ì¥ ì í•©í•œì§€ ì¡°ì‚¬í•´ì•¼ í•¨.\nì´ë•Œ ê° ë…¸ë“œì˜ ìê¸° ìƒê´€ í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ì´ˆê¸° ë¶„ì„ ê²°ê³¼, 2ì°¨ ìê¸°íšŒê·€ êµ¬ì„± ìš”ì†Œê°€ ì¶©ë¶„í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ì–´ p = 2ê¹Œì§€ì˜ GNAR ëª¨ë¸ì„ ì‹œí—˜í•¨.\nê° ì‹œê°„ ì§€ì—°ì—ì„œ ìµœëŒ€ 2ê°œì˜ ì´ì›ƒ ì§‘í•©ì„ í¬í•¨í•¨.\nì´ì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì€ GNAR ëª¨ë¸ì´ ì‹œí—˜ë¨.\n\nGNAR(1, [0]), GNAR(1, [1]), GNAR(2, [0, 0]), GNAR(2, [1, 0]), GNAR(2, [1, 1]), GNAR(2, [2, 0]), GNAR(2, [2, 1]), ê·¸ë¦¬ê³  GNAR(2, [2, 2])ê°€ ì‹œí—˜ë˜ë©°, ê°ê° individual-\\(\\alpha\\)ì™€ global-\\(\\alpha\\) GNAR ëª¨ë¸ë¡œ ì í•©í•¨.\nì´ 16ê°œì˜ ëª¨ë¸ì´ ìƒì„±ë¨.\nì´ ì¤‘ì—ì„œ ì „ì²´ GDP ì˜ˆì¸¡ì— ì‚¬ìš©í•  GNAR ëª¨ë¸ì„ ì„ íƒí•  ê²ƒ.\nì—°ê²° í™•ë¥ ì´ 0.15ì¸ 10,000ê°œì˜ ì„ì˜ì˜ ì–‘ë°©í–¥ ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•˜ê³ , ìœ„ì—ì„œ ì–¸ê¸‰í•œ GNAR ëª¨ë¸ì„ ì´ìš©í•´ ì˜ˆì¸¡í•  ê²ƒ.\nê·¸ë˜ì„œ ì´ ì˜ˆì œëŠ” ìƒë‹¹í•œ ê³„ì‚° ì‹œê°„ì´ í•„ìš”(ë°ìŠ¤í¬íƒ‘ PCì—ì„œ ì•½ 90ë¶„).\nì´ë¥¼ ìœ„í•´ ì•„ë˜ ì½”ë“œì—ëŠ” ì¼ë¶€ ë¶„ì„ë§Œ í¬í•¨.\nê³„ì‚° ìƒì˜ ì´ìœ ë¡œ, ìš°ì„  ê° ë…¸ë“œì—ì„œ í‘œì¤€ í¸ì°¨ë¡œ ë‚˜ëˆ ì„œ ì”ì°¨ê°€ ê° ë…¸ë“œì—ì„œ ë™ì¼í•œ ë¶„ì‚°ì„ ê°€ì§€ê²Œ í•¨.\nseedSim í•¨ìˆ˜ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì›ë˜ ê°’ì˜ ì œê³± ì°¨ì´ì˜ í•©ì„ ì¶œë ¥í•˜ê³ , ì´ë¥¼ ì˜ˆì¸¡ ì •í™•ë„ì˜ ì¸¡ì • ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©\n\n\n\n%%R\ngdpVTSn <- apply(gdpVTS, 2, function(x){x / sd(x[1:50], na.rm = TRUE)})\nalphas <- c(rep(1, 2), rep(2, 6))\nbetas <- list(c(0), c(1), c(0, 0), c(1, 0), c(1, 1), c(2, 0), c(2, 1), c(2, 2))\nseedSim <- function(seedNo, modelNo, globalalpha){\n    net1 <- seedToNet(seed.no = seedNo, nnodes = 35, graph.prob = 0.15)\n    gdpPred <- predict(GNARfit(vts = gdpVTSn[1:50, ], net = net1,\n                               alphaOrder = alphas[modelNo], betaOrder = betas[[modelNo]],\n                               globalalpha = globalalpha))\n    return(sum((gdpPred - gdpVTSn[51, ])^2))\n    }\n\n\n%%R\nseedSim(seedNo = seed.nos[1], modelNo = 1, globalalpha = TRUE)\n\n[1] 23.36913\n\n\n\n%%R\nseedSim(seed.nos[1], modelNo = 3, globalalpha = TRUE)\n\n[1] 11.50739\n\n\n\n%%R\nseedSim(seed.nos[1], modelNo = 3, globalalpha = FALSE)\n\n[1] 18.96766\n\n\n\n\n\nimage.png\n\n\n\n10,000ê°œì˜ ì„ì˜ì˜ ë„¤íŠ¸ì›Œí¬ì™€ 16ê°œì˜ ëª¨ë¸ë¡œë¶€í„° ì‹œë®¬ë ˆì´ì…˜í•œ ì˜ˆì¸¡ ì˜¤ë¥˜ì˜ ë°•ìŠ¤ ê·¸ë˜í”„\n(ê³„ì‚° ì‹œê°„ì´ ê¸¸ì–´(90ë¶„) ì½”ë“œëŠ” ìƒëµ).\nì¼ë°˜ì ìœ¼ë¡œ global-Î± ëª¨ë¸ì€ ë” ë‚®ì€ ì˜ˆì¸¡ ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚´.\nê·¸ë˜ì„œ ì´ ë²„ì „ì˜ GNAR ëª¨ë¸ì„ ì‚¬ìš©í•  ê²ƒ.\nê·¸ë¦¼ 9ì—ì„œ ì²« ë²ˆì§¸ ëª¨ë¸ì¸ GNAR(1, [0])ê³¼ ì„¸ ë²ˆì§¸ ëª¨ë¸ì¸ GNAR(2, [0, 0])ì˜ ê²½ìš°, â€œë°•ìŠ¤ ê·¸ë˜í”„â€ëŠ” ì¸ì ‘í•œ ë§¤ê°œë³€ìˆ˜ê°€ ì í•©ë˜ì§€ ì•Šì•„ ê²°ê³¼ê°€ ì „ë¶€ ë™ì¼í•´ ì§§ì€ ìˆ˜í‰ì„ ìœ¼ë¡œ í‘œì‹œë¨.\në‹¤ë¥¸ global-Î± ëª¨ë¸ë“¤ì€ ì´ ì•ˆì— í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—, global-Î± GNAR(2, [2, 2])ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ìµœì†Œê°€ ë˜ëŠ” ì„ì˜ì˜ ê·¸ë˜í”„ë¥¼ ì„ íƒí•  ê²ƒ.\nì´ëŠ” seed.nos[921]ì—ì„œ ìƒì„±ëœ ë„¤íŠ¸ì›Œí¬ê°€ ì„ íƒë˜ê²Œ ë©ë‹ˆë‹¤.\n\n\n%%R\nnet921 <- seedToNet(seed.no = seed.nos[921], nnodes = 35, graph.prob = 0.15)\nlayout(matrix(c(1), 1, 1))\nplot(net921, vertex.label = colnames(gdpVTS), vertex.size = 0)\n\n\n\n\nRandomly generated un-weighted and un-directed graph over the OECD ountries that minimises the prediction error at t = 51 using GNAR(2, [2, 2]).\n\nseed.nos[921]ì—ì„œ ìƒì„±ëœ ë„¤íŠ¸ì›Œí¬\në„¤íŠ¸ì›Œí¬ì—ëŠ” ì „ë¶€ 2ê°œ ì´ìƒì˜ ì´ì›ƒì„ ê°€ì§€ê³  ìˆëŠ” countriesë“¤ì´ ìˆê³ , ì´ 97ê°œì˜ edgesì´ ìˆìŒ.\nì´ â€œ921â€ ë„¤íŠ¸ì›Œí¬ëŠ” GDP ì˜ˆì¸¡ì„ ìœ„í•´ ìƒì„±ë˜ì—ˆê¸° ë•Œë¬¸ì—, ì°¾ì€ ë„¤íŠ¸ì›Œí¬ì— ì¸ì‹ ê°€ëŠ¥í•œ êµ¬ì¡°ê°€ ìˆì§€ ì•Šì„ ê²ƒì´ë¼ê³  ì˜ˆìƒí•  ìˆ˜ ìˆìŒ\nê·¸ëŸ¬ë‚˜ ë¯¸êµ­, ë©•ì‹œì½”, ìºë‚˜ë‹¤ëŠ” ê°ê° 8ê°œ, 8ê°œ, 6ê°œì˜ edgeì„ ê°€ì§€ê³  ìˆì–´ ë§¤ìš° ì˜ ì—°ê²°ë˜ì–´ ìˆìŒ.\nìŠ¤ì›¨ë´ê³¼ ì¹ ë ˆë„ ì˜ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©°, ê°ê° 8ê°œì™€ 7ê°œì˜ edgeì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\nì˜ˆì¸¡ ì„±ëŠ¥ì´ ìœ ì‚¬í•œ ì ì€ ê°œìˆ˜ì˜ edgeë¥¼ ê°€ì§„ ë„¤íŠ¸ì›Œí¬ë¥¼ ì°¾ê¸° ìœ„í•´ í…ŒìŠ¤íŠ¸ ë  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì „ì²´ ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.\nì´ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ BICë¥¼ ì´ìš©í•´ ìµœì ì˜ GNAR ìˆœì„œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŒ.\n\n\n%%R\nres <- rep(NA, 8)\nfor(i in 1:8){\n    res[i] <- BIC(GNARfit(gdpVTSn[1:50, ],\n                          net = seedToNet(seed.nos[921], nnodes = 35, graph.prob = 0.15),\n                          alphaOrder = alphas[i], betaOrder = betas[[i]]))}\norder(res)\n\n[1] 6 3 4 7 8 5 1 2\n\n\n\n%%R\nsort(res)\n\n[1] -64.44811 -64.32155 -64.18751 -64.12683 -64.09656 -63.86919 -60.67858\n[8] -60.54207"
  },
  {
    "objectID": "posts/GCN/2023-01-05-GNAR.html#results-and-comparisons",
    "href": "posts/GCN/2023-01-05-GNAR.html#results-and-comparisons",
    "title": "GNAR data",
    "section": "4.2. Results and comparisons",
    "text": "4.2. Results and comparisons\n\nì´ì „ ì„¹ì…˜ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ t=52ì¼ ë•Œì˜ ê°’ì„ ì˜ˆì¸¡\nì´ ì˜ˆì¸¡ ì˜¤ë¥˜ë¥¼ í‘œì¤€ ARê³¼ VAR ëª¨ë¸ì„ ì‚¬ìš©í•´ ì°¾ì€ ì˜ˆì¸¡ ì˜¤ë¥˜ì™€ ë¹„êµ\nGNAR ì˜ˆì¸¡ì€ ì„ íƒëœ ë„¤íŠ¸ì›Œí¬(seed.nos[921]ì— í•´ë‹¹)ë¥¼ ê°€ì§„ GNAR(2, [2, 0]) ëª¨ë¸ì„ t=51ê¹Œì§€ì˜ ë°ì´í„°ì— ì í•©ì‹œí‚¤ê³ , t=52ì¼ ë•Œì˜ ê°’ì„ ì˜ˆì¸¡\nìš°ì„  seriesë¥¼ ì •ê·œí™”í•œ ë‹¤ìŒ, ëª¨ë¸ ì í•©ìœ¼ë¡œë¶€í„° SSEë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n\n\n%%R\ngdpVTSn2 <- apply(gdpVTS, 2, function(x){x / sd(x[1:51], na.rm = TRUE)})\ngdpFit <- GNARfit(gdpVTSn2[1:51,], net = net921, alphaOrder = 2, betaOrder = c(2, 0))\nsummary(gdpFit)\n\n\nCall:\nlm(formula = yvec2 ~ dmat2 + 0)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4806 -0.5491 -0.0121  0.5013  3.1208 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \ndmat2alpha1  -0.41693    0.03154 -13.221  < 2e-16 ***\ndmat2beta1.1 -0.12662    0.05464  -2.317   0.0206 *  \ndmat2beta1.2  0.28044    0.06233   4.500  7.4e-06 ***\ndmat2alpha2  -0.33282    0.02548 -13.064  < 2e-16 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 0.8926 on 1332 degrees of freedom\n  (23 observations deleted due to missingness)\nMultiple R-squared:  0.1859,    Adjusted R-squared:  0.1834 \nF-statistic: 76.02 on 4 and 1332 DF,  p-value: < 2.2e-16\n\nGNAR BIC: -62.86003\n\n\n\n%%R\nsum((predict(gdpFit) - gdpVTSn2[52, ])^2)\n\n[1] 5.737203\n\n\nì´ GNAR ëª¨ë¸ì˜ ì í•©ëœ ë§¤ê°œë³€ìˆ˜ëŠ” \\(\\alpha^1 = - 0.42, \\beta^1,1 = - 0.13, \\beta^1,2 = 0.28\\), ê·¸ë¦¬ê³  \\(\\alpha^2 = - 0.33\\)ì…ë‹ˆë‹¤.\n\n\n\nModel\nparameters\nprediction error\n\n\n\n\nGNAR(2,[2,0])\n4\n5.7\n\n\nIndividual AR(2)\n38\n8.1\n\n\nVAR(1)\n199\n26.2\n\n\n\nEstimated prediction error of differenced real GDP change at t = 52 for all 35 countries.\nìš°ë¦¬ì˜ ë°©ë²•ê³¼ CRAN forecast íŒ¨í‚¤ì§€ì˜ ë²„ì „ 8.0ì—ì„œì˜ forecast.ar()ê³¼ auto.arima() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ê° ë…¸ë“œë³„ë¡œ AR ëª¨ë¸ì„ ì í•©í•œ ê²°ê³¼ë¥¼ ë¹„êµ\n\nì„¹ì…˜ 4.1ì˜ ìê¸°ìƒê´€ ë¶„ì„ì„ ê³ ë ¤í•´ ê°ê° 35ê°œì˜ ê°œë³„ ëª¨ë¸ì˜ ìµœëŒ€ AR ìˆœì„œë¥¼ p=2ë¡œ ì„¤ì •\n\n\n%%R\nlibrary(\"forecast\")\narforecast <- apply(gdpVTSn2[1:51, ], 2, function(x){\n            forecast(auto.arima(x[!is.na(x)], d= ,D=0,max.p = 2,max.q=0,\n                                max.P=0,max.Q = 0,stationary = TRUE, seasonal = FALSE), ic = \"bic\",\n                     allowmean = FALSE, allowdraft = FALSE, trace = FALSE, h=1)$mean\n})\nsum((arforecast - gdpVTSn2[52, ])^2)\n\nR[write to console]: Registered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\n\n[1] 7.8974\n\n\nWe fit the model using the VAR function and then use the restrict function to reduce dimensionality further, by setting to zero any coefficient whose associated absolute t-statistic value is less than two.\n\n%%R\nlibrary(\"vars\")\ngdpVTSn2.0 <- gdpVTSn2\ngdpVTSn2.0[is.na(gdpVTSn2.0)] <- 0\nvarforecast <- predict(restrict(VAR(gdpVTSn2.0[1:51, ], p = 1, type = \"none\")), n.ahead = 1)\n\ncompute the prediction error\n\n%%R\ngetfcst <- function(x){return(x[1])}\nvarforecastpt <- unlist(lapply(varforecast$fcst, getfcst))\nsum((varforecastpt - gdpVTSn2.0[52, ])^2)\n\n[1] 26.19805\n\n\nGNAR ëª¨ë¸ì€ ARê³¼ VAR ê²°ê³¼ë³´ë‹¤ ì ì€ ì˜ˆì¸¡ ì˜¤ë¥˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ARê³¼ ë¹„êµí–ˆì„ ë•Œ 29%ê°€ ì¤„ì–´ë“¤ê³ , VARê³¼ ë¹„êµí–ˆì„ ë•Œ 78%ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤.\nìœ„ ì ˆì°¨ë¥¼ ë°˜ë³µí•´ 2ë‹¨ê³„ ì•ìœ¼ë¡œì˜ ì˜ˆì¸¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\nì´ ê²½ìš° ë‹¤ë¥¸ ë„¤íŠ¸ì›Œí¬ê°€ GNAR(2,[2,2]) ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.\nê·¸ëŸ¬ë‚˜ BIC ë‹¨ê³„ì—ì„œ GNAR(2,[0,0]) ëª¨ë¸ì´ ìµœì ìœ¼ë¡œ ì í•©ëœ ê²ƒì„ ì‹ë³„í•˜ì˜€ê³ , ì´ëŠ” ë„¤íŠ¸ì›Œí¬ íšŒê·€ ë§¤ê°œë³€ìˆ˜ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n\n%%R\nlibrary(\"vars\")\ngdpVTSn2.0 <- gdpVTSn2\ngdpVTSn2.0[is.na(gdpVTSn2.0)] <- 0\nvarforecast <- predict(restrict(VAR(gdpVTSn2.0[1:51, ], p = 1, type = \"none\")), n.ahead = 40)"
  },
  {
    "objectID": "posts/GCN/2023-05-06-article_refer.html",
    "href": "posts/GCN/2023-05-06-article_refer.html",
    "title": "ITSTGCN Article Refernece",
    "section": "",
    "text": "summerizing it\n\n\n\n\n\n\n\nNote\n\n\n\n\nê¸€ì´ ì§„í–‰ë˜ëŠ” ìˆœì„œë¡œ ì‘ì„±í•¨.\n\n\n\n\nIntroduction\nlittle1989analysis\n\nThe analysis of social science data with missing values\n\nLittle, Roderick JA and Rubin, Donald B\n\n\nìœ„ ë…¼ë¬¸ì€ êµ¬í•˜ì§€ ëª»í–ˆê³ , ì•„ë˜ ë…¼ë¬¸ì—ì„œ refer ê±´ ê²ƒ ë³´ê³  ì‘ì„±\nEvaluating the Influence of Missing Data on Classification Algorithms in Data Mining Applications by Luciano C. Blomberg\në‚´ìš©\n\nFurthermore, distribution of missing data is another aspect that may influence the effectiveness of classification algorithms. Litle and Rubin [1987] presented three different mechanisms by which the missing data are distributed:\n\nli2018missing\n\nMissing value imputation for traffic-related time series data based on a multi-view learning method\n\nLi, Linchao and Zhang, Jian and Wang, Yonggang and Ran, Bin\n\n\në‚´ìš©\n\nIn this circumstance, the difficulty of imputation is increased as we may not be able to find stable inputs for a model.\n\nSpatiotemporal Data\natluri2018spatio\n\nSpatio-temporal data mining: A survey of problems and methods\n\nAtluri, Gowtham and Karpatne, Anuj and Kumar, Vipin\n\n\në‚´ìš©\n\n3.2. Data type ë‚´ìš©\n\nwang2020deep\n\nDeep learning for spatio-temporal data mining: A survey\n\nWang, Senzhang and Cao, Jiannong and Yu, Philip\n\n\në‚´ìš©\n\n2.1. Spatio-Temporal Data Types í•­ëª© ë‚´ìš©ì—ì„œ STData ì¢…ë¥˜\n\nyu2017spatio\n\nSpatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting\n\nYu, Bing and Yin, Haoteng and Zhu, Zhanxing\n\n\në‚´ìš©\n\nThe linear interpolation method is used to fill missing values after data cleaning.\n\nguo2019attention\n\nAttention based spatial-temporal graph convolutional networks for traffic flow forecasting\n\nGuo, Shengnan and Lin, Youfang and Feng, Ning and Song, Chao and Wan, Huaiyu\n\n\në‚´ìš©\n\nThe missing values are filled by the linear interpolation.\n\nbai2020adaptive\n\nAdaptive graph convolutional recurrent network for traffic forecasting\n\nBai, Lei and Yao, Lina and Li, Can and Wang, Xianzhi and Wang, Can\n\n\në‚´ìš©\n\nThe missing values in the datasets are filled by linear interpolation.\n\nli2019predicting\n\nPredicting path failure in time-evolving graphs\n\nLi, Jia and Han, Zhichao and Cheng, Hong and Su, Jiao and Wang, Pengyun and Zhang, Jianfeng and Pan, Lujia\n\n\në‚´ìš©\n\nWe replace missing values with 0, and normalize the features to the range\n\nzhao2019t\n\nT-GCN: A Temporal Graph Convol- utional Network for Traffic Prediction\n\nZhao, Ling and Song, Yujiao and Zhang, Chao and Liu, Yu and Wang, Pu and Lin, Tao and Deng, Min and Li, Haifeng\n\n\në‚´ìš©\n\nwe used the linear interpolation method to fill missing values.\n\nbaraldi2010introduction\n\nAn introduction to modern missing data analyses\n\nBaraldi, Amanda N and Enders, Craig K\n\n\në‚´ìš©\n\nAn overview of traditional missing data techniques í•­ëª©\n\nshi2022air\n\nAir Quality Prediction Model Based on Spatio-temporal Graph Convolution Neural Networks\n\nShi, Weidi and Song, Anjun\n\n\në‚´ìš©\n\nDue to weather reasons and corrosion or damage of some sensors, some data were lost and abnormal. Therefore, the data needs to be cleaned. We used the average imputation method to fill some lost data and deleted the data which lost too many values.\n\nbatista2003analysis\n\nAn analysis of four missing data treatment methods for supervised learning\n\nBatista, Gustavo EAPA and Monard, Maria Carolina\n\n\në‚´ìš©\n\nIMPUTATION METHODS\nImputation methods involve replacing missing values with estimated ones based on information available in the data set. There are many options varying from naive methods, such as mean imputation, to some more robust methods based on relationships among attributes. A description of some widely used imputation methods follows:\n\nblomberg2013evaluating\n\nEvaluating the performance of regression algorithms on datasets with missing data\n\nBlomberg, Luciano Costa and Hemerich, Daiane and Ruiz, Duncan Dubugras Alcoba\n\n\në‚´ìš©\n\nfor example, replaces the missing values with means or modes.\n\ndonders2006gentle\n\nReview: A gentle introduction to imputation of missing values\n\nDonders, A Rogier T and Van Der Heijden, Geert JMG and Stijnen, Theo and Moons, Karel GM\n\n\në‚´ìš©\n\nthe indicator method and overall mean imputation, give biased results.\nThe mean of the standard errors is a measure for the uncertainty in the estimated associations caused by sampling the study subjects from a source popu- lation. Additionally, the standard deviation of the multiple estimated associations (e.g., regression coefficients) reflects the differences between the imputed data sets, i.e., the un- certainty in the estimated underlying distributions of the variables with missing values.\n\nbaraldi2010introduction\n\nAn introduction to modern missing data analyses\n\nBaraldi, Amanda N and Enders, Craig K\n\n\në‚´ìš©\n\nTo illustrate the bias that can result from the use of traditional missing data methods, we use the artificial math performance data set found in Table 1.\n\n\n\nProposed Methods\nSelf-Consistent Estimator"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html",
    "title": "Class of Method(GNAR) lag 1",
    "section": "",
    "text": "GNAR fiveNet,fivenodes"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "title": "Class of Method(GNAR) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)",
    "text": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)\nì‹œë‚˜ë¦¬ì˜¤1\n\nmissing rate: 0%\në³´ê°„ë°©ë²•: None\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.43it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\nlibrary(tidyverse)\n\n\n%R -i fiveVTS_train\n\n\n%%R\nanswer <- GNARfit(vts = fiveVTS_train, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean(axis=0)\ntest_mse_total_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.9994323113693153, 1.2692101967317866)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(1,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),gnar_train.reshape(-1,5)[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(161,201),gnar_test.reshape(-1,5)[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "title": "Class of Method(GNAR) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤2",
    "text": "ì‹œë‚˜ë¦¬ì˜¤2\nì‹œë‚˜ë¦¬ì˜¤2\n\nmissing rate: 50%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:35<00:00,  1.41it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:37<00:00,  1.33it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7473098322871093, 1.3231643342748722)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(161,201),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "title": "Class of Method(GNAR) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤3",
    "text": "ì‹œë‚˜ë¦¬ì˜¤3\nì‹œë‚˜ë¦¬ì˜¤3\n\nmissing rate: 80%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:35<00:00,  1.39it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:37<00:00,  1.33it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.38358787816283946, 1.3239931193379793)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(161,201),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "href": "posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "title": "Class of Method(GNAR) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤4",
    "text": "ì‹œë‚˜ë¦¬ì˜¤4\nì‹œë‚˜ë¦¬ì˜¤4\n\nmissing rate: 30%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.79it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(X).squeeze()\nX_test1 =  np.array(XX).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test[1:,:])**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test[1:,:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7978462123549198, 1.3146463350699074)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(160,199),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(161,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,159),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(160,200),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-07-08-toy_example_using_gnar.html",
    "href": "posts/GCN/2023-07-08-toy_example_using_gnar.html",
    "title": "Toy example using GNAR",
    "section": "",
    "text": "Import\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nimport torch\nimport itstgcn\nimport random\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\n\nGNAR Data copy\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\n\nedge(list)\ndist(list)\n\n\n%%R\nplot(fiveNet, vertex.label = c(\"A\", \"B\", \"C\", \"D\", \"E\"))\n\n\n\n\n\n%%R\nas.matrix(fiveNet)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\\[X_{i,t} = \\sum^p_{j=1}\\big( \\alpha_{i,j} X_{i,t-j} + \\sum^C_{c=1} \\sum^{s_j}_{r=1} \\beta_{j,r,c} \\sum_{1 \\in \\cal{N}^{(r)}_t (i)} \\omega^{(t)}_{i,q,c} X_{q,t-j} \\big) + u_{i,t}\\]\n\n\\(p \\in \\mathbb{N}\\) is the maximum time lag\n\\([s] = (s_1, \\dots , s_p)\\) and \\(s_j \\in \\mathbb{N}_0\\) is the maximum stage of neighbor dependence for time lag \\(j\\), with \\(\\mathbb{N}_0 = \\mathbb{N} \\cup \\{ 0\\}\\)\n\\(\\cal{N}^{(r)}_t (i)\\) is the \\(r\\)th stage neighbour set of node \\(i\\) at time \\(t\\)\n\\(\\omega^{(t)}_{i,q,c} \\in [0,1]\\) is the connection weight between node \\(i\\) and node \\(q\\) at time \\(t\\) if the path corresponds to covariate \\(c\\)\n\n\\[X_{A,t} = 0.206 X_{A,tâˆ’1}+0.503 (X_{E,tâˆ’1}+X_{D,tâˆ’1})/2+0.021 X_{A,tâˆ’2}âˆ’0.095(X_{E,tâˆ’2}+X_{D,tâˆ’2})/2+u_{A,t}\\]\n\\[X_{B,t} = 0.206 X_{B,tâˆ’1}+0.503 (X_{C,tâˆ’1}+X_{D,tâˆ’1})/2+0.021 X_{B,tâˆ’2}âˆ’0.095(X_{C,tâˆ’2}+X_{D,tâˆ’2})/2+u_{B,t}\\]\n\\[X_{C,t} = 0.206 X_{C,tâˆ’1}+0.503 (X_{B,tâˆ’1}+X_{D,tâˆ’1})/2+0.021 X_{C,tâˆ’2}âˆ’0.095(X_{B,tâˆ’2}+X_{D,tâˆ’2})/2+u_{C,t}\\]\n\\[X_{D,t} = 0.206 X_{D,tâˆ’1}+0.503 (X_{A,tâˆ’1}+X_{B,tâˆ’1}+X_{C,tâˆ’1})/3+0.021 X_{D,tâˆ’2}âˆ’0.095(X_{A,tâˆ’1}+X_{B,tâˆ’1}+X_{C,tâˆ’1})/3+u_{D,t}\\]\n\\[X_{E,t} = 0.206 X_{E,tâˆ’1}+0.503 (X_{A,tâˆ’1})+0.021 X_{E,tâˆ’2}âˆ’0.095(X_{A,tâˆ’1})+u_{E,t}\\]\n\nfrom statsmodels.tsa.arima.model import ARIMA\n\nhttps://communities.sas.com/t5/SAS-Tech-Tip/SAS-%ED%99%9C%EC%9A%A9-%EB%85%B8%ED%95%98%EC%9A%B0-%EC%8B%9C%EA%B3%84%EC%97%B4-AR-1-%EA%B3%BC-AR-2/ta-p/792106\n\na_ylag1 = np.random.normal(size=1)\na_ylag2 = np.random.normal(size=1)\n\n\nb_ylag1 = np.random.normal(size=1)\nb_ylag2 = np.random.normal(size=1)\n\n\n# alpha1 = 0.15\nalpha1 = 0.4\nalpha2 = 0.2\n# alpha2 = 0.01\n# beta1 = 0.503\nbeta1 = 0.01\nbeta2 = - 0.1\na_ar_values = []\na_ar_values_true = []\nb_ar_values = []\nb_ar_values_true = []\n\n\nfor i in range(500):\n    a_e = np.random.normal(size=1) * 0.2\n    b_e = np.random.normal(size=1)  * 0.2\n    \n    # a_y = alpha1 * a_ylag1 + alpha2 * a_ylag2 + a_e + beta1 * (e_ylag1 + d_ylag1) / 2 + beta2 * (e_ylag2 + d_ylag2) / 2\n    # b_y = alpha1 * b_ylag1 + alpha2 * b_ylag2 + b_e + beta1 * (c_ylag1 + d_ylag1) / 2 + beta2 * (c_ylag2 + d_ylag2) / 2\n    # c_y = alpha1 * c_ylag1 + alpha2 * c_ylag2 + c_e + beta1 * (b_ylag1 + d_ylag1) / 2 + beta2 * (b_ylag2 + d_ylag2) / 2\n    # d_y = alpha1 * d_ylag1 + alpha2 * d_ylag2 + d_e + beta1 * (a_ylag1 + b_ylag1 + c_ylag1) / 3 + beta2 * (a_ylag2 + b_ylag2 + c_ylag2) / 3\n    # e_y = alpha1 * e_ylag1 + alpha2 * e_ylag2 + e_e + beta1 * a_ylag1 + beta2 * a_ylag2\n    a_y_true = alpha1 * a_ylag1 + alpha2 * a_ylag2 + beta1 * (b_ylag1) + beta2 * (a_ylag2)\n    a_y = a_y_true + a_e\n    b_y_true = alpha1 * b_ylag1 + alpha2 * b_ylag2 + beta1 * (a_ylag1) + beta2 * (b_ylag2)\n    b_y = b_y_true + b_e\n    \n    a_ar_values_true.append(a_y_true[0])\n    a_ar_values.append(a_y[0])\n    b_ar_values_true.append(b_y_true[0])\n    b_ar_values.append(b_y[0])\n    \n    a_ylag2 = a_ylag1\n    b_ylag2 = b_ylag1\n    \n    a_ylag1 = a_y\n    b_ylag1 = b_y\n\n\nnp.sum(a_ar_values)\n\n0.6513402621576372\n\n\n\nnp.sum(b_ar_values)\n\n11.796436691361254\n\n\n\nplt.plot(a_ar_values_true)\n\n\n\n\n\nplt.plot(a_ar_values)\n\n\n\n\n\nplt.plot(b_ar_values_true)\n\n\n\n\n\nplt.plot(b_ar_values)\n\n\n\n\n\ndf = {'A' : a_ar_values, 'B' : b_ar_values}\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_edges = torch.tensor([[0,1],[1,0]]).tolist()\n\n\n_FX1 = np.stack([a_ar_values,b_ar_values],axis=1).tolist()\n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX1}\n\n\nsave_data(data_dict,'toy_ex_dataset.pkl')\n\n\n\nRandom\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_rand = itstgcn.rand_mindex(train_dataset,mrate=0.7)\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\ntrain_dataset_miss_rand = itstgcn.miss(train_dataset,mindex_rand,mtype='rand')\n\n\ntrain_dataset_padded_rand = itstgcn.padding(train_dataset_miss_rand) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr_rand = itstgcn.StgcnLearner(train_dataset_padded_rand)\n\n\nlrnr_rand.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_rand_it = itstgcn.ITStgcnLearner(train_dataset_padded_rand)\n\n\nlrnr_rand_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor_rand = itstgcn.Evaluator(lrnr_rand,train_dataset_padded_rand,test_dataset)\n\n\nfig = evtor_rand.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rand_it = itstgcn.Evaluator(lrnr_rand_it,train_dataset_padded_rand,test_dataset)\n\n\nfig = evtor_rand_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rand.mse\n\n{'train': {'each_node': [0.014082524925470352, 0.015163550153374672],\n  'total': 0.014623038470745087},\n 'test': {'each_node': [0.07657670229673386, 0.06272050738334656],\n  'total': 0.0696486085653305},\n 'test(base)': {'each_node': [0.05262065306305885, 0.05082978680729866],\n  'total': 0.05172521993517876}}\n\n\n\nevtor_rand_it.mse\n\n{'train': {'each_node': [0.013057202100753784, 0.014180357567965984],\n  'total': 0.013618779368698597},\n 'test': {'each_node': [0.06001878157258034, 0.04732104390859604],\n  'total': 0.05366990715265274},\n 'test(base)': {'each_node': [0.05262065306305885, 0.05082978680729866],\n  'total': 0.05172521993517876}}\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_rand.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:400,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rand.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rand_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rand.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rand_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rand.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rand_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rand.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rand_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\n\nBlock\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_block = [list(range(80,180)),list(range(100,190))]\n\n\ntrain_dataset_miss_block = itstgcn.miss(train_dataset,mindex_block,mtype='block')\n\n\ntrain_dataset_padded_block = itstgcn.padding(train_dataset_miss_block) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr_block = itstgcn.StgcnLearner(train_dataset_padded_block)\n\n\nlrnr_block.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_block_it = itstgcn.ITStgcnLearner(train_dataset_padded_block)\n\n\nlrnr_block_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor_block = itstgcn.Evaluator(lrnr_block,train_dataset_padded_block,test_dataset)\n\n\nfig = evtor_block.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_block_it = itstgcn.Evaluator(lrnr_block_it,train_dataset_padded_block,test_dataset)\n\n\nfig = evtor_block_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_block.mse\n\n\nevtor_block_it.mse\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_block.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_block.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_block.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_block_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_block.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_block_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='TrGround Truthue')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_block.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_block.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_block.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_block_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_block.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_block_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\n\n\n\n\nRandom & Block\n\ndata_dict = load_data('toy_ex_dataset.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\ndataset = loader.get_dataset(lags=2)\n\n\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex_rdbl = [random.sample(range(0, 400), int(400*0.7)),[np.array(list(range(150,220)))]]\n\n\ntrain_dataset_miss_rdbl = itstgcn.miss(train_dataset,mindex_rdbl,mtype='block')\n\n\ntrain_dataset_padded_rdbl = itstgcn.padding(train_dataset_miss_rdbl) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr_rdbl = itstgcn.StgcnLearner(train_dataset_padded_rdbl)\n\n\nlrnr_rdbl.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nlrnr_rdbl_it = itstgcn.ITStgcnLearner(train_dataset_padded_rdbl)\n\n\nlrnr_rdbl_it.learn(filters=12,epoch=5)\n\n5/5\n\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor_rdbl = itstgcn.Evaluator(lrnr_rdbl,train_dataset_padded_rdbl,test_dataset)\n\n\nfig = evtor_rdbl.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\n\n\n\nevtor_rdbl_it = itstgcn.Evaluator(lrnr_rdbl_it,train_dataset_padded_rdbl,test_dataset)\n\n\nfig = evtor_rdbl_it.plot('--.',h=5,max_node=2,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(20)\nfig.set_figheight(10)\nfig.tight_layout()\nfig\n\n\nevtor_rdbl.mse\n\n\nevtor_rdbl_it.mse\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5,ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(a_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,0],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_miss_rdbl.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,0,0],torch.tensor(train_dataset_padded_rdbl.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:399,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(a_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rdbl.fhat_tr[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rdbl_it.fhat_tr[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[400:,0],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(a_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rdbl.fhat_test[:,0],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rdbl_it.fhat_test[:,0],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2,figsize=(40,20))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    \n    ax1.plot(b_ar_values_true,label='Ground Truth')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    \n    ax2.plot(np.array(data_dict['FX'])[:,1],'-',color='C3',label='Complete Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(np.array(data_dict['FX'])[:,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_miss_rand.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(np.array(data_dict['FX'])[:,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(torch.cat([torch.tensor(dataset.features)[:2,1,0],torch.tensor(train_dataset_padded_rdbl.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',alpha=0.8,label='Linear Interpolation')\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n    \n    ax5.plot(torch.tensor(data_dict['FX'])[:400,1],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax5.plot(b_ar_values_true[:400],color='black',label='Ground Truth',lw=3)\n    ax5.plot(evtor_rdbl.fhat_tr[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax5.plot(evtor_rdbl_it.fhat_tr[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    # ax5.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax5.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax5.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax5.tick_params(axis='y', labelsize=20)\n    ax5.tick_params(axis='x', labelsize=20)\n    \n    ax6.plot(torch.tensor(data_dict['FX'])[399:,1],'--',color='C5',alpha=0.5,label='Test')\n    ax6.plot(b_ar_values_true[400:],color='black',label='Ground Truth',lw=3)\n    ax6.plot(evtor_rdbl.fhat_test[:,1],color='brown',lw=3,label='GConvGRU',alpha=0.5)\n    ax6.plot(evtor_rdbl_it.fhat_test[:,1],color='blue',lw=3,label='IT-TGNN',alpha=0.5)\n    ax6.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax6.tick_params(axis='y', labelsize=20)\n    ax6.tick_params(axis='x', labelsize=20)\n# # plt.savefig('try2_node1.png')"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "",
    "text": "Try to divide train and test(GNAR fivenet)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nmean_f_fiveVTS_train = torch.tensor(fiveVTS_train_mean).reshape(160,5,1).float()\n\n\nmean_X_fiveVTS = mean_f_fiveVTS_train[:159,:,:]\nmean_y_fiveVTS = mean_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.84it/s]\n\n\n\nmean_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nxt_test = torch.tensor(fiveVTS_test.reshape(40,5,1)[:-1,:,:]).float()\n\n\nmean_fhat_fiveVTS_forecast = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_fiveVTS_forecast);\n\n\n\n\n\nvis2(fiveVTS_train_mean,mean_fhat_fiveVTS);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n# np.fft(mean_fhat_fiveVTS[:,0,0])\n\n\n# mean_fhat_fiveVTS.shape\n\n\n# fft_result =np.stack([np.fft.fft(mean_fhat_fiveVTS[:,n,0]) for n in range(N)]).T\n\n\n# plt.plot(abs(fft_result[:,0])**2)\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_fiveVTS.reshape(159*N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n\nvis2(mean_fhat_fiveVTS,fhatbarhat_mean_spatio_temporal.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.88it/s]\n\n\n\nmean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal,mean_fhat_spatio_temporal);\n\n\n\n\n\n\nfor i in tqdm(range(50)):\n    ## GFT \n    fhatbar = Psi.T @ mean_fhat_fiveVTS.reshape(159*N,1)\n\n    ## Ebayes\n    ebayesthresh = importr('EbayesThresh').ebayesthresh\n    fhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n    #plt.plot(fhatbar)\n    #plt.plot(fhatbar_threshed)\n\n    ## inverse GFT \n    fhatbarhat = Psi @ fhatbar_threshed\n    fhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n    #vis2(mean_fhat_fiveVTS,fhatbarhat_mean_spatio_temporal.reshape(159,5));\n\n    ## STGCN \n    fiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\n    fiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number1,1,0]\n    fiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number1,2,0]\n    fiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number1,3,0]\n    fiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number1,4,0]\n    #vis(fiveVTS_train_mean);\n\n    #model = RecurrentGCN(node_features=1, filters=4)\n\n    #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n    #model.train()\n    for epoch in range(1):\n        for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n            y_hat = model(xt, edge_index, edge_attr)\n            cost = torch.mean((y_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    mean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n    mean_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n    #vis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test);\n    #vis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:55<00:00,  1.10s/it]\n\n\n\nvis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);\n\n\n\n\n\nvis2(fiveVTS_train_backup,mean_fhat_spatio_temporal);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_spatio_temporal.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\n\n\n\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-1",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal2 = fhatbarhat.reshape(159,N,1)\n\n\nvis2(mean_fhat_spatio_temporal,fhatbarhat_mean_spatio_temporal2.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.84it/s]\n\n\n\nmean_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test2 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test2);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal2,mean_fhat_spatio_temporal2);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "10) Fourier transform",
    "text": "10) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_spatio_temporal.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "11) Ebayes",
    "text": "11) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-2",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "12) Inverse Fourier transform",
    "text": "12) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal3 = fhatbarhat.reshape(159,N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "13) ST-GCN",
    "text": "13) ST-GCN\n\nfiveVTS_train_mean[seed_number1,0] = fhatbarhat_mean_spatio_temporal[seed_number1,0,0]\nfiveVTS_train_mean[seed_number2,1] = fhatbarhat_mean_spatio_temporal[seed_number2,1,0]\nfiveVTS_train_mean[seed_number3,2] = fhatbarhat_mean_spatio_temporal[seed_number3,2,0]\nfiveVTS_train_mean[seed_number4,3] = fhatbarhat_mean_spatio_temporal[seed_number4,3,0]\nfiveVTS_train_mean[seed_number5,4] = fhatbarhat_mean_spatio_temporal[seed_number5,4,0]\nvis(fiveVTS_train_mean);\n\n\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s]\n\n\n\nmean_fhat_spatio_temporal3 = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nmean_fhat_spatio_temporal_test3 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_spatio_temporal_test3);\n\n\n\n\n\nvis2(fhatbarhat_mean_spatio_temporal3,mean_fhat_spatio_temporal3);\n\n\n\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\nfour = []\nfor i in range(N):\n    four.append(np.mean((fiveVTS_test[1:,i] - mean_fhat_spatio_temporal_test3.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three,'four':four})\n\n\n\n\n\n  \n    \n      \n      one\n      two\n      three\n      four\n    \n  \n  \n    \n      0\n      -0.196310\n      -0.189000\n      -0.173563\n      -0.200559\n    \n    \n      1\n      -0.161632\n      -0.135003\n      -0.142250\n      -0.159892\n    \n    \n      2\n      0.079347\n      0.106893\n      0.108179\n      0.079011\n    \n    \n      3\n      -0.267653\n      -0.244438\n      -0.248220\n      -0.269292\n    \n    \n      4\n      -0.162464\n      -0.135709\n      -0.130221\n      -0.167336"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nlinear_f_fiveVTS_train = torch.tensor(linear_fiveVTS_train).reshape(160,5,1).float()\n\n\nlinear_X_fiveVTS = linear_f_fiveVTS_train[:159,:,:]\nlinear_y_fiveVTS = linear_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_fiveVTS,linear_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_fiveVTS]).detach().numpy()\n\n\nxt_test = torch.tensor(fiveVTS_test.reshape(40,5,1)[:-1,:,:]).float()\n\n\nlinear_fhat_fiveVTS_forecast = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_fiveVTS_forecast);\n\n\nvis2(linear_fiveVTS_train,linear_f_fiveVTS_train);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_fiveVTS.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nplt.plot(fhatbar.reshape(159,5)[:,0]**2)\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-3",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n\nvis2(linear_fhat_fiveVTS,fhatbarhat_linear_spatio_temporal.reshape(159,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nlinear_spatio_temporal = torch.tensor(fhatbarhat_linear_spatio_temporal).reshape(159,5,1).float()\n\n\nlinear_X_spatio_temporal = linear_spatio_temporal[:158,:,:]\nlinear_y_spatio_temporal = linear_spatio_temporal[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal,linear_y_spatio_temporal)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test);\n\n\nvis2(fhatbarhat_linear_spatio_temporal,linear_fhat_spatio_temporal);"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nw=np.zeros((158*N,158*N))\n\n\nfor i in range(158*N):\n    for j in range(158*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_spatio_temporal.reshape(158*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-4",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal2 = fhatbarhat.reshape(158,N,1)\n\n\nvis2(linear_fhat_spatio_temporal,fhatbarhat_linear_spatio_temporal2.reshape(158,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-6",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-6",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nlinear_spatio_temporal2 = torch.tensor(fhatbarhat_linear_spatio_temporal2).reshape(158,5,1).float()\n\n\nlinear_X_spatio_temporal2 = linear_spatio_temporal2[:157,:,:]\nlinear_y_spatio_temporal2 = linear_spatio_temporal2[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal2,linear_y_spatio_temporal2)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal2]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test2 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test2);\n\n\nvis2(fhatbarhat_linear_spatio_temporal2,linear_fhat_spatio_temporal2);\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three})"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#fourier-transform-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "10) Fourier transform",
    "text": "10) Fourier transform\n\nw=np.zeros((157*N,157*N))\n\n\nfor i in range(157*N):\n    for j in range(157*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ linear_fhat_spatio_temporal2.reshape(157*N,1)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#ebayes-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "11) Ebayes",
    "text": "11) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-5",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#inverse-fourier-transform-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "12) Inverse Fourier transform",
    "text": "12) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal3 = fhatbarhat.reshape(157,N,1)\n\n\nvis2(linear_fhat_spatio_temporal2,fhatbarhat_linear_spatio_temporal3.reshape(157,5));"
  },
  {
    "objectID": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-7",
    "href": "posts/GCN/2023-01-20-Algorithm_traintest.html#st-gcn-7",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "13) ST-GCN",
    "text": "13) ST-GCN\n\nlinear_spatio_temporal3 = torch.tensor(fhatbarhat_linear_spatio_temporal3).reshape(157,5,1).float()\n\n\nlinear_X_spatio_temporal3 = linear_spatio_temporal3[:156,:,:]\nlinear_y_spatio_temporal3 = linear_spatio_temporal3[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal3,linear_y_spatio_temporal3)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_spatio_temporal3 = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal3]).detach().numpy()\n\n\nlinear_fhat_spatio_temporal_test3 = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],linear_fhat_spatio_temporal_test3);\n\n\nvis2(fhatbarhat_linear_spatio_temporal3,linear_fhat_spatio_temporal3);\n\n\none = []\nfor i in range(N):\n    one.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_fiveVTS_forecast.reshape(39,5)[:,i])))\n\n\ntwo = []\nfor i in range(N):\n    two.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test.reshape(39,5)[:,i])))\n\n\nthree = []\nfor i in range(N):\n    three.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test2.reshape(39,5)[:,i])))\n\n\nfour = []\nfor i in range(N):\n    four.append(np.mean((fiveVTS_test[1:,i] - linear_fhat_spatio_temporal_test3.reshape(39,5)[:,i])))\n\n\npd.DataFrame({'one':one,'two':two,'three':three,'four':four})"
  },
  {
    "objectID": "posts/GCN/2023-03-17-ITSTGCN-Tutorial.html",
    "href": "posts/GCN/2023-03-17-ITSTGCN-Tutorial.html",
    "title": "ITSTGCN-Tutorial",
    "section": "",
    "text": "edit\n\n\nimport\n\nimport itstgcn \nimport torch\n\n\n\nì˜ˆì œ1: vanilla STGCN\n- ë°ì´í„°\n\ndata_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.StgcnLearner(train_dataset,dataset_name='five_nodes')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/learners.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset) \n#lrnr(test_dataset)\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) \nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ2: padding missing values\n- ë°ì´í„°\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- ì„ì˜ë¡œ ê²°ì¸¡ì¹˜ ë°œìƒ\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex=mindex,mtype='rand')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n- ì ì ˆí•œ methodë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ì›€ (default ëŠ” linear)\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\në‹¤ë¥¸ methodë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš¸ìˆ˜ë„ ìˆìŒ. ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë“¤ì€ ì•„ë˜ì— ì •ë¦¬ë˜ì–´ ìˆìŒ\n\nref: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='nearest')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='quadratic')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='cubic')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.utils.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n- ë¸”ë½ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ë°œìƒ\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\nì˜ˆì œ3: vanilla STGCN with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.learners.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ4: vanilla STGCN with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ5: threshold example (random)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- ê²°ì¸¡ì¹˜ ë°œìƒ ë° íŒ¨ë”©\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.utils.plot(f_miss,'o')\nitstgcn.utils.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\nì˜ˆì œ6: threshold example (block)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n- ê²°ì¸¡ì¹˜ ë°œìƒ ë° íŒ¨ë”©\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.plot(f_miss,'o')\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\nì˜ˆì œ7: iterative thresholded STGCN (IT-STGCN) with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ8: iterative thresholded STGCN (IT-STGCN) with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ9: GNAR (random missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\nì˜ˆì œ10: GNAR (block missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n\n- í•™ìŠµ\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- ì í•©ê°’\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\nì‹¤í–‰í•˜ë©´ X,y,yhat ì¶œë ¥\n\n- ëª¨í˜• í‰ê°€ ë° ì‹œê°í™”\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes ëŠ” 1ë³´ë‹¤ ì»¤ì•¼í•¨\nfig.set_figwidth(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html",
    "title": "Data management for ITSTGCN",
    "section": "",
    "text": "ìˆœí™˜í˜• êµ¬ì¡°ë¥¼ ê°€ì§„ ëª¨ë¸(Models with recurrent structures):"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\ndf.query(\"model=='GNAR' and dataset=='fivenodes'\")\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n      model\n    \n  \n  \n    \n      23326\n      fivenodes\n      GNAR\n      0.0\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      1.40683\n      0.021981\n      GNAR\n    \n    \n      23327\n      fivenodes\n      GNAR\n      0.0\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      1.40683\n      0.017151\n      GNAR\n    \n    \n      23328\n      fivenodes\n      GNAR\n      0.7\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.084960\n      GNAR\n    \n    \n      23329\n      fivenodes\n      GNAR\n      0.7\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.010853\n      GNAR\n    \n    \n      23330\n      fivenodes\n      GNAR\n      0.8\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.012061\n      GNAR\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23594\n      fivenodes\n      GNAR\n      0.3\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.008497\n      GNAR\n    \n    \n      23595\n      fivenodes\n      GNAR\n      0.5\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.010377\n      GNAR\n    \n    \n      23596\n      fivenodes\n      GNAR\n      0.5\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.018586\n      GNAR\n    \n    \n      23597\n      fivenodes\n      GNAR\n      0.6\n      rand\n      2\n      NaN\n      linear\n      NaN\n      1.40683\n      0.007493\n      GNAR\n    \n    \n      23598\n      fivenodes\n      GNAR\n      0.6\n      rand\n      2\n      NaN\n      nearest\n      NaN\n      1.40683\n      0.008042\n      GNAR\n    \n  \n\n204 rows Ã— 11 columns\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','nof_filters','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      nof_filters\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      2.0\n      2\n      50.0\n      1.229\n      0.041\n    \n    \n      1\n      DyGrEncoder\n      12.0\n      2\n      50.0\n      1.114\n      0.037\n    \n    \n      2\n      EvolveGCNH\n      12.0\n      2\n      50.0\n      1.175\n      0.068\n    \n    \n      3\n      EvolveGCNO\n      12.0\n      2\n      50.0\n      1.168\n      0.065\n    \n    \n      4\n      GCLSTM\n      4.0\n      2\n      50.0\n      1.209\n      0.023\n    \n    \n      5\n      GConvGRU\n      12.0\n      2\n      50.0\n      0.732\n      0.005\n    \n    \n      6\n      GConvLSTM\n      12.0\n      2\n      50.0\n      1.131\n      0.041\n    \n    \n      7\n      LRGCN\n      4.0\n      2\n      50.0\n      1.212\n      0.024\n    \n    \n      8\n      TGCN\n      12.0\n      2\n      50.0\n      1.085\n      0.016"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\nhttps://matplotlib.org/stable/gallery/statistics/boxplot.html#sphx-glr-gallery-statistics-boxplot-py\n\n# with plt.style.context('cyberpunk'):\n#     plt.rcParams['figure.figsize'] = [40,20]\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='GConvGRU' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='GConvLSTM' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==2 and epoch==50 and model=='GCLSTM' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==2 and epoch==50 and model=='LRGCN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='DyGrEncoder' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and lags==2 and epoch==50 and model=='EvolveGCNH' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and lags==2 and epoch==50 and model=='EvolveGCNO' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==2 and epoch==50 and model=='TGCN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='fivenodes' and mtype=='rand' and inter_method == 'linear' and nof_filters==2 and lags==2 and epoch==50 and model=='DCRNN' and mrate in [0.3  , 0.5  , 0.6 ,0.7  , 0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.7 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      12\n      DCRNN\n      0.7\n      2.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.247\n      0.044\n    \n    \n      13\n      DCRNN\n      0.7\n      2.0\n      linear\n      STGCN\n      2\n      50.0\n      1.271\n      0.066\n    \n    \n      32\n      DyGrEncoder\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.252\n      0.060\n    \n    \n      33\n      DyGrEncoder\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.548\n      0.158\n    \n    \n      52\n      EvolveGCNH\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.188\n      0.049\n    \n    \n      53\n      EvolveGCNH\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.228\n      0.064\n    \n    \n      72\n      EvolveGCNO\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.162\n      0.052\n    \n    \n      73\n      EvolveGCNO\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.198\n      0.045\n    \n    \n      92\n      GCLSTM\n      0.7\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.228\n      0.034\n    \n    \n      93\n      GCLSTM\n      0.7\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.245\n      0.033\n    \n    \n      112\n      GConvGRU\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.180\n      0.060\n    \n    \n      113\n      GConvGRU\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.858\n      0.139\n    \n    \n      132\n      GConvLSTM\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.287\n      0.075\n    \n    \n      133\n      GConvLSTM\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.472\n      0.125\n    \n    \n      152\n      LRGCN\n      0.7\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.244\n      0.041\n    \n    \n      153\n      LRGCN\n      0.7\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.261\n      0.047\n    \n    \n      172\n      TGCN\n      0.7\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.110\n      0.037\n    \n    \n      173\n      TGCN\n      0.7\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.184\n      0.057\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['model','mrate','nof_filters','inter_method','method','lags','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','lags','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.8\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      lags\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      16\n      DCRNN\n      0.8\n      2.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.257\n      0.057\n    \n    \n      17\n      DCRNN\n      0.8\n      2.0\n      linear\n      STGCN\n      2\n      50.0\n      1.255\n      0.040\n    \n    \n      18\n      DCRNN\n      0.8\n      2.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.246\n      0.034\n    \n    \n      19\n      DCRNN\n      0.8\n      2.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.253\n      0.043\n    \n    \n      36\n      DyGrEncoder\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.333\n      0.080\n    \n    \n      37\n      DyGrEncoder\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.496\n      0.146\n    \n    \n      38\n      DyGrEncoder\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.311\n      0.057\n    \n    \n      39\n      DyGrEncoder\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.519\n      0.129\n    \n    \n      56\n      EvolveGCNH\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.212\n      0.065\n    \n    \n      57\n      EvolveGCNH\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.217\n      0.061\n    \n    \n      58\n      EvolveGCNH\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.207\n      0.057\n    \n    \n      59\n      EvolveGCNH\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.217\n      0.059\n    \n    \n      76\n      EvolveGCNO\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.194\n      0.065\n    \n    \n      77\n      EvolveGCNO\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.220\n      0.063\n    \n    \n      78\n      EvolveGCNO\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.224\n      0.079\n    \n    \n      79\n      EvolveGCNO\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.212\n      0.053\n    \n    \n      96\n      GCLSTM\n      0.8\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.235\n      0.027\n    \n    \n      97\n      GCLSTM\n      0.8\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.263\n      0.050\n    \n    \n      98\n      GCLSTM\n      0.8\n      4.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.237\n      0.029\n    \n    \n      99\n      GCLSTM\n      0.8\n      4.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.258\n      0.046\n    \n    \n      116\n      GConvGRU\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.383\n      0.108\n    \n    \n      117\n      GConvGRU\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      2.224\n      0.192\n    \n    \n      118\n      GConvGRU\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.360\n      0.084\n    \n    \n      119\n      GConvGRU\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      2.641\n      0.117\n    \n    \n      136\n      GConvLSTM\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.298\n      0.060\n    \n    \n      137\n      GConvLSTM\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.442\n      0.111\n    \n    \n      138\n      GConvLSTM\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.312\n      0.065\n    \n    \n      139\n      GConvLSTM\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.436\n      0.098\n    \n    \n      156\n      LRGCN\n      0.8\n      4.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.233\n      0.041\n    \n    \n      157\n      LRGCN\n      0.8\n      4.0\n      linear\n      STGCN\n      2\n      50.0\n      1.250\n      0.038\n    \n    \n      158\n      LRGCN\n      0.8\n      4.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.230\n      0.036\n    \n    \n      159\n      LRGCN\n      0.8\n      4.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.250\n      0.046\n    \n    \n      176\n      TGCN\n      0.8\n      12.0\n      linear\n      IT-STGCN\n      2\n      50.0\n      1.125\n      0.047\n    \n    \n      177\n      TGCN\n      0.8\n      12.0\n      linear\n      STGCN\n      2\n      50.0\n      1.199\n      0.070\n    \n    \n      178\n      TGCN\n      0.8\n      12.0\n      nearest\n      IT-STGCN\n      2\n      50.0\n      1.139\n      0.054\n    \n    \n      179\n      TGCN\n      0.8\n      12.0\n      nearest\n      STGCN\n      2\n      50.0\n      1.140\n      0.044"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.125\n      2.0\n      linear\n      IT-STGCN\n      50.0\n      1.232\n      0.033\n    \n    \n      1\n      DCRNN\n      0.125\n      2.0\n      linear\n      STGCN\n      50.0\n      1.260\n      0.051\n    \n    \n      2\n      DCRNN\n      0.125\n      2.0\n      nearest\n      IT-STGCN\n      50.0\n      1.222\n      0.025\n    \n    \n      3\n      DCRNN\n      0.125\n      2.0\n      nearest\n      STGCN\n      50.0\n      1.248\n      0.039\n    \n    \n      4\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.124\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.173\n      0.037\n    \n    \n      6\n      DyGrEncoder\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.128\n      0.031\n    \n    \n      7\n      DyGrEncoder\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.135\n      0.033\n    \n    \n      8\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.181\n      0.055\n    \n    \n      9\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.197\n      0.076\n    \n    \n      10\n      EvolveGCNH\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.159\n      0.053\n    \n    \n      11\n      EvolveGCNH\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.181\n      0.037\n    \n    \n      12\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.162\n      0.040\n    \n    \n      13\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.176\n      0.056\n    \n    \n      14\n      EvolveGCNO\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.167\n      0.061\n    \n    \n      15\n      EvolveGCNO\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.195\n      0.065\n    \n    \n      16\n      GCLSTM\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.219\n      0.025\n    \n    \n      17\n      GCLSTM\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.244\n      0.033\n    \n    \n      18\n      GCLSTM\n      0.125\n      4.0\n      nearest\n      IT-STGCN\n      50.0\n      1.215\n      0.022\n    \n    \n      19\n      GCLSTM\n      0.125\n      4.0\n      nearest\n      STGCN\n      50.0\n      1.248\n      0.040\n    \n    \n      20\n      GConvGRU\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.165\n      0.043\n    \n    \n      21\n      GConvGRU\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.210\n      0.039\n    \n    \n      22\n      GConvGRU\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.156\n      0.042\n    \n    \n      23\n      GConvGRU\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.220\n      0.032\n    \n    \n      24\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.140\n      0.038\n    \n    \n      25\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.172\n      0.055\n    \n    \n      26\n      GConvLSTM\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.121\n      0.027\n    \n    \n      27\n      GConvLSTM\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.140\n      0.058\n    \n    \n      28\n      LRGCN\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.220\n      0.020\n    \n    \n      29\n      LRGCN\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.251\n      0.037\n    \n    \n      30\n      LRGCN\n      0.125\n      4.0\n      nearest\n      IT-STGCN\n      50.0\n      1.216\n      0.030\n    \n    \n      31\n      LRGCN\n      0.125\n      4.0\n      nearest\n      STGCN\n      50.0\n      1.239\n      0.034\n    \n    \n      32\n      TGCN\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.090\n      0.015\n    \n    \n      33\n      TGCN\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.107\n      0.020\n    \n    \n      34\n      TGCN\n      0.125\n      12.0\n      nearest\n      IT-STGCN\n      50.0\n      1.091\n      0.015\n    \n    \n      35\n      TGCN\n      0.125\n      12.0\n      nearest\n      STGCN\n      50.0\n      1.091\n      0.011\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['model','mrate','nof_filters','inter_method','method','epoch'])['mse'].std().reset_index(),\n         on=['model','inter_method','method','nof_filters','mrate','epoch']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      inter_method\n      method\n      epoch\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.125\n      2.0\n      linear\n      IT-STGCN\n      50.0\n      1.232\n      0.033\n    \n    \n      1\n      DCRNN\n      0.125\n      2.0\n      linear\n      STGCN\n      50.0\n      1.260\n      0.051\n    \n    \n      4\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.124\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.173\n      0.037\n    \n    \n      8\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.181\n      0.055\n    \n    \n      9\n      EvolveGCNH\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.197\n      0.076\n    \n    \n      12\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.162\n      0.040\n    \n    \n      13\n      EvolveGCNO\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.176\n      0.056\n    \n    \n      16\n      GCLSTM\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.219\n      0.025\n    \n    \n      17\n      GCLSTM\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.244\n      0.033\n    \n    \n      20\n      GConvGRU\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.165\n      0.043\n    \n    \n      21\n      GConvGRU\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.210\n      0.039\n    \n    \n      24\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.140\n      0.038\n    \n    \n      25\n      GConvLSTM\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.172\n      0.055\n    \n    \n      28\n      LRGCN\n      0.125\n      4.0\n      linear\n      IT-STGCN\n      50.0\n      1.220\n      0.020\n    \n    \n      29\n      LRGCN\n      0.125\n      4.0\n      linear\n      STGCN\n      50.0\n      1.251\n      0.037\n    \n    \n      32\n      TGCN\n      0.125\n      12.0\n      linear\n      IT-STGCN\n      50.0\n      1.090\n      0.015\n    \n    \n      33\n      TGCN\n      0.125\n      12.0\n      linear\n      STGCN\n      50.0\n      1.107\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-1",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['model','nof_filters'])['mse'].std().reset_index(),\n         on=['model','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      nof_filters\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      16.0\n      0.727\n      0.009\n    \n    \n      1\n      DyGrEncoder\n      12.0\n      0.906\n      0.051\n    \n    \n      2\n      EvolveGCNH\n      32.0\n      1.000\n      0.020\n    \n    \n      3\n      EvolveGCNO\n      32.0\n      0.986\n      0.018\n    \n    \n      4\n      GCLSTM\n      16.0\n      0.885\n      0.051\n    \n    \n      5\n      GConvGRU\n      16.0\n      0.752\n      0.013\n    \n    \n      6\n      GConvLSTM\n      32.0\n      0.959\n      0.088\n    \n    \n      7\n      LRGCN\n      8.0\n      0.868\n      0.047\n    \n    \n      8\n      TGCN\n      12.0\n      1.090\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-1",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='GConvGRU' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==32 and lags==4 and epoch==50 and model=='GConvLSTM' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='GCLSTM' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='LRGCN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='DyGrEncoder' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNH' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNO' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='TGCN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='chickenpox' and mtype=='rand' and inter_method == 'linear' and nof_filters==16 and lags==4 and epoch==50 and model=='DCRNN' and mrate in [ 0.3   , 0.5   ,   0.6  , 0.8 ]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate==0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.797\n      0.010\n    \n    \n      1\n      DCRNN\n      0.3\n      linear\n      16.0\n      STGCN\n      1.032\n      0.039\n    \n    \n      8\n      DyGrEncoder\n      0.3\n      linear\n      12.0\n      IT-STGCN\n      0.868\n      0.028\n    \n    \n      9\n      DyGrEncoder\n      0.3\n      linear\n      12.0\n      STGCN\n      1.080\n      0.037\n    \n    \n      16\n      EvolveGCNH\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      1.011\n      0.019\n    \n    \n      17\n      EvolveGCNH\n      0.3\n      linear\n      32.0\n      STGCN\n      1.058\n      0.015\n    \n    \n      24\n      EvolveGCNO\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      0.998\n      0.019\n    \n    \n      25\n      EvolveGCNO\n      0.3\n      linear\n      32.0\n      STGCN\n      1.054\n      0.011\n    \n    \n      32\n      GCLSTM\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.850\n      0.022\n    \n    \n      33\n      GCLSTM\n      0.3\n      linear\n      16.0\n      STGCN\n      1.050\n      0.036\n    \n    \n      40\n      GConvGRU\n      0.3\n      linear\n      16.0\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      41\n      GConvGRU\n      0.3\n      linear\n      16.0\n      STGCN\n      1.087\n      0.046\n    \n    \n      48\n      GConvLSTM\n      0.3\n      linear\n      32.0\n      IT-STGCN\n      0.872\n      0.035\n    \n    \n      49\n      GConvLSTM\n      0.3\n      linear\n      32.0\n      STGCN\n      1.114\n      0.057\n    \n    \n      56\n      LRGCN\n      0.3\n      linear\n      8.0\n      IT-STGCN\n      0.870\n      0.035\n    \n    \n      57\n      LRGCN\n      0.3\n      linear\n      8.0\n      STGCN\n      1.086\n      0.029\n    \n    \n      64\n      TGCN\n      0.3\n      linear\n      12.0\n      IT-STGCN\n      1.042\n      0.020\n    \n    \n      65\n      TGCN\n      0.3\n      linear\n      12.0\n      STGCN\n      1.054\n      0.015\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['model','mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate!=0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.869\n      0.018\n    \n    \n      3\n      DCRNN\n      0.5\n      linear\n      16.0\n      STGCN\n      1.473\n      0.058\n    \n    \n      4\n      DCRNN\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      0.973\n      0.032\n    \n    \n      5\n      DCRNN\n      0.6\n      linear\n      16.0\n      STGCN\n      1.848\n      0.072\n    \n    \n      6\n      DCRNN\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.467\n      0.076\n    \n    \n      7\n      DCRNN\n      0.8\n      linear\n      16.0\n      STGCN\n      2.287\n      0.074\n    \n    \n      10\n      DyGrEncoder\n      0.5\n      linear\n      12.0\n      IT-STGCN\n      0.915\n      0.029\n    \n    \n      11\n      DyGrEncoder\n      0.5\n      linear\n      12.0\n      STGCN\n      1.540\n      0.045\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      linear\n      12.0\n      IT-STGCN\n      1.013\n      0.035\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      linear\n      12.0\n      STGCN\n      1.807\n      0.068\n    \n    \n      14\n      DyGrEncoder\n      0.8\n      linear\n      12.0\n      IT-STGCN\n      1.399\n      0.063\n    \n    \n      15\n      DyGrEncoder\n      0.8\n      linear\n      12.0\n      STGCN\n      2.127\n      0.240\n    \n    \n      18\n      EvolveGCNH\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.026\n      0.017\n    \n    \n      19\n      EvolveGCNH\n      0.5\n      linear\n      16.0\n      STGCN\n      1.122\n      0.035\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.054\n      0.024\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      linear\n      16.0\n      STGCN\n      1.162\n      0.044\n    \n    \n      22\n      EvolveGCNH\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.140\n      0.042\n    \n    \n      23\n      EvolveGCNH\n      0.8\n      linear\n      32.0\n      STGCN\n      1.203\n      0.061\n    \n    \n      26\n      EvolveGCNO\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      1.020\n      0.014\n    \n    \n      27\n      EvolveGCNO\n      0.5\n      linear\n      16.0\n      STGCN\n      1.145\n      0.027\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.050\n      0.018\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      linear\n      16.0\n      STGCN\n      1.205\n      0.055\n    \n    \n      30\n      EvolveGCNO\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.161\n      0.054\n    \n    \n      31\n      EvolveGCNO\n      0.8\n      linear\n      32.0\n      STGCN\n      1.234\n      0.096\n    \n    \n      34\n      GCLSTM\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.899\n      0.023\n    \n    \n      35\n      GCLSTM\n      0.5\n      linear\n      16.0\n      STGCN\n      1.514\n      0.050\n    \n    \n      36\n      GCLSTM\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.003\n      0.030\n    \n    \n      37\n      GCLSTM\n      0.6\n      linear\n      16.0\n      STGCN\n      1.808\n      0.069\n    \n    \n      38\n      GCLSTM\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.371\n      0.072\n    \n    \n      39\n      GCLSTM\n      0.8\n      linear\n      16.0\n      STGCN\n      2.172\n      0.186\n    \n    \n      42\n      GConvGRU\n      0.5\n      linear\n      16.0\n      IT-STGCN\n      0.958\n      0.072\n    \n    \n      43\n      GConvGRU\n      0.5\n      linear\n      16.0\n      STGCN\n      1.530\n      0.106\n    \n    \n      44\n      GConvGRU\n      0.6\n      linear\n      16.0\n      IT-STGCN\n      1.120\n      0.072\n    \n    \n      45\n      GConvGRU\n      0.6\n      linear\n      16.0\n      STGCN\n      1.753\n      0.181\n    \n    \n      46\n      GConvGRU\n      0.8\n      linear\n      16.0\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      47\n      GConvGRU\n      0.8\n      linear\n      16.0\n      STGCN\n      2.529\n      0.292\n    \n    \n      50\n      GConvLSTM\n      0.5\n      linear\n      32.0\n      IT-STGCN\n      0.901\n      0.024\n    \n    \n      51\n      GConvLSTM\n      0.5\n      linear\n      32.0\n      STGCN\n      1.518\n      0.063\n    \n    \n      52\n      GConvLSTM\n      0.6\n      linear\n      32.0\n      IT-STGCN\n      1.004\n      0.038\n    \n    \n      53\n      GConvLSTM\n      0.6\n      linear\n      32.0\n      STGCN\n      1.787\n      0.055\n    \n    \n      54\n      GConvLSTM\n      0.8\n      linear\n      32.0\n      IT-STGCN\n      1.433\n      0.080\n    \n    \n      55\n      GConvLSTM\n      0.8\n      linear\n      32.0\n      STGCN\n      2.522\n      0.111\n    \n    \n      58\n      LRGCN\n      0.5\n      linear\n      8.0\n      IT-STGCN\n      0.931\n      0.034\n    \n    \n      59\n      LRGCN\n      0.5\n      linear\n      8.0\n      STGCN\n      1.458\n      0.068\n    \n    \n      60\n      LRGCN\n      0.6\n      linear\n      8.0\n      IT-STGCN\n      1.017\n      0.029\n    \n    \n      61\n      LRGCN\n      0.6\n      linear\n      8.0\n      STGCN\n      1.615\n      0.134\n    \n    \n      62\n      LRGCN\n      0.8\n      linear\n      8.0\n      IT-STGCN\n      1.334\n      0.071\n    \n    \n      63\n      LRGCN\n      0.8\n      linear\n      8.0\n      STGCN\n      1.632\n      0.156\n    \n    \n      66\n      TGCN\n      0.5\n      linear\n      12.0\n      IT-STGCN\n      1.032\n      0.012\n    \n    \n      67\n      TGCN\n      0.5\n      linear\n      12.0\n      STGCN\n      1.167\n      0.018\n    \n    \n      68\n      TGCN\n      0.6\n      linear\n      12.0\n      IT-STGCN\n      1.054\n      0.014\n    \n    \n      69\n      TGCN\n      0.6\n      linear\n      12.0\n      STGCN\n      1.242\n      0.021\n    \n    \n      70\n      TGCN\n      0.8\n      linear\n      12.0\n      IT-STGCN\n      1.183\n      0.028\n    \n    \n      71\n      TGCN\n      0.8\n      linear\n      12.0\n      STGCN\n      1.466\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-1",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-1",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.740\n      0.007\n    \n    \n      1\n      DCRNN\n      linear\n      0.288\n      16.0\n      STGCN\n      0.812\n      0.006\n    \n    \n      2\n      DCRNN\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.738\n      0.007\n    \n    \n      3\n      DCRNN\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.832\n      0.009\n    \n    \n      4\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      0.899\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      STGCN\n      0.912\n      0.043\n    \n    \n      6\n      DyGrEncoder\n      nearest\n      0.288\n      12.0\n      IT-STGCN\n      0.909\n      0.043\n    \n    \n      7\n      DyGrEncoder\n      nearest\n      0.288\n      12.0\n      STGCN\n      0.930\n      0.035\n    \n    \n      8\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.007\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      STGCN\n      1.027\n      0.023\n    \n    \n      10\n      EvolveGCNH\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      1.011\n      0.018\n    \n    \n      11\n      EvolveGCNH\n      nearest\n      0.288\n      32.0\n      STGCN\n      1.030\n      0.017\n    \n    \n      12\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.002\n      0.015\n    \n    \n      13\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      STGCN\n      1.028\n      0.016\n    \n    \n      14\n      EvolveGCNO\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      0.999\n      0.022\n    \n    \n      15\n      EvolveGCNO\n      nearest\n      0.288\n      32.0\n      STGCN\n      1.026\n      0.015\n    \n    \n      16\n      GCLSTM\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.883\n      0.045\n    \n    \n      17\n      GCLSTM\n      linear\n      0.288\n      16.0\n      STGCN\n      0.890\n      0.033\n    \n    \n      18\n      GCLSTM\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.901\n      0.054\n    \n    \n      19\n      GCLSTM\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.885\n      0.042\n    \n    \n      20\n      GConvGRU\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.807\n      0.016\n    \n    \n      21\n      GConvGRU\n      linear\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      22\n      GConvGRU\n      nearest\n      0.288\n      16.0\n      IT-STGCN\n      0.824\n      0.023\n    \n    \n      23\n      GConvGRU\n      nearest\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      24\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      25\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      STGCN\n      0.900\n      0.049\n    \n    \n      26\n      GConvLSTM\n      nearest\n      0.288\n      32.0\n      IT-STGCN\n      0.885\n      0.040\n    \n    \n      27\n      GConvLSTM\n      nearest\n      0.288\n      32.0\n      STGCN\n      0.896\n      0.054\n    \n    \n      28\n      LRGCN\n      linear\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.035\n    \n    \n      29\n      LRGCN\n      linear\n      0.288\n      8.0\n      STGCN\n      0.911\n      0.047\n    \n    \n      30\n      LRGCN\n      nearest\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.041\n    \n    \n      31\n      LRGCN\n      nearest\n      0.288\n      8.0\n      STGCN\n      0.902\n      0.039\n    \n    \n      32\n      TGCN\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      1.065\n      0.031\n    \n    \n      33\n      TGCN\n      linear\n      0.288\n      12.0\n      STGCN\n      1.082\n      0.028\n    \n    \n      34\n      TGCN\n      nearest\n      0.288\n      12.0\n      IT-STGCN\n      1.070\n      0.028\n    \n    \n      35\n      TGCN\n      nearest\n      0.288\n      12.0\n      STGCN\n      1.079\n      0.027\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['model','inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.740\n      0.007\n    \n    \n      1\n      DCRNN\n      linear\n      0.288\n      16.0\n      STGCN\n      0.812\n      0.006\n    \n    \n      4\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      0.899\n      0.035\n    \n    \n      5\n      DyGrEncoder\n      linear\n      0.288\n      12.0\n      STGCN\n      0.912\n      0.043\n    \n    \n      8\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.007\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      linear\n      0.288\n      32.0\n      STGCN\n      1.027\n      0.023\n    \n    \n      12\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      1.002\n      0.015\n    \n    \n      13\n      EvolveGCNO\n      linear\n      0.288\n      32.0\n      STGCN\n      1.028\n      0.016\n    \n    \n      16\n      GCLSTM\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.883\n      0.045\n    \n    \n      17\n      GCLSTM\n      linear\n      0.288\n      16.0\n      STGCN\n      0.890\n      0.033\n    \n    \n      20\n      GConvGRU\n      linear\n      0.288\n      16.0\n      IT-STGCN\n      0.807\n      0.016\n    \n    \n      21\n      GConvGRU\n      linear\n      0.288\n      16.0\n      STGCN\n      0.828\n      0.022\n    \n    \n      24\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      25\n      GConvLSTM\n      linear\n      0.288\n      32.0\n      STGCN\n      0.900\n      0.049\n    \n    \n      28\n      LRGCN\n      linear\n      0.288\n      8.0\n      IT-STGCN\n      0.888\n      0.035\n    \n    \n      29\n      LRGCN\n      linear\n      0.288\n      8.0\n      STGCN\n      0.911\n      0.047\n    \n    \n      32\n      TGCN\n      linear\n      0.288\n      12.0\n      IT-STGCN\n      1.065\n      0.031\n    \n    \n      33\n      TGCN\n      linear\n      0.288\n      12.0\n      STGCN\n      1.082\n      0.028"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-2",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['model','lags','nof_filters'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['model','lags','nof_filters'])['mse'].std().reset_index(),\n         on=['model','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      nof_filters\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      4\n      8.0\n      1.131\n      0.015\n    \n    \n      1\n      DyGrEncoder\n      4\n      12.0\n      1.190\n      0.047\n    \n    \n      2\n      EvolveGCNH\n      4\n      2.0\n      1.213\n      0.057\n    \n    \n      3\n      EvolveGCNO\n      4\n      2.0\n      1.223\n      0.051\n    \n    \n      4\n      GCLSTM\n      4\n      4.0\n      1.181\n      0.040\n    \n    \n      5\n      GConvGRU\n      4\n      12.0\n      1.233\n      0.107\n    \n    \n      6\n      GConvLSTM\n      4\n      2.0\n      1.214\n      0.055\n    \n    \n      7\n      LRGCN\n      4\n      8.0\n      1.191\n      0.054\n    \n    \n      8\n      TGCN\n      4\n      12.0\n      1.307\n      0.075"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-2",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='GConvGRU' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==2 and lags==4 and epoch==50 and model=='GConvLSTM' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==4 and lags==4 and epoch==50 and model=='GCLSTM' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='LRGCN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='DyGrEncoder' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNH' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and lags==4 and epoch==50 and model=='EvolveGCNO' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==4 and epoch==50 and model=='TGCN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='pedalme' and mtype=='rand' and inter_method == 'linear' and nof_filters==8 and lags==4 and epoch==50 and model=='DCRNN' and mrate in [0.3,0.5,0.6,0.8]\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.set_yscale('log')\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate == 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.190\n      0.029\n    \n    \n      1\n      DCRNN\n      0.3\n      4\n      8.0\n      linear\n      STGCN\n      1.277\n      0.064\n    \n    \n      2\n      DCRNN\n      0.3\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.179\n      0.035\n    \n    \n      3\n      DCRNN\n      0.3\n      4\n      8.0\n      nearest\n      STGCN\n      1.278\n      0.060\n    \n    \n      16\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.207\n      0.046\n    \n    \n      17\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.279\n      0.061\n    \n    \n      18\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.205\n      0.075\n    \n    \n      19\n      DyGrEncoder\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.289\n      0.096\n    \n    \n      32\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.245\n      0.069\n    \n    \n      33\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.273\n      0.057\n    \n    \n      34\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.238\n      0.046\n    \n    \n      35\n      EvolveGCNH\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.244\n      0.054\n    \n    \n      48\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.251\n      0.072\n    \n    \n      49\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.267\n      0.072\n    \n    \n      50\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.251\n      0.057\n    \n    \n      51\n      EvolveGCNO\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.265\n      0.056\n    \n    \n      64\n      GCLSTM\n      0.3\n      4\n      4.0\n      linear\n      IT-STGCN\n      1.202\n      0.029\n    \n    \n      65\n      GCLSTM\n      0.3\n      4\n      4.0\n      linear\n      STGCN\n      1.267\n      0.041\n    \n    \n      66\n      GCLSTM\n      0.3\n      4\n      4.0\n      nearest\n      IT-STGCN\n      1.211\n      0.039\n    \n    \n      67\n      GCLSTM\n      0.3\n      4\n      4.0\n      nearest\n      STGCN\n      1.256\n      0.038\n    \n    \n      80\n      GConvGRU\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      81\n      GConvGRU\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      82\n      GConvGRU\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      83\n      GConvGRU\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      96\n      GConvLSTM\n      0.3\n      4\n      2.0\n      linear\n      IT-STGCN\n      1.227\n      0.056\n    \n    \n      97\n      GConvLSTM\n      0.3\n      4\n      2.0\n      linear\n      STGCN\n      1.244\n      0.041\n    \n    \n      98\n      GConvLSTM\n      0.3\n      4\n      2.0\n      nearest\n      IT-STGCN\n      1.224\n      0.035\n    \n    \n      99\n      GConvLSTM\n      0.3\n      4\n      2.0\n      nearest\n      STGCN\n      1.266\n      0.068\n    \n    \n      112\n      LRGCN\n      0.3\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.210\n      0.039\n    \n    \n      113\n      LRGCN\n      0.3\n      4\n      8.0\n      linear\n      STGCN\n      1.274\n      0.045\n    \n    \n      114\n      LRGCN\n      0.3\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.220\n      0.046\n    \n    \n      115\n      LRGCN\n      0.3\n      4\n      8.0\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      128\n      TGCN\n      0.3\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.280\n      0.070\n    \n    \n      129\n      TGCN\n      0.3\n      4\n      12.0\n      linear\n      STGCN\n      1.302\n      0.112\n    \n    \n      130\n      TGCN\n      0.3\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.248\n      0.074\n    \n    \n      131\n      TGCN\n      0.3\n      4\n      12.0\n      nearest\n      STGCN\n      1.291\n      0.111\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.5\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.238\n      0.080\n    \n    \n      5\n      DCRNN\n      0.5\n      4\n      8.0\n      linear\n      STGCN\n      1.451\n      0.061\n    \n    \n      6\n      DCRNN\n      0.5\n      4\n      8.0\n      nearest\n      IT-STGCN\n      1.232\n      0.061\n    \n    \n      7\n      DCRNN\n      0.5\n      4\n      8.0\n      nearest\n      STGCN\n      1.447\n      0.073\n    \n    \n      8\n      DCRNN\n      0.6\n      4\n      8.0\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      139\n      TGCN\n      0.6\n      4\n      12.0\n      nearest\n      STGCN\n      1.301\n      0.090\n    \n    \n      140\n      TGCN\n      0.8\n      4\n      12.0\n      linear\n      IT-STGCN\n      1.294\n      0.063\n    \n    \n      141\n      TGCN\n      0.8\n      4\n      12.0\n      linear\n      STGCN\n      1.289\n      0.065\n    \n    \n      142\n      TGCN\n      0.8\n      4\n      12.0\n      nearest\n      IT-STGCN\n      1.258\n      0.053\n    \n    \n      143\n      TGCN\n      0.8\n      4\n      12.0\n      nearest\n      STGCN\n      1.277\n      0.080\n    \n  \n\n108 rows Ã— 8 columns\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\").\\\nquery(\"inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      6\n      DCRNN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.232\n      0.061\n    \n    \n      7\n      DCRNN\n      0.5\n      4\n      nearest\n      STGCN\n      1.447\n      0.073\n    \n    \n      10\n      DCRNN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.303\n      0.078\n    \n    \n      11\n      DCRNN\n      0.6\n      4\n      nearest\n      STGCN\n      1.509\n      0.068\n    \n    \n      14\n      DCRNN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.527\n      0.079\n    \n    \n      15\n      DCRNN\n      0.8\n      4\n      nearest\n      STGCN\n      1.616\n      0.075\n    \n    \n      22\n      DyGrEncoder\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.236\n      0.059\n    \n    \n      23\n      DyGrEncoder\n      0.5\n      4\n      nearest\n      STGCN\n      1.427\n      0.076\n    \n    \n      26\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.285\n      0.051\n    \n    \n      27\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.083\n    \n    \n      30\n      DyGrEncoder\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.476\n      0.098\n    \n    \n      31\n      DyGrEncoder\n      0.8\n      4\n      nearest\n      STGCN\n      1.614\n      0.096\n    \n    \n      38\n      EvolveGCNH\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.242\n      0.058\n    \n    \n      39\n      EvolveGCNH\n      0.5\n      4\n      nearest\n      STGCN\n      1.285\n      0.049\n    \n    \n      42\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.091\n    \n    \n      43\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      STGCN\n      1.284\n      0.066\n    \n    \n      46\n      EvolveGCNH\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.299\n      0.082\n    \n    \n      47\n      EvolveGCNH\n      0.8\n      4\n      nearest\n      STGCN\n      1.292\n      0.074\n    \n    \n      54\n      EvolveGCNO\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.254\n      0.037\n    \n    \n      55\n      EvolveGCNO\n      0.5\n      4\n      nearest\n      STGCN\n      1.274\n      0.080\n    \n    \n      58\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.267\n      0.067\n    \n    \n      59\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      STGCN\n      1.292\n      0.075\n    \n    \n      62\n      EvolveGCNO\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.312\n      0.073\n    \n    \n      63\n      EvolveGCNO\n      0.8\n      4\n      nearest\n      STGCN\n      1.334\n      0.144\n    \n    \n      70\n      GCLSTM\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.221\n      0.042\n    \n    \n      71\n      GCLSTM\n      0.5\n      4\n      nearest\n      STGCN\n      1.333\n      0.066\n    \n    \n      74\n      GCLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.042\n    \n    \n      75\n      GCLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.365\n      0.064\n    \n    \n      78\n      GCLSTM\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.352\n      0.050\n    \n    \n      79\n      GCLSTM\n      0.8\n      4\n      nearest\n      STGCN\n      1.396\n      0.079\n    \n    \n      86\n      GConvGRU\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.507\n      0.235\n    \n    \n      87\n      GConvGRU\n      0.5\n      4\n      nearest\n      STGCN\n      1.673\n      0.223\n    \n    \n      90\n      GConvGRU\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      91\n      GConvGRU\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254\n    \n    \n      94\n      GConvGRU\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.608\n      0.243\n    \n    \n      95\n      GConvGRU\n      0.8\n      4\n      nearest\n      STGCN\n      1.871\n      0.214\n    \n    \n      102\n      GConvLSTM\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.235\n      0.042\n    \n    \n      103\n      GConvLSTM\n      0.5\n      4\n      nearest\n      STGCN\n      1.283\n      0.071\n    \n    \n      106\n      GConvLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.045\n    \n    \n      107\n      GConvLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.274\n      0.078\n    \n    \n      110\n      GConvLSTM\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.287\n      0.065\n    \n    \n      111\n      GConvLSTM\n      0.8\n      4\n      nearest\n      STGCN\n      1.364\n      0.069\n    \n    \n      115\n      GNAR\n      0.5\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      117\n      GNAR\n      0.6\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      119\n      GNAR\n      0.8\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      126\n      LRGCN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.240\n      0.036\n    \n    \n      127\n      LRGCN\n      0.5\n      4\n      nearest\n      STGCN\n      1.379\n      0.079\n    \n    \n      130\n      LRGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.286\n      0.033\n    \n    \n      131\n      LRGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.462\n      0.084\n    \n    \n      134\n      LRGCN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.436\n      0.091\n    \n    \n      135\n      LRGCN\n      0.8\n      4\n      nearest\n      STGCN\n      1.529\n      0.071\n    \n    \n      142\n      TGCN\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.066\n    \n    \n      143\n      TGCN\n      0.5\n      4\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      146\n      TGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.072\n    \n    \n      147\n      TGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.301\n      0.090\n    \n    \n      150\n      TGCN\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.258\n      0.053\n    \n    \n      151\n      TGCN\n      0.8\n      4\n      nearest\n      STGCN\n      1.277\n      0.080"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-2",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-2",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.154\n      0.014\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.248\n      0.019\n    \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.167\n      0.040\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.222\n      0.054\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.259\n      0.085\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.246\n      0.073\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.246\n      0.034\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.031\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.211\n      0.023\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.069\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.223\n      0.042\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046\n    \n    \n      28\n      GNAR\n      0.286\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      29\n      GNAR\n      0.286\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      30\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.169\n      0.040\n    \n    \n      31\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.204\n      0.032\n    \n    \n      32\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      33\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033\n    \n    \n      34\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.056\n    \n    \n      35\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.244\n      0.071\n    \n    \n      36\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      37\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).\\\nquery(\"lags==4 and inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.032\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.269\n      0.066\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.040\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.265\n      0.072\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046\n    \n    \n      29\n      GNAR\n      0.286\n      4\n      nearest\n      GNAR\n      1.303\n      0.000\n    \n    \n      32\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      33\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033\n    \n    \n      36\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      37\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#w_st",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#w_st",
    "title": "Data management for ITSTGCN",
    "section": "W_st",
    "text": "W_st\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate==0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.153\n      0.036\n    \n    \n      1\n      DCRNN\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.053\n    \n    \n      2\n      DCRNN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.154\n      0.038\n    \n    \n      3\n      DCRNN\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.068\n    \n    \n      8\n      DyGrEncoder\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.222\n      0.083\n    \n    \n      9\n      DyGrEncoder\n      0.3\n      4\n      linear\n      STGCN\n      1.276\n      0.058\n    \n    \n      10\n      DyGrEncoder\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.091\n    \n    \n      11\n      DyGrEncoder\n      0.3\n      4\n      nearest\n      STGCN\n      1.281\n      0.068\n    \n    \n      16\n      EvolveGCNH\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.218\n      0.058\n    \n    \n      17\n      EvolveGCNH\n      0.3\n      4\n      linear\n      STGCN\n      1.237\n      0.051\n    \n    \n      18\n      EvolveGCNH\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.068\n    \n    \n      19\n      EvolveGCNH\n      0.3\n      4\n      nearest\n      STGCN\n      1.237\n      0.058\n    \n    \n      24\n      EvolveGCNO\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.223\n      0.041\n    \n    \n      25\n      EvolveGCNO\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.048\n    \n    \n      26\n      EvolveGCNO\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.234\n      0.046\n    \n    \n      27\n      EvolveGCNO\n      0.3\n      4\n      nearest\n      STGCN\n      1.252\n      0.071\n    \n    \n      32\n      GCLSTM\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.191\n      0.041\n    \n    \n      33\n      GCLSTM\n      0.3\n      4\n      linear\n      STGCN\n      1.264\n      0.041\n    \n    \n      34\n      GCLSTM\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.193\n      0.033\n    \n    \n      35\n      GCLSTM\n      0.3\n      4\n      nearest\n      STGCN\n      1.250\n      0.049\n    \n    \n      40\n      GConvGRU\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      41\n      GConvGRU\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      42\n      GConvGRU\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      43\n      GConvGRU\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      48\n      GConvLSTM\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.340\n      0.166\n    \n    \n      49\n      GConvLSTM\n      0.3\n      4\n      linear\n      STGCN\n      1.392\n      0.109\n    \n    \n      50\n      GConvLSTM\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.368\n      0.158\n    \n    \n      51\n      GConvLSTM\n      0.3\n      4\n      nearest\n      STGCN\n      1.338\n      0.118\n    \n    \n      56\n      LRGCN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.299\n      0.147\n    \n    \n      57\n      LRGCN\n      0.3\n      4\n      linear\n      STGCN\n      1.325\n      0.086\n    \n    \n      58\n      LRGCN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.117\n    \n    \n      59\n      LRGCN\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.087\n    \n    \n      64\n      TGCN\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.320\n      0.164\n    \n    \n      65\n      TGCN\n      0.3\n      4\n      linear\n      STGCN\n      1.287\n      0.126\n    \n    \n      66\n      TGCN\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.276\n      0.105\n    \n    \n      67\n      TGCN\n      0.3\n      4\n      nearest\n      STGCN\n      1.313\n      0.101\n    \n  \n\n\n\n\n\ní…Œì´ë¸” ì •ë¦¬ìš©\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      DCRNN\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      37\n      GCLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      45\n      GConvGRU\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      53\n      GConvLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      61\n      LRGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      69\n      TGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"method !='STGCN' and lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"method !='STGCN' and lags==4 and mrate == 0.6 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      8\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      24\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.294\n      0.056\n    \n    \n      40\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.279\n      0.057\n    \n    \n      56\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.065\n    \n    \n      72\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.040\n    \n    \n      88\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      104\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.255\n      0.049\n    \n    \n      116\n      GNAR\n      0.6\n      4\n      linear\n      GNAR\n      1.303\n      0.000\n    \n    \n      128\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.286\n      0.053\n    \n    \n      144\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.257\n      0.048\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and mrate == 0.6\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      4\n      DCRNN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      DCRNN\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      6\n      DCRNN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.079\n    \n    \n      7\n      DCRNN\n      0.6\n      4\n      nearest\n      STGCN\n      1.552\n      0.087\n    \n    \n      12\n      DyGrEncoder\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.287\n      0.095\n    \n    \n      13\n      DyGrEncoder\n      0.6\n      4\n      linear\n      STGCN\n      1.497\n      0.077\n    \n    \n      14\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.305\n      0.131\n    \n    \n      15\n      DyGrEncoder\n      0.6\n      4\n      nearest\n      STGCN\n      1.513\n      0.073\n    \n    \n      20\n      EvolveGCNH\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.229\n      0.070\n    \n    \n      21\n      EvolveGCNH\n      0.6\n      4\n      linear\n      STGCN\n      1.278\n      0.066\n    \n    \n      22\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.246\n      0.067\n    \n    \n      23\n      EvolveGCNH\n      0.6\n      4\n      nearest\n      STGCN\n      1.291\n      0.063\n    \n    \n      28\n      EvolveGCNO\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      29\n      EvolveGCNO\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      30\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.072\n    \n    \n      31\n      EvolveGCNO\n      0.6\n      4\n      nearest\n      STGCN\n      1.321\n      0.094\n    \n    \n      36\n      GCLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      37\n      GCLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      38\n      GCLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.044\n    \n    \n      39\n      GCLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.355\n      0.068\n    \n    \n      44\n      GConvGRU\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      45\n      GConvGRU\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      46\n      GConvGRU\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      47\n      GConvGRU\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n    \n      52\n      GConvLSTM\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      53\n      GConvLSTM\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      54\n      GConvLSTM\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.313\n      0.205\n    \n    \n      55\n      GConvLSTM\n      0.6\n      4\n      nearest\n      STGCN\n      1.503\n      0.101\n    \n    \n      60\n      LRGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      61\n      LRGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      62\n      LRGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.331\n      0.120\n    \n    \n      63\n      LRGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.453\n      0.115\n    \n    \n      68\n      TGCN\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      69\n      TGCN\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n    \n      70\n      TGCN\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.338\n      0.202\n    \n    \n      71\n      TGCN\n      0.6\n      4\n      nearest\n      STGCN\n      1.297\n      0.093\n    \n  \n\n\n\n\n\nconclusion table\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4 and inter_method=='linear'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      28\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      29\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      32\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      33\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n  \n\n\n\n\n\npd.merge(df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df2.query(\"dataset == 'pedalme' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      DCRNN\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      2\n      DCRNN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.143\n      0.011\n    \n    \n      3\n      DCRNN\n      0.286\n      4\n      nearest\n      STGCN\n      1.310\n      0.019\n    \n    \n      4\n      DyGrEncoder\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.196\n      0.055\n    \n    \n      5\n      DyGrEncoder\n      0.286\n      4\n      linear\n      STGCN\n      1.224\n      0.037\n    \n    \n      6\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.204\n      0.063\n    \n    \n      7\n      DyGrEncoder\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.043\n    \n    \n      8\n      EvolveGCNH\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.188\n      0.042\n    \n    \n      9\n      EvolveGCNH\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      10\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.037\n    \n    \n      11\n      EvolveGCNH\n      0.286\n      4\n      nearest\n      STGCN\n      1.240\n      0.062\n    \n    \n      12\n      EvolveGCNO\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      13\n      EvolveGCNO\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      14\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.033\n    \n    \n      15\n      EvolveGCNO\n      0.286\n      4\n      nearest\n      STGCN\n      1.241\n      0.095\n    \n    \n      16\n      GCLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      17\n      GCLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      18\n      GCLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.185\n      0.035\n    \n    \n      19\n      GCLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.249\n      0.027\n    \n    \n      20\n      GConvGRU\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      21\n      GConvGRU\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      22\n      GConvGRU\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      23\n      GConvGRU\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145\n    \n    \n      24\n      GConvLSTM\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      25\n      GConvLSTM\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      26\n      GConvLSTM\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.310\n      0.151\n    \n    \n      27\n      GConvLSTM\n      0.286\n      4\n      nearest\n      STGCN\n      1.459\n      0.153\n    \n    \n      28\n      LRGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      29\n      LRGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      30\n      LRGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.106\n    \n    \n      31\n      LRGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.347\n      0.117\n    \n    \n      32\n      TGCN\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      33\n      TGCN\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n    \n      34\n      TGCN\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.237\n      0.083\n    \n    \n      35\n      TGCN\n      0.286\n      4\n      nearest\n      STGCN\n      1.258\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-3",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='wikimath' and mrate==0\").groupby(['model','lags','nof_filters','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mrate==0\").groupby(['model','lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['model','lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      8\n      12.0\n      IT-STGCN\n      0.582\n      0.006\n    \n    \n      1\n      DCRNN\n      8\n      12.0\n      STGCN\n      0.580\n      0.006\n    \n    \n      2\n      DyGrEncoder\n      8\n      12.0\n      IT-STGCN\n      0.563\n      0.030\n    \n    \n      3\n      DyGrEncoder\n      8\n      12.0\n      STGCN\n      0.560\n      0.029\n    \n    \n      4\n      EvolveGCNH\n      8\n      12.0\n      IT-STGCN\n      0.784\n      0.027\n    \n    \n      5\n      EvolveGCNH\n      8\n      12.0\n      STGCN\n      0.771\n      0.028\n    \n    \n      6\n      EvolveGCNO\n      8\n      12.0\n      IT-STGCN\n      0.735\n      0.023\n    \n    \n      7\n      EvolveGCNO\n      8\n      12.0\n      STGCN\n      0.734\n      0.025\n    \n    \n      8\n      GCLSTM\n      8\n      64.0\n      IT-STGCN\n      0.643\n      0.024\n    \n    \n      9\n      GCLSTM\n      8\n      64.0\n      STGCN\n      0.645\n      0.018\n    \n    \n      10\n      GConvGRU\n      8\n      12.0\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      11\n      GConvGRU\n      8\n      12.0\n      STGCN\n      0.528\n      0.003\n    \n    \n      12\n      GConvLSTM\n      8\n      64.0\n      IT-STGCN\n      0.626\n      0.015\n    \n    \n      13\n      GConvLSTM\n      8\n      64.0\n      STGCN\n      0.640\n      0.031\n    \n    \n      14\n      LRGCN\n      8\n      32.0\n      IT-STGCN\n      0.610\n      0.017\n    \n    \n      15\n      LRGCN\n      8\n      32.0\n      STGCN\n      0.608\n      0.014\n    \n    \n      16\n      TGCN\n      8\n      12.0\n      IT-STGCN\n      0.730\n      0.030\n    \n    \n      17\n      TGCN\n      8\n      12.0\n      STGCN\n      0.732\n      0.035"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-3",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ax = plt.subplots(3, 3,figsize=(40,20))\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='GConvGRU'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,0],grid=False,widths=0.5)\nax[0,0].set_title('GConvGRU')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==64 and lags==8 and epoch==50 and model=='GConvLSTM'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,1],grid=False,widths=0.5)\nax[0,1].set_title('GConvLSTM')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==64 and lags==8 and epoch==50 and model=='GCLSTM'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[0,2],grid=False,widths=0.5)\nax[0,2].set_title('GCLSTM')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==32 and lags==8 and epoch==50 and model=='LRGCN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,0],grid=False,widths=0.5)\nax[1,0].set_title('LRGCN')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='DyGrEncoder'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,1],grid=False,widths=0.5)\nax[1,1].set_title('DyGrEncoder')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50 and model=='EvolveGCNH'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[1,2],grid=False,widths=0.5)\nax[1,2].set_title('EvolveGCNH')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50 and model=='EvolveGCNO'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,0],grid=False,widths=0.5)\nax[2,0].set_title('EvolveGCNO')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='TGCN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,1],grid=False,widths=0.5)\nax[2,1].set_title('TGCN')\n\ndf.query(\"dataset=='wikimath' and mtype=='rand' and inter_method == 'linear' and nof_filters==12 and lags==8 and epoch==50 and model=='DCRNN'\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax[2,2],grid=False,widths=0.5)\nax[2,2].set_title('DCRNN')\n\n\nfor ax in ax.flat:\n    ax.set_yticklabels([])\n    ax.axvline(x=2.5, color='black', linestyle='-')\n    ax.axvline(x=4.5, color='black', linestyle='-')\n    ax.axvline(x=6.5, color='black', linestyle='-')\n    ax.axvline(x=8.5, color='black', linestyle='-')\n    # ax.set_xticklabels(['IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN','IT-TGNN','TGNN'])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    \nfig.suptitle('',fontsize=40)\n\nText(0.5, 0.98, '')\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','nof_filters','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate == 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      nof_filters\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.588\n      0.007\n    \n    \n      1\n      DCRNN\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.603\n      0.010\n    \n    \n      4\n      DyGrEncoder\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.578\n      0.031\n    \n    \n      5\n      DyGrEncoder\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.562\n      0.016\n    \n    \n      8\n      EvolveGCNH\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.775\n      0.021\n    \n    \n      9\n      EvolveGCNH\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.787\n      0.024\n    \n    \n      12\n      EvolveGCNO\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.738\n      0.018\n    \n    \n      13\n      EvolveGCNO\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.743\n      0.024\n    \n    \n      16\n      GCLSTM\n      0.3\n      8\n      64.0\n      linear\n      IT-STGCN\n      0.628\n      0.020\n    \n    \n      17\n      GCLSTM\n      0.3\n      8\n      64.0\n      linear\n      STGCN\n      0.674\n      0.020\n    \n    \n      20\n      GConvGRU\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      21\n      GConvGRU\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.570\n      0.006\n    \n    \n      28\n      GConvLSTM\n      0.3\n      8\n      64.0\n      linear\n      IT-STGCN\n      0.631\n      0.019\n    \n    \n      29\n      GConvLSTM\n      0.3\n      8\n      64.0\n      linear\n      STGCN\n      0.764\n      0.057\n    \n    \n      32\n      LRGCN\n      0.3\n      8\n      32.0\n      linear\n      IT-STGCN\n      0.619\n      0.019\n    \n    \n      33\n      LRGCN\n      0.3\n      8\n      32.0\n      linear\n      STGCN\n      0.689\n      0.032\n    \n    \n      36\n      TGCN\n      0.3\n      8\n      12.0\n      linear\n      IT-STGCN\n      0.739\n      0.040\n    \n    \n      37\n      TGCN\n      0.3\n      8\n      12.0\n      linear\n      STGCN\n      0.734\n      0.027\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"mrate != 0.3\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      2\n      DCRNN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.672\n      0.007\n    \n    \n      3\n      DCRNN\n      0.8\n      8\n      linear\n      STGCN\n      0.846\n      0.031\n    \n    \n      6\n      DyGrEncoder\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.606\n      0.017\n    \n    \n      7\n      DyGrEncoder\n      0.8\n      8\n      linear\n      STGCN\n      0.770\n      0.045\n    \n    \n      10\n      EvolveGCNH\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.877\n      0.045\n    \n    \n      11\n      EvolveGCNH\n      0.8\n      8\n      linear\n      STGCN\n      0.915\n      0.063\n    \n    \n      14\n      EvolveGCNO\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.780\n      0.027\n    \n    \n      15\n      EvolveGCNO\n      0.8\n      8\n      linear\n      STGCN\n      0.863\n      0.038\n    \n    \n      18\n      GCLSTM\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.815\n      0.058\n    \n    \n      19\n      GCLSTM\n      0.8\n      8\n      linear\n      STGCN\n      1.407\n      0.117\n    \n    \n      22\n      GConvGRU\n      0.5\n      8\n      linear\n      IT-STGCN\n      0.524\n      0.003\n    \n    \n      23\n      GConvGRU\n      0.5\n      8\n      linear\n      STGCN\n      0.658\n      0.010\n    \n    \n      24\n      GConvGRU\n      0.6\n      8\n      linear\n      IT-STGCN\n      0.539\n      0.004\n    \n    \n      25\n      GConvGRU\n      0.6\n      8\n      linear\n      STGCN\n      0.731\n      0.015\n    \n    \n      26\n      GConvGRU\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      27\n      GConvGRU\n      0.8\n      8\n      linear\n      STGCN\n      0.932\n      0.043\n    \n    \n      30\n      GConvLSTM\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.920\n      0.069\n    \n    \n      31\n      GConvLSTM\n      0.8\n      8\n      linear\n      STGCN\n      1.423\n      0.121\n    \n    \n      33\n      GNAR\n      0.8\n      8\n      linear\n      GNAR\n      1.354\n      0.000\n    \n    \n      36\n      LRGCN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.769\n      0.045\n    \n    \n      37\n      LRGCN\n      0.8\n      8\n      linear\n      STGCN\n      1.105\n      0.099\n    \n    \n      40\n      TGCN\n      0.8\n      8\n      linear\n      IT-STGCN\n      0.771\n      0.020\n    \n    \n      41\n      TGCN\n      0.8\n      8\n      linear\n      STGCN\n      0.827\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-3",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-3",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.583\n      0.006\n    \n    \n      1\n      DCRNN\n      0.120\n      8\n      linear\n      STGCN\n      0.578\n      0.005\n    \n    \n      2\n      DyGrEncoder\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.563\n      0.025\n    \n    \n      3\n      DyGrEncoder\n      0.120\n      8\n      linear\n      STGCN\n      0.546\n      0.016\n    \n    \n      4\n      EvolveGCNH\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.776\n      0.028\n    \n    \n      5\n      EvolveGCNH\n      0.120\n      8\n      linear\n      STGCN\n      0.773\n      0.021\n    \n    \n      6\n      EvolveGCNO\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.732\n      0.025\n    \n    \n      7\n      EvolveGCNO\n      0.120\n      8\n      linear\n      STGCN\n      0.735\n      0.022\n    \n    \n      8\n      GCLSTM\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.640\n      0.019\n    \n    \n      9\n      GCLSTM\n      0.120\n      8\n      linear\n      STGCN\n      0.638\n      0.013\n    \n    \n      10\n      GConvGRU\n      0.004\n      8\n      linear\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      11\n      GConvGRU\n      0.004\n      8\n      linear\n      STGCN\n      0.528\n      0.003\n    \n    \n      12\n      GConvGRU\n      0.096\n      8\n      linear\n      IT-STGCN\n      0.529\n      0.004\n    \n    \n      13\n      GConvGRU\n      0.096\n      8\n      linear\n      STGCN\n      0.544\n      0.011\n    \n    \n      14\n      GConvGRU\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.523\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.120\n      8\n      linear\n      STGCN\n      0.531\n      0.002\n    \n    \n      16\n      GConvLSTM\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.627\n      0.014\n    \n    \n      17\n      GConvLSTM\n      0.120\n      8\n      linear\n      STGCN\n      0.660\n      0.034\n    \n    \n      18\n      GNAR\n      0.120\n      8\n      linear\n      GNAR\n      1.354\n      0.000\n    \n    \n      19\n      LRGCN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.608\n      0.012\n    \n    \n      20\n      LRGCN\n      0.120\n      8\n      linear\n      STGCN\n      0.624\n      0.024\n    \n    \n      21\n      TGCN\n      0.120\n      8\n      linear\n      IT-STGCN\n      0.748\n      0.046\n    \n    \n      22\n      TGCN\n      0.120\n      8\n      linear\n      STGCN\n      0.741\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#missing-values-on-the-same-nodes",
    "title": "Data management for ITSTGCN",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(df2.query(\"dataset=='wikimath'\").groupby(['model','mrate','lags','method'])['mse'].mean().reset_index(),\n        df2.query(\"dataset=='wikimath'\").groupby(['model','mrate','lags','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.512\n      8\n      IT-STGCN\n      0.592\n      0.005\n    \n    \n      1\n      DCRNN\n      0.512\n      8\n      STGCN\n      0.665\n      0.015\n    \n    \n      2\n      DyGrEncoder\n      0.512\n      8\n      IT-STGCN\n      0.561\n      0.031\n    \n    \n      3\n      DyGrEncoder\n      0.512\n      8\n      STGCN\n      0.626\n      0.027\n    \n    \n      4\n      EvolveGCNH\n      0.512\n      8\n      IT-STGCN\n      0.794\n      0.031\n    \n    \n      5\n      EvolveGCNH\n      0.512\n      8\n      STGCN\n      0.818\n      0.031\n    \n    \n      6\n      EvolveGCNO\n      0.512\n      8\n      IT-STGCN\n      0.745\n      0.017\n    \n    \n      7\n      EvolveGCNO\n      0.512\n      8\n      STGCN\n      0.753\n      0.026\n    \n    \n      8\n      GCLSTM\n      0.512\n      8\n      IT-STGCN\n      0.617\n      0.011\n    \n    \n      9\n      GCLSTM\n      0.512\n      8\n      STGCN\n      0.823\n      0.048\n    \n    \n      10\n      GConvGRU\n      0.512\n      8\n      IT-STGCN\n      0.533\n      0.003\n    \n    \n      11\n      GConvGRU\n      0.512\n      8\n      STGCN\n      0.726\n      0.015\n    \n    \n      12\n      GConvLSTM\n      0.512\n      8\n      IT-STGCN\n      0.653\n      0.033\n    \n    \n      13\n      GConvLSTM\n      0.512\n      8\n      STGCN\n      0.963\n      0.098\n    \n    \n      14\n      GNAR\n      0.512\n      8\n      GNAR\n      1.354\n      0.000\n    \n    \n      15\n      LRGCN\n      0.512\n      8\n      IT-STGCN\n      0.624\n      0.019\n    \n    \n      16\n      LRGCN\n      0.512\n      8\n      STGCN\n      0.810\n      0.064\n    \n    \n      17\n      TGCN\n      0.512\n      8\n      IT-STGCN\n      0.750\n      0.039\n    \n    \n      18\n      TGCN\n      0.512\n      8\n      STGCN\n      0.782\n      0.030"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-4",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['model','lags'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['model','lags'])['mse'].std().reset_index(),\n         on=['model','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      GCLSTM\n      8\n      0.993\n      0.013\n    \n    \n      1\n      GConvGRU\n      8\n      1.003\n      0.004\n    \n    \n      2\n      GConvLSTM\n      8\n      1.019\n      0.045\n    \n    \n      3\n      GNAR\n      8\n      1.649\n      0.000"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-4",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ((ax1)) = plt.subplots(nrows=1, ncols=1, figsize=(50, 6), sharey=True)\ndf.query(\"dataset=='windmillsmall' and mtype=='rand' and inter_method == 'linear' and lags==8 and epoch==50\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax1,grid=False,widths=0.5)\n\n<Axes: title={'center': 'mse'}, xlabel='[model, mrate, method]'>\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.085\n      0.040\n    \n    \n      1\n      DCRNN\n      0.7\n      8\n      linear\n      STGCN\n      1.375\n      0.024\n    \n    \n      2\n      GCLSTM\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.116\n      0.021\n    \n    \n      3\n      GCLSTM\n      0.7\n      8\n      linear\n      STGCN\n      1.574\n      0.104\n    \n    \n      4\n      GConvGRU\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.194\n      0.042\n    \n    \n      5\n      GConvGRU\n      0.7\n      8\n      linear\n      STGCN\n      1.662\n      0.073\n    \n    \n      6\n      GConvLSTM\n      0.7\n      8\n      linear\n      IT-STGCN\n      1.142\n      0.021\n    \n    \n      7\n      GConvLSTM\n      0.7\n      8\n      linear\n      STGCN\n      1.600\n      0.056\n    \n    \n      8\n      GNAR\n      0.7\n      8\n      nearest\n      GNAR\n      1.649\n      0.000"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-4",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-4",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['model','mrate','nof_filters','lags','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['model','mrate','nof_filters','lags','method'])['mse'].std().reset_index(),\n         on=['model','method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      GCLSTM\n      0.081\n      16.0\n      8\n      IT-STGCN\n      0.985\n      0.002\n    \n    \n      1\n      GCLSTM\n      0.081\n      16.0\n      8\n      STGCN\n      0.985\n      0.002\n    \n    \n      2\n      GConvGRU\n      0.081\n      12.0\n      8\n      IT-STGCN\n      1.007\n      0.005\n    \n    \n      3\n      GConvGRU\n      0.081\n      12.0\n      8\n      STGCN\n      1.008\n      0.006\n    \n    \n      4\n      GConvLSTM\n      0.081\n      16.0\n      8\n      IT-STGCN\n      0.997\n      0.022\n    \n    \n      5\n      GConvLSTM\n      0.081\n      16.0\n      8\n      STGCN\n      0.989\n      0.009"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#baseline-5",
    "title": "Data management for ITSTGCN",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(df.query(\"dataset=='monte' and mrate==0\").groupby(['model','lags'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mrate==0\").groupby(['model','lags'])['mse'].std().reset_index(),\n         on=['model','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      4\n      0.936\n      0.002\n    \n    \n      1\n      DyGrEncoder\n      4\n      0.995\n      0.034\n    \n    \n      2\n      EvolveGCNH\n      4\n      1.182\n      0.192\n    \n    \n      3\n      EvolveGCNO\n      4\n      1.157\n      0.182\n    \n    \n      4\n      GCLSTM\n      4\n      0.970\n      0.011\n    \n    \n      5\n      GConvGRU\n      4\n      0.931\n      0.002\n    \n    \n      6\n      GConvLSTM\n      4\n      0.960\n      0.011\n    \n    \n      7\n      GNAR\n      4\n      1.062\n      0.000\n    \n    \n      8\n      LRGCN\n      4\n      0.980\n      0.024\n    \n    \n      9\n      TGCN\n      4\n      0.983\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#random-5",
    "title": "Data management for ITSTGCN",
    "section": "Random",
    "text": "Random\n\nfig, ((ax1)) = plt.subplots(nrows=1, ncols=1, figsize=(50, 6), sharey=True)\ndf.query(\"dataset=='monte' and mtype=='rand' and inter_method == 'nearest' and lags==4 and epoch==50\").\\\niloc[:,[1,2,8,10]].boxplot(by=['model','mrate','method'],ax=ax1,grid=False,widths=0.5)\n\n<Axes: title={'center': 'mse'}, xlabel='[model, mrate, method]'>\n\n\n\n\n\n\npd.merge(df.query(\"dataset=='monte' and mtype=='rand'\").groupby(['model','mrate','nof_filters','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='rand'\").groupby(['model','mrate','nof_filters','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','mrate','nof_filters','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      nof_filters\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.111\n      0.036\n    \n    \n      1\n      DCRNN\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.225\n      0.073\n    \n    \n      2\n      DyGrEncoder\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.216\n      0.118\n    \n    \n      3\n      DyGrEncoder\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.358\n      0.149\n    \n    \n      4\n      EvolveGCNH\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.845\n      0.504\n    \n    \n      5\n      EvolveGCNH\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      2.158\n      0.545\n    \n    \n      6\n      EvolveGCNO\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      2.263\n      0.476\n    \n    \n      7\n      EvolveGCNO\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      2.623\n      0.693\n    \n    \n      8\n      GCLSTM\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.968\n      0.013\n    \n    \n      9\n      GCLSTM\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      1.003\n      0.016\n    \n    \n      10\n      GCLSTM\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.957\n      0.008\n    \n    \n      11\n      GCLSTM\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.074\n      0.040\n    \n    \n      12\n      GCLSTM\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.001\n      0.010\n    \n    \n      13\n      GCLSTM\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.131\n      0.070\n    \n    \n      14\n      GCLSTM\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.032\n      0.028\n    \n    \n      15\n      GCLSTM\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.140\n      0.061\n    \n    \n      16\n      GConvGRU\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.936\n      0.002\n    \n    \n      17\n      GConvGRU\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      0.991\n      0.007\n    \n    \n      18\n      GConvGRU\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.942\n      0.003\n    \n    \n      19\n      GConvGRU\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.149\n      0.018\n    \n    \n      20\n      GConvGRU\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.015\n      0.012\n    \n    \n      21\n      GConvGRU\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.393\n      0.028\n    \n    \n      22\n      GConvGRU\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.096\n      0.019\n    \n    \n      23\n      GConvGRU\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.516\n      0.040\n    \n    \n      24\n      GConvLSTM\n      0.3\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.951\n      0.009\n    \n    \n      25\n      GConvLSTM\n      0.3\n      12.0\n      4\n      nearest\n      STGCN\n      0.981\n      0.020\n    \n    \n      26\n      GConvLSTM\n      0.5\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.947\n      0.006\n    \n    \n      27\n      GConvLSTM\n      0.5\n      12.0\n      4\n      nearest\n      STGCN\n      1.055\n      0.030\n    \n    \n      28\n      GConvLSTM\n      0.7\n      12.0\n      4\n      nearest\n      IT-STGCN\n      0.997\n      0.013\n    \n    \n      29\n      GConvLSTM\n      0.7\n      12.0\n      4\n      nearest\n      STGCN\n      1.121\n      0.065\n    \n    \n      30\n      GConvLSTM\n      0.8\n      12.0\n      4\n      nearest\n      IT-STGCN\n      1.156\n      0.062\n    \n    \n      31\n      GConvLSTM\n      0.8\n      12.0\n      4\n      nearest\n      STGCN\n      1.134\n      0.069\n    \n    \n      32\n      LRGCN\n      0.8\n      2.0\n      4\n      nearest\n      IT-STGCN\n      0.982\n      0.013\n    \n    \n      33\n      LRGCN\n      0.8\n      2.0\n      4\n      nearest\n      STGCN\n      0.989\n      0.029\n    \n    \n      34\n      TGCN\n      0.8\n      8.0\n      4\n      nearest\n      IT-STGCN\n      1.073\n      0.024\n    \n    \n      35\n      TGCN\n      0.8\n      8.0\n      4\n      nearest\n      STGCN\n      1.218\n      0.086"
  },
  {
    "objectID": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-5",
    "href": "posts/GCN/2023-07-05-ITSTGCN_data_management.html#block-5",
    "title": "Data management for ITSTGCN",
    "section": "Block",
    "text": "Block\n\npd.merge(df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.940\n      0.001\n    \n    \n      1\n      DCRNN\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.003\n    \n    \n      2\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.005\n      0.046\n    \n    \n      3\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      STGCN\n      1.030\n      0.044\n    \n    \n      4\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.392\n      0.110\n    \n    \n      5\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      STGCN\n      1.612\n      0.216\n    \n    \n      6\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.345\n      0.110\n    \n    \n      7\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      STGCN\n      1.766\n      0.123\n    \n    \n      8\n      GCLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.959\n      0.008\n    \n    \n      9\n      GCLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.005\n    \n    \n      10\n      GConvGRU\n      0.149\n      4\n      cubic\n      IT-STGCN\n      1.023\n      0.021\n    \n    \n      11\n      GConvGRU\n      0.149\n      4\n      cubic\n      STGCN\n      1.028\n      0.031\n    \n    \n      12\n      GConvGRU\n      0.149\n      4\n      linear\n      IT-STGCN\n      0.930\n      0.002\n    \n    \n      13\n      GConvGRU\n      0.149\n      4\n      linear\n      STGCN\n      0.935\n      0.005\n    \n    \n      14\n      GConvGRU\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.932\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.149\n      4\n      nearest\n      STGCN\n      0.935\n      0.004\n    \n    \n      16\n      GConvLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.949\n      0.008\n    \n    \n      17\n      GConvLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.950\n      0.005\n    \n    \n      18\n      GNAR\n      0.149\n      4\n      nearest\n      GNAR\n      1.062\n      0.000\n    \n    \n      19\n      LRGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.978\n      0.024\n    \n    \n      20\n      LRGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.977\n      0.020\n    \n    \n      21\n      TGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      22\n      TGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.985\n      0.005\n    \n  \n\n\n\n\n\npd.merge(df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         df.query(\"dataset=='monte' and mtype=='block'\").groupby(['model','mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['model','method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"inter_method=='nearest'\")\n\n\n\n\n\n  \n    \n      \n      model\n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      DCRNN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.940\n      0.001\n    \n    \n      1\n      DCRNN\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.003\n    \n    \n      2\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.005\n      0.046\n    \n    \n      3\n      DyGrEncoder\n      0.149\n      4\n      nearest\n      STGCN\n      1.030\n      0.044\n    \n    \n      4\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.392\n      0.110\n    \n    \n      5\n      EvolveGCNH\n      0.149\n      4\n      nearest\n      STGCN\n      1.612\n      0.216\n    \n    \n      6\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      IT-STGCN\n      1.345\n      0.110\n    \n    \n      7\n      EvolveGCNO\n      0.149\n      4\n      nearest\n      STGCN\n      1.766\n      0.123\n    \n    \n      8\n      GCLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.959\n      0.008\n    \n    \n      9\n      GCLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.956\n      0.005\n    \n    \n      14\n      GConvGRU\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.932\n      0.002\n    \n    \n      15\n      GConvGRU\n      0.149\n      4\n      nearest\n      STGCN\n      0.935\n      0.004\n    \n    \n      16\n      GConvLSTM\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.949\n      0.008\n    \n    \n      17\n      GConvLSTM\n      0.149\n      4\n      nearest\n      STGCN\n      0.950\n      0.005\n    \n    \n      18\n      GNAR\n      0.149\n      4\n      nearest\n      GNAR\n      1.062\n      0.000\n    \n    \n      19\n      LRGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.978\n      0.024\n    \n    \n      20\n      LRGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.977\n      0.020\n    \n    \n      21\n      TGCN\n      0.149\n      4\n      nearest\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      22\n      TGCN\n      0.149\n      4\n      nearest\n      STGCN\n      0.985\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-07-18-EbayesThresh toy ex.html",
    "href": "posts/GCN/2023-07-18-EbayesThresh toy ex.html",
    "title": "EbayesThresh Toy ex",
    "section": "",
    "text": "Import\n\nfrom itstgcn.learners import * \n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\n\n\nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nWhile \\({\\bf p}_y\\) serves as a consistent estimator for \\(\\mathbb{E}[|{\\bf V}^H{\\bf y}|^2]\\), it is not an efficient estimator, and therefore, improvement is needed [@djuric2018cooperative]. The traditional approach for improvement is to use the windowed periodogram.\nThe windowed periodogram is efficient in detecting specific frequencies or periods, but it may not be as efficient in estimating the underlying function. One notable paper that utilized the windowed periodogram is the one that detected the El NiÃ±o phenomenon.\nAs this structure exhibits a â€œsparse signal + heavy-tailedâ€ characteristics, by applying Bayesian modeling and thresholding \\({\\bf p}_y\\), we can estimate an appropriate \\({\\bf p}_{pp}\\) as discussed in [@johnstone2004needles].\n\n\n\nBayesian Model\n\\(x_i \\sim N(\\mu_i,1)\\)\ní™•ë¥ ë³€ìˆ˜ê°€ ì˜ ì •ì˜ë˜ì–´ ìˆì„ë•Œ, ì—¬ê¸°ì„œ \\(\\mu_i\\)ë¥¼ ì •í•˜ëŠ” Baysian.\n\n\\(\\mu_i \\sim\\) ì‚¬ì „ë¶„í¬(\\(\\mu_i\\)ë¥¼ ë½‘ì„ ìˆ˜ ìˆëŠ”)\n\\((\\mu_i | X_i = x_i)^n_{i=1} \\sim\\) ì‚¬í›„ë¶„í¬\n\nex) \\(N(10,1) \\sim\\) ì‚¬ì „ë¶„í¬\nê´€ì¸¡ì¹˜\n\n_obs = [7.1,6.9,8.5]\n\n\nnp.mean(_obs)\n\n7.5\n\n\nê´€ì¸¡ì¹˜ë¥¼ ë³´ë‹ˆ í‰ê· ì´ 10ì´ ì•„ë‹Œ ê²ƒ ê°™ë‹¤.\n\\(N(10-3,1) \\sim\\) ì‚¬í›„ë¶„í¬\n\nì—¬ê¸°ì„œ, \\(10-3\\)ì´ posterior meman\nì‚¬í›„ ë¶„í¬ë¥¼ ì •ì˜í• ë•Œ, ì´ë²¤íŠ¸ì˜ meanì´ëƒ, medianì´ëƒë¡œ ì¡ëŠ” ë°©ë²•ì€ ì •í•´ì§„ ê²ƒì´ ì•„ë‹ˆë‹¤.(ì´ë² ì´ì¦ˆì—ì„œëŠ” medianìœ¼ë¡œ ì¡ìŒ)\n\nEbayesëŠ” ì‚¬ì „ë¶„í¬ë¥¼ Heavy-tailìœ¼ë¡œ ì •ì˜í–ˆë‹¤.\nheavy tail?\n\n\n\nimage.png\n\n\n\\(\\mu_x \\sim\\) Double Exponential \\(= p_{pp} + p_{ac}\\) -> í˜¼í•©í˜•(misture) = pure point + absolutely continuous\n\\(E(\\mu_i | X_i = x_i) = \\hat{\\mu}_i\\) -> thresholdingì˜ ê²°ê³¼\n\\(f_{prior}(\\mu) = (1-w)\\delta_0(\\mu) + w \\gamma (\\mu)\\)\n\n\\(\\delta_0\\) = ë””ë ‰í•¨ìˆ˜(íŠ¹ì •ê°’ì´ ì•„ë‹ˆë©´ ë‹¤ 0ìœ¼ë¡œ ë´„)\n\\(\\gamma = \\frac{a}{2} e^{-a|\\mu|}\\)\n\nEbayesì˜ ì—­í•  = ìë™ìœ¼ë¡œ \\(w\\)ë¥¼ ê³„ì‚° í˜¹ì€ ì¶”ì •\n\n\\(1-w\\) í™•ë¥ ë¡œ \\(\\delta_0\\)ë¥¼ ì •ì˜, \\(w\\)ì˜ í™•ë£”ë¡œ \\(\\gamma\\)ë¥¼ ì •ì˜.\n\n\\(X_i = \\mu_i + \\epsilon_i, \\epsilon_i \\sim N(0,1)\\)ì—ì„œ \\(\\mu_i\\)ë¥¼ ì°¾ëŠ”ê²Œ ëª©ì ì´ë‹¤. ì´ê²Œ ë°”ë¡œ \\(\\eta\\)ê°’\n\nEbayesë¡œ sparse signalë§Œ ê³¨ëŸ¬ë‚¼ ê²ƒì´ë‹¤.\ní‰ê·  ì´ìƒì˜ ê°’ì—ì„œ ìë¥¼ ê²ƒì´ë‹¤.\n\nthresh(ì„ê³„ì¹˜)ë¥¼ ì¡ëŠ” ê²Œ ì–´ë ¤ìš¸ í…ë°, ìœ„ì—ì„œ ì´ë² ì´ì¦ˆê°€ \\(w\\)ë¥¼ ìë™ìœ¼ë¡œ ì¡ì•„ í™•ë¥  ê³„ì‚°ë˜ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•œ ê²ƒ,\n\nbaysian modeling ì‚¬ìš©í•˜ì—¬ heavy tail + impulse(sparse)ì—ì„œ posterior median ì¶”ì •í•˜ì—¬ ì„ê³„ê°’threshìœ¼ë¡œ \\(p\\)ì—ì„œ \\(p_{pp}\\)ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ GODE ëª©ì \n\n\n\nEbayesThresh\n\nT = 100\n\n\nt = np.arange(T)/T * 10\n\n\ny_true = 3*np.sin(0.5*t) + 1.2*np.sin(1.0*t) + 0.5*np.sin(1.2*t) \n\n\ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y_true)\n\n\n\n\n- ê´€ì°°í•œ ì‹ í˜¸\n\nplt.plot(t,y,'o')\nplt.plot(t,y_true,'--')\n\n\n\n\n- í“¨ë¦¬ì— ë³€í™˜\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nplt.plot(t,fbar**2) # periodogram \n\n\n\n\n- threshed\n\nfbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\nplt.plot((fbar**2)) # periodogram \nplt.plot((fbar_threshed**2)) \n\n\n\n\n\nplt.plot((fbar**2)[20:80]) # periodogram \nplt.plot((fbar_threshed**2)[20:80]) \n\n\n\n\n- ì—­í“¨ë¦¬ì—ë³€í™˜\n\nyhat = Psi @ fbar_threshed # inverse dft\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y,'.')\nplt.plot(t,y_true,'--')\nplt.plot(t,yhat)\n\n\n\n\n\nplt.figure(figsize=(10,6))\nplt.plot(y,'.')\nplt.plot(y_true)\n\n\n\n\n\n\nResult\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(40,15))\n    fig.suptitle('Figure 1',fontsize=40)\n    \n    ax1.plot(y, 'b.',alpha=0.5)\n    ax1.plot(y_true,'p--',label='True')\n    ax1.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    \n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(y, 'b.',alpha=0.5)\n    ax2.plot(y_true,'p--',label='True')\n    ax2.plot(yhat,label='y hat')\n    ax2.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot((fbar**2)) # periodogram \n    ax3.plot((fbar_threshed**2)) \n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    ax3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n    \n    ax4.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \n    ax4.plot(range(20, 80),(fbar_threshed**2)[20:80]) \n    ax4.set_xticks(range(20, 81, 10))\n    ax4.set_xticklabels(range(20, 81, 10))\n    # ax4.set_xticklabels(['20','40','60'])\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\n\n\n\nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset, inset_axes\nplt.figure(figsize = (20,10))\nplt.suptitle('Figure',fontsize=40)\nax = plt.subplot(1, 1, 1)\nax.plot(range(0,100),(fbar**2))\nax.plot((fbar_threshed**2)) \naxins = inset_axes(ax, 8, 3, loc = 1, bbox_to_anchor=(0.8, 0.8),\n                   bbox_transform = ax.figure.transFigure)\naxins.plot(range(20, 80),(fbar**2)[20:80])\naxins.plot(range(20, 80),(fbar_threshed**2)[20:80]) \naxins.set_xlim(20, 80)\naxins.set_ylim(-0.1, 7)\nmark_inset(ax, axins, loc1=4, loc2=3, fc=\"none\", ec = \"0.01\")\nax.tick_params(axis='y', labelsize=20)\nax.tick_params(axis='x', labelsize=20)\naxins.tick_params(axis='y', labelsize=15)\naxins.tick_params(axis='x', labelsize=15)\n# plt.savefig('Ebayes_Toy.png')\n\n\n\n\n\nfrom matplotlib.patches import ConnectionPatch\nfig = plt.figure(figsize=(20,10))\nplt.suptitle('Figure 1',fontsize=40)\nplot1 = fig.add_subplot(2,2,(1,2))\n\nplot1.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \nplot1.plot(range(20, 80),(fbar_threshed**2)[20:80]) \nplot1.set_xticks(range(20, 81, 10))\nplot1.set_xticklabels(range(20, 81, 10))\nplot1.tick_params(axis='y', labelsize=20)\nplot1.tick_params(axis='x', labelsize=20)\n\nplot3 = fig.add_subplot(2,2,(3,4)) \n\nplot3.plot((fbar**2)) # periodogram \nplot3.plot((fbar_threshed**2)) \nplot3.tick_params(axis='y', labelsize=20)\nplot3.tick_params(axis='x', labelsize=20)\nplot3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n# plot3.fill_between((20, 80), 10, 60, facecolor= \"red\", alpha = 0.2)\nconn1 = ConnectionPatch(xyA = (20, -0.1), coordsA=plot1.transData,\n                       xyB=(20, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn1)\nconn2 = ConnectionPatch(xyA = (79, -0.1), coordsA=plot1.transData,\n                       xyB=(80, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn2)\nplt.show()\n\n\n\n\n\n\nIn article\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: â€˜igraphâ€™\n\n\nR[write to console]: The following objects are masked from â€˜package:statsâ€™:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from â€˜package:baseâ€™:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\nimport rpy2\n\n\nfrom rpy2.robjects.packages import importr\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n#import rpy2\n#import rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nGNAR = importr('GNAR') # import GNAR \n#igraph = importr('igraph') # import igraph \nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n%%R\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\n\n\\(X_i\\)ì—ì„œ \\(\\mu_i\\) ì¶”ì¶œ ê°€ëŠ¥í•˜ëŠ” ê²ƒì„ ì¦ëª…í•  ì˜ˆì œ\n\n%%R\n# png(\"Ebayes_plot1.png\", width=1600, height=800)\npar(mfrow=c(1,2))\npar(cex.axis=2) \npar(cex.lab=2)\nplot(x, type='l', xlab=\"Observed data\", ylab=\"\")\nplot(ebayesthresh(x, sdev=1),type='l', xlab=\"Estimate\", ylab=\"\")\n# dev.off()\n\n\n\n\n\nimport itstgcn\n\n\nitstgcn.make_Psi(T)\n\narray([[ 0.07106691, -0.10050378,  0.10050378, ..., -0.10050378,\n        -0.10050378,  0.07106691],\n       [ 0.10050378, -0.14206225,  0.14184765, ...,  0.14184765,\n         0.14206225, -0.10050378],\n       [ 0.10050378, -0.14184765,  0.14099032, ..., -0.14099032,\n        -0.14184765,  0.10050378],\n       ...,\n       [ 0.10050378,  0.14184765,  0.14099032, ...,  0.14099032,\n        -0.14184765, -0.10050378],\n       [ 0.10050378,  0.14206225,  0.14184765, ..., -0.14184765,\n         0.14206225,  0.10050378],\n       [ 0.07106691,  0.10050378,  0.10050378, ...,  0.10050378,\n        -0.10050378, -0.07106691]])\n\n\ndef trim(f):\n    f = np.array(f)\n    if len(f.shape)==1: f = f.reshape(-1,1)\n    T,N = f.shape\n    Psi = make_Psi(T)\n    fbar = Psi.T @ f # apply dft \n    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n    fhat = Psi @ fbar_threshed # inverse dft \n    return fhat\n\nplt.plot(y)\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T).T@y)\n\n\n\n\n\nplt.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T)@ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\n_T = 1000\n\n\n_t = np.arange(_T)/_T * 10\n\n\n_x = 1.5*np.sin(2*_t)+2*np.random.rand(_T)+1.5*np.sin(4*_t)+1.5*np.sin(8*_t)\nplt.plot(_x)\n\n\n\n\n\nimport itstgcn\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\n_node_ids = {'node1':0,'node2':1}\n\n_FX1 = np.stack([_x,_x],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\ndata1 = pd.DataFrame({'x':_x,'x1':_x,'xer':_x,'xer1':_x})\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=2)\n\n\nmindex = itstgcn.rand_mindex(dataset,mrate=0.7)\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\nPsi\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fst.pdf', format='pdf')\n\n\n\n\nfourier transform\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem(itstgcn.make_Psi(_T).T@np.array(_x),linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem((itstgcn.make_Psi(_T).T@np.array(_x))[:100],linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd_zin.pdf', format='pdf')\n\n\n\n\nEbayesthresh/trim\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem((ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))))[:100],linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd_zout.pdf', format='pdf')\n\n\n\n\nfhat\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3,alpha=0.3)\n    ax1.plot(itstgcn.make_Psi(_T)@ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='Inverse Fourier Transform',lw=5)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fth.pdf', format='pdf')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_fst.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax2 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data',markersize=15)\n    ax2.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=40)\n    ax2.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_snd.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax3 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=40)\n    ax3.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_3rd.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax4 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(138, -1.2, 'o', markersize=230, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(220, -1.5, 'o', markersize=200, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(290, -1.2, 'o', markersize=310, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(455, -0.9, 'o', markersize=280, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=40)\n    ax4.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_4th_1.png')\n\n\n\n\n\n\nFor Paper\n\nT = 500\n\n\nt = np.arange(T)/T * 10\n\n\ny_true = 3*np.sin(0.5*t) + 1.2*np.sin(1.0*t) + 0.5*np.sin(1.2*t) \n\n\ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(20,10))\nplt.plot(t,y_true,color='red',label = 'true')\nplt.plot(t,y,'.',color='black',label = 'f')\nplt.legend(fontsize=15,loc='lower left',facecolor='white', frameon=True)\n# plt.savefig('1.png')\n\n\n\n\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nfbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n\n\nplt.figure(figsize=(20,10))\nplt.plot(fbar**2,color='black')\n# plt.savefig('1.png')\n\n\n\n\n\nplt.figure(figsize=(20,10))\nplt.plot(fbar_threshed**2,color='blue')\n# plt.savefig('2.png')\n\n\n\n\n\nplt.figure(figsize = (20,10))\nax = plt.subplot(1, 1, 1)\nax.plot(range(0,500),(fbar**2),color='black')\nax.plot((fbar_threshed**2),color='blue')\naxins = inset_axes(ax, 8, 3, loc = 1, bbox_to_anchor=(0.8, 0.8),\n                   bbox_transform = ax.figure.transFigure)\naxins.plot(range(100, 200),(fbar**2)[100:200],color='black')\naxins.plot(range(100, 200),(fbar_threshed**2)[100:200],color='blue') \naxins.set_xlim(100, 200)\naxins.set_ylim(-0.1, 7)\nmark_inset(ax, axins, loc1=4, loc2=3, fc=\"none\", ec = \"0.01\")\nax.tick_params(axis='y', labelsize=20)\nax.tick_params(axis='x', labelsize=20)\naxins.tick_params(axis='y', labelsize=15)\naxins.tick_params(axis='x', labelsize=15)\n# plt.savefig('3.png')\n\n\n\n\n\nplt.figure(figsize=(20,10))\nplt.plot((fbar_threshed**2),color='blue')\n# plt.savefig('4.png')\n\n\n\n\n\nfbar_hat = Psi @ fbar_threshed # apply dft \n\n\nplt.figure(figsize=(20,10))\nplt.plot(y_true,'r',label = 'True')\nplt.plot(y,'k.',label='f')\nplt.plot(fbar_hat,color='blue',label = 'fhat')\nplt.legend(fontsize=15,loc='lower left',facecolor='white', frameon=True)\n# plt.savefig('5.png')"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "",
    "text": "Try to divide train and test(ST-GCN WikiMathsDatasetLoader)"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#train",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#train",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n583\n\n\n\nT_train = time\nN = len(data[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([583, 1068, 1])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([583, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([583, 1068, 1]), torch.Size([583, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#test",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#test",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "ST-GCN",
    "text": "ST-GCN\n\nmean_f_train = x_train_mean.reshape(T_train,N,1).float()\n\n\nmean_X = mean_f_train[:438,:,:]\nmean_y = mean_f_train[145:,:,:]\n\n\nmean_X.shape,mean_y.shape\n\n(torch.Size([438, 1068, 1]), torch.Size([438, 1068, 1]))\n\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X,mean_y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [04:17<00:00,  5.15s/it]\n\n\n\nmean_X_fore = mean_f_train[438:,:]\n\n\nmean_fhat = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fore]).detach().numpy()\n\n\nmean_X_fore.shape,x_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068, 1]))"
  },
  {
    "objectID": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn-1",
    "href": "posts/GCN/2023-01-18-Algorithm_traintest_2.html#st-gcn-1",
    "title": "2nd ST-GCN Example dividing train and test",
    "section": "ST-GCN",
    "text": "ST-GCN\n\nlinear_f_train = x_train_linear.clone()\n\n\nlinear_X = linear_f_train[:438,:,:]\nlinear_y = linear_f_train[145:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X,linear_y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [04:20<00:00,  5.22s/it]\n\n\n\nlinear_X_fore = linear_f_train[438:,:]\n\n\nlinear_X_fore.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\nlinear_fhat = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_fore]).detach().numpy()\n\n\nlinear_X_fore.shape,x_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068, 1]))"
  },
  {
    "objectID": "posts/GCN/2023-07-17-toy_example_guebin.html",
    "href": "posts/GCN/2023-07-17-toy_example_guebin.html",
    "title": "Toy example using GNAR",
    "section": "",
    "text": "Import\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nimport torch\nimport itstgcn_gb as itstgcn\nimport random\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef toy_analyze(FX,edges,lags,train_ratio,mrate,filters,epoch,mtype): \n    data_dict = {'edges':edges, 'node_ids':{i:'node'+str(i) for i in range(FX.shape[-1])}, 'FX':FX}\n    save_data(data_dict,'toy_ex_dataset.pkl')\n    data_dict = load_data('toy_ex_dataset.pkl')\n    loader = itstgcn.DatasetLoader(data_dict)\n    dataset = loader.get_dataset(lags=lags)\n    train_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=train_ratio)\n    mindex_rand = itstgcn.rand_mindex(train_dataset,mrate=mrate)\n    train_dataset_miss_rand = itstgcn.miss(train_dataset,mindex_rand,mtype=mtype)\n    train_dataset_padded_rand = itstgcn.padding(train_dataset_miss_rand) # padding(train_dataset_miss,method='linear'ì™€ ê°™ìŒ)\n    lrnr_classic = itstgcn.StgcnLearner(train_dataset_padded_rand)\n    lrnr_proposed = itstgcn.ITStgcnLearner(train_dataset_padded_rand)\n    lrnr_classic.learn(filters=filters,epoch=epoch)\n    lrnr_proposed.learn(filters=filters,epoch=epoch)\n    yhat_classic=lrnr_classic(dataset)['yhat']\n    yhat_proposed=lrnr_proposed(dataset)['yhat']    \n    return yhat_classic,yhat_proposed\n\n\n\nData\n\nT = 50\nt = np.linspace(0,np.pi*2,T)\ne = np.random.randn(T)*0.1\ny1 = np.cos(2*t)\ny2 = np.cos(3*t)\ny3 = y1+y2+e\ny = np.stack([y1,y2,y3],axis=1)\n_, N = y.shape \ntrain_ratio = 0.9\ntest_len = int(T*(1-train_ratio))\ntr_len = T - test_len\ntest_index = [False]*tr_len + [True]*test_len \nedges = [[0,2],[1,2]]\nlags = 8\nmrate = 0.8\nfilters = 2\nepoch = 50\nmtype = 'rand' \n### \nyhat_classic,yhat_proposed = toy_analyze(y,edges,lags,train_ratio,mrate,filters,epoch,mtype)\n\n50/50\n\n\n\nnode = 2\nplt.rcParams['figure.dpi'] = 200\nplt.plot(y[lags:,node],'.')\nplt.plot(yhat_classic[:,node],'--',label='classic')\nplt.plot(yhat_proposed[:,node],'--',label='proposed')\nplt.plot(y[lags:,0]+y[lags:,1],'-',label='true')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f30c156c970>"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html",
    "title": "Padalme GSO_st",
    "section": "",
    "text": "edit"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html#random",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html#random",
    "title": "Padalme GSO_st",
    "section": "random",
    "text": "random\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.3,0.6],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnsnd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-07-02_07-01-12.csv"
  },
  {
    "objectID": "posts/GCN/2023-04-29-pedalme_GSO_st.html#block",
    "href": "posts/GCN/2023-04-29-pedalme_GSO_st.html#block",
    "title": "Padalme GSO_st",
    "section": "block",
    "text": "block\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(10,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[4] = another_list\nmy_list[5] = another_list\nanother_list = list(range(5,20))\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[10] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnsnd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-07-02_07-19-21.csv\n\n\n\n# df1 = pd.read_csv('./simulation_results/2023-04-13_20-37-59.csv')\n\n\n# data = pd.concat([df1],axis=0);data"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ì¼ì •",
    "text": "missing ì¼ì •\n\nstgcn_train1 = []\nstgcn_test1 = []\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    for epoch in range(50):\n        for time, (xt,yt) in enumerate(zip(X,y)):\n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n    \n    train_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    stgcn_train1.append(train_mse_total_stgcn.tolist())\n    stgcn_test1.append(test_mse_total_stgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_train1);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë‹¤ë¥´ê²Œ",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë‹¤ë¥´ê²Œ",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ë‹¤ë¥´ê²Œ",
    "text": "missing ë‹¤ë¥´ê²Œ\n\nstgcn_train2 = []\nstgcn_test2 = []\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    for epoch in range(50):\n        for time, (xt,yt) in enumerate(zip(X,y)):\n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n    \n    train_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean() \n    \n    stgcn_train2.append(train_mse_total_stgcn.tolist())\n    stgcn_test2.append(test_mse_total_stgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(stgcn_test2);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •-1",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •-1",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ì¼ì •",
    "text": "missing ì¼ì •\n\nestgcn_train1 = []\nestgcn_test1 = []\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\ny = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    signal = interpolated_signal.copy()\n    for epoch in range(50):\n        signal = update_from_freq_domain(signal,missing_index)\n        X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n        y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for time, (xt,yt) in enumerate(zip(X,y)):        \n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n    train_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    estgcn_train1.append(train_mse_total_estgcn.tolist())\n    estgcn_test1.append(test_mse_total_estgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_train1); \n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë§¤ë²ˆ-ë‹¤ë¥´ê²Œ",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë§¤ë²ˆ-ë‹¤ë¥´ê²Œ",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ë§¤ë²ˆ ë‹¤ë¥´ê²Œ",
    "text": "missing ë§¤ë²ˆ ë‹¤ë¥´ê²Œ\n\nestgcn_train2 = []\nestgcn_test2 = []\n\nXX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n    y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n    net = RecurrentGCN(node_features=1, filters=4)\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n    net.train()\n    signal = interpolated_signal.copy()\n    for epoch in range(50):\n        signal = update_from_freq_domain(signal,missing_index)\n        X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n        y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for time, (xt,yt) in enumerate(zip(X,y)):        \n            yt_hat = net(xt, edge_index, edge_attr)\n            cost = torch.mean((yt_hat-yt)**2)\n            cost.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n    yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n    yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n    train_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\n    test_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n    \n    estgcn_train2.append(train_mse_total_estgcn.tolist())\n    estgcn_test2.append(test_mse_total_estgcn.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(estgcn_test2);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •-2",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ì¼ì •-2",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ì¼ì •",
    "text": "missing ì¼ì •\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\nX = np.array(torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:].squeeze())\ny = np.array(torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:].squeeze())\n\nXX = np.array(torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float().squeeze())\nyy = np.array(torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float().squeeze())\n\nreal_y = np.array(torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:])\n\n\n%R -i X\n%R -i XX\n\n\n%%R\ngnar_train1 <- matrix(ncol=1,nrow=100)\ngnar_test1 <- matrix(ncol=1,nrow=100)\nfor(i in 1:100){\n  answer <- GNARfit(vts = X, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\n  prediction <- predict(answer,n.ahead=40)\n  \n  train_mse_total_gnar <- mean(residuals(answer)**2)\n  test_mse_total_gnar <- mean((XX - prediction[1:40])**2)\n  \n  gnar_train1[i] <- train_mse_total_gnar\n  gnar_test1[i] <- train_mse_total_gnar\n}\n\n\n%R -o gnar_train1\n%R -o gnar_test1\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_train1);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_test1);"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë‹¤ë¥´ê²Œ-1",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html#missing-ë‹¤ë¥´ê²Œ-1",
    "title": "Class of Method(GNAR) lag 1 80% Missing repeat",
    "section": "missing ë‹¤ë¥´ê²Œ",
    "text": "missing ë‹¤ë¥´ê²Œ\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n\ngnar_train2 = []\ngnar_test2 = []\n\nyy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n\nfor i in range(100):\n    \n    _zero = Missing(fiveVTS_train)\n    _zero.miss(percent = 0.8)\n    _zero.second_linear()\n\n    missing_index = _zero.number\n    interpolated_signal = _zero.train_linear\n\n    X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n    answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n    predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n    \n    train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n    test_mse_total_gnar = ((yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n    \n    gnar_train2.append(train_mse_total_gnar.tolist())\n    gnar_test2.append(test_mse_total_gnar.tolist())\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_train2);\n\n\n\n\n\nplt.figure(figsize=(12, 8))\nplt.boxplot(gnar_test2);"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and inter_method=='cubic' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' and inter_method!='cubic' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "Simulation",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-04-30_13-00-12.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-30_13-31-32.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-30_14-01-49.csv')\ndf4 = pd.read_csv('./simulation_results/2023-04-30_14-31-56.csv')\ndf5 = pd.read_csv('./simulation_results/2023-04-30_15-02-23.csv')\ndf6 = pd.read_csv('./simulation_results/2023-04-30_15-33-03.csv')\ndf7 = pd.read_csv('./simulation_results/2023-04-30_16-07-43.csv')\ndf8 = pd.read_csv('./simulation_results/2023-04-30_16-41-35.csv')\ndf9 = pd.read_csv('./simulation_results/2023-04-30_17-14-51.csv')\ndf10 = pd.read_csv('./simulation_results/2023-04-30_17-49-34.csv')\ndf11 = pd.read_csv('./simulation_results/2023-04-30_18-21-29.csv')\ndf12 = pd.read_csv('./simulation_results/2023-04-30_18-50-24.csv')\ndf13 = pd.read_csv('./simulation_results/2023-04-30_20-33-28.csv')\ndf14 = pd.read_csv('./simulation_results/2023-05-04_16-40-05.csv')\ndf15 = pd.read_csv('./simulation_results/2023-05-04_17-34-00.csv')\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype!='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-1",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-1",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR'\").groupby('mrate')['mse'].unique()\n\nmrate\n0.0    [1.2959295511245728, 1.2547194957733154]\n0.3    [1.2959295511245728, 1.2547194957733154]\n0.5    [1.2959295511245728, 1.2547194957733154]\nName: mse, dtype: object\n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-1",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-1",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-04-27_07-50-11.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-27_22-09-07.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-28_14-40-59.csv')\ndf4 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n# df5 = pd.read_csv('./simulation_results/2023-05-14_19-46-46.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/wikimath_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/wikimath_block.csv')\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#missing-values-on-the-same-nodes",
    "title": "Simulation",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\ndf1 = pd.read_csv('./simulation_results/2023-04-29_03-57-07.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-04-29_20-15-46.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-30_16-19-58.csv') # STGCN IT-STGCN\n# 60% í™•ì¸í•˜ê³  ë‹¤ì‹œ ëŒë¦¬ê¸°\ndf4 = pd.read_csv('./simulation_results/2023-05-05_04-21-57.csv') # STGCN IT-STGCN 60%\ndf5 = pd.read_csv('./simulation_results/2023-05-06_11-34-46.csv') # STGCN IT-STGCN\ndf6 = pd.read_csv('./simulation_results/2023-05-06_23-43-35.csv') # STGCN IT-STGCN\ndf7 = pd.read_csv('./simulation_results/2023-05-07_14-06-44.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/wikimath_GSO_st.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\narray([], dtype=float64)\n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-2",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndf1 = pd.read_csv('./simulation_results/2023-04-17_06-05-37.csv') # STGCN IT-STGCN 70%\ndf2 = pd.read_csv('./simulation_results/2023-04-17_08-05-26.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-17_13-41-19.csv') # STGCN IT-STGCN\ndf4 = pd.read_csv('./simulation_results/2023-04-17_15-44-21.csv') # STGCN IT-STGCN\ndf5 = pd.read_csv('./simulation_results/2023-04-17_21-27-38.csv') # STGCN IT-STGCN\n# df6 = pd.read_csv('./simulation_results/2023-04-15_15-00-32.csv') # GNAR 30%, 50%, 70% # ë­”ê°€ ì¼ë‹¨ í•„ìš”ì—†ì–´ì„œ ë°ì´í„°ì…‹ì—ì„œ ëºŒ\ndf7 = pd.read_csv('./simulation_results/2023-04-18_05-01-55.csv') # STGCN IT-STGCN\ndf8 = pd.read_csv('./simulation_results/2023-04-18_06-14-06.csv') # STGCN IT-STGCN\ndf9 = pd.read_csv('./simulation_results/2023-04-18_17-32-30.csv') # STGCN IT-STGCN\ndf10 = pd.read_csv('./simulation_results/2023-04-19_01-52-24.csv') # STGCN IT-STGCN\ndf11 = pd.read_csv('./simulation_results/2023-04-19_07-50-52.csv') # STGCN IT-STGCN\ndf12 = pd.read_csv('./simulation_results/2023-04-19_09-30-25.csv') # STGCN IT-STGCN\ndf13 = pd.read_csv('./simulation_results/2023-04-19_15-32-55.csv') # STGCN IT-STGCN\ndf14 = pd.read_csv('./simulation_results/2023-04-19_17-12-06.csv') # STGCN IT-STGCN\ndf15 = pd.read_csv('./simulation_results/2023-04-19_23-07-36.csv') # STGCN IT-STGCN\ndf16 = pd.read_csv('./simulation_results/2023-04-20_00-46-43.csv') # STGCN IT-STGCN\ndf17 = pd.read_csv('./simulation_results/2023-04-20_06-51-34.csv') # STGCN IT-STGCN\ndf18 = pd.read_csv('./simulation_results/2023-04-20_08-30-27.csv') # STGCN IT-STGCN\ndf19 = pd.read_csv('./simulation_results/2023-04-20_14-28-35.csv') # STGCN IT-STGCN\ndf20 = pd.read_csv('./simulation_results/2023-04-20_16-08-39.csv') # STGCN IT-STGCN\ndf21 = pd.read_csv('./simulation_results/2023-04-20_22-09-37.csv') # STGCN IT-STGCN\ndf22 = pd.read_csv('./simulation_results/2023-04-20_23-48-26.csv') # STGCN IT-STGCN\ndf23 = pd.read_csv('./simulation_results/2023-04-21_05-36-47.csv') # STGCN IT-STGCN\ndf24 = pd.read_csv('./simulation_results/2023-04-21_15-26-00.csv') # STGCN IT-STGCN\ndf25 = pd.read_csv('./simulation_results/2023-04-21_23-27-11.csv') # STGCN IT-STGCN\ndf26 = pd.read_csv('./simulation_results/2023-04-22_07-46-08.csv') # STGCN IT-STGCN\ndf27 = pd.read_csv('./simulation_results/2023-04-22_15-45-20.csv') # STGCN IT-STGCN\ndf28 = pd.read_csv('./simulation_results/2023-04-22_22-57-31.csv') # STGCN IT-STGCN\ndf29 = pd.read_csv('./simulation_results/2023-04-23_07-00-15.csv') # STGCN IT-STGCN\ndf30 = pd.read_csv('./simulation_results/2023-04-23_15-18-02.csv') # STGCN IT-STGCN\ndf31 = pd.read_csv('./simulation_results/2023-04-23_15-22-36.csv') # GNAR 70%\n# baseline\ndf32 = pd.read_csv('./simulation_results/2023-04-29_06-54-40.csv') # GNAR \ndf33 = pd.read_csv('./simulation_results/2023-04-30_18-55-12.csv')\ndf34 = pd.read_csv('./simulation_results/2023-05-01_02-55-33.csv')\ndf35 = pd.read_csv('./simulation_results/2023-05-01_10-21-15.csv')\ndf36 = pd.read_csv('./simulation_results/2023-05-01_19-23-57.csv')\ndf37 = pd.read_csv('./simulation_results/2023-05-02_01-10-53.csv')\ndf38 = pd.read_csv('./simulation_results/2023-05-02_08-26-53.csv')\ndf39 = pd.read_csv('./simulation_results/2023-05-02_16-00-40.csv')\ndf40 = pd.read_csv('./simulation_results/2023-05-03_00-34-09.csv')\ndf41 = pd.read_csv('./simulation_results/2023-05-03_08-04-42.csv')\ndf42 = pd.read_csv('./simulation_results/2023-05-03_15-50-50.csv')\ndf43 = pd.read_csv('./simulation_results/2023-05-03_23-46-56.csv')\ndf44 = pd.read_csv('./simulation_results/2023-05-04_05-22-59.csv')\ndf45 = pd.read_csv('./simulation_results/2023-05-04_09-22-37.csv')\ndf46 = pd.read_csv('./simulation_results/2023-05-04_15-00-57.csv')\ndf47 = pd.read_csv('./simulation_results/2023-05-04_23-41-21.csv')\ndf48 = pd.read_csv('./simulation_results/2023-05-05_07-23-04.csv')\ndf49 = pd.read_csv('./simulation_results/2023-05-05_15-03-17.csv')\ndf50 = pd.read_csv('./simulation_results/2023-05-06_05-18-07.csv')\ndf51 = pd.read_csv('./simulation_results/2023-05-06_12-57-14.csv')\ndf52 = pd.read_csv('./simulation_results/2023-05-06_19-10-23.csv')\ndf53 = pd.read_csv('./simulation_results/2023-05-07_03-20-10.csv')\ndf54 = pd.read_csv('./simulation_results/2023-05-07_11-26-24.csv')\ndf55 = pd.read_csv('./simulation_results/2023-05-08_00-04-56.csv')\ndf56 = pd.read_csv('./simulation_results/2023-05-08_04-27-01.csv')\ndf57 = pd.read_csv('./simulation_results/2023-05-08_10-06-55.csv')\ndf58 = pd.read_csv('./simulation_results/2023-05-08_17-50-36.csv')\ndf59 = pd.read_csv('./simulation_results/2023-05-09_03-28-08.csv')\ndf60 = pd.read_csv('./simulation_results/2023-05-09_11-08-10.csv')\ndf61 = pd.read_csv('./simulation_results/2023-05-09_20-11-45.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,\n                 df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,\n                 df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,\n                 df51,df52,df53,df54,df55,df56,df57,df58,df59,df60,df61],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/windmillsmall.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/windmillsmall.csv')\n\n\ndata.query(\"method=='GNAR' and mrate ==0\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-2",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR' and mrate !=0\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-2",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-2",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-04-24_02-48-08.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-04-24_10-57-10.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-04-24_18-53-34.csv') # STGCN IT-STGCN\ndf4 = pd.read_csv('./simulation_results/2023-04-25_02-30-27.csv') # STGCN IT-STGCN\ndf5 = pd.read_csv('./simulation_results/2023-04-25_10-48-46.csv') # STGCN IT-STGCN\ndf6 = pd.read_csv('./simulation_results/2023-04-25_10-53-14.csv') # GNAR \ndf7 = pd.read_csv('./simulation_results/2023-04-25_18-40-53.csv') # STGCN IT-STGCN\ndf8 = pd.read_csv('./simulation_results/2023-04-25_23-30-08.csv') # STGCN IT-STGCN\ndf9 = pd.read_csv('./simulation_results/2023-04-26_04-15-00.csv') # STGCN IT-STGCN\ndf10 = pd.read_csv('./simulation_results/2023-04-27_07-59-36.csv') # STGCN IT-STGCN\ndf11 = pd.read_csv('./simulation_results/2023-04-27_15-29-00.csv') # STGCN IT-STGCN\ndf12 = pd.read_csv('./simulation_results/2023-04-27_23-37-18.csv') # STGCN IT-STGCN\ndf13 = pd.read_csv('./simulation_results/2023-04-28_08-21-54.csv') # STGCN IT-STGCN\ndf14 = pd.read_csv('./simulation_results/2023-04-28_16-06-55.csv') # STGCN IT-STGCN\ndf15 = pd.read_csv('./simulation_results/2023-04-28_21-19-37.csv') # STGCN IT-STGCN\ndf16 = pd.read_csv('./simulation_results/2023-04-29_03-07-03.csv') # STGCN IT-STGCN\ndf17 = pd.read_csv('./simulation_results/2023-04-29_09-00-42.csv') # STGCN IT-STGCN\ndf18 = pd.read_csv('./simulation_results/2023-04-29_19-07-49.csv') # STGCN IT-STGCN\ndf19 = pd.read_csv('./simulation_results/2023-04-30_05-14-07.csv') # STGCN IT-STGCN\ndf20 = pd.read_csv('./simulation_results/2023-04-30_15-23-16.csv') # STGCN IT-STGCN\ndf21 = pd.read_csv('./simulation_results/2023-05-01_00-16-37.csv') # STGCN IT-STGCN\ndf22 = pd.read_csv('./simulation_results/2023-05-01_07-41-52.csv') # STGCN IT-STGCN\ndf23 = pd.read_csv('./simulation_results/2023-05-01_16-21-41.csv') # STGCN IT-STGCN\ndf24 = pd.read_csv('./simulation_results/2023-05-01_23-38-23.csv') # STGCN IT-STGCN\ndf25 = pd.read_csv('./simulation_results/2023-05-02_13-51-13.csv') # STGCN IT-STGCN\ndf26 = pd.read_csv('./simulation_results/2023-05-02_21-43-26.csv') # STGCN IT-STGCN\ndf27 = pd.read_csv('./simulation_results/2023-05-03_06-04-32.csv') # STGCN IT-STGCN\ndf28 = pd.read_csv('./simulation_results/2023-05-03_13-43-11.csv') # STGCN IT-STGCN\ndf29 = pd.read_csv('./simulation_results/2023-05-03_21-58-04.csv') # STGCN IT-STGCN\ndf30 = pd.read_csv('./simulation_results/2023-05-04_04-39-00.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,\n                 df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/windmillsmall_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/windmillsmall_block.csv')\n\n\ndata.query(\"method=='GNAR'\")['mse'].unique()\n\narray([1.64923024])\n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#baseline-3",
    "title": "Simulation",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#random-3",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndata.query(\"method=='GNAR'\").groupby('mrate')['mse'].unique()\n\nmrate\n0.0    [1.0619367361068726, 1.068463921546936]\n0.3    [1.0619367361068726, 1.068463921546936]\n0.4    [1.0619367361068726, 1.068463921546936]\n0.8    [1.0619367361068726, 1.068463921546936]\n0.9    [1.0619367361068726, 1.068463921546936]\nName: mse, dtype: object\n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.8 and mrate!=0.9\").sort_values('lags').plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)\n\n\n                                                \n\n\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR' and mrate!=0.3 and mrate!=0.4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-3",
    "href": "posts/GCN/2023-04-05-Simulation_boxplot.html#block-3",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/2023-05-04_21-03-21.csv')\ndf2 = pd.read_csv('./simulation_results/2023-05-05_12-10-44.csv')\ndf3 = pd.read_csv('./simulation_results/2023-05-06_12-42-22.csv')\ndf4 = pd.read_csv('./simulation_results/2023-05-06_15-40-47.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation/monte_block.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation/monte_block.csv')\n\n\ndata.query(\"mtype=='block' and method=='GNAR'\")['mse'].mean()\n\n1.0652003288269043\n\n\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html",
    "title": "TGCN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random",
    "title": "TGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block",
    "title": "TGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-1",
    "title": "TGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-2",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-2",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "TGCN_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-21_22-29-02.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-21_22-51-34.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/TGCN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/TGCN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-3",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-3",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "TGCN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-27_03-08-38.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-27_15-49-21.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-27_09-33-29.csv') \n\n\ndata = pd.concat([df1],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/TGCN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/TGCN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-4",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-4",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "TGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#random-5",
    "title": "TGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html#block-5",
    "title": "TGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html",
    "href": "posts/GCN/2023-04-25-note_matrix.html",
    "title": "Note_weight amatrix",
    "section": "",
    "text": "weight matrix\n- í•˜ì´í¼íŒŒë¼ë©”í„°\n- wt,ws,f\n- fë¥¼ í¼ì¹¨\n- í¼ì³ì§„ fì— ëŒ€ì‘í•˜ëŠ” W ìƒì„±\n- trim\nì„ì˜ë¡œ ftrimed_flattenì´ f_flattenê³¼ ê°™ë‹¤ê³  ìƒê°í•˜ì.\n- ftrimed"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#chickenpox",
    "href": "posts/GCN/2023-04-25-note_matrix.html#chickenpox",
    "title": "Note_weight amatrix",
    "section": "Chickenpox",
    "text": "Chickenpox\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\na = loader1.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(20, 20)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- fë¥¼ í¼ì¹¨\n\nf_flatten = f.reshape(-1,1)\nf_flatten\n\narray([[-1.08135724e-03],\n       [-7.11136085e-01],\n       [-3.22808515e+00],\n       ...,\n       [ 4.71099041e-02],\n       [ 2.45684924e+00],\n       [-3.44296107e-01]])\n\n\n- í¼ì³ì§„ fì— ëŒ€ì‘í•˜ëŠ” W ìƒì„±\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\narray([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]])\n\n\n\nnp.save('./weight_st/W_chickenpox.npy', W_flatten)\n\n\nnp.load('./weight_st/W_chickenpox.npy')\n\narray([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]])\n\n\n\nd = np.array(W_flatten.sum(axis=1))\n\n\nD = np.diag(d)\n\n\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-W_flatten) @ np.diag(1/np.sqrt(d)))\n\n\nlamb, Psi = np.linalg.eigh(L)\n\n\nnp.save('./weight_st/Psi_chickenpox.npy', Psi)\n\n\nnp.load('./weight_st/Psi_chickenpox.npy')\n\narray([[ 1.04115841e-02, -1.47242159e-02,  1.47242532e-02, ...,\n         6.41186713e-04, -4.27546925e-04,  2.13800213e-04],\n       [ 8.23107997e-03, -1.16404883e-02,  1.16404382e-02, ...,\n        -4.77715858e-04,  3.18549731e-04, -1.59296626e-04],\n       [ 8.23107997e-03, -1.16404502e-02,  1.16402861e-02, ...,\n         2.85275946e-04, -1.90235274e-04,  9.51330388e-05],\n       ...,\n       [ 8.23107997e-03,  1.16404565e-02,  1.16403112e-02, ...,\n        -6.65738542e-04, -4.43946869e-04, -2.22009806e-04],\n       [ 1.04115841e-02,  1.47242028e-02,  1.47242009e-02, ...,\n         1.35543431e-04,  9.03781585e-05,  4.51938438e-05],\n       [ 8.23107997e-03,  1.16404680e-02,  1.16403570e-02, ...,\n         5.65995233e-04,  3.77431091e-04,  1.88745843e-04]])\n\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#pedalme",
    "href": "posts/GCN/2023-04-25-note_matrix.html#pedalme",
    "title": "Note_weight amatrix",
    "section": "Pedalme",
    "text": "Pedalme\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\na = loader2.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(wt).shape\n\n(34, 34)\n\n\n\nnp.array(ws).shape\n\n(15, 15)\n\n\n\n34*15\n\n510\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- fë¥¼ í¼ì¹¨\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- í¼ì³ì§„ fì— ëŒ€ì‘í•˜ëŠ” W ìƒì„±\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\narray([[1.        , 0.42545896, 0.15735536, ..., 0.        , 0.        ,\n        0.        ],\n       [0.42545896, 1.        , 0.06751402, ..., 0.        , 0.        ,\n        0.        ],\n       [0.15735536, 0.06751402, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 1.        , 0.07069877,\n        0.06899971],\n       [0.        , 0.        , 0.        , ..., 0.07069877, 1.        ,\n        0.32983841],\n       [0.        , 0.        , 0.        , ..., 0.06899971, 0.32983841,\n        1.        ]])\n\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_pedalme.npy', W_flatten)\n\n\nnp.load('./weight_st/W_pedalme.npy')\n\narray([[1.        , 0.42545896, 0.15735536, ..., 0.        , 0.        ,\n        0.        ],\n       [0.42545896, 1.        , 0.06751402, ..., 0.        , 0.        ,\n        0.        ],\n       [0.15735536, 0.06751402, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 1.        , 0.07069877,\n        0.06899971],\n       [0.        , 0.        , 0.        , ..., 0.07069877, 1.        ,\n        0.32983841],\n       [0.        , 0.        , 0.        , ..., 0.06899971, 0.32983841,\n        1.        ]])\n\n\n\nd = np.array(W_flatten.sum(axis=1))\n\n\nD = np.diag(d)\n\n\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-W_flatten) @ np.diag(1/np.sqrt(d)))\n\n\nlamb, Psi = np.linalg.eigh(L)\n\n\nPsi.T.shape\n\n(510, 510)\n\n\n\nPsi.shape\n\n(510, 510)\n\n\n\nnp.save('./weight_st/Psi_pedalme.npy', Psi)\n\n\nnp.load('./weight_st/Psi_pedalme.npy')\n\narray([[ 4.61219573e-02, -6.52404719e-02,  6.52791904e-02, ...,\n        -4.33862149e-04, -2.17206920e-04,  8.97548015e-05],\n       [ 4.44297451e-02, -6.28451968e-02,  6.28773329e-02, ...,\n        -2.56832039e-05, -1.49624707e-05,  7.00873447e-06],\n       [ 3.51291880e-02, -4.95907787e-02,  4.93238061e-02, ...,\n        -2.71803598e-02, -1.77647577e-02,  8.79413561e-03],\n       ...,\n       [ 3.75563137e-02,  5.30576275e-02,  5.28917644e-02, ...,\n         5.85830960e-03, -4.16888716e-03, -2.15565030e-03],\n       [ 3.87057680e-02,  5.47153694e-02,  5.46437177e-02, ...,\n         1.08555123e-03, -6.10976014e-04, -2.76608545e-04],\n       [ 4.03127107e-02,  5.70025038e-02,  5.69740769e-02, ...,\n        -2.05662084e-04,  9.91534370e-05,  4.05213281e-05]])"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#wikimath",
    "href": "posts/GCN/2023-04-25-note_matrix.html#wikimath",
    "title": "Note_weight amatrix",
    "section": "Wikimath",
    "text": "Wikimath\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\na = loader3.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nnp.array(mtr).shape\n\n(2, 27079)\n\n\n\nnp.array(mtr2).shape\n\n(27079,)\n\n\n\nmtr\n\narray([[   0,    0,    0, ..., 1056, 1063, 1065],\n       [   1,    2,    3, ..., 1059, 1064, 1066]])\n\n\n\npd.DataFrame(mtr2).iloc[:,0].unique()\n\narray([ 1,  4,  2,  5,  3,  6,  7,  9,  8, 12, 10, 13, 16, 11])\n\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(1068, 1068)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- fë¥¼ í¼ì¹¨\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- í¼ì³ì§„ fì— ëŒ€ì‘í•˜ëŠ” W ìƒì„±\n\nN = len(ws)\nT = len(wt)\nIs = np.eye(N,N)\nlst = [[0]*T for t in range(T)]\n\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_wikimath.npy', W_flatten)\n\n\nnp.load('./weight_st/W_wikimath.npy')"
  },
  {
    "objectID": "posts/GCN/2023-04-25-note_matrix.html#windmillsmall",
    "href": "posts/GCN/2023-04-25-note_matrix.html#windmillsmall",
    "title": "Note_weight amatrix",
    "section": "Windmillsmall",
    "text": "Windmillsmall\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader6 = WindmillOutputSmallDatasetLoader()\n\n\na = loader6.get_dataset(lags=1)\n\ntime,number of nodes\n\nT,N,_ = np.array(a.features).shape\n\n- wt,ws,f\n\nwt = np.zeros((T,T))\nfor i in range(T):\n    for j in range(T):\n        if i==j :\n            wt[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            wt[i,j] = 1\n\n\nmtr = a.edge_index\nmtr2 = a.edge_weight\n\n\nws = np.zeros((N,N))\nfor i in range(N):\n    for j in range(mtr2.shape[0]):\n        if mtr[0][j] == i :\n            ws[i,mtr[1][j]] = mtr2[j]\n\n\nnp.array(ws).shape\n\n(11, 11)\n\n\n\nf = np.array(a.features).reshape(T,N)\n\n- fë¥¼ í¼ì¹¨\n\nf_flatten = f.reshape(-1,1)\n# f_flatten\n\n- í¼ì³ì§„ fì— ëŒ€ì‘í•˜ëŠ” W ìƒì„±\n\ndef flatten_weight(ws,wt):\n  N = len(ws)\n  T = len(wt)\n  Is = np.eye(N,N)\n  lst = [[0]*T for t in range(T)]\n  for i in range(T):\n    for j in range(T):\n      if i==j: \n        lst[i][j] = ws \n      elif abs(i-j)==1:\n        lst[i][j] = Is\n      else:\n        lst[i][j] = Is*0\n  return np.concatenate([np.concatenate(l,axis=1) for l in lst],axis=0)\n\n\nW_flatten = flatten_weight(ws,wt)\nW_flatten\n\n- trim\nftrimed_flatten = trim(f_flatten,W_flatten)\n\nnp.save('./weight_st/W_windmillsmall.npy', W_flatten)\n\n\nnp.load('./weight_st/W_windmillsmall.npy')"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "",
    "text": "PyTorch Geometric Temporal"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Applications",
    "text": "Applications\n\nEpidemiological Forecasting\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [02:40<00:00,  1.24it/s]\n\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 1.0232\n\nMSE: 1.0247\n\n\n\n\nShape Check (1)\n\na = torch.randn(20, 1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\n\n\nDoesnâ€™t it have to â€˜y_hatâ€™ be the same shape as snapshot.y?\n\nIf we want to compare the y_hat from the model with the values y, the same shape is appropriate to evaluate.\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:27<00:00,  2.30it/s]\n\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 1.0232\n\nMSE: 1.2844\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(20, 1).reshape(-1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])"
  },
  {
    "objectID": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "href": "posts/GCN/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Web Traffic Prediction",
    "text": "Web Traffic Prediction\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [31:26<00:00, 37.73s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 0.7760\n\nMSE: 0.7939\n\n\n\n\nShape Check (1)\n\na = torch.randn(1068, 1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\nIf the code changes the shape of y_hat?\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [36:39<00:00, 43.99s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# >>> MSE: 0.7760\n\nMSE: 0.7807\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(1068, 1).reshape(-1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068]) torch.Size([1068]) torch.Size([1068])\n\n\n\nFix : https://github.com/benedekrozemberczki/pytorch_geometric_temporal/issues/231"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      2\n      1.212\n      0.026\n    \n    \n      1\n      4\n      STGCN\n      2\n      1.206\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      IT-STGCN\n      2\n      1.219\n      0.022\n    \n    \n      1\n      0.3\n      4\n      STGCN\n      2\n      1.221\n      0.029\n    \n    \n      2\n      0.5\n      4\n      IT-STGCN\n      2\n      1.220\n      0.027\n    \n    \n      3\n      0.5\n      4\n      STGCN\n      2\n      1.236\n      0.035\n    \n    \n      4\n      0.6\n      4\n      IT-STGCN\n      2\n      1.215\n      0.024\n    \n    \n      5\n      0.6\n      4\n      STGCN\n      2\n      1.242\n      0.041\n    \n    \n      6\n      0.7\n      4\n      IT-STGCN\n      2\n      1.226\n      0.033\n    \n    \n      7\n      0.7\n      4\n      STGCN\n      2\n      1.245\n      0.052\n    \n    \n      8\n      0.8\n      4\n      IT-STGCN\n      2\n      1.236\n      0.028\n    \n    \n      9\n      0.8\n      4\n      STGCN\n      2\n      1.261\n      0.048"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      4\n      IT-STGCN\n      1.217\n      0.023\n    \n    \n      1\n      0.125\n      4\n      STGCN\n      1.246\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.878\n      0.047\n    \n    \n      1\n      16\n      STGCN\n      0.892\n      0.054"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.850\n      0.022\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.050\n      0.036\n    \n    \n      2\n      0.5\n      linear\n      16\n      IT-STGCN\n      0.899\n      0.023\n    \n    \n      3\n      0.5\n      linear\n      16\n      STGCN\n      1.514\n      0.050\n    \n    \n      4\n      0.6\n      linear\n      16\n      IT-STGCN\n      0.997\n      0.030\n    \n    \n      5\n      0.6\n      linear\n      16\n      STGCN\n      1.807\n      0.064\n    \n    \n      6\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.371\n      0.072\n    \n    \n      7\n      0.8\n      linear\n      16\n      STGCN\n      2.172\n      0.186"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-1",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.883365\n      0.045500\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.889922\n      0.033144\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.901308\n      0.054389\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.884887\n      0.041756"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      4\n      IT-STGCN\n      1.170\n      0.040\n    \n    \n      1\n      4\n      4\n      STGCN\n      1.191\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.202\n      0.029\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.267\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.039\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.256\n      0.038\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.040\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.364\n      0.068\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.259\n      0.042\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.365\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-2",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.031\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.211\n      0.023\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.195\n      0.029\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.248\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#w_st",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.191\n      0.041\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.264\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.193\n      0.033\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.250\n      0.049\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.260\n      0.084\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.340\n      0.059\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.231\n      0.044\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.355\n      0.068\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.182\n      0.045\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.225\n      0.030\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.185\n      0.035\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.249\n      0.027"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      64\n      IT-STGCN\n      0.643\n      0.024\n    \n    \n      1\n      8\n      64\n      STGCN\n      0.645\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.628\n      0.020\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.674\n      0.020\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.815\n      0.058\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.407\n      0.117"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-3",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.640461\n      0.019198\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.637772\n      0.012983"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.617\n      0.011\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.823\n      0.048"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      0.994\n      0.014\n    \n    \n      1\n      8\n      STGCN\n      0.992\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.116\n      0.021\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.574\n      0.104"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-4",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      0.985\n      0.002\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      0.985\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#baseline-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.969\n      0.012\n    \n    \n      1\n      4\n      STGCN\n      0.970\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#random-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.031532\n      0.028135\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.140193\n      0.061301"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html#block-5",
    "title": "GCLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.958620\n      0.007766\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.955762\n      0.005461"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html",
    "title": "2nd ITSTGCN",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn",
    "title": "2nd ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn",
    "title": "2nd ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar",
    "title": "2nd ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#stgcn-1",
    "title": "2nd ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#enhencement-of-stgcn-1",
    "title": "2nd ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html#gnar-1",
    "title": "2nd ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "",
    "text": "ST-GCN Dataset WikiMathsDatasetLoader"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#train",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#train",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 4]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n580\n\n\n\nT_train = time\nN = len(data_train[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([580, 1068, 4])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([580, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([580, 1068, 4]), torch.Size([580, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#test",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#test",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 4]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 4])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 4]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)",
    "text": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)\nì‹œë‚˜ë¦¬ì˜¤1\n\nmissing rate: 0%\në³´ê°„ë°©ë²•: None\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([x_train_f[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = x_train_f[4:T_train,:].reshape(T_train-4,N,-1).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [05:47<00:00,  6.96s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y.squeeze()-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y.squeeze()-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: â€˜igraphâ€™\n\n\nR[write to console]: The following objects are masked from â€˜package:statsâ€™:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from â€˜package:baseâ€™:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train_f)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((yy-gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n GNAR: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(4,580),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(4,583),gnar_train[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(583,728),gnar_test[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "ì‹œë‚˜ë¦¬ì˜¤2",
    "text": "ì‹œë‚˜ë¦¬ì˜¤2\nì‹œë‚˜ë¦¬ì˜¤2\n\nmissing rate: 50%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train[:,:,0][:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\nimport numpy as np\n\nT= 100\nN= 5\nlag =4 \n\nsignal=np.arange(T*N).reshape(T,N)\n\nX= np.stack([signal[i:(T-lag+i),:] for i in range(lag)],axis=-1)\nX.shape\n\ny=signal[lag:].reshape(T-lag,N,1)\ny.shape\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [06:23<00:00,  7.67s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [07:11<00:00,  8.63s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\ny_train.shape,T_train\n\n(torch.Size([580, 1068]), 580)\n\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "ì‹œë‚˜ë¦¬ì˜¤3",
    "text": "ì‹œë‚˜ë¦¬ì˜¤3\nì‹œë‚˜ë¦¬ì˜¤3\n\nmissing rate: 80%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train_f[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [06:40<00:00,  8.01s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [07:18<00:00,  8.77s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "href": "posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "title": "Class of Method(WikiMath) lag 4",
    "section": "ì‹œë‚˜ë¦¬ì˜¤4",
    "text": "ì‹œë‚˜ë¦¬ì˜¤4\nì‹œë‚˜ë¦¬ì˜¤4\n\nmissing rate: 30%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train_f)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train_f[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [06:32<00:00,  7.86s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train[4:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(T_train-4+i),:] for i in range(4)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[4:,:]).float()\n\n\nXX = x_test\nyy = y_test\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=4, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(T_train+i),:] for i in range(4)],axis = -1)).reshape(T_train,N,4).float()\n    y = torch.tensor(signal).reshape(-1,N,1).float()[4:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [07:13<00:00,  8.66s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat.squeeze()).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat.squeeze()).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_gnar = np.array(torch.concat([X[:-1,:,0], x_train[-1,:,:].T]))\nEdge = np.array(edge_index)\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 4, betaOrder = c(1,1,1,1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((y_test-gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((y_test-gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,h=5)\nfig = plot_add(fig,x_test_f[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,729))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(4,580),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(583,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(4,584),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(582,727),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(4,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(583,728),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario4: \\n missing=30% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html",
    "title": "SY 1st ITSTGCN",
    "section": "",
    "text": "edit"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_rand",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_rand",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nplans_stgcn_rand = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nclass PLNR_STGCN_RAND:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):  \n            product_iterator = itertools.product(\n                self.plans['method'], \n                self.plans['mrate'], \n                self.plans['lags'], \n                self.plans['nof_filters'], \n                self.plans['inter_method'],\n                self.plans['epoch']\n            )\n            for prod_iter in product_iterator:\n                method,mrate,lags,nof_filters,inter_method,epoch = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                if mrate > 0: \n                    mtype = 'rand'\n                    mindex = rand_mindex(train_dataset,mrate=mrate)\n                    train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                elif mrate ==0: \n                    mtype = None\n                    inter_method = None \n                if method == 'STGCN':\n                    lrnr = StgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                elif method == 'IT-STGCN':\n                    lrnr = ITStgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn(filters=nof_filters,epoch=epoch)\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n            print('{}/{} is done'.format(_+1,self.plans['max_iteration']))\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_STGCN_RAND(plans,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/3 is done\n2/3 is done\n3/3 is done\n\n\n\ndf = plnr.simulation_results\ndf\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      8\n      None\n      1\n      1.202111\n    \n    \n      1\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      8\n      None\n      1\n      1.173311\n    \n    \n      2\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      16\n      None\n      1\n      1.170123\n    \n    \n      3\n      five_nodes\n      STGCN\n      0.0\n      None\n      2\n      16\n      None\n      1\n      1.18629\n    \n    \n      4\n      five_nodes\n      STGCN\n      0.0\n      None\n      4\n      8\n      None\n      1\n      1.238957\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      139\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      2\n      16\n      linear\n      1\n      1.195191\n    \n    \n      140\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      8\n      nearest\n      1\n      1.208371\n    \n    \n      141\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      8\n      linear\n      1\n      1.160624\n    \n    \n      142\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      16\n      nearest\n      1\n      1.15774\n    \n    \n      143\n      five_nodes\n      IT-STGCN\n      0.4\n      rand\n      4\n      16\n      linear\n      1\n      1.217873\n    \n  \n\n144 rows Ã— 9 columns"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_block",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_stgcn_block",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_STGCN_BLOCK",
    "text": "PLNR_STGCN_BLOCK\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nmindex_block = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex_block],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nclass PLNR_STGCN_BLOCK:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['method'], \n                self.plans['mindex'],\n                self.plans['lags'],\n                self.plans['nof_filters'],\n                self.plans['inter_method'],\n                self.plans['epoch']\n            )\n            for prod_iter in product_iterator:\n                method,mrate,lags,nof_filters,inter_method,epoch = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                mtype = 'block'\n                train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                if method == 'STGCN':\n                    lrnr = StgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                elif method == 'IT-STGCN':\n                    lrnr = ITStgcnLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn(filters=nof_filters,epoch=epoch)\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                mrate= lrnr.mrate_total\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_STGCN_BLOCK(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/1\n\n\n\ndf = plnr.simulation_results\ndf\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.162601\n    \n    \n      1\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.145895\n    \n    \n      2\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.166197\n    \n    \n      3\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.165355\n    \n    \n      4\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.157954\n    \n    \n      5\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.162674\n    \n    \n      6\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.179143\n    \n    \n      7\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.175561\n    \n    \n      8\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.195364\n    \n    \n      9\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.2184\n    \n    \n      10\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.210481\n    \n    \n      11\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.169326\n    \n    \n      12\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.193523\n    \n    \n      13\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.199567\n    \n    \n      14\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.201094\n    \n    \n      15\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.210867\n    \n    \n      16\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.169622\n    \n    \n      17\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.173848\n    \n    \n      18\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.176841\n    \n    \n      19\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.15848\n    \n    \n      20\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.191304\n    \n    \n      21\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.155874\n    \n    \n      22\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.188419\n    \n    \n      23\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.197183\n    \n    \n      24\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.210021\n    \n    \n      25\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.184674\n    \n    \n      26\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.274009\n    \n    \n      27\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.188723\n    \n    \n      28\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.217735\n    \n    \n      29\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.202317\n    \n    \n      30\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.219543\n    \n    \n      31\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.202418\n    \n    \n      32\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.158991\n    \n    \n      33\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.187762\n    \n    \n      34\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.182213\n    \n    \n      35\n      five_nodes\n      STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.161439\n    \n    \n      36\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.188787\n    \n    \n      37\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.233327\n    \n    \n      38\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.15206\n    \n    \n      39\n      five_nodes\n      STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.161346\n    \n    \n      40\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      nearest\n      1\n      1.215097\n    \n    \n      41\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      8\n      linear\n      1\n      1.163064\n    \n    \n      42\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      nearest\n      1\n      1.206054\n    \n    \n      43\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      2\n      16\n      linear\n      1\n      1.177454\n    \n    \n      44\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      nearest\n      1\n      1.233471\n    \n    \n      45\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      8\n      linear\n      1\n      1.209842\n    \n    \n      46\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      nearest\n      1\n      1.221017\n    \n    \n      47\n      five_nodes\n      IT-STGCN\n      0.5\n      block\n      4\n      16\n      linear\n      1\n      1.218403"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_rand",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_rand",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nclass PLNR_GNAR_RAND:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['mrate'],\n                self.plans['lags'],\n                self.plans['inter_method']\n            )\n            for prod_iter in product_iterator:\n                mrate,lags,inter_method = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                if mrate > 0: \n                    mtype = 'rand'\n                    mindex = rand_mindex(train_dataset,mrate=mrate)\n                    train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                elif mrate ==0: \n                    mtype = None\n                    inter_method = None \n                method = 'GNAR'\n                lrnr = GNARLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn()\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                nof_filters = None \n                epoch= None\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nplnr.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      1\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      2\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      3\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      4\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      5\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      6\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      7\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      8\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      9\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      10\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      11\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      12\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      13\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      14\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      15\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      16\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      17\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      18\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      19\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      20\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      21\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      22\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      23\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      24\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      25\n      five_nodes\n      GNAR\n      0.0\n      None\n      2\n      None\n      None\n      None\n      1.40683\n    \n    \n      26\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      27\n      five_nodes\n      GNAR\n      0.0\n      None\n      4\n      None\n      None\n      None\n      1.469004\n    \n    \n      28\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      29\n      five_nodes\n      GNAR\n      0.2\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      30\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      31\n      five_nodes\n      GNAR\n      0.2\n      rand\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      32\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      33\n      five_nodes\n      GNAR\n      0.4\n      rand\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      34\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      35\n      five_nodes\n      GNAR\n      0.4\n      rand\n      4\n      None\n      linear\n      None\n      1.469004"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_block",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#plnr_gnar_block",
    "title": "SY 1st ITSTGCN",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n# _data = load_data('./data/fivenodes.pkl')\n\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = DatasetLoader(data_dict)\n\n\nmindex_block = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex_block],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nclass PLNR_GNAR_BLOCK:\n    def __init__(self,plans,loader,dataset_name=None,simulation_results=None):\n        self.plans = plans\n        col = ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse']\n        self.loader = loader\n        self.dataset_name = dataset_name\n        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n    def simulate(self):\n        for _ in range(self.plans['max_iteration']):\n            product_iterator = itertools.product(\n                self.plans['mindex'],\n                self.plans['lags'],\n                self.plans['inter_method']\n            )\n            for prod_iter in product_iterator:\n                mrate,lags,inter_method = prod_iter\n                self.dataset = self.loader.get_dataset(lags=lags)\n                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.8)\n                mtype = 'block'\n                train_dataset = padding(train_dataset_miss = miss(train_dataset,mindex=mindex,mtype=mtype),interpolation_method=inter_method)\n                method = 'GNAR'\n                lrnr = GNARLearner(train_dataset,dataset_name=self.dataset_name)\n                lrnr.learn()\n                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n                evtor.calculate_mse()\n                mse = evtor.mse['test']['total']\n                nof_filters = None \n                epoch= None\n                mrate= lrnr.mrate_total\n                self._record(method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse)\n    def _record(self,method,mrate,mtype,lags,nof_filters,inter_method,epoch,mse):\n        dct = {'dataset': self.dataset_name,\n               'method': method,\n               'mrate': mrate,\n               'mtype': mtype, \n               'lags': lags,\n               'nof_filters': nof_filters,\n               'inter_method': inter_method,\n               'epoch': epoch,\n               'mse': mse\n              }\n        simulation_result_new = pd.Series(dct).to_frame().transpose()\n        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n\n\nplnr = PLNR_GNAR_BLOCK(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nplnr.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n    \n  \n  \n    \n      0\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      1\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      2\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      3\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      4\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      5\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      6\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      7\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n    \n      8\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      nearest\n      None\n      1.40683\n    \n    \n      9\n      five_nodes\n      GNAR\n      0.5\n      block\n      2\n      None\n      linear\n      None\n      1.40683\n    \n    \n      10\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      nearest\n      None\n      1.469004\n    \n    \n      11\n      five_nodes\n      GNAR\n      0.5\n      block\n      4\n      None\n      linear\n      None\n      1.469004\n    \n  \n\n\n\n\n\nì—¬ê¸°ë¶€í„° ì„œì—°ì´ì½”ë“œ\n\nedges_tensor = torch.tensor(data['edges'])\nfiveVTS = np.array(data['f'])\nnonzero_indices = edges_tensor.nonzero()\nfiveNet_edge = np.array(nonzero_indices).T\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\nedge_index\n\nNameError: name 'edge_index' is not defined\n\n\n- train / test\n\nfiveVTS_train = fiveVTS[:int(len(fiveVTS)*0.8)]\nfiveVTS_test = fiveVTS[int(len(fiveVTS)*0.8):]"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#random-missing-values",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#random-missing-values",
    "title": "SY 1st ITSTGCN",
    "section": "Random Missing Values",
    "text": "Random Missing Values\n\nclass Missing:\n    def __init__(self,df):\n        self.df = df\n        self.N = N\n        self.number = []\n    def miss(self,percent=0.5):\n        self.missing = self.df.copy()\n        self.percent = percent\n        for i in range(self.N):\n            #self.seed = np.random.choice(1000,1,replace=False)\n            #np.random.seed(self.seed)\n            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n            self.missing[self.number[i],i] = float('nan')\n    def first_mean(self):\n        self.train_mean = self.missing.copy()\n        for i in range(self.N):\n            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n    def second_linear(self):\n        self.train_linear = pd.DataFrame(self.missing)\n        self.train_linear.interpolate(method='linear', inplace=True)\n        self.train_linear = self.train_linear.fillna(0)\n        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)\n\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n\nrate = [i/10 for i in range(10)]"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#class-code-by-method",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#class-code-by-method",
    "title": "SY 1st ITSTGCN",
    "section": "Class code by Method",
    "text": "Class code by Method"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn",
    "title": "SY 1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn",
    "title": "SY 1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar",
    "title": "SY 1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#stgcn-1",
    "title": "SY 1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#enhencement-of-stgcn-1",
    "title": "SY 1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar-1",
    "href": "posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html#gnar-1",
    "title": "SY 1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      0.732\n      0.005\n    \n    \n      1\n      12\n      STGCN\n      2\n      0.732\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      12\n      IT-STGCN\n      2\n      1.186\n      0.051\n    \n    \n      1\n      0.3\n      12\n      STGCN\n      2\n      1.208\n      0.051\n    \n    \n      2\n      0.5\n      12\n      IT-STGCN\n      2\n      1.242\n      0.061\n    \n    \n      3\n      0.5\n      12\n      STGCN\n      2\n      1.330\n      0.073\n    \n    \n      4\n      0.6\n      12\n      IT-STGCN\n      2\n      1.251\n      0.055\n    \n    \n      5\n      0.6\n      12\n      STGCN\n      2\n      1.422\n      0.086\n    \n    \n      6\n      0.7\n      12\n      IT-STGCN\n      2\n      1.167\n      0.059\n    \n    \n      7\n      0.7\n      12\n      STGCN\n      2\n      2.077\n      0.252\n    \n    \n      8\n      0.8\n      12\n      IT-STGCN\n      2\n      1.371\n      0.097\n    \n    \n      9\n      0.8\n      12\n      STGCN\n      2\n      2.432\n      0.263"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.160\n      0.042\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.215\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.752\n      0.013\n    \n    \n      1\n      16\n      STGCN\n      0.752\n      0.012"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.087\n      0.046\n    \n    \n      2\n      0.5\n      linear\n      16\n      IT-STGCN\n      0.958\n      0.072\n    \n    \n      3\n      0.5\n      linear\n      16\n      STGCN\n      1.530\n      0.106\n    \n    \n      4\n      0.6\n      linear\n      16\n      IT-STGCN\n      1.120\n      0.072\n    \n    \n      5\n      0.6\n      linear\n      16\n      STGCN\n      1.753\n      0.181\n    \n    \n      6\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      7\n      0.8\n      linear\n      16\n      STGCN\n      2.529\n      0.292"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-1",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.807041\n      0.016362\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.828224\n      0.021919\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.823756\n      0.022918\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.828498\n      0.022007"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.233\n      0.115\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.233\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      4\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.528\n      0.190\n    \n    \n      5\n      0.5\n      4\n      linear\n      STGCN\n      1.593\n      0.195\n    \n    \n      6\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.507\n      0.235\n    \n    \n      7\n      0.5\n      4\n      nearest\n      STGCN\n      1.673\n      0.223\n    \n    \n      8\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      9\n      0.6\n      4\n      linear\n      STGCN\n      1.655\n      0.179\n    \n    \n      10\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      11\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254\n    \n    \n      12\n      0.8\n      4\n      linear\n      IT-STGCN\n      1.753\n      0.306\n    \n    \n      13\n      0.8\n      4\n      linear\n      STGCN\n      1.753\n      0.148\n    \n    \n      14\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.608\n      0.243\n    \n    \n      15\n      0.8\n      4\n      nearest\n      STGCN\n      1.871\n      0.214"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-2",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#w_st",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.528\n      0.003"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.570\n      0.006\n    \n    \n      2\n      0.5\n      8\n      IT-STGCN\n      0.524\n      0.003\n    \n    \n      3\n      0.5\n      8\n      STGCN\n      0.658\n      0.010\n    \n    \n      4\n      0.6\n      8\n      IT-STGCN\n      0.539\n      0.004\n    \n    \n      5\n      0.6\n      8\n      STGCN\n      0.731\n      0.015\n    \n    \n      6\n      0.8\n      8\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      7\n      0.8\n      8\n      STGCN\n      0.932\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-3",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003835\n      8\n      IT-STGCN\n      0.528737\n      0.002806\n    \n    \n      1\n      0.003835\n      8\n      STGCN\n      0.527871\n      0.002606\n    \n    \n      2\n      0.095870\n      8\n      IT-STGCN\n      0.529440\n      0.003820\n    \n    \n      3\n      0.095870\n      8\n      STGCN\n      0.544176\n      0.010772\n    \n    \n      4\n      0.119837\n      8\n      IT-STGCN\n      0.522825\n      0.002422\n    \n    \n      5\n      0.119837\n      8\n      STGCN\n      0.531188\n      0.002295"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.533\n      0.003\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.726\n      0.015"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.004\n      0.004\n    \n    \n      1\n      8\n      STGCN\n      1.003\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.194\n      0.042\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.662\n      0.073"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-4",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      1.007\n      0.005\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      1.008\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#baseline-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.931\n      0.001\n    \n    \n      1\n      4\n      STGCN\n      0.931\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#random-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      nearest\n      IT-STGCN\n      0.936185\n      0.001825\n    \n    \n      1\n      0.3\n      4\n      nearest\n      STGCN\n      0.991390\n      0.007285\n    \n    \n      2\n      0.5\n      4\n      nearest\n      IT-STGCN\n      0.942045\n      0.002642\n    \n    \n      3\n      0.5\n      4\n      nearest\n      STGCN\n      1.149221\n      0.017820\n    \n    \n      4\n      0.7\n      4\n      nearest\n      IT-STGCN\n      1.015221\n      0.012403\n    \n    \n      5\n      0.7\n      4\n      nearest\n      STGCN\n      1.393108\n      0.027555\n    \n    \n      6\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.095560\n      0.018743\n    \n    \n      7\n      0.8\n      4\n      nearest\n      STGCN\n      1.516000\n      0.039793"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html#block-5",
    "title": "GConvGRU and GNAR_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      cubic\n      IT-STGCN\n      1.022866\n      0.021048\n    \n    \n      1\n      0.149142\n      4\n      cubic\n      STGCN\n      1.028363\n      0.031275\n    \n    \n      2\n      0.149142\n      4\n      linear\n      IT-STGCN\n      0.930156\n      0.001956\n    \n    \n      3\n      0.149142\n      4\n      linear\n      STGCN\n      0.934719\n      0.004724\n    \n    \n      4\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.931785\n      0.002158\n    \n    \n      5\n      0.149142\n      4\n      nearest\n      STGCN\n      0.934596\n      0.003562"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html",
    "title": "Class of Method(GNAR) lag 2",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 2"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "title": "Class of Method(GNAR) lag 2",
    "section": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)",
    "text": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)\nì‹œë‚˜ë¦¬ì˜¤1\n\nmissing rate: 0%\në³´ê°„ë°©ë²•: None\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([fiveVTS_train[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(fiveVTS_train[2:int(T*0.8),:].reshape(int(T*0.8)-2,N,-1)).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.87it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\nlibrary(tidyverse)\n\n\n%R -i fiveVTS_train\n\n\n%%R\nanswer <- GNARfit(vts = fiveVTS_train, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean(axis=0)\ntest_mse_total_gnar = ((fiveVTS_test - gnar_test.reshape(-1,5))**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.995256618187614, 1.2577286248028454)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(2,160),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),gnar_train.reshape(-1,5)[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(160,200),gnar_test.reshape(-1,5)[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "title": "Class of Method(GNAR) lag 2",
    "section": "ì‹œë‚˜ë¦¬ì˜¤2",
    "text": "ì‹œë‚˜ë¦¬ì˜¤2\nì‹œë‚˜ë¦¬ì˜¤2\n\nmissing rate: 50%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:28<00:00,  1.78it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.6280648350096797, 1.3222499750457097)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "title": "Class of Method(GNAR) lag 2",
    "section": "ì‹œë‚˜ë¦¬ì˜¤3",
    "text": "ì‹œë‚˜ë¦¬ì˜¤3\nì‹œë‚˜ë¦¬ì˜¤3\n\nmissing rate: 80%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.85it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:28<00:00,  1.77it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.2092691948436627, 1.5191113001100904)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "href": "posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "title": "Class of Method(GNAR) lag 2",
    "section": "ì‹œë‚˜ë¦¬ì˜¤4",
    "text": "ì‹œë‚˜ë¦¬ì˜¤4\nì‹œë‚˜ë¦¬ì˜¤4\n\nmissing rate: 30%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(fiveVTS_train)\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(fiveVTS,'--o',h=4,color='gray',label='complete data',alpha=0.2)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_stgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = torch.tensor(np.stack([interpolated_signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\ny = torch.tensor(interpolated_signal[2:,:]).float()\n\n\nXX = torch.tensor(np.stack([fiveVTS_test[i:(int(T*0.2)-2+i),:] for i in range(2)],axis = -1)).float()\nyy = fiveVTS_test[2:int(T*0.2),:].reshape(int(T*0.2)-2,N,-1)\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=2, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(np.stack([signal[i:(int(T*0.8)-2+i),:] for i in range(2)],axis = -1)).float()\n    y = torch.tensor(signal[2:,:]).float()\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.79it/s]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[2:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nX_train1 = np.array(interpolated_signal).squeeze()\nX_test1 =  np.array(fiveVTS_test).squeeze()\n\n\n%R -i X_train1\n\n\n%%R\nanswer <- GNARfit(vts = X_train1, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nprediction <- predict(answer,n.ahead=40)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((X_test1 - gnar_test)**2).mean(axis=0)\ntest_mse_total_gnar = ((X_test1 - gnar_test)**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\ntrain_mse_total_gnar,test_mse_total_gnar\n\n(0.7594163080873634, 1.2656937545324825)\n\n\n\nfig = plot(fiveVTS,'--.',h=4,color='gray',label='complete data',alpha=0.5)\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],fiveVTS_train[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(2,160),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(162,200),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(2,160),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(162,200),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(2,160),gnar_train[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(162,202),gnar_test[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario3: \\n missing=80% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2022-12-07-torchgcn.html",
    "href": "posts/GCN/2022-12-07-torchgcn.html",
    "title": "TORCH_GEOMETRIC.NN",
    "section": "",
    "text": "221207\nhttps://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html\n\nimport torch\nfrom torch_geometric.data import Data\n\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index)\n\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\nG=nx.Graph()\nG.add_node('0')\nG.add_node('1')\nG.add_node('2')\nG.add_edge('0','1')\nG.add_edge('1','2')\npos = {}\npos['0'] = (0,0)\npos['1'] = (1,1)\npos['2'] = (2,0)\nnx.draw(G,pos,with_labels=True)\nplt.show()\n\n\n\n\n\nfrom torch.nn import Linear, ReLU\nfrom torch_geometric.nn import Sequential, GCNConv\n\nex\nmodel = Sequential('x, edge_index', [\n    (GCNConv(in_channels, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    Linear(64, out_channels),\n])\n\nmodel = Sequential('x, edge_index', [\n    (GCNConv(3, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x, edge_index -> x'),\n    ReLU(inplace=True),\n    Linear(64, 3),\n])\n\n\nmodel(x,edge_index)\n\n\nfrom torch.nn import Linear, ReLU, Dropout\nfrom torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\nfrom torch_geometric.nn import global_mean_pool\n\nmodel = Sequential('x, edge_index, batch', [\n    (Dropout(p=0.5), 'x -> x'),\n    (GCNConv(dataset.num_features, 64), 'x, edge_index -> x1'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n    ReLU(inplace=True),\n    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n    (global_mean_pool, 'x, batch -> x'),\n    Linear(2 * 64, dataset.num_classes),\n])\n\nmodel = Sequential('x, edge_index, batch', [\n    (Dropout(p=0.5), 'x -> x'),\n    (GCNConv(dataset.num_features, 64), 'x, edge_index -> x1'),\n    ReLU(inplace=True),\n    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n    ReLU(inplace=True),\n    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n    (global_mean_pool, 'x, batch -> x'),\n    Linear(2 * 64, dataset.num_classes),\n])\n\n\ntorch_geometric.nn.Linear()"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html",
    "href": "posts/GCN/2023-01-21-Class.html",
    "title": "Class of Method",
    "section": "",
    "text": "Class"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean",
    "href": "posts/GCN/2023-01-21-Class.html#mean",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero.train_mean\nc = ___zero.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n\n\n3282.4832243919373\n\n\n\nmean_mse100_10 = pd.DataFrame(_mse)\n\n\nmean_mae100_10 = pd.DataFrame(_mae)\n\n\n_train_result_mean10 = _train_result.copy()\n\n\n_test_result_mean10 = _test_result.copy()\n\n\nplt.plot(mean_mse100_10.T);\n\n\n\n\n\nplt.plot(mean_mae100_10.T);\n\n\n\n\n\nvis2(_zero.train_mean,_train_result[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear",
    "href": "posts/GCN/2023-01-21-Class.html#linear",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero.second_linear\nc = ___zero.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3295.478456020355\n\n\n\nlinear_mse100_10 = pd.DataFrame(_mse)\n\n\nlinear_mae100_10 = pd.DataFrame(_mae)\n\n\n_train_result_linear10 = _train_result.copy()\n\n\n_test_result_linear10 = _test_result.copy()\n\n\nplt.plot(linear_mse100_10.T);\n\n\n\n\n\nplt.plot(linear_mae100_10.T);\n\n\n\n\n\nvis2(_zero.train_mean,_train_result_linear10[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear10[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-1",
    "href": "posts/GCN/2023-01-21-Class.html#mean-1",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero20.train_mean\nc = ___zero20.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.89it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.89it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n\n\n3277.0478909015656\n\n\n\nmean_mse100_20 = pd.DataFrame(_mse)\n\n\nmean_mae100_20 = pd.DataFrame(_mae)\n\n\n_train_result_mean20 = _train_result.copy()\n\n\n_test_result_mean20 = _test_result.copy()\n\n\nplt.plot(mean_mse100_20.T);\n\n\n\n\n\nplt.plot(mean_mae100_20.T);\n\n\n\n\n\nvis2(___zero20.train_mean,_train_result_mean20[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean20[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean20)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-1",
    "href": "posts/GCN/2023-01-21-Class.html#linear-1",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero20.second_linear\nc = ___zero20.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3298.6988050937653\n\n\n\nlinear_mse100_20 = pd.DataFrame(_mse)\n\n\nlinear_mae100_20 = pd.DataFrame(_mae)\n\n\n_train_result_linear20 = _train_result.copy()\n\n\n_test_result_linear20 = _test_result.copy()\n\n\nplt.plot(linear_mse100_20.T);\n\n\n\n\n\nplt.plot(linear_mae100_20.T);\n\n\n\n\n\nvis2(___zero20.train_mean,_train_result_linear20[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear20[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear20)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-2",
    "href": "posts/GCN/2023-01-21-Class.html#mean-2",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero30.train_mean\nc = ___zero30.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n\n\n3280.9767186641693\n\n\n\nmean_mse_30 = pd.DataFrame(_mse)\n\n\nmean_mae_30 = pd.DataFrame(_mae)\n\n\n_train_result_mean30 = _train_result.copy()\n\n\n_test_result_mean30 = _test_result.copy()\n\n\nplt.plot(mean_mse_30.T);\n\n\n\n\n\nplt.plot(mean_mae_30.T);\n\n\n\n\n\nvis2(___zero30.train_mean,_train_result_mean30[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean30[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean30)\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-2",
    "href": "posts/GCN/2023-01-21-Class.html#linear-2",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero30.second_linear\nc = ___zero30.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3305.375289440155\n\n\n\nlinear_mse_30 = pd.DataFrame(_mse)\n\n\nlinear_mae_30 = pd.DataFrame(_mae)\n\n\n_train_result_linear30 = _train_result.copy()\n\n\n_test_result_linear30 = _test_result.copy()\n\n\nplt.plot(linear_mse_30.T);\n\n\n\n\n\nplt.plot(linear_mae_30.T);\n\n\n\n\n\nvis2(___zero30.train_mean,_train_result_linear30[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear30[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear30)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-3",
    "href": "posts/GCN/2023-01-21-Class.html#mean-3",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero40.train_mean\nc = ___zero40.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n\n\n3287.529237985611\n\n\n\nmean_mse_40 = pd.DataFrame(_mse)\n\n\nmean_mae_40 = pd.DataFrame(_mae)\n\n\n_train_result_mean40 = _train_result.copy()\n\n\n_test_result_mean40 = _test_result.copy()\n\n\nplt.plot(mean_mse_40.T);\n\n\n\n\n\nplt.plot(mean_mae_40.T);\n\n\n\n\n\nvis2(___zero40.train_mean,_train_result_mean40[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_mean40[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_mean40)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-3",
    "href": "posts/GCN/2023-01-21-Class.html#linear-3",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero40.second_linear\nc = ___zero40.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.82it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.84it/s]\n\n\n3303.96302652359\n\n\n\nlinear_mse_40 = pd.DataFrame(_mse)\n\n\nlinear_mae_40 = pd.DataFrame(_mae)\n\n\n_train_result_linear40 = _train_result.copy()\n\n\n_test_result_linear40 = _test_result.copy()\n\n\nplt.plot(linear_mse_40.T);\n\n\n\n\n\nplt.plot(linear_mae_40.T);\n\n\n\n\n\nvis2(___zero40.train_mean,_train_result_linear40[59]);\n\n\n\n\n\nvis2(fiveVTS_test[1:],_test_result_linear40[0]);\n\n\n\n\n\nshow_lrpr(fiveVTS_test[1:,0],fiveVTS_test[1:,1],fiveVTS_test[1:,2],fiveVTS_test[1:,3],fiveVTS_test[1:,4],_test_result_linear40)\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#mean-4",
    "href": "posts/GCN/2023-01-21-Class.html#mean-4",
    "title": "Class of Method",
    "section": "Mean",
    "text": "Mean\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero50.train_mean\nc = ___zero50.number\nd = train_X_mean\nf = train_y_mean\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n\nmean_mse_50 = pd.DataFrame(_mse)\n\n\nmean_mae_50 = pd.DataFrame(_mae)\n\n\n_train_result_mean50 = _train_result.copy()\n\n\n_test_result_mean50 = _test_result.copy()\n\n\nplt.plot(mean_mse_50.T);\n\n\nplt.plot(mean_mae_50.T);\n\n\nvis2(_zero.train_mean,_train_result_mean50[59]);\n\n\nvis2(fiveVTS_test[1:],_test_result_mean50[0]);"
  },
  {
    "objectID": "posts/GCN/2023-01-21-Class.html#linear-4",
    "href": "posts/GCN/2023-01-21-Class.html#linear-4",
    "title": "Class of Method",
    "section": "Linear",
    "text": "Linear\n\nt1= time.time()\nttt = 160\n_mse = []\n_mae = []\n_train_result = []\n_test_result = []\nb = ___zero50.second_linear\nc = ___zero50.number\nd = train_X_linear\nf = train_y_linear\nfor i in range(60):\n    a = Method(b,ttt,c,d,f)\n    a.FT()\n    _mse.append(a.mse)\n    _mae.append(a.mae)\n    _train_result.append(a.train_result)\n    _test_result.append(a.test_result)\n    b = a.FT_result\nt2 = time.time()\nt2-t1\n\n\nlinear_mse_50 = pd.DataFrame(_mse)\n\n\nlinear_mae_50 = pd.DataFrame(_mae)\n\n\n_train_result_linear50 = _train_result.copy()\n\n\n_test_result_linear50 = _test_result.copy()\n\n\nplt.plot(linear_mse_50.T);\n\n\nplt.plot(linear_mae_50.T);\n\n\nvis2(_zero.train_mean,_train_result_linear50[59]);\n\n\nvis2(fiveVTS_test[1:],_test_result_linear50[0]);"
  },
  {
    "objectID": "posts/GCN/2023-07-04-toy_example_figure.html",
    "href": "posts/GCN/2023-07-04-toy_example_figure.html",
    "title": "Toy Example Figure(Intro)",
    "section": "",
    "text": "edit\n\n\nêµìˆ˜ë‹˜ ì„¤ì •(ìˆ˜ì • ì•ˆ í•œ ê²ƒ)\n\nT = 100\nt = np.arange(T)/T * 5\n\nx = 0.1*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\ndf1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset_DCRNN = loader1.get_dataset(lags=1)\n\n\nmindex = [[np.array(list(range(20,35)))],random.sample(range(0, T), int(T*0.5))]\ndataset_miss_DCRNN = itstgcn.miss(dataset_DCRNN,mindex,mtype='block')\n\n\ndataset_padded_DCRNN = itstgcn.padding(dataset_miss_DCRNN,interpolation_method='linear')\n\n\nlrnr_DCRNN = itstgcn.StgcnLearner(dataset_padded_DCRNN)\n\n\nlrnr_DCRNN.learn(filters=1,epoch=10,lr=0.01,RecurrentGCN='GConvLSTM')\n\n\nevtor_DCRNN = Eval_csy(lrnr_DCRNN,dataset_padded_DCRNN)\n\n\nlrnr_DCRNN2 = itstgcn.ITStgcnLearner(dataset_padded_DCRNN)\n\n\nlrnr_DCRNN2.learn(filters=1,epoch=10,lr=0.01,RecurrentGCN='GConvLSTM')\n\n\n\n\nì´ˆê¸° ì„¤ì •(ìˆ˜ì • ì•ˆ í•œ ê²ƒ)\n\nT = 200\nt = np.arange(T)/T * 10\nx = 0.1*np.sin(2*t)+0.2*np.sin(4*t)+0.1*np.sin(8*t)+0.2*np.sin(16*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\neps_y  = np.random.normal(size=T)*0\nx = x*0.35\ny = y*0.3\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1],[1,0]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\ndf1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset_GConvLSTM = loader1.get_dataset(lags=1)\n\n\nmindex = [random.sample(range(0, T), int(T*0.5)),[np.array(list(range(100,120)))]]\ndataset_miss_GConvLSTM = itstgcn.miss(dataset_GConvLSTM,mindex,mtype='block')\n\n\ndataset_padded_cubic_GConvLSTM = itstgcn.padding(dataset_miss_GConvLSTM,interpolation_method='cubic')\n\n\nlrnr_GConvLSTM = itstgcn.StgcnLearner(dataset_padded_cubic_GConvLSTM)\n\n\nlrnr_GConvLSTM.learn(filters=8,epoch=50,RecurrentGCN='GConvLSTM')\n\n\n\n\nimport\n\nimport itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nimport random\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nfrom plotnine import *\n\n\n\nExample\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+np.random.rand(T)+np.sin(4*t)+1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n_x = np.array(dataset_padded.targets)[:,0]\n\n\nplt.plot(_x)\nplt.plot(itstgcn.trim(_x))\n\n\n\n\n\n# T = 100\n# t = np.arange(T)/T * 5\n\n# x = 0.01*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\n# eps_x  = np.random.normal(size=T)*0\n# y = x.copy()\n# for i in range(2,T):\n#     y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \n# eps_y  = np.random.normal(size=T)*0\n# x = x\n# y = y\n# plt.plot(t,x,color='C0',lw=5)\n# plt.plot(t,x+eps_x,alpha=0.5,color='C0')\n# plt.plot(t,y,color='C1',lw=5)\n# plt.plot(t,y+eps_y,alpha=0.5,color='C1')\n# _node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n# _edges1 = torch.tensor([[0,1]]).tolist()\n\n# data_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\n# data1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.9)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1],'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot((mindex[1][0][0]+mindex[1][0][len(mindex[1][0])-1])/2, 0.1,'s', markersize=110, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [[np.array(list(range(40,55)))],[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=1,epoch=10)\n\n10/10\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=1,epoch=10)\n\n10/10\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nnp.array(dataset_miss.features).shape\n\n(96, 2, 4)\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\n\nì‹œë„ 1\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = np.sin(2*t)+0.5*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=4,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax1 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n#     ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax1.tick_params(axis='y', labelsize=40)\n#     ax1.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_fst.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax2 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data',markersize=15)\n#     ax2.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax2.tick_params(axis='y', labelsize=40)\n#     ax2.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_snd.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax3 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)    \n#     ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n#     ax3.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax3.tick_params(axis='y', labelsize=40)\n#     ax3.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_3rd.png')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ax4 = plt.subplots(figsize=(40,15))\n#     # fig.suptitle('Figure 1(node 1)',fontsize=40)\n#     ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n#     ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n#     ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n#     ax4.plot(138, -1.2, 'o', markersize=230, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(220, -1.5, 'o', markersize=200, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(290, -1.2, 'o', markersize=310, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.plot(455, -0.9, 'o', markersize=280, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n#     ax4.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n#     ax4.tick_params(axis='y', labelsize=40)\n#     ax4.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_4th_1.png')\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\nì‹œë„ 2\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.4*np.random.rand(T)+np.sin(4*t)+1.3*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try1_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try1_node2.png')\n\n\n\n\n\n\nì‹œë„ 3\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n_data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n_loader = itstgcn.DatasetLoader(_data_dict)\n\n\n_dataset = _loader.get_dataset(lags=2)\n\n\nmindex = [random.sample(range(0, 200), int(200*0.8)),[np.array(list(range(40,100)))]]\n_dataset_miss = itstgcn.miss(_dataset,mindex,mtype='block')\n\n\n# mindex = itstgcn.rand_mindex(dataset,mrate=0.8)\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n_dataset_padded = itstgcn.padding(_dataset_miss,interpolation_method='linear')\n\n\n_lrnr = itstgcn.StgcnLearner(_dataset_padded)\n\n\n_lrnr.learn(filters=12,epoch=10)\n\n10/10\n\n\n\n_evtor = Eval_csy(_lrnr,_dataset_padded)\n\n\n_lrnr_2 = itstgcn.ITStgcnLearner(_dataset_padded)\n\n\n_lrnr_2.learn(filters=12,epoch=10)\n\n10/10\n\n\n\n_evtor_2 = Eval_csy(_lrnr_2,_dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(_dataset.features)[:2,0,0],torch.tensor(_dataset_miss.targets).reshape(-1,5)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(_evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(torch.tensor(_dataset.features)[:,0,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(_evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(_evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(torch.tensor(_dataset.features)[:,1,0],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(_dataset.features)[:2,1,0],torch.tensor(_dataset_miss.targets).reshape(-1,5)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(_evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(torch.tensor(_dataset.features)[:,1,0],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(_evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(_evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\nì‹œë„ 4 noise 0\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+np.sin(4*t)+1.2*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.5)),[np.array(list(range(50,95)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(135, -1.5, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(220, -1.5, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(290, -1.8, 'o', markersize=120, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(450, -1.5, 'o', markersize=120, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1_2.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(75, 0.75, 'o', markersize=150, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2_2.png')\n\n\n\n\n\n\nì‹œë„ 5 noise 10%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.1*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.8)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try3_node1_noise10.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try3_node2_noise10.png')\n\n\n\n\n\n\nì‹œë„ 6 noise 20%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.2*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.75)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try4_node1_noise20.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2_noise20.png')\n\n\n\n\n\n\nì‹œë„ 7 noise 30%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.75)),[np.array(list(range(20,35)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try5_node1_noise30.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try5_node2_noise20.png')\n\n\n\n\n\n\nì‹œë„ 8 noise 30% only random\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\n# mindex = [random.sample(range(0, T), int(T*0.7)),[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\nmindex = itstgcn.rand_mindex(dataset,mrate=0.75)\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=8,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node1.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 2)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try2_node2.png')\n\n\n\n\n\n\nì‹œë„ 9 noise 40%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.4*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [[np.array(list(range(40,85)))],random.sample(range(0, T), int(T*0.7))]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=32,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=32,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolation')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node1_noise40.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node2_noise40.png')\n\n\n\n\n\n\nì‹œë„ 10 noise 50%\n\nT = 500\nt = np.arange(T)/T * 5\n\nx = 1.5*np.sin(2*t)+0.1*np.random.rand(T)+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=4)\n\n\nmindex = [random.sample(range(0, T), int(T*0.7)),[np.array(list(range(40,85)))]]\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\n# mindex = [[np.array(list(range(181,300)))],[np.array(list(range(20,35)))]]\n# dataset_miss = itstgcn.miss(dataset,mindex,mtype='block')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=12,epoch=5)\n\n5/5\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node1_noise40.png')\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    # plt.rcParams['font.family'] = 'xkcd'\n    # plt.xkcd(scale=0,length=200)\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(40,15))\n    fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['y'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,1]],dim=0),'--o',color='C3',label='Observed Data')\n    ax2.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,1],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    \n    ax4.plot(data1['y'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,1],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,1],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(55, 0, 'o', markersize=100, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(150, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(185, 0, 'o', markersize=80, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=20,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n# plt.savefig('try6_node2_noise40.png')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html",
    "title": "1st ITSTGCN",
    "section": "",
    "text": "GNAR fiveNet,fivenodes lag 1"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn",
    "title": "1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nclass STGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            for epoch in range(50):\n                for time, (xt,yt) in enumerate(zip(X,y)):\n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset, \n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn",
    "title": "1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nclass ESTGCN_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n\n        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n        for i in range(self.iterable):\n    \n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n\n\n            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n            net.train()\n            signal = interpolated_signal.copy()\n            for epoch in range(50):\n                signal = update_from_freq_domain(signal,missing_index)\n                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n                for time, (xt,yt) in enumerate(zip(X,y)):        \n                    yt_hat = net(xt, edge_index, edge_attr)\n                    cost = torch.mean((yt_hat-yt)**2)\n                    cost.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n\n            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n\n            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar",
    "title": "1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nm = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)\n\n\nclass GNAR_Missing:\n    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n        self.Dataset = Dataset\n        self.df = df\n        self.iterable = iterable\n        self.Method = Method\n        self.Missingrate = Missingrate\n        self.Missingtype = Missingtype\n        self.lag = lag\n        self.Number_of_filters = Number_of_filters\n        self.Interpolation = Interpolation\n    def iter(self):\n        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n        for i in range(self.iterable):\n\n            _zero = Missing(fiveVTS_train)\n            _zero.miss(percent = self.Missingrate)\n            _zero.second_linear()\n\n            missing_index = _zero.number\n            interpolated_signal = _zero.train_linear\n\n            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n\n            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = 160, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n            predict = GNAR.predict_GNARfit(answer,n_ahead=40)\n\n\n            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n            test_mse_total_gnar = ((self.yy.squeeze() - pd.DataFrame(predict).values.reshape(-1,5)[:-1,:])**2).mean()\n\n            df_row = pd.DataFrame(columns=col)\n            df_row['Dataset'] = self.Dataset,\n            df_row['iteration'] = i+1, # 1,2,3,...,10 \n            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n            df_row['lag'] = self.lag, # 1,2,3,4 ... \n            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n\n            self.df = pd.concat([self.df,df_row])"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#stgcn-1",
    "title": "1st ITSTGCN",
    "section": "STGCN",
    "text": "STGCN\n\nDataset = 'fivenodes'\nMethod = 'stgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_stgcn= pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    stgcn.iter()\n    df_add = stgcn.df.copy()\n    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)\n\n\nsave_data(df_stgcn, './data/GNAR_stgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#enhencement-of-stgcn-1",
    "title": "1st ITSTGCN",
    "section": "Enhencement of STGCN",
    "text": "Enhencement of STGCN\n\nDataset = 'fivenodes'\nMethod = 'estgcn' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = 4 # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_estgcn = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    estgcn.iter()\n    df_add = estgcn.df.copy()\n    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)\n\n\nsave_data(df_estgcn, './data/GNAR_estgcn_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar-1",
    "href": "posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html#gnar-1",
    "title": "1st ITSTGCN",
    "section": "GNAR",
    "text": "GNAR\n\nDataset = 'fivenodes'\nMethod = 'gnar' # 'stgcn','estgcn','gnar' \nMissingtype = 'randomly'  # None, 'randomly' and 'block' \nlag = 1 # 1,2,3,4 ... \nNumber_of_filters = None # 16,24,32, ... \nInterpolation = 'Linear' # None, 'mean', 'linear'\niterable = 100\n\n\ndf_gnar = pd.DataFrame(columns=col)\n\n\nfor Missingrate in rate:\n    df = pd.DataFrame(columns=col)\n    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n    gnar.iter()\n    df_add = gnar.df.copy()\n    df_gnar = pd.concat([df_gnar,df_add],axis=0)\n\n\nsave_data(df_gnar, './data/GANR_gnar_randomly_by_rate.pkl')"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-1",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-2",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-10_15-33-00.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-10_16-06-20.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-3",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-14_19-23-44.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-15_15-51-38.csv')\ndf3 = pd.read_csv('./simulation_results/2023-06-16_04-32-51.csv')\n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/GConvLSTM_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-4",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#random-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html#block-5",
    "title": "GConvLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      2\n      1.211\n      0.021\n    \n    \n      1\n      4\n      STGCN\n      2\n      1.213\n      0.026"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      IT-STGCN\n      2\n      1.220\n      0.026\n    \n    \n      1\n      0.3\n      4\n      STGCN\n      2\n      1.216\n      0.020\n    \n    \n      2\n      0.5\n      4\n      IT-STGCN\n      2\n      1.215\n      0.025\n    \n    \n      3\n      0.5\n      4\n      STGCN\n      2\n      1.237\n      0.038\n    \n    \n      4\n      0.6\n      4\n      IT-STGCN\n      2\n      1.226\n      0.031\n    \n    \n      5\n      0.6\n      4\n      STGCN\n      2\n      1.234\n      0.036\n    \n    \n      6\n      0.7\n      4\n      IT-STGCN\n      2\n      1.232\n      0.036\n    \n    \n      7\n      0.7\n      4\n      STGCN\n      2\n      1.250\n      0.048\n    \n    \n      8\n      0.8\n      4\n      IT-STGCN\n      2\n      1.232\n      0.038\n    \n    \n      9\n      0.8\n      4\n      STGCN\n      2\n      1.250\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      4\n      IT-STGCN\n      1.218\n      0.025\n    \n    \n      1\n      0.125\n      4\n      STGCN\n      1.245\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      0.865\n      0.040\n    \n    \n      1\n      8\n      STGCN\n      0.872\n      0.053"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      8\n      IT-STGCN\n      0.870\n      0.035\n    \n    \n      1\n      0.3\n      linear\n      8\n      STGCN\n      1.086\n      0.029\n    \n    \n      2\n      0.5\n      linear\n      8\n      IT-STGCN\n      0.931\n      0.034\n    \n    \n      3\n      0.5\n      linear\n      8\n      STGCN\n      1.458\n      0.068\n    \n    \n      4\n      0.6\n      linear\n      8\n      IT-STGCN\n      1.017\n      0.029\n    \n    \n      5\n      0.6\n      linear\n      8\n      STGCN\n      1.615\n      0.134\n    \n    \n      6\n      0.8\n      linear\n      8\n      IT-STGCN\n      1.334\n      0.071\n    \n    \n      7\n      0.8\n      linear\n      8\n      STGCN\n      1.632\n      0.156"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-1",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      8\n      IT-STGCN\n      0.888210\n      0.034704\n    \n    \n      1\n      linear\n      0.28777\n      8\n      STGCN\n      0.910671\n      0.047118\n    \n    \n      2\n      nearest\n      0.28777\n      8\n      IT-STGCN\n      0.888035\n      0.040932\n    \n    \n      3\n      nearest\n      0.28777\n      8\n      STGCN\n      0.902404\n      0.039003"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      8\n      IT-STGCN\n      1.193\n      0.059\n    \n    \n      1\n      4\n      8\n      STGCN\n      1.188\n      0.050"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.210\n      0.039\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.274\n      0.045\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.220\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.287\n      0.065\n    \n    \n      4\n      0.5\n      4\n      linear\n      IT-STGCN\n      1.242\n      0.057\n    \n    \n      5\n      0.5\n      4\n      linear\n      STGCN\n      1.432\n      0.077\n    \n    \n      6\n      0.5\n      4\n      nearest\n      IT-STGCN\n      1.240\n      0.036\n    \n    \n      7\n      0.5\n      4\n      nearest\n      STGCN\n      1.379\n      0.079\n    \n    \n      8\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.286\n      0.053\n    \n    \n      9\n      0.6\n      4\n      linear\n      STGCN\n      1.459\n      0.073\n    \n    \n      10\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.286\n      0.033\n    \n    \n      11\n      0.6\n      4\n      nearest\n      STGCN\n      1.462\n      0.084\n    \n    \n      12\n      0.8\n      4\n      linear\n      IT-STGCN\n      1.440\n      0.094\n    \n    \n      13\n      0.8\n      4\n      linear\n      STGCN\n      1.496\n      0.086\n    \n    \n      14\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.436\n      0.091\n    \n    \n      15\n      0.8\n      4\n      nearest\n      STGCN\n      1.529\n      0.071"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-2",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.169\n      0.040\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.204\n      0.032\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.165\n      0.035\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.263\n      0.033"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#w_st",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.299\n      0.147\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.325\n      0.086\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.117\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.087\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.265\n      0.100\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.466\n      0.085\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.331\n      0.120\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.453\n      0.115\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.201\n      0.081\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.227\n      0.070\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.197\n      0.106\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.347\n      0.117"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      32\n      IT-STGCN\n      0.610\n      0.017\n    \n    \n      1\n      8\n      32\n      STGCN\n      0.608\n      0.014"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.619\n      0.019\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.689\n      0.032\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.769\n      0.045\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.105\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-3",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.608375\n      0.012177\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.624250\n      0.023857"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.624\n      0.019\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.810\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-4",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#baseline-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.977\n      0.024\n    \n    \n      1\n      4\n      STGCN\n      0.983\n      0.024"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#random-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      0.982006\n      0.013261\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      0.989219\n      0.028653"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html#block-5",
    "title": "LRGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.978381\n      0.024324\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.976996\n      0.020351"
  },
  {
    "objectID": "posts/GCN/2023-04-27-toy_example_notes.html",
    "href": "posts/GCN/2023-04-27-toy_example_notes.html",
    "title": "Toy Example Note",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nimport pickle\n\n\nT = 50\nt = np.arange(T)/T * 10 \n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nimport torch\n\n\nx = 50*np.sin(2*t)#+30*np.sin(5*t)\neps_x  = np.random.normal(size=T)\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 50*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)\n\n\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x,y],axis=1).tolist()\n\n_edges1 = torch.tensor([[1,0]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nnp.stack([x+eps_x,y+eps_y],axis=1).shape\n\n(800, 2)\n\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_FX = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n\n_edges = torch.tensor([[0,0],[0,1],[1,0],[1,1]]).tolist()\n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\ndata_dict['edges']\n\n[[0, 0], [0, 1], [1, 0], [1, 1]]\n\n\n\nnp.array(data_dict['edges']).shape\n\n(4, 2)\n\n\n\nsave_data(data_dict, './data/toy_example.pkl')\n\n\ndata_dict = load_data('./data/toy_example.pkl')\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\ndata_dict['edges']\n\n[[0, 0], [0, 1], [1, 0], [1, 1]]\n\n\n\ndata_dict['node_ids']\n\n{'node1': 0, 'node2': 1}\n\n\n\nnp.array(data_dict['FX']).shape\n\n(800, 2)\n\n\n\ndata = pd.DataFrame({'x':x,'y':y,'xer':x+eps_x,'yer':y+eps_y})\n\n\nsave_data(data, './data/toy_example_true.csv')\n\n\ndata = load_data('./data/toy_example_true.csv')\n\n\n_node_ids = {'node1':0, 'node2':1}\n\n\n_FX1 = np.stack([x,y],axis=1).tolist()\n\n\n_edges1 = torch.tensor([[1,0]]).tolist()\n\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n\nsave_data(data1, './data/toy_example_true1.csv')"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html",
    "title": "data load, data save as pickle",
    "section": "",
    "text": "data load, data save as pickle\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/index.html\n1st\n2nd\n3rd\n4rd\n5th - TwitterTennisDatasetLoader(ì›í•« ì¸ì½”ë”© í•¨ìˆ˜ë„ ë³„ë„ë¡œ ìˆìŒ) - get_dataset(self) -> DynamicGraphTemporalSignal: - dataset = DynamicGraphTemporalSignal(self.edges, self.edge_weights, self.features, self.target"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#chickenpoxdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#chickenpoxdatasetloader",
    "title": "data load, data save as pickle",
    "section": "ChickenpoxDatasetLoader",
    "text": "ChickenpoxDatasetLoader\nChickenpox Hungary\n\nA dataset of county level chicken pox cases in Hungary between 2004 and 2014. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are counties and edges are neighbourhoods. Vertex features are lagged weekly counts of the chickenpox cases (we included 4 lags). The target is the weekly number of cases for the upcoming week (signed integers). Our dataset consist of more than 500 snapshots (weeks).\n2004ë…„ë¶€í„° 2014ë…„ ì‚¬ì´ í—ê°€ë¦¬ì˜ ì§€ì—­ë³„ ìˆ˜ë‘ì¦ ë°œìƒ ë°ì´í„°ì…‹\nê·¸ë˜í”„ëŠ” ì •ì \nnode ì§€ì—­\nedge ì´ì›ƒ ê´€ê³„\nnode íŠ¹ì„±ì€ ìˆ˜ë‘ì¦ ë°œìƒì˜ ì§€ì—°ëœ ì£¼ê°„ íšŸìˆ˜(4ì£¼ì˜ ì§€ì—°ì´ í¬í•¨ë˜ì–´ ìˆìŒ)\ntargetëŠ” ë‹¤ìŒ ì£¼ì— ëŒ€í•œ ì£¼ê°„ ì‚¬ë¡€ ìˆ˜\n500ê°œ ì´ìƒì˜ ìŠ¤ëƒ…ìƒ·(ì£¼ê°„)\n\në°ì´í„°ì •ë¦¬\n\nT = 519\nN = 20 # number of nodes\nE = 102 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,)\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 517\n\nbetween 2004 and 2014\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\na = loader1.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(520, 20, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 102)\n\n\n\nnp.array(a.edge_weight).shape\n\n(102,)\n\n\n\na.edge_weight\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\n\n\na.edge_index\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nfrom haversine import haversine\n\n\nhaversine?\n\n\nSignature:\nhaversine(\n    point1,\n    point2,\n    unit=<Unit.KILOMETERS: 'km'>,\n    normalize=False,\n    check=True,\n)\nDocstring:\nCalculate the great-circle distance between two points on the Earth surface.\nTakes two 2-tuples, containing the latitude and longitude of each point in decimal degrees,\nand, optionally, a unit of length.\n:param point1: first point; tuple of (latitude, longitude) in decimal degrees\n:param point2: second point; tuple of (latitude, longitude) in decimal degrees\n:param unit: a member of haversine.Unit, or, equivalently, a string containing the\n             initials of its corresponding unit of measurement (i.e. miles = mi)\n             default 'km' (kilometers).\n:param normalize: if True, normalize the points to [-90, 90] latitude and [-180, 180] longitude.\n:param check: if True, check that points are normalized.\nExample: ``haversine((45.7597, 4.8422), (48.8567, 2.3508), unit=Unit.METERS)``\nPrecondition: ``unit`` is a supported unit (supported units are listed in the `Unit` enum)\n:return: the distance between the two points in the requested unit, as a float.\nThe default returned unit is kilometers. The default unit can be changed by\nsetting the unit parameter to a member of ``haversine.Unit``\n(e.g. ``haversine.Unit.INCHES``), or, equivalently, to a string containing the\ncorresponding abbreviation (e.g. 'in'). All available units can be found in the ``Unit`` enum.\nFile:      ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/haversine/haversine.py\nType:      function\n\n\n\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_chickenpox.png\")\n\n\n\n\n\n# nx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\nnode_list = []\nfor i in range(0, 20):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(20,1,figsize=(30,70))\nfor k in range(20):\n    ax[k].plot(np.array(loader1.targets).reshape(20,-1)[k][:],alpha=1,label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\n# fig,ax = plt.subplots(3,1,figsize=(20,10))\n# for k in range(3):\n#     ax[k].plot(np.array(loader1.targets).reshape(20,-1)[k][:],alpha=1,label='observed')\n#     ax[k].set_title('node: {}'.format(node_list[k]))\n#     ax[k].legend()\n# fig.tight_layout()\n# plt.savefig('graph_node_ex2.png')\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\n# fig = px.line(_df, x='x', y=['y1', 'y2','y3','y4','y5','y6'])\n# fig.update_layout(width=900, height=500)\n# fig.show()\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# ì„œë¸Œí”Œë¡¯ ìƒì„±\nfig = make_subplots(rows=2, cols=3)\n\n# ê° ì„œë¸Œí”Œë¡¯ì— ì„  ê·¸ë˜í”„ ì¶”ê°€\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# ê·¸ë˜í”„ í¬ê¸° ì¡°ì •\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# ê·¸ë˜í”„ ì¶œë ¥\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_chickenpox.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_chickenpox.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#pedalmedatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#pedalmedatasetloader",
    "title": "data load, data save as pickle",
    "section": "PedalMeDatasetLoader",
    "text": "PedalMeDatasetLoader\nPedal Me Deliveries\n\nA dataset of PedalMe Bicycle deliver orders in London between 2020 and 2021. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are localities and edges are spatial_connections. Vertex features are lagged weekly counts of the delivery demands (we included 4 lags). The target is the weekly number of deliveries the upcoming week. Our dataset consist of more than 30 snapshots (weeks)\n2020ë…„ê³¼ 2021ë…„ ì‚¬ì´ ëŸ°ë˜ì—ì„œ PedalMe ìì „ê±° ë°°ì†¡ ì£¼ë¬¸ ë°ì´í„°ì…‹\nê·¸ë˜í”„ëŠ” ì •ì \nnode ì¥ì†Œ\nedge ê³µê°„ ì—°ê²°\nnode íŠ¹ì„±ì€ ë°°ì†¡ ìˆ˜ìš”ì˜ ì§€ì—°ëœ ì£¼ê°„ íšŸìˆ˜(4ì£¼ì˜ ì§€ì—°ì´ í¬í•¨ë˜ì–´ ìˆìŒ)\ntarget ë‹¤ìŒ ì£¼ì— ëŒ€í•œ ì£¼ê°„ ë°°ì†¡ íšŸìˆ˜\n30ê°œ ì´ìƒì˜ ìŠ¤ëƒ…ìƒ·(ì£¼ê°„)\n\në°ì´í„°ì •ë¦¬\n\nT = 31\nV = ì§€ì—­ì˜ ì§‘í•©\nN = 15 # number of nodes\nE = 225 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # number of deliveries\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (15,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (15,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 15\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 31\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\na = loader2.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(34, 15, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 225)\n\n\n\nnp.array(a.edge_weight).shape\n\n(225,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_pedalme.png\")\n\n\n\n\n\nnode_list = []\nfor i in range(0, 15):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(15,1,figsize=(20,50))\nfor k in range(15):\n    ax[k].plot(np.array(loader2.targets).reshape(15,-1)[k][:],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\n# fig = px.line(_df, x='x', y=['y1', 'y2','y3','y4','y5','y6'])\n# fig.update_layout(width=900, height=500)\n# fig.show()\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# ì„œë¸Œí”Œë¡¯ ìƒì„±\nfig = make_subplots(rows=2, cols=3)\n\n# ê° ì„œë¸Œí”Œë¡¯ì— ì„  ê·¸ë˜í”„ ì¶”ê°€\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# ê·¸ë˜í”„ í¬ê¸° ì¡°ì •\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# ê·¸ë˜í”„ ì¶œë ¥\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_pedalme.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_pedalme.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#wikimathsdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#wikimathsdatasetloader",
    "title": "data load, data save as pickle",
    "section": "WikiMathsDatasetLoader",
    "text": "WikiMathsDatasetLoader\nWikipedia Math\n\nA dataset of vital mathematics articles from Wikipedia. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are Wikipedia pages and edges are links between them. The graph is directed and weighted. Weights represent the number of links found at the source Wikipedia page linking to the target Wikipedia page. The target is the daily user visits to the Wikipedia pages between March 16th 2019 and March 15th 2021 which results in 731 periods.\nìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì¤‘ìš”í•œ ìˆ˜í•™ ê¸°ì‚¬ë“¤ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ì…‹\nê·¸ë˜í”„ëŠ” ì •ì \nnode ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€\nedge í˜ì´ì§€ ê°„ì˜ ë§í¬\nê·¸ë˜í”„ëŠ” ë°©í–¥ì„±ì´ ìˆìœ¼ë©° ê°€ì¤‘ì¹˜ê°€ ìˆìŒ\nê°€ì¤‘ì¹˜ëŠ” ì†ŒìŠ¤ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ì—ì„œ ëŒ€ìƒ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¡œ ì—°ê²°ëœ ë§í¬ ìˆ˜\ntarget 2019ë…„ 3ì›” 16ì¼ë¶€í„° 2021ë…„ 3ì›” 15ì¼ê¹Œì§€ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ì˜ ì¼ì¼ ì‚¬ìš©ì ë°©ë¬¸ ìˆ˜\nê¸°ê°„ì€ 731ê°œì˜ ê¸°ê°„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n\në°ì´í„°ì •ë¦¬\n\nT = 723\nV = ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€\nN = 1068 # number of nodes\nE = 27079 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # í•´ë‹¹í˜ì´ì§€ë¥¼ ìœ ì €ê°€ ë°©ë¬¸í•œ íšŸìˆ˜\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (1068,8) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3),f(v,t_4),f(v,t_5),f(v,t_6),f(v,t_7)\\)\ny: (1068,) (N,), \\(f(v,t_8)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 1068\n\nvertices are Wikipedia pages\n\n-Edges : 27079\n\nedges are links between them\n\n- Time : 723\n\nWikipedia pages between March 16th 2019 and March 15th 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\na = loader3.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(730, 1068, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 27079)\n\n\n\nnp.array(a.edge_weight).shape\n\n(27079,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_wikimath.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 1068):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(20, 70))\nindices = random.sample(range(0, 1068), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader3.targets).reshape(1068,-1)[idx][:], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# ê° ì„œë¸Œí”Œë¡¯ì— ì„  ê·¸ë˜í”„ ì¶”ê°€\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# ê·¸ë˜í”„ í¬ê¸° ì¡°ì •\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# ê·¸ë˜í”„ ì¶œë ¥\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_wikimath.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_wikimath.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputlargedatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputlargedatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputLargeDatasetLoader",
    "text": "WindmillOutputLargeDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 319 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks\nìœ ëŸ½ êµ­ê°€ì˜ í’ë ¥ ë°œì „ì†Œì—ì„œ 2ë…„ ì´ìƒì— ê±¸ì³ ë°œìƒí•œ ì‹œê°„ë³„ ì—ë„ˆì§€ ì¶œë ¥ ë°ì´í„°\nnode 319ê°œì˜ í’ë ¥ ë°œì „ì†Œ\nê°€ì¤‘ì¹˜ê°€ ìˆëŠ” edgeëŠ” ê´€ê³„ì˜ ê°•ë„\níšŒê·€ ë¶„ì„ ì‘ì—…ì— ì í•©í•œ ëª©í‘œ ë³€ìˆ˜ë¥¼ ì œê³µ\n\në°ì´í„°ì •ë¦¬\n\nT = 17464\nV = í’ë ¥ë°œì „ì†Œ\nN = 319 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (319,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (319,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 319\n\nvertices represent 319 windmills\n\n-Edges : 101761\n\nweighted edges describe the strength of relationships.\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputLargeDatasetLoader\nloader4 = WindmillOutputLargeDatasetLoader()\n\n\na = loader4.get_dataset()\n\n\nnp.array(a.features).shape\n\n(17464, 319, 8)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 101761)\n\n\n\nnp.array(a.edge_weight).shape\n\n(101761,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\na= np.arange(1,100)\na\n\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n\n\n\na[::10]\n\narray([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n\n\n\nnp.array(loader4.targets).reshape(319,-1)[idx][::100].shape\n\n(175,)\n\n\n\nnode_list = []\nfor i in range(0, 319):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader4.targets).reshape(319,-1)[idx][:1000], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader4.targets).reshape(319,-1)[idx][:], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputmediumdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputmediumdatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputMediumDatasetLoader",
    "text": "WindmillOutputMediumDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 26 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\nìœ ëŸ½ êµ­ê°€ì˜ í’ë ¥ ë°œì „ì†Œì—ì„œ 2ë…„ ì´ìƒì— ê±¸ì³ ë°œìƒí•œ ì‹œê°„ë³„ ì—ë„ˆì§€ ì¶œë ¥ ë°ì´í„°ì…‹\nnode 26ê°œì˜ í’ë ¥ ë°œì „ì†Œ\nê°€ì¤‘ì¹˜ê°€ ìˆëŠ” edgeëŠ” ê´€ê³„ì˜ ê°•ë„\níšŒê·€ ë¶„ì„ ì‘ì—…ì— ì í•©í•œ ëª©í‘œ ë³€ìˆ˜ë¥¼ ì œê³µ\n\në°ì´í„°ì •ë¦¬\n\nT = 17464\nV = í’ë ¥ë°œì „ì†Œ\nN = 26 # number of nodes\nE = 676 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (26,4) (N,8), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (26,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 26\n\nvertices represent 26 windmills\n\n-Edges : 676\n\nweighted edges describe the strength of relationships\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputMediumDatasetLoader\nloader5 = WindmillOutputMediumDatasetLoader()\n\n\na = loader5.get_dataset()\n\n\nnp.array(a.features).shape\n\n(17464, 26, 8)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 676)\n\n\n\nnp.array(a.edge_weight).shape\n\n(676,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 26):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(26,1,figsize=(30,70))\nfor k in range(26):\n    ax[k].plot(np.array(loader5.targets).reshape(26,-1)[k],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nfig,ax = plt.subplots(26,1,figsize=(30,70))\nfor k in range(26):\n    ax[k].plot(np.array(loader5.targets).reshape(26,-1)[k][:1000],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputsmalldatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#windmilloutputsmalldatasetloader",
    "title": "data load, data save as pickle",
    "section": "WindmillOutputSmallDatasetLoader",
    "text": "WindmillOutputSmallDatasetLoader\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 11 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\nìœ ëŸ½ êµ­ê°€ì˜ í’ë ¥ ë°œì „ì†Œì—ì„œ 2ë…„ ì´ìƒì— ê±¸ì³ ë°œìƒí•œ ì‹œê°„ë³„ ì—ë„ˆì§€ ì¶œë ¥ ë°ì´í„°ì…‹\nnode 11ê°œì˜ í’ë ¥ ë°œì „ì†Œ\nê°€ì¤‘ì¹˜ê°€ ìˆëŠ” edgeëŠ” ê´€ê³„ì˜ ê°•ë„\níšŒê·€ ë¶„ì„ ì‘ì—…ì— ì í•©í•œ ëª©í‘œ ë³€ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\në°ì´í„°ì •ë¦¬\n\nT = 17464\nV = í’ë ¥ë°œì „ì†Œ\nN = 11 # number of nodes\nE = 121 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (11,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (11,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 11\n\nvertices represent 11 windmills\n\n-Edges : 121\n\nweighted edges describe the strength of relationships\n\n- Time : 17464\n\nmore than 2 years\n\n\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\nloader6 = WindmillOutputSmallDatasetLoader()\n\n\na = loader6.get_dataset(lags=1)\n\n\nnp.array(a.features).shape\n\n(17471, 11, 1)\n\n\n\nnp.array(a.edge_index).shape\n\n(2, 121)\n\n\n\nnp.array(a.edge_weight).shape\n\n(121,)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_windmillsmall.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 11):\n    node_list.append(i)\n\n\nfig,ax = plt.subplots(11,1,figsize=(30,50))\nfor k in range(11):\n    ax[k].plot(np.array(loader6.targets).reshape(11,-1)[k][:],label='observed')\n    ax[k].set_title('node: {}'.format(node_list[k]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# ê° ì„œë¸Œí”Œë¡¯ì— ì„  ê·¸ë˜í”„ ì¶”ê°€\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# ê·¸ë˜í”„ í¬ê¸° ì¡°ì •\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# ê·¸ë˜í”„ ì¶œë ¥\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_windmillsmall.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_windmillsmall.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#metrladatasetloader_real-world-traffic-dataset",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#metrladatasetloader_real-world-traffic-dataset",
    "title": "data load, data save as pickle",
    "section": "METRLADatasetLoader_real world traffic dataset",
    "text": "METRLADatasetLoader_real world traffic dataset\nA traffic forecasting dataset based on Los Angeles Metropolitan traffic conditions. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County in aggregated 5 minute intervals for 4 months between March 2012 to June 2012.\në°ì´í„°ì •ë¦¬\n\nT = 33\nV = êµ¬ì—­\nN = 207 # number of nodes\nE = 225\n\\(f(v,t)\\)ì˜ ì°¨ì›? (3,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? False\nX: (207,4) (N,2,12), \\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\ny: (207,) (N,), \\((x_{12})\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\nhttps://arxiv.org/pdf/1707.01926.pdf\n- Nodes : 207\n\nvertices are localities\n\n-Edges : 225\n\nedges are spatial_connections\n\n- Time : 33\n\nbetween 2020 and 2021\nper weeks\n\n\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nloader7 = METRLADatasetLoader()\n\n\na = loader7.get_dataset(num_timesteps_in=1,num_timesteps_out=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 1722)\n\n\n\nnp.array(a.edge_weight).shape\n\n(1722,)\n\n\n\nnp.array(a.targets).shape\n\n(34271, 207, 1)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 207):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 207), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader7.targets).reshape(207,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#pemsbaydatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#pemsbaydatasetloader",
    "title": "data load, data save as pickle",
    "section": "PemsBayDatasetLoader",
    "text": "PemsBayDatasetLoader\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12644\n\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nA traffic forecasting dataset as described in Diffusion Convolution Layer Paper.\nThis traffic dataset is collected by California Transportation Agencies (CalTrans) Performance Measurement System (PeMS). It is represented by a network of 325 traffic sensors in the Bay Area with 6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals.\nFor details see: \"Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>\nìº˜ë¦¬í¬ë‹ˆì•„ êµí†µêµ­(CalTrans) ì„±ëŠ¥ ì¸¡ì • ì‹œìŠ¤í…œ(PeMS)ì—ì„œ ìˆ˜ì§‘\n2017ë…„ 1ì›” 1ì¼ë¶€í„° 2017ë…„ 5ì›” 31ì¼ê¹Œì§€ 6ê°œì›” ë™ì•ˆ 5ë¶„ ê°„ê²©ìœ¼ë¡œ íŠ¸ë˜í”½ íŒë…ì¹˜ê°€ í¬í•¨ëœ ë² ì´ ì§€ì—­ì˜ 325ê°œ êµí†µ ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ë¡œ í‘œì‹œ\n\në°ì´í„°ì •ë¦¬\n\nT = 17470\nV = êµí†µì„¼ì„œ\nN = 325 # number of nodes\nE = 2694 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # Hourly energy output\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? No\nX: (325,2,12) (N,2,12),\n\n\\(x_0,x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11}\\)\n\\(z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8,z_9,z_{10},z_{11}\\)\n\ny: (325,) (N,2,12),\n\n\\(x_{13},x_{14},x_{15},x_{16},x_{17},x_{18},x_{19},x_{20},x_{21},x_{22},x_{23},x_{24}\\)\n\\(z_{13},z_{14},z_{15},z_{16},z_{17},z_{18},z_{19},z_{20},z_{21},z_{22},z_{23},z_{24}\\)\n\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 325\n\nvertices are sensors\n\n-Edges : 2694\n\nweighted edges are between seonsor paris measured by the road nretwork distance\n\n- Time : 52081\n\n6 months of traffic readings ranging from Jan 1st 2017 to May 31th 2017 in 5 minute intervals\n\n\nfrom torch_geometric_temporal.dataset import PemsBayDatasetLoader\nloader8 = PemsBayDatasetLoader()\n\n\na = loader8.get_dataset(num_timesteps_in=1,num_timesteps_out=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 2694)\n\n\n\na.edge_index\n\narray([[  0,   1,   2, ..., 324, 324, 324],\n       [  0,   1,   2, ..., 257, 310, 324]])\n\n\n\nnp.array(a.edge_weight).shape\n\n(2694,)\n\n\n\nnp.array(a.targets).shape\n\n(52104, 325, 2, 1)\n\n\n\na.targets[0][0][0]\n\narray([0.99281436], dtype=float32)\n\n\n\nnode_list = []\nfor i in range(0, 325):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 325), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader8.targets).reshape(325,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#englandcoviddatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#englandcoviddatasetloader",
    "title": "data load, data save as pickle",
    "section": "EnglandCovidDatasetLoader",
    "text": "EnglandCovidDatasetLoader\nCovid19 England\n\nA dataset about mass mobility between regions in England and the number of confirmed COVID-19 cases from March to May 2020 [38]. Each day contains a different mobility graph and node features corresponding to the number of cases in the previous days. Mobility stems from Facebook Data For Good 1 and cases from gov.uk 2\n\nhttps://arxiv.org/pdf/2009.08388.pdf\në°ì´í„°ì •ë¦¬\n\nT = 60\nV = ì§€ì—­\nN = 129 # number of nodes\nE = 2158\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # ì½”ë¡œë‚˜í™•ì§„ììˆ˜\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of edgeê°€ ë³€í•˜ëŠ”ì§€? TRUE\nX: (20,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (20,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 129\n\nvertices are correspond to the number of COVID-19 cases in the region in the past window days.\n\n-Edges : 2158\n\nthe spatial edges capture county-to-county movement at a specific date, and a county is connected to a number of past instances of itself with temporal edges.\n\n- Time : 61\n\nfrom 3 March to 12 of May\n\n\nfrom torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\nloader9 = EnglandCovidDatasetLoader()\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n\na = loader9.get_dataset(lags=1)\n\n\na, _a = temporal_signal_split(a, train_ratio=0.8)\n\n\na.snapshot_count,_a.snapshot_count\n\n(60, 12)\n\n\nì›ë˜ 60\n\na.edge_indices[59]\n\nIndexError: list index out of range\n\n\n\nnp.array(a.edge_indices[59]).shape\n\n(2, 1476)\n\n\n\na.edge_weights[59]\n\narray([2.96600e+03, 1.88595e+05, 1.30000e+02, ..., 1.10000e+01,\n       1.80000e+01, 1.00000e+01])\n\n\n\nnp.array(a.edge_weights[59]).shape\n\n(1476,)\n\n\n\na.snapshot_count\n\n60\n\n\n\nnp.array(a.features).shape\n\n(60, 129, 1)\n\n\n\nnp.array(a.targets).shape\n\n(60, 129)\n\n\n\nG = nx.Graph()\nG.add_edges_from(a.edge_indices[0].T)\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nG = nx.Graph()\nG.add_edges_from(a.edge_indices[58].T)\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 129):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 129), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader9.targets).reshape(129,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#montevideobusdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#montevideobusdatasetloader",
    "title": "data load, data save as pickle",
    "section": "MontevideoBusDatasetLoader",
    "text": "MontevideoBusDatasetLoader\nMontevideo Buses\n\nA dataset of inflow passenger at bus stop level from Montevideo city. This dataset comprises hourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay). The bus lines selected are the ones that carry people to the center of the city and they load more than 25% of the total daily inflow traffic. Vertices are bus stops, edges are links between bus stops when a bus line connects them and the weight represent the road distance. The target is the passenger inflow. This is a curated dataset made from different data sources of the Metropolitan Transportation System (STM) of Montevideo. These datasets are freely available to anyone in the National Catalog of Open Data from the government of Uruguay (https://catalogodatos.gub.uy/)\nëª¬í…Œë¹„ë°ì˜¤ ì‹œí‹°ì—ì„œ ë²„ìŠ¤ ì •ë¥˜ì¥ ì¸µìœ¼ë¡œ ìœ ì…ëœ ìŠ¹ê°ì˜ ë°ì´í„° ì…‹\n2020ë…„ 10ì›” ë™ì•ˆ ëª¬í…Œë¹„ë°ì˜¤ ì‹œí‹°(ìš°ë£¨ê³¼ì´)ì—ì„œ 11ê°œ ë²„ìŠ¤ ë…¸ì„ ì— ëŒ€í•œ ë²„ìŠ¤ ì •ë¥˜ì¥ ìˆ˜ì¤€ì˜ ì‹œê°„ë‹¹ ìœ ì… ìŠ¹ê° ë°ì´í„°\nì„ ì •ëœ ë²„ìŠ¤ ë…¸ì„ ì€ ë„ì‹¬ê¹Œì§€ ì‚¬ëŒì„ ì‹¤ì–´ ë‚˜ë¥´ëŠ” ë…¸ì„ ìœ¼ë¡œ í•˜ë£¨ ì´ ìœ ì…ëŸ‰ì˜ 25% ì´ìƒì„ ì ì¬\nnodeëŠ” ë²„ìŠ¤ ì •ë¥˜ì¥\nedgeëŠ” ë²„ìŠ¤ ë…¸ì„ ì´ ë²„ìŠ¤ ì •ë¥˜ì¥ì„ ì—°ê²°í•  ë•Œ ë²„ìŠ¤ ì •ë¥˜ì¥ ì‚¬ì´ì˜ ë§í¬\nweightëŠ” ë„ë¡œ ê±°ë¦¬\ntargetì€ ìŠ¹ê° ìœ ì…\nëª¬í…Œë¹„ë°ì˜¤ì˜ ë©”íŠ¸ë¡œí´ë¦¬íƒ„ êµí†µ ì‹œìŠ¤í…œ(STM)ì˜ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ë¡œ ë§Œë“¤ì–´ì§„ íë ˆì´ì…˜ëœ ë°ì´í„° ì…‹\n\në°ì´í„°ì •ë¦¬\n\nT = 743\nV = ë²„ìŠ¤ì •ë¥˜ì¥\nN = 675 # number of nodes\nE = 101761 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # passenger inflow\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nX: (675,4) (N,4), \\(f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3)\\)\ny: (675,,) (N,), \\(f(v,t_4)\\)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 675\n\nvertices are bus stops\n\n-Edges : 690\n\nedges are links between bus stops when a bus line connects them and the weight represent the road distance\n\n- Time : 743\n\nhourly inflow passenger data at bus stop level for 11 bus lines during October 2020 from Montevideo city (Uruguay).\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader10 = MontevideoBusDatasetLoader()\n\n\na = loader10.get_dataset(lags=1)\n\n\nnp.array(a.edge_index).shape\n\n(2, 690)\n\n\n\nnp.array(a.edge_weight).shape\n\n(690,)\n\n\n\nnp.array(a.features).shape\n\n(743, 675, 1)\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(a.edge_index.T)\n\n\nplt.figure(figsize=(20, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='green', node_size=550, font_color='white', width=1)\nplt.savefig(\"graph_node_monte.png\")\n\n\n\n\n\nnx.draw(G,with_labels=True,font_weight='bold',node_color='green',node_size=350,font_color='white',width=1)\n\n\n\n\n\nnode_list = []\nfor i in range(0, 675):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 319), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader10.targets).reshape(675,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nx = list(range(a.snapshot_count))\ny1 = np.array(a.features)[:, 0, :].reshape(-1)\ny2 = np.array(a.features)[:, 1, :].reshape(-1)\ny3 = np.array(a.features)[:, 2, :].reshape(-1)\ny4 = np.array(a.features)[:, 3, :].reshape(-1)\ny5 = np.array(a.features)[:, 4, :].reshape(-1)\ny6 = np.array(a.features)[:, 5, :].reshape(-1)\n\n_df = pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'y6':y6})\n\n\nfig = make_subplots(rows=2, cols=3)\n\n# ê° ì„œë¸Œí”Œë¡¯ì— ì„  ê·¸ë˜í”„ ì¶”ê°€\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y1'], mode='lines', name='node 0'), row=1, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y2'], mode='lines', name='node 1'), row=1, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y3'], mode='lines', name='node 2'), row=1, col=3)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y4'], mode='lines', name='node 3'), row=2, col=1)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y5'], mode='lines', name='node 4'), row=2, col=2)\nfig.add_trace(go.Scatter(x=_df['x'], y=_df['y6'], mode='lines', name='node 5'), row=2, col=3)\n\n# ê·¸ë˜í”„ í¬ê¸° ì¡°ì •\nfig.update_layout(width=1000, height=500, legend=dict(x=0.5, y=1.1, orientation='h'))\n\n# ê·¸ë˜í”„ ì¶œë ¥\nfig.show()\n\n\n                                                \n\n\n\nwith open('fig_monte.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open(\"fig_monte.pkl\", \"rb\") as file:\n    loaded_object1 = pickle.load(file)\n\nloaded_object1"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#twittertennisdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#twittertennisdatasetloader",
    "title": "data load, data save as pickle",
    "section": "TwitterTennisDatasetLoader",
    "text": "TwitterTennisDatasetLoader\nhttps://appliednetsci.springeropen.com/articles/10.1007/s41109-018-0080-5?ref=https://githubhelp.com\nTwitter Tennis RG and UO\n\nTwitter mention graphs of major tennis tournaments from 2017. Each snapshot contains the graph of popular player or sport news accounts and mentions between them [5, 6]. Node labels encode the number of mentions received and vertex features are structural properties\n\në°ì´í„°ì •ë¦¬\n\nT = 52081\nV = íŠ¸ìœ„í„°ê³„ì •\n\nN = 1000 # number of nodes\nE = 119 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (1,) # passenger inflow\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? ??\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? True\nX: ?\ny: ?\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 1000\n\nvertices are Twitter accounts\n\n-Edges : 119\n\nedges are mentions between them\n\n- Time : 52081\n\nTwitter mention graphs related to major tennis tournaments from 2017\n\n\nfrom torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\nloader11 = TwitterTennisDatasetLoader()\n\n\na = loader11.get_dataset()\n\n\na.edge_indices[119]\n\narray([[900, 347, 347, 407, 407, 407, 407, 407, 407,   0,  35, 448, 407,\n        396, 396, 370, 233, 233, 357,  15,  15, 135, 135, 358, 233, 233,\n        243, 115, 115, 667, 667, 667, 667, 440, 440, 440, 101, 650, 309,\n        309, 309, 233, 347, 347, 974, 161, 218, 309, 309,  93,  93, 813,\n        101, 417,  69,  69, 480, 480, 416, 272, 813, 813, 813, 379, 903,\n        903, 903,  95, 309, 309, 309, 144, 890, 890, 484, 484, 484, 653,\n        653, 234, 234, 234, 253, 253, 630, 769, 769, 156, 156, 156, 892,\n        912, 912,   0, 278, 896, 896, 896, 233,  92,  69, 802, 324, 324,\n        574,  87,  87,  87, 365, 365,  87, 522, 611, 427, 427, 427, 110,\n        246, 246, 445, 156, 156, 133, 133, 217, 217,   4,   4, 105, 105,\n        105, 105, 630, 630, 630, 792,  84, 452,  51,  84, 445, 613, 985,\n        290, 290, 290, 290, 290, 290, 420, 420, 420, 420, 420, 420, 420,\n        420, 420,   0, 626, 626, 519, 519, 519, 519, 519, 519, 519, 519,\n        519, 217, 437, 437, 437, 309, 309, 217, 666,   4, 637, 540,  38,\n         38, 605, 605, 605, 605, 605, 215],\n       [  0,   0, 152,  41, 590,   0, 133, 116, 731,   1,   1,   1,   2,\n          0,   1,   0,   0, 982,   2,   1,   0,   0,   1,  51,   1, 427,\n          2,  74,   0,   1,  97,   0,   5,   0,   1, 614,  99,   0, 427,\n          0,   1, 203,   2,   1, 731,   1,   1,   2,  15,   0, 152,   1,\n          1,   0,   0,   1,   1,   0,   0,   0,  81,  97,   0,   0,   0,\n        416,  69,   1, 317,  67, 438,   0,   0,   1,   0,   1, 234,  15,\n          0,   1, 484,   0,   0, 141,   0,   1,  97, 221,   0, 540, 445,\n          1,   0,   2,   0,   0, 132, 438, 745,  92,   2,  80,   0, 152,\n          0,   0,   1,   4, 129, 338, 170,   0,   1, 123,   1,   0,   1,\n          1,   0,   1,   1, 427,   0,   1,   1, 217,   0,   1,   1,  97,\n          0, 226, 123,   1, 427,   0,   0,   1,   1,   1,   0,   1,   1,\n          5, 121,   0,  99,  15, 226,   5,   2, 221,  97,   6,  99, 226,\n        121,   0, 706,   0, 211,  99,   0,   5,  97, 226, 121,   6, 221,\n          2,   0,   1,   0, 217,  69, 416, 210,   0, 634, 291, 236,   1,\n          0, 234, 437, 286,   1, 745,  56]])\n\n\n\na.edge_weights[119]\n\narray([1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 6, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 3, 1,\n       3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n\na.features[119]\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])\n\n\n\na.snapshot_count\n\n120\n\n\n\nnp.array(a.targets).shape\n\n(120, 1000)\n\n\n\nnode_list = []\nfor i in range(0, 1000):\n    node_list.append(i)\n\n\nfig, ax = plt.subplots(20, 1, figsize=(30, 50))\nindices = random.sample(range(0, 1000), 20)\nfor k, idx in enumerate(indices):\n    ax[k].plot(np.array(loader11.targets).reshape(1000,-1)[idx], label='observed')\n    ax[k].set_title('node: {}'.format(node_list[idx]))\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\ndef transform_degree(x, cutoff=4):\n    log_deg = np.ceil(np.log(x + 1.0))\n    return np.minimum(log_deg, cutoff)\n\n\ndef transform_transitivity(x):\n    trans = x * 10\n    return np.floor(trans)\n\n\ndef onehot_encoding(x, unique_vals):\n    E = np.zeros((len(x), len(unique_vals)))\n    for i, val in enumerate(x):\n        E[i, unique_vals.index(val)] = 1.0\n    return E\n\n\ndef encode_features(X, log_degree_cutoff=4):\n    X_arr = np.array(X)\n    a = transform_degree(X_arr[:, 0], log_degree_cutoff)\n    b = transform_transitivity(X_arr[:, 1])\n    A = onehot_encoding(a, range(log_degree_cutoff + 1))\n    B = onehot_encoding(b, range(11))\n    return np.concatenate((A, B), axis=1)"
  },
  {
    "objectID": "posts/GCN/2023-03-20-data load, data save as pickle.html#mtmdatasetloader",
    "href": "posts/GCN/2023-03-20-data load, data save as pickle.html#mtmdatasetloader",
    "title": "data load, data save as pickle",
    "section": "MTMDatasetLoader",
    "text": "MTMDatasetLoader\nMTM-1 Hand Motions\n\nA dataset of Methods-Time Measurement-1 <https://en.wikipedia.org/wiki/Methods-time_measurement>(MTM-1) motions, signalled as consecutive video frames of 21 3D hand keypoints, acquired via MediaPipe Hands <https://google.github.io/mediapipe/solutions/hands.html> from RGB-Video material. Vertices are the finger joints of the human hand and edges are the bones connecting them. The targets are manually labeled for each frame, according to one of the five MTM-1 motions (classes :math:C): Grasp, Release, Move, Reach, Position plus a negative class for frames without graph signals (no hand present). This is a classification task where :math:T consecutive frames need to be assigned to the corresponding class :math:C. The data x is returned in shape :obj:(3, 21, T), the target is returned one-hot-encoded in shape :obj:(T, 6).\n\në°ì´í„°ì •ë¦¬\n\nT = 14452\nV = ì†ì˜ shapeì— ëŒ€ì‘í•˜ëŠ” dot\n\nN = 325 # number of nodes\nE = 19 = N^2 # edges\n\\(f(v,t)\\)ì˜ ì°¨ì›? (Grasp, Release, Move, Reach, Poision, -1)\nì‹œê°„ì— ë”°ë¼ì„œ Nì´ ë³€í•˜ëŠ”ì§€? ??\nì‹œê°„ì— ë”°ë¼ì„œ Eê°€ ë³€í•˜ëŠ”ì§€? ??\nX: ?\ny: ?\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: No\n\n- Nodes : 325\n\nvertices are are the finger joints of the human hand\n\n-Edges : 19\n\nedges are the bones connecting them\n\n- Time : 14452\n\n # target eoncoding: {0 : 'Grasp', 1 : 'Move', 2 : 'Negative',\n        #                   3 : 'Position', 4 : 'Reach', 5 : 'Release'}\n\n\nfrom torch_geometric_temporal.dataset import MTMDatasetLoader\nloader12 = MTMDatasetLoader()\n\n\na = loader12.get_dataset(frames=16)\n\n\nnp.array(a.edge_index).shape\n\n(2, 19)\n\n\n\nnp.shape(a.edge_weight)\n\n(19,)\n\n\n\nnp.array(a.features).shape\n\n(14453, 3, 21, 16)\n\n\n\na.snapshot_count\n\n14453\n\n\n\nnp.array(a.targets).shape\n\n(14453, 16, 6)\n\n\n\na.targets[0]\n\narray([[0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.]])\n\n\n\nb=[]\nfor i in range(a.snapshot_count):\n    b.append(np.argmax(a.targets[i]))\n\n\npd.DataFrame(b)[0].unique()\n\narray([2, 4, 0, 1, 3, 5])\n\n\n\npd.DataFrame(b).value_counts()\n\n0    3910\n1    3189\n3    3069\n4    2480\n2    1266\n5     539\ndtype: int64"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.172\n      0.064\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.164\n      0.065"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.173\n      0.048\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.201\n      0.064\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.209\n      0.073\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.216\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.165\n      0.051\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.185\n      0.061"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      32\n      IT-STGCN\n      0.984\n      0.016\n    \n    \n      1\n      32\n      STGCN\n      0.988\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      32\n      IT-STGCN\n      0.998\n      0.019\n    \n    \n      1\n      0.3\n      linear\n      32\n      STGCN\n      1.054\n      0.011\n    \n    \n      2\n      0.8\n      linear\n      32\n      IT-STGCN\n      1.161\n      0.054\n    \n    \n      3\n      0.8\n      linear\n      32\n      STGCN\n      1.234\n      0.096"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-1",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      32\n      IT-STGCN\n      1.002350\n      0.015102\n    \n    \n      1\n      linear\n      0.28777\n      32\n      STGCN\n      1.027605\n      0.015945\n    \n    \n      2\n      nearest\n      0.28777\n      32\n      IT-STGCN\n      0.998713\n      0.021721\n    \n    \n      3\n      nearest\n      0.28777\n      32\n      STGCN\n      1.025797\n      0.014844"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.213\n      0.045\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.234\n      0.055"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.251\n      0.072\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.267\n      0.072\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.251\n      0.057\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.265\n      0.056\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.065\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.305\n      0.092\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.267\n      0.067\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.292\n      0.075"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-2",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.246\n      0.034\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.230\n      0.056\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.245\n      0.045\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.246\n      0.035"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#w_st",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.223\n      0.041\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.048\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.234\n      0.046\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.252\n      0.071\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.269\n      0.092\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.304\n      0.061\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.072\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.321\n      0.094\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.204\n      0.033\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.210\n      0.058\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.211\n      0.033\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.241\n      0.095"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      nof_filters\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-3",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-4",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#baseline-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      1.317\n      0.118\n    \n    \n      1\n      4\n      STGCN\n      0.997\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#random-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      2.263371\n      0.476410\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      2.622998\n      0.693321"
  },
  {
    "objectID": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html#block-5",
    "title": "EvolveGCNO_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      1.345316\n      0.110313\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      1.766133\n      0.123163"
  },
  {
    "objectID": "posts/GCN/2023-05-11-CPUvsGPU.html",
    "href": "posts/GCN/2023-05-11-CPUvsGPU.html",
    "title": "PyG Geometric Temporal CPU vs GPU",
    "section": "",
    "text": "CPU vs GPU\n\n\n!nvidia-smi\n\nFri May 12 06:42:19 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n|  0%   37C    P8    35W / 420W |     19MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A      1062      G   /usr/lib/xorg/Xorg                  9MiB |\n|    0   N/A  N/A      1309      G   /usr/bin/gnome-shell                8MiB |\n+-----------------------------------------------------------------------------+\n\n\n\nimport time\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue\n\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\n\nGPU\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n\ntime.time()\n\n1683806883.6646736\n\n\n\nt1=time.time()\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).to(\"cuda:0\")\n        cost = cost + torch.mean((y_hat-snapshot.y.to(\"cuda:0\"))**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [03:05<00:00,  1.08it/s]\n\n\n\nimport time\n\n\nt2=time.time()\n\n\nt2-t1\n\n185.09801506996155\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.0507\n\n\n\n\nCPU\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n\nimport time\n\n\nt1=time.time()\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [05:08<00:00,  1.54s/it]\n\n\n\nimport time\n\n\nt2=time.time()\n\n\nt2-t1\n\n308.58231496810913\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.0542"
  },
  {
    "objectID": "posts/GCN/2022-12-28-gcn_simulation.html",
    "href": "posts/GCN/2022-12-28-gcn_simulation.html",
    "title": "Simulation of geometric-temporal",
    "section": "",
    "text": "Simulation\n\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\n\nimport\n\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\n\nê³µì‹ í™ˆí˜ì´ì§€ ì˜ˆì œ\n\ndata\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\n\nRecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\n\nLearn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(1)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]\n\n\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\nsnapshot.y.shape\n\ntorch.Size([1068])\n\n\n\n1068ê°œì˜ nodes\ní•œ ê°œì˜ nodeì— mappingëœ ì°¨ì›ì˜ ìˆ˜\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n\n\nìš°ë¦¬ ì˜ˆì œ\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\nT = 100\nN = 4 # number of Nodes\nE = np.array([[0,1],[1,2],[2,3],[3,0]]).T\nV = np.array([1,2,3,4])\nAMP = np.array([3,2,1,2.2])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = np.stack([a*np.sin(2*t**2/1000)+np.random.normal(loc=0,scale=0.2,size=T) for a in AMP],axis=1).reshape(T,N,node_features)\nf = torch.tensor(f).float()\n\n\nf.shape\n\ntorch.Size([100, 4, 1])\n\n\n\nX = f[:99,:,:]\ny = f[1:,:,:]\n\n\nplt.plot(y[:,0,0],label=\"v1\")\nplt.plot(y[:,1,0],label=\"v2\")\nplt.plot(y[:,2,0],label=\"v3\")\nplt.plot(y[:,3,0],label=\"v4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc48673490>\n\n\n\n\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:16<00:00,  3.01it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(y[:,0,0],label=\"y in V1\")\nplt.plot(yhat[:,0,0],label=\"yhat in V1\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc48524730>\n\n\n\n\n\n\nplt.plot(y[:,1,0],label=\"y in V2\")\nplt.plot(yhat[:,1,0],label=\"yhat in V2\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc4849c730>\n\n\n\n\n\n\nplt.plot(y[:,2,0],label=\"y in V3\")\nplt.plot(yhat[:,2,0],label=\"yhat in V3\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc484098e0>\n\n\n\n\n\n\nplt.plot(y[:,3,0],label=\"y in V4\")\nplt.plot(yhat[:,3,0],label=\"yhat in V4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7efc483f5880>\n\n\n\n\n\n\n\nGNAR\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: â€˜igraphâ€™\n\n\nR[write to console]: The following objects are masked from â€˜package:statsâ€™:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from â€˜package:baseâ€™:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\n%%R\nsummary(fiveNet)\n\nGNARnet with 5 nodes and 10 edges\n of equal length  1\n\n\n\n%%R\nedges <- as.matrix(fiveNet)\nedges\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    1    1\n[2,]    0    0    1    1    0\n[3,]    0    1    0    1    0\n[4,]    1    1    1    0    0\n[5,]    1    0    0    0    0\n\n\n\n%%R\nprint(fiveNet)\n\nGNARnet with 5 nodes \nedges:1--4 1--5 2--3 2--4 3--2 3--4 4--1 4--2 4--3 5--1 \n     \n edges of each of length  1 \n\n\n\n%%R\ndata(\"fiveNode\")\nanswer <- GNARfit(vts = fiveVTS, net = fiveNet, alphaOrder = 2, betaOrder = c(1, 1))\nanswer\n\nModel: \nGNAR(2,[1,1]) \n\nCall:\nlm(formula = yvec ~ dmat + 0)\n\nCoefficients:\n dmatalpha1  dmatbeta1.1   dmatalpha2  dmatbeta2.1  \n    0.20624      0.50277      0.02124     -0.09523  \n\n\n\n\n%%R\nlayout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))\nplot(fiveVTS[, 1], ylab = \"Node A Time Series\")\nlines(fitted(answer)[, 1], col = 2)\nplot(fiveVTS[, 2], ylab = \"Node B Time Series\")\nlines(fitted(answer)[, 2], col = 2)\nplot(fiveVTS[, 3], ylab = \"Node C Time Series\")\nlines(fitted(answer)[, 3], col = 2)\nplot(fiveVTS[, 4], ylab = \"Node D Time Series\")\nlines(fitted(answer)[, 4], col = 2)\n\n\n\n\n\n%R -o fiveVTS\n%R -o edges\n\n\nnode: 5\ntime 200\n\n\nedges_tensor = torch.tensor(edges)\n\n\nnonzero_indices = edges_tensor.nonzero()\n\n\nfiveNet_edge = np.array(nonzero_indices).T\nfiveNet_edge\n\narray([[0, 0, 1, 1, 2, 2, 3, 3, 3, 4],\n       [3, 4, 2, 3, 1, 3, 0, 1, 2, 0]])\n\n\n\nfiveVTS.shape\n\n(200, 5)\n\n\n\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(fiveVTS).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=8)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆ| 50/50 [00:34<00:00,  1.45it/\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nyhat.shape\n\n(199, 5, 1)\n\n\n\nplt.plot(y[:,1])\nplt.plot(yhat[:,1].data)\n\n\n\n\n\n\nWind network time series\nthe data suite vswind that contains a number of R objects pertaining to 721 wind speeds taken at each of 102 weather stations in England and Wales. The suite contains the vector time series vswindts, the associated network vswindnet, a character vector of the weather station location names in vswindnames and coordinates of the stations in the two column matrix vswindcoords. The data originate from the UK Met Office site http://wow.metoffice.gov.uk and full details can be found in the vswind help file in the GNAR package.\n\n%%R\noldpar <- par(cex = 0.75)\nwindnetplot()\npar(oldpar)\n\n\n\n\n\n%%R\nedges_wind <- as.matrix(vswindnet)\n\n\n%R -o vswindts\n%R -o edges_wind\n\n\nnodes : 102\ntime step : 721\n\n\nvswindts.shape\n\n(721, 102)\n\n\n\nedges_wind.shape\n\n(102, 102)\n\n\n\nedges_winds = torch.tensor(edges_wind)\n\n\nnonzero_indices_wind = edges_winds.nonzero()\n\n\nvswindnet_edge = np.array(nonzero_indices_wind).T\nvswindnet_edge.shape\n\n(2, 202)\n\n\n\nT = 721\nN = 102 # number of Nodes\nE = vswindnet_edge\nV = np.array(range(101))\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(vswindts).reshape(721,102,1).float()\n\n\nX = f[:720,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1]*202),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:16<00:00,  2.73s/it]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nyhat.shape\n\n(720, 102, 1)\n\n\n\nplt.plot(y[:,1])\nplt.plot(yhat[:,1].data)\n\n\n\n\n\n\nOECD GDP\ní•´ë‹¹ì˜ˆì œëŠ” GNAR íŒ¨í‚¤ì§€ì—ì„œ ë„¤íŠ¸ì›Œí¬(ì—£ì§€)ë¥¼ ë§ì¶”ëŠ” ì˜ˆì œë¡œì„œ ë‚˜ì˜´, ê·¸ë ‡ê¸°ì— ë„¤íŠ¸ì›Œí¬ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì—°êµ¬ ì˜ˆì œë¡œì„œ ì‚¬ìš©í•˜ì§€ ì•Šì„ ì˜ˆì •\nì´ ë°ì´í„°ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ì¶”ì •í•˜ì—¬ fit ë° predictí•¨\nGOP growth rate time series\n\n35 countries from the OECD website\ntime series : 1961 - 2013\nT = 52\nNodes = 35\nIn this data set 20.8% (379 out of 1820) of the observations were missing due to some nodes not being included from the start.\n\n\n%%R\nlibrary(\"fields\")\n\n\n%R -o gdpVTS\n\n\ngdpVTS.shape\n\n(52, 35)\n\n\n\nplt.plot(gdpVTS[:,1])"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "",
    "text": "ST-GCN Dataset WikiMathsDatasetLoader"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#train",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#train",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "Train",
    "text": "Train\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time,snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n583\n\n\n\nT_train = time\nN = len(data_train[0][1].x)\n\n\nedge_index = data_train[0][1].edge_index\nedge_attr = data_train[0][1].edge_attr\n\n\nx_train = []\nfor i in range(time):\n    x_train.append(data_train[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_train = data_tensor.reshape(time,1068,-1)\nx_train.shape\n\ntorch.Size([583, 1068, 1])\n\n\n\ny_train = []\nfor i in range(time):\n    y_train.append(data_train[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_train:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_train = data_tensor.reshape(time,1068)\ny_train.shape\n\ntorch.Size([583, 1068])\n\n\n\nx_train.shape, y_train.shape\n\n(torch.Size([583, 1068, 1]), torch.Size([583, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#test",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#test",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "Test",
    "text": "Test\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([1068, 1]),\n torch.Size([1068]),\n torch.Size([2, 27079]),\n torch.Size([27079]))\n\n\n\ntime\n\n145\n\n\n\nT_test = time\n\n\nx_test = []\nfor i in range(time):\n    x_test.append(data_test[i][1].x)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in x_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\nx_test = data_tensor.reshape(time,1068,-1)\nx_test.shape\n\ntorch.Size([145, 1068, 1])\n\n\n\ny_test = []\nfor i in range(time):\n    y_test.append(data_test[i][1].y)\n\n\ndata_tensor = torch.Tensor()\n# Iterate over the data points of the dataset\nfor i in y_test:\n    # Concatenate the data point to the tensor\n    data_tensor = torch.cat((data_tensor, i), dim=0)\ny_test = data_tensor.reshape(time,1068)\ny_test.shape\n\ntorch.Size([145, 1068])\n\n\n\nx_test.shape, y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤1-baseline",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)",
    "text": "ì‹œë‚˜ë¦¬ì˜¤1 (Baseline)\nì‹œë‚˜ë¦¬ì˜¤1\n\nmissing rate: 0%\në³´ê°„ë°©ë²•: None\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [05:31<00:00,  6.62s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n GNAR: mse(train) = {3:.2f}, mse(test) = {4:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(range(1,583),stgcn_train[:,i],label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test[:,i],label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),gnar_train[:,i],label='GNAR (train)',color='C1')\n    a.plot(range(583,728),gnar_test[:,i],label='GNAR (test)',color='C1')\n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario1: STGCN \\n missing=0% \\n interpolation=None \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n GNAR: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤2",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤2",
    "text": "ì‹œë‚˜ë¦¬ì˜¤2\nì‹œë‚˜ë¦¬ì˜¤2\n\nmissing rate: 50%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.5)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train[:,:,0][:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [05:34<00:00,  6.68s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [06:56<00:00,  8.33s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nx_test.shape,y_test.shape\n\n(torch.Size([145, 1068, 1]), torch.Size([145, 1068]))\n\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤3",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤3",
    "text": "ì‹œë‚˜ë¦¬ì˜¤3\nì‹œë‚˜ë¦¬ì˜¤3\n\nmissing rate: 80%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.8)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train.squeeze()[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [05:51<00:00,  7.04s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [07:00<00:00,  8.40s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "href": "posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html#ì‹œë‚˜ë¦¬ì˜¤4",
    "title": "Class of Method(WikiMath) lag 1",
    "section": "ì‹œë‚˜ë¦¬ì˜¤4",
    "text": "ì‹œë‚˜ë¦¬ì˜¤4\nì‹œë‚˜ë¦¬ì˜¤4\n\nmissing rate: 30%\në³´ê°„ë°©ë²•: linear\n\n- ê²°ì¸¡ì¹˜ìƒì„± + ë³´ê°„\n\n_zero = Missing(x_train.squeeze())\n_zero.miss(percent = 0.3)\n_zero.second_linear()\n\n\nmissing_index = _zero.number\ninterpolated_signal = _zero.train_linear\n\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.plot(missing_index[i],x_train.squeeze()[:,i][missing_index[i]],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.legend()\nfig.set_figwidth(15)\nfig\n\n\n\n\n\nSTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [05:54<00:00,  7.09s/it]\n\n\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nstgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nstgcn_test = yyhat.squeeze() \n\n\ntrain_mse_eachnode_stgcn = (((y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_stgcn = (((y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_stgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_stgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\n\nESTGCN ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n\nX = x_train.float()[:-1,:,:]\ny = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\n\nXX = x_test[:-1,:,:].float()\nyy = y_test.reshape(T_test,N,1)[1:,:,:].float()\n\n- ESTGCN\n\nnet = RecurrentGCN(node_features=1, filters=4)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nnet.train()\nsignal = interpolated_signal.copy()\nfor epoch in tqdm(range(50)):\n    signal = update_from_freq_domain(signal,missing_index)\n    X = torch.tensor(signal).reshape(T_train,N,1).float()[:-1,:,:]\n    y = torch.tensor(signal).reshape(T_train,N,1).float()[1:,:,:]\n    for time, (xt,yt) in enumerate(zip(X,y)):        \n        yt_hat = net(xt, edge_index, edge_attr)\n        cost = torch.mean((yt_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])        \n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [07:00<00:00,  8.40s/it]\n\n\n- ESTGCN\n\nyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\nyyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in XX]).detach().numpy()\n\n\nreal_y = y_train.reshape(T_train,N,1).float()[1:,:,:]\n\ntrain_mse_eachnode_estgcn = (((real_y-yhat).squeeze())**2).mean(axis=0)\ntrain_mse_total_estgcn = (((real_y-yhat).squeeze())**2).mean()\ntest_mse_eachnode_estgcn = (((yy-yyhat).squeeze())**2).mean(axis=0)\ntest_mse_total_estgcn = (((yy-yyhat).squeeze())**2).mean()\n\n\nestgcn_train = yhat.squeeze() # stgcnì€ stgcnì— ì˜í•œ ì í•©ê²°ê³¼ë¥¼ ì˜ë¯¸í•¨\nestgcn_test = yyhat.squeeze() \n\n\n\nGNAR ìœ¼ë¡œ ì í•© + ì˜ˆì¸¡\n-\n\nEdge = np.array(edge_index)\nX_gnar = np.array(x_train.squeeze())\n\n\nw=np.zeros((1068,1068))\n\n\nfor k in range(27079):\n    w[edge_index[0][k],edge_index[1][k]] = 1\n\n\n%R -i X_gnar\n%R -i w\n%R -i T_test\n\n\n%%R\nwikiNet <- matrixtoGNAR(w)\n\n\n%%R\nanswer <- GNARfit(vts = X_gnar, net = wikiNet, alphaOrder = 1, betaOrder = c(1))\nprediction <- predict(answer,n.ahead=T_test)\n\n\n%%R\ngnar_train <- residuals(answer)\ngnar_test <- prediction\n\n\n%R -o gnar_train\n%R -o gnar_test\n\n\ntrain_mse_eachnode_gnar = (gnar_train**2).mean(axis=0)\ntrain_mse_total_gnar = (gnar_train**2).mean()\ntest_mse_eachnode_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean(axis=0)\ntest_mse_total_gnar = ((yy.squeeze()-gnar_test[1:])**2).mean()\n\n\n\nê²°ê³¼ì‹œê°í™”\n\nfig = plot(x_train.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2)\nfig = plot_add(fig,x_test.squeeze()[:,:5],'--o',color='gray',label='complete data',alpha=0.2,t=range(581,726))\nax = fig.get_axes()\nfor i,a in enumerate(ax):     \n    a.set_title('node{0} \\n STGCN: mse(train) = {1:.2f}, mse(test) = {2:.2f} \\n ESTGCN: mse(train) = {3:.2f}, mse(test) = {4:.2f}\\n GNAR: mse(train) = {5:.2f}, mse(test) = {6:.2f}'.format(i,train_mse_eachnode_stgcn[i],test_mse_eachnode_stgcn[i],train_mse_eachnode_estgcn[i],test_mse_eachnode_estgcn[i],train_mse_eachnode_gnar[i],test_mse_eachnode_gnar[i]))\n    a.plot(missing_index[i],x_train[missing_index[i],i,0],'xk',label='missing')\n    a.plot(interpolated_signal[:,i],'-',color='gray',label='linear interpolation')\n    a.plot(range(1,583),stgcn_train.squeeze()[:,i],'--.',label='STCGCN (train)',color='C0')\n    a.plot(range(584,728),stgcn_test.squeeze()[:,i],'--.',label='STCGCN (test)',color='C0')\n    a.plot(range(1,583),estgcn_train.squeeze()[:,i],label='ESTCGCN (train)',color='C1')\n    a.plot(range(584,728),estgcn_test.squeeze()[:,i],label='ESTCGCN (test)',color='C1')\n    a.plot(range(1,583),gnar_train.squeeze()[:,i],label='GNAR (train)',color='C2')\n    a.plot(range(584,729),gnar_test.squeeze()[:,i],label='GNAR (test)',color='C2')\n    \n    a.legend()\nfig.set_figwidth(14)\nfig.suptitle(\"Scenario2: \\n missing=50% \\n interpolation=linear \\n\\n STGCN: mse(train) = {0:.2f}, mse(test) = {1:.2f} \\n ESTGCN: mse(train) = {2:.2f}, mse(test) = {3:.2f} \\n GNAR: mse(train) = {4:.2f}, mse(test) = {5:.2f} \\n\".format(train_mse_total_stgcn,test_mse_total_stgcn,train_mse_total_estgcn,test_mse_total_estgcn,train_mse_total_gnar,test_mse_total_gnar),size=15)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html",
    "title": "SimualtionPlanner-Tutorial",
    "section": "",
    "text": "table"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_rand",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.3,0.6],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n1/15 is done\n2/15 is done\n3/15 is done\n4/15 is done\n5/500\n\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.7],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGConvLSTM/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n1/50\n\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGCLSTM/learners.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader5,dataset_name='windmillmedium')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_manual",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_stgcn_manual",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,200))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = list(range(200,500))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(26)] #windmilmedi\nanother_list = list(range(200,500)) # 676*0.8 = 540.8\nmy_list[10] = another_list\nmindex = my_list\n\n\nimport numpy as np\n\n\nimport random\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,7500)) # 17470*0.8 = 13976.0\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nimport random\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = random.sample(range(0, 576), 432)\nfor i in range(0, 1068):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest','linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_rand",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\nplans_gnar_rand = {\n    'max_iteration': 30, \n#    'method': ['GNAR'], \n    'mrate': [0.8, 0.9],\n    'lags': [4], \n#    'nof_filters': [8,16], \n    'inter_method': ['cubic','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader2,dataset_name='pedalme')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate()\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_block",
    "href": "posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html#plnr_gnar_block",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,200))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = list(range(10,20))\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(26)] #windmilmedi\nanother_list = list(range(200,500)) # 676*0.8 = 540.8\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,10000)) # 17470*0.8 = 13976.0\nmy_list[10] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex = [[],[],list(range(50,250)),[],[]]\n# mindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [4,8], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex,mtype='block')\n\n\n# mindex = [[],[],list(range(50,250)),[],[]]\n# mindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [8], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader5,dataset_name='windmiloutputmedium')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader6,dataset_name='windmiloutputsmall')\nplnr.simulate(mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader10,dataset_name='monte')\nplnr.simulate(mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html",
    "href": "posts/GCN/2023-04-05-Simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random",
    "href": "posts/GCN/2023-04-05-Simulation.html#random",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_random_epoch200.csv')\n\n\ndf_gnar = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_random.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df_gnar],axis=0)\n\n\ndata.query(\"method!='GNAR' and inter_method=='linear' and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\n0.7,0.75,0.8,0.85\n12,16\n150\n\n# 1. mrate = 0.8, filter = 12, epoch = 150\ndata.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\")['calculation_time'].mean(),data.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\")['mse'].mean()\n\n(109.59549897114435, 1.2304790377616883)\n\n\n\ndata.query(\"mrate==0.8 and inter_method=='linear' and nof_filters==12 and epoch==150 and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block",
    "href": "posts/GCN/2023-04-05-Simulation.html#block",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndf1 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch50.csv')\ndf2 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch100.csv')\ndf3 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch150.csv')\ndf4 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node1_epoch200.csv')\ndf5 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch50.csv')\ndf6 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch100.csv')\ndf7 = pd.read_csv('./simulation_results/fivenodes/fivenodes_STGCN_ITSTGCN_block_node2_epoch150.csv')\ndf8 = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_block_node1.csv')\ndf9 = pd.read_csv('./simulation_results/fivenodes/fivenodes_GNAR_block_node2.csv')\n\n\ndf1['block']=1\ndf2['block']=1\ndf3['block']=1\ndf4['block']=1\ndf5['block']=2\ndf6['block']=2\ndf7['block']=2\ndf8['block']=1\ndf9['block']=2\n\n\ndata2 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9],axis=0)\n\n\ndata2.query(\"method=='GNAR' and block == 1\")['mse'].mean(),data2.query(\"method=='GNAR' and block == 2\")['mse'].mean()\n\n(1.455923080444336, 1.5004450678825378)\n\n\n\ndata2.query(\"method=='GNAR' and inter_method == 'linear'\")['mse'].mean(),data2.query(\"method=='GNAR' and inter_method == 'nearest'\")['mse'].mean() # ì°¨ì´ ì—†ìŒ\n\n(1.4813642161233085, 1.4813642161233085)\n\n\n\ndata2.query(\"epoch==50\")['calculation_time'].mean(),data2.query(\"epoch==50\")['calculation_time'].max()\n\n(39.11611335332747, 56.8712797164917)\n\n\n\ndata2.query(\"epoch==150\")['calculation_time'].mean(),data2.query(\"epoch==150\")['calculation_time'].max()\n\n(102.26520284502594, 152.8869686126709)\n\n\n\ndata2.query(\"method!='GNAR' and lags == 2 and inter_method=='nearest'\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=800)\n\n\n                                                \n\n\n\ndata2.query(\"inter_method=='linear' and epoch==150\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\nblock 1,2 ìœ„ ì„¸íŒ… ê·¸ëŒ€ë¡œ\nëœë¤ã… ë§ê³  blockë§Œ\n\n# 1. block = 2 interpolation = linear, filter = 12, epoch = 150\ndata2.query(\"block==1 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\")['calculation_time'].mean(),data2.query(\"block==2 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\")['mse'].mean()\n\n(40.18422634204229, 1.2096982955932618)\n\n\n\ndata2.query(\"block==1 and inter_method=='linear' and nof_filters==12 and epoch==50 and lags==2\").plot.box(backend='plotly',x='block',color='method',y='mse',facet_col='epoch',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-1",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-1",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\nê³µì‹ íŒ¨í‚¤ì§€: lags 4 ì§€ì •\nmrate = 0.3\n\nê²°ì¸¡ê°’ ë¹„ìœ¨ í¬ë‹ˆê¹Œ ì˜¤ì°¨ ë§ì´ ì»¤ì§€ëŠ” ê²½í–¥ ìˆì–´ì„œ\n\nnof_filters = 4\n\nì°¨ì´ ì—†ì–´ì„œ\n\nlags = 4, 8\n\ní´ ìˆ˜ë¡ ì‘ì•„ì§€ëŠ” ê²½í–¥ ìˆì–´ì„œ\n\nGNARë³´ë‹¤ MSEëŠ” ë‚®ìŒ\ncal_time\n\nmean = 10\nmax = 21\n\nblock ì€ ì„ì˜ë¡œ í•œ ë…¸ë“œë§Œ í•´ ë³¸ ê²°ê³¼ì„\n\n\ndata = pd.read_csv('./simulation_results/chickenpox_random.csv').sort_values(by='lags')\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n(10.42619569649299, 21.886654376983643, 7.567165851593018)\n\n\n\ndata.query(\"method!='GNAR' and inter_method=='cubic' and mrate==0.3\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\ndata.query(\"method=='GNAR' and inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=600)\n\n\n                                                \n\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\nepoch = 50\nmrate = 0.3~0.5\nfilter 32 ê³µì‹ì˜ˆì œë¡œ ê°€ê¸° í•˜ê³  ìƒ†ìœ¼ë©´ 3ê°œ ì •ë„ ì¶”ê°€ë¡œ\n\n# 1. mrate = 0.3, filter = 4, epoch = 50, lags = 4\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\")['calculation_time'].mean(),data.query(\"method != 'GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\")['mse'].mean()\n\n(10.115000387032827, 1.0320488701264063)\n\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==4 and lags==2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-1",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-1",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/chickenpox_block.csv')\n\n\ndata.query(\"method != 'GNAR' and lags!=4 and lags!=6 and inter_method !='linear'\").plot.box(backend='plotly',x='nof_filters',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method=='GNAR'\").plot.box(backend='plotly',x='mrate',color='inter_method',y='mse',facet_col='lags',height=600)\n\n\n                                                \n\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\nblock, rand ë‹¤\nê³µì‹ì˜ˆì œ ìˆ˜ ë”°ë¼\nepoch 50\në‚˜ì¤‘ì— ì‹œê°„ ë‚¨ìœ¼ë©´ 100\n\ndata.query(\"inter_method=='cubic' and nof_filters==4 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-2",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-2",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/pedalme_block.csv');data\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      0\n      pedalme\n      IT-STGCN\n      0.047619\n      block\n      2\n      4.0\n      cubic\n      5.0\n      1.229210\n      0.758090\n    \n    \n      1\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      12.0\n      linear\n      5.0\n      1.223644\n      0.681700\n    \n    \n      2\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      12.0\n      cubic\n      5.0\n      1.237086\n      0.684113\n    \n    \n      3\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      4.0\n      linear\n      5.0\n      1.225114\n      0.659210\n    \n    \n      4\n      pedalme\n      STGCN\n      0.047619\n      block\n      2\n      4.0\n      cubic\n      5.0\n      1.216191\n      0.664208\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      715\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      4.0\n      cubic\n      5.0\n      1.425474\n      0.640063\n    \n    \n      716\n      pedalme\n      STGCN\n      0.045977\n      block\n      8\n      12.0\n      cubic\n      5.0\n      1.302402\n      0.718187\n    \n    \n      717\n      pedalme\n      STGCN\n      0.045977\n      block\n      8\n      12.0\n      linear\n      5.0\n      1.336038\n      0.719500\n    \n    \n      718\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      12.0\n      linear\n      5.0\n      1.311962\n      0.831888\n    \n    \n      719\n      pedalme\n      IT-STGCN\n      0.045977\n      block\n      8\n      12.0\n      cubic\n      5.0\n      1.315647\n      0.667004\n    \n  \n\n720 rows Ã— 10 columns\n\n\n\nmissing rate ì¡°ì •í•˜ê¸° 30~50% ì—¬ëŸ¬ê°œ block í•´ì„œ\n\ndata.query(\"method!='GNAR'\").plot.box(backend='plotly',x='inter_method',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\n                                                \n\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==4\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-3",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-3",
    "title": "Simulation",
    "section": "random",
    "text": "random\n\ndf1 = pd.read_csv('./simulation_results/2023-04-15_16-58-03.csv')\ndf2 = pd.read_csv('./simulation_results/2023-04-15_17-01-39.csv')\ndf3 = pd.read_csv('./simulation_results/2023-04-15_17-07-23.csv')\ndf4 = pd.read_csv('./simulation_results/2023-04-15_17-13-13.csv')\ndf5 = pd.read_csv('./simulation_results/2023-04-15_17-29-49.csv')\n\n\ndata = pd.concat([df1,df2,df3,df4,df5],axis=0)\n\n\ndata.query(\"method=='STGCN'\").sort_values(['mrate','lags','nof_filters'])\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      0\n      wikimath\n      STGCN\n      0.3\n      rand\n      4\n      12\n      linear\n      1\n      0.863623\n      25.504817\n    \n    \n      0\n      wikimath\n      STGCN\n      0.3\n      rand\n      4\n      12\n      cubic\n      1\n      0.847675\n      27.086116\n    \n    \n      0\n      wikimath\n      STGCN\n      0.4\n      rand\n      2\n      12\n      linear\n      1\n      0.912734\n      30.048937\n    \n    \n      1\n      wikimath\n      STGCN\n      0.4\n      rand\n      2\n      12\n      cubic\n      1\n      0.916843\n      27.104823\n    \n    \n      0\n      wikimath\n      STGCN\n      0.4\n      rand\n      4\n      12\n      linear\n      1\n      0.907305\n      24.776503\n    \n    \n      1\n      wikimath\n      STGCN\n      0.4\n      rand\n      4\n      12\n      cubic\n      1\n      0.854127\n      24.608104\n    \n    \n      2\n      wikimath\n      STGCN\n      0.4\n      rand\n      8\n      12\n      linear\n      1\n      0.788011\n      24.233431\n    \n    \n      3\n      wikimath\n      STGCN\n      0.4\n      rand\n      8\n      12\n      cubic\n      1\n      0.795219\n      24.228026\n    \n    \n      0\n      wikimath\n      STGCN\n      0.5\n      rand\n      4\n      12\n      linear\n      1\n      0.914080\n      26.301605\n    \n    \n      1\n      wikimath\n      STGCN\n      0.5\n      rand\n      4\n      12\n      cubic\n      1\n      0.975948\n      27.855870\n    \n  \n\n\n\n\n\ndata.query(\"method!='STGCN'\").sort_values(['mrate','lags','nof_filters'])\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      mrate\n      mtype\n      lags\n      nof_filters\n      inter_method\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      1\n      wikimath\n      IT-STGCN\n      0.3\n      rand\n      4\n      12\n      linear\n      1\n      0.908916\n      28.928112\n    \n    \n      1\n      wikimath\n      IT-STGCN\n      0.3\n      rand\n      4\n      12\n      cubic\n      1\n      0.856639\n      29.759748\n    \n    \n      4\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      2\n      12\n      linear\n      1\n      0.864580\n      29.660712\n    \n    \n      5\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      2\n      12\n      cubic\n      1\n      0.926426\n      30.838968\n    \n    \n      2\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      4\n      12\n      linear\n      1\n      0.871146\n      29.008776\n    \n    \n      3\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      4\n      12\n      cubic\n      1\n      0.905354\n      30.405766\n    \n    \n      6\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      8\n      12\n      linear\n      1\n      0.822462\n      32.329447\n    \n    \n      7\n      wikimath\n      IT-STGCN\n      0.4\n      rand\n      8\n      12\n      cubic\n      1\n      0.817621\n      29.447260\n    \n    \n      2\n      wikimath\n      IT-STGCN\n      0.5\n      rand\n      4\n      12\n      linear\n      1\n      0.878943\n      31.140878\n    \n    \n      3\n      wikimath\n      IT-STGCN\n      0.5\n      rand\n      4\n      12\n      cubic\n      1\n      1.002361\n      28.461372\n    \n  \n\n\n\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n\ndata.query(\"mtype=='rand' and mrate != 0.9 and method!='GNAR' and inter_method=='cubic'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\ndata.query(\"mtype=='rand' and method!='GNAR' and inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"method !='GNAR' and mrate==0.3 and inter_method=='cubic' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and inter_method=='linear' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"method !='GNAR' and mrate==0.3 and inter_method=='linear' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"method !='GNAR' and mrate==0.3 and nof_filters==12 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-3",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-3",
    "title": "Simulation",
    "section": "block",
    "text": "block\n\ndata = pd.read_csv('./simulation_results/wiki_block.csv');data\n\n\ndata.query(\"method!='GNAR'\")['calculation_time'].mean(),data.query(\"method!='GNAR'\")['calculation_time'].max(),data.query(\"method!='GNAR'\")['calculation_time'].min()\n\n\ndata.query(\"method!='GNAR' and inter_method=='cubic'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\ndata.query(\"inter_method=='linear'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)\n\n\nì‹œë®¬ ì˜ˆì •(í‰ê·  ì‹œê°„, í‰ê· mse)\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==8\")['calculation_time'].mean(),data.query(\"inter_method=='linear' and nof_filters==12 and lags==8\")['mse'].mean()\n\n\ndata.query(\"inter_method=='linear' and nof_filters==12 and lags==8\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-4",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-4",
    "title": "Simulation",
    "section": "random",
    "text": "random"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-4",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-4",
    "title": "Simulation",
    "section": "block",
    "text": "block"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#random-5",
    "href": "posts/GCN/2023-04-05-Simulation.html#random-5",
    "title": "Simulation",
    "section": "random",
    "text": "random"
  },
  {
    "objectID": "posts/GCN/2023-04-05-Simulation.html#block-5",
    "href": "posts/GCN/2023-04-05-Simulation.html#block-5",
    "title": "Simulation",
    "section": "block",
    "text": "block"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html",
    "title": "GCLSTM_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-1",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-2",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "GCLSTM_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\n# df1 = pd.read_csv('./simulation_results/2023-06-13_18-41-53.csv') # gclm ì˜ëª» ëŒë¦¼\ndf1 = pd.read_csv('./simulation_results/2023-06-13_18-14-13.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-16_20-25-15.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/GCLSTM_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/GCLSTM_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-3",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GCLSTM_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-17_01-42-41.csv') # STGCN IT-STGCN block\n# df2 = pd.read_csv('./simulation_results/2023-06-17_03-35-20.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-17_10-06-34.csv') \n\ndf4 = pd.read_csv('./simulation_results/2023-07-10_05-37-15.csv') \ndf5 = pd.read_csv('./simulation_results/2023-07-10_11-00-23.csv') \ndf6 = pd.read_csv('./simulation_results/2023-07-10_16-03-18.csv') \n\n\ndata = pd.concat([df1,df3,df4,df5,df6],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/GCLSTM_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/GCLSTM_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-4",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#random-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html#block-5",
    "title": "GCLSTM_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-11-PyGGeometricTemporalEx.html",
    "href": "posts/GCN/2023-05-11-PyGGeometricTemporalEx.html",
    "title": "PyG Geometric Temporal Examples",
    "section": "",
    "text": "Examples\n\nRefer: https://github.com/benedekrozemberczki/pytorch_geometric_temporal/tree/master/examples/recurrent\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n\nT = 250\nt = np.arange(T)/T * 5\n\nx = 1*np.sin(2*t)+0.3*np.random.rand(T)+0.5+np.sin(4*t)+1.5*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.4*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\n# save_data(data_dict1, './data/toy_example1.pkl')\n\ndata = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\n# save_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\nimport itstgcn\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nGConvGRU(Done)\n\nGConvGRU?\n\n\nInit signature:\nGConvGRU(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the Chebyshev Graph Convolutional Gated Recurrent Unit\nCell. For details see this paper: `\"Structured Sequence Modeling with Graph\nConvolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gconv_gru.py\nType:           type\nSubclasses:     \n\n\n\n\n\n# from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):# 50\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        _b.append(y_hat)\n        mean_diff = torch.mean((y_hat-snapshot.y), dim=0)\n        cost = torch.square(mean_diff)\n        _d.append(cost)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:16<00:00,  3.00it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a = []\n_a1 = []\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.4200\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nA3GCN2\n\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n\n# import torch\n# import torch.nn.functional as F\n# from torch_geometric.nn import GCNConv\n# from torch_geometric_temporal.nn.recurrent import A3TGCN2\n\n\n# # GPU support\n# DEVICE = torch.device('cuda') # cuda\n# shuffle=True\n# batch_size = 32\n\n\n#Dataset\n#Traffic forecasting dataset based on Los Angeles Metropolitan traffic\n#207 loop detectors on highways\n#March 2012 - June 2012\n#From the paper: Diffusion Convolutional Recurrent Neural Network\n\n\n# from torch_geometric_temporal.dataset import METRLADatasetLoader\n# loader = METRLADatasetLoader()\n# dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\n\n# # Visualize traffic over time\n# sensor_number = 1\n# hours = 24\n# sensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\n# plt.plot(sensor_labels)\n\n\n# # Train test split \n\n# from torch_geometric_temporal.signal import temporal_signal_split\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\n# # Creating Dataloaders\n\n# train_input = np.array(train_dataset.features) # (27399, 207, 2, 12)\n# train_target = np.array(train_dataset.targets) # (27399, 207, 12)\n# train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n# train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n# train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n# train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)\n\n\n# test_input = np.array(test_dataset.features) # (, 207, 2, 12)\n# test_target = np.array(test_dataset.targets) # (, 207, 12)\n# test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n# test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n# test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n# test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)\n\n\n# # Making the model \n# class TemporalGNN(torch.nn.Module):\n#     def __init__(self, node_features, periods, batch_size):\n#         super(TemporalGNN, self).__init__()\n#         # Attention Temporal Graph Convolutional Cell\n#         self.tgnn = A3TGCN2(in_channels=node_features,  out_channels=32, periods=periods,batch_size=batch_size) # node_features=2, periods=12\n#         # Equals single-shot prediction\n#         self.linear = torch.nn.Linear(32, periods)\n\n#     def forward(self, x, edge_index):\n#         \"\"\"\n#         x = Node features for T time steps\n#         edge_index = Graph edge indices\n#         \"\"\"\n#         h = self.tgnn(x, edge_index) # x [b, 207, 2, 12]  returns h [b, 207, 12]\n#         h = F.relu(h) \n#         h = self.linear(h)\n#         return h\n\n\n# TemporalGNN(node_features=2, periods=12, batch_size=2)\n\n\n# # Create model and optimizers\n# model = TemporalGNN(node_features=2, periods=12, batch_size=batch_size).to(DEVICE)\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# loss_fn = torch.nn.MSELoss()\n\n\n# print('Net\\'s state_dict:')\n# total_param = 0\n# for param_tensor in model.state_dict():\n#     print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n#     total_param += np.prod(model.state_dict()[param_tensor].size())\n# print('Net\\'s total params:', total_param)\n# #--------------------------------------------------\n# print('Optimizer\\'s state_dict:')  # If you notice here the Attention is a trainable parameter\n# for var_name in optimizer.state_dict():\n#     print(var_name, '\\t', optimizer.state_dict()[var_name])\n\n\n# # Loading the graph once because it's a static graph\n\n# for snapshot in train_dataset:\n#     static_edge_index = snapshot.edge_index.to(DEVICE)\n#     break;\n\n\n# # Training the model \n# model.train()\n\n# for epoch in range(3): # 30\n#     step = 0\n#     loss_list = []\n#     for encoder_inputs, labels in train_loader:\n#         y_hat = model(encoder_inputs, static_edge_index)         # Get model predictions\n#         loss = loss_fn(y_hat, labels) # Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse\n#         loss.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n#         step= step+ 1\n#         loss_list.append(loss.item())\n#         if step % 100 == 0 :\n#             print(sum(loss_list)/len(loss_list))\n#     print(\"Epoch {} train RMSE: {:.4f}\".format(epoch, sum(loss_list)/len(loss_list)))\n\n\n## Evaluation\n\n#- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n#- The model always gets one hour and needs to predict the next hour\n\n\n# model.eval()\n# step = 0\n# # Store for analysis\n# total_loss = []\n# for encoder_inputs, labels in test_loader:\n#     # Get model predictions\n#     y_hat = model(encoder_inputs, static_edge_index)\n#     # Mean squared error\n#     loss = loss_fn(y_hat, labels)\n#     total_loss.append(loss.item())\n#     # Store for analysis below\n#     #test_labels.append(labels)\n#     #predictions.append(y_hat)\n\n\n# print(\"Test MSE: {:.4f}\".format(sum(total_loss)/len(total_loss)))\n\n\n## Visualization\n\n# - The further away the point in time is, the worse the predictions get\n# - Predictions shape: [num_data_points, num_sensors, num_timesteps]\n\n\n# sensor = 123\n# timestep = 11 \n# preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in y_hat])\n# labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n# print(\"Data points:,\", preds.shape)\n\n\n# plt.figure(figsize=(20,5))\n# sns.lineplot(data=preds, label=\"pred\")\n# sns.lineplot(data=labs, label=\"true\")\n\n\n\nA3GCN(cuda ë¬¸ì œ)\n\n# try:\n#     from tqdm import tqdm\n# except ImportError:\n#     def tqdm(iterable):\n#         return iterable\n\n\n# # import torch\n# # import torch.nn.functional as F\n# from torch_geometric_temporal.nn.recurrent import A3TGCN\n\n\n# # from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n# from torch_geometric_temporal.signal import temporal_signal_split\n\n\n# # loader = ChickenpoxDatasetLoader()\n\n# dataset = loader.get_dataset(lags=4)\n\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\n# class RecurrentGCN(torch.nn.Module):\n#     def __init__(self, node_features, periods):\n#         super(RecurrentGCN, self).__init__()\n#         self.recurrent = A3TGCN(node_features, 32, periods)\n#         self.linear = torch.nn.Linear(32, 1)\n\n#     def forward(self, x, edge_index, edge_weight):\n#         h = self.recurrent(x.to(\"cuda:0\").view(x.shape[0], 1, x.shape[1]), edge_index, edge_weight)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         return h\n\n\n# model = RecurrentGCN(node_features = 4, periods = 4)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     cost = 0\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = cost + torch.mean((y_hat-snapshot.y)**2)\n#     cost = cost / (time+1)\n#     cost.backward()\n#     optimizer.step()\n#     optimizer.zero_grad()\n\n\n# model.eval()\n# cost = 0\n# for time, snapshot in enumerate(test_dataset):\n#     y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#     cost = cost + torch.mean((y_hat-snapshot.y)**2)\n# cost = cost / (time+1)\n# cost = cost.item()\n# print(\"MSE: {:.4f}\".format(cost))\n\n\n\nAGCRN\n\nAGCRN?\n\n\nInit signature:\nAGCRN(\n    number_of_nodes: int,\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    embedding_dimensions: int,\n)\nDocstring:     \nAn implementation of the Adaptive Graph Convolutional Recurrent Unit.\nFor details see: `\"Adaptive Graph Convolutional Recurrent Network\nfor Traffic Forecasting\" <https://arxiv.org/abs/2007.02842>`_\nArgs:\n    number_of_nodes (int): Number of vertices.\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Filter size :math:`K`.\n    embedding_dimensions (int): Number of node embedding dimensions.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/agcrn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import AGCRN\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=8)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features,number_of_nodes):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = AGCRN(number_of_nodes = 20,\n                              in_channels = node_features,\n                              out_channels = 2,\n                              K = 2,\n                              embedding_dimensions = 4)\n        self.linear = torch.nn.Linear(2, 1)\n\n    def forward(self, x, e, h):\n        h_0 = self.recurrent(x, e, h)\n        y = F.relu(h_0)\n        y = self.linear(y)\n        return y, h_0\n\ntorch.nn.init.xavier_uniform_(e) ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n\ne = torch.empty(20, 4)\n\n\ne\n\ntensor([[ 2.3516e+23,  3.0646e-41,  1.2073e+23,  3.0646e-41],\n        [ 1.2839e+00,  4.5579e-41,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 3.1494e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 1.2162e-01,  3.0726e-01,  5.5876e+24,  3.0646e-41],\n        [        nan,  4.5912e-41,         nan,  4.5912e-41],\n        [ 0.0000e+00,  0.0000e+00, -5.1905e-35,  4.5579e-41],\n        [ 4.5606e-01,  1.7410e-01,  4.3082e-01,  4.4134e-01],\n        [ 4.2527e-01,  3.9021e-01,  6.6931e-02,  1.1973e-03],\n        [ 8.9360e-02,  3.5911e-02,  3.8786e-02,  3.9897e-01],\n        [ 4.7854e-01,  0.0000e+00,  1.4659e-01,  3.2289e-01],\n        [ 4.2682e-01,  9.1125e-02,  1.1351e-43,  0.0000e+00],\n        [ 8.2566e+26,  3.0646e-41, -7.3231e+36,  4.5579e-41],\n        [ 3.2420e-02,  3.5085e-02,  2.4460e-02,  2.4794e-01]])\n\n\n\ntorch.nn.init.xavier_uniform_(e)\n\ntensor([[-0.1886, -0.1182, -0.2437,  0.4621],\n        [-0.2045, -0.0095, -0.2639, -0.3215],\n        [-0.3641,  0.1362, -0.2829,  0.3273],\n        [ 0.1198, -0.0813,  0.2029,  0.1687],\n        [ 0.2984, -0.3694,  0.2065, -0.4666],\n        [ 0.2634, -0.4748,  0.2762, -0.1667],\n        [-0.1677,  0.3808,  0.1978, -0.4734],\n        [-0.3368, -0.1218, -0.4826, -0.0898],\n        [ 0.1866,  0.0516, -0.4581,  0.0136],\n        [-0.2521, -0.3840, -0.2820,  0.0543],\n        [ 0.4000, -0.1176, -0.3463, -0.3728],\n        [-0.0128, -0.1869, -0.2293,  0.3790],\n        [-0.4311, -0.1795, -0.3970,  0.2133],\n        [-0.0487,  0.3308, -0.1300, -0.2409],\n        [ 0.4507, -0.3846,  0.1356, -0.3181],\n        [ 0.3372, -0.2599, -0.4767,  0.0201],\n        [-0.4959,  0.0642, -0.0844, -0.2929],\n        [-0.1447, -0.3859,  0.4434, -0.2623],\n        [ 0.0794,  0.2285, -0.1525,  0.4936],\n        [ 0.2819, -0.1921,  0.3888, -0.2040]])\n\n\n\ne\n\ntensor([[-0.1886, -0.1182, -0.2437,  0.4621],\n        [-0.2045, -0.0095, -0.2639, -0.3215],\n        [-0.3641,  0.1362, -0.2829,  0.3273],\n        [ 0.1198, -0.0813,  0.2029,  0.1687],\n        [ 0.2984, -0.3694,  0.2065, -0.4666],\n        [ 0.2634, -0.4748,  0.2762, -0.1667],\n        [-0.1677,  0.3808,  0.1978, -0.4734],\n        [-0.3368, -0.1218, -0.4826, -0.0898],\n        [ 0.1866,  0.0516, -0.4581,  0.0136],\n        [-0.2521, -0.3840, -0.2820,  0.0543],\n        [ 0.4000, -0.1176, -0.3463, -0.3728],\n        [-0.0128, -0.1869, -0.2293,  0.3790],\n        [-0.4311, -0.1795, -0.3970,  0.2133],\n        [-0.0487,  0.3308, -0.1300, -0.2409],\n        [ 0.4507, -0.3846,  0.1356, -0.3181],\n        [ 0.3372, -0.2599, -0.4767,  0.0201],\n        [-0.4959,  0.0642, -0.0844, -0.2929],\n        [-0.1447, -0.3859,  0.4434, -0.2623],\n        [ 0.0794,  0.2285, -0.1525,  0.4936],\n        [ 0.2819, -0.1921,  0.3888, -0.2040]])\n\n\n\nmodel = RecurrentGCN(node_features = 8,number_of_nodes=20)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\ne = torch.empty(20, 4)\n\ntorch.nn.init.xavier_uniform_(e)\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    h = None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        x = snapshot.x.view(1, 20, 8)\n        y_hat, h = model(x, e, h)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:11<00:00,  4.26it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    x = snapshot.x.view(1, 20, 8)\n    y_hat, h = model(x, e, h)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.1103\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nDCRNN(Done)\n\nDCRNN?\n\n\nInit signature: DCRNN(in_channels: int, out_channels: int, K: int, bias: bool = True)\nDocstring:     \nAn implementation of the Diffusion Convolutional Gated Recurrent Unit.\nFor details see: `\"Diffusion Convolutional Recurrent Neural Network:\nData-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Filter size :math:`K`.\n    bias (bool, optional): If set to :obj:`False`, the layer\n        will not learn an additive bias (default :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/dcrnn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:21<00:00,  9.44it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a = []\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1927\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nDYGRENCODER(Done)\n\nDyGrEncoder?\n\n\nInit signature:\nDyGrEncoder(\n    conv_out_channels: int,\n    conv_num_layers: int,\n    conv_aggr: str,\n    lstm_out_channels: int,\n    lstm_num_layers: int,\n)\nDocstring:     \nAn implementation of the integrated Gated Graph Convolution Long Short\nTerm Memory Layer. For details see this paper: `\"Predictive Temporal Embedding\nof Dynamic Graphs.\" <https://ieeexplore.ieee.org/document/9073186>`_\nArgs:\n    conv_out_channels (int): Number of output channels for the GGCN.\n    conv_num_layers (int): Number of Gated Graph Convolutions.\n    conv_aggr (str): Aggregation scheme to use\n        (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n    lstm_out_channels (int): Number of LSTM channels.\n    lstm_num_layers (int): Number of neurons in LSTM.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/dygrae.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DyGrEncoder\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DyGrEncoder(conv_out_channels=4, conv_num_layers=1, conv_aggr=\"mean\", lstm_out_channels=32, lstm_num_layers=1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h_0, c_0):\n        h, h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h_0, c_0)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:20<00:00,  9.58it/s]\n\n\n\nmodel.eval()\ncost = 0\nh, c = None, None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.4587\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nEvolveGCNH(Done)\n\nEvolveGCNH?\n\n\nInit signature:\nEvolveGCNH(\n    num_of_nodes: int,\n    in_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    normalize: bool = True,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Evolving Graph Convolutional Hidden Layer.\nFor details see this paper: `\"EvolveGCN: Evolving Graph Convolutional\nNetworks for Dynamic Graph.\" <https://arxiv.org/abs/1902.10191>`_\nArgs:\n    num_of_nodes (int): Number of vertices.\n    in_channels (int): Number of filters.\n    improved (bool, optional): If set to :obj:`True`, the layer computes\n        :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n        (default: :obj:`False`)\n    cached (bool, optional): If set to :obj:`True`, the layer will cache\n        the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n        \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n        cached version for further executions.\n        This parameter should only be set to :obj:`True` in transductive\n        learning scenarios. (default: :obj:`False`)\n    normalize (bool, optional): Whether to add self-loops and apply\n        symmetric normalization. (default: :obj:`True`)\n    add_self_loops (bool, optional): If set to :obj:`False`, will not add\n        self-loops to the input graph. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/evolvegcnh.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import EvolveGCNH\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, num_of_nodes, in_channels):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = EvolveGCNH(num_of_nodes, in_channels)\n        self.linear = torch.nn.Linear(in_channels, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(num_of_nodes = 20,in_channels = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:33<00:00,  5.96it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.9995\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nEVOLVEGCNO(Done)\n\nEvolveGCNO?\n\n\nInit signature:\nEvolveGCNO(\n    in_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    normalize: bool = True,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Evolving Graph Convolutional without Hidden Layer.\nFor details see this paper: `\"EvolveGCN: Evolving Graph Convolutional\nNetworks for Dynamic Graph.\" <https://arxiv.org/abs/1902.10191>`_\nArgs:\n    in_channels (int): Number of filters.\n    improved (bool, optional): If set to :obj:`True`, the layer computes\n        :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n        (default: :obj:`False`)\n    cached (bool, optional): If set to :obj:`True`, the layer will cache\n        the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n        \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n        cached version for further executions.\n        This parameter should only be set to :obj:`True` in transductive\n        learning scenarios. (default: :obj:`False`)\n    normalize (bool, optional): Whether to add self-loops and apply\n        symmetric normalization. (default: :obj:`True`)\n    add_self_loops (bool, optional): If set to :obj:`False`, will not add\n        self-loops to the input graph. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/evolvegcno.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import EvolveGCNO\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = EvolveGCNO(node_features)\n        self.linear = torch.nn.Linear(node_features, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\nfor param in model.parameters():\n    param.retain_grad()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward(retain_graph=True)\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:08<00:00, 22.31it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    if time == 0:\n        model.recurrent.weight = None\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.5661\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nGCLSTM(Done)\n\nGCLSTM?\n\n\nInit signature:\nGCLSTM(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the the Integrated Graph Convolutional Long Short Term\nMemory Cell. For details see this paper: `\"GC-LSTM: Graph Convolution Embedded LSTM\nfor Dynamic Link Prediction.\" <https://arxiv.org/abs/1812.04206>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gc_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GCLSTM\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GCLSTM(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(100)): #200\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:10<00:00,  9.17it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2557\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nGConvLSTM(Done)\n\nGConvLSTM?\n\n\nInit signature:\nGConvLSTM(\n    in_channels: int,\n    out_channels: int,\n    K: int,\n    normalization: str = 'sym',\n    bias: bool = True,\n)\nDocstring:     \nAn implementation of the Chebyshev Graph Convolutional Long Short Term Memory\nCell. For details see this paper: `\"Structured Sequence Modeling with Graph\nConvolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    K (int): Chebyshev filter size :math:`K`.\n    normalization (str, optional): The normalization scheme for the graph\n        Laplacian (default: :obj:`\"sym\"`):\n        1. :obj:`None`: No normalization\n        :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n        2. :obj:`\"sym\"`: Symmetric normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n        \\mathbf{D}^{-1/2}`\n        3. :obj:`\"rw\"`: Random-walk normalization\n        :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n        You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n        this operator in case the normalization is non-symmetric.\n        :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n        :obj:`[num_graphs]` in a mini-batch scenario and a\n        scalar/zero-dimensional tensor when operating on single graphs.\n        You can pre-compute :obj:`lambda_max` via the\n        :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n        an additive bias. (default: :obj:`True`)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/gconv_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader1 = ChickenpoxDatasetLoader()\n\ndataset = loader1.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(node_features, 8, 1)\n        self.linear = torch.nn.Linear(8, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)): #200\n    cost = 0\n    h, c = None, None\n    _b = []\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:30<00:00,  1.66it/s]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.7228\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nLightning(ì„¤ì¹˜ ì•ˆ ë¨)\n\n# import torch\n# from torch.nn import functional as F\n\n# import pytorch_lightning as pl\n# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n# from torch_geometric_temporal.signal import temporal_signal_split\n\n\n# class LitDiffConvModel(pl.LightningModule):\n\n#     def __init__(self, node_features, filters):\n#         super().__init__()\n#         self.recurrent = DCRNN(node_features, filters, 1)\n#         self.linear = torch.nn.Linear(filters, 1)\n\n\n#     def configure_optimizers(self):\n#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-2)\n#         return optimizer\n\n#     def training_step(self, train_batch, batch_idx):\n#         x = train_batch.x\n#         y = train_batch.y.view(-1, 1)\n#         edge_index = train_batch.edge_index\n#         h = self.recurrent(x, edge_index)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         loss = F.mse_loss(h, y)\n#         return loss\n\n#     def validation_step(self, val_batch, batch_idx):\n#         x = val_batch.x\n#         y = val_batch.y.view(-1, 1)\n#         edge_index = val_batch.edge_index\n#         h = self.recurrent(x, edge_index)\n#         h = F.relu(h)\n#         h = self.linear(h)\n#         loss = F.mse_loss(h, y)\n#         metrics = {'val_loss': loss}\n#         self.log_dict(metrics)\n#         return metrics\n\n\n# loader = ChickenpoxDatasetLoader()\n\n# dataset_loader = loader.get_dataset(lags=32)\n\n# train_loader, val_loader = temporal_signal_split(dataset_loader,\n#                                                  train_ratio=0.2)\n\n\n# model = LitDiffConvModel(node_features=32,\n#                          filters=16)\n\n\n# early_stop_callback = EarlyStopping(monitor='val_loss',\n#                                     min_delta=0.00,\n#                                     patience=10,\n#                                     verbose=False,\n#                                     mode='max')\n\n\n# trainer = pl.Trainer(callbacks=[early_stop_callback])\n\n\n# trainer.fit(model, train_loader, val_loader)\n\n\n\nLRGCN(Done)\n\nLRGCN?\n\n\nInit signature:\nLRGCN(\n    in_channels: int,\n    out_channels: int,\n    num_relations: int,\n    num_bases: int,\n)\nDocstring:     \nAn implementation of the Long Short Term Memory Relational\nGraph Convolution Layer. For details see this paper: `\"Predicting Path\nFailure In Time-Evolving Graphs.\" <https://arxiv.org/abs/1905.03994>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    num_relations (int): Number of relations.\n    num_bases (int): Number of bases.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/lrgcn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import LRGCN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = LRGCN(node_features, 32, 1, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight, h_0, c_0):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h_0, c_0)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    h, c = None, None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:47<00:00,  4.23it/s]\n\n\n\nmodel.eval()\ncost = 0\nh, c = None, None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2608\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nMPNNLSTM\n\nMPNNLSTM?\n\n\nInit signature:\nMPNNLSTM(\n    in_channels: int,\n    hidden_size: int,\n    num_nodes: int,\n    window: int,\n    dropout: float,\n)\nDocstring:     \nAn implementation of the Message Passing Neural Network with Long Short Term Memory.\nFor details see this paper: `\"Transfer Graph Neural Networks for Pandemic Forecasting.\" <https://arxiv.org/abs/2009.08388>`_\nArgs:\n    in_channels (int): Number of input features.\n    hidden_size (int): Dimension of hidden representations.\n    num_nodes (int): Number of nodes in the network.\n    window (int): Number of past samples included in the input.\n    dropout (float): Dropout rate.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/mpnn_lstm.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import MPNNLSTM\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nnum_nodes=2\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = MPNNLSTM(node_features, 8,  num_nodes, 1, 0.3) # 32, 32, 20, 1, 0.5 ì´ì—ˆëŠ”ë° position ì˜ëª»ë˜ì—ˆë‹¤í•´ì„œ 32í•˜ë‚˜ ëºŒ\n        self.linear = torch.nn.Linear(num_nodes*8 + node_features, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:57<00:00,  1.14s/it]\n\n\n\nmodel.eval()\ncost = 0\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.3623\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)\n\n\n\n\n\n\nTGCN(Done)\n\nTGCN?\n\n\nInit signature:\nTGCN(\n    in_channels: int,\n    out_channels: int,\n    improved: bool = False,\n    cached: bool = False,\n    add_self_loops: bool = True,\n)\nDocstring:     \nAn implementation of the Temporal Graph Convolutional Gated Recurrent Cell.\nFor details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\nTraffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\nArgs:\n    in_channels (int): Number of input features.\n    out_channels (int): Number of output features.\n    improved (bool): Stronger self loops. Default is False.\n    cached (bool): Caching the message weights. Default is False.\n    add_self_loops (bool): Adding self-loops for smoothing. Default is True.\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py\nType:           type\nSubclasses:     \n\n\n\n\n\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable):\n        return iterable\n\n\n# import torch\n# import torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import TGCN\n\n# from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\n# loader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset(lags=4)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = TGCN(node_features, 8)\n        self.linear = torch.nn.Linear(8, 1)\n\n    def forward(self, x, edge_index, edge_weight, prev_hidden_state):\n        h = self.recurrent(x, edge_index, edge_weight, prev_hidden_state)\n        y = F.relu(h)\n        y = self.linear(y)\n        return y, h\n\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    cost = 0\n    hidden_state = None\n    _b=[]\n    _d=[]\n    for time, snapshot in enumerate(train_dataset):\n        y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr,hidden_state)\n        y_hat = y_hat.reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n        _b.append(y_hat)\n        _d.append(cost)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  8.10it/s]\n\n\n\nmodel.eval()\ncost = 0\nhidden_state = None\n_a=[]\n_a1=[]\nfor time, snapshot in enumerate(test_dataset):\n    y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, hidden_state)\n    y_hat = y_hat.reshape(-1)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    _a.append(y_hat)\n    _a1.append(cost)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.8115\n\n\n\n_e = [_d[i].detach() for i in range(len(_d))]\n\n\n_c = [_a1[i].detach() for i in range(len(_a1))]\n\n\nfig, (( ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(30,20))\n\nax1.set_title('train node1')\nax1.plot([train_dataset.targets[i][0] for i in range(train_dataset.snapshot_count)])\nax1.plot(torch.tensor([_b[i].detach()[0] for i in range(train_dataset.snapshot_count)]))\n\nax2.set_title('test node1')\nax2.plot([test_dataset.targets[i][0] for i in range(test_dataset.snapshot_count)])\nax2.plot(torch.tensor([_a[i].detach()[0] for i in range(test_dataset.snapshot_count)]))\n\nax3.set_title('train node2')\nax3.plot([train_dataset.targets[i][1] for i in range(train_dataset.snapshot_count)])\nax3.plot(torch.tensor([_b[i].detach()[1] for i in range(train_dataset.snapshot_count)]))\n\n\nax4.set_title('test node2')\nax4.plot([test_dataset.targets[i][1] for i in range(test_dataset.snapshot_count)])\nax4.plot(torch.tensor([_a[i].detach()[1] for i in range(test_dataset.snapshot_count)]))\n\nax5.set_title('train cost')\nax5.plot(_e)\n\nax6.set_title('test cost')\nax6.plot(_c)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='mrate',facet_row='inter_method',height=600)\n\n\n                                                \n\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 \").plot.box(backend='plotly',x='epoch',color='method',y='mse',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-1",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-05-28_10-40-44.csv')\ndf2 = pd.read_csv('./simulation_results/2023-05-28_11-09-06.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-2",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\n# 10%\ndf1 = pd.read_csv('./simulation_results/2023-05-30_15-07-43.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-05-31_01-58-40.csv') # STGCN IT-STGCN\n\n\ndata = pd.concat([df1,df2],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-3",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#baseline-5",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#random-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html#block-4",
    "title": "GConvGRU_Simulation Boxplot_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html",
    "title": "LRGCN_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random",
    "title": "LRGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block",
    "title": "LRGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-1",
    "title": "LRGCN_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-2",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "LRGCN_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-20_19-13-42.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-20_19-46-03.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/LRGCN_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/LRGCN_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-3",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "LRGCN_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-06-21_19-31-38.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-06-21_22-43-39.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-06-22_02-04-05.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/LRGCN_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/LRGCN_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-4",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#baseline-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#random-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html#block-5",
    "title": "LRGCN_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html",
    "title": "SimualtionPlanner-Tutorial",
    "section": "",
    "text": "table"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.7,0.8],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='fivenodes')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3,0.8],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.3],\n    'lags': [2, 4], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\n\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'RecurrentGCN' : ['DCRNN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(11)] #windmilsmall\nanother_list = list(range(5000,7500)) # 17470*0.8 = 13976.0\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcnGCLSTM/utils.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_new.cpp:245.)\n  lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGCLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader6,dataset_name='windmillsmall')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmy_list[13] = another_list\nmy_list[15] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,35))\nmy_list[2] = another_list\nmy_list[4] = another_list\nmy_list[7] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 72)\n# my_listì—ì„œ 250ê°œ ìš”ì†Œ ë¬´ì‘ìœ„ ì„ íƒ\nselected_indexes = random.sample(range(len(my_list)), 250)\n# ì„ íƒëœ ìš”ì†Œì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤ì„ another_listì— í• ë‹¹\nfor index in selected_indexes:\n    my_list[index] = another_list\n\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n# loader = itstgcn.DatasetLoader(data_dict)\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'RecurrentGCN' : ['GConvGRU','GConvLSTM'],\n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [16], \n    'inter_method': ['linear'],\n    'epoch': [50],\n    'lr': [0.01]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'RecurrentGCN' : ['GConvGRU','GConvLSTM'],\n    'mindex': [mindex],\n    'lags': [2,4], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnadd.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\n\n\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# data_dict=itstgcn.load_data('./data/fivenodes.pkl')\n# loader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 30, \n#    'method': ['GNAR'], \n    'mrate': [0.1],\n    'lags': [4], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear','cubic'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader2,dataset_name='pedalme')\nplnr.simulate()\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0],\n    'lags': [2,4], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0,0.3],\n    'lags': [8], \n#    'nof_filters': [8,16], \n    'inter_method': ['linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader5,dataset_name='windmillmedium')\nplnr.simulate()"
  },
  {
    "objectID": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "href": "posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "title": "SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n# _data = itstgcn.load_data('./data/fivenodes.pkl')\n# _edges = torch.tensor(_data['edges']).nonzero().tolist()\n# _FX = _data['f'].tolist()\n# _node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n# data_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n# loader = itstgcn.DatasetLoader(data_dict)\n# loader = itstgcn.load_data('./data/fivenodes.pkl')\n\n\n Nodes : 26\n\nvertices represent 26 windmills\n-Edges : 676\n\nweighted edges describe the strength of relationships\n- Time : 17464\n\n\nmy_list = [[] for _ in range(26)] #medium\nanother_list = list(range(1000,2000))+list(range(4000,5000))+list(range(7000,8000)) #17464\n\nfor i in np.array(random.sample(range(0, 26), 15)):\n    my_list[i] = another_list\nmindex = my_list\n\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[2] = another_list\nmy_list[4] = another_list\nmy_list[6] = another_list\nmy_list[8] = another_list\nmy_list[10] = another_list\nmy_list[12] = another_list\nmy_list[14] = another_list\nmy_list[16] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [4], \n    'inter_method': ['cubic','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader1,dataset_name='chickenpox')\nplnr.simulate(mindex,mtype='block')\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2,4], \n    'inter_method': ['linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.126\n      0.034\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.137\n      0.047"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.7\n      12\n      IT-STGCN\n      2\n      1.287\n      0.075\n    \n    \n      1\n      linear\n      0.7\n      12\n      STGCN\n      2\n      1.472\n      0.125\n    \n    \n      2\n      linear\n      0.8\n      12\n      IT-STGCN\n      2\n      1.298\n      0.060\n    \n    \n      3\n      linear\n      0.8\n      12\n      STGCN\n      2\n      1.442\n      0.111\n    \n    \n      4\n      nearest\n      0.7\n      12\n      IT-STGCN\n      2\n      1.261\n      0.077\n    \n    \n      5\n      nearest\n      0.7\n      12\n      STGCN\n      2\n      1.394\n      0.085\n    \n    \n      6\n      nearest\n      0.8\n      12\n      IT-STGCN\n      2\n      1.312\n      0.065\n    \n    \n      7\n      nearest\n      0.8\n      12\n      STGCN\n      2\n      1.436\n      0.098"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.125\n      12\n      IT-STGCN\n      1.140\n      0.038\n    \n    \n      1\n      linear\n      0.125\n      12\n      STGCN\n      1.172\n      0.055\n    \n    \n      2\n      nearest\n      0.125\n      12\n      IT-STGCN\n      1.121\n      0.027\n    \n    \n      3\n      nearest\n      0.125\n      12\n      STGCN\n      1.140\n      0.058"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['inter_method','mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','inter_method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.3\n      32\n      IT-STGCN\n      4\n      0.035\n      0.035\n    \n    \n      1\n      linear\n      0.3\n      32\n      STGCN\n      4\n      0.057\n      0.057\n    \n    \n      2\n      linear\n      0.8\n      32\n      IT-STGCN\n      4\n      0.080\n      0.080\n    \n    \n      3\n      linear\n      0.8\n      32\n      STGCN\n      4\n      0.111\n      0.111"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-1",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.288\n      32\n      IT-STGCN\n      0.911\n      0.069\n    \n    \n      1\n      linear\n      0.288\n      32\n      STGCN\n      0.900\n      0.049\n    \n    \n      2\n      nearest\n      0.288\n      32\n      IT-STGCN\n      0.885\n      0.040\n    \n    \n      3\n      nearest\n      0.288\n      32\n      STGCN\n      0.896\n      0.054"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      2\n      IT-STGCN\n      1.213\n      0.050\n    \n    \n      1\n      4\n      2\n      STGCN\n      1.215\n      0.059"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.227\n      0.056\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.244\n      0.041\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.224\n      0.035\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.266\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.255\n      0.049\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.332\n      0.089\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.045\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.274\n      0.078"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-2",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.069\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.223\n      0.042\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.222\n      0.039\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.237\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#w_st",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.340\n      0.166\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.392\n      0.109\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.368\n      0.158\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.338\n      0.118\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.312\n      0.162\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.498\n      0.083\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.313\n      0.205\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.503\n      0.101\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.120\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.372\n      0.199\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.310\n      0.151\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.459\n      0.153"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      64\n      IT-STGCN\n      0.626\n      0.015\n    \n    \n      1\n      8\n      64\n      STGCN\n      0.640\n      0.031"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.631\n      0.019\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.764\n      0.057\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.920\n      0.069\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      1.423\n      0.121"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-3",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.119837\n      8\n      IT-STGCN\n      0.627324\n      0.013908\n    \n    \n      1\n      0.119837\n      8\n      STGCN\n      0.660386\n      0.033577"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.653\n      0.033\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.963\n      0.098"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.014\n      0.031\n    \n    \n      1\n      8\n      STGCN\n      1.023\n      0.055"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.142\n      0.021\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.600\n      0.056"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-4",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.081\n      8\n      IT-STGCN\n      0.997\n      0.022\n    \n    \n      1\n      0.081\n      8\n      STGCN\n      0.989\n      0.009"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#baseline-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.959\n      0.012\n    \n    \n      1\n      4\n      STGCN\n      0.960\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#random-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.156399\n      0.061898\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.133692\n      0.068590"
  },
  {
    "objectID": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html#block-5",
    "title": "GConvLSTM_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.949276\n      0.007582\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.949673\n      0.005402"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "",
    "text": "Simulation"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#pyg-ì˜-data-ìë£Œí˜•",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#pyg-ì˜-data-ìë£Œí˜•",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "PyG ì˜ Data ìë£Œí˜•",
    "text": "PyG ì˜ Data ìë£Œí˜•\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- ìë£ŒëŠ” PyGì˜ Data ì˜¤ë¸Œì íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤.\n(ì˜ˆì œ) ì•„ë˜ì™€ ê°™ì€ ê·¸ë˜í”„ìë£Œë¥¼ ê³ ë ¤í•˜ì.\n\nì´ëŸ¬í•œ ìë£Œí˜•ì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•œë‹¤.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # DataëŠ” ê·¸ë˜í”„ìë£Œí˜•ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-ì˜-ìë£Œí˜•",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-ì˜-ìë£Œí˜•",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "PyTorch Geometric Temporal ì˜ ìë£Œí˜•",
    "text": "PyTorch Geometric Temporal ì˜ ìë£Œí˜•\n\nref: PyTorch Geometric Temporal Signal\n\nì•„ë˜ì˜ í´ë˜ìŠ¤ë“¤ì¤‘ í•˜ë‚˜ë¥¼ ì´ìš©í•˜ì—¬ ë§Œë“ ë‹¤.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\nì´ì¤‘ â€œHeterogeneous Temporal Signalâ€ ì€ ìš°ë¦¬ê°€ ê´€ì‹¬ì´ ìˆëŠ” ì‹ í˜¸ê°€ ì•„ë‹ˆë¯€ë¡œ ì‚¬ì‹¤ìƒ ì•„ë˜ì˜ 3ê°œë§Œ ê³ ë ¤í•˜ë©´ ëœë‹¤.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\nì—¬ê¸°ì—ì„œ StaticGraphTemporalSignal ëŠ” ì‹œê°„ì— ë”°ë¼ì„œ ê·¸ë˜í”„ êµ¬ì¡°ê°€ ì¼ì •í•œ ê²½ìš°, ì¦‰ \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ì˜ë¯¸í•œë‹¤.\n(ì˜ˆì œ1) StaticGraphTemporalSignal ë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„° ì…‹ ë§Œë“¤ê¸°\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict ì¶œë ¥ì´ ê¹€\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- ì‚´í´ë³´ê¸°\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\ní˜¹ì€ \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\nì¦‰ data_dictëŠ” ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŒ\n\n\n\n\n\n\n\n\n\n\nìˆ˜í•™ ê¸°í˜¸\nì½”ë“œì— ì €ì¥ëœ ë³€ìˆ˜\nìë£Œí˜•\nì°¨ì›\nì„¤ëª…\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20ê°œì˜ ë…¸ë“œì— ëŒ€í•œ ì„¤ëª…ì´ ìˆìŒ\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\në…¸ë“œë“¤ì— ëŒ€í•œ 102ê°œì˜ ì—°ê²°ì„ ì •ì˜í•¨\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- ì£¼ì–´ì§„ ìë£Œë¥¼ ì •ë¦¬í•˜ì—¬ ê·¸ë˜í”„ì‹ í˜¸ \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)ë¥¼ ë§Œë“¤ë©´ ì•„ë˜ì™€ ê°™ë‹¤.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\nì—¬ê¸°ì—ì„œ edgesëŠ” \\({\\cal E}\\)ì— ëŒ€í•œ ì •ë³´ë¥¼\nedges_weightëŠ” \\({\\bf W}\\)ì— ëŒ€í•œ ì •ë³´ë¥¼\nfëŠ” \\({\\bf f}\\)ì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥í•œë‹¤.\n\n\nNote: ì´ë•Œ \\({\\bf W}={\\bf E}\\) ë¡œ ì •ì˜í•œë‹¤. (í•˜ì§€ë§Œ ê¼­ ì´ë˜ì•¼ í•˜ëŠ”ê±´ ì•„ë‹ˆì•¼)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\nì„¤ëª…ë³€ìˆ˜\në°˜ì‘ë³€ìˆ˜\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR ëŠë‚Œìœ¼ë¡œ í‘œí˜„í•˜ë©´ AR(4) ì„\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f3423668bd0>\n\n\n- ê·¸ëŸ°ë° ì´ ê³¼ì •ì„ ì•„ë˜ì™€ ê°™ì´ í•  ìˆ˜ë„ ìˆìŒ\n# PyTorch Geometric Temporal ê³µì‹í™ˆí˜ì´ì§€ì— ì†Œê°œëœ ì½”ë“œ\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- datasetì€ dataset[0], \\(\\dots\\) , dataset[516]ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ê° ì‹œì ë³„ ìë£Œì— ì ‘ê·¼ê°€ëŠ¥\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\nê° ì‹œì ì— ëŒ€í•œ ìë£Œí˜•ì€ ì•„ê¹Œ ì‚´í´ë³´ì•˜ë˜ PyGì˜ Data ìë£Œí˜•ê³¼ ê°™ìŒ\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\nì´ ê°’ë“¤ì€ features[0]ì˜ ê°’ë“¤ê³¼ ê°™ìŒ. ì¦‰ \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)ë¥¼ ì˜ë¯¸í•¨\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\nì´ ê°’ë“¤ì€ targets[0]ì˜ ê°’ë“¤ê³¼ ê°™ìŒ. ì¦‰ \\({\\bf f}_5\\)ë¥¼ ì˜ë¯¸í•¨"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)ì˜ ì°¨ì›? (1,)\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\nì‹œê°„ì— ë”°ë¼ì„œ Number of nodesê°€ ë³€í•˜ëŠ”ì§€? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\nì˜ˆì œì½”ë“œì ìš©ê°€ëŠ¥ì—¬ë¶€: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#learn",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#learn",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:57<00:00,  1.15s/it]"
  },
  {
    "objectID": "posts/GCN/2022-12-29-STGCN-tutorial.html#visualization",
    "href": "posts/GCN/2022-12-29-STGCN-tutorial.html#visualization",
    "title": "[IT-STGCN] STGCN íŠœí† ë¦¬ì–¼",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      0.732\n      0.005\n    \n    \n      1\n      12\n      STGCN\n      2\n      0.732\n      0.005"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.167\n      0.059\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      2.077\n      0.252\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.371\n      0.097\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      2.432\n      0.263"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.160\n      0.042\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.215\n      0.036"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.752\n      0.013\n    \n    \n      1\n      16\n      STGCN\n      0.752\n      0.012"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.851\n      0.031\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.087\n      0.046\n    \n    \n      2\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.586\n      0.199\n    \n    \n      3\n      0.8\n      linear\n      16\n      STGCN\n      2.529\n      0.292"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-1",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.807041\n      0.016362\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.828224\n      0.021919\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.823756\n      0.022918\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.828498\n      0.022007"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.233\n      0.115\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.233\n      0.099"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.354\n      0.134\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.575\n      0.198\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.385\n      0.173\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.527\n      0.342\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.516\n      0.211\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.655\n      0.179\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.625\n      0.324\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.851\n      0.254"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-2",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.329\n      0.131\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.320\n      0.111\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.289\n      0.115\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.270\n      0.114"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#w_st",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.270\n      0.163\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.556\n      0.264\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.324\n      0.163\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.520\n      0.206\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.434\n      0.222\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.678\n      0.211\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.410\n      0.208\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.771\n      0.220\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.391\n      0.151\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.420\n      0.110\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.361\n      0.114\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.430\n      0.145"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      12\n      IT-STGCN\n      0.529\n      0.003\n    \n    \n      1\n      8\n      12\n      STGCN\n      0.528\n      0.003"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.518\n      0.002\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.570\n      0.006\n    \n    \n      2\n      0.8\n      8\n      IT-STGCN\n      0.687\n      0.021\n    \n    \n      3\n      0.8\n      8\n      STGCN\n      0.932\n      0.043"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-3",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.003835\n      8\n      IT-STGCN\n      0.528737\n      0.002806\n    \n    \n      1\n      0.003835\n      8\n      STGCN\n      0.527871\n      0.002606\n    \n    \n      2\n      0.095870\n      8\n      IT-STGCN\n      0.529440\n      0.003820\n    \n    \n      3\n      0.095870\n      8\n      STGCN\n      0.544176\n      0.010772"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.512\n      8\n      IT-STGCN\n      0.531\n      0.002\n    \n    \n      1\n      0.512\n      8\n      STGCN\n      0.720\n      0.013"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      8\n      IT-STGCN\n      1.004\n      0.004\n    \n    \n      1\n      8\n      STGCN\n      1.003\n      0.004"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      8\n      IT-STGCN\n      1.193\n      0.045\n    \n    \n      1\n      0.7\n      8\n      STGCN\n      1.661\n      0.076"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-4",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#baseline-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.931\n      0.001\n    \n    \n      1\n      4\n      STGCN\n      0.931\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#random-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.09556\n      0.018743\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.51600\n      0.039793"
  },
  {
    "objectID": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html#block-5",
    "title": "GConvGRU_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      cubic\n      IT-STGCN\n      1.022866\n      0.021048\n    \n    \n      1\n      0.149142\n      4\n      cubic\n      STGCN\n      1.028363\n      0.031275\n    \n    \n      2\n      0.149142\n      4\n      linear\n      IT-STGCN\n      0.930156\n      0.001956\n    \n    \n      3\n      0.149142\n      4\n      linear\n      STGCN\n      0.934719\n      0.004724\n    \n    \n      4\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.931785\n      0.002158\n    \n    \n      5\n      0.149142\n      4\n      nearest\n      STGCN\n      0.934596\n      0.003562"
  },
  {
    "objectID": "posts/GCN/2099-05-31-Other Method.html",
    "href": "posts/GCN/2099-05-31-Other Method.html",
    "title": "ITSTGCN add Model",
    "section": "",
    "text": "summerizing it\n\n\nRANDOM\n\n\nì˜ˆ\n\nimport itstgcnDCRNN\nimport torch\nimport itstgcnDCRNN.planner \nimport pandas as pd\n\nimport numpy as np\nimport random\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndata_dict = itstgcnGCLSTM.load_data('./data/fivenodes.pkl')\nloader = itstgcnGConvLSTM.DatasetLoader(data_dict)\n\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nloader1 = ChickenpoxDatasetLoader()\n\n\nfrom torch_geometric_temporal.dataset import PedalMeDatasetLoader\nloader2 = PedalMeDatasetLoader()\n\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nloader3 = WikiMathsDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputLargeDatasetLoader\n# loader4 = WindmillOutputLargeDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputMediumDatasetLoader\n# loader5 = WindmillOutputMediumDatasetLoader()\n\n\n# from torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\n# loader6 = WindmillOutputSmallDatasetLoader()\n\n\nloader6 = itstgcnDCRNN.load_data('./data/Windmillsmall.pkl')\n\n\n# dataset6 = _a.get_dataset(lags=8)\n\n\nfrom torch_geometric_temporal.dataset import MontevideoBusDatasetLoader\nloader10 = MontevideoBusDatasetLoader()\n\n\n\nSimulation\n\nplans_stgcn_rand = {\n    'max_iteration': 1, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.7],\n    'lags': [8], \n    'nof_filters': [4], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n50/50\n\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplnr = itstgcnDCRNN.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader6,dataset_name='windmillsmall')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.7],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.8],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='fivenodes')\n\nplnr.simulate()\n\n\nmindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mindex': [mindex],\n    'lags': [2], \n    'nof_filters': [12], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='fivenodes')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3,0.8],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader1,dataset_name='chickenpox')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(20)] #chickenpox\nanother_list = list(range(100,400))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmy_list[13] = another_list\nmy_list[15] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]\n# mindex= [list(range(50,150)),[],list(range(50,90)),list(range(50,150)),[]] # node 2\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [32], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader1,dataset_name='chickenpox')\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0,0.3,0.6],\n    'lags': [4], \n    'nof_filters': [2], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader2,dataset_name='pedalme')\n\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(15)] #pedalme\nanother_list = list(range(5,25))\nmy_list[1] = another_list\nmy_list[3] = another_list\nmy_list[5] = another_list\nmy_list[7] = another_list\nmy_list[9] = another_list\nmy_list[11] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 30, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [2], \n    'inter_method': ['linear','nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader2,dataset_name='pedalme')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.3],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader3,dataset_name='wikimath')\nplnr.simulate()\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 72)\n# my_listì—ì„œ 250ê°œ ìš”ì†Œ ë¬´ì‘ìœ„ ì„ íƒ\nselected_indexes = random.sample(range(len(my_list)), 250)\n# ì„ íƒëœ ìš”ì†Œì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤ì„ another_listì— í• ë‹¹\nfor index in selected_indexes:\n    my_list[index] = another_list\n\nimport random\nmy_list = [[] for _ in range(1068)] # wikimath\nanother_list = random.sample(range(570), 150)\n# my_listì—ì„œ 250ê°œ ìš”ì†Œ ë¬´ì‘ìœ„ ì„ íƒ\nselected_indexes = random.sample(range(len(my_list)), 500)\n# ì„ íƒëœ ìš”ì†Œì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤ì„ another_listì— í• ë‹¹\nfor index in selected_indexes:\n    my_list[index] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\nê°™ì€ ë…¸ë“œ ê°™ì€ missing\n\nmy_list = [[] for _ in range(1068)] #wikimath\nanother_list = random.sample(range(0, 576), 300)\nfor i in range(0, 1068):\n    my_list[i] = another_list\nmindex = my_list\n\n\nplans_stgcn_block = {\n    'max_iteration': 10, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [8], \n    'nof_filters': [12], \n    'inter_method': ['linear'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnEvolveGCNH.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader3,dataset_name='wikimath')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0.8],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplans_stgcn_rand = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'],\n    'mrate': [0],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader10,dataset_name='monte')\nplnr.simulate()\n\n\nmy_list = [[] for _ in range(675)] #monte\nanother_list = list(range(200,350)) #743\n\nfor i in np.array(random.sample(range(0, 675), 400)):\n    my_list[i] = another_list\nmindex = my_list\n\n\n# mindex= [[],[],[],list(range(50,150)),[]]  # node 1\n# mindex= [list(range(10,100)),[],list(range(50,80)),[],[]] # node 2\n# mindex= [list(range(10,100)),[],list(range(50,80)),list(range(50,150)),[]] # node3\nplans_stgcn_block = {\n    'max_iteration': 15, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [4], \n    'nof_filters': [12], \n    'inter_method': ['nearest'],\n    'epoch': [50]\n}\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')\n\n\nplnr = itstgcnGConvLSTM.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader10,dataset_name='monte')\nplnr.simulate(mindex=mindex,mtype='block')"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html",
    "title": "GCN Algorithm Example 1",
    "section": "",
    "text": "Our method; GNAR Dataset Example(fiveVTS, fiveNet)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#ë°ì´í„°-ì¼ë¶€-missing-ì²˜ë¦¬",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#ë°ì´í„°-ì¼ë¶€-missing-ì²˜ë¦¬",
    "title": "GCN Algorithm Example 1",
    "section": "ë°ì´í„° ì¼ë¶€ missing ì²˜ë¦¬",
    "text": "ë°ì´í„° ì¼ë¶€ missing ì²˜ë¦¬\n\n1) Block ì²˜ë¦¬\n\n[1] ST-GCN\n\n%%R\nfiveVTS0 <- fiveVTS\nfiveVTS0[50:150, 3] <- NA\n\n\nplt.plot(fiveVTS0[:,2])\n\n\n\n\n\nT = 200\nN = 5 # number of Nodes\nE = fiveNet_edge\nV = np.array([1,2,3,4,5])\nt = np.arange(0,T)\nnode_features = 1\n\n\nf = torch.tensor(fiveVTS0).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.53it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(yhat[:,0].data)\nplt.plot(yhat[:,1].data)\nplt.plot(yhat[:,2].data)\nplt.plot(yhat[:,3].data)\n\n\n\n\n\n\n\n2) Random missing values\n\n%%R\nset.seed(1)\nfiveVTSrandom <- fiveVTS\nsampleindex = sort(sample(1:200, 100))\nfiveVTSrandom[sampleindex,3] <- NA\n\n\n%R -o fiveVTSrandom\n%R -o sampleindex\n\n\nplt.plot(fiveVTSrandom[:,2],'o')\n\n\n\n\n\n\n3) By 2\n\n%%R\nfiveVTStwo <- fiveVTS\nindextwo <- rep(seq(1, by = 2, 200))\nfiveVTStwo[indextwo, 3] <- NA\n\n\n%R -o fiveVTStwo\n%R -o indextwo\n\n\nplt.plot(fiveVTStwo[:,2],'o')"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean",
    "title": "GCN Algorithm Example 1",
    "section": "1.1. Mean",
    "text": "1.1. Mean\n\n1) Block\n\nfiveVTS0_mean = fiveVTS0.copy()\n\n\nfiveVTS0_mean[49:150,2] = np.mean(fiveVTS0[:49,2].tolist()+fiveVTS0[150:,2].tolist())\n\n\nplt.plot(fiveVTS0_mean[:,2])\n\n\n\n\n\n\n2) Random missing values\n\nfiveVTSrandom_mean = fiveVTSrandom.copy()\n\n\ndf = pd.DataFrame(fiveVTSrandom[:,2])\nmean_value = df.mean() # finds the mean value of the column A\ndf = df.fillna(mean_value) # replace missing values with the mean value\n\n\nfiveVTSrandom_mean[:,2] = np.array(df).reshape(200,)\n\n\nplt.plot(fiveVTSrandom_mean[:,2])\n\n\n\n\n\n\n3) By 2\n\nfiveVTStwo_mean = fiveVTStwo.copy()\n\n\ndf = pd.DataFrame(fiveVTStwo[:,2])\nmean_value = df.mean() # finds the mean value of the column A\ndf = df.fillna(mean_value) # replace missing values with the mean value\n\n\nfiveVTStwo_mean[:,2] = np.array(df).reshape(200,)\n\n\nplt.plot(fiveVTStwo_mean[:,2])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation",
    "title": "GCN Algorithm Example 1",
    "section": "1.2. linear interpolation",
    "text": "1.2. linear interpolation\n\n1) Block\n\nfiveVTS0_linearinterpolation = fiveVTS0.copy()\n\n\n# Sample data points\nx = np.array([48,150])\ny = np.array([fiveVTS0_linearinterpolation[48,2],fiveVTS0_linearinterpolation[150,2]])\n\n# Create interpolating function\nf = interp1d(x, y, kind='linear')\n\n# Estimate y value for x = 2.5\ny_interp = f(range(49,150))\n\n\nfiveVTS0_linearinterpolation[49:150,2] = y_interp\n\n\nplt.plot(fiveVTS0_linearinterpolation[:,2])\n\n\n\n\n\n\n2) Random missing values\n\nfiveVTSrandom_linearinterpolation = fiveVTSrandom.copy()\n\n\n_df = pd.DataFrame(fiveVTSrandom_linearinterpolation[:,2])\n_df.interpolate(method='linear', inplace=True)\n_df = _df.fillna(0)\n\n\nfiveVTSrandom_linearinterpolation[:,2] = np.array(_df).reshape(200,)\n\n\nplt.plot(fiveVTSrandom_linearinterpolation[:,2])\n\n\n\n\n\n\n3) By 2\n\nfiveVTStwo_linearinterpolation = fiveVTStwo.copy()\n\n\n_df = pd.Series(fiveVTStwo_linearinterpolation[:,2])\n_df.interpolate(method='linear', inplace=True)\n_df = _df.fillna(0)\n\n\nfiveVTStwo_linearinterpolation[:,2] = _df\n\n\nplt.plot(fiveVTStwo_linearinterpolation[:,2])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-1",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-1",
    "title": "GCN Algorithm Example 1",
    "section": "2.1. Mean",
    "text": "2.1. Mean\n\n1) Block\n\nf_mean = torch.tensor(fiveVTS0_mean).reshape(200,5,1).float()\n\n\nX_mean = f_mean[:199,:,:]\ny_mean = f_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_mean,y_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.56it/s]\n\n\n\nfhat_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_mean]).detach().numpy()\n\n\nplt.plot(fhat_mean[:,2].data)\n\n\n\n\n\n\n2) Random missing values\n\nf_fiveVTSrandom_mean = torch.tensor(fiveVTSrandom_mean).reshape(200,5,1).float()\n\n\nX_fiveVTSrandom_mean = f_fiveVTSrandom_mean[:199,:,:]\ny_fiveVTSrandom_mean = f_fiveVTSrandom_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTSrandom_mean,y_fiveVTSrandom_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTSrandom_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTSrandom_mean]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTSrandom_mean[:,2].data)\n\n\n\n\n\n\n3) By 2\n\nf_fiveVTStwo_mean = torch.tensor(fiveVTStwo_mean).reshape(200,5,1).float()\n\n\nX_fiveVTStwo_mean = f_fiveVTStwo_mean[:199,:,:]\ny_fiveVTStwo_mean = f_fiveVTStwo_mean[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTStwo_mean,y_fiveVTStwo_mean)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.54it/s]\n\n\n\nfhat_fiveVTStwo_mean = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTStwo_mean]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTStwo_mean[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-1",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-1",
    "title": "GCN Algorithm Example 1",
    "section": "2.2. linear interpolation",
    "text": "2.2. linear interpolation\n\n1) Block\n\nf_linearinterpolation = torch.tensor(fiveVTS0_linearinterpolation).reshape(200,5,1).float()\n\n\nX_linearinterpolation = f_linearinterpolation[:199,:,:]\ny_linearinterpolation = f_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_linearinterpolation,y_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_linearinterpolation[:,2].data)\n\n\n\n\n\n\n2) Random missing values\n\nf_fiveVTSrandom_linearinterpolation = torch.tensor(fiveVTSrandom_linearinterpolation).reshape(200,5,1).float()\n\n\nX_fiveVTSrandom_linearinterpolation = f_fiveVTSrandom_linearinterpolation[:199,:,:]\ny_fiveVTSrandom_linearinterpolation = f_fiveVTSrandom_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTSrandom_linearinterpolation,y_fiveVTSrandom_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTSrandom_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTSrandom_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTSrandom_linearinterpolation[:,2].data)\n\n\n\n\n\n\n3) By 2\n\nf_fiveVTStwo_linearinterpolation = torch.tensor(fiveVTStwo_linearinterpolation).reshape(200,5,1).float()\n\n\nX_fiveVTStwo_linearinterpolation = f_fiveVTSrandom_linearinterpolation[:199,:,:]\ny_fiveVTStwo_linearinterpolation = f_fiveVTSrandom_linearinterpolation[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X_fiveVTStwo_linearinterpolation,y_fiveVTStwo_linearinterpolation)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTStwo_linearinterpolation = torch.stack([model(xt, edge_index, edge_attr) for xt in X_fiveVTStwo_linearinterpolation]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTStwo_linearinterpolation[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#ì›ë˜-f",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#ì›ë˜-f",
    "title": "GCN Algorithm Example 1",
    "section": "2.3. ì›ë˜ f",
    "text": "2.3. ì›ë˜ f\n\nf = torch.tensor(fiveVTS).reshape(200,5,1).float()\n\n\nX = f[:199,:,:]\ny = f[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s]\n\n\n\nfhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(fhat_fiveVTS[:,2].data)"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-2",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#mean-2",
    "title": "GCN Algorithm Example 1",
    "section": "3.1. Mean",
    "text": "3.1. Mean\n\n3.1.1. Temporal\n\n1) Block\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_mean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_mean_temporal[:,0])\nplt.plot(fhatbarhat_mean_temporal[:,1])\nplt.plot(fhatbarhat_mean_temporal[:,2])\nplt.plot(fhatbarhat_mean_temporal[:,3])\nplt.plot(fhatbarhat_mean_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTSrandom_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_random_mean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_mean_temporal[:,0])\nplt.plot(fhatbarhat_random_mean_temporal[:,1])\nplt.plot(fhatbarhat_random_mean_temporal[:,2])\nplt.plot(fhatbarhat_random_mean_temporal[:,3])\nplt.plot(fhatbarhat_random_mean_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTStwo_mean[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_twomean_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_twomean_temporal[:,0])\nplt.plot(fhatbarhat_twomean_temporal[:,1])\nplt.plot(fhatbarhat_twomean_temporal[:,2])\nplt.plot(fhatbarhat_twomean_temporal[:,3])\nplt.plot(fhatbarhat_twomean_temporal[:,4])\n\n\n\n\n\n\n\n3.1.2. Spatio\n\n1) Block\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_mean_spatio[:,0])\nplt.plot(fhatbarhat_mean_spatio[:,1])\nplt.plot(fhatbarhat_mean_spatio[:,2])\nplt.plot(fhatbarhat_mean_spatio[:,3])\nplt.plot(fhatbarhat_mean_spatio[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_mean_spatio[:,0])\nplt.plot(fhatbarhat_random_mean_spatio[:,1])\nplt.plot(fhatbarhat_random_mean_spatio[:,2])\nplt.plot(fhatbarhat_random_mean_spatio[:,3])\nplt.plot(fhatbarhat_random_mean_spatio[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_mean.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_mean_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_mean_spatio[:,0])\nplt.plot(fhatbarhat_two_mean_spatio[:,1])\nplt.plot(fhatbarhat_two_mean_spatio[:,2])\nplt.plot(fhatbarhat_two_mean_spatio[:,3])\nplt.plot(fhatbarhat_two_mean_spatio[:,4])\n\n\n\n\n\n\n\n3.1.3. Spatio-Temporal\n\n1) Block\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_mean_spatio_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_random_mean_spatio_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_mean.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_mean_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,0])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,1])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,2])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,3])\nplt.plot(fhatbarhat_two_mean_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-2",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#linear-interpolation-2",
    "title": "GCN Algorithm Example 1",
    "section": "3.2.linear interpolation",
    "text": "3.2.linear interpolation\n\n3.2.1. Temporal\n\n1) Block\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTSrandom_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_random_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_random_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])\nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTStwo_linearinterpolation[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_two_linearinterpolation_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,0])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,1])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,2])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,3])\nplt.plot(fhatbarhat_two_linearinterpolation_temporal[:,4])\n\n\n\n\n\n\n\n3.2.2. Spatio\n\n1) Block\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_random_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_random_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_linearinterpolation.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_two_linearinterpolation_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,0])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,1])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,2])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,3])\nplt.plot(fhatbarhat_two_linearinterpolation_spatio[:,4])\n\n\n\n\n\n\n\n3.2.3. Spatio-Temporal\n\n1) Block\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_linearinterpolation_spatio_temporal[:,4])\n\n\n\n\n\n\n2) Random missing values\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTSrandom_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_random_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_random_linearinterpolation_spatio_temporal[:,4])\n\n\n\n\n\n\n3) By 2\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTStwo_linearinterpolation.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_two_linearinterpolation_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,0])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,1])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,2])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,3])\nplt.plot(fhat_two_linearinterpolation_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-01-11-Algorithm_EX_1.html#original",
    "href": "posts/GCN/2023-01-11-Algorithm_EX_1.html#original",
    "title": "GCN Algorithm Example 1",
    "section": "3.3. original",
    "text": "3.3. original\n\n1) Temporal\n\nw=np.zeros((5,199,199))\n\n\nfor k in range(5):\n    for i in range(199):\n        for j in range(199):\n            if i==j :\n                w[k,i,j] = 0\n            elif np.abs(i-j) <= 1 : \n                w[k,i,j] = 1\n\n\nd = np.array([w[i].sum(axis=1) for i in range(5)])\nD= np.array([np.diag(d[i]) for i in range(5)])\nL = np.array([np.diag(1/np.sqrt(d[i])) @ (D[i]-w[i]) @ np.diag(1/np.sqrt(d[i])) for i in range(5)])\nlamb, Psi  = np.linalg.eigh(L)[0],np.linalg.eigh(L)[1]\nLamb = np.array([np.diag(lamb[i]) for i in range(5)])    \nfhatbar = np.hstack([Psi[i] @ fhat_fiveVTS[:,i] for i in range(5)])\n_fhatbar = fhatbar.reshape(5,199)\npower = _fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(_fhatbar[i]**2))) for i in range(5)])\nfhatbar_threshed = np.where(power_threshed>0,_fhatbar,0)\nfhatbarhat = np.array([Psi[i] @ fhatbar_threshed[i] for i in range(5)])    \nfhatbarhat_temporal = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_temporal[:,0])\nplt.plot(fhatbarhat_temporal[:,1])\nplt.plot(fhatbarhat_temporal[:,2])\nplt.plot(fhatbarhat_temporal[:,3])\nplt.plot(fhatbarhat_temporal[:,4])\n\n\n\n\n\n\n2) Spatio\n\nw=np.zeros((5,5))\n\n\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTS.reshape(5,199)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(5)])    \nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_spatio = fhatbarhat.reshape(199,-1)\n\n\nplt.plot(fhatbarhat_spatio[:,0])\nplt.plot(fhatbarhat_spatio[:,1])\nplt.plot(fhatbarhat_spatio[:,2])\nplt.plot(fhatbarhat_spatio[:,3])\nplt.plot(fhatbarhat_spatio[:,4])\n\n\n\n\n\n\n3) Spatio-Temporal\n\nw=np.zeros((995,995))\n\n\nfor i in range(995):\n    for j in range(995):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ fhat_fiveVTS.reshape(995,1)\npower = fhatbar**2 \nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(995)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)\nfhatbarhat = Psi @ fhatbar_threshed\nfhat_spatio_temporal = fhatbarhat.reshape(199,5,1)\n\n\nplt.plot(fhat_spatio_temporal[:,0])\nplt.plot(fhat_spatio_temporal[:,1])\nplt.plot(fhat_spatio_temporal[:,2])\nplt.plot(fhat_spatio_temporal[:,3])\nplt.plot(fhat_spatio_temporal[:,4])"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      2\n      IT-STGCN\n      2\n      1.228\n      0.041\n    \n    \n      1\n      2\n      STGCN\n      2\n      1.230\n      0.042"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      2\n      IT-STGCN\n      1.227\n      0.030\n    \n    \n      1\n      0.125\n      2\n      STGCN\n      1.254\n      0.046"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      16\n      IT-STGCN\n      0.726\n      0.007\n    \n    \n      1\n      16\n      STGCN\n      0.727\n      0.011"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      16\n      IT-STGCN\n      0.797\n      0.010\n    \n    \n      1\n      0.3\n      linear\n      16\n      STGCN\n      1.032\n      0.039\n    \n    \n      2\n      0.8\n      linear\n      16\n      IT-STGCN\n      1.467\n      0.076\n    \n    \n      3\n      0.8\n      linear\n      16\n      STGCN\n      2.287\n      0.074"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-1",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      16\n      IT-STGCN\n      0.739812\n      0.007356\n    \n    \n      1\n      linear\n      0.28777\n      16\n      STGCN\n      0.812195\n      0.006422\n    \n    \n      2\n      nearest\n      0.28777\n      16\n      IT-STGCN\n      0.738336\n      0.007345\n    \n    \n      3\n      nearest\n      0.28777\n      16\n      STGCN\n      0.832292\n      0.009452"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      8\n      IT-STGCN\n      1.131\n      0.015\n    \n    \n      1\n      4\n      8\n      STGCN\n      1.131\n      0.015"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.190\n      0.029\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.277\n      0.064\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.179\n      0.035\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.278\n      0.060\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.314\n      0.072\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.551\n      0.092\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.303\n      0.078\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.509\n      0.068"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-2",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.154\n      0.014\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.248\n      0.019\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.150\n      0.014\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.304\n      0.021"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#w_st",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.153\n      0.036\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.263\n      0.053\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.154\n      0.038\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.269\n      0.068\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.241\n      0.079\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.506\n      0.065\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.208\n      0.079\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.552\n      0.087\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.145\n      0.013\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.295\n      0.019\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.143\n      0.011\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.310\n      0.019"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-3",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-4",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#baseline-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.936\n      0.002\n    \n    \n      1\n      4\n      STGCN\n      0.936\n      0.002"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#random-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.111060\n      0.036307\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.225077\n      0.072743"
  },
  {
    "objectID": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html#block-5",
    "title": "DCRNN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.940344\n      0.001323\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.955944\n      0.003010"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "",
    "text": "Simulation Tables"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      12\n      IT-STGCN\n      2\n      1.084\n      0.017\n    \n    \n      1\n      12\n      STGCN\n      2\n      1.085\n      0.014"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='rand'\").groupby(['mrate','nof_filters','method','lags'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==12\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      lags\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.7\n      12\n      IT-STGCN\n      2\n      1.119\n      0.043\n    \n    \n      1\n      0.7\n      12\n      STGCN\n      2\n      1.156\n      0.070\n    \n    \n      2\n      0.8\n      12\n      IT-STGCN\n      2\n      1.132\n      0.051\n    \n    \n      3\n      0.8\n      12\n      STGCN\n      2\n      1.169\n      0.065"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='fivenodes' and mtype=='block'\").groupby(['mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters','mrate']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.125\n      12\n      IT-STGCN\n      1.090\n      0.015\n    \n    \n      1\n      0.125\n      12\n      STGCN\n      1.099\n      0.018"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype!='rand' and mtype!='block'\").groupby(['nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"nof_filters==16\")\n\n\n\n\n\n  \n    \n      \n      nof_filters\n      method\n      mean\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='rand'\").groupby(['mrate','inter_method','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      inter_method\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      linear\n      12\n      IT-STGCN\n      1.042\n      0.020\n    \n    \n      1\n      0.3\n      linear\n      12\n      STGCN\n      1.054\n      0.015\n    \n    \n      2\n      0.8\n      linear\n      12\n      IT-STGCN\n      1.183\n      0.028\n    \n    \n      3\n      0.8\n      linear\n      12\n      STGCN\n      1.466\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-1",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-1",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='chickenpox' and mtype=='block'\").groupby(['inter_method','mrate','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','inter_method','mrate','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      inter_method\n      mrate\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      linear\n      0.28777\n      12\n      IT-STGCN\n      1.064651\n      0.030813\n    \n    \n      1\n      linear\n      0.28777\n      12\n      STGCN\n      1.082494\n      0.028106\n    \n    \n      2\n      nearest\n      0.28777\n      12\n      IT-STGCN\n      1.069594\n      0.028391\n    \n    \n      3\n      nearest\n      0.28777\n      12\n      STGCN\n      1.079100\n      0.027403"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype!='rand' and mtype!='block'\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['method','lags','nof_filters']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      lags\n      nof_filters\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      12\n      IT-STGCN\n      1.341\n      0.067\n    \n    \n      1\n      4\n      12\n      STGCN\n      1.274\n      0.067"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.280\n      0.070\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.302\n      0.112\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.248\n      0.074\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.291\n      0.111\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.257\n      0.048\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.257\n      0.072\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.260\n      0.072\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.301\n      0.090"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-2",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-2",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='pedalme' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.278\n      0.056\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.244\n      0.071\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.262\n      0.066\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.232\n      0.069"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#w_st",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#w_st",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "W_st",
    "text": "W_st\n\npd.merge(data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      4\n      linear\n      IT-STGCN\n      1.320\n      0.164\n    \n    \n      1\n      0.3\n      4\n      linear\n      STGCN\n      1.287\n      0.126\n    \n    \n      2\n      0.3\n      4\n      nearest\n      IT-STGCN\n      1.276\n      0.105\n    \n    \n      3\n      0.3\n      4\n      nearest\n      STGCN\n      1.313\n      0.101\n    \n    \n      4\n      0.6\n      4\n      linear\n      IT-STGCN\n      1.304\n      0.129\n    \n    \n      5\n      0.6\n      4\n      linear\n      STGCN\n      1.299\n      0.076\n    \n    \n      6\n      0.6\n      4\n      nearest\n      IT-STGCN\n      1.338\n      0.202\n    \n    \n      7\n      0.6\n      4\n      nearest\n      STGCN\n      1.297\n      0.093\n    \n  \n\n\n\n\n\npd.merge(data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data_pedal2.query(\"mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags','inter_method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3).query(\"lags==4\")\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.286\n      4\n      linear\n      IT-STGCN\n      1.243\n      0.110\n    \n    \n      1\n      0.286\n      4\n      linear\n      STGCN\n      1.176\n      0.068\n    \n    \n      2\n      0.286\n      4\n      nearest\n      IT-STGCN\n      1.237\n      0.083\n    \n    \n      3\n      0.286\n      4\n      nearest\n      STGCN\n      1.258\n      0.064"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mrate==0\").groupby(['lags','nof_filters','method'])['mse'].std().reset_index(),\n         on=['lags','nof_filters','method']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      nof_filters\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.3\n      8\n      IT-STGCN\n      0.748\n      0.052\n    \n    \n      1\n      0.3\n      8\n      STGCN\n      0.720\n      0.020"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-3",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-3",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='wikimath' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#missing-values-on-the-same-nodes",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\npd.merge(data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n        data_wiki_GSO.groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='rand'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-4",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-4",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='windmillsmall' and mtype=='block'\").groupby(['mrate','lags','method'])['mse'].std().reset_index(),\n         on=['method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      mean\n      mrate\n      lags\n      method\n      std"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#baseline-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Baseline",
    "text": "Baseline\n\npd.merge(data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mrate==0\").groupby(['lags','method'])['mse'].std().reset_index(),\n         on=['method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'}).round(3)\n\n\n\n\n\n  \n    \n      \n      lags\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      4\n      IT-STGCN\n      0.984\n      0.007\n    \n    \n      1\n      4\n      STGCN\n      0.982\n      0.006"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#random-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Random",
    "text": "Random\n\npd.merge(data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='rand'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['mrate','inter_method','method','mrate','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.8\n      4\n      nearest\n      IT-STGCN\n      1.072795\n      0.024438\n    \n    \n      1\n      0.8\n      4\n      nearest\n      STGCN\n      1.217952\n      0.085842"
  },
  {
    "objectID": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-5",
    "href": "posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html#block-5",
    "title": "TGCN_Simulation Tables_reshape",
    "section": "Block",
    "text": "Block\n\npd.merge(data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].mean().reset_index(),\n         data.query(\"dataset=='monte' and mtype=='block'\").groupby(['mrate','lags','inter_method','method'])['mse'].std().reset_index(),\n         on=['method','mrate','inter_method','lags']).rename(columns={'mse_x':'mean','mse_y':'std'})\n\n\n\n\n\n  \n    \n      \n      mrate\n      lags\n      inter_method\n      method\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.149142\n      4\n      nearest\n      IT-STGCN\n      0.983640\n      0.006550\n    \n    \n      1\n      0.149142\n      4\n      nearest\n      STGCN\n      0.985485\n      0.005308"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html",
    "title": "Data management Figure for ITSTGCN",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\n\n\ndf <- read.csv(\"./df_fig.csv\")\n\n\nhead(df)\n\n\n\n\n\n    Xdatasetmethodmratemtypelagsnof_filtersinter_methodepochmsecalculation_timemodel\n    <int><chr><chr><dbl><chr><int><dbl><chr><dbl><dbl><dbl><chr>\n\n\n    10fivenodesSTGCN0.0    212       500.7293743 80.98522GConvGRU\n    21fivenodesSTGCN0.0    212       500.7290817 80.89179GConvGRU\n    32fivenodesSTGCN0.7rand212linear 501.8922616 81.97655GConvGRU\n    43fivenodesSTGCN0.7rand212nearest502.2112885 87.80387GConvGRU\n    54fivenodesSTGCN0.8rand212linear 502.0728178103.64874GConvGRU\n    65fivenodesSTGCN0.8rand212nearest502.5664744 98.34010GConvGRU\n\n\nA data.frame: 6 Ã— 12"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#í›„ë³´-1",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#í›„ë³´-1",
    "title": "Data management Figure for ITSTGCN",
    "section": "í›„ë³´ 1",
    "text": "í›„ë³´ 1\n\nggplot(fivenodes, aes(x=mrate,y= mse,group=mrate)) + facet_wrap(model~method) + \ngeom_boxplot(fill='grey',color='black',width=0.7,outlier.color = 'darkblue',outlier.shape = 2) + theme_classic()\n# ggsave(\"random_list_fivenodes.png\")"
  },
  {
    "objectID": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#í›„ë³´-2",
    "href": "posts/GCN/2023-07-20-ITSTGCN_data_magement_figure.html#í›„ë³´-2",
    "title": "Data management Figure for ITSTGCN",
    "section": "í›„ë³´ 2",
    "text": "í›„ë³´ 2\n\nggplot(fivenodes, aes(x=mrate,y= log10(mse),group=mrate)) + facet_wrap(model~method,,ncol=4) + \ngeom_boxplot(fill='grey',color='black',width=0.7,outlier.color = 'darkblue',outlier.shape = 2) + \ntheme_classic() \n# ggsave(\"random_list_fivenodes.png\")"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "",
    "text": "Simulation Study"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate==0\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Random",
    "text": "Random\n\ndata.query(\"method!='GNAR' and mtype =='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-1",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-1",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Block",
    "text": "Block\n\ndata.query(\"method!='GNAR' and mtype =='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate ==0 and lags!=2\").plot.box(backend='plotly',x='epoch',color='method',y='mse',facet_col='nof_filters',facet_row='lags',height=400)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' and lags!=2\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-2",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-2",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' and lags!=2 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='nof_filters',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#weight-matrix-time-node-ê³ ë ¤í•œ-ê²°ê³¼",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼",
    "text": "weight matrix time, node ê³ ë ¤í•œ ê²°ê³¼\n\ndf1 = pd.read_csv('./simulation_results/2023-06-30_13-25-56.csv')\ndf2 = pd.read_csv('./simulation_results/2023-06-30_14-00-19.csv')\n\n\ndata2 = pd.concat([df1,df2],axis=0)\n\n\ndata2.to_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_pedalme_Simulation_itstgcnsnd.csv',index=False)\n\n\ndata2 = pd.read_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_pedalme_Simulation_itstgcnsnd.csv')\n\n\ndata2.query(\"mtype=='rand'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)\n\n\n                                                \n\n\n\ndata2.query(\"mtype=='block'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='nof_filters',height=1000)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-3",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-3",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#missing-values-on-the-same-nodes",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "missing values on the same nodes",
    "text": "missing values on the same nodes\n\ndf1 = pd.read_csv('./simulation_results/2023-07-01_17-41-40.csv') # STGCN IT-STGCN block\ndf2 = pd.read_csv('./simulation_results/2023-07-01_21-00-26.csv') # STGCN IT-STGCN\ndf3 = pd.read_csv('./simulation_results/2023-07-02_00-17-30.csv') \n\n\ndata = pd.concat([df1,df2,df3],axis=0)\n\n\ndata.to_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_wikimath_GSO_st.csv',index=False)\n\n\ndata = pd.read_csv('./simulation_results/Real_simulation_reshape/DYGRENCODER_wikimath_GSO_st.csv')\n\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='inter_method',facet_row='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"method!='GNAR' and mrate ==0 \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"method!='GNAR' and mtype =='rand' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-4",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-4",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"method!='GNAR' and mtype =='block' \").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#baseline-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "Baseline",
    "text": "Baseline\n\ndata.query(\"mrate==0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=600)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#random-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "random",
    "text": "random\n\ndata.query(\"mtype=='rand' and mrate !=0 and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='inter_method',height=800)"
  },
  {
    "objectID": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-5",
    "href": "posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html#block-5",
    "title": "DYGRENCODER_Simulation_reshape",
    "section": "block",
    "text": "block\n\ndata.query(\"mtype=='block' and method!='GNAR'\").plot.box(backend='plotly',x='mrate',color='method',y='mse',facet_col='lags',facet_row='nof_filters',height=1200)"
  },
  {
    "objectID": "posts/FRAUD/2023-07-10-fraud_data.html",
    "href": "posts/FRAUD/2023-07-10-fraud_data.html",
    "title": "Fraud data",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport sklearn\n\n# from ctgan import CTGAN\n# from ctgan import load_demo\n\nfrom sklearn import model_selection # splití•¨ìˆ˜ì´ìš©\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\nref: https://miruetoto.github.io/yechan3/posts/3_Researches/BORAM/2023-07-03-CTGAN_%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C.html\n\n\nData\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf50 = down_sample_textbook(df02)\n_df50 = df50.assign(Date=list(map(lambda x: x.split(' ')[0],df50['trans_date_trans_time'])),Time=list(map(lambda x: x.split(' ')[1],df50['trans_date_trans_time'])))\n\n\n_df50\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      city_pop\n      job\n      dob\n      trans_num\n      unix_time\n      merch_lat\n      merch_long\n      is_fraud\n      Date\n      Time\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      885\n      Soil scientist\n      1988-09-15\n      e8a81877ae9a0a7f883e15cb39dc4022\n      1325466397\n      36.430124\n      -81.179483\n      1\n      2019-01-02\n      1:06\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      bc7d41c41103877b03232f03f1f8d3f5\n      1325468849\n      29.819364\n      -99.142791\n      1\n      2019-01-02\n      1:47\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      b98f12f4168391b2203238813df5aa8c\n      1325473523\n      29.273085\n      -98.836360\n      1\n      2019-01-02\n      3:05\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      885\n      Soil scientist\n      1988-09-15\n      397894a5c4c02e3c61c784001f0f14e4\n      1325475483\n      35.909292\n      -82.091010\n      1\n      2019-01-02\n      3:38\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      1595797\n      Horticultural consultant\n      1960-10-28\n      7863235a750d73a244c07f1fb7f0185a\n      1325476547\n      29.786426\n      -98.683410\n      1\n      2019-01-02\n      3:55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      1507\n      Land/geomatics surveyor\n      1993-10-12\n      c66cb411019c7dfd4d89f42a1ba4765f\n      1339961448\n      44.212695\n      -95.661879\n      0\n      2019-06-17\n      19:30\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      965\n      Horticultural therapist\n      1982-02-10\n      316b9d25b9fa7d08a6831b7dab6634cd\n      1331994839\n      38.394240\n      -86.413557\n      0\n      2019-03-17\n      14:33\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      530\n      Transport planner\n      1967-09-23\n      d92e9e63d9b24c3ccb92d05cba4cac54\n      1355747517\n      39.695248\n      -89.853063\n      0\n      2019-12-17\n      12:31\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      885\n      Pilot, airline\n      1949-08-14\n      8390ce51cfb8482b618ebc4ac370bcf7\n      1326878457\n      42.633204\n      -95.598143\n      0\n      2019-01-18\n      9:20\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      1760\n      Occupational psychologist\n      1972-01-20\n      04e1be9bcb18ea8b96048659bd02177b\n      1345123058\n      33.885236\n      -95.885110\n      0\n      2019-08-16\n      13:17\n    \n  \n\n12012 rows Ã— 24 columns\n\n\n\n\n_df50.columns\n\nIndex(['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n       'merch_long', 'is_fraud', 'Date', 'Time'],\n      dtype='object')\n\n\n\ndf50['is_fraud'].mean()\n\n0.5\n\n\n\ndf50['category'].unique()\n\narray(['grocery_pos', 'gas_transport', 'shopping_net', 'misc_net',\n       'shopping_pos', 'travel', 'grocery_net', 'misc_pos',\n       'health_fitness', 'kids_pets', 'entertainment', 'food_dining',\n       'home', 'personal_care'], dtype=object)\n\n\n\n_df50_add = _df50.assign(Year = list(map(lambda x: x.split('-')[0],_df50['Date'])),\\\n                        Mon = list(map(lambda x: x.split('-')[1],_df50['Date'])),\\\n                        Day = list(map(lambda x: x.split('-')[2],_df50['Date'])),\\\n                         Hour= list(map(lambda x: x.split(':')[0],_df50['Time'])),\\\n                         Sec= list(map(lambda x: x.split(':')[1],_df50['Time'])))\n_df50_add.Year = _df50_add.Year.astype(np.float64)\n_df50_add.Mon = _df50_add.Mon.astype(np.float64)\n_df50_add.Day = _df50_add.Day.astype(np.float64)\n_df50_add.Hour = _df50_add.Hour.astype(np.float64)\n_df50_add.Sec = _df50_add.Sec.astype(np.float64)\n\n\n_df50_add\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      merch_lat\n      merch_long\n      is_fraud\n      Date\n      Time\n      Year\n      Mon\n      Day\n      Hour\n      Sec\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      36.430124\n      -81.179483\n      1\n      2019-01-02\n      1:06\n      2019.0\n      1.0\n      2.0\n      1.0\n      6.0\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.819364\n      -99.142791\n      1\n      2019-01-02\n      1:47\n      2019.0\n      1.0\n      2.0\n      1.0\n      47.0\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.273085\n      -98.836360\n      1\n      2019-01-02\n      3:05\n      2019.0\n      1.0\n      2.0\n      3.0\n      5.0\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.909292\n      -82.091010\n      1\n      2019-01-02\n      3:38\n      2019.0\n      1.0\n      2.0\n      3.0\n      38.0\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.786426\n      -98.683410\n      1\n      2019-01-02\n      3:55\n      2019.0\n      1.0\n      2.0\n      3.0\n      55.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      44.212695\n      -95.661879\n      0\n      2019-06-17\n      19:30\n      2019.0\n      6.0\n      17.0\n      19.0\n      30.0\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      38.394240\n      -86.413557\n      0\n      2019-03-17\n      14:33\n      2019.0\n      3.0\n      17.0\n      14.0\n      33.0\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      39.695248\n      -89.853063\n      0\n      2019-12-17\n      12:31\n      2019.0\n      12.0\n      17.0\n      12.0\n      31.0\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      42.633204\n      -95.598143\n      0\n      2019-01-18\n      9:20\n      2019.0\n      1.0\n      18.0\n      9.0\n      20.0\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      33.885236\n      -95.885110\n      0\n      2019-08-16\n      13:17\n      2019.0\n      8.0\n      16.0\n      13.0\n      17.0\n    \n  \n\n12012 rows Ã— 29 columns\n\n\n\n\nfig,ax =plt.subplots(5,5)\nk=0\nfor i in range(5):\n    for j in range(5):\n        ax[i][j].hist(_df50_add[(_df50_add['Hour'] > k) & (_df50_add['Hour'] <= k+1)]['amt'])\n        # ax[i][j].set_xlim([0,15000])\n        ax[i][j].set_title(str(k))\n        if k < 24:\n            k = k + 1\n        else:\n            pass\nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig,ax =plt.subplots(4,4)\nk=0\nfor i in range(4):\n    for j in range(4):\n        ax[i][j].hist(df50[df50['category']==df50['category'].unique()[k]]['amt'])\n        # ax[i][j].set_ylim([-2,7])\n        ax[i][j].set_title(df50['category'].unique()[k])\n        if k < 12:\n            k = k + 1\n        else:\n            pass\nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html",
    "title": "Other Outlier Detection",
    "section": "",
    "text": "Note\n\n\n\nknn, cblof, ocsvm ì„ ì œì™¸í•œ ì´ìƒì¹˜ íƒì§€ ê¸°ë²•ë“¤ì— ë°ì´í„° ì§‘í•©ì—ì„œ ì´ìƒì¹˜ ë¹„ìœ¨ì„ ì§€ì •í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì´ ì¡´ì¬í•˜ì˜€ìŒ.\ndefaultê°’ì€ 10%ì¸ë°, ABOD ë°©ë²•ì—ì„œëŠ” 5ë¡œ ì§€ì •í•´ì£¼ì—ˆê³ , ë‹¤ë¥¸ ë°©ë²•ë“¤ì€ defaultì¸ 10%ê°€ ë“¤ì–´ê°”ë‹¤.\nì¼ë‹¨ ìš°ë¦¬ ë°©ë²•ì´ë‘ ë¹„êµí•´ì„œ ì¢‹ì€ì§€ ë³´ê¸°\niter\niter x - kNN, Feature Bagging, ABOD, Isolation, HBOS, SOS, SO-GAAL, MO-GAAL, LSCP\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(5,7)\\) and \\(U(-7,-5)\\).\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(3,7)\\) and \\(U(-7,-3)\\)."
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#class-code",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#class-code",
    "title": "Other Outlier Detection",
    "section": "Class Code",
    "text": "Class Code\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_orbit = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_bunny = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\nclass Conf_matrx:\n    def __init__(self,original,compare,tab):\n        self.original = original\n        self.compare = compare\n        self.tab = tab\n    def conf(self,name):\n        self.conf_matrix = confusion_matrix(self.original, self.compare)\n        \n        fig, ax = plt.subplots(figsize=(5, 5))\n        ax.matshow(self.conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n        for i in range(self.conf_matrix.shape[0]):\n            for j in range(self.conf_matrix.shape[1]):\n                ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n        plt.xlabel('Predictions', fontsize=18)\n        plt.ylabel('Actuals', fontsize=18)\n        plt.title('Confusion Matrix', fontsize=18)\n        plt.show()\n        \n        self.acc = accuracy_score(self.original, self.compare)\n        self.pre = precision_score(self.original, self.compare)\n        self.rec = recall_score(self.original, self.compare)\n        self.f1 = f1_score(self.original, self.compare)\n        \n        print('Accuracy: %.3f' % self.acc)\n        print('Precision: %.3f' % self.pre)\n        print('Recall: %.3f' % self.rec)\n        print('F1 Score: %.3f' % self.f1)\n        \n        self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\nclass Linear:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        #self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=20): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n\n\nclass Orbit:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=20): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n\n\nclass BUNNY:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = _W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-ebayesthresh",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-ebayesthresh",
    "title": "Other Outlier Detection",
    "section": "Linear EbayesThresh",
    "text": "Linear EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\n# signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))\nsignal_1 = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier_1 = which(signal_1!=0)\nindex_of_trueoutlier_1\nx_1=signal_1+epsilon\n\n\n%R -o x_1\n%R -o index_of_trueoutlier_1\n%R -o signal_1\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\noutlier_true_index_1 = index_of_trueoutlier_1\n\n\noutlier_true_value_1 = x_1[index_of_trueoutlier_1]\n\n\noutlier_true_one_1 = signal_1.copy()\n\n\noutlier_true_one_1 = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one_1))"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear",
    "title": "Other Outlier Detection",
    "section": "Linear",
    "text": "Linear\n\n_x_1 = np.linspace(0,2,1000)\n_y1_1 = 5*_x_1\n_y_1 = _y1_1 + x_1 # x is epsilon\n\n\n_df=pd.DataFrame({'x':_x_1, 'y':_y_1})\n\n\nX = np.array(_df)\n\n\n# _df.to_csv('simple_linear_df.csv')\n\n\n# pd.DataFrame(outlier_true_one_1).to_csv('simple_linear_outlier.csv')\n\n\nGODE\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n_Linear = Linear(_df)\n\n\n_Linear.fit(sd=20)\n\n\noutlier_simul_one = (_Linear.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 9.8 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)\n\n\noutlier_simul_one.count(1)\n\n950\n\n\n\noutlier_simul_one.count(-1)\n\n50\n\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF(Breunig et al. 2000)\\(\\star\\)\n\nBreunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and JÃ¶rg Sander. 2000. â€œLOF: Identifying Density-Based Local Outliers.â€ In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 93â€“104.\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\nLof ë…¼ë¬¸ ì›ë¬¸ì— ë”°ë¼ LOFë¥¼ ê³„ì‚°í•˜ê³ , min-max ë²”ìœ„ë¥¼ ë„˜ìœ¼ë©´ ì´ìƒì¹˜\n\n\n\nFigure: LOFâ€™s outliers detection method\n\n\n\n_conf = Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.926\nPrecision: 0.961\nRecall: 0.961\nF1 Score: 0.961\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nfrom pyod.models.knn import KNN\n\n\nclf = KNN()\nclf.fit(_df[['x', 'y']])\n_df['knn_Clf'] = clf.labels_\n\nkë²ˆì§¸ ì´ìƒì€ outlierë¡œ ë³¸ë‹¤.\nì´ìƒì¹˜ ë¹„ìœ¨ ì •í•˜ì§€ ì•ŠìŒ\nThree kNN detectors are supported:\n\nlargest: use the distance to the kth neighbor as the outlier score\nmean: use the average of all k neighbors as the outlier score\nmedian: use the median of the distance to k neighbors as the outlier score\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 1.000\nRecall: 0.947\nF1 Score: 0.973\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF(ì˜¤ë¥˜)\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n_df =  pd.read_csv('simple_linear_df.csv')\n\n\noutlier_true_one_1 = pd.read_csv('simple_linear_outlier.csv').iloc[:,1].tolist()\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\noutlier_CBLOF_one = list(clf.labels_)\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)\n\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.972\nPrecision: 0.985\nRecall: 0.985\nF1 Score: 0.985\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\n# four = three.append(_conf.tab)\n\n\nAccuracy: 0.972\nPrecision: 0.985\nRecall: 0.985\nF1 Score: 0.985\n\n\n\nOCSVM\ndefault=10%\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.05, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.05, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.991\nRecall: 0.940\nF1 Score: 0.965\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\\(\\star\\)\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\\(\\star\\)\ndefaultê°’ì€ 10%ë¡œ ì„¤ì •ë˜ì–´ ìˆì—ˆê³ , 5%ë¡œ ì§€ì •í•œ ê²°ê³¼, í‰ê°€ì§€í‘œê°’ì´ ì „ë°˜ì ìœ¼ë¡œ 1%ì´ìƒ ë‚®ì•„ì¡Œë‹¤.\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.986\nPrecision: 0.993\nRecall: 0.993\nF1 Score: 0.993\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\\(\\star\\)\ndefault ê°’ì´ 5%ì´ë©°, ì´ë¯¸ ì§€ì •ëœ ì±„ë ¤ ì‹œë®¬ë ˆì´ì…˜ ëŒë¦¼\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['ABOD_Clf'] = clf.labels_\n\ncontamination : float in (0., 0.5), optional (default=0.1)\n\nThe amount of contamination of the data set, i.e.\nthe proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\n\n\nIForest\\(\\star\\)\nn_estimators Number of base estimators in the ensemble.\n\nnì´ ì´ 1000ê°œë‹ˆê¹Œ 5%ì¸ 50 ì§€ì •í•´ì¤„ ìˆ˜ ìˆìŒ\n\n\nod = IForest(\n    threshold=0.,\n    n_estimators=50\n)\n\n\nod.fit(_df[['x', 'y']])\n\n\npreds = od.predict(\n    _df[['x', 'y']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.868\nPrecision: 0.999\nRecall: 0.862\nF1 Score: 0.925\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\\(\\star\\)\ndefaultê°’ì€ ì´ìƒì¹˜ê°’ì„ 10%ë¡œ ì§€ì •í•˜ì˜€ìœ¼ë©°, 5%ë¡œ ì§€ì •í•œ ê²°ê³¼ ê°’ ë‹¤ ì‘ì•„ì§\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.960\nPrecision: 0.978\nRecall: 0.980\nF1 Score: 0.979\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\\(\\star\\)\ndefault ëŠ” 10%\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3130\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.3524\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3562\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3857\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3845\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3516\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3861\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4008\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3870\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4348\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.3913\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4431\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4510\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4427\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.4704\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4752\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4794\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4972\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4998\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.5168\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5228\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.5560\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5677\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.4929\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5675\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5508\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5679\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5563\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5806\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.5637\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5749\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6370\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6088\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6408\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6699\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5958\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5661\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.6471\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.6815\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6419\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6967\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7016\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6348\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 5ms/step - loss: 1.6519\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6470\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6582\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6890\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7197\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7613\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7085\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6933\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7013\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7330\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7275\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7635\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7682\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8321\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7557\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.7231\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7787\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.7553\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7782\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7678\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8069\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.7798\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8038\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 5ms/step - loss: 1.8120\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7591\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8204\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8033\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8414\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.7215\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8414\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8143\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8406\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8562\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8167\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8597\n32/32 [==============================] - 0s 2ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.936\nPrecision: 0.966\nRecall: 0.966\nF1 Score: 0.966\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\\(\\star\\)\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n32/32 [==============================] - 0s 658us/step\n\nTesting for epoch 1 index 2:\n32/32 [==============================] - 0s 865us/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n32/32 [==============================] - 0s 597us/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n32/32 [==============================] - 0s 623us/step\n\nTesting for epoch 4 index 2:\n32/32 [==============================] - 0s 633us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n32/32 [==============================] - 0s 597us/step\n\nTesting for epoch 5 index 2:\n32/32 [==============================] - 0s 605us/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n32/32 [==============================] - 0s 810us/step\n\nTesting for epoch 6 index 2:\n32/32 [==============================] - 0s 613us/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n32/32 [==============================] - 0s 610us/step\n\nTesting for epoch 7 index 2:\n32/32 [==============================] - 0s 624us/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n32/32 [==============================] - 0s 597us/step\n\nTesting for epoch 8 index 2:\n32/32 [==============================] - 0s 833us/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n32/32 [==============================] - 0s 615us/step\n\nTesting for epoch 9 index 2:\n32/32 [==============================] - 0s 600us/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n32/32 [==============================] - 0s 614us/step\n\nTesting for epoch 10 index 2:\n32/32 [==============================] - 0s 635us/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n32/32 [==============================] - 0s 619us/step\n\nTesting for epoch 11 index 2:\n32/32 [==============================] - 0s 610us/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n32/32 [==============================] - 0s 610us/step\n\nTesting for epoch 12 index 2:\n32/32 [==============================] - 0s 613us/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n32/32 [==============================] - 0s 616us/step\n\nTesting for epoch 13 index 2:\n32/32 [==============================] - 0s 627us/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n32/32 [==============================] - 0s 621us/step\n\nTesting for epoch 14 index 2:\n32/32 [==============================] - 0s 614us/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n32/32 [==============================] - 0s 846us/step\n\nTesting for epoch 15 index 2:\n32/32 [==============================] - 0s 623us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n32/32 [==============================] - 0s 915us/step\n\nTesting for epoch 16 index 2:\n32/32 [==============================] - 0s 836us/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 17 index 2:\n32/32 [==============================] - 0s 829us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n32/32 [==============================] - 0s 860us/step\n\nTesting for epoch 18 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n32/32 [==============================] - 0s 832us/step\n\nTesting for epoch 20 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n32/32 [==============================] - 0s 870us/step\n\nTesting for epoch 21 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3802\n16/16 [==============================] - 0s 992us/step - loss: 0.7194\n16/16 [==============================] - 0s 1ms/step - loss: 0.9382\n16/16 [==============================] - 0s 2ms/step - loss: 1.1679\n16/16 [==============================] - 0s 1ms/step - loss: 1.2953\n16/16 [==============================] - 0s 982us/step - loss: 1.3707\n16/16 [==============================] - 0s 1ms/step - loss: 1.4090\n16/16 [==============================] - 0s 1ms/step - loss: 1.4370\n16/16 [==============================] - 0s 1ms/step - loss: 1.4481\n16/16 [==============================] - 0s 1ms/step - loss: 1.4524\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3784\n16/16 [==============================] - 0s 3ms/step - loss: 0.7280\n16/16 [==============================] - 0s 1ms/step - loss: 0.9713\n16/16 [==============================] - 0s 2ms/step - loss: 1.2091\n16/16 [==============================] - 0s 1ms/step - loss: 1.3341\n16/16 [==============================] - 0s 2ms/step - loss: 1.4019\n16/16 [==============================] - 0s 2ms/step - loss: 1.4333\n16/16 [==============================] - 0s 1ms/step - loss: 1.4551\n16/16 [==============================] - 0s 1ms/step - loss: 1.4629\n16/16 [==============================] - 0s 1ms/step - loss: 1.4656\n\nTesting for epoch 22 index 2:\n32/32 [==============================] - 0s 913us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3866\n16/16 [==============================] - 0s 1ms/step - loss: 0.7327\n16/16 [==============================] - 0s 2ms/step - loss: 0.9839\n16/16 [==============================] - 0s 5ms/step - loss: 1.2335\n16/16 [==============================] - 0s 1ms/step - loss: 1.3481\n16/16 [==============================] - 0s 3ms/step - loss: 1.4093\n16/16 [==============================] - 0s 1ms/step - loss: 1.4348\n16/16 [==============================] - 0s 2ms/step - loss: 1.4506\n16/16 [==============================] - 0s 1ms/step - loss: 1.4559\n16/16 [==============================] - 0s 2ms/step - loss: 1.4576\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.3956\n16/16 [==============================] - 0s 1ms/step - loss: 0.7406\n16/16 [==============================] - 0s 1ms/step - loss: 0.9936\n16/16 [==============================] - 0s 2ms/step - loss: 1.2356\n16/16 [==============================] - 0s 2ms/step - loss: 1.3418\n16/16 [==============================] - 0s 1ms/step - loss: 1.3928\n16/16 [==============================] - 0s 2ms/step - loss: 1.4131\n16/16 [==============================] - 0s 1ms/step - loss: 1.4239\n16/16 [==============================] - 0s 1ms/step - loss: 1.4275\n16/16 [==============================] - 0s 1ms/step - loss: 1.4283\n\nTesting for epoch 23 index 2:\n32/32 [==============================] - 0s 5ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3925\n16/16 [==============================] - 0s 1ms/step - loss: 0.7523\n16/16 [==============================] - 0s 1ms/step - loss: 1.0367\n16/16 [==============================] - 0s 1ms/step - loss: 1.2950\n16/16 [==============================] - 0s 2ms/step - loss: 1.3968\n16/16 [==============================] - 0s 2ms/step - loss: 1.4439\n16/16 [==============================] - 0s 2ms/step - loss: 1.4623\n16/16 [==============================] - 0s 1ms/step - loss: 1.4710\n16/16 [==============================] - 0s 2ms/step - loss: 1.4735\n16/16 [==============================] - 0s 2ms/step - loss: 1.4740\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4051\n16/16 [==============================] - 0s 2ms/step - loss: 0.7528\n16/16 [==============================] - 0s 2ms/step - loss: 1.0473\n16/16 [==============================] - 0s 1ms/step - loss: 1.2922\n16/16 [==============================] - 0s 1ms/step - loss: 1.3798\n16/16 [==============================] - 0s 2ms/step - loss: 1.4177\n16/16 [==============================] - 0s 2ms/step - loss: 1.4316\n16/16 [==============================] - 0s 2ms/step - loss: 1.4376\n16/16 [==============================] - 0s 1ms/step - loss: 1.4391\n16/16 [==============================] - 0s 2ms/step - loss: 1.4393\n\nTesting for epoch 24 index 2:\n32/32 [==============================] - 0s 897us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.4123\n16/16 [==============================] - 0s 2ms/step - loss: 0.7576\n16/16 [==============================] - 0s 2ms/step - loss: 1.0566\n16/16 [==============================] - 0s 2ms/step - loss: 1.2987\n16/16 [==============================] - 0s 2ms/step - loss: 1.3765\n16/16 [==============================] - 0s 4ms/step - loss: 1.4095\n16/16 [==============================] - 0s 2ms/step - loss: 1.4206\n16/16 [==============================] - 0s 2ms/step - loss: 1.4250\n16/16 [==============================] - 0s 2ms/step - loss: 1.4259\n16/16 [==============================] - 0s 1ms/step - loss: 1.4259\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4149\n16/16 [==============================] - 0s 2ms/step - loss: 0.7675\n16/16 [==============================] - 0s 1ms/step - loss: 1.0765\n16/16 [==============================] - 0s 2ms/step - loss: 1.3167\n16/16 [==============================] - 0s 1ms/step - loss: 1.3880\n16/16 [==============================] - 0s 1ms/step - loss: 1.4164\n16/16 [==============================] - 0s 2ms/step - loss: 1.4257\n16/16 [==============================] - 0s 1ms/step - loss: 1.4288\n16/16 [==============================] - 0s 1ms/step - loss: 1.4294\n16/16 [==============================] - 0s 1ms/step - loss: 1.4293\n\nTesting for epoch 25 index 2:\n32/32 [==============================] - 0s 899us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4172\n16/16 [==============================] - 0s 1ms/step - loss: 0.7677\n16/16 [==============================] - 0s 1ms/step - loss: 1.0818\n16/16 [==============================] - 0s 1ms/step - loss: 1.3143\n16/16 [==============================] - 0s 1ms/step - loss: 1.3797\n16/16 [==============================] - 0s 1ms/step - loss: 1.4048\n16/16 [==============================] - 0s 1ms/step - loss: 1.4123\n16/16 [==============================] - 0s 1ms/step - loss: 1.4147\n16/16 [==============================] - 0s 2ms/step - loss: 1.4150\n16/16 [==============================] - 0s 2ms/step - loss: 1.4148\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n32/32 [==============================] - 0s 754us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4148\n16/16 [==============================] - 0s 2ms/step - loss: 0.7766\n16/16 [==============================] - 0s 4ms/step - loss: 1.1064\n16/16 [==============================] - 0s 2ms/step - loss: 1.3376\n16/16 [==============================] - 0s 1ms/step - loss: 1.4002\n16/16 [==============================] - 0s 1ms/step - loss: 1.4228\n16/16 [==============================] - 0s 1ms/step - loss: 1.4290\n16/16 [==============================] - 0s 1ms/step - loss: 1.4308\n16/16 [==============================] - 0s 1ms/step - loss: 1.4309\n16/16 [==============================] - 0s 1ms/step - loss: 1.4307\n\nTesting for epoch 26 index 2:\n32/32 [==============================] - 0s 842us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4190\n16/16 [==============================] - 0s 1ms/step - loss: 0.7761\n16/16 [==============================] - 0s 2ms/step - loss: 1.1055\n16/16 [==============================] - 0s 1ms/step - loss: 1.3282\n16/16 [==============================] - 0s 2ms/step - loss: 1.3846\n16/16 [==============================] - 0s 1ms/step - loss: 1.4044\n16/16 [==============================] - 0s 2ms/step - loss: 1.4095\n16/16 [==============================] - 0s 1ms/step - loss: 1.4108\n16/16 [==============================] - 0s 2ms/step - loss: 1.4108\n16/16 [==============================] - 0s 2ms/step - loss: 1.4105\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4225\n16/16 [==============================] - 0s 1ms/step - loss: 0.7746\n16/16 [==============================] - 0s 1ms/step - loss: 1.1026\n16/16 [==============================] - 0s 1ms/step - loss: 1.3159\n16/16 [==============================] - 0s 1ms/step - loss: 1.3665\n16/16 [==============================] - 0s 2ms/step - loss: 1.3838\n16/16 [==============================] - 0s 972us/step - loss: 1.3880\n16/16 [==============================] - 0s 1ms/step - loss: 1.3888\n16/16 [==============================] - 0s 1ms/step - loss: 1.3887\n16/16 [==============================] - 0s 2ms/step - loss: 1.3884\n\nTesting for epoch 27 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4196\n16/16 [==============================] - 0s 1ms/step - loss: 0.7825\n16/16 [==============================] - 0s 2ms/step - loss: 1.1245\n16/16 [==============================] - 0s 1ms/step - loss: 1.3411\n16/16 [==============================] - 0s 2ms/step - loss: 1.3905\n16/16 [==============================] - 0s 1ms/step - loss: 1.4071\n16/16 [==============================] - 0s 2ms/step - loss: 1.4109\n16/16 [==============================] - 0s 2ms/step - loss: 1.4116\n16/16 [==============================] - 0s 1ms/step - loss: 1.4115\n16/16 [==============================] - 0s 3ms/step - loss: 1.4112\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4124\n16/16 [==============================] - 0s 2ms/step - loss: 0.7896\n16/16 [==============================] - 0s 2ms/step - loss: 1.1481\n16/16 [==============================] - 0s 2ms/step - loss: 1.3684\n16/16 [==============================] - 0s 2ms/step - loss: 1.4180\n16/16 [==============================] - 0s 2ms/step - loss: 1.4340\n16/16 [==============================] - 0s 2ms/step - loss: 1.4374\n16/16 [==============================] - 0s 1ms/step - loss: 1.4380\n16/16 [==============================] - 0s 1ms/step - loss: 1.4378\n16/16 [==============================] - 0s 1ms/step - loss: 1.4375\n\nTesting for epoch 28 index 2:\n32/32 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4173\n16/16 [==============================] - 0s 2ms/step - loss: 0.7865\n16/16 [==============================] - 0s 2ms/step - loss: 1.1353\n16/16 [==============================] - 0s 1ms/step - loss: 1.3465\n16/16 [==============================] - 0s 1ms/step - loss: 1.3927\n16/16 [==============================] - 0s 1ms/step - loss: 1.4072\n16/16 [==============================] - 0s 2ms/step - loss: 1.4101\n16/16 [==============================] - 0s 1ms/step - loss: 1.4105\n16/16 [==============================] - 0s 1ms/step - loss: 1.4102\n16/16 [==============================] - 0s 1ms/step - loss: 1.4099\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n32/32 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4145\n16/16 [==============================] - 0s 1ms/step - loss: 0.7933\n16/16 [==============================] - 0s 1ms/step - loss: 1.1517\n16/16 [==============================] - 0s 1ms/step - loss: 1.3656\n16/16 [==============================] - 0s 5ms/step - loss: 1.4111\n16/16 [==============================] - 0s 4ms/step - loss: 1.4251\n16/16 [==============================] - 0s 4ms/step - loss: 1.4278\n16/16 [==============================] - 0s 2ms/step - loss: 1.4281\n16/16 [==============================] - 0s 2ms/step - loss: 1.4278\n16/16 [==============================] - 0s 2ms/step - loss: 1.4275\n\nTesting for epoch 29 index 2:\n32/32 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4111\n16/16 [==============================] - 0s 1ms/step - loss: 0.7909\n16/16 [==============================] - 0s 1ms/step - loss: 1.1516\n16/16 [==============================] - 0s 2ms/step - loss: 1.3647\n16/16 [==============================] - 0s 1ms/step - loss: 1.4090\n16/16 [==============================] - 0s 1ms/step - loss: 1.4224\n16/16 [==============================] - 0s 2ms/step - loss: 1.4249\n16/16 [==============================] - 0s 2ms/step - loss: 1.4250\n16/16 [==============================] - 0s 2ms/step - loss: 1.4247\n16/16 [==============================] - 0s 2ms/step - loss: 1.4244\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n32/32 [==============================] - 0s 869us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4107\n16/16 [==============================] - 0s 1ms/step - loss: 0.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.1611\n16/16 [==============================] - 0s 2ms/step - loss: 1.3750\n16/16 [==============================] - 0s 994us/step - loss: 1.4188\n16/16 [==============================] - 0s 903us/step - loss: 1.4319\n16/16 [==============================] - 0s 916us/step - loss: 1.4343\n16/16 [==============================] - 0s 997us/step - loss: 1.4344\n16/16 [==============================] - 0s 4ms/step - loss: 1.4341\n16/16 [==============================] - 0s 1ms/step - loss: 1.4338\n\nTesting for epoch 30 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4054\n16/16 [==============================] - 0s 4ms/step - loss: 0.7927\n16/16 [==============================] - 0s 3ms/step - loss: 1.1646\n16/16 [==============================] - 0s 2ms/step - loss: 1.3805\n16/16 [==============================] - 0s 4ms/step - loss: 1.4241\n16/16 [==============================] - 0s 2ms/step - loss: 1.4369\n16/16 [==============================] - 0s 2ms/step - loss: 1.4391\n16/16 [==============================] - 0s 1ms/step - loss: 1.4391\n16/16 [==============================] - 0s 1ms/step - loss: 1.4388\n16/16 [==============================] - 0s 1ms/step - loss: 1.4384\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3962\n16/16 [==============================] - 0s 2ms/step - loss: 0.7984\n16/16 [==============================] - 0s 1ms/step - loss: 1.1888\n16/16 [==============================] - 0s 5ms/step - loss: 1.4144\n16/16 [==============================] - 0s 3ms/step - loss: 1.4594\n16/16 [==============================] - 0s 2ms/step - loss: 1.4726\n16/16 [==============================] - 0s 4ms/step - loss: 1.4748\n16/16 [==============================] - 0s 2ms/step - loss: 1.4749\n16/16 [==============================] - 0s 1ms/step - loss: 1.4745\n16/16 [==============================] - 0s 1ms/step - loss: 1.4742\n\nTesting for epoch 31 index 2:\n32/32 [==============================] - 0s 898us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3984\n16/16 [==============================] - 0s 1ms/step - loss: 0.7936\n16/16 [==============================] - 0s 1ms/step - loss: 1.1789\n16/16 [==============================] - 0s 3ms/step - loss: 1.4023\n16/16 [==============================] - 0s 2ms/step - loss: 1.4465\n16/16 [==============================] - 0s 1ms/step - loss: 1.4593\n16/16 [==============================] - 0s 954us/step - loss: 1.4615\n16/16 [==============================] - 0s 1ms/step - loss: 1.4616\n16/16 [==============================] - 0s 998us/step - loss: 1.4612\n16/16 [==============================] - 0s 2ms/step - loss: 1.4608\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3891\n16/16 [==============================] - 0s 1ms/step - loss: 0.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.1911\n16/16 [==============================] - 0s 1ms/step - loss: 1.4219\n16/16 [==============================] - 0s 3ms/step - loss: 1.4666\n16/16 [==============================] - 0s 2ms/step - loss: 1.4796\n16/16 [==============================] - 0s 2ms/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.4815\n16/16 [==============================] - 0s 1ms/step - loss: 1.4811\n\nTesting for epoch 32 index 2:\n32/32 [==============================] - 0s 913us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.3883\n16/16 [==============================] - 0s 3ms/step - loss: 0.7919\n16/16 [==============================] - 0s 2ms/step - loss: 1.1930\n16/16 [==============================] - 0s 1ms/step - loss: 1.4285\n16/16 [==============================] - 0s 2ms/step - loss: 1.4721\n16/16 [==============================] - 0s 1ms/step - loss: 1.4852\n16/16 [==============================] - 0s 2ms/step - loss: 1.4875\n16/16 [==============================] - 0s 1ms/step - loss: 1.4875\n16/16 [==============================] - 0s 1ms/step - loss: 1.4871\n16/16 [==============================] - 0s 3ms/step - loss: 1.4867\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3772\n16/16 [==============================] - 0s 1ms/step - loss: 0.7929\n16/16 [==============================] - 0s 2ms/step - loss: 1.2122\n16/16 [==============================] - 0s 1ms/step - loss: 1.4584\n16/16 [==============================] - 0s 3ms/step - loss: 1.5041\n16/16 [==============================] - 0s 3ms/step - loss: 1.5178\n16/16 [==============================] - 0s 1ms/step - loss: 1.5201\n16/16 [==============================] - 0s 1ms/step - loss: 1.5202\n16/16 [==============================] - 0s 1ms/step - loss: 1.5198\n16/16 [==============================] - 0s 973us/step - loss: 1.5194\n\nTesting for epoch 33 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3685\n16/16 [==============================] - 0s 2ms/step - loss: 0.7940\n16/16 [==============================] - 0s 1ms/step - loss: 1.2262\n16/16 [==============================] - 0s 2ms/step - loss: 1.4829\n16/16 [==============================] - 0s 2ms/step - loss: 1.5311\n16/16 [==============================] - 0s 1ms/step - loss: 1.5455\n16/16 [==============================] - 0s 2ms/step - loss: 1.5481\n16/16 [==============================] - 0s 4ms/step - loss: 1.5482\n16/16 [==============================] - 0s 2ms/step - loss: 1.5478\n16/16 [==============================] - 0s 3ms/step - loss: 1.5474\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.3693\n16/16 [==============================] - 0s 1ms/step - loss: 0.7909\n16/16 [==============================] - 0s 1ms/step - loss: 1.2196\n16/16 [==============================] - 0s 1ms/step - loss: 1.4752\n16/16 [==============================] - 0s 2ms/step - loss: 1.5233\n16/16 [==============================] - 0s 2ms/step - loss: 1.5375\n16/16 [==============================] - 0s 1ms/step - loss: 1.5400\n16/16 [==============================] - 0s 1ms/step - loss: 1.5400\n16/16 [==============================] - 0s 2ms/step - loss: 1.5396\n16/16 [==============================] - 0s 3ms/step - loss: 1.5392\n\nTesting for epoch 34 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3592\n16/16 [==============================] - 0s 1ms/step - loss: 0.7936\n16/16 [==============================] - 0s 2ms/step - loss: 1.2413\n16/16 [==============================] - 0s 2ms/step - loss: 1.5117\n16/16 [==============================] - 0s 2ms/step - loss: 1.5633\n16/16 [==============================] - 0s 2ms/step - loss: 1.5786\n16/16 [==============================] - 0s 4ms/step - loss: 1.5814\n16/16 [==============================] - 0s 2ms/step - loss: 1.5816\n16/16 [==============================] - 0s 2ms/step - loss: 1.5812\n16/16 [==============================] - 0s 1ms/step - loss: 1.5808\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n32/32 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 923us/step - loss: 0.3582\n16/16 [==============================] - 0s 1ms/step - loss: 0.7895\n16/16 [==============================] - 0s 1ms/step - loss: 1.2360\n16/16 [==============================] - 0s 1ms/step - loss: 1.5072\n16/16 [==============================] - 0s 952us/step - loss: 1.5584\n16/16 [==============================] - 0s 2ms/step - loss: 1.5735\n16/16 [==============================] - 0s 2ms/step - loss: 1.5763\n16/16 [==============================] - 0s 1ms/step - loss: 1.5764\n16/16 [==============================] - 0s 2ms/step - loss: 1.5760\n16/16 [==============================] - 0s 1ms/step - loss: 1.5756\n\nTesting for epoch 35 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.3488\n16/16 [==============================] - 0s 2ms/step - loss: 0.7942\n16/16 [==============================] - 0s 1ms/step - loss: 1.2601\n16/16 [==============================] - 0s 1ms/step - loss: 1.5469\n16/16 [==============================] - 0s 1ms/step - loss: 1.6015\n16/16 [==============================] - 0s 1ms/step - loss: 1.6177\n16/16 [==============================] - 0s 1ms/step - loss: 1.6207\n16/16 [==============================] - 0s 2ms/step - loss: 1.6210\n16/16 [==============================] - 0s 2ms/step - loss: 1.6206\n16/16 [==============================] - 0s 1ms/step - loss: 1.6202\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n32/32 [==============================] - 0s 829us/step\n16/16 [==============================] - 0s 980us/step - loss: 0.3512\n16/16 [==============================] - 0s 943us/step - loss: 0.7854\n16/16 [==============================] - 0s 842us/step - loss: 1.2413\n16/16 [==============================] - 0s 816us/step - loss: 1.5228\n16/16 [==============================] - 0s 1ms/step - loss: 1.5761\n16/16 [==============================] - 0s 829us/step - loss: 1.5918\n16/16 [==============================] - 0s 819us/step - loss: 1.5947\n16/16 [==============================] - 0s 801us/step - loss: 1.5949\n16/16 [==============================] - 0s 852us/step - loss: 1.5945\n16/16 [==============================] - 0s 874us/step - loss: 1.5940\n\nTesting for epoch 36 index 2:\n32/32 [==============================] - 0s 637us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.3437\n16/16 [==============================] - 0s 798us/step - loss: 0.7857\n16/16 [==============================] - 0s 793us/step - loss: 1.2551\n16/16 [==============================] - 0s 784us/step - loss: 1.5475\n16/16 [==============================] - 0s 778us/step - loss: 1.6036\n16/16 [==============================] - 0s 789us/step - loss: 1.6201\n16/16 [==============================] - 0s 800us/step - loss: 1.6232\n16/16 [==============================] - 0s 786us/step - loss: 1.6234\n16/16 [==============================] - 0s 804us/step - loss: 1.6230\n16/16 [==============================] - 0s 771us/step - loss: 1.6226\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n32/32 [==============================] - 0s 837us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.3392\n16/16 [==============================] - 0s 772us/step - loss: 0.7786\n16/16 [==============================] - 0s 1ms/step - loss: 1.2518\n16/16 [==============================] - 0s 1ms/step - loss: 1.5415\n16/16 [==============================] - 0s 1ms/step - loss: 1.5975\n16/16 [==============================] - 0s 1ms/step - loss: 1.6140\n16/16 [==============================] - 0s 836us/step - loss: 1.6171\n16/16 [==============================] - 0s 781us/step - loss: 1.6173\n16/16 [==============================] - 0s 805us/step - loss: 1.6169\n16/16 [==============================] - 0s 802us/step - loss: 1.6165\n\nTesting for epoch 37 index 2:\n32/32 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.3362\n16/16 [==============================] - 0s 795us/step - loss: 0.7794\n16/16 [==============================] - 0s 806us/step - loss: 1.2570\n16/16 [==============================] - 0s 780us/step - loss: 1.5521\n16/16 [==============================] - 0s 821us/step - loss: 1.6094\n16/16 [==============================] - 0s 778us/step - loss: 1.6265\n16/16 [==============================] - 0s 835us/step - loss: 1.6298\n16/16 [==============================] - 0s 774us/step - loss: 1.6300\n16/16 [==============================] - 0s 773us/step - loss: 1.6296\n16/16 [==============================] - 0s 782us/step - loss: 1.6291\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n32/32 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.3350\n16/16 [==============================] - 0s 780us/step - loss: 0.7829\n16/16 [==============================] - 0s 807us/step - loss: 1.2628\n16/16 [==============================] - 0s 798us/step - loss: 1.5617\n16/16 [==============================] - 0s 790us/step - loss: 1.6196\n16/16 [==============================] - 0s 810us/step - loss: 1.6369\n16/16 [==============================] - 0s 814us/step - loss: 1.6402\n16/16 [==============================] - 0s 784us/step - loss: 1.6404\n16/16 [==============================] - 0s 812us/step - loss: 1.6400\n16/16 [==============================] - 0s 808us/step - loss: 1.6395\n\nTesting for epoch 38 index 2:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 854us/step - loss: 0.3207\n16/16 [==============================] - 0s 771us/step - loss: 0.7883\n16/16 [==============================] - 0s 791us/step - loss: 1.2870\n16/16 [==============================] - 0s 762us/step - loss: 1.6028\n16/16 [==============================] - 0s 770us/step - loss: 1.6645\n16/16 [==============================] - 0s 770us/step - loss: 1.6830\n16/16 [==============================] - 0s 792us/step - loss: 1.6866\n16/16 [==============================] - 0s 788us/step - loss: 1.6869\n16/16 [==============================] - 0s 827us/step - loss: 1.6865\n16/16 [==============================] - 0s 758us/step - loss: 1.6861\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 807us/step - loss: 0.3234\n16/16 [==============================] - 0s 771us/step - loss: 0.7890\n16/16 [==============================] - 0s 777us/step - loss: 1.2822\n16/16 [==============================] - 0s 780us/step - loss: 1.5961\n16/16 [==============================] - 0s 807us/step - loss: 1.6572\n16/16 [==============================] - 0s 795us/step - loss: 1.6753\n16/16 [==============================] - 0s 803us/step - loss: 1.6788\n16/16 [==============================] - 0s 1ms/step - loss: 1.6791\n16/16 [==============================] - 0s 682us/step - loss: 1.6786\n16/16 [==============================] - 0s 750us/step - loss: 1.6782\n\nTesting for epoch 39 index 2:\n32/32 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 660us/step - loss: 0.3169\n16/16 [==============================] - 0s 1ms/step - loss: 0.7846\n16/16 [==============================] - 0s 664us/step - loss: 1.2831\n16/16 [==============================] - 0s 655us/step - loss: 1.6025\n16/16 [==============================] - 0s 771us/step - loss: 1.6649\n16/16 [==============================] - 0s 675us/step - loss: 1.6836\n16/16 [==============================] - 0s 677us/step - loss: 1.6870\n16/16 [==============================] - 0s 815us/step - loss: 1.6873\n16/16 [==============================] - 0s 791us/step - loss: 1.6868\n16/16 [==============================] - 0s 785us/step - loss: 1.6863\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.3223\n16/16 [==============================] - 0s 769us/step - loss: 0.7759\n16/16 [==============================] - 0s 774us/step - loss: 1.2607\n16/16 [==============================] - 0s 769us/step - loss: 1.5701\n16/16 [==============================] - 0s 806us/step - loss: 1.6300\n16/16 [==============================] - 0s 781us/step - loss: 1.6478\n16/16 [==============================] - 0s 791us/step - loss: 1.6509\n16/16 [==============================] - 0s 779us/step - loss: 1.6511\n16/16 [==============================] - 0s 1ms/step - loss: 1.6506\n16/16 [==============================] - 0s 779us/step - loss: 1.6501\n\nTesting for epoch 40 index 2:\n32/32 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.3189\n16/16 [==============================] - 0s 824us/step - loss: 0.7810\n16/16 [==============================] - 0s 808us/step - loss: 1.2802\n16/16 [==============================] - 0s 809us/step - loss: 1.6001\n16/16 [==============================] - 0s 777us/step - loss: 1.6622\n16/16 [==============================] - 0s 785us/step - loss: 1.6807\n16/16 [==============================] - 0s 780us/step - loss: 1.6840\n16/16 [==============================] - 0s 805us/step - loss: 1.6842\n16/16 [==============================] - 0s 783us/step - loss: 1.6838\n16/16 [==============================] - 0s 818us/step - loss: 1.6833\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n32/32 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.3072\n16/16 [==============================] - 0s 828us/step - loss: 0.7912\n16/16 [==============================] - 0s 783us/step - loss: 1.3176\n16/16 [==============================] - 0s 819us/step - loss: 1.6547\n16/16 [==============================] - 0s 783us/step - loss: 1.7199\n16/16 [==============================] - 0s 810us/step - loss: 1.7392\n16/16 [==============================] - 0s 818us/step - loss: 1.7426\n16/16 [==============================] - 0s 773us/step - loss: 1.7428\n16/16 [==============================] - 0s 769us/step - loss: 1.7424\n16/16 [==============================] - 0s 772us/step - loss: 1.7419\n\nTesting for epoch 41 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.3088\n16/16 [==============================] - 0s 818us/step - loss: 0.7812\n16/16 [==============================] - 0s 804us/step - loss: 1.2987\n16/16 [==============================] - 0s 774us/step - loss: 1.6308\n16/16 [==============================] - 0s 770us/step - loss: 1.6949\n16/16 [==============================] - 0s 772us/step - loss: 1.7138\n16/16 [==============================] - 0s 803us/step - loss: 1.7172\n16/16 [==============================] - 0s 773us/step - loss: 1.7174\n16/16 [==============================] - 0s 789us/step - loss: 1.7170\n16/16 [==============================] - 0s 771us/step - loss: 1.7165\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n32/32 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.3021\n16/16 [==============================] - 0s 792us/step - loss: 0.7873\n16/16 [==============================] - 0s 673us/step - loss: 1.3203\n16/16 [==============================] - 0s 786us/step - loss: 1.6612\n16/16 [==============================] - 0s 2ms/step - loss: 1.7264\n16/16 [==============================] - 0s 2ms/step - loss: 1.7454\n16/16 [==============================] - 0s 2ms/step - loss: 1.7487\n16/16 [==============================] - 0s 767us/step - loss: 1.7489\n16/16 [==============================] - 0s 2ms/step - loss: 1.7484\n16/16 [==============================] - 0s 844us/step - loss: 1.7479\n\nTesting for epoch 42 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2994\n16/16 [==============================] - 0s 655us/step - loss: 0.7933\n16/16 [==============================] - 0s 1ms/step - loss: 1.3330\n16/16 [==============================] - 0s 818us/step - loss: 1.6811\n16/16 [==============================] - 0s 1ms/step - loss: 1.7477\n16/16 [==============================] - 0s 806us/step - loss: 1.7671\n16/16 [==============================] - 0s 825us/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.7707\n16/16 [==============================] - 0s 1ms/step - loss: 1.7702\n16/16 [==============================] - 0s 2ms/step - loss: 1.7697\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.3054\n16/16 [==============================] - 0s 2ms/step - loss: 0.7894\n16/16 [==============================] - 0s 2ms/step - loss: 1.3140\n16/16 [==============================] - 0s 799us/step - loss: 1.6513\n16/16 [==============================] - 0s 1ms/step - loss: 1.7147\n16/16 [==============================] - 0s 894us/step - loss: 1.7329\n16/16 [==============================] - 0s 2ms/step - loss: 1.7359\n16/16 [==============================] - 0s 896us/step - loss: 1.7360\n16/16 [==============================] - 0s 1ms/step - loss: 1.7355\n16/16 [==============================] - 0s 2ms/step - loss: 1.7350\n\nTesting for epoch 43 index 2:\n32/32 [==============================] - 0s 551us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2985\n16/16 [==============================] - 0s 2ms/step - loss: 0.7894\n16/16 [==============================] - 0s 2ms/step - loss: 1.3189\n16/16 [==============================] - 0s 2ms/step - loss: 1.6614\n16/16 [==============================] - 0s 803us/step - loss: 1.7256\n16/16 [==============================] - 0s 2ms/step - loss: 1.7439\n16/16 [==============================] - 0s 2ms/step - loss: 1.7470\n16/16 [==============================] - 0s 2ms/step - loss: 1.7471\n16/16 [==============================] - 0s 2ms/step - loss: 1.7465\n16/16 [==============================] - 0s 2ms/step - loss: 1.7460\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2929\n16/16 [==============================] - 0s 773us/step - loss: 0.7969\n16/16 [==============================] - 0s 1ms/step - loss: 1.3407\n16/16 [==============================] - 0s 2ms/step - loss: 1.6916\n16/16 [==============================] - 0s 2ms/step - loss: 1.7567\n16/16 [==============================] - 0s 819us/step - loss: 1.7749\n16/16 [==============================] - 0s 2ms/step - loss: 1.7779\n16/16 [==============================] - 0s 2ms/step - loss: 1.7780\n16/16 [==============================] - 0s 2ms/step - loss: 1.7775\n16/16 [==============================] - 0s 2ms/step - loss: 1.7769\n\nTesting for epoch 44 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 796us/step - loss: 0.2909\n16/16 [==============================] - 0s 772us/step - loss: 0.7933\n16/16 [==============================] - 0s 823us/step - loss: 1.3388\n16/16 [==============================] - 0s 2ms/step - loss: 1.6890\n16/16 [==============================] - 0s 951us/step - loss: 1.7538\n16/16 [==============================] - 0s 831us/step - loss: 1.7717\n16/16 [==============================] - 0s 1ms/step - loss: 1.7746\n16/16 [==============================] - 0s 2ms/step - loss: 1.7747\n16/16 [==============================] - 0s 796us/step - loss: 1.7741\n16/16 [==============================] - 0s 2ms/step - loss: 1.7736\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 791us/step - loss: 0.2946\n16/16 [==============================] - 0s 786us/step - loss: 0.7951\n16/16 [==============================] - 0s 823us/step - loss: 1.3410\n16/16 [==============================] - 0s 1ms/step - loss: 1.6875\n16/16 [==============================] - 0s 1ms/step - loss: 1.7506\n16/16 [==============================] - 0s 812us/step - loss: 1.7678\n16/16 [==============================] - 0s 1ms/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.7705\n16/16 [==============================] - 0s 1ms/step - loss: 1.7700\n16/16 [==============================] - 0s 2ms/step - loss: 1.7694\n\nTesting for epoch 45 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2911\n16/16 [==============================] - 0s 789us/step - loss: 0.7943\n16/16 [==============================] - 0s 817us/step - loss: 1.3485\n16/16 [==============================] - 0s 2ms/step - loss: 1.6968\n16/16 [==============================] - 0s 934us/step - loss: 1.7600\n16/16 [==============================] - 0s 2ms/step - loss: 1.7771\n16/16 [==============================] - 0s 816us/step - loss: 1.7797\n16/16 [==============================] - 0s 807us/step - loss: 1.7796\n16/16 [==============================] - 0s 820us/step - loss: 1.7791\n16/16 [==============================] - 0s 932us/step - loss: 1.7785\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 804us/step - loss: 0.2932\n16/16 [==============================] - 0s 2ms/step - loss: 0.7938\n16/16 [==============================] - 0s 2ms/step - loss: 1.3487\n16/16 [==============================] - 0s 942us/step - loss: 1.6919\n16/16 [==============================] - 0s 984us/step - loss: 1.7534\n16/16 [==============================] - 0s 828us/step - loss: 1.7699\n16/16 [==============================] - 0s 2ms/step - loss: 1.7723\n16/16 [==============================] - 0s 839us/step - loss: 1.7722\n16/16 [==============================] - 0s 801us/step - loss: 1.7717\n16/16 [==============================] - 0s 796us/step - loss: 1.7711\n\nTesting for epoch 46 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 805us/step - loss: 0.2842\n16/16 [==============================] - 0s 2ms/step - loss: 0.8012\n16/16 [==============================] - 0s 2ms/step - loss: 1.3785\n16/16 [==============================] - 0s 809us/step - loss: 1.7329\n16/16 [==============================] - 0s 853us/step - loss: 1.7961\n16/16 [==============================] - 0s 2ms/step - loss: 1.8129\n16/16 [==============================] - 0s 812us/step - loss: 1.8153\n16/16 [==============================] - 0s 1ms/step - loss: 1.8152\n16/16 [==============================] - 0s 760us/step - loss: 1.8146\n16/16 [==============================] - 0s 794us/step - loss: 1.8141\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 831us/step - loss: 0.2767\n16/16 [==============================] - 0s 805us/step - loss: 0.8072\n16/16 [==============================] - 0s 1ms/step - loss: 1.4037\n16/16 [==============================] - 0s 869us/step - loss: 1.7654\n16/16 [==============================] - 0s 843us/step - loss: 1.8289\n16/16 [==============================] - 0s 814us/step - loss: 1.8455\n16/16 [==============================] - 0s 837us/step - loss: 1.8479\n16/16 [==============================] - 0s 827us/step - loss: 1.8477\n16/16 [==============================] - 0s 2ms/step - loss: 1.8471\n16/16 [==============================] - 0s 2ms/step - loss: 1.8466\n\nTesting for epoch 47 index 2:\n32/32 [==============================] - 0s 582us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2830\n16/16 [==============================] - 0s 2ms/step - loss: 0.8001\n16/16 [==============================] - 0s 2ms/step - loss: 1.3796\n16/16 [==============================] - 0s 799us/step - loss: 1.7297\n16/16 [==============================] - 0s 822us/step - loss: 1.7904\n16/16 [==============================] - 0s 2ms/step - loss: 1.8061\n16/16 [==============================] - 0s 830us/step - loss: 1.8082\n16/16 [==============================] - 0s 2ms/step - loss: 1.8080\n16/16 [==============================] - 0s 805us/step - loss: 1.8074\n16/16 [==============================] - 0s 842us/step - loss: 1.8069\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n32/32 [==============================] - 0s 671us/step\n16/16 [==============================] - 0s 763us/step - loss: 0.2810\n16/16 [==============================] - 0s 786us/step - loss: 0.8040\n16/16 [==============================] - 0s 770us/step - loss: 1.3884\n16/16 [==============================] - 0s 764us/step - loss: 1.7378\n16/16 [==============================] - 0s 757us/step - loss: 1.7973\n16/16 [==============================] - 0s 769us/step - loss: 1.8124\n16/16 [==============================] - 0s 773us/step - loss: 1.8144\n16/16 [==============================] - 0s 1ms/step - loss: 1.8141\n16/16 [==============================] - 0s 1ms/step - loss: 1.8134\n16/16 [==============================] - 0s 1ms/step - loss: 1.8129\n\nTesting for epoch 48 index 2:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2789\n16/16 [==============================] - 0s 783us/step - loss: 0.8059\n16/16 [==============================] - 0s 779us/step - loss: 1.3913\n16/16 [==============================] - 0s 762us/step - loss: 1.7401\n16/16 [==============================] - 0s 762us/step - loss: 1.7989\n16/16 [==============================] - 0s 846us/step - loss: 1.8136\n16/16 [==============================] - 0s 857us/step - loss: 1.8155\n16/16 [==============================] - 0s 839us/step - loss: 1.8151\n16/16 [==============================] - 0s 860us/step - loss: 1.8145\n16/16 [==============================] - 0s 877us/step - loss: 1.8139\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2754\n16/16 [==============================] - 0s 800us/step - loss: 0.8119\n16/16 [==============================] - 0s 791us/step - loss: 1.4077\n16/16 [==============================] - 0s 786us/step - loss: 1.7589\n16/16 [==============================] - 0s 1ms/step - loss: 1.8171\n16/16 [==============================] - 0s 801us/step - loss: 1.8315\n16/16 [==============================] - 0s 886us/step - loss: 1.8332\n16/16 [==============================] - 0s 1ms/step - loss: 1.8328\n16/16 [==============================] - 0s 875us/step - loss: 1.8322\n16/16 [==============================] - 0s 861us/step - loss: 1.8316\n\nTesting for epoch 49 index 2:\n32/32 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.2707\n16/16 [==============================] - 0s 784us/step - loss: 0.8127\n16/16 [==============================] - 0s 817us/step - loss: 1.4127\n16/16 [==============================] - 0s 815us/step - loss: 1.7644\n16/16 [==============================] - 0s 792us/step - loss: 1.8221\n16/16 [==============================] - 0s 817us/step - loss: 1.8361\n16/16 [==============================] - 0s 800us/step - loss: 1.8377\n16/16 [==============================] - 0s 800us/step - loss: 1.8373\n16/16 [==============================] - 0s 812us/step - loss: 1.8366\n16/16 [==============================] - 0s 856us/step - loss: 1.8360\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n32/32 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.2747\n16/16 [==============================] - 0s 783us/step - loss: 0.8236\n16/16 [==============================] - 0s 793us/step - loss: 1.4341\n16/16 [==============================] - 0s 1ms/step - loss: 1.7868\n16/16 [==============================] - 0s 904us/step - loss: 1.8438\n16/16 [==============================] - 0s 877us/step - loss: 1.8574\n16/16 [==============================] - 0s 811us/step - loss: 1.8589\n16/16 [==============================] - 0s 807us/step - loss: 1.8584\n16/16 [==============================] - 0s 791us/step - loss: 1.8578\n16/16 [==============================] - 0s 820us/step - loss: 1.8572\n\nTesting for epoch 50 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2854\n16/16 [==============================] - 0s 818us/step - loss: 0.8126\n16/16 [==============================] - 0s 790us/step - loss: 1.3992\n16/16 [==============================] - 0s 837us/step - loss: 1.7342\n16/16 [==============================] - 0s 789us/step - loss: 1.7876\n16/16 [==============================] - 0s 781us/step - loss: 1.8000\n16/16 [==============================] - 0s 785us/step - loss: 1.8013\n16/16 [==============================] - 0s 779us/step - loss: 1.8007\n16/16 [==============================] - 0s 781us/step - loss: 1.8000\n16/16 [==============================] - 0s 806us/step - loss: 1.7995\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n32/32 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.2657\n16/16 [==============================] - 0s 813us/step - loss: 0.8298\n16/16 [==============================] - 0s 787us/step - loss: 1.4637\n16/16 [==============================] - 0s 791us/step - loss: 1.8214\n16/16 [==============================] - 0s 790us/step - loss: 1.8778\n16/16 [==============================] - 0s 780us/step - loss: 1.8907\n16/16 [==============================] - 0s 803us/step - loss: 1.8920\n16/16 [==============================] - 0s 817us/step - loss: 1.8915\n16/16 [==============================] - 0s 779us/step - loss: 1.8908\n16/16 [==============================] - 0s 777us/step - loss: 1.8902\n\nTesting for epoch 51 index 2:\n32/32 [==============================] - 0s 594us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.2715\n16/16 [==============================] - 0s 1ms/step - loss: 0.8213\n16/16 [==============================] - 0s 1ms/step - loss: 1.4421\n16/16 [==============================] - 0s 1ms/step - loss: 1.7886\n16/16 [==============================] - 0s 1ms/step - loss: 1.8427\n16/16 [==============================] - 0s 787us/step - loss: 1.8549\n16/16 [==============================] - 0s 1ms/step - loss: 1.8561\n16/16 [==============================] - 0s 1ms/step - loss: 1.8555\n16/16 [==============================] - 0s 1ms/step - loss: 1.8549\n16/16 [==============================] - 0s 796us/step - loss: 1.8543\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.2673\n16/16 [==============================] - 0s 799us/step - loss: 0.8241\n16/16 [==============================] - 0s 780us/step - loss: 1.4541\n16/16 [==============================] - 0s 796us/step - loss: 1.8011\n16/16 [==============================] - 0s 811us/step - loss: 1.8543\n16/16 [==============================] - 0s 779us/step - loss: 1.8660\n16/16 [==============================] - 0s 791us/step - loss: 1.8671\n16/16 [==============================] - 0s 771us/step - loss: 1.8665\n16/16 [==============================] - 0s 823us/step - loss: 1.8658\n16/16 [==============================] - 0s 774us/step - loss: 1.8652\n\nTesting for epoch 52 index 2:\n32/32 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.2792\n16/16 [==============================] - 0s 780us/step - loss: 0.8209\n16/16 [==============================] - 0s 825us/step - loss: 1.4352\n16/16 [==============================] - 0s 812us/step - loss: 1.7676\n16/16 [==============================] - 0s 821us/step - loss: 1.8181\n16/16 [==============================] - 0s 814us/step - loss: 1.8289\n16/16 [==============================] - 0s 1ms/step - loss: 1.8298\n16/16 [==============================] - 0s 1ms/step - loss: 1.8291\n16/16 [==============================] - 0s 802us/step - loss: 1.8284\n16/16 [==============================] - 0s 797us/step - loss: 1.8278\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n32/32 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 859us/step - loss: 0.2657\n16/16 [==============================] - 0s 817us/step - loss: 0.8274\n16/16 [==============================] - 0s 799us/step - loss: 1.4711\n16/16 [==============================] - 0s 898us/step - loss: 1.8159\n16/16 [==============================] - 0s 791us/step - loss: 1.8675\n16/16 [==============================] - 0s 821us/step - loss: 1.8786\n16/16 [==============================] - 0s 802us/step - loss: 1.8795\n16/16 [==============================] - 0s 823us/step - loss: 1.8789\n16/16 [==============================] - 0s 779us/step - loss: 1.8782\n16/16 [==============================] - 0s 797us/step - loss: 1.8776\n\nTesting for epoch 53 index 2:\n32/32 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.2711\n16/16 [==============================] - 0s 779us/step - loss: 0.8247\n16/16 [==============================] - 0s 798us/step - loss: 1.4613\n16/16 [==============================] - 0s 772us/step - loss: 1.7968\n16/16 [==============================] - 0s 780us/step - loss: 1.8466\n16/16 [==============================] - 0s 797us/step - loss: 1.8571\n16/16 [==============================] - 0s 811us/step - loss: 1.8579\n16/16 [==============================] - 0s 801us/step - loss: 1.8572\n16/16 [==============================] - 0s 776us/step - loss: 1.8565\n16/16 [==============================] - 0s 774us/step - loss: 1.8559\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n32/32 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2669\n16/16 [==============================] - 0s 830us/step - loss: 0.8337\n16/16 [==============================] - 0s 782us/step - loss: 1.4889\n16/16 [==============================] - 0s 901us/step - loss: 1.8301\n16/16 [==============================] - 0s 812us/step - loss: 1.8797\n16/16 [==============================] - 0s 816us/step - loss: 1.8901\n16/16 [==============================] - 0s 775us/step - loss: 1.8908\n16/16 [==============================] - 0s 778us/step - loss: 1.8901\n16/16 [==============================] - 0s 797us/step - loss: 1.8894\n16/16 [==============================] - 0s 784us/step - loss: 1.8888\n\nTesting for epoch 54 index 2:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 811us/step - loss: 0.2687\n16/16 [==============================] - 0s 800us/step - loss: 0.8254\n16/16 [==============================] - 0s 794us/step - loss: 1.4729\n16/16 [==============================] - 0s 777us/step - loss: 1.8040\n16/16 [==============================] - 0s 775us/step - loss: 1.8518\n16/16 [==============================] - 0s 790us/step - loss: 1.8616\n16/16 [==============================] - 0s 806us/step - loss: 1.8622\n16/16 [==============================] - 0s 781us/step - loss: 1.8615\n16/16 [==============================] - 0s 804us/step - loss: 1.8608\n16/16 [==============================] - 0s 782us/step - loss: 1.8602\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n32/32 [==============================] - 0s 848us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2630\n16/16 [==============================] - 0s 1ms/step - loss: 0.8345\n16/16 [==============================] - 0s 1ms/step - loss: 1.5023\n16/16 [==============================] - 0s 1ms/step - loss: 1.8396\n16/16 [==============================] - 0s 1ms/step - loss: 1.8872\n16/16 [==============================] - 0s 769us/step - loss: 1.8970\n16/16 [==============================] - 0s 822us/step - loss: 1.8976\n16/16 [==============================] - 0s 778us/step - loss: 1.8968\n16/16 [==============================] - 0s 778us/step - loss: 1.8961\n16/16 [==============================] - 0s 804us/step - loss: 1.8955\n\nTesting for epoch 55 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.2649\n16/16 [==============================] - 0s 825us/step - loss: 0.8307\n16/16 [==============================] - 0s 785us/step - loss: 1.4969\n16/16 [==============================] - 0s 799us/step - loss: 1.8271\n16/16 [==============================] - 0s 800us/step - loss: 1.8735\n16/16 [==============================] - 0s 1ms/step - loss: 1.8829\n16/16 [==============================] - 0s 1ms/step - loss: 1.8834\n16/16 [==============================] - 0s 1ms/step - loss: 1.8826\n16/16 [==============================] - 0s 1ms/step - loss: 1.8818\n16/16 [==============================] - 0s 1ms/step - loss: 1.8813\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n32/32 [==============================] - 0s 845us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2646\n16/16 [==============================] - 0s 1ms/step - loss: 0.8302\n16/16 [==============================] - 0s 1ms/step - loss: 1.4973\n16/16 [==============================] - 0s 780us/step - loss: 1.8229\n16/16 [==============================] - 0s 773us/step - loss: 1.8679\n16/16 [==============================] - 0s 794us/step - loss: 1.8768\n16/16 [==============================] - 0s 1ms/step - loss: 1.8772\n16/16 [==============================] - 0s 1ms/step - loss: 1.8763\n16/16 [==============================] - 0s 804us/step - loss: 1.8756\n16/16 [==============================] - 0s 806us/step - loss: 1.8750\n\nTesting for epoch 56 index 2:\n32/32 [==============================] - 0s 843us/step\n16/16 [==============================] - 0s 844us/step - loss: 0.2654\n16/16 [==============================] - 0s 777us/step - loss: 0.8271\n16/16 [==============================] - 0s 797us/step - loss: 1.4953\n16/16 [==============================] - 0s 781us/step - loss: 1.8151\n16/16 [==============================] - 0s 797us/step - loss: 1.8594\n16/16 [==============================] - 0s 774us/step - loss: 1.8680\n16/16 [==============================] - 0s 811us/step - loss: 1.8683\n16/16 [==============================] - 0s 808us/step - loss: 1.8674\n16/16 [==============================] - 0s 782us/step - loss: 1.8667\n16/16 [==============================] - 0s 785us/step - loss: 1.8661\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n32/32 [==============================] - 0s 626us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.2603\n16/16 [==============================] - 0s 797us/step - loss: 0.8334\n16/16 [==============================] - 0s 781us/step - loss: 1.5190\n16/16 [==============================] - 0s 775us/step - loss: 1.8422\n16/16 [==============================] - 0s 772us/step - loss: 1.8866\n16/16 [==============================] - 0s 819us/step - loss: 1.8950\n16/16 [==============================] - 0s 814us/step - loss: 1.8952\n16/16 [==============================] - 0s 790us/step - loss: 1.8943\n16/16 [==============================] - 0s 798us/step - loss: 1.8935\n16/16 [==============================] - 0s 802us/step - loss: 1.8930\n\nTesting for epoch 57 index 2:\n32/32 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.2586\n16/16 [==============================] - 0s 775us/step - loss: 0.8385\n16/16 [==============================] - 0s 784us/step - loss: 1.5405\n16/16 [==============================] - 0s 786us/step - loss: 1.8654\n16/16 [==============================] - 0s 784us/step - loss: 1.9105\n16/16 [==============================] - 0s 787us/step - loss: 1.9188\n16/16 [==============================] - 0s 787us/step - loss: 1.9191\n16/16 [==============================] - 0s 825us/step - loss: 1.9182\n16/16 [==============================] - 0s 796us/step - loss: 1.9175\n16/16 [==============================] - 0s 790us/step - loss: 1.9169\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n32/32 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2664\n16/16 [==============================] - 0s 887us/step - loss: 0.8317\n16/16 [==============================] - 0s 789us/step - loss: 1.5162\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 807us/step - loss: 1.8701\n16/16 [==============================] - 0s 780us/step - loss: 1.8777\n16/16 [==============================] - 0s 782us/step - loss: 1.8779\n16/16 [==============================] - 0s 782us/step - loss: 1.8769\n16/16 [==============================] - 0s 778us/step - loss: 1.8762\n16/16 [==============================] - 0s 801us/step - loss: 1.8756\n\nTesting for epoch 58 index 2:\n32/32 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.2565\n16/16 [==============================] - 0s 790us/step - loss: 0.8364\n16/16 [==============================] - 0s 832us/step - loss: 1.5469\n16/16 [==============================] - 0s 782us/step - loss: 1.8653\n16/16 [==============================] - 0s 796us/step - loss: 1.9092\n16/16 [==============================] - 0s 783us/step - loss: 1.9169\n16/16 [==============================] - 0s 790us/step - loss: 1.9171\n16/16 [==============================] - 0s 785us/step - loss: 1.9162\n16/16 [==============================] - 0s 799us/step - loss: 1.9154\n16/16 [==============================] - 0s 822us/step - loss: 1.9149\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n32/32 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 843us/step - loss: 0.2551\n16/16 [==============================] - 0s 823us/step - loss: 0.8408\n16/16 [==============================] - 0s 1ms/step - loss: 1.5610\n16/16 [==============================] - 0s 804us/step - loss: 1.8795\n16/16 [==============================] - 0s 1ms/step - loss: 1.9230\n16/16 [==============================] - 0s 832us/step - loss: 1.9304\n16/16 [==============================] - 0s 1ms/step - loss: 1.9306\n16/16 [==============================] - 0s 1ms/step - loss: 1.9296\n16/16 [==============================] - 0s 875us/step - loss: 1.9289\n16/16 [==============================] - 0s 825us/step - loss: 1.9283\n\nTesting for epoch 59 index 2:\n32/32 [==============================] - 0s 794us/step\n16/16 [==============================] - 0s 827us/step - loss: 0.2557\n16/16 [==============================] - 0s 812us/step - loss: 0.8404\n16/16 [==============================] - 0s 1ms/step - loss: 1.5661\n16/16 [==============================] - 0s 1ms/step - loss: 1.8818\n16/16 [==============================] - 0s 1ms/step - loss: 1.9253\n16/16 [==============================] - 0s 1ms/step - loss: 1.9326\n16/16 [==============================] - 0s 820us/step - loss: 1.9327\n16/16 [==============================] - 0s 1ms/step - loss: 1.9318\n16/16 [==============================] - 0s 1ms/step - loss: 1.9311\n16/16 [==============================] - 0s 1ms/step - loss: 1.9305\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2626\n16/16 [==============================] - 0s 1ms/step - loss: 0.8359\n16/16 [==============================] - 0s 1ms/step - loss: 1.5479\n16/16 [==============================] - 0s 1ms/step - loss: 1.8518\n16/16 [==============================] - 0s 1ms/step - loss: 1.8930\n16/16 [==============================] - 0s 1ms/step - loss: 1.8996\n16/16 [==============================] - 0s 853us/step - loss: 1.8996\n16/16 [==============================] - 0s 825us/step - loss: 1.8986\n16/16 [==============================] - 0s 819us/step - loss: 1.8979\n16/16 [==============================] - 0s 857us/step - loss: 1.8973\n\nTesting for epoch 60 index 2:\n32/32 [==============================] - 0s 645us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.2643\n16/16 [==============================] - 0s 836us/step - loss: 0.8245\n16/16 [==============================] - 0s 851us/step - loss: 1.5218\n16/16 [==============================] - 0s 854us/step - loss: 1.8173\n16/16 [==============================] - 0s 807us/step - loss: 1.8571\n16/16 [==============================] - 0s 829us/step - loss: 1.8634\n16/16 [==============================] - 0s 803us/step - loss: 1.8633\n16/16 [==============================] - 0s 814us/step - loss: 1.8623\n16/16 [==============================] - 0s 811us/step - loss: 1.8615\n16/16 [==============================] - 0s 828us/step - loss: 1.8609\n32/32 [==============================] - 0s 634us/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.965\nRecall: 0.972\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntherteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  therteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\\(\\star\\)\ndefault=10%\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = therteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = therteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#linear-result",
    "title": "Other Outlier Detection",
    "section": "Linear Result",
    "text": "Linear Result\n\\(U^\\star\\), which is a mixture of uniform distributions \\(U(5,7)\\) and \\(U(-7,-5)\\).\n\nfourteen\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.998\n      0.998947\n      0.998947\n      0.998947\n    \n    \n      LOF (Breunig et al., 2000)\n      0.926\n      0.961053\n      0.961053\n      0.961053\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.950\n      1.000000\n      0.947368\n      0.972973\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.935\n      0.991121\n      0.940000\n      0.964884\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.998\n      0.998947\n      0.998947\n      0.998947\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.986\n      0.992632\n      0.992632\n      0.992632\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.993684\n      0.993684\n      0.993684\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.868\n      0.998780\n      0.862105\n      0.925424\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.960\n      0.977941\n      0.980000\n      0.978970\n    \n    \n      SOS (Janssens et al., 2012)\n      0.916\n      0.955789\n      0.955789\n      0.955789\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.936\n      0.966316\n      0.966316\n      0.966316\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.940\n      0.965481\n      0.971579\n      0.968520\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.988\n      0.993684\n      0.993684\n      0.993684"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-ebayesthresh",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-ebayesthresh",
    "title": "Other Outlier Detection",
    "section": "Orbit EbayesThresh",
    "text": "Orbit EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier = which(signal!=0)\nindex_of_trueoutlier\nx=signal+epsilon\nplot(1:1000,x)\npoints(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)\n\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\n\n\n\n%R -o x\n%R -o index_of_trueoutlier\n%R -o signal\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n# plt.plot(x)\n# plt.plot(xhat)\n\n\noutlier_true_index = index_of_trueoutlier\n\n\noutlier_true_value = x[index_of_trueoutlier]\n\npackageì™€ ë¹„êµë¥¼ ìœ„í•´ outlierëŠ” -1, inlierëŠ” 1ë¡œ í‘œì‹œ\n\noutlier_true_one = signal.copy()\n\n\noutlier_true_one = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one))\n\n\n# pd.DataFrame(outlier_true_one).to_csv('orbit_outlier.csv')"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit",
    "title": "Other Outlier Detection",
    "section": "Orbit",
    "text": "Orbit\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\n_df = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f})\n\n\nX = np.array(_df)\n\n\n# save_data(_df,'Orbit.pkl')\n\n\nGODE\n\n_Orbit = Orbit(_df)\n\n\n_Orbit.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 340.03it/s]\n\n\n\n_Orbit.get_weightmatrix(theta=(_Orbit.D[_Orbit.D>0].mean()),kappa=2500) \n\n\n_Orbit.fit(sd=15,ref=20)\n\n\noutlier_simul_one = (_Orbit.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 13 else 1,outlier_simul_one))\n\n\noutlier_simul_one.count(1)\n\n950\n\n\n\noutlier_simul_one.count(-1)\n\n50\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF\\(\\star\\)\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.954\nPrecision: 0.976\nRecall: 0.976\nF1 Score: 0.976\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','f']])\n_df['knn_clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF\n\nimport pickle\n\n\n_df = load_data('Orbit.pkl')\n\n\noutlier_true_one = pd.read_csv('orbit_outlier.csv').iloc[:,1].tolist()\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\noutlier_CBLOF_one = list(clf.labels_)\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n_conf = Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n# four = three.append(_conf.tab)\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.05, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.05, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.908\nPrecision: 0.977\nRecall: 0.925\nF1 Score: 0.950\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\\(\\star\\)\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.916\nPrecision: 0.956\nRecall: 0.956\nF1 Score: 0.956\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\\(\\star\\)\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.942\nPrecision: 0.969\nRecall: 0.969\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\\(\\star\\)\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\n\n\nIForest\\(\\star\\)\n\nod = IForest(\n    threshold=0.,\n    n_estimators=50\n)\n\n\nod.fit(_df[['x', 'y','f']])\n\n\npreds = od.predict(\n    _df[['x', 'y','f']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.443\nPrecision: 0.992\nRecall: 0.417\nF1 Score: 0.587\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\\(\\star\\)\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.960\nRecall: 0.973\nF1 Score: 0.966\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\\(\\star\\)\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.974\nRecall: 0.974\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\\(\\star\\)\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 969us/step - loss: 1.3463\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3506\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3586\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3721\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.3866\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3800\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4006\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4023\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4122\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.4314\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4473\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.4588\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4734\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.4913\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5128\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5221\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5512\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5569\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5717\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.5833\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5991\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6237\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.6486\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6528\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6775\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6728\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7114\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7382\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7361\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7442\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7632\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7813\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.7997\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8135\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8074\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8185\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8404\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 4ms/step - loss: 1.8432\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8590\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8644\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8872\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9012\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 1.9049\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9139\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9184\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 1.9365\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9581\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9824\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9639\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0122\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0024\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0080\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.0230\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0424\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0419\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0648\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0705\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0983\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1023\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1145\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1403\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1403\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1572\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1621\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1594\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1776\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1913\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2041\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2355\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2292\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2431\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2475\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2408\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2696\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2748\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3000\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3168\n32/32 [==============================] - 0s 2ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\\(\\star\\)\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 5 index 2:\n32/32 [==============================] - 0s 3ms/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 10 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n32/32 [==============================] - 0s 3ms/step\n\nTesting for epoch 12 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 13 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n32/32 [==============================] - 0s 2ms/step\n\nTesting for epoch 14 index 2:\n32/32 [==============================] - 0s 1ms/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 2:\n32/32 [==============================] - 0s 992us/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n32/32 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 2:\n32/32 [==============================] - 0s 782us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n32/32 [==============================] - 0s 680us/step\n\nTesting for epoch 18 index 2:\n32/32 [==============================] - 0s 801us/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n32/32 [==============================] - 0s 642us/step\n\nTesting for epoch 19 index 2:\n32/32 [==============================] - 0s 617us/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n32/32 [==============================] - 0s 801us/step\n\nTesting for epoch 20 index 2:\n32/32 [==============================] - 0s 2ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n32/32 [==============================] - 0s 894us/step\n\nTesting for epoch 21 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4662\n16/16 [==============================] - 0s 1ms/step - loss: 1.1250\n16/16 [==============================] - 0s 1ms/step - loss: 1.1652\n16/16 [==============================] - 0s 1ms/step - loss: 1.1668\n16/16 [==============================] - 0s 997us/step - loss: 1.1673\n16/16 [==============================] - 0s 965us/step - loss: 1.1677\n16/16 [==============================] - 0s 1ms/step - loss: 1.1681\n16/16 [==============================] - 0s 1ms/step - loss: 1.1688\n16/16 [==============================] - 0s 971us/step - loss: 1.1690\n16/16 [==============================] - 0s 2ms/step - loss: 1.1690\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n32/32 [==============================] - 0s 858us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4861\n16/16 [==============================] - 0s 2ms/step - loss: 1.1078\n16/16 [==============================] - 0s 1ms/step - loss: 1.1395\n16/16 [==============================] - 0s 1ms/step - loss: 1.1408\n16/16 [==============================] - 0s 1ms/step - loss: 1.1412\n16/16 [==============================] - 0s 1ms/step - loss: 1.1417\n16/16 [==============================] - 0s 2ms/step - loss: 1.1423\n16/16 [==============================] - 0s 2ms/step - loss: 1.1430\n16/16 [==============================] - 0s 1ms/step - loss: 1.1433\n16/16 [==============================] - 0s 1ms/step - loss: 1.1433\n\nTesting for epoch 22 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4978\n16/16 [==============================] - 0s 2ms/step - loss: 1.1226\n16/16 [==============================] - 0s 1ms/step - loss: 1.1496\n16/16 [==============================] - 0s 2ms/step - loss: 1.1507\n16/16 [==============================] - 0s 1ms/step - loss: 1.1512\n16/16 [==============================] - 0s 4ms/step - loss: 1.1516\n16/16 [==============================] - 0s 3ms/step - loss: 1.1520\n16/16 [==============================] - 0s 2ms/step - loss: 1.1527\n16/16 [==============================] - 0s 2ms/step - loss: 1.1529\n16/16 [==============================] - 0s 1ms/step - loss: 1.1529\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n32/32 [==============================] - 0s 900us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5048\n16/16 [==============================] - 0s 1ms/step - loss: 1.1336\n16/16 [==============================] - 0s 2ms/step - loss: 1.1607\n16/16 [==============================] - 0s 1ms/step - loss: 1.1618\n16/16 [==============================] - 0s 2ms/step - loss: 1.1622\n16/16 [==============================] - 0s 4ms/step - loss: 1.1625\n16/16 [==============================] - 0s 2ms/step - loss: 1.1630\n16/16 [==============================] - 0s 1ms/step - loss: 1.1636\n16/16 [==============================] - 0s 1ms/step - loss: 1.1638\n16/16 [==============================] - 0s 2ms/step - loss: 1.1638\n\nTesting for epoch 23 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5183\n16/16 [==============================] - 0s 2ms/step - loss: 1.1345\n16/16 [==============================] - 0s 2ms/step - loss: 1.1583\n16/16 [==============================] - 0s 2ms/step - loss: 1.1593\n16/16 [==============================] - 0s 2ms/step - loss: 1.1597\n16/16 [==============================] - 0s 2ms/step - loss: 1.1601\n16/16 [==============================] - 0s 1ms/step - loss: 1.1606\n16/16 [==============================] - 0s 1ms/step - loss: 1.1612\n16/16 [==============================] - 0s 2ms/step - loss: 1.1614\n16/16 [==============================] - 0s 2ms/step - loss: 1.1614\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5228\n16/16 [==============================] - 0s 1ms/step - loss: 1.1392\n16/16 [==============================] - 0s 1ms/step - loss: 1.1615\n16/16 [==============================] - 0s 977us/step - loss: 1.1623\n16/16 [==============================] - 0s 1ms/step - loss: 1.1628\n16/16 [==============================] - 0s 1ms/step - loss: 1.1633\n16/16 [==============================] - 0s 1ms/step - loss: 1.1639\n16/16 [==============================] - 0s 2ms/step - loss: 1.1646\n16/16 [==============================] - 0s 1ms/step - loss: 1.1649\n16/16 [==============================] - 0s 1ms/step - loss: 1.1649\n\nTesting for epoch 24 index 2:\n32/32 [==============================] - 0s 848us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5259\n16/16 [==============================] - 0s 1ms/step - loss: 1.1609\n16/16 [==============================] - 0s 1ms/step - loss: 1.1832\n16/16 [==============================] - 0s 1ms/step - loss: 1.1841\n16/16 [==============================] - 0s 2ms/step - loss: 1.1845\n16/16 [==============================] - 0s 2ms/step - loss: 1.1848\n16/16 [==============================] - 0s 2ms/step - loss: 1.1853\n16/16 [==============================] - 0s 2ms/step - loss: 1.1859\n16/16 [==============================] - 0s 2ms/step - loss: 1.1861\n16/16 [==============================] - 0s 2ms/step - loss: 1.1861\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5249\n16/16 [==============================] - 0s 2ms/step - loss: 1.1680\n16/16 [==============================] - 0s 2ms/step - loss: 1.1921\n16/16 [==============================] - 0s 1ms/step - loss: 1.1930\n16/16 [==============================] - 0s 1ms/step - loss: 1.1933\n16/16 [==============================] - 0s 1ms/step - loss: 1.1937\n16/16 [==============================] - 0s 959us/step - loss: 1.1941\n16/16 [==============================] - 0s 3ms/step - loss: 1.1947\n16/16 [==============================] - 0s 1ms/step - loss: 1.1949\n16/16 [==============================] - 0s 1ms/step - loss: 1.1949\n\nTesting for epoch 25 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5256\n16/16 [==============================] - 0s 4ms/step - loss: 1.1816\n16/16 [==============================] - 0s 1ms/step - loss: 1.2066\n16/16 [==============================] - 0s 1ms/step - loss: 1.2075\n16/16 [==============================] - 0s 1ms/step - loss: 1.2079\n16/16 [==============================] - 0s 2ms/step - loss: 1.2082\n16/16 [==============================] - 0s 1ms/step - loss: 1.2087\n16/16 [==============================] - 0s 1ms/step - loss: 1.2092\n16/16 [==============================] - 0s 1ms/step - loss: 1.2095\n16/16 [==============================] - 0s 2ms/step - loss: 1.2095\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.1842\n16/16 [==============================] - 0s 1ms/step - loss: 1.2109\n16/16 [==============================] - 0s 2ms/step - loss: 1.2118\n16/16 [==============================] - 0s 2ms/step - loss: 1.2122\n16/16 [==============================] - 0s 1ms/step - loss: 1.2126\n16/16 [==============================] - 0s 1ms/step - loss: 1.2131\n16/16 [==============================] - 0s 4ms/step - loss: 1.2137\n16/16 [==============================] - 0s 2ms/step - loss: 1.2140\n16/16 [==============================] - 0s 878us/step - loss: 1.2140\n\nTesting for epoch 26 index 2:\n32/32 [==============================] - 0s 656us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.5174\n16/16 [==============================] - 0s 864us/step - loss: 1.1946\n16/16 [==============================] - 0s 732us/step - loss: 1.2231\n16/16 [==============================] - 0s 767us/step - loss: 1.2241\n16/16 [==============================] - 0s 810us/step - loss: 1.2245\n16/16 [==============================] - 0s 822us/step - loss: 1.2248\n16/16 [==============================] - 0s 808us/step - loss: 1.2252\n16/16 [==============================] - 0s 788us/step - loss: 1.2257\n16/16 [==============================] - 0s 821us/step - loss: 1.2259\n16/16 [==============================] - 0s 810us/step - loss: 1.2260\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n32/32 [==============================] - 0s 615us/step\n16/16 [==============================] - 0s 796us/step - loss: 0.5052\n16/16 [==============================] - 0s 812us/step - loss: 1.2202\n16/16 [==============================] - 0s 814us/step - loss: 1.2513\n16/16 [==============================] - 0s 778us/step - loss: 1.2525\n16/16 [==============================] - 0s 782us/step - loss: 1.2529\n16/16 [==============================] - 0s 804us/step - loss: 1.2532\n16/16 [==============================] - 0s 777us/step - loss: 1.2536\n16/16 [==============================] - 0s 785us/step - loss: 1.2541\n16/16 [==============================] - 0s 795us/step - loss: 1.2544\n16/16 [==============================] - 0s 797us/step - loss: 1.2544\n\nTesting for epoch 27 index 2:\n32/32 [==============================] - 0s 631us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.5002\n16/16 [==============================] - 0s 831us/step - loss: 1.2353\n16/16 [==============================] - 0s 827us/step - loss: 1.2665\n16/16 [==============================] - 0s 780us/step - loss: 1.2678\n16/16 [==============================] - 0s 798us/step - loss: 1.2682\n16/16 [==============================] - 0s 771us/step - loss: 1.2685\n16/16 [==============================] - 0s 778us/step - loss: 1.2690\n16/16 [==============================] - 0s 809us/step - loss: 1.2696\n16/16 [==============================] - 0s 818us/step - loss: 1.2698\n16/16 [==============================] - 0s 784us/step - loss: 1.2698\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n32/32 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.4877\n16/16 [==============================] - 0s 796us/step - loss: 1.2490\n16/16 [==============================] - 0s 816us/step - loss: 1.2845\n16/16 [==============================] - 0s 825us/step - loss: 1.2858\n16/16 [==============================] - 0s 782us/step - loss: 1.2862\n16/16 [==============================] - 0s 824us/step - loss: 1.2866\n16/16 [==============================] - 0s 812us/step - loss: 1.2870\n16/16 [==============================] - 0s 799us/step - loss: 1.2875\n16/16 [==============================] - 0s 792us/step - loss: 1.2877\n16/16 [==============================] - 0s 811us/step - loss: 1.2877\n\nTesting for epoch 28 index 2:\n32/32 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 782us/step - loss: 0.4795\n16/16 [==============================] - 0s 819us/step - loss: 1.2762\n16/16 [==============================] - 0s 807us/step - loss: 1.3130\n16/16 [==============================] - 0s 810us/step - loss: 1.3144\n16/16 [==============================] - 0s 812us/step - loss: 1.3148\n16/16 [==============================] - 0s 816us/step - loss: 1.3151\n16/16 [==============================] - 0s 774us/step - loss: 1.3156\n16/16 [==============================] - 0s 780us/step - loss: 1.3161\n16/16 [==============================] - 0s 805us/step - loss: 1.3163\n16/16 [==============================] - 0s 775us/step - loss: 1.3163\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n32/32 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.4700\n16/16 [==============================] - 0s 815us/step - loss: 1.2786\n16/16 [==============================] - 0s 795us/step - loss: 1.3164\n16/16 [==============================] - 0s 800us/step - loss: 1.3177\n16/16 [==============================] - 0s 781us/step - loss: 1.3182\n16/16 [==============================] - 0s 768us/step - loss: 1.3186\n16/16 [==============================] - 0s 775us/step - loss: 1.3191\n16/16 [==============================] - 0s 795us/step - loss: 1.3197\n16/16 [==============================] - 0s 799us/step - loss: 1.3199\n16/16 [==============================] - 0s 775us/step - loss: 1.3199\n\nTesting for epoch 29 index 2:\n32/32 [==============================] - 0s 611us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.4639\n16/16 [==============================] - 0s 816us/step - loss: 1.2951\n16/16 [==============================] - 0s 784us/step - loss: 1.3344\n16/16 [==============================] - 0s 821us/step - loss: 1.3358\n16/16 [==============================] - 0s 769us/step - loss: 1.3362\n16/16 [==============================] - 0s 798us/step - loss: 1.3366\n16/16 [==============================] - 0s 773us/step - loss: 1.3371\n16/16 [==============================] - 0s 781us/step - loss: 1.3376\n16/16 [==============================] - 0s 803us/step - loss: 1.3379\n16/16 [==============================] - 0s 795us/step - loss: 1.3379\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n32/32 [==============================] - 0s 629us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.4496\n16/16 [==============================] - 0s 777us/step - loss: 1.3229\n16/16 [==============================] - 0s 782us/step - loss: 1.3686\n16/16 [==============================] - 0s 793us/step - loss: 1.3703\n16/16 [==============================] - 0s 798us/step - loss: 1.3707\n16/16 [==============================] - 0s 792us/step - loss: 1.3710\n16/16 [==============================] - 0s 784us/step - loss: 1.3714\n16/16 [==============================] - 0s 780us/step - loss: 1.3719\n16/16 [==============================] - 0s 803us/step - loss: 1.3720\n16/16 [==============================] - 0s 773us/step - loss: 1.3721\n\nTesting for epoch 30 index 2:\n32/32 [==============================] - 0s 598us/step\n16/16 [==============================] - 0s 780us/step - loss: 0.4461\n16/16 [==============================] - 0s 772us/step - loss: 1.3343\n16/16 [==============================] - 0s 771us/step - loss: 1.3836\n16/16 [==============================] - 0s 777us/step - loss: 1.3853\n16/16 [==============================] - 0s 823us/step - loss: 1.3857\n16/16 [==============================] - 0s 797us/step - loss: 1.3861\n16/16 [==============================] - 0s 783us/step - loss: 1.3865\n16/16 [==============================] - 0s 770us/step - loss: 1.3870\n16/16 [==============================] - 0s 769us/step - loss: 1.3871\n16/16 [==============================] - 0s 791us/step - loss: 1.3872\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n32/32 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.4388\n16/16 [==============================] - 0s 803us/step - loss: 1.3348\n16/16 [==============================] - 0s 785us/step - loss: 1.3881\n16/16 [==============================] - 0s 795us/step - loss: 1.3898\n16/16 [==============================] - 0s 784us/step - loss: 1.3903\n16/16 [==============================] - 0s 814us/step - loss: 1.3906\n16/16 [==============================] - 0s 764us/step - loss: 1.3910\n16/16 [==============================] - 0s 769us/step - loss: 1.3915\n16/16 [==============================] - 0s 766us/step - loss: 1.3917\n16/16 [==============================] - 0s 770us/step - loss: 1.3917\n\nTesting for epoch 31 index 2:\n32/32 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.4335\n16/16 [==============================] - 0s 778us/step - loss: 1.3689\n16/16 [==============================] - 0s 776us/step - loss: 1.4249\n16/16 [==============================] - 0s 794us/step - loss: 1.4268\n16/16 [==============================] - 0s 773us/step - loss: 1.4272\n16/16 [==============================] - 0s 770us/step - loss: 1.4275\n16/16 [==============================] - 0s 770us/step - loss: 1.4279\n16/16 [==============================] - 0s 788us/step - loss: 1.4283\n16/16 [==============================] - 0s 792us/step - loss: 1.4285\n16/16 [==============================] - 0s 802us/step - loss: 1.4285\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n32/32 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.4265\n16/16 [==============================] - 0s 805us/step - loss: 1.3817\n16/16 [==============================] - 0s 815us/step - loss: 1.4402\n16/16 [==============================] - 0s 784us/step - loss: 1.4422\n16/16 [==============================] - 0s 785us/step - loss: 1.4426\n16/16 [==============================] - 0s 791us/step - loss: 1.4429\n16/16 [==============================] - 0s 811us/step - loss: 1.4432\n16/16 [==============================] - 0s 791us/step - loss: 1.4435\n16/16 [==============================] - 0s 809us/step - loss: 1.4437\n16/16 [==============================] - 0s 777us/step - loss: 1.4437\n\nTesting for epoch 32 index 2:\n32/32 [==============================] - 0s 622us/step\n16/16 [==============================] - 0s 819us/step - loss: 0.4303\n16/16 [==============================] - 0s 794us/step - loss: 1.3806\n16/16 [==============================] - 0s 809us/step - loss: 1.4368\n16/16 [==============================] - 0s 791us/step - loss: 1.4388\n16/16 [==============================] - 0s 781us/step - loss: 1.4392\n16/16 [==============================] - 0s 797us/step - loss: 1.4396\n16/16 [==============================] - 0s 784us/step - loss: 1.4399\n16/16 [==============================] - 0s 786us/step - loss: 1.4404\n16/16 [==============================] - 0s 808us/step - loss: 1.4406\n16/16 [==============================] - 0s 809us/step - loss: 1.4406\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.4255\n16/16 [==============================] - 0s 2ms/step - loss: 1.3957\n16/16 [==============================] - 0s 2ms/step - loss: 1.4540\n16/16 [==============================] - 0s 2ms/step - loss: 1.4562\n16/16 [==============================] - 0s 1ms/step - loss: 1.4566\n16/16 [==============================] - 0s 2ms/step - loss: 1.4569\n16/16 [==============================] - 0s 1ms/step - loss: 1.4573\n16/16 [==============================] - 0s 2ms/step - loss: 1.4577\n16/16 [==============================] - 0s 2ms/step - loss: 1.4579\n16/16 [==============================] - 0s 4ms/step - loss: 1.4579\n\nTesting for epoch 33 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4288\n16/16 [==============================] - 0s 1ms/step - loss: 1.4084\n16/16 [==============================] - 0s 1ms/step - loss: 1.4660\n16/16 [==============================] - 0s 1ms/step - loss: 1.4681\n16/16 [==============================] - 0s 2ms/step - loss: 1.4686\n16/16 [==============================] - 0s 2ms/step - loss: 1.4689\n16/16 [==============================] - 0s 1ms/step - loss: 1.4692\n16/16 [==============================] - 0s 1ms/step - loss: 1.4696\n16/16 [==============================] - 0s 1ms/step - loss: 1.4698\n16/16 [==============================] - 0s 1ms/step - loss: 1.4698\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4279\n16/16 [==============================] - 0s 1ms/step - loss: 1.4181\n16/16 [==============================] - 0s 1ms/step - loss: 1.4764\n16/16 [==============================] - 0s 5ms/step - loss: 1.4786\n16/16 [==============================] - 0s 4ms/step - loss: 1.4790\n16/16 [==============================] - 0s 2ms/step - loss: 1.4793\n16/16 [==============================] - 0s 2ms/step - loss: 1.4796\n16/16 [==============================] - 0s 1ms/step - loss: 1.4800\n16/16 [==============================] - 0s 1ms/step - loss: 1.4802\n16/16 [==============================] - 0s 1ms/step - loss: 1.4802\n\nTesting for epoch 34 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.4335\n16/16 [==============================] - 0s 1ms/step - loss: 1.4360\n16/16 [==============================] - 0s 2ms/step - loss: 1.4928\n16/16 [==============================] - 0s 3ms/step - loss: 1.4949\n16/16 [==============================] - 0s 1ms/step - loss: 1.4954\n16/16 [==============================] - 0s 1ms/step - loss: 1.4957\n16/16 [==============================] - 0s 938us/step - loss: 1.4960\n16/16 [==============================] - 0s 3ms/step - loss: 1.4964\n16/16 [==============================] - 0s 4ms/step - loss: 1.4966\n16/16 [==============================] - 0s 2ms/step - loss: 1.4966\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4357\n16/16 [==============================] - 0s 1ms/step - loss: 1.4423\n16/16 [==============================] - 0s 1ms/step - loss: 1.4991\n16/16 [==============================] - 0s 1ms/step - loss: 1.5013\n16/16 [==============================] - 0s 987us/step - loss: 1.5017\n16/16 [==============================] - 0s 2ms/step - loss: 1.5019\n16/16 [==============================] - 0s 2ms/step - loss: 1.5022\n16/16 [==============================] - 0s 1ms/step - loss: 1.5026\n16/16 [==============================] - 0s 1ms/step - loss: 1.5028\n16/16 [==============================] - 0s 2ms/step - loss: 1.5028\n\nTesting for epoch 35 index 2:\n32/32 [==============================] - 0s 4ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4458\n16/16 [==============================] - 0s 3ms/step - loss: 1.4532\n16/16 [==============================] - 0s 1ms/step - loss: 1.5074\n16/16 [==============================] - 0s 1ms/step - loss: 1.5094\n16/16 [==============================] - 0s 1ms/step - loss: 1.5098\n16/16 [==============================] - 0s 1ms/step - loss: 1.5100\n16/16 [==============================] - 0s 1ms/step - loss: 1.5103\n16/16 [==============================] - 0s 1ms/step - loss: 1.5106\n16/16 [==============================] - 0s 1ms/step - loss: 1.5107\n16/16 [==============================] - 0s 2ms/step - loss: 1.5107\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4508\n16/16 [==============================] - 0s 2ms/step - loss: 1.4504\n16/16 [==============================] - 0s 2ms/step - loss: 1.5026\n16/16 [==============================] - 0s 1ms/step - loss: 1.5046\n16/16 [==============================] - 0s 1ms/step - loss: 1.5050\n16/16 [==============================] - 0s 1ms/step - loss: 1.5053\n16/16 [==============================] - 0s 1ms/step - loss: 1.5056\n16/16 [==============================] - 0s 1ms/step - loss: 1.5060\n16/16 [==============================] - 0s 1ms/step - loss: 1.5062\n16/16 [==============================] - 0s 1ms/step - loss: 1.5062\n\nTesting for epoch 36 index 2:\n32/32 [==============================] - 0s 988us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4614\n16/16 [==============================] - 0s 1ms/step - loss: 1.4690\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.5217\n16/16 [==============================] - 0s 1ms/step - loss: 1.5222\n16/16 [==============================] - 0s 1ms/step - loss: 1.5225\n16/16 [==============================] - 0s 2ms/step - loss: 1.5228\n16/16 [==============================] - 0s 891us/step - loss: 1.5233\n16/16 [==============================] - 0s 1ms/step - loss: 1.5235\n16/16 [==============================] - 0s 1ms/step - loss: 1.5235\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.4674\n16/16 [==============================] - 0s 1ms/step - loss: 1.4703\n16/16 [==============================] - 0s 3ms/step - loss: 1.5202\n16/16 [==============================] - 0s 1ms/step - loss: 1.5220\n16/16 [==============================] - 0s 1ms/step - loss: 1.5224\n16/16 [==============================] - 0s 1ms/step - loss: 1.5226\n16/16 [==============================] - 0s 1ms/step - loss: 1.5229\n16/16 [==============================] - 0s 1ms/step - loss: 1.5232\n16/16 [==============================] - 0s 1ms/step - loss: 1.5233\n16/16 [==============================] - 0s 1ms/step - loss: 1.5233\n\nTesting for epoch 37 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4817\n16/16 [==============================] - 0s 2ms/step - loss: 1.4794\n16/16 [==============================] - 0s 2ms/step - loss: 1.5276\n16/16 [==============================] - 0s 2ms/step - loss: 1.5293\n16/16 [==============================] - 0s 1ms/step - loss: 1.5296\n16/16 [==============================] - 0s 1ms/step - loss: 1.5299\n16/16 [==============================] - 0s 2ms/step - loss: 1.5301\n16/16 [==============================] - 0s 2ms/step - loss: 1.5304\n16/16 [==============================] - 0s 2ms/step - loss: 1.5305\n16/16 [==============================] - 0s 2ms/step - loss: 1.5305\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.4878\n16/16 [==============================] - 0s 1ms/step - loss: 1.4939\n16/16 [==============================] - 0s 1ms/step - loss: 1.5415\n16/16 [==============================] - 0s 2ms/step - loss: 1.5431\n16/16 [==============================] - 0s 2ms/step - loss: 1.5435\n16/16 [==============================] - 0s 1ms/step - loss: 1.5437\n16/16 [==============================] - 0s 2ms/step - loss: 1.5439\n16/16 [==============================] - 0s 2ms/step - loss: 1.5442\n16/16 [==============================] - 0s 2ms/step - loss: 1.5443\n16/16 [==============================] - 0s 2ms/step - loss: 1.5443\n\nTesting for epoch 38 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5035\n16/16 [==============================] - 0s 1ms/step - loss: 1.4905\n16/16 [==============================] - 0s 1ms/step - loss: 1.5351\n16/16 [==============================] - 0s 1ms/step - loss: 1.5365\n16/16 [==============================] - 0s 1ms/step - loss: 1.5370\n16/16 [==============================] - 0s 1ms/step - loss: 1.5373\n16/16 [==============================] - 0s 988us/step - loss: 1.5376\n16/16 [==============================] - 0s 2ms/step - loss: 1.5381\n16/16 [==============================] - 0s 2ms/step - loss: 1.5382\n16/16 [==============================] - 0s 2ms/step - loss: 1.5383\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5103\n16/16 [==============================] - 0s 1ms/step - loss: 1.5127\n16/16 [==============================] - 0s 1ms/step - loss: 1.5577\n16/16 [==============================] - 0s 1ms/step - loss: 1.5592\n16/16 [==============================] - 0s 4ms/step - loss: 1.5596\n16/16 [==============================] - 0s 4ms/step - loss: 1.5598\n16/16 [==============================] - 0s 1ms/step - loss: 1.5601\n16/16 [==============================] - 0s 3ms/step - loss: 1.5604\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n\nTesting for epoch 39 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5264\n16/16 [==============================] - 0s 1ms/step - loss: 1.5167\n16/16 [==============================] - 0s 3ms/step - loss: 1.5597\n16/16 [==============================] - 0s 2ms/step - loss: 1.5612\n16/16 [==============================] - 0s 1ms/step - loss: 1.5615\n16/16 [==============================] - 0s 1ms/step - loss: 1.5617\n16/16 [==============================] - 0s 1ms/step - loss: 1.5620\n16/16 [==============================] - 0s 1ms/step - loss: 1.5622\n16/16 [==============================] - 0s 1ms/step - loss: 1.5623\n16/16 [==============================] - 0s 1ms/step - loss: 1.5623\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5342\n16/16 [==============================] - 0s 2ms/step - loss: 1.5283\n16/16 [==============================] - 0s 2ms/step - loss: 1.5709\n16/16 [==============================] - 0s 1ms/step - loss: 1.5724\n16/16 [==============================] - 0s 1ms/step - loss: 1.5727\n16/16 [==============================] - 0s 1ms/step - loss: 1.5729\n16/16 [==============================] - 0s 2ms/step - loss: 1.5732\n16/16 [==============================] - 0s 1ms/step - loss: 1.5734\n16/16 [==============================] - 0s 1ms/step - loss: 1.5735\n16/16 [==============================] - 0s 1ms/step - loss: 1.5735\n\nTesting for epoch 40 index 2:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5499\n16/16 [==============================] - 0s 2ms/step - loss: 1.5318\n16/16 [==============================] - 0s 2ms/step - loss: 1.5719\n16/16 [==============================] - 0s 1ms/step - loss: 1.5733\n16/16 [==============================] - 0s 1ms/step - loss: 1.5736\n16/16 [==============================] - 0s 2ms/step - loss: 1.5738\n16/16 [==============================] - 0s 2ms/step - loss: 1.5740\n16/16 [==============================] - 0s 2ms/step - loss: 1.5743\n16/16 [==============================] - 0s 1ms/step - loss: 1.5744\n16/16 [==============================] - 0s 1ms/step - loss: 1.5744\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5570\n16/16 [==============================] - 0s 1ms/step - loss: 1.5475\n16/16 [==============================] - 0s 1ms/step - loss: 1.5874\n16/16 [==============================] - 0s 1ms/step - loss: 1.5888\n16/16 [==============================] - 0s 2ms/step - loss: 1.5891\n16/16 [==============================] - 0s 2ms/step - loss: 1.5892\n16/16 [==============================] - 0s 2ms/step - loss: 1.5893\n16/16 [==============================] - 0s 1ms/step - loss: 1.5895\n16/16 [==============================] - 0s 1ms/step - loss: 1.5896\n16/16 [==============================] - 0s 2ms/step - loss: 1.5896\n\nTesting for epoch 41 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5733\n16/16 [==============================] - 0s 1ms/step - loss: 1.5531\n16/16 [==============================] - 0s 1ms/step - loss: 1.5914\n16/16 [==============================] - 0s 1ms/step - loss: 1.5927\n16/16 [==============================] - 0s 2ms/step - loss: 1.5931\n16/16 [==============================] - 0s 2ms/step - loss: 1.5932\n16/16 [==============================] - 0s 2ms/step - loss: 1.5934\n16/16 [==============================] - 0s 1ms/step - loss: 1.5937\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n32/32 [==============================] - 0s 830us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.5804\n16/16 [==============================] - 0s 2ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5989\n16/16 [==============================] - 0s 2ms/step - loss: 1.6002\n16/16 [==============================] - 0s 1ms/step - loss: 1.6005\n16/16 [==============================] - 0s 1ms/step - loss: 1.6007\n16/16 [==============================] - 0s 2ms/step - loss: 1.6010\n16/16 [==============================] - 0s 2ms/step - loss: 1.6013\n16/16 [==============================] - 0s 1ms/step - loss: 1.6014\n16/16 [==============================] - 0s 2ms/step - loss: 1.6014\n\nTesting for epoch 42 index 2:\n32/32 [==============================] - 0s 770us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.5964\n16/16 [==============================] - 0s 3ms/step - loss: 1.5755\n16/16 [==============================] - 0s 2ms/step - loss: 1.6137\n16/16 [==============================] - 0s 2ms/step - loss: 1.6149\n16/16 [==============================] - 0s 1ms/step - loss: 1.6153\n16/16 [==============================] - 0s 1ms/step - loss: 1.6155\n16/16 [==============================] - 0s 1ms/step - loss: 1.6157\n16/16 [==============================] - 0s 2ms/step - loss: 1.6160\n16/16 [==============================] - 0s 2ms/step - loss: 1.6161\n16/16 [==============================] - 0s 3ms/step - loss: 1.6161\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6020\n16/16 [==============================] - 0s 2ms/step - loss: 1.5861\n16/16 [==============================] - 0s 4ms/step - loss: 1.6247\n16/16 [==============================] - 0s 2ms/step - loss: 1.6259\n16/16 [==============================] - 0s 2ms/step - loss: 1.6263\n16/16 [==============================] - 0s 2ms/step - loss: 1.6264\n16/16 [==============================] - 0s 1ms/step - loss: 1.6266\n16/16 [==============================] - 0s 2ms/step - loss: 1.6268\n16/16 [==============================] - 0s 2ms/step - loss: 1.6269\n16/16 [==============================] - 0s 2ms/step - loss: 1.6269\n\nTesting for epoch 43 index 2:\n32/32 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6162\n16/16 [==============================] - 0s 1ms/step - loss: 1.5924\n16/16 [==============================] - 0s 988us/step - loss: 1.6302\n16/16 [==============================] - 0s 2ms/step - loss: 1.6314\n16/16 [==============================] - 0s 2ms/step - loss: 1.6318\n16/16 [==============================] - 0s 1ms/step - loss: 1.6319\n16/16 [==============================] - 0s 1ms/step - loss: 1.6321\n16/16 [==============================] - 0s 1ms/step - loss: 1.6323\n16/16 [==============================] - 0s 2ms/step - loss: 1.6324\n16/16 [==============================] - 0s 2ms/step - loss: 1.6324\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n32/32 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.6208\n16/16 [==============================] - 0s 3ms/step - loss: 1.6042\n16/16 [==============================] - 0s 2ms/step - loss: 1.6422\n16/16 [==============================] - 0s 1ms/step - loss: 1.6435\n16/16 [==============================] - 0s 2ms/step - loss: 1.6438\n16/16 [==============================] - 0s 2ms/step - loss: 1.6440\n16/16 [==============================] - 0s 2ms/step - loss: 1.6442\n16/16 [==============================] - 0s 1ms/step - loss: 1.6444\n16/16 [==============================] - 0s 1ms/step - loss: 1.6445\n16/16 [==============================] - 0s 1ms/step - loss: 1.6445\n\nTesting for epoch 44 index 2:\n32/32 [==============================] - 0s 855us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6333\n16/16 [==============================] - 0s 1ms/step - loss: 1.6115\n16/16 [==============================] - 0s 2ms/step - loss: 1.6493\n16/16 [==============================] - 0s 2ms/step - loss: 1.6505\n16/16 [==============================] - 0s 1ms/step - loss: 1.6508\n16/16 [==============================] - 0s 1ms/step - loss: 1.6510\n16/16 [==============================] - 0s 2ms/step - loss: 1.6512\n16/16 [==============================] - 0s 2ms/step - loss: 1.6515\n16/16 [==============================] - 0s 1ms/step - loss: 1.6516\n16/16 [==============================] - 0s 2ms/step - loss: 1.6516\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n32/32 [==============================] - 0s 836us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6363\n16/16 [==============================] - 0s 2ms/step - loss: 1.6203\n16/16 [==============================] - 0s 1ms/step - loss: 1.6589\n16/16 [==============================] - 0s 1ms/step - loss: 1.6601\n16/16 [==============================] - 0s 1ms/step - loss: 1.6604\n16/16 [==============================] - 0s 1ms/step - loss: 1.6606\n16/16 [==============================] - 0s 771us/step - loss: 1.6608\n16/16 [==============================] - 0s 1ms/step - loss: 1.6610\n16/16 [==============================] - 0s 954us/step - loss: 1.6611\n16/16 [==============================] - 0s 943us/step - loss: 1.6611\n\nTesting for epoch 45 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.6489\n16/16 [==============================] - 0s 1ms/step - loss: 1.6337\n16/16 [==============================] - 0s 1ms/step - loss: 1.6729\n16/16 [==============================] - 0s 1ms/step - loss: 1.6741\n16/16 [==============================] - 0s 1ms/step - loss: 1.6744\n16/16 [==============================] - 0s 1ms/step - loss: 1.6746\n16/16 [==============================] - 0s 2ms/step - loss: 1.6747\n16/16 [==============================] - 0s 2ms/step - loss: 1.6749\n16/16 [==============================] - 0s 1ms/step - loss: 1.6749\n16/16 [==============================] - 0s 2ms/step - loss: 1.6750\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6501\n16/16 [==============================] - 0s 1ms/step - loss: 1.6367\n16/16 [==============================] - 0s 1ms/step - loss: 1.6765\n16/16 [==============================] - 0s 3ms/step - loss: 1.6777\n16/16 [==============================] - 0s 2ms/step - loss: 1.6780\n16/16 [==============================] - 0s 2ms/step - loss: 1.6781\n16/16 [==============================] - 0s 2ms/step - loss: 1.6783\n16/16 [==============================] - 0s 1ms/step - loss: 1.6784\n16/16 [==============================] - 0s 2ms/step - loss: 1.6785\n16/16 [==============================] - 0s 1ms/step - loss: 1.6785\n\nTesting for epoch 46 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 819us/step - loss: 0.6612\n16/16 [==============================] - 0s 804us/step - loss: 1.6441\n16/16 [==============================] - 0s 1ms/step - loss: 1.6840\n16/16 [==============================] - 0s 785us/step - loss: 1.6852\n16/16 [==============================] - 0s 1ms/step - loss: 1.6855\n16/16 [==============================] - 0s 1ms/step - loss: 1.6856\n16/16 [==============================] - 0s 1ms/step - loss: 1.6857\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\n16/16 [==============================] - 0s 1ms/step - loss: 1.6858\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n32/32 [==============================] - 0s 835us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6626\n16/16 [==============================] - 0s 1ms/step - loss: 1.6545\n16/16 [==============================] - 0s 805us/step - loss: 1.6944\n16/16 [==============================] - 0s 804us/step - loss: 1.6957\n16/16 [==============================] - 0s 1ms/step - loss: 1.6960\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n16/16 [==============================] - 0s 1ms/step - loss: 1.6961\n16/16 [==============================] - 0s 1ms/step - loss: 1.6962\n16/16 [==============================] - 0s 778us/step - loss: 1.6962\n16/16 [==============================] - 0s 792us/step - loss: 1.6962\n\nTesting for epoch 47 index 2:\n32/32 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.6744\n16/16 [==============================] - 0s 976us/step - loss: 1.6678\n16/16 [==============================] - 0s 1ms/step - loss: 1.7065\n16/16 [==============================] - 0s 804us/step - loss: 1.7078\n16/16 [==============================] - 0s 1ms/step - loss: 1.7081\n16/16 [==============================] - 0s 1ms/step - loss: 1.7083\n16/16 [==============================] - 0s 1ms/step - loss: 1.7085\n16/16 [==============================] - 0s 777us/step - loss: 1.7087\n16/16 [==============================] - 0s 800us/step - loss: 1.7088\n16/16 [==============================] - 0s 789us/step - loss: 1.7088\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n32/32 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.6775\n16/16 [==============================] - 0s 800us/step - loss: 1.6875\n16/16 [==============================] - 0s 1ms/step - loss: 1.7276\n16/16 [==============================] - 0s 1ms/step - loss: 1.7289\n16/16 [==============================] - 0s 808us/step - loss: 1.7292\n16/16 [==============================] - 0s 776us/step - loss: 1.7293\n16/16 [==============================] - 0s 792us/step - loss: 1.7294\n16/16 [==============================] - 0s 1ms/step - loss: 1.7295\n16/16 [==============================] - 0s 1ms/step - loss: 1.7296\n16/16 [==============================] - 0s 1ms/step - loss: 1.7296\n\nTesting for epoch 48 index 2:\n32/32 [==============================] - 0s 831us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.6904\n16/16 [==============================] - 0s 1ms/step - loss: 1.7060\n16/16 [==============================] - 0s 1ms/step - loss: 1.7464\n16/16 [==============================] - 0s 1ms/step - loss: 1.7477\n16/16 [==============================] - 0s 1ms/step - loss: 1.7480\n16/16 [==============================] - 0s 1ms/step - loss: 1.7481\n16/16 [==============================] - 0s 1ms/step - loss: 1.7482\n16/16 [==============================] - 0s 1ms/step - loss: 1.7484\n16/16 [==============================] - 0s 813us/step - loss: 1.7485\n16/16 [==============================] - 0s 1ms/step - loss: 1.7485\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n32/32 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.6923\n16/16 [==============================] - 0s 771us/step - loss: 1.7161\n16/16 [==============================] - 0s 799us/step - loss: 1.7569\n16/16 [==============================] - 0s 819us/step - loss: 1.7583\n16/16 [==============================] - 0s 1ms/step - loss: 1.7586\n16/16 [==============================] - 0s 1ms/step - loss: 1.7587\n16/16 [==============================] - 0s 1ms/step - loss: 1.7589\n16/16 [==============================] - 0s 1ms/step - loss: 1.7591\n16/16 [==============================] - 0s 1ms/step - loss: 1.7592\n16/16 [==============================] - 0s 1ms/step - loss: 1.7592\n\nTesting for epoch 49 index 2:\n32/32 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.7016\n16/16 [==============================] - 0s 782us/step - loss: 1.7163\n16/16 [==============================] - 0s 798us/step - loss: 1.7574\n16/16 [==============================] - 0s 790us/step - loss: 1.7587\n16/16 [==============================] - 0s 796us/step - loss: 1.7589\n16/16 [==============================] - 0s 778us/step - loss: 1.7590\n16/16 [==============================] - 0s 770us/step - loss: 1.7591\n16/16 [==============================] - 0s 799us/step - loss: 1.7591\n16/16 [==============================] - 0s 810us/step - loss: 1.7591\n16/16 [==============================] - 0s 779us/step - loss: 1.7591\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n32/32 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.7041\n16/16 [==============================] - 0s 787us/step - loss: 1.7274\n16/16 [==============================] - 0s 833us/step - loss: 1.7685\n16/16 [==============================] - 0s 826us/step - loss: 1.7698\n16/16 [==============================] - 0s 792us/step - loss: 1.7702\n16/16 [==============================] - 0s 818us/step - loss: 1.7703\n16/16 [==============================] - 0s 778us/step - loss: 1.7705\n16/16 [==============================] - 0s 841us/step - loss: 1.7707\n16/16 [==============================] - 0s 805us/step - loss: 1.7708\n16/16 [==============================] - 0s 838us/step - loss: 1.7708\n\nTesting for epoch 50 index 2:\n32/32 [==============================] - 0s 624us/step\n16/16 [==============================] - 0s 824us/step - loss: 0.7152\n16/16 [==============================] - 0s 796us/step - loss: 1.7311\n16/16 [==============================] - 0s 817us/step - loss: 1.7720\n16/16 [==============================] - 0s 781us/step - loss: 1.7732\n16/16 [==============================] - 0s 1ms/step - loss: 1.7736\n16/16 [==============================] - 0s 1ms/step - loss: 1.7737\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 895us/step - loss: 1.7741\n16/16 [==============================] - 0s 776us/step - loss: 1.7742\n16/16 [==============================] - 0s 804us/step - loss: 1.7742\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.7194\n16/16 [==============================] - 0s 799us/step - loss: 1.7544\n16/16 [==============================] - 0s 796us/step - loss: 1.7966\n16/16 [==============================] - 0s 790us/step - loss: 1.7980\n16/16 [==============================] - 0s 810us/step - loss: 1.7983\n16/16 [==============================] - 0s 804us/step - loss: 1.7984\n16/16 [==============================] - 0s 821us/step - loss: 1.7985\n16/16 [==============================] - 0s 791us/step - loss: 1.7987\n16/16 [==============================] - 0s 781us/step - loss: 1.7987\n16/16 [==============================] - 0s 789us/step - loss: 1.7987\n\nTesting for epoch 51 index 2:\n32/32 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.7322\n16/16 [==============================] - 0s 802us/step - loss: 1.7637\n16/16 [==============================] - 0s 793us/step - loss: 1.8060\n16/16 [==============================] - 0s 795us/step - loss: 1.8073\n16/16 [==============================] - 0s 783us/step - loss: 1.8076\n16/16 [==============================] - 0s 776us/step - loss: 1.8077\n16/16 [==============================] - 0s 770us/step - loss: 1.8079\n16/16 [==============================] - 0s 779us/step - loss: 1.8080\n16/16 [==============================] - 0s 787us/step - loss: 1.8081\n16/16 [==============================] - 0s 805us/step - loss: 1.8081\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n32/32 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.7334\n16/16 [==============================] - 0s 807us/step - loss: 1.7648\n16/16 [==============================] - 0s 785us/step - loss: 1.8070\n16/16 [==============================] - 0s 789us/step - loss: 1.8083\n16/16 [==============================] - 0s 788us/step - loss: 1.8086\n16/16 [==============================] - 0s 825us/step - loss: 1.8088\n16/16 [==============================] - 0s 794us/step - loss: 1.8089\n16/16 [==============================] - 0s 839us/step - loss: 1.8091\n16/16 [==============================] - 0s 827us/step - loss: 1.8092\n16/16 [==============================] - 0s 832us/step - loss: 1.8092\n\nTesting for epoch 52 index 2:\n32/32 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 953us/step - loss: 0.7473\n16/16 [==============================] - 0s 1ms/step - loss: 1.7771\n16/16 [==============================] - 0s 1ms/step - loss: 1.8202\n16/16 [==============================] - 0s 782us/step - loss: 1.8215\n16/16 [==============================] - 0s 806us/step - loss: 1.8217\n16/16 [==============================] - 0s 789us/step - loss: 1.8217\n16/16 [==============================] - 0s 821us/step - loss: 1.8217\n16/16 [==============================] - 0s 810us/step - loss: 1.8217\n16/16 [==============================] - 0s 706us/step - loss: 1.8217\n16/16 [==============================] - 0s 675us/step - loss: 1.8217\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n32/32 [==============================] - 0s 543us/step\n16/16 [==============================] - 0s 815us/step - loss: 0.7534\n16/16 [==============================] - 0s 798us/step - loss: 1.7954\n16/16 [==============================] - 0s 682us/step - loss: 1.8386\n16/16 [==============================] - 0s 821us/step - loss: 1.8399\n16/16 [==============================] - 0s 786us/step - loss: 1.8402\n16/16 [==============================] - 0s 788us/step - loss: 1.8403\n16/16 [==============================] - 0s 801us/step - loss: 1.8404\n16/16 [==============================] - 0s 864us/step - loss: 1.8405\n16/16 [==============================] - 0s 866us/step - loss: 1.8405\n16/16 [==============================] - 0s 861us/step - loss: 1.8405\n\nTesting for epoch 53 index 2:\n32/32 [==============================] - 0s 821us/step\n16/16 [==============================] - 0s 901us/step - loss: 0.7658\n16/16 [==============================] - 0s 876us/step - loss: 1.7944\n16/16 [==============================] - 0s 904us/step - loss: 1.8367\n16/16 [==============================] - 0s 923us/step - loss: 1.8380\n16/16 [==============================] - 0s 863us/step - loss: 1.8382\n16/16 [==============================] - 0s 888us/step - loss: 1.8383\n16/16 [==============================] - 0s 892us/step - loss: 1.8384\n16/16 [==============================] - 0s 872us/step - loss: 1.8385\n16/16 [==============================] - 0s 874us/step - loss: 1.8385\n16/16 [==============================] - 0s 1ms/step - loss: 1.8385\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n32/32 [==============================] - 0s 675us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.7743\n16/16 [==============================] - 0s 878us/step - loss: 1.8193\n16/16 [==============================] - 0s 800us/step - loss: 1.8622\n16/16 [==============================] - 0s 791us/step - loss: 1.8635\n16/16 [==============================] - 0s 786us/step - loss: 1.8638\n16/16 [==============================] - 0s 794us/step - loss: 1.8639\n16/16 [==============================] - 0s 798us/step - loss: 1.8640\n16/16 [==============================] - 0s 828us/step - loss: 1.8641\n16/16 [==============================] - 0s 797us/step - loss: 1.8642\n16/16 [==============================] - 0s 812us/step - loss: 1.8642\n\nTesting for epoch 54 index 2:\n32/32 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.7864\n16/16 [==============================] - 0s 822us/step - loss: 1.8117\n16/16 [==============================] - 0s 809us/step - loss: 1.8535\n16/16 [==============================] - 0s 794us/step - loss: 1.8547\n16/16 [==============================] - 0s 811us/step - loss: 1.8550\n16/16 [==============================] - 0s 806us/step - loss: 1.8551\n16/16 [==============================] - 0s 844us/step - loss: 1.8552\n16/16 [==============================] - 0s 794us/step - loss: 1.8553\n16/16 [==============================] - 0s 784us/step - loss: 1.8554\n16/16 [==============================] - 0s 802us/step - loss: 1.8554\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n32/32 [==============================] - 0s 621us/step\n16/16 [==============================] - 0s 873us/step - loss: 0.7953\n16/16 [==============================] - 0s 873us/step - loss: 1.8319\n16/16 [==============================] - 0s 808us/step - loss: 1.8741\n16/16 [==============================] - 0s 859us/step - loss: 1.8754\n16/16 [==============================] - 0s 809us/step - loss: 1.8757\n16/16 [==============================] - 0s 847us/step - loss: 1.8758\n16/16 [==============================] - 0s 827us/step - loss: 1.8758\n16/16 [==============================] - 0s 860us/step - loss: 1.8759\n16/16 [==============================] - 0s 804us/step - loss: 1.8760\n16/16 [==============================] - 0s 876us/step - loss: 1.8760\n\nTesting for epoch 55 index 2:\n32/32 [==============================] - 0s 643us/step\n16/16 [==============================] - 0s 808us/step - loss: 0.8131\n16/16 [==============================] - 0s 893us/step - loss: 1.8454\n16/16 [==============================] - 0s 809us/step - loss: 1.8876\n16/16 [==============================] - 0s 907us/step - loss: 1.8889\n16/16 [==============================] - 0s 873us/step - loss: 1.8891\n16/16 [==============================] - 0s 886us/step - loss: 1.8892\n16/16 [==============================] - 0s 869us/step - loss: 1.8892\n16/16 [==============================] - 0s 876us/step - loss: 1.8892\n16/16 [==============================] - 0s 808us/step - loss: 1.8892\n16/16 [==============================] - 0s 796us/step - loss: 1.8892\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 694us/step - loss: 0.8154\n16/16 [==============================] - 0s 812us/step - loss: 1.8371\n16/16 [==============================] - 0s 815us/step - loss: 1.8781\n16/16 [==============================] - 0s 796us/step - loss: 1.8793\n16/16 [==============================] - 0s 867us/step - loss: 1.8796\n16/16 [==============================] - 0s 798us/step - loss: 1.8797\n16/16 [==============================] - 0s 791us/step - loss: 1.8798\n16/16 [==============================] - 0s 878us/step - loss: 1.8799\n16/16 [==============================] - 0s 872us/step - loss: 1.8800\n16/16 [==============================] - 0s 799us/step - loss: 1.8800\n\nTesting for epoch 56 index 2:\n32/32 [==============================] - 0s 611us/step\n16/16 [==============================] - 0s 830us/step - loss: 0.8363\n16/16 [==============================] - 0s 883us/step - loss: 1.8623\n16/16 [==============================] - 0s 873us/step - loss: 1.9037\n16/16 [==============================] - 0s 817us/step - loss: 1.9049\n16/16 [==============================] - 0s 837us/step - loss: 1.9052\n16/16 [==============================] - 0s 811us/step - loss: 1.9052\n16/16 [==============================] - 0s 862us/step - loss: 1.9053\n16/16 [==============================] - 0s 859us/step - loss: 1.9054\n16/16 [==============================] - 0s 839us/step - loss: 1.9054\n16/16 [==============================] - 0s 809us/step - loss: 1.9054\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n32/32 [==============================] - 0s 860us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.8392\n16/16 [==============================] - 0s 866us/step - loss: 1.8604\n16/16 [==============================] - 0s 854us/step - loss: 1.9012\n16/16 [==============================] - 0s 1ms/step - loss: 1.9024\n16/16 [==============================] - 0s 1ms/step - loss: 1.9027\n16/16 [==============================] - 0s 853us/step - loss: 1.9028\n16/16 [==============================] - 0s 892us/step - loss: 1.9029\n16/16 [==============================] - 0s 901us/step - loss: 1.9030\n16/16 [==============================] - 0s 666us/step - loss: 1.9031\n16/16 [==============================] - 0s 2ms/step - loss: 1.9031\n\nTesting for epoch 57 index 2:\n32/32 [==============================] - 0s 570us/step\n16/16 [==============================] - 0s 875us/step - loss: 0.8581\n16/16 [==============================] - 0s 839us/step - loss: 1.8764\n16/16 [==============================] - 0s 1ms/step - loss: 1.9169\n16/16 [==============================] - 0s 793us/step - loss: 1.9180\n16/16 [==============================] - 0s 829us/step - loss: 1.9183\n16/16 [==============================] - 0s 852us/step - loss: 1.9184\n16/16 [==============================] - 0s 2ms/step - loss: 1.9185\n16/16 [==============================] - 0s 786us/step - loss: 1.9186\n16/16 [==============================] - 0s 890us/step - loss: 1.9187\n16/16 [==============================] - 0s 2ms/step - loss: 1.9187\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n32/32 [==============================] - 0s 549us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.8680\n16/16 [==============================] - 0s 922us/step - loss: 1.8985\n16/16 [==============================] - 0s 765us/step - loss: 1.9394\n16/16 [==============================] - 0s 781us/step - loss: 1.9405\n16/16 [==============================] - 0s 820us/step - loss: 1.9408\n16/16 [==============================] - 0s 1ms/step - loss: 1.9409\n16/16 [==============================] - 0s 781us/step - loss: 1.9410\n16/16 [==============================] - 0s 755us/step - loss: 1.9411\n16/16 [==============================] - 0s 811us/step - loss: 1.9412\n16/16 [==============================] - 0s 2ms/step - loss: 1.9412\n\nTesting for epoch 58 index 2:\n32/32 [==============================] - 0s 613us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.8825\n16/16 [==============================] - 0s 2ms/step - loss: 1.9008\n16/16 [==============================] - 0s 799us/step - loss: 1.9412\n16/16 [==============================] - 0s 2ms/step - loss: 1.9423\n16/16 [==============================] - 0s 2ms/step - loss: 1.9425\n16/16 [==============================] - 0s 2ms/step - loss: 1.9426\n16/16 [==============================] - 0s 791us/step - loss: 1.9427\n16/16 [==============================] - 0s 851us/step - loss: 1.9427\n16/16 [==============================] - 0s 2ms/step - loss: 1.9427\n16/16 [==============================] - 0s 2ms/step - loss: 1.9427\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n32/32 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.8879\n16/16 [==============================] - 0s 803us/step - loss: 1.9056\n16/16 [==============================] - 0s 2ms/step - loss: 1.9456\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 962us/step - loss: 1.9470\n16/16 [==============================] - 0s 794us/step - loss: 1.9470\n16/16 [==============================] - 0s 800us/step - loss: 1.9471\n16/16 [==============================] - 0s 2ms/step - loss: 1.9471\n16/16 [==============================] - 0s 2ms/step - loss: 1.9471\n16/16 [==============================] - 0s 1ms/step - loss: 1.9471\n\nTesting for epoch 59 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 830us/step - loss: 0.9059\n16/16 [==============================] - 0s 1ms/step - loss: 1.9160\n16/16 [==============================] - 0s 838us/step - loss: 1.9552\n16/16 [==============================] - 0s 788us/step - loss: 1.9563\n16/16 [==============================] - 0s 2ms/step - loss: 1.9566\n16/16 [==============================] - 0s 761us/step - loss: 1.9567\n16/16 [==============================] - 0s 808us/step - loss: 1.9569\n16/16 [==============================] - 0s 2ms/step - loss: 1.9571\n16/16 [==============================] - 0s 2ms/step - loss: 1.9571\n16/16 [==============================] - 0s 1ms/step - loss: 1.9571\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n32/32 [==============================] - 0s 561us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.9083\n16/16 [==============================] - 0s 2ms/step - loss: 1.9140\n16/16 [==============================] - 0s 800us/step - loss: 1.9538\n16/16 [==============================] - 0s 793us/step - loss: 1.9549\n16/16 [==============================] - 0s 877us/step - loss: 1.9551\n16/16 [==============================] - 0s 783us/step - loss: 1.9551\n16/16 [==============================] - 0s 1ms/step - loss: 1.9551\n16/16 [==============================] - 0s 1ms/step - loss: 1.9552\n16/16 [==============================] - 0s 884us/step - loss: 1.9552\n16/16 [==============================] - 0s 2ms/step - loss: 1.9552\n\nTesting for epoch 60 index 2:\n32/32 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.9274\n16/16 [==============================] - 0s 2ms/step - loss: 1.9310\n16/16 [==============================] - 0s 2ms/step - loss: 1.9710\n16/16 [==============================] - 0s 775us/step - loss: 1.9721\n16/16 [==============================] - 0s 960us/step - loss: 1.9723\n16/16 [==============================] - 0s 2ms/step - loss: 1.9723\n16/16 [==============================] - 0s 794us/step - loss: 1.9722\n16/16 [==============================] - 0s 1ms/step - loss: 1.9721\n16/16 [==============================] - 0s 2ms/step - loss: 1.9721\n16/16 [==============================] - 0s 2ms/step - loss: 1.9721\n32/32 [==============================] - 0s 1ms/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthirteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  thirteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\\(\\star\\)\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = thirteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#orbit-result",
    "title": "Other Outlier Detection",
    "section": "Orbit Result",
    "text": "Orbit Result\n\nround(fourteen,3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.998\n      0.999\n      0.999\n      0.999\n    \n    \n      LOF (Breunig et al., 2000)\n      0.954\n      0.976\n      0.976\n      0.976\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.948\n      0.999\n      0.946\n      0.972\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.908\n      0.977\n      0.925\n      0.950\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.916\n      0.956\n      0.956\n      0.956\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.942\n      0.969\n      0.969\n      0.969\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.994\n      0.994\n      0.994\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.443\n      0.992\n      0.417\n      0.587\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.935\n      0.960\n      0.973\n      0.966\n    \n    \n      SOS (Janssens et al., 2012)\n      0.950\n      0.974\n      0.974\n      0.974\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.950\n      0.950\n      1.000\n      0.974\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.950\n      0.950\n      1.000\n      0.974\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.988\n      0.994\n      0.994\n      0.994\n    \n  \n\n\n\n\n\n\n\nOrbit\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nLOF (Breunig et al., 2000)\n0.954\n0.976\n0.976\n0.976\n\n\nKNN\n\n\n\n\n\n\nCBLOF\n\n\n\n\n\n\nOCSVM (Sch Ìˆolkopf et al., 2001)\n\n\n\n\n\n\nMCD (Hardin and Rocke, 2004)\n0.916\n0.956\n0.956\n0.956\n\n\nFeature Bagging (Lazarevic and Kumar, 2005)\n0.942\n0.969\n0.969\n0.969\n\n\nABOD (Kriegel et al., 2008)\n0.988\n0.994\n0.994\n0.994\n\n\nIsolation Forest (Liu et al., 2008)\n0.443\n0.992\n0.417\n0.587\n\n\nHBOS (Goldstein and Dengel, 2012)\n0.935\n0.960\n0.973\n0.966\n\n\nSOS (Janssens et al., 2012)\n0.950\n0.974\n0.974\n0.974\n\n\nSO-GAAL (Liu et al., 2019)\n0.950\n0.950\n1.000\n0.974\n\n\nMO-GAAL (Liu et al., 2019)\n0.950\n0.950\n1.000\n0.974\n\n\nLSCP (Zhao et al., 2019)\n0.988\n0.994\n0.994\n0.994"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny",
    "title": "Other Outlier Detection",
    "section": "Bunny",
    "text": "Bunny\n\n\nbunny ì €ì¥ìš©\n\nfrom pygsp import graphs, filters, plotting, utils\n\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nimport numpy as np\n\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) \n\n\nn=2503\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\nindex_of_trueoutlier2 = np.where(unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2023-07-04 17:37:32,017:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nG.coords.shape\n\n(2503, 3)\n\n\n\n_W = G.W.toarray()\n_x = G.coords[:,0]\n_y = G.coords[:,1]\n_z = -G.coords[:,2]\n\n\nimport pandas as pd\n\n\n_df = pd.DataFrame({'x':_x,'y':_y,'z':_z})\n\n\nimport pickle\n\n\n_df = {'W':_W,'x':_x,'y':_y,'z':_z, 'fnoise':f+noise,'f' : f, 'noise': noise,'unif':unif,'index_of_trueoutlier2':index_of_trueoutlier2}\n\n\nsave_data(_df,'Bunny.pkl')\n\n\n_df\n\n{'W': array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n 'x': array([ 0.26815193, -0.58456893, -0.02730755, ...,  0.15397547,\n        -0.45056488, -0.29405249]),\n 'y': array([ 0.39314334,  0.63468595,  0.33280949, ...,  0.80205526,\n         0.6207154 , -0.40187451]),\n 'z': array([-0.13834514, -0.22438843,  0.08658215, ...,  0.33698514,\n         0.58353051, -0.08647485]),\n 'fnoise': array([-1.63569131,  0.49423926, -1.04026277, ..., -1.0694093 ,\n        -0.24395499,  0.41729667]),\n 'f': array([-1.54422488, -0.03596483, -0.93972715, ..., -0.01924028,\n        -0.02470869, -0.26266752]),\n 'noise': array([-0.09146643,  0.53020409, -0.10053563, ..., -1.05016902,\n        -0.2192463 ,  0.67996419]),\n 'unif': array([0., 0., 0., ..., 0., 0., 0.]),\n 'index_of_trueoutlier2': (array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,\n          240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,\n          397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,\n          569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,\n          858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,\n         1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,\n         1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,\n         1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,\n         1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,\n         2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,\n         2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)}\n\n\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\n\n_df1 = load_data('Bunny.pkl')\n\n\n_df = pd.DataFrame({'x': _df1['x'],'y':_df1['y'],'z':_df1['z'],'fnoise':_df1['fnoise'],'f':_df1['f'],'noise':_df1['noise']})\n\n\nunif = _df1['unif']\n\n\n_df1['index_of_trueoutlier2']\n\n(array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,\n         240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,\n         397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,\n         569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,\n         858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,\n        1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,\n        1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,\n        1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,\n        1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,\n        2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,\n        2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)\n\n\n\n# _df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})\n\n\noutlier_true_one_2 = unif.copy()\n\n\noutlier_true_one_2 = list(map(lambda x: -1 if x !=0  else 1,outlier_true_one_2))\n\n\n# pd.DataFrame(outlier_true_one_2).to_csv('bunny_outlier.csv')\n\n\nX = np.array(_df)[:,:4]\n\n\n\nGODE\n\n_W = _df1['W']\n\n\n_BUNNY = BUNNY(_df)\n\n\n_BUNNY.fit(sd=20,ref=10)\n\n\nlen(_BUNNY.f)\n\n2503\n\n\n\n2503*0.05\n\n125.15\n\n\n\noutlier_simul_one = (_BUNNY.df['Residual']**2).tolist()\n\n\n# outlier_simul_one = list(map(lambda x: -1 if x > 8.7 else 1,outlier_simul_one))\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 8.05 else 1,outlier_simul_one))\n\n\noutlier_simul_one.count(1)\n\n2378\n\n\n\noutlier_simul_one.count(-1)\n\n125\n\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.995\nRecall: 0.993\nF1 Score: 0.994\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2,contamination=0.05)\n\n\n_conf = Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.913\nPrecision: 0.955\nRecall: 0.953\nF1 Score: 0.954\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwo = one.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  two = one.append(_conf.tab)\n\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.942\nPrecision: 0.997\nRecall: 0.942\nF1 Score: 0.969\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthree = two.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  three = two.append(_conf.tab)\n\n\n\n\nCBLOF\n\n_df1 = load_data('Bunny.pkl')\n\n\noutlier_true_one_2 = pd.read_csv('bunny_outlier.csv').iloc[:,1].to_list()\n\n\n_df = pd.DataFrame({'x': _df1['x'],'y':_df1['y'],'z':_df1['z'],'fnoise':_df1['fnoise'],'f':_df1['f'],'noise':_df1['noise']})\n\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.974\nPrecision: 0.988\nRecall: 0.985\nF1 Score: 0.987\n\n\nAttributeError: 'DataFrame' object has no attribute 'append'\n\n\n\n# four = three.append(_conf.tab)\n\n\nAccuracy: 0.974\nPrecision: 0.988\nRecall: 0.985\nF1 Score: 0.987\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.992\nRecall: 0.939\nF1 Score: 0.965\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfive = three.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  five = three.append(_conf.tab)\n\n\n\n\nMCD\n\nclf = MCD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.982\nPrecision: 0.992\nRecall: 0.989\nF1 Score: 0.990\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nsix = five.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  six = five.append(_conf.tab)\n\n\n\n\nFeature Bagging\n\nclf = FeatureBagging(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.954\nPrecision: 0.977\nRecall: 0.974\nF1 Score: 0.976\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nseven = six.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  seven = six.append(_conf.tab)\n\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.979\nPrecision: 0.990\nRecall: 0.988\nF1 Score: 0.989\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neight = seven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eight = seven.append(_conf.tab)\n\n\nnormal fix ì•ˆ í•´ì¤˜ì„œ ì¢€ ë‹¤ë¥¸ë“¯\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=125\n)\n\n\nod.fit(_df[['x', 'y','fnoise']])\n\n\npreds = od.predict(\n    _df[['x', 'y','fnoise']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.827\nPrecision: 0.995\nRecall: 0.822\nF1 Score: 0.900\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nnine = eight.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nine = eight.append(_conf.tab)\n\n\n\n\nHBOS\n\nclf = HBOS(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.919\nPrecision: 0.958\nRecall: 0.956\nF1 Score: 0.957\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nten = nine.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  ten = nine.append(_conf.tab)\n\n\n\n\nSOS\n\nclf = SOS(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SOS_clf'] = clf.labels_\n\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.955\nRecall: 0.953\nF1 Score: 0.954\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\neleven = ten.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  eleven = ten.append(_conf.tab)\n\n\n\n\nSO_GAAL\n\nclf = SO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7853\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 5ms/step - loss: 1.8346\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8320\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8046\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8184\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8771\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8672\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 1.8837\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8886\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9140\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.8837\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9102\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9125\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0084\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9376\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9044\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9835\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9699\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9834\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0290\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9765\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9838\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 1.9822\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0609\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0396\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0832\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0676\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0518\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0792\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1063\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1162\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0633\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0415\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1830\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1030\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0691\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1029\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0695\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1422\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1041\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1561\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1334\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1333\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0868\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.0846\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.1405\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1730\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1575\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1294\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1989\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1998\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1295\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2162\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2034\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1361\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2382\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2261\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.1818\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2120\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2132\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2494\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2255\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2671\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2116\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2581\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2491\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2208\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2014\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2550\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2830\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2405\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3333\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2521\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2896\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3155\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3146\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2681\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2337\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2561\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2611\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3340\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2951\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2973\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3241\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3202\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2970\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2818\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2771\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3100\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.2902\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3639\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2836\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4120\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3052\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.2881\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3652\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3530\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3983\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3804\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3145\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3505\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 2.3759\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3779\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4360\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3967\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4442\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3817\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4227\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3354\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3362\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3727\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4077\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4266\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4087\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3740\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4019\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4554\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4162\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4631\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4390\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3997\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4826\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.3973\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4596\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4296\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4578\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5058\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4464\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4684\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4405\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4991\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4709\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4676\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4131\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4753\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5160\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4963\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4678\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4248\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5513\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4780\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4913\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4956\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4918\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.4777\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5556\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4938\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4807\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5070\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5431\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4874\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5284\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5150\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5187\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5245\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5878\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5331\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5031\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5649\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.5189\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5311\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5879\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5670\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5522\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5572\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5563\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5327\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5742\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4747\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 2.5711\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5344\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5182\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.4722\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5704\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6122\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5826\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5456\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5821\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5895\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 2.6114\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5628\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5592\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 2.6494\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5955\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6131\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6084\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5200\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5612\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5473\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 5ms/step - loss: 2.6558\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6821\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 2.5944\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6211\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5937\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.6623\n79/79 [==============================] - 0s 1ms/step\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\ntwelve = eleven.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  twelve = eleven.append(_conf.tab)\n\n\n\n\nMO_GAAL\n\nclf = MO_GAAL(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 2 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 3:\n79/79 [==============================] - 0s 664us/step\n\nTesting for epoch 3 index 4:\n79/79 [==============================] - 0s 875us/step\n\nTesting for epoch 3 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n79/79 [==============================] - 0s 820us/step\n\nTesting for epoch 4 index 3:\n79/79 [==============================] - 0s 609us/step\n\nTesting for epoch 4 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 4 index 5:\n79/79 [==============================] - 0s 512us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 2:\n79/79 [==============================] - 0s 684us/step\n\nTesting for epoch 5 index 3:\n79/79 [==============================] - 0s 589us/step\n\nTesting for epoch 5 index 4:\n79/79 [==============================] - 0s 742us/step\n\nTesting for epoch 5 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n79/79 [==============================] - 0s 3ms/step\n\nTesting for epoch 6 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 6 index 4:\n79/79 [==============================] - 0s 3ms/step\n\nTesting for epoch 6 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 7 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 7 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 8 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 8 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 9 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 9 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 10 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 11 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 12 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 5:\n79/79 [==============================] - 0s 2ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 5:\n79/79 [==============================] - 0s 976us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 2:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 16 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 17 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 18 index 2:\n79/79 [==============================] - 0s 891us/step\n\nTesting for epoch 18 index 3:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 18 index 4:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 18 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 19 index 2:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 4:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 19 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n79/79 [==============================] - 0s 2ms/step\n\nTesting for epoch 20 index 2:\n79/79 [==============================] - 0s 978us/step\n\nTesting for epoch 20 index 3:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 4:\n79/79 [==============================] - 0s 969us/step\n\nTesting for epoch 20 index 5:\n79/79 [==============================] - 0s 1ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n79/79 [==============================] - 0s 1ms/step\n\nTesting for epoch 21 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2249\n16/16 [==============================] - 0s 1ms/step - loss: 1.3848\n16/16 [==============================] - 0s 2ms/step - loss: 1.5898\n16/16 [==============================] - 1s 2ms/step - loss: 1.6900\n16/16 [==============================] - 0s 1ms/step - loss: 1.7373\n16/16 [==============================] - 0s 2ms/step - loss: 1.7695\n16/16 [==============================] - 0s 1ms/step - loss: 1.7774\n16/16 [==============================] - 0s 1ms/step - loss: 1.7766\n16/16 [==============================] - 0s 1ms/step - loss: 1.7754\n16/16 [==============================] - 0s 1ms/step - loss: 1.7754\n\nTesting for epoch 21 index 3:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2249\n16/16 [==============================] - 0s 2ms/step - loss: 1.4195\n16/16 [==============================] - 0s 3ms/step - loss: 1.6365\n16/16 [==============================] - 0s 2ms/step - loss: 1.7426\n16/16 [==============================] - 0s 2ms/step - loss: 1.7927\n16/16 [==============================] - 0s 2ms/step - loss: 1.8275\n16/16 [==============================] - 0s 1ms/step - loss: 1.8359\n16/16 [==============================] - 0s 1ms/step - loss: 1.8351\n16/16 [==============================] - 0s 2ms/step - loss: 1.8338\n16/16 [==============================] - 0s 2ms/step - loss: 1.8338\n\nTesting for epoch 21 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.2255\n16/16 [==============================] - 0s 2ms/step - loss: 1.4083\n16/16 [==============================] - 0s 2ms/step - loss: 1.6229\n16/16 [==============================] - 0s 1ms/step - loss: 1.7262\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 2ms/step - loss: 1.8067\n16/16 [==============================] - 0s 2ms/step - loss: 1.8141\n16/16 [==============================] - 0s 1ms/step - loss: 1.8131\n16/16 [==============================] - 0s 2ms/step - loss: 1.8118\n16/16 [==============================] - 0s 2ms/step - loss: 1.8117\n\nTesting for epoch 21 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2193\n16/16 [==============================] - 0s 2ms/step - loss: 1.4150\n16/16 [==============================] - 0s 2ms/step - loss: 1.6347\n16/16 [==============================] - 0s 2ms/step - loss: 1.7387\n16/16 [==============================] - 0s 1ms/step - loss: 1.7855\n16/16 [==============================] - 0s 2ms/step - loss: 1.8169\n16/16 [==============================] - 0s 2ms/step - loss: 1.8234\n16/16 [==============================] - 0s 2ms/step - loss: 1.8219\n16/16 [==============================] - 0s 2ms/step - loss: 1.8205\n16/16 [==============================] - 0s 2ms/step - loss: 1.8205\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.2173\n16/16 [==============================] - 0s 2ms/step - loss: 1.4357\n16/16 [==============================] - 0s 2ms/step - loss: 1.6634\n16/16 [==============================] - 0s 5ms/step - loss: 1.7700\n16/16 [==============================] - 0s 2ms/step - loss: 1.8171\n16/16 [==============================] - 0s 3ms/step - loss: 1.8488\n16/16 [==============================] - 0s 5ms/step - loss: 1.8558\n16/16 [==============================] - 0s 2ms/step - loss: 1.8544\n16/16 [==============================] - 0s 2ms/step - loss: 1.8529\n16/16 [==============================] - 0s 3ms/step - loss: 1.8529\n\nTesting for epoch 22 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2139\n16/16 [==============================] - 0s 2ms/step - loss: 1.4286\n16/16 [==============================] - 0s 2ms/step - loss: 1.6561\n16/16 [==============================] - 0s 1ms/step - loss: 1.7609\n16/16 [==============================] - 0s 4ms/step - loss: 1.8068\n16/16 [==============================] - 0s 2ms/step - loss: 1.8372\n16/16 [==============================] - 0s 6ms/step - loss: 1.8438\n16/16 [==============================] - 0s 2ms/step - loss: 1.8422\n16/16 [==============================] - 0s 2ms/step - loss: 1.8407\n16/16 [==============================] - 0s 2ms/step - loss: 1.8407\n\nTesting for epoch 22 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.2148\n16/16 [==============================] - 0s 1ms/step - loss: 1.4293\n16/16 [==============================] - 0s 2ms/step - loss: 1.6578\n16/16 [==============================] - 0s 4ms/step - loss: 1.7632\n16/16 [==============================] - 0s 2ms/step - loss: 1.8090\n16/16 [==============================] - 0s 2ms/step - loss: 1.8394\n16/16 [==============================] - 0s 2ms/step - loss: 1.8454\n16/16 [==============================] - 0s 5ms/step - loss: 1.8437\n16/16 [==============================] - 0s 2ms/step - loss: 1.8423\n16/16 [==============================] - 0s 2ms/step - loss: 1.8423\n\nTesting for epoch 22 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2181\n16/16 [==============================] - 0s 3ms/step - loss: 1.3837\n16/16 [==============================] - 0s 2ms/step - loss: 1.6049\n16/16 [==============================] - 0s 2ms/step - loss: 1.7082\n16/16 [==============================] - 0s 2ms/step - loss: 1.7544\n16/16 [==============================] - 0s 4ms/step - loss: 1.7860\n16/16 [==============================] - 0s 3ms/step - loss: 1.7928\n16/16 [==============================] - 0s 2ms/step - loss: 1.7913\n16/16 [==============================] - 0s 3ms/step - loss: 1.7897\n16/16 [==============================] - 0s 2ms/step - loss: 1.7897\n\nTesting for epoch 22 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.2083\n16/16 [==============================] - 0s 991us/step - loss: 1.4684\n16/16 [==============================] - 0s 873us/step - loss: 1.7111\n16/16 [==============================] - 0s 2ms/step - loss: 1.8243\n16/16 [==============================] - 0s 820us/step - loss: 1.8730\n16/16 [==============================] - 0s 947us/step - loss: 1.9051\n16/16 [==============================] - 0s 771us/step - loss: 1.9109\n16/16 [==============================] - 0s 1ms/step - loss: 1.9087\n16/16 [==============================] - 0s 1ms/step - loss: 1.9069\n16/16 [==============================] - 0s 839us/step - loss: 1.9069\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n79/79 [==============================] - 0s 564us/step\n16/16 [==============================] - 0s 872us/step - loss: 0.2068\n16/16 [==============================] - 0s 929us/step - loss: 1.4438\n16/16 [==============================] - 0s 859us/step - loss: 1.6817\n16/16 [==============================] - 0s 829us/step - loss: 1.7917\n16/16 [==============================] - 0s 1ms/step - loss: 1.8384\n16/16 [==============================] - 0s 672us/step - loss: 1.8677\n16/16 [==============================] - 0s 2ms/step - loss: 1.8721\n16/16 [==============================] - 0s 3ms/step - loss: 1.8696\n16/16 [==============================] - 0s 1ms/step - loss: 1.8677\n16/16 [==============================] - 0s 942us/step - loss: 1.8676\n\nTesting for epoch 23 index 2:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 827us/step - loss: 0.2075\n16/16 [==============================] - 0s 724us/step - loss: 1.4278\n16/16 [==============================] - 0s 781us/step - loss: 1.6611\n16/16 [==============================] - 0s 855us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.8137\n16/16 [==============================] - 0s 689us/step - loss: 1.8419\n16/16 [==============================] - 0s 846us/step - loss: 1.8465\n16/16 [==============================] - 0s 826us/step - loss: 1.8442\n16/16 [==============================] - 0s 818us/step - loss: 1.8425\n16/16 [==============================] - 0s 818us/step - loss: 1.8425\n\nTesting for epoch 23 index 3:\n79/79 [==============================] - 0s 843us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2072\n16/16 [==============================] - 0s 1ms/step - loss: 1.4404\n16/16 [==============================] - 0s 2ms/step - loss: 1.6810\n16/16 [==============================] - 0s 5ms/step - loss: 1.7908\n16/16 [==============================] - 0s 1ms/step - loss: 1.8406\n16/16 [==============================] - 0s 1ms/step - loss: 1.8710\n16/16 [==============================] - 0s 1ms/step - loss: 1.8762\n16/16 [==============================] - 0s 2ms/step - loss: 1.8739\n16/16 [==============================] - 0s 2ms/step - loss: 1.8721\n16/16 [==============================] - 0s 1ms/step - loss: 1.8720\n\nTesting for epoch 23 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.2005\n16/16 [==============================] - 0s 4ms/step - loss: 1.4690\n16/16 [==============================] - 0s 2ms/step - loss: 1.7149\n16/16 [==============================] - 0s 1ms/step - loss: 1.8240\n16/16 [==============================] - 0s 1ms/step - loss: 1.8711\n16/16 [==============================] - 0s 2ms/step - loss: 1.8977\n16/16 [==============================] - 0s 2ms/step - loss: 1.9010\n16/16 [==============================] - 0s 2ms/step - loss: 1.8979\n16/16 [==============================] - 0s 2ms/step - loss: 1.8961\n16/16 [==============================] - 0s 2ms/step - loss: 1.8960\n\nTesting for epoch 23 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1965\n16/16 [==============================] - 0s 933us/step - loss: 1.4857\n16/16 [==============================] - 0s 2ms/step - loss: 1.7374\n16/16 [==============================] - 0s 1ms/step - loss: 1.8489\n16/16 [==============================] - 0s 1ms/step - loss: 1.8958\n16/16 [==============================] - 0s 1ms/step - loss: 1.9208\n16/16 [==============================] - 0s 2ms/step - loss: 1.9232\n16/16 [==============================] - 0s 1ms/step - loss: 1.9199\n16/16 [==============================] - 0s 2ms/step - loss: 1.9179\n16/16 [==============================] - 0s 2ms/step - loss: 1.9179\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n79/79 [==============================] - 0s 934us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1949\n16/16 [==============================] - 0s 2ms/step - loss: 1.5125\n16/16 [==============================] - 0s 1ms/step - loss: 1.7705\n16/16 [==============================] - 0s 2ms/step - loss: 1.8843\n16/16 [==============================] - 0s 1ms/step - loss: 1.9321\n16/16 [==============================] - 0s 1ms/step - loss: 1.9573\n16/16 [==============================] - 0s 934us/step - loss: 1.9592\n16/16 [==============================] - 0s 2ms/step - loss: 1.9558\n16/16 [==============================] - 0s 2ms/step - loss: 1.9537\n16/16 [==============================] - 0s 1ms/step - loss: 1.9537\n\nTesting for epoch 24 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1959\n16/16 [==============================] - 0s 1ms/step - loss: 1.4640\n16/16 [==============================] - 0s 2ms/step - loss: 1.7067\n16/16 [==============================] - 0s 2ms/step - loss: 1.8128\n16/16 [==============================] - 0s 2ms/step - loss: 1.8585\n16/16 [==============================] - 0s 2ms/step - loss: 1.8822\n16/16 [==============================] - 0s 970us/step - loss: 1.8835\n16/16 [==============================] - 0s 1ms/step - loss: 1.8799\n16/16 [==============================] - 0s 2ms/step - loss: 1.8778\n16/16 [==============================] - 0s 1ms/step - loss: 1.8777\n\nTesting for epoch 24 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1986\n16/16 [==============================] - 0s 1ms/step - loss: 1.4867\n16/16 [==============================] - 0s 4ms/step - loss: 1.7359\n16/16 [==============================] - 0s 3ms/step - loss: 1.8473\n16/16 [==============================] - 0s 2ms/step - loss: 1.8954\n16/16 [==============================] - 0s 2ms/step - loss: 1.9193\n16/16 [==============================] - 0s 2ms/step - loss: 1.9209\n16/16 [==============================] - 0s 1ms/step - loss: 1.9173\n16/16 [==============================] - 0s 2ms/step - loss: 1.9152\n16/16 [==============================] - 0s 1ms/step - loss: 1.9151\n\nTesting for epoch 24 index 4:\n79/79 [==============================] - 0s 862us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1967\n16/16 [==============================] - 0s 1ms/step - loss: 1.4806\n16/16 [==============================] - 0s 2ms/step - loss: 1.7273\n16/16 [==============================] - 0s 1ms/step - loss: 1.8367\n16/16 [==============================] - 0s 2ms/step - loss: 1.8844\n16/16 [==============================] - 0s 2ms/step - loss: 1.9072\n16/16 [==============================] - 0s 1ms/step - loss: 1.9083\n16/16 [==============================] - 0s 1ms/step - loss: 1.9047\n16/16 [==============================] - 0s 2ms/step - loss: 1.9027\n16/16 [==============================] - 0s 2ms/step - loss: 1.9027\n\nTesting for epoch 24 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1922\n16/16 [==============================] - 0s 1ms/step - loss: 1.5153\n16/16 [==============================] - 0s 1ms/step - loss: 1.7681\n16/16 [==============================] - 0s 1ms/step - loss: 1.8780\n16/16 [==============================] - 0s 1ms/step - loss: 1.9241\n16/16 [==============================] - 0s 1ms/step - loss: 1.9447\n16/16 [==============================] - 0s 2ms/step - loss: 1.9445\n16/16 [==============================] - 0s 1ms/step - loss: 1.9402\n16/16 [==============================] - 0s 954us/step - loss: 1.9381\n16/16 [==============================] - 0s 1ms/step - loss: 1.9380\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.1929\n16/16 [==============================] - 0s 1ms/step - loss: 1.4627\n16/16 [==============================] - 0s 1ms/step - loss: 1.7036\n16/16 [==============================] - 0s 953us/step - loss: 1.8077\n16/16 [==============================] - 0s 1000us/step - loss: 1.8516\n16/16 [==============================] - 0s 2ms/step - loss: 1.8687\n16/16 [==============================] - 0s 1ms/step - loss: 1.8670\n16/16 [==============================] - 0s 4ms/step - loss: 1.8625\n16/16 [==============================] - 0s 3ms/step - loss: 1.8602\n16/16 [==============================] - 0s 2ms/step - loss: 1.8602\n\nTesting for epoch 25 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.1918\n16/16 [==============================] - 0s 1ms/step - loss: 1.5117\n16/16 [==============================] - 0s 2ms/step - loss: 1.7683\n16/16 [==============================] - 0s 1ms/step - loss: 1.8769\n16/16 [==============================] - 0s 2ms/step - loss: 1.9240\n16/16 [==============================] - 0s 2ms/step - loss: 1.9418\n16/16 [==============================] - 0s 1ms/step - loss: 1.9400\n16/16 [==============================] - 0s 1ms/step - loss: 1.9352\n16/16 [==============================] - 0s 2ms/step - loss: 1.9327\n16/16 [==============================] - 0s 2ms/step - loss: 1.9326\n\nTesting for epoch 25 index 3:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1905\n16/16 [==============================] - 0s 1ms/step - loss: 1.5434\n16/16 [==============================] - 0s 1ms/step - loss: 1.8096\n16/16 [==============================] - 0s 1ms/step - loss: 1.9206\n16/16 [==============================] - 0s 1ms/step - loss: 1.9683\n16/16 [==============================] - 0s 5ms/step - loss: 1.9856\n16/16 [==============================] - 0s 2ms/step - loss: 1.9832\n16/16 [==============================] - 0s 2ms/step - loss: 1.9781\n16/16 [==============================] - 0s 4ms/step - loss: 1.9756\n16/16 [==============================] - 0s 2ms/step - loss: 1.9755\n\nTesting for epoch 25 index 4:\n79/79 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 856us/step - loss: 0.1849\n16/16 [==============================] - 0s 898us/step - loss: 1.5488\n16/16 [==============================] - 0s 842us/step - loss: 1.8135\n16/16 [==============================] - 0s 817us/step - loss: 1.9221\n16/16 [==============================] - 0s 797us/step - loss: 1.9682\n16/16 [==============================] - 0s 795us/step - loss: 1.9825\n16/16 [==============================] - 0s 833us/step - loss: 1.9783\n16/16 [==============================] - 0s 813us/step - loss: 1.9727\n16/16 [==============================] - 0s 792us/step - loss: 1.9702\n16/16 [==============================] - 0s 794us/step - loss: 1.9701\n\nTesting for epoch 25 index 5:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 817us/step - loss: 0.1847\n16/16 [==============================] - 0s 809us/step - loss: 1.5567\n16/16 [==============================] - 0s 778us/step - loss: 1.8307\n16/16 [==============================] - 0s 778us/step - loss: 1.9453\n16/16 [==============================] - 0s 771us/step - loss: 1.9954\n16/16 [==============================] - 0s 826us/step - loss: 2.0152\n16/16 [==============================] - 0s 802us/step - loss: 2.0137\n16/16 [==============================] - 0s 813us/step - loss: 2.0085\n16/16 [==============================] - 0s 779us/step - loss: 2.0058\n16/16 [==============================] - 0s 769us/step - loss: 2.0056\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n79/79 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1844\n16/16 [==============================] - 0s 807us/step - loss: 1.5198\n16/16 [==============================] - 0s 785us/step - loss: 1.7813\n16/16 [==============================] - 0s 804us/step - loss: 1.8883\n16/16 [==============================] - 0s 778us/step - loss: 1.9336\n16/16 [==============================] - 0s 799us/step - loss: 1.9494\n16/16 [==============================] - 0s 789us/step - loss: 1.9453\n16/16 [==============================] - 0s 816us/step - loss: 1.9398\n16/16 [==============================] - 0s 785us/step - loss: 1.9373\n16/16 [==============================] - 0s 785us/step - loss: 1.9372\n\nTesting for epoch 26 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 806us/step - loss: 0.1859\n16/16 [==============================] - 0s 815us/step - loss: 1.5434\n16/16 [==============================] - 0s 803us/step - loss: 1.8104\n16/16 [==============================] - 0s 770us/step - loss: 1.9219\n16/16 [==============================] - 0s 847us/step - loss: 1.9699\n16/16 [==============================] - 0s 794us/step - loss: 1.9883\n16/16 [==============================] - 0s 779us/step - loss: 1.9855\n16/16 [==============================] - 0s 801us/step - loss: 1.9802\n16/16 [==============================] - 0s 835us/step - loss: 1.9775\n16/16 [==============================] - 0s 1ms/step - loss: 1.9773\n\nTesting for epoch 26 index 3:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1817\n16/16 [==============================] - 0s 1ms/step - loss: 1.5762\n16/16 [==============================] - 0s 1ms/step - loss: 1.8483\n16/16 [==============================] - 0s 1ms/step - loss: 1.9610\n16/16 [==============================] - 0s 781us/step - loss: 2.0079\n16/16 [==============================] - 0s 1ms/step - loss: 2.0228\n16/16 [==============================] - 0s 1ms/step - loss: 2.0191\n16/16 [==============================] - 0s 1ms/step - loss: 2.0135\n16/16 [==============================] - 0s 771us/step - loss: 2.0108\n16/16 [==============================] - 0s 785us/step - loss: 2.0106\n\nTesting for epoch 26 index 4:\n79/79 [==============================] - 0s 749us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1829\n16/16 [==============================] - 0s 1ms/step - loss: 1.5509\n16/16 [==============================] - 0s 808us/step - loss: 1.8163\n16/16 [==============================] - 0s 782us/step - loss: 1.9243\n16/16 [==============================] - 0s 783us/step - loss: 1.9681\n16/16 [==============================] - 0s 782us/step - loss: 1.9796\n16/16 [==============================] - 0s 785us/step - loss: 1.9733\n16/16 [==============================] - 0s 789us/step - loss: 1.9671\n16/16 [==============================] - 0s 795us/step - loss: 1.9644\n16/16 [==============================] - 0s 797us/step - loss: 1.9643\n\nTesting for epoch 26 index 5:\n79/79 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 834us/step - loss: 0.1804\n16/16 [==============================] - 0s 785us/step - loss: 1.5986\n16/16 [==============================] - 0s 791us/step - loss: 1.8789\n16/16 [==============================] - 0s 810us/step - loss: 1.9937\n16/16 [==============================] - 0s 786us/step - loss: 2.0401\n16/16 [==============================] - 0s 775us/step - loss: 2.0543\n16/16 [==============================] - 0s 813us/step - loss: 2.0491\n16/16 [==============================] - 0s 841us/step - loss: 2.0430\n16/16 [==============================] - 0s 787us/step - loss: 2.0402\n16/16 [==============================] - 0s 802us/step - loss: 2.0401\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 980us/step - loss: 0.1780\n16/16 [==============================] - 0s 1ms/step - loss: 1.5897\n16/16 [==============================] - 0s 1ms/step - loss: 1.8713\n16/16 [==============================] - 0s 1ms/step - loss: 1.9847\n16/16 [==============================] - 0s 785us/step - loss: 2.0309\n16/16 [==============================] - 0s 800us/step - loss: 2.0444\n16/16 [==============================] - 0s 801us/step - loss: 2.0382\n16/16 [==============================] - 0s 800us/step - loss: 2.0316\n16/16 [==============================] - 0s 775us/step - loss: 2.0287\n16/16 [==============================] - 0s 772us/step - loss: 2.0286\n\nTesting for epoch 27 index 2:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1847\n16/16 [==============================] - 0s 776us/step - loss: 1.5399\n16/16 [==============================] - 0s 808us/step - loss: 1.8078\n16/16 [==============================] - 0s 805us/step - loss: 1.9151\n16/16 [==============================] - 0s 1ms/step - loss: 1.9593\n16/16 [==============================] - 0s 774us/step - loss: 1.9706\n16/16 [==============================] - 0s 922us/step - loss: 1.9641\n16/16 [==============================] - 0s 1ms/step - loss: 1.9579\n16/16 [==============================] - 0s 1ms/step - loss: 1.9552\n16/16 [==============================] - 0s 1ms/step - loss: 1.9551\n\nTesting for epoch 27 index 3:\n79/79 [==============================] - 0s 609us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1802\n16/16 [==============================] - 0s 1ms/step - loss: 1.5996\n16/16 [==============================] - 0s 840us/step - loss: 1.8825\n16/16 [==============================] - 0s 865us/step - loss: 1.9942\n16/16 [==============================] - 0s 893us/step - loss: 2.0396\n16/16 [==============================] - 0s 707us/step - loss: 2.0499\n16/16 [==============================] - 0s 796us/step - loss: 2.0429\n16/16 [==============================] - 0s 686us/step - loss: 2.0363\n16/16 [==============================] - 0s 703us/step - loss: 2.0335\n16/16 [==============================] - 0s 713us/step - loss: 2.0335\n\nTesting for epoch 27 index 4:\n79/79 [==============================] - 0s 763us/step\n16/16 [==============================] - 0s 845us/step - loss: 0.1746\n16/16 [==============================] - 0s 1ms/step - loss: 1.6245\n16/16 [==============================] - 0s 1ms/step - loss: 1.9167\n16/16 [==============================] - 0s 796us/step - loss: 2.0309\n16/16 [==============================] - 0s 813us/step - loss: 2.0769\n16/16 [==============================] - 0s 803us/step - loss: 2.0875\n16/16 [==============================] - 0s 811us/step - loss: 2.0801\n16/16 [==============================] - 0s 796us/step - loss: 2.0733\n16/16 [==============================] - 0s 815us/step - loss: 2.0704\n16/16 [==============================] - 0s 790us/step - loss: 2.0703\n\nTesting for epoch 27 index 5:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 831us/step - loss: 0.1721\n16/16 [==============================] - 0s 817us/step - loss: 1.6490\n16/16 [==============================] - 0s 829us/step - loss: 1.9488\n16/16 [==============================] - 0s 804us/step - loss: 2.0650\n16/16 [==============================] - 0s 814us/step - loss: 2.1109\n16/16 [==============================] - 0s 828us/step - loss: 2.1218\n16/16 [==============================] - 0s 836us/step - loss: 2.1139\n16/16 [==============================] - 0s 2ms/step - loss: 2.1069\n16/16 [==============================] - 0s 2ms/step - loss: 2.1038\n16/16 [==============================] - 0s 2ms/step - loss: 2.1037\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 842us/step - loss: 0.1745\n16/16 [==============================] - 0s 841us/step - loss: 1.6265\n16/16 [==============================] - 0s 856us/step - loss: 1.9218\n16/16 [==============================] - 0s 844us/step - loss: 2.0351\n16/16 [==============================] - 0s 870us/step - loss: 2.0786\n16/16 [==============================] - 0s 884us/step - loss: 2.0882\n16/16 [==============================] - 0s 929us/step - loss: 2.0794\n16/16 [==============================] - 0s 911us/step - loss: 2.0722\n16/16 [==============================] - 0s 983us/step - loss: 2.0691\n16/16 [==============================] - 0s 924us/step - loss: 2.0690\n\nTesting for epoch 28 index 2:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1718\n16/16 [==============================] - 0s 4ms/step - loss: 1.6199\n16/16 [==============================] - 0s 2ms/step - loss: 1.9153\n16/16 [==============================] - 0s 1ms/step - loss: 2.0279\n16/16 [==============================] - 0s 2ms/step - loss: 2.0710\n16/16 [==============================] - 0s 2ms/step - loss: 2.0805\n16/16 [==============================] - 0s 1ms/step - loss: 2.0718\n16/16 [==============================] - 0s 2ms/step - loss: 2.0644\n16/16 [==============================] - 0s 2ms/step - loss: 2.0613\n16/16 [==============================] - 0s 2ms/step - loss: 2.0612\n\nTesting for epoch 28 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1764\n16/16 [==============================] - 0s 2ms/step - loss: 1.5756\n16/16 [==============================] - 0s 992us/step - loss: 1.8577\n16/16 [==============================] - 0s 1ms/step - loss: 1.9628\n16/16 [==============================] - 0s 4ms/step - loss: 2.0023\n16/16 [==============================] - 0s 1ms/step - loss: 2.0074\n16/16 [==============================] - 0s 2ms/step - loss: 1.9974\n16/16 [==============================] - 0s 2ms/step - loss: 1.9900\n16/16 [==============================] - 0s 2ms/step - loss: 1.9869\n16/16 [==============================] - 0s 2ms/step - loss: 1.9867\n\nTesting for epoch 28 index 4:\n79/79 [==============================] - 0s 897us/step\n16/16 [==============================] - 0s 991us/step - loss: 0.1714\n16/16 [==============================] - 0s 2ms/step - loss: 1.5748\n16/16 [==============================] - 0s 2ms/step - loss: 1.8565\n16/16 [==============================] - 0s 1ms/step - loss: 1.9601\n16/16 [==============================] - 0s 2ms/step - loss: 1.9993\n16/16 [==============================] - 0s 2ms/step - loss: 2.0048\n16/16 [==============================] - 0s 2ms/step - loss: 1.9951\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 1ms/step - loss: 1.9850\n16/16 [==============================] - 0s 2ms/step - loss: 1.9849\n\nTesting for epoch 28 index 5:\n79/79 [==============================] - 0s 947us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1700\n16/16 [==============================] - 0s 1ms/step - loss: 1.6374\n16/16 [==============================] - 0s 1ms/step - loss: 1.9381\n16/16 [==============================] - 0s 1ms/step - loss: 2.0497\n16/16 [==============================] - 0s 1ms/step - loss: 2.0926\n16/16 [==============================] - 0s 1ms/step - loss: 2.0984\n16/16 [==============================] - 0s 1ms/step - loss: 2.0886\n16/16 [==============================] - 0s 1ms/step - loss: 2.0809\n16/16 [==============================] - 0s 1ms/step - loss: 2.0778\n16/16 [==============================] - 0s 2ms/step - loss: 2.0776\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n79/79 [==============================] - 0s 878us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1688\n16/16 [==============================] - 0s 2ms/step - loss: 1.6160\n16/16 [==============================] - 0s 2ms/step - loss: 1.9106\n16/16 [==============================] - 0s 1ms/step - loss: 2.0177\n16/16 [==============================] - 0s 1ms/step - loss: 2.0581\n16/16 [==============================] - 0s 1ms/step - loss: 2.0626\n16/16 [==============================] - 0s 2ms/step - loss: 2.0522\n16/16 [==============================] - 0s 1ms/step - loss: 2.0446\n16/16 [==============================] - 0s 1ms/step - loss: 2.0417\n16/16 [==============================] - 0s 3ms/step - loss: 2.0417\n\nTesting for epoch 29 index 2:\n79/79 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1690\n16/16 [==============================] - 0s 1ms/step - loss: 1.6719\n16/16 [==============================] - 0s 1ms/step - loss: 1.9800\n16/16 [==============================] - 0s 2ms/step - loss: 2.0915\n16/16 [==============================] - 0s 1ms/step - loss: 2.1340\n16/16 [==============================] - 0s 1ms/step - loss: 2.1376\n16/16 [==============================] - 0s 1ms/step - loss: 2.1260\n16/16 [==============================] - 0s 1ms/step - loss: 2.1178\n16/16 [==============================] - 0s 964us/step - loss: 2.1145\n16/16 [==============================] - 0s 1ms/step - loss: 2.1144\n\nTesting for epoch 29 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1690\n16/16 [==============================] - 0s 2ms/step - loss: 1.5813\n16/16 [==============================] - 0s 1ms/step - loss: 1.8637\n16/16 [==============================] - 0s 1ms/step - loss: 1.9638\n16/16 [==============================] - 0s 2ms/step - loss: 2.0025\n16/16 [==============================] - 0s 2ms/step - loss: 2.0058\n16/16 [==============================] - 0s 2ms/step - loss: 1.9953\n16/16 [==============================] - 0s 2ms/step - loss: 1.9879\n16/16 [==============================] - 0s 2ms/step - loss: 1.9850\n16/16 [==============================] - 0s 1ms/step - loss: 1.9849\n\nTesting for epoch 29 index 4:\n79/79 [==============================] - 0s 3ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1653\n16/16 [==============================] - 0s 2ms/step - loss: 1.7200\n16/16 [==============================] - 0s 2ms/step - loss: 2.0423\n16/16 [==============================] - 0s 1ms/step - loss: 2.1567\n16/16 [==============================] - 0s 1ms/step - loss: 2.2005\n16/16 [==============================] - 0s 1ms/step - loss: 2.2035\n16/16 [==============================] - 0s 1ms/step - loss: 2.1900\n16/16 [==============================] - 0s 1ms/step - loss: 2.1809\n16/16 [==============================] - 0s 2ms/step - loss: 2.1772\n16/16 [==============================] - 0s 3ms/step - loss: 2.1770\n\nTesting for epoch 29 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1656\n16/16 [==============================] - 0s 2ms/step - loss: 1.6312\n16/16 [==============================] - 0s 1ms/step - loss: 1.9296\n16/16 [==============================] - 0s 1ms/step - loss: 2.0334\n16/16 [==============================] - 0s 1ms/step - loss: 2.0736\n16/16 [==============================] - 0s 1ms/step - loss: 2.0773\n16/16 [==============================] - 0s 1ms/step - loss: 2.0655\n16/16 [==============================] - 0s 2ms/step - loss: 2.0575\n16/16 [==============================] - 0s 2ms/step - loss: 2.0543\n16/16 [==============================] - 0s 2ms/step - loss: 2.0542\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1641\n16/16 [==============================] - 0s 1ms/step - loss: 1.6943\n16/16 [==============================] - 0s 1ms/step - loss: 2.0115\n16/16 [==============================] - 0s 1ms/step - loss: 2.1206\n16/16 [==============================] - 0s 2ms/step - loss: 2.1614\n16/16 [==============================] - 0s 1ms/step - loss: 2.1623\n16/16 [==============================] - 0s 933us/step - loss: 2.1487\n16/16 [==============================] - 0s 2ms/step - loss: 2.1400\n16/16 [==============================] - 0s 2ms/step - loss: 2.1366\n16/16 [==============================] - 0s 1ms/step - loss: 2.1364\n\nTesting for epoch 30 index 2:\n79/79 [==============================] - 0s 864us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1658\n16/16 [==============================] - 0s 1ms/step - loss: 1.6611\n16/16 [==============================] - 0s 1ms/step - loss: 1.9702\n16/16 [==============================] - 0s 1ms/step - loss: 2.0763\n16/16 [==============================] - 0s 1ms/step - loss: 2.1169\n16/16 [==============================] - 0s 1ms/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.1036\n16/16 [==============================] - 0s 1ms/step - loss: 2.0951\n16/16 [==============================] - 0s 1ms/step - loss: 2.0918\n16/16 [==============================] - 0s 2ms/step - loss: 2.0917\n\nTesting for epoch 30 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1678\n16/16 [==============================] - 0s 2ms/step - loss: 1.6270\n16/16 [==============================] - 0s 2ms/step - loss: 1.9300\n16/16 [==============================] - 0s 2ms/step - loss: 2.0320\n16/16 [==============================] - 0s 2ms/step - loss: 2.0718\n16/16 [==============================] - 0s 2ms/step - loss: 2.0723\n16/16 [==============================] - 0s 1ms/step - loss: 2.0596\n16/16 [==============================] - 0s 2ms/step - loss: 2.0514\n16/16 [==============================] - 0s 2ms/step - loss: 2.0481\n16/16 [==============================] - 0s 2ms/step - loss: 2.0479\n\nTesting for epoch 30 index 4:\n79/79 [==============================] - 0s 932us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1629\n16/16 [==============================] - 0s 2ms/step - loss: 1.6611\n16/16 [==============================] - 0s 2ms/step - loss: 1.9644\n16/16 [==============================] - 0s 2ms/step - loss: 2.0613\n16/16 [==============================] - 0s 1ms/step - loss: 2.0966\n16/16 [==============================] - 0s 3ms/step - loss: 2.0905\n16/16 [==============================] - 0s 2ms/step - loss: 2.0735\n16/16 [==============================] - 0s 1ms/step - loss: 2.0643\n16/16 [==============================] - 0s 2ms/step - loss: 2.0611\n16/16 [==============================] - 0s 1ms/step - loss: 2.0611\n\nTesting for epoch 30 index 5:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1580\n16/16 [==============================] - 0s 1ms/step - loss: 1.7343\n16/16 [==============================] - 0s 926us/step - loss: 2.0589\n16/16 [==============================] - 0s 3ms/step - loss: 2.1636\n16/16 [==============================] - 0s 2ms/step - loss: 2.2026\n16/16 [==============================] - 0s 960us/step - loss: 2.1988\n16/16 [==============================] - 0s 2ms/step - loss: 2.1826\n16/16 [==============================] - 0s 2ms/step - loss: 2.1732\n16/16 [==============================] - 0s 2ms/step - loss: 2.1697\n16/16 [==============================] - 0s 2ms/step - loss: 2.1695\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1629\n16/16 [==============================] - 0s 2ms/step - loss: 1.6340\n16/16 [==============================] - 0s 2ms/step - loss: 1.9369\n16/16 [==============================] - 0s 4ms/step - loss: 2.0366\n16/16 [==============================] - 0s 1ms/step - loss: 2.0749\n16/16 [==============================] - 0s 2ms/step - loss: 2.0736\n16/16 [==============================] - 0s 1ms/step - loss: 2.0595\n16/16 [==============================] - 0s 2ms/step - loss: 2.0507\n16/16 [==============================] - 0s 1ms/step - loss: 2.0472\n16/16 [==============================] - 0s 2ms/step - loss: 2.0470\n\nTesting for epoch 31 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1602\n16/16 [==============================] - 0s 2ms/step - loss: 1.6604\n16/16 [==============================] - 0s 1ms/step - loss: 1.9645\n16/16 [==============================] - 0s 2ms/step - loss: 2.0619\n16/16 [==============================] - 0s 1ms/step - loss: 2.0977\n16/16 [==============================] - 0s 2ms/step - loss: 2.0922\n16/16 [==============================] - 0s 1ms/step - loss: 2.0766\n16/16 [==============================] - 0s 2ms/step - loss: 2.0677\n16/16 [==============================] - 0s 2ms/step - loss: 2.0645\n16/16 [==============================] - 0s 2ms/step - loss: 2.0644\n\nTesting for epoch 31 index 3:\n79/79 [==============================] - 0s 814us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1592\n16/16 [==============================] - 0s 3ms/step - loss: 1.7109\n16/16 [==============================] - 0s 2ms/step - loss: 2.0223\n16/16 [==============================] - 0s 1ms/step - loss: 2.1224\n16/16 [==============================] - 0s 1ms/step - loss: 2.1597\n16/16 [==============================] - 0s 977us/step - loss: 2.1517\n16/16 [==============================] - 0s 961us/step - loss: 2.1344\n16/16 [==============================] - 0s 2ms/step - loss: 2.1248\n16/16 [==============================] - 0s 1ms/step - loss: 2.1212\n16/16 [==============================] - 0s 1ms/step - loss: 2.1210\n\nTesting for epoch 31 index 4:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 975us/step - loss: 0.1591\n16/16 [==============================] - 0s 1ms/step - loss: 1.7203\n16/16 [==============================] - 0s 1ms/step - loss: 2.0343\n16/16 [==============================] - 0s 4ms/step - loss: 2.1337\n16/16 [==============================] - 0s 1ms/step - loss: 2.1707\n16/16 [==============================] - 0s 2ms/step - loss: 2.1621\n16/16 [==============================] - 0s 2ms/step - loss: 2.1441\n16/16 [==============================] - 0s 2ms/step - loss: 2.1342\n16/16 [==============================] - 0s 1ms/step - loss: 2.1305\n16/16 [==============================] - 0s 1ms/step - loss: 2.1303\n\nTesting for epoch 31 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1568\n16/16 [==============================] - 0s 2ms/step - loss: 1.7400\n16/16 [==============================] - 0s 2ms/step - loss: 2.0591\n16/16 [==============================] - 0s 2ms/step - loss: 2.1605\n16/16 [==============================] - 0s 2ms/step - loss: 2.1977\n16/16 [==============================] - 0s 2ms/step - loss: 2.1903\n16/16 [==============================] - 0s 1ms/step - loss: 2.1724\n16/16 [==============================] - 0s 2ms/step - loss: 2.1626\n16/16 [==============================] - 0s 2ms/step - loss: 2.1590\n16/16 [==============================] - 0s 1ms/step - loss: 2.1589\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n79/79 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1585\n16/16 [==============================] - 0s 2ms/step - loss: 1.7001\n16/16 [==============================] - 0s 1ms/step - loss: 2.0088\n16/16 [==============================] - 0s 2ms/step - loss: 2.1060\n16/16 [==============================] - 0s 2ms/step - loss: 2.1420\n16/16 [==============================] - 0s 2ms/step - loss: 2.1348\n16/16 [==============================] - 0s 2ms/step - loss: 2.1169\n16/16 [==============================] - 0s 2ms/step - loss: 2.1072\n16/16 [==============================] - 0s 4ms/step - loss: 2.1037\n16/16 [==============================] - 0s 2ms/step - loss: 2.1035\n\nTesting for epoch 32 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 899us/step - loss: 0.1574\n16/16 [==============================] - 0s 1ms/step - loss: 1.7923\n16/16 [==============================] - 0s 1ms/step - loss: 2.1196\n16/16 [==============================] - 0s 2ms/step - loss: 2.2226\n16/16 [==============================] - 0s 990us/step - loss: 2.2597\n16/16 [==============================] - 0s 1ms/step - loss: 2.2503\n16/16 [==============================] - 0s 1ms/step - loss: 2.2299\n16/16 [==============================] - 0s 962us/step - loss: 2.2193\n16/16 [==============================] - 0s 1ms/step - loss: 2.2156\n16/16 [==============================] - 0s 996us/step - loss: 2.2155\n\nTesting for epoch 32 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 7ms/step - loss: 0.1557\n16/16 [==============================] - 0s 2ms/step - loss: 1.7954\n16/16 [==============================] - 0s 2ms/step - loss: 2.1247\n16/16 [==============================] - 0s 2ms/step - loss: 2.2272\n16/16 [==============================] - 0s 2ms/step - loss: 2.2635\n16/16 [==============================] - 0s 2ms/step - loss: 2.2531\n16/16 [==============================] - 0s 2ms/step - loss: 2.2322\n16/16 [==============================] - 0s 2ms/step - loss: 2.2215\n16/16 [==============================] - 0s 2ms/step - loss: 2.2178\n16/16 [==============================] - 0s 2ms/step - loss: 2.2177\n\nTesting for epoch 32 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1537\n16/16 [==============================] - 0s 1ms/step - loss: 1.7869\n16/16 [==============================] - 0s 1ms/step - loss: 2.1168\n16/16 [==============================] - 0s 1ms/step - loss: 2.2210\n16/16 [==============================] - 0s 1ms/step - loss: 2.2596\n16/16 [==============================] - 0s 1ms/step - loss: 2.2526\n16/16 [==============================] - 0s 992us/step - loss: 2.2329\n16/16 [==============================] - 0s 969us/step - loss: 2.2226\n16/16 [==============================] - 0s 1ms/step - loss: 2.2187\n16/16 [==============================] - 0s 1ms/step - loss: 2.2184\n\nTesting for epoch 32 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1510\n16/16 [==============================] - 0s 2ms/step - loss: 1.7654\n16/16 [==============================] - 0s 1ms/step - loss: 2.0879\n16/16 [==============================] - 0s 2ms/step - loss: 2.1879\n16/16 [==============================] - 0s 1ms/step - loss: 2.2230\n16/16 [==============================] - 0s 1ms/step - loss: 2.2123\n16/16 [==============================] - 0s 1ms/step - loss: 2.1914\n16/16 [==============================] - 0s 1ms/step - loss: 2.1809\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 1ms/step - loss: 2.1768\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1555\n16/16 [==============================] - 0s 1ms/step - loss: 1.7559\n16/16 [==============================] - 0s 2ms/step - loss: 2.0784\n16/16 [==============================] - 0s 2ms/step - loss: 2.1784\n16/16 [==============================] - 0s 4ms/step - loss: 2.2136\n16/16 [==============================] - 0s 2ms/step - loss: 2.2035\n16/16 [==============================] - 0s 2ms/step - loss: 2.1825\n16/16 [==============================] - 0s 1ms/step - loss: 2.1721\n16/16 [==============================] - 0s 3ms/step - loss: 2.1683\n16/16 [==============================] - 0s 2ms/step - loss: 2.1681\n\nTesting for epoch 33 index 2:\n79/79 [==============================] - 0s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1507\n16/16 [==============================] - 0s 932us/step - loss: 1.7736\n16/16 [==============================] - 0s 877us/step - loss: 2.0996\n16/16 [==============================] - 0s 821us/step - loss: 2.2003\n16/16 [==============================] - 0s 801us/step - loss: 2.2338\n16/16 [==============================] - 0s 821us/step - loss: 2.2216\n16/16 [==============================] - 0s 842us/step - loss: 2.2004\n16/16 [==============================] - 0s 791us/step - loss: 2.1900\n16/16 [==============================] - 0s 787us/step - loss: 2.1864\n16/16 [==============================] - 0s 816us/step - loss: 2.1863\n\nTesting for epoch 33 index 3:\n79/79 [==============================] - 0s 589us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1522\n16/16 [==============================] - 0s 829us/step - loss: 1.7884\n16/16 [==============================] - 0s 806us/step - loss: 2.1161\n16/16 [==============================] - 0s 793us/step - loss: 2.2152\n16/16 [==============================] - 0s 777us/step - loss: 2.2465\n16/16 [==============================] - 0s 780us/step - loss: 2.2315\n16/16 [==============================] - 0s 794us/step - loss: 2.2087\n16/16 [==============================] - 0s 783us/step - loss: 2.1979\n16/16 [==============================] - 0s 824us/step - loss: 2.1942\n16/16 [==============================] - 0s 1ms/step - loss: 2.1941\n\nTesting for epoch 33 index 4:\n79/79 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1512\n16/16 [==============================] - 0s 838us/step - loss: 1.7421\n16/16 [==============================] - 0s 848us/step - loss: 2.0614\n16/16 [==============================] - 0s 818us/step - loss: 2.1598\n16/16 [==============================] - 0s 791us/step - loss: 2.1919\n16/16 [==============================] - 0s 785us/step - loss: 2.1795\n16/16 [==============================] - 0s 815us/step - loss: 2.1576\n16/16 [==============================] - 0s 800us/step - loss: 2.1471\n16/16 [==============================] - 0s 835us/step - loss: 2.1433\n16/16 [==============================] - 0s 804us/step - loss: 2.1431\n\nTesting for epoch 33 index 5:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 850us/step - loss: 0.1533\n16/16 [==============================] - 0s 823us/step - loss: 1.7343\n16/16 [==============================] - 0s 841us/step - loss: 2.0496\n16/16 [==============================] - 0s 819us/step - loss: 2.1449\n16/16 [==============================] - 0s 840us/step - loss: 2.1741\n16/16 [==============================] - 0s 829us/step - loss: 2.1592\n16/16 [==============================] - 0s 810us/step - loss: 2.1358\n16/16 [==============================] - 0s 784us/step - loss: 2.1250\n16/16 [==============================] - 0s 834us/step - loss: 2.1212\n16/16 [==============================] - 0s 850us/step - loss: 2.1210\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1524\n16/16 [==============================] - 0s 1ms/step - loss: 1.7155\n16/16 [==============================] - 0s 1ms/step - loss: 2.0298\n16/16 [==============================] - 0s 1ms/step - loss: 2.1247\n16/16 [==============================] - 0s 816us/step - loss: 2.1539\n16/16 [==============================] - 0s 845us/step - loss: 2.1409\n16/16 [==============================] - 0s 784us/step - loss: 2.1187\n16/16 [==============================] - 0s 1ms/step - loss: 2.1082\n16/16 [==============================] - 0s 1ms/step - loss: 2.1044\n16/16 [==============================] - 0s 970us/step - loss: 2.1041\n\nTesting for epoch 34 index 2:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1485\n16/16 [==============================] - 0s 826us/step - loss: 1.7384\n16/16 [==============================] - 0s 794us/step - loss: 2.0580\n16/16 [==============================] - 0s 786us/step - loss: 2.1532\n16/16 [==============================] - 0s 782us/step - loss: 2.1809\n16/16 [==============================] - 0s 782us/step - loss: 2.1669\n16/16 [==============================] - 0s 792us/step - loss: 2.1444\n16/16 [==============================] - 0s 779us/step - loss: 2.1341\n16/16 [==============================] - 0s 782us/step - loss: 2.1306\n16/16 [==============================] - 0s 828us/step - loss: 2.1305\n\nTesting for epoch 34 index 3:\n79/79 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 809us/step - loss: 0.1477\n16/16 [==============================] - 0s 1ms/step - loss: 1.7757\n16/16 [==============================] - 0s 1ms/step - loss: 2.1041\n16/16 [==============================] - 0s 820us/step - loss: 2.1998\n16/16 [==============================] - 0s 783us/step - loss: 2.2271\n16/16 [==============================] - 0s 774us/step - loss: 2.2111\n16/16 [==============================] - 0s 783us/step - loss: 2.1877\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 772us/step - loss: 2.1732\n16/16 [==============================] - 0s 817us/step - loss: 2.1731\n\nTesting for epoch 34 index 4:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 807us/step - loss: 0.1443\n16/16 [==============================] - 0s 797us/step - loss: 1.8313\n16/16 [==============================] - 0s 766us/step - loss: 2.1753\n16/16 [==============================] - 0s 775us/step - loss: 2.2750\n16/16 [==============================] - 0s 775us/step - loss: 2.3028\n16/16 [==============================] - 0s 782us/step - loss: 2.2844\n16/16 [==============================] - 0s 778us/step - loss: 2.2581\n16/16 [==============================] - 0s 780us/step - loss: 2.2464\n16/16 [==============================] - 0s 793us/step - loss: 2.2425\n16/16 [==============================] - 0s 798us/step - loss: 2.2424\n\nTesting for epoch 34 index 5:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 779us/step - loss: 0.1507\n16/16 [==============================] - 0s 1ms/step - loss: 1.7991\n16/16 [==============================] - 0s 1ms/step - loss: 2.1385\n16/16 [==============================] - 0s 805us/step - loss: 2.2388\n16/16 [==============================] - 0s 777us/step - loss: 2.2689\n16/16 [==============================] - 0s 769us/step - loss: 2.2553\n16/16 [==============================] - 0s 770us/step - loss: 2.2330\n16/16 [==============================] - 0s 766us/step - loss: 2.2225\n16/16 [==============================] - 0s 796us/step - loss: 2.2189\n16/16 [==============================] - 0s 802us/step - loss: 2.2187\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 810us/step - loss: 0.1468\n16/16 [==============================] - 0s 1000us/step - loss: 1.8167\n16/16 [==============================] - 0s 1ms/step - loss: 2.1570\n16/16 [==============================] - 0s 783us/step - loss: 2.2540\n16/16 [==============================] - 0s 816us/step - loss: 2.2807\n16/16 [==============================] - 0s 980us/step - loss: 2.2621\n16/16 [==============================] - 0s 787us/step - loss: 2.2360\n16/16 [==============================] - 0s 814us/step - loss: 2.2244\n16/16 [==============================] - 0s 805us/step - loss: 2.2204\n16/16 [==============================] - 0s 832us/step - loss: 2.2203\n\nTesting for epoch 35 index 2:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1469\n16/16 [==============================] - 0s 791us/step - loss: 1.8178\n16/16 [==============================] - 0s 775us/step - loss: 2.1558\n16/16 [==============================] - 0s 784us/step - loss: 2.2515\n16/16 [==============================] - 0s 796us/step - loss: 2.2769\n16/16 [==============================] - 0s 783us/step - loss: 2.2571\n16/16 [==============================] - 0s 802us/step - loss: 2.2299\n16/16 [==============================] - 0s 779us/step - loss: 2.2181\n16/16 [==============================] - 0s 811us/step - loss: 2.2141\n16/16 [==============================] - 0s 798us/step - loss: 2.2140\n\nTesting for epoch 35 index 3:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1499\n16/16 [==============================] - 0s 823us/step - loss: 1.7804\n16/16 [==============================] - 0s 814us/step - loss: 2.1084\n16/16 [==============================] - 0s 789us/step - loss: 2.1988\n16/16 [==============================] - 0s 779us/step - loss: 2.2227\n16/16 [==============================] - 0s 772us/step - loss: 2.2030\n16/16 [==============================] - 0s 794us/step - loss: 2.1772\n16/16 [==============================] - 0s 787us/step - loss: 2.1661\n16/16 [==============================] - 0s 822us/step - loss: 2.1624\n16/16 [==============================] - 0s 797us/step - loss: 2.1623\n\nTesting for epoch 35 index 4:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1474\n16/16 [==============================] - 0s 804us/step - loss: 1.7882\n16/16 [==============================] - 0s 816us/step - loss: 2.1206\n16/16 [==============================] - 0s 826us/step - loss: 2.2126\n16/16 [==============================] - 0s 844us/step - loss: 2.2362\n16/16 [==============================] - 0s 804us/step - loss: 2.2145\n16/16 [==============================] - 0s 1ms/step - loss: 2.1867\n16/16 [==============================] - 0s 881us/step - loss: 2.1749\n16/16 [==============================] - 0s 852us/step - loss: 2.1709\n16/16 [==============================] - 0s 785us/step - loss: 2.1708\n\nTesting for epoch 35 index 5:\n79/79 [==============================] - 0s 585us/step\n16/16 [==============================] - 0s 861us/step - loss: 0.1426\n16/16 [==============================] - 0s 1ms/step - loss: 1.8107\n16/16 [==============================] - 0s 762us/step - loss: 2.1481\n16/16 [==============================] - 0s 757us/step - loss: 2.2402\n16/16 [==============================] - 0s 771us/step - loss: 2.2636\n16/16 [==============================] - 0s 772us/step - loss: 2.2406\n16/16 [==============================] - 0s 768us/step - loss: 2.2119\n16/16 [==============================] - 0s 766us/step - loss: 2.1997\n16/16 [==============================] - 0s 765us/step - loss: 2.1956\n16/16 [==============================] - 0s 771us/step - loss: 2.1955\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 782us/step - loss: 0.1440\n16/16 [==============================] - 0s 780us/step - loss: 1.8571\n16/16 [==============================] - 0s 775us/step - loss: 2.2097\n16/16 [==============================] - 0s 779us/step - loss: 2.3070\n16/16 [==============================] - 0s 776us/step - loss: 2.3319\n16/16 [==============================] - 0s 788us/step - loss: 2.3098\n16/16 [==============================] - 0s 1ms/step - loss: 2.2808\n16/16 [==============================] - 0s 1ms/step - loss: 2.2685\n16/16 [==============================] - 0s 800us/step - loss: 2.2645\n16/16 [==============================] - 0s 891us/step - loss: 2.2644\n\nTesting for epoch 36 index 2:\n79/79 [==============================] - 0s 693us/step\n16/16 [==============================] - 0s 833us/step - loss: 0.1417\n16/16 [==============================] - 0s 814us/step - loss: 1.8655\n16/16 [==============================] - 0s 906us/step - loss: 2.2205\n16/16 [==============================] - 0s 829us/step - loss: 2.3178\n16/16 [==============================] - 0s 872us/step - loss: 2.3425\n16/16 [==============================] - 0s 864us/step - loss: 2.3198\n16/16 [==============================] - 0s 792us/step - loss: 2.2908\n16/16 [==============================] - 0s 803us/step - loss: 2.2784\n16/16 [==============================] - 0s 796us/step - loss: 2.2743\n16/16 [==============================] - 0s 821us/step - loss: 2.2743\n\nTesting for epoch 36 index 3:\n79/79 [==============================] - 0s 620us/step\n16/16 [==============================] - 0s 820us/step - loss: 0.1445\n16/16 [==============================] - 0s 830us/step - loss: 1.8152\n16/16 [==============================] - 0s 800us/step - loss: 2.1608\n16/16 [==============================] - 0s 826us/step - loss: 2.2564\n16/16 [==============================] - 0s 814us/step - loss: 2.2806\n16/16 [==============================] - 0s 806us/step - loss: 2.2592\n16/16 [==============================] - 0s 792us/step - loss: 2.2315\n16/16 [==============================] - 0s 823us/step - loss: 2.2197\n16/16 [==============================] - 0s 819us/step - loss: 2.2156\n16/16 [==============================] - 0s 807us/step - loss: 2.2155\n\nTesting for epoch 36 index 4:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.1423\n16/16 [==============================] - 0s 803us/step - loss: 1.8472\n16/16 [==============================] - 0s 782us/step - loss: 2.1950\n16/16 [==============================] - 0s 816us/step - loss: 2.2881\n16/16 [==============================] - 0s 794us/step - loss: 2.3102\n16/16 [==============================] - 0s 786us/step - loss: 2.2857\n16/16 [==============================] - 0s 786us/step - loss: 2.2565\n16/16 [==============================] - 0s 794us/step - loss: 2.2442\n16/16 [==============================] - 0s 788us/step - loss: 2.2402\n16/16 [==============================] - 0s 792us/step - loss: 2.2401\n\nTesting for epoch 36 index 5:\n79/79 [==============================] - 0s 659us/step\n16/16 [==============================] - 0s 872us/step - loss: 0.1383\n16/16 [==============================] - 0s 805us/step - loss: 1.8481\n16/16 [==============================] - 0s 806us/step - loss: 2.2002\n16/16 [==============================] - 0s 807us/step - loss: 2.2955\n16/16 [==============================] - 0s 810us/step - loss: 2.3191\n16/16 [==============================] - 0s 818us/step - loss: 2.2953\n16/16 [==============================] - 0s 846us/step - loss: 2.2663\n16/16 [==============================] - 0s 817us/step - loss: 2.2540\n16/16 [==============================] - 0s 842us/step - loss: 2.2498\n16/16 [==============================] - 0s 808us/step - loss: 2.2496\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1396\n16/16 [==============================] - 0s 800us/step - loss: 1.8411\n16/16 [==============================] - 0s 794us/step - loss: 2.1902\n16/16 [==============================] - 0s 789us/step - loss: 2.2840\n16/16 [==============================] - 0s 805us/step - loss: 2.3066\n16/16 [==============================] - 0s 794us/step - loss: 2.2821\n16/16 [==============================] - 0s 787us/step - loss: 2.2532\n16/16 [==============================] - 0s 790us/step - loss: 2.2411\n16/16 [==============================] - 0s 814us/step - loss: 2.2372\n16/16 [==============================] - 0s 796us/step - loss: 2.2371\n\nTesting for epoch 37 index 2:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1395\n16/16 [==============================] - 0s 832us/step - loss: 1.8573\n16/16 [==============================] - 0s 835us/step - loss: 2.2095\n16/16 [==============================] - 0s 826us/step - loss: 2.3029\n16/16 [==============================] - 0s 804us/step - loss: 2.3241\n16/16 [==============================] - 0s 805us/step - loss: 2.2983\n16/16 [==============================] - 0s 796us/step - loss: 2.2682\n16/16 [==============================] - 0s 807us/step - loss: 2.2556\n16/16 [==============================] - 0s 1ms/step - loss: 2.2513\n16/16 [==============================] - 0s 1ms/step - loss: 2.2511\n\nTesting for epoch 37 index 3:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1401\n16/16 [==============================] - 0s 796us/step - loss: 1.8239\n16/16 [==============================] - 0s 798us/step - loss: 2.1752\n16/16 [==============================] - 0s 804us/step - loss: 2.2721\n16/16 [==============================] - 0s 838us/step - loss: 2.2980\n16/16 [==============================] - 0s 841us/step - loss: 2.2774\n16/16 [==============================] - 0s 820us/step - loss: 2.2510\n16/16 [==============================] - 0s 694us/step - loss: 2.2395\n16/16 [==============================] - 0s 737us/step - loss: 2.2355\n16/16 [==============================] - 0s 689us/step - loss: 2.2353\n\nTesting for epoch 37 index 4:\n79/79 [==============================] - 0s 668us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1385\n16/16 [==============================] - 0s 2ms/step - loss: 1.8566\n16/16 [==============================] - 0s 2ms/step - loss: 2.2037\n16/16 [==============================] - 0s 2ms/step - loss: 2.2918\n16/16 [==============================] - 0s 2ms/step - loss: 2.3097\n16/16 [==============================] - 0s 844us/step - loss: 2.2792\n16/16 [==============================] - 0s 855us/step - loss: 2.2463\n16/16 [==============================] - 0s 2ms/step - loss: 2.2331\n16/16 [==============================] - 0s 2ms/step - loss: 2.2290\n16/16 [==============================] - 0s 769us/step - loss: 2.2290\n\nTesting for epoch 37 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 876us/step - loss: 0.1371\n16/16 [==============================] - 0s 2ms/step - loss: 1.8841\n16/16 [==============================] - 0s 781us/step - loss: 2.2415\n16/16 [==============================] - 0s 754us/step - loss: 2.3349\n16/16 [==============================] - 0s 831us/step - loss: 2.3552\n16/16 [==============================] - 0s 788us/step - loss: 2.3269\n16/16 [==============================] - 0s 832us/step - loss: 2.2956\n16/16 [==============================] - 0s 797us/step - loss: 2.2825\n16/16 [==============================] - 0s 2ms/step - loss: 2.2780\n16/16 [==============================] - 0s 2ms/step - loss: 2.2778\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1392\n16/16 [==============================] - 0s 846us/step - loss: 1.9016\n16/16 [==============================] - 0s 2ms/step - loss: 2.2615\n16/16 [==============================] - 0s 2ms/step - loss: 2.3548\n16/16 [==============================] - 0s 2ms/step - loss: 2.3744\n16/16 [==============================] - 0s 783us/step - loss: 2.3445\n16/16 [==============================] - 0s 1ms/step - loss: 2.3121\n16/16 [==============================] - 0s 2ms/step - loss: 2.2989\n16/16 [==============================] - 0s 2ms/step - loss: 2.2947\n16/16 [==============================] - 0s 1ms/step - loss: 2.2946\n\nTesting for epoch 38 index 2:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1370\n16/16 [==============================] - 0s 2ms/step - loss: 1.8808\n16/16 [==============================] - 0s 2ms/step - loss: 2.2309\n16/16 [==============================] - 0s 803us/step - loss: 2.3252\n16/16 [==============================] - 0s 2ms/step - loss: 2.3458\n16/16 [==============================] - 0s 2ms/step - loss: 2.3187\n16/16 [==============================] - 0s 2ms/step - loss: 2.2874\n16/16 [==============================] - 0s 840us/step - loss: 2.2746\n16/16 [==============================] - 0s 2ms/step - loss: 2.2703\n16/16 [==============================] - 0s 805us/step - loss: 2.2702\n\nTesting for epoch 38 index 3:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1335\n16/16 [==============================] - 0s 2ms/step - loss: 1.9326\n16/16 [==============================] - 0s 2ms/step - loss: 2.2893\n16/16 [==============================] - 0s 804us/step - loss: 2.3820\n16/16 [==============================] - 0s 2ms/step - loss: 2.3984\n16/16 [==============================] - 0s 817us/step - loss: 2.3647\n16/16 [==============================] - 0s 2ms/step - loss: 2.3292\n16/16 [==============================] - 0s 2ms/step - loss: 2.3153\n16/16 [==============================] - 0s 883us/step - loss: 2.3110\n16/16 [==============================] - 0s 2ms/step - loss: 2.3111\n\nTesting for epoch 38 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 849us/step - loss: 0.1333\n16/16 [==============================] - 0s 805us/step - loss: 1.9265\n16/16 [==============================] - 0s 793us/step - loss: 2.2845\n16/16 [==============================] - 0s 815us/step - loss: 2.3802\n16/16 [==============================] - 0s 808us/step - loss: 2.3993\n16/16 [==============================] - 0s 818us/step - loss: 2.3696\n16/16 [==============================] - 0s 2ms/step - loss: 2.3358\n16/16 [==============================] - 0s 800us/step - loss: 2.3221\n16/16 [==============================] - 0s 792us/step - loss: 2.3175\n16/16 [==============================] - 0s 2ms/step - loss: 2.3173\n\nTesting for epoch 38 index 5:\n79/79 [==============================] - 0s 759us/step\n16/16 [==============================] - 0s 844us/step - loss: 0.1361\n16/16 [==============================] - 0s 833us/step - loss: 1.9262\n16/16 [==============================] - 0s 799us/step - loss: 2.2858\n16/16 [==============================] - 0s 2ms/step - loss: 2.3821\n16/16 [==============================] - 0s 814us/step - loss: 2.4018\n16/16 [==============================] - 0s 2ms/step - loss: 2.3724\n16/16 [==============================] - 0s 2ms/step - loss: 2.3391\n16/16 [==============================] - 0s 833us/step - loss: 2.3258\n16/16 [==============================] - 0s 814us/step - loss: 2.3215\n16/16 [==============================] - 0s 823us/step - loss: 2.3214\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 833us/step - loss: 0.1330\n16/16 [==============================] - 0s 1ms/step - loss: 1.8945\n16/16 [==============================] - 0s 2ms/step - loss: 2.2436\n16/16 [==============================] - 0s 1ms/step - loss: 2.3363\n16/16 [==============================] - 0s 911us/step - loss: 2.3546\n16/16 [==============================] - 0s 808us/step - loss: 2.3242\n16/16 [==============================] - 0s 2ms/step - loss: 2.2909\n16/16 [==============================] - 0s 2ms/step - loss: 2.2776\n16/16 [==============================] - 0s 2ms/step - loss: 2.2733\n16/16 [==============================] - 0s 791us/step - loss: 2.2731\n\nTesting for epoch 39 index 2:\n79/79 [==============================] - 0s 929us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1358\n16/16 [==============================] - 0s 2ms/step - loss: 1.8447\n16/16 [==============================] - 0s 832us/step - loss: 2.1816\n16/16 [==============================] - 0s 795us/step - loss: 2.2687\n16/16 [==============================] - 0s 807us/step - loss: 2.2848\n16/16 [==============================] - 0s 2ms/step - loss: 2.2549\n16/16 [==============================] - 0s 1ms/step - loss: 2.2232\n16/16 [==============================] - 0s 919us/step - loss: 2.2103\n16/16 [==============================] - 0s 2ms/step - loss: 2.2061\n16/16 [==============================] - 0s 787us/step - loss: 2.2059\n\nTesting for epoch 39 index 3:\n79/79 [==============================] - 0s 533us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1353\n16/16 [==============================] - 0s 1ms/step - loss: 1.9032\n16/16 [==============================] - 0s 2ms/step - loss: 2.2511\n16/16 [==============================] - 0s 2ms/step - loss: 2.3409\n16/16 [==============================] - 0s 780us/step - loss: 2.3580\n16/16 [==============================] - 0s 891us/step - loss: 2.3288\n16/16 [==============================] - 0s 863us/step - loss: 2.2962\n16/16 [==============================] - 0s 876us/step - loss: 2.2830\n16/16 [==============================] - 0s 1ms/step - loss: 2.2787\n16/16 [==============================] - 0s 937us/step - loss: 2.2786\n\nTesting for epoch 39 index 4:\n79/79 [==============================] - 0s 781us/step\n16/16 [==============================] - 0s 835us/step - loss: 0.1367\n16/16 [==============================] - 0s 2ms/step - loss: 1.9084\n16/16 [==============================] - 0s 990us/step - loss: 2.2575\n16/16 [==============================] - 0s 814us/step - loss: 2.3489\n16/16 [==============================] - 0s 777us/step - loss: 2.3668\n16/16 [==============================] - 0s 782us/step - loss: 2.3375\n16/16 [==============================] - 0s 714us/step - loss: 2.3043\n16/16 [==============================] - 0s 1ms/step - loss: 2.2911\n16/16 [==============================] - 0s 649us/step - loss: 2.2868\n16/16 [==============================] - 0s 790us/step - loss: 2.2867\n\nTesting for epoch 39 index 5:\n79/79 [==============================] - 0s 661us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1330\n16/16 [==============================] - 0s 780us/step - loss: 1.9413\n16/16 [==============================] - 0s 778us/step - loss: 2.3006\n16/16 [==============================] - 0s 786us/step - loss: 2.3940\n16/16 [==============================] - 0s 804us/step - loss: 2.4106\n16/16 [==============================] - 0s 791us/step - loss: 2.3794\n16/16 [==============================] - 0s 780us/step - loss: 2.3453\n16/16 [==============================] - 0s 779us/step - loss: 2.3317\n16/16 [==============================] - 0s 815us/step - loss: 2.3272\n16/16 [==============================] - 0s 790us/step - loss: 2.3271\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1342\n16/16 [==============================] - 0s 1ms/step - loss: 1.9180\n16/16 [==============================] - 0s 1ms/step - loss: 2.2724\n16/16 [==============================] - 0s 1ms/step - loss: 2.3660\n16/16 [==============================] - 0s 1ms/step - loss: 2.3839\n16/16 [==============================] - 0s 781us/step - loss: 2.3552\n16/16 [==============================] - 0s 1ms/step - loss: 2.3228\n16/16 [==============================] - 0s 788us/step - loss: 2.3097\n16/16 [==============================] - 0s 800us/step - loss: 2.3054\n16/16 [==============================] - 0s 800us/step - loss: 2.3052\n\nTesting for epoch 40 index 2:\n79/79 [==============================] - 0s 583us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1336\n16/16 [==============================] - 0s 806us/step - loss: 1.8845\n16/16 [==============================] - 0s 785us/step - loss: 2.2270\n16/16 [==============================] - 0s 789us/step - loss: 2.3128\n16/16 [==============================] - 0s 803us/step - loss: 2.3252\n16/16 [==============================] - 0s 807us/step - loss: 2.2901\n16/16 [==============================] - 0s 789us/step - loss: 2.2552\n16/16 [==============================] - 0s 803us/step - loss: 2.2418\n16/16 [==============================] - 0s 903us/step - loss: 2.2374\n16/16 [==============================] - 0s 860us/step - loss: 2.2373\n\nTesting for epoch 40 index 3:\n79/79 [==============================] - 0s 587us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1321\n16/16 [==============================] - 0s 817us/step - loss: 1.9400\n16/16 [==============================] - 0s 819us/step - loss: 2.2933\n16/16 [==============================] - 0s 825us/step - loss: 2.3799\n16/16 [==============================] - 0s 819us/step - loss: 2.3924\n16/16 [==============================] - 0s 885us/step - loss: 2.3564\n16/16 [==============================] - 0s 882us/step - loss: 2.3207\n16/16 [==============================] - 0s 823us/step - loss: 2.3070\n16/16 [==============================] - 0s 865us/step - loss: 2.3027\n16/16 [==============================] - 0s 803us/step - loss: 2.3027\n\nTesting for epoch 40 index 4:\n79/79 [==============================] - 0s 669us/step\n16/16 [==============================] - 0s 815us/step - loss: 0.1334\n16/16 [==============================] - 0s 833us/step - loss: 1.9022\n16/16 [==============================] - 0s 806us/step - loss: 2.2463\n16/16 [==============================] - 0s 796us/step - loss: 2.3297\n16/16 [==============================] - 0s 790us/step - loss: 2.3413\n16/16 [==============================] - 0s 790us/step - loss: 2.3067\n16/16 [==============================] - 0s 791us/step - loss: 2.2727\n16/16 [==============================] - 0s 828us/step - loss: 2.2595\n16/16 [==============================] - 0s 819us/step - loss: 2.2552\n16/16 [==============================] - 0s 798us/step - loss: 2.2550\n\nTesting for epoch 40 index 5:\n79/79 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.1269\n16/16 [==============================] - 0s 804us/step - loss: 1.9772\n16/16 [==============================] - 0s 796us/step - loss: 2.3427\n16/16 [==============================] - 0s 779us/step - loss: 2.4319\n16/16 [==============================] - 0s 792us/step - loss: 2.4454\n16/16 [==============================] - 0s 806us/step - loss: 2.4078\n16/16 [==============================] - 0s 804us/step - loss: 2.3714\n16/16 [==============================] - 0s 817us/step - loss: 2.3572\n16/16 [==============================] - 0s 854us/step - loss: 2.3526\n16/16 [==============================] - 0s 889us/step - loss: 2.3524\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n79/79 [==============================] - 0s 862us/step\n16/16 [==============================] - 0s 846us/step - loss: 0.1301\n16/16 [==============================] - 0s 833us/step - loss: 1.9242\n16/16 [==============================] - 0s 1ms/step - loss: 2.2728\n16/16 [==============================] - 0s 814us/step - loss: 2.3565\n16/16 [==============================] - 0s 834us/step - loss: 2.3696\n16/16 [==============================] - 0s 832us/step - loss: 2.3336\n16/16 [==============================] - 0s 849us/step - loss: 2.2979\n16/16 [==============================] - 0s 895us/step - loss: 2.2839\n16/16 [==============================] - 0s 835us/step - loss: 2.2793\n16/16 [==============================] - 0s 842us/step - loss: 2.2791\n\nTesting for epoch 41 index 2:\n79/79 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 832us/step - loss: 0.1314\n16/16 [==============================] - 0s 845us/step - loss: 1.9663\n16/16 [==============================] - 0s 874us/step - loss: 2.3249\n16/16 [==============================] - 0s 816us/step - loss: 2.4099\n16/16 [==============================] - 0s 824us/step - loss: 2.4224\n16/16 [==============================] - 0s 826us/step - loss: 2.3848\n16/16 [==============================] - 0s 849us/step - loss: 2.3482\n16/16 [==============================] - 0s 800us/step - loss: 2.3341\n16/16 [==============================] - 0s 856us/step - loss: 2.3296\n16/16 [==============================] - 0s 797us/step - loss: 2.3295\n\nTesting for epoch 41 index 3:\n79/79 [==============================] - 0s 719us/step\n16/16 [==============================] - 0s 843us/step - loss: 0.1290\n16/16 [==============================] - 0s 858us/step - loss: 2.0148\n16/16 [==============================] - 0s 784us/step - loss: 2.3873\n16/16 [==============================] - 0s 856us/step - loss: 2.4746\n16/16 [==============================] - 0s 835us/step - loss: 2.4879\n16/16 [==============================] - 0s 810us/step - loss: 2.4474\n16/16 [==============================] - 0s 865us/step - loss: 2.4088\n16/16 [==============================] - 0s 884us/step - loss: 2.3940\n16/16 [==============================] - 0s 869us/step - loss: 2.3894\n16/16 [==============================] - 0s 785us/step - loss: 2.3893\n\nTesting for epoch 41 index 4:\n79/79 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1312\n16/16 [==============================] - 0s 807us/step - loss: 1.9137\n16/16 [==============================] - 0s 1ms/step - loss: 2.2591\n16/16 [==============================] - 0s 798us/step - loss: 2.3380\n16/16 [==============================] - 0s 1ms/step - loss: 2.3479\n16/16 [==============================] - 0s 1ms/step - loss: 2.3084\n16/16 [==============================] - 0s 830us/step - loss: 2.2720\n16/16 [==============================] - 0s 788us/step - loss: 2.2582\n16/16 [==============================] - 0s 795us/step - loss: 2.2539\n16/16 [==============================] - 0s 855us/step - loss: 2.2538\n\nTesting for epoch 41 index 5:\n79/79 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 857us/step - loss: 0.1289\n16/16 [==============================] - 0s 817us/step - loss: 1.9509\n16/16 [==============================] - 0s 905us/step - loss: 2.3031\n16/16 [==============================] - 0s 799us/step - loss: 2.3834\n16/16 [==============================] - 0s 915us/step - loss: 2.3938\n16/16 [==============================] - 0s 1ms/step - loss: 2.3538\n16/16 [==============================] - 0s 911us/step - loss: 2.3167\n16/16 [==============================] - 0s 934us/step - loss: 2.3026\n16/16 [==============================] - 0s 891us/step - loss: 2.2981\n16/16 [==============================] - 0s 866us/step - loss: 2.2980\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1312\n16/16 [==============================] - 0s 3ms/step - loss: 1.9436\n16/16 [==============================] - 0s 1ms/step - loss: 2.2942\n16/16 [==============================] - 0s 1ms/step - loss: 2.3728\n16/16 [==============================] - 0s 801us/step - loss: 2.3809\n16/16 [==============================] - 0s 1ms/step - loss: 2.3390\n16/16 [==============================] - 0s 881us/step - loss: 2.3013\n16/16 [==============================] - 0s 818us/step - loss: 2.2872\n16/16 [==============================] - 0s 807us/step - loss: 2.2829\n16/16 [==============================] - 0s 794us/step - loss: 2.2830\n\nTesting for epoch 42 index 2:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 830us/step - loss: 0.1277\n16/16 [==============================] - 0s 825us/step - loss: 1.9867\n16/16 [==============================] - 0s 818us/step - loss: 2.3500\n16/16 [==============================] - 0s 797us/step - loss: 2.4348\n16/16 [==============================] - 0s 795us/step - loss: 2.4465\n16/16 [==============================] - 0s 798us/step - loss: 2.4073\n16/16 [==============================] - 0s 790us/step - loss: 2.3709\n16/16 [==============================] - 0s 803us/step - loss: 2.3569\n16/16 [==============================] - 0s 799us/step - loss: 2.3525\n16/16 [==============================] - 0s 796us/step - loss: 2.3524\n\nTesting for epoch 42 index 3:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1334\n16/16 [==============================] - 0s 821us/step - loss: 1.9570\n16/16 [==============================] - 0s 806us/step - loss: 2.3121\n16/16 [==============================] - 0s 808us/step - loss: 2.3937\n16/16 [==============================] - 0s 805us/step - loss: 2.4031\n16/16 [==============================] - 0s 824us/step - loss: 2.3619\n16/16 [==============================] - 0s 808us/step - loss: 2.3245\n16/16 [==============================] - 0s 827us/step - loss: 2.3104\n16/16 [==============================] - 0s 827us/step - loss: 2.3060\n16/16 [==============================] - 0s 813us/step - loss: 2.3059\n\nTesting for epoch 42 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1268\n16/16 [==============================] - 0s 794us/step - loss: 1.9501\n16/16 [==============================] - 0s 868us/step - loss: 2.3015\n16/16 [==============================] - 0s 822us/step - loss: 2.3798\n16/16 [==============================] - 0s 828us/step - loss: 2.3880\n16/16 [==============================] - 0s 789us/step - loss: 2.3466\n16/16 [==============================] - 0s 802us/step - loss: 2.3094\n16/16 [==============================] - 0s 821us/step - loss: 2.2953\n16/16 [==============================] - 0s 815us/step - loss: 2.2908\n16/16 [==============================] - 0s 839us/step - loss: 2.2906\n\nTesting for epoch 42 index 5:\n79/79 [==============================] - 0s 730us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1280\n16/16 [==============================] - 0s 1ms/step - loss: 1.9975\n16/16 [==============================] - 0s 805us/step - loss: 2.3589\n16/16 [==============================] - 0s 798us/step - loss: 2.4382\n16/16 [==============================] - 0s 829us/step - loss: 2.4454\n16/16 [==============================] - 0s 821us/step - loss: 2.4015\n16/16 [==============================] - 0s 797us/step - loss: 2.3619\n16/16 [==============================] - 0s 1ms/step - loss: 2.3472\n16/16 [==============================] - 0s 815us/step - loss: 2.3427\n16/16 [==============================] - 0s 813us/step - loss: 2.3427\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1275\n16/16 [==============================] - 0s 1ms/step - loss: 2.0014\n16/16 [==============================] - 0s 773us/step - loss: 2.3669\n16/16 [==============================] - 0s 771us/step - loss: 2.4493\n16/16 [==============================] - 0s 1ms/step - loss: 2.4593\n16/16 [==============================] - 0s 1ms/step - loss: 2.4179\n16/16 [==============================] - 0s 1ms/step - loss: 2.3796\n16/16 [==============================] - 0s 1ms/step - loss: 2.3652\n16/16 [==============================] - 0s 1ms/step - loss: 2.3606\n16/16 [==============================] - 0s 787us/step - loss: 2.3604\n\nTesting for epoch 43 index 2:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1274\n16/16 [==============================] - 0s 800us/step - loss: 1.9885\n16/16 [==============================] - 0s 800us/step - loss: 2.3486\n16/16 [==============================] - 0s 793us/step - loss: 2.4281\n16/16 [==============================] - 0s 810us/step - loss: 2.4365\n16/16 [==============================] - 0s 805us/step - loss: 2.3939\n16/16 [==============================] - 0s 806us/step - loss: 2.3558\n16/16 [==============================] - 0s 830us/step - loss: 2.3415\n16/16 [==============================] - 0s 830us/step - loss: 2.3370\n16/16 [==============================] - 0s 812us/step - loss: 2.3370\n\nTesting for epoch 43 index 3:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 810us/step - loss: 0.1306\n16/16 [==============================] - 0s 811us/step - loss: 1.9621\n16/16 [==============================] - 0s 817us/step - loss: 2.3132\n16/16 [==============================] - 0s 805us/step - loss: 2.3880\n16/16 [==============================] - 0s 784us/step - loss: 2.3952\n16/16 [==============================] - 0s 820us/step - loss: 2.3532\n16/16 [==============================] - 0s 793us/step - loss: 2.3157\n16/16 [==============================] - 0s 778us/step - loss: 2.3018\n16/16 [==============================] - 0s 786us/step - loss: 2.2976\n16/16 [==============================] - 0s 785us/step - loss: 2.2976\n\nTesting for epoch 43 index 4:\n79/79 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1253\n16/16 [==============================] - 0s 825us/step - loss: 2.0501\n16/16 [==============================] - 0s 816us/step - loss: 2.4197\n16/16 [==============================] - 0s 851us/step - loss: 2.4972\n16/16 [==============================] - 0s 822us/step - loss: 2.5028\n16/16 [==============================] - 0s 876us/step - loss: 2.4551\n16/16 [==============================] - 0s 910us/step - loss: 2.4127\n16/16 [==============================] - 0s 879us/step - loss: 2.3973\n16/16 [==============================] - 0s 871us/step - loss: 2.3927\n16/16 [==============================] - 0s 818us/step - loss: 2.3928\n\nTesting for epoch 43 index 5:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 828us/step - loss: 0.1265\n16/16 [==============================] - 0s 801us/step - loss: 2.0007\n16/16 [==============================] - 0s 796us/step - loss: 2.3614\n16/16 [==============================] - 0s 798us/step - loss: 2.4380\n16/16 [==============================] - 0s 812us/step - loss: 2.4449\n16/16 [==============================] - 0s 809us/step - loss: 2.4011\n16/16 [==============================] - 0s 821us/step - loss: 2.3625\n16/16 [==============================] - 0s 811us/step - loss: 2.3483\n16/16 [==============================] - 0s 815us/step - loss: 2.3439\n16/16 [==============================] - 0s 808us/step - loss: 2.3438\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1299\n16/16 [==============================] - 0s 803us/step - loss: 1.9974\n16/16 [==============================] - 0s 782us/step - loss: 2.3529\n16/16 [==============================] - 0s 792us/step - loss: 2.4269\n16/16 [==============================] - 0s 795us/step - loss: 2.4322\n16/16 [==============================] - 0s 797us/step - loss: 2.3865\n16/16 [==============================] - 0s 805us/step - loss: 2.3467\n16/16 [==============================] - 0s 805us/step - loss: 2.3323\n16/16 [==============================] - 0s 795us/step - loss: 2.3279\n16/16 [==============================] - 0s 793us/step - loss: 2.3279\n\nTesting for epoch 44 index 2:\n79/79 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1263\n16/16 [==============================] - 0s 809us/step - loss: 2.0233\n16/16 [==============================] - 0s 809us/step - loss: 2.3927\n16/16 [==============================] - 0s 835us/step - loss: 2.4734\n16/16 [==============================] - 0s 809us/step - loss: 2.4828\n16/16 [==============================] - 0s 835us/step - loss: 2.4407\n16/16 [==============================] - 0s 810us/step - loss: 2.4019\n16/16 [==============================] - 0s 906us/step - loss: 2.3872\n16/16 [==============================] - 0s 824us/step - loss: 2.3824\n16/16 [==============================] - 0s 789us/step - loss: 2.3822\n\nTesting for epoch 44 index 3:\n79/79 [==============================] - 0s 595us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1234\n16/16 [==============================] - 0s 929us/step - loss: 2.0523\n16/16 [==============================] - 0s 784us/step - loss: 2.4219\n16/16 [==============================] - 0s 829us/step - loss: 2.4981\n16/16 [==============================] - 0s 831us/step - loss: 2.5027\n16/16 [==============================] - 0s 805us/step - loss: 2.4546\n16/16 [==============================] - 0s 1ms/step - loss: 2.4132\n16/16 [==============================] - 0s 1ms/step - loss: 2.3981\n16/16 [==============================] - 0s 1ms/step - loss: 2.3935\n16/16 [==============================] - 0s 1ms/step - loss: 2.3934\n\nTesting for epoch 44 index 4:\n79/79 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1256\n16/16 [==============================] - 0s 787us/step - loss: 1.9662\n16/16 [==============================] - 0s 788us/step - loss: 2.3195\n16/16 [==============================] - 0s 787us/step - loss: 2.3944\n16/16 [==============================] - 0s 790us/step - loss: 2.4012\n16/16 [==============================] - 0s 790us/step - loss: 2.3588\n16/16 [==============================] - 0s 795us/step - loss: 2.3210\n16/16 [==============================] - 0s 790us/step - loss: 2.3069\n16/16 [==============================] - 0s 788us/step - loss: 2.3024\n16/16 [==============================] - 0s 801us/step - loss: 2.3022\n\nTesting for epoch 44 index 5:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1243\n16/16 [==============================] - 0s 807us/step - loss: 2.0090\n16/16 [==============================] - 0s 838us/step - loss: 2.3705\n16/16 [==============================] - 0s 823us/step - loss: 2.4464\n16/16 [==============================] - 0s 817us/step - loss: 2.4520\n16/16 [==============================] - 0s 803us/step - loss: 2.4062\n16/16 [==============================] - 0s 809us/step - loss: 2.3657\n16/16 [==============================] - 0s 829us/step - loss: 2.3510\n16/16 [==============================] - 0s 824us/step - loss: 2.3466\n16/16 [==============================] - 0s 796us/step - loss: 2.3466\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n79/79 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1223\n16/16 [==============================] - 0s 1ms/step - loss: 2.0306\n16/16 [==============================] - 0s 1ms/step - loss: 2.3982\n16/16 [==============================] - 0s 1ms/step - loss: 2.4740\n16/16 [==============================] - 0s 806us/step - loss: 2.4773\n16/16 [==============================] - 0s 825us/step - loss: 2.4287\n16/16 [==============================] - 0s 821us/step - loss: 2.3869\n16/16 [==============================] - 0s 791us/step - loss: 2.3718\n16/16 [==============================] - 0s 1ms/step - loss: 2.3672\n16/16 [==============================] - 0s 791us/step - loss: 2.3671\n\nTesting for epoch 45 index 2:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1210\n16/16 [==============================] - 0s 791us/step - loss: 2.0704\n16/16 [==============================] - 0s 1ms/step - loss: 2.4462\n16/16 [==============================] - 0s 1ms/step - loss: 2.5242\n16/16 [==============================] - 0s 1ms/step - loss: 2.5296\n16/16 [==============================] - 0s 1ms/step - loss: 2.4812\n16/16 [==============================] - 0s 1ms/step - loss: 2.4387\n16/16 [==============================] - 0s 1ms/step - loss: 2.4232\n16/16 [==============================] - 0s 1ms/step - loss: 2.4184\n16/16 [==============================] - 0s 786us/step - loss: 2.4183\n\nTesting for epoch 45 index 3:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1213\n16/16 [==============================] - 0s 1ms/step - loss: 2.0630\n16/16 [==============================] - 0s 1ms/step - loss: 2.4339\n16/16 [==============================] - 0s 791us/step - loss: 2.5090\n16/16 [==============================] - 0s 1ms/step - loss: 2.5119\n16/16 [==============================] - 0s 1ms/step - loss: 2.4617\n16/16 [==============================] - 0s 796us/step - loss: 2.4184\n16/16 [==============================] - 0s 790us/step - loss: 2.4027\n16/16 [==============================] - 0s 787us/step - loss: 2.3979\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n\nTesting for epoch 45 index 4:\n79/79 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1207\n16/16 [==============================] - 0s 1ms/step - loss: 2.0925\n16/16 [==============================] - 0s 916us/step - loss: 2.4711\n16/16 [==============================] - 0s 783us/step - loss: 2.5501\n16/16 [==============================] - 0s 783us/step - loss: 2.5549\n16/16 [==============================] - 0s 826us/step - loss: 2.5060\n16/16 [==============================] - 0s 813us/step - loss: 2.4629\n16/16 [==============================] - 0s 857us/step - loss: 2.4472\n16/16 [==============================] - 0s 1ms/step - loss: 2.4425\n16/16 [==============================] - 0s 1ms/step - loss: 2.4424\n\nTesting for epoch 45 index 5:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 797us/step - loss: 0.1209\n16/16 [==============================] - 0s 794us/step - loss: 2.0450\n16/16 [==============================] - 0s 781us/step - loss: 2.4120\n16/16 [==============================] - 0s 811us/step - loss: 2.4853\n16/16 [==============================] - 0s 1ms/step - loss: 2.4875\n16/16 [==============================] - 0s 1ms/step - loss: 2.4384\n16/16 [==============================] - 0s 1ms/step - loss: 2.3963\n16/16 [==============================] - 0s 1ms/step - loss: 2.3811\n16/16 [==============================] - 0s 807us/step - loss: 2.3765\n16/16 [==============================] - 0s 797us/step - loss: 2.3764\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1157\n16/16 [==============================] - 0s 803us/step - loss: 2.0892\n16/16 [==============================] - 0s 783us/step - loss: 2.4688\n16/16 [==============================] - 0s 779us/step - loss: 2.5448\n16/16 [==============================] - 0s 790us/step - loss: 2.5463\n16/16 [==============================] - 0s 791us/step - loss: 2.4953\n16/16 [==============================] - 0s 788us/step - loss: 2.4526\n16/16 [==============================] - 0s 786us/step - loss: 2.4370\n16/16 [==============================] - 0s 788us/step - loss: 2.4322\n16/16 [==============================] - 0s 792us/step - loss: 2.4321\n\nTesting for epoch 46 index 2:\n79/79 [==============================] - 0s 599us/step\n16/16 [==============================] - 0s 784us/step - loss: 0.1203\n16/16 [==============================] - 0s 786us/step - loss: 2.0153\n16/16 [==============================] - 0s 774us/step - loss: 2.3790\n16/16 [==============================] - 0s 782us/step - loss: 2.4528\n16/16 [==============================] - 0s 786us/step - loss: 2.4549\n16/16 [==============================] - 0s 791us/step - loss: 2.4069\n16/16 [==============================] - 0s 776us/step - loss: 2.3664\n16/16 [==============================] - 0s 778us/step - loss: 2.3517\n16/16 [==============================] - 0s 772us/step - loss: 2.3471\n16/16 [==============================] - 0s 782us/step - loss: 2.3469\n\nTesting for epoch 46 index 3:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1176\n16/16 [==============================] - 0s 784us/step - loss: 2.0705\n16/16 [==============================] - 0s 780us/step - loss: 2.4423\n16/16 [==============================] - 0s 778us/step - loss: 2.5156\n16/16 [==============================] - 0s 787us/step - loss: 2.5160\n16/16 [==============================] - 0s 775us/step - loss: 2.4639\n16/16 [==============================] - 0s 780us/step - loss: 2.4200\n16/16 [==============================] - 0s 783us/step - loss: 2.4040\n16/16 [==============================] - 0s 779us/step - loss: 2.3992\n16/16 [==============================] - 0s 780us/step - loss: 2.3991\n\nTesting for epoch 46 index 4:\n79/79 [==============================] - 0s 610us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1199\n16/16 [==============================] - 0s 796us/step - loss: 2.0859\n16/16 [==============================] - 0s 808us/step - loss: 2.4654\n16/16 [==============================] - 0s 790us/step - loss: 2.5423\n16/16 [==============================] - 0s 787us/step - loss: 2.5441\n16/16 [==============================] - 0s 1ms/step - loss: 2.4922\n16/16 [==============================] - 0s 781us/step - loss: 2.4480\n16/16 [==============================] - 0s 794us/step - loss: 2.4320\n16/16 [==============================] - 0s 800us/step - loss: 2.4271\n16/16 [==============================] - 0s 783us/step - loss: 2.4269\n\nTesting for epoch 46 index 5:\n79/79 [==============================] - 0s 594us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1187\n16/16 [==============================] - 0s 794us/step - loss: 2.0720\n16/16 [==============================] - 0s 787us/step - loss: 2.4514\n16/16 [==============================] - 0s 784us/step - loss: 2.5300\n16/16 [==============================] - 0s 806us/step - loss: 2.5335\n16/16 [==============================] - 0s 798us/step - loss: 2.4858\n16/16 [==============================] - 0s 802us/step - loss: 2.4440\n16/16 [==============================] - 0s 798us/step - loss: 2.4288\n16/16 [==============================] - 0s 794us/step - loss: 2.4241\n16/16 [==============================] - 0s 794us/step - loss: 2.4240\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1168\n16/16 [==============================] - 0s 779us/step - loss: 2.0878\n16/16 [==============================] - 0s 786us/step - loss: 2.4644\n16/16 [==============================] - 0s 803us/step - loss: 2.5367\n16/16 [==============================] - 0s 800us/step - loss: 2.5353\n16/16 [==============================] - 0s 821us/step - loss: 2.4811\n16/16 [==============================] - 0s 796us/step - loss: 2.4357\n16/16 [==============================] - 0s 793us/step - loss: 2.4197\n16/16 [==============================] - 0s 784us/step - loss: 2.4149\n16/16 [==============================] - 0s 793us/step - loss: 2.4149\n\nTesting for epoch 47 index 2:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1129\n16/16 [==============================] - 0s 863us/step - loss: 2.1291\n16/16 [==============================] - 0s 866us/step - loss: 2.5159\n16/16 [==============================] - 0s 877us/step - loss: 2.5921\n16/16 [==============================] - 0s 791us/step - loss: 2.5924\n16/16 [==============================] - 0s 785us/step - loss: 2.5399\n16/16 [==============================] - 0s 793us/step - loss: 2.4954\n16/16 [==============================] - 0s 794us/step - loss: 2.4795\n16/16 [==============================] - 0s 808us/step - loss: 2.4746\n16/16 [==============================] - 0s 813us/step - loss: 2.4745\n\nTesting for epoch 47 index 3:\n79/79 [==============================] - 0s 591us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1157\n16/16 [==============================] - 0s 801us/step - loss: 2.0875\n16/16 [==============================] - 0s 797us/step - loss: 2.4622\n16/16 [==============================] - 0s 793us/step - loss: 2.5350\n16/16 [==============================] - 0s 793us/step - loss: 2.5349\n16/16 [==============================] - 0s 802us/step - loss: 2.4821\n16/16 [==============================] - 0s 803us/step - loss: 2.4374\n16/16 [==============================] - 0s 803us/step - loss: 2.4214\n16/16 [==============================] - 0s 790us/step - loss: 2.4166\n16/16 [==============================] - 0s 784us/step - loss: 2.4165\n\nTesting for epoch 47 index 4:\n79/79 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1148\n16/16 [==============================] - 0s 780us/step - loss: 2.1379\n16/16 [==============================] - 0s 809us/step - loss: 2.5248\n16/16 [==============================] - 0s 780us/step - loss: 2.5999\n16/16 [==============================] - 0s 872us/step - loss: 2.5989\n16/16 [==============================] - 0s 866us/step - loss: 2.5435\n16/16 [==============================] - 0s 863us/step - loss: 2.4969\n16/16 [==============================] - 0s 863us/step - loss: 2.4802\n16/16 [==============================] - 0s 787us/step - loss: 2.4751\n16/16 [==============================] - 0s 859us/step - loss: 2.4750\n\nTesting for epoch 47 index 5:\n79/79 [==============================] - 0s 580us/step\n16/16 [==============================] - 0s 790us/step - loss: 0.1154\n16/16 [==============================] - 0s 786us/step - loss: 2.0392\n16/16 [==============================] - 0s 788us/step - loss: 2.4002\n16/16 [==============================] - 0s 784us/step - loss: 2.4684\n16/16 [==============================] - 0s 795us/step - loss: 2.4659\n16/16 [==============================] - 0s 801us/step - loss: 2.4131\n16/16 [==============================] - 0s 824us/step - loss: 2.3696\n16/16 [==============================] - 0s 790us/step - loss: 2.3543\n16/16 [==============================] - 0s 812us/step - loss: 2.3497\n16/16 [==============================] - 0s 795us/step - loss: 2.3497\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n79/79 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 876us/step - loss: 0.1150\n16/16 [==============================] - 0s 864us/step - loss: 2.1081\n16/16 [==============================] - 0s 861us/step - loss: 2.4903\n16/16 [==============================] - 0s 856us/step - loss: 2.5626\n16/16 [==============================] - 0s 862us/step - loss: 2.5596\n16/16 [==============================] - 0s 865us/step - loss: 2.5044\n16/16 [==============================] - 0s 865us/step - loss: 2.4593\n16/16 [==============================] - 0s 870us/step - loss: 2.4434\n16/16 [==============================] - 0s 875us/step - loss: 2.4386\n16/16 [==============================] - 0s 808us/step - loss: 2.4386\n\nTesting for epoch 48 index 2:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1147\n16/16 [==============================] - 0s 781us/step - loss: 2.1044\n16/16 [==============================] - 0s 779us/step - loss: 2.4888\n16/16 [==============================] - 0s 782us/step - loss: 2.5643\n16/16 [==============================] - 0s 825us/step - loss: 2.5644\n16/16 [==============================] - 0s 801us/step - loss: 2.5118\n16/16 [==============================] - 0s 819us/step - loss: 2.4675\n16/16 [==============================] - 0s 796us/step - loss: 2.4516\n16/16 [==============================] - 0s 786us/step - loss: 2.4465\n16/16 [==============================] - 0s 779us/step - loss: 2.4463\n\nTesting for epoch 48 index 3:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1152\n16/16 [==============================] - 0s 774us/step - loss: 2.0719\n16/16 [==============================] - 0s 786us/step - loss: 2.4408\n16/16 [==============================] - 0s 809us/step - loss: 2.5109\n16/16 [==============================] - 0s 793us/step - loss: 2.5086\n16/16 [==============================] - 0s 795us/step - loss: 2.4552\n16/16 [==============================] - 0s 811us/step - loss: 2.4115\n16/16 [==============================] - 0s 797us/step - loss: 2.3960\n16/16 [==============================] - 0s 824us/step - loss: 2.3913\n16/16 [==============================] - 0s 818us/step - loss: 2.3912\n\nTesting for epoch 48 index 4:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 802us/step - loss: 0.1107\n16/16 [==============================] - 0s 795us/step - loss: 2.1577\n16/16 [==============================] - 0s 857us/step - loss: 2.5481\n16/16 [==============================] - 0s 813us/step - loss: 2.6204\n16/16 [==============================] - 0s 797us/step - loss: 2.6165\n16/16 [==============================] - 0s 790us/step - loss: 2.5579\n16/16 [==============================] - 0s 782us/step - loss: 2.5097\n16/16 [==============================] - 0s 804us/step - loss: 2.4927\n16/16 [==============================] - 0s 779us/step - loss: 2.4877\n16/16 [==============================] - 0s 782us/step - loss: 2.4876\n\nTesting for epoch 48 index 5:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 829us/step - loss: 0.1159\n16/16 [==============================] - 0s 803us/step - loss: 2.0767\n16/16 [==============================] - 0s 810us/step - loss: 2.4525\n16/16 [==============================] - 0s 781us/step - loss: 2.5232\n16/16 [==============================] - 0s 796us/step - loss: 2.5203\n16/16 [==============================] - 0s 810us/step - loss: 2.4657\n16/16 [==============================] - 0s 782us/step - loss: 2.4213\n16/16 [==============================] - 0s 814us/step - loss: 2.4055\n16/16 [==============================] - 0s 805us/step - loss: 2.4008\n16/16 [==============================] - 0s 781us/step - loss: 2.4008\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1130\n16/16 [==============================] - 0s 806us/step - loss: 2.1188\n16/16 [==============================] - 0s 784us/step - loss: 2.5027\n16/16 [==============================] - 0s 783us/step - loss: 2.5749\n16/16 [==============================] - 0s 777us/step - loss: 2.5720\n16/16 [==============================] - 0s 790us/step - loss: 2.5164\n16/16 [==============================] - 0s 787us/step - loss: 2.4706\n16/16 [==============================] - 0s 823us/step - loss: 2.4543\n16/16 [==============================] - 0s 811us/step - loss: 2.4493\n16/16 [==============================] - 0s 819us/step - loss: 2.4491\n\nTesting for epoch 49 index 2:\n79/79 [==============================] - 0s 589us/step\n16/16 [==============================] - 0s 806us/step - loss: 0.1130\n16/16 [==============================] - 0s 798us/step - loss: 2.1207\n16/16 [==============================] - 0s 791us/step - loss: 2.5027\n16/16 [==============================] - 0s 807us/step - loss: 2.5732\n16/16 [==============================] - 0s 794us/step - loss: 2.5696\n16/16 [==============================] - 0s 795us/step - loss: 2.5133\n16/16 [==============================] - 0s 790us/step - loss: 2.4675\n16/16 [==============================] - 0s 787us/step - loss: 2.4516\n16/16 [==============================] - 0s 790us/step - loss: 2.4468\n16/16 [==============================] - 0s 789us/step - loss: 2.4468\n\nTesting for epoch 49 index 3:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1157\n16/16 [==============================] - 0s 771us/step - loss: 2.1044\n16/16 [==============================] - 0s 773us/step - loss: 2.4790\n16/16 [==============================] - 0s 775us/step - loss: 2.5455\n16/16 [==============================] - 0s 783us/step - loss: 2.5407\n16/16 [==============================] - 0s 848us/step - loss: 2.4851\n16/16 [==============================] - 0s 846us/step - loss: 2.4397\n16/16 [==============================] - 0s 861us/step - loss: 2.4239\n16/16 [==============================] - 0s 847us/step - loss: 2.4191\n16/16 [==============================] - 0s 868us/step - loss: 2.4191\n\nTesting for epoch 49 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1159\n16/16 [==============================] - 0s 797us/step - loss: 2.1415\n16/16 [==============================] - 0s 792us/step - loss: 2.5249\n16/16 [==============================] - 0s 821us/step - loss: 2.5930\n16/16 [==============================] - 0s 888us/step - loss: 2.5871\n16/16 [==============================] - 0s 879us/step - loss: 2.5281\n16/16 [==============================] - 0s 867us/step - loss: 2.4804\n16/16 [==============================] - 0s 893us/step - loss: 2.4640\n16/16 [==============================] - 0s 804us/step - loss: 2.4592\n16/16 [==============================] - 0s 808us/step - loss: 2.4592\n\nTesting for epoch 49 index 5:\n79/79 [==============================] - 0s 590us/step\n16/16 [==============================] - 0s 821us/step - loss: 0.1108\n16/16 [==============================] - 0s 839us/step - loss: 2.1666\n16/16 [==============================] - 0s 802us/step - loss: 2.5501\n16/16 [==============================] - 0s 670us/step - loss: 2.6150\n16/16 [==============================] - 0s 783us/step - loss: 2.6061\n16/16 [==============================] - 0s 2ms/step - loss: 2.5432\n16/16 [==============================] - 0s 748us/step - loss: 2.4931\n16/16 [==============================] - 0s 2ms/step - loss: 2.4759\n16/16 [==============================] - 0s 746us/step - loss: 2.4708\n16/16 [==============================] - 0s 2ms/step - loss: 2.4707\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n79/79 [==============================] - 0s 834us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1092\n16/16 [==============================] - 0s 2ms/step - loss: 2.1786\n16/16 [==============================] - 0s 2ms/step - loss: 2.5691\n16/16 [==============================] - 0s 783us/step - loss: 2.6374\n16/16 [==============================] - 0s 1ms/step - loss: 2.6307\n16/16 [==============================] - 0s 983us/step - loss: 2.5707\n16/16 [==============================] - 0s 1ms/step - loss: 2.5218\n16/16 [==============================] - 0s 2ms/step - loss: 2.5047\n16/16 [==============================] - 0s 827us/step - loss: 2.4996\n16/16 [==============================] - 0s 820us/step - loss: 2.4996\n\nTesting for epoch 50 index 2:\n79/79 [==============================] - 0s 577us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1106\n16/16 [==============================] - 0s 812us/step - loss: 2.1213\n16/16 [==============================] - 0s 2ms/step - loss: 2.4972\n16/16 [==============================] - 0s 805us/step - loss: 2.5617\n16/16 [==============================] - 0s 2ms/step - loss: 2.5540\n16/16 [==============================] - 0s 779us/step - loss: 2.4949\n16/16 [==============================] - 0s 798us/step - loss: 2.4473\n16/16 [==============================] - 0s 802us/step - loss: 2.4311\n16/16 [==============================] - 0s 827us/step - loss: 2.4263\n16/16 [==============================] - 0s 827us/step - loss: 2.4263\n\nTesting for epoch 50 index 3:\n79/79 [==============================] - 0s 574us/step\n16/16 [==============================] - 0s 825us/step - loss: 0.1134\n16/16 [==============================] - 0s 833us/step - loss: 2.1640\n16/16 [==============================] - 0s 831us/step - loss: 2.5466\n16/16 [==============================] - 0s 806us/step - loss: 2.6094\n16/16 [==============================] - 0s 2ms/step - loss: 2.5990\n16/16 [==============================] - 0s 2ms/step - loss: 2.5356\n16/16 [==============================] - 0s 2ms/step - loss: 2.4853\n16/16 [==============================] - 0s 2ms/step - loss: 2.4681\n16/16 [==============================] - 0s 830us/step - loss: 2.4631\n16/16 [==============================] - 0s 2ms/step - loss: 2.4631\n\nTesting for epoch 50 index 4:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1106\n16/16 [==============================] - 0s 2ms/step - loss: 2.1669\n16/16 [==============================] - 0s 2ms/step - loss: 2.5499\n16/16 [==============================] - 0s 2ms/step - loss: 2.6154\n16/16 [==============================] - 0s 919us/step - loss: 2.6077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5490\n16/16 [==============================] - 0s 2ms/step - loss: 2.5020\n16/16 [==============================] - 0s 2ms/step - loss: 2.4856\n16/16 [==============================] - 0s 2ms/step - loss: 2.4805\n16/16 [==============================] - 0s 1ms/step - loss: 2.4803\n\nTesting for epoch 50 index 5:\n79/79 [==============================] - 0s 853us/step\n16/16 [==============================] - 0s 803us/step - loss: 0.1134\n16/16 [==============================] - 0s 1ms/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.5127\n16/16 [==============================] - 0s 1ms/step - loss: 2.5788\n16/16 [==============================] - 0s 818us/step - loss: 2.5713\n16/16 [==============================] - 0s 828us/step - loss: 2.5120\n16/16 [==============================] - 0s 806us/step - loss: 2.4655\n16/16 [==============================] - 0s 1ms/step - loss: 2.4496\n16/16 [==============================] - 0s 825us/step - loss: 2.4450\n16/16 [==============================] - 0s 851us/step - loss: 2.4451\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 799us/step - loss: 0.1102\n16/16 [==============================] - 0s 2ms/step - loss: 2.1080\n16/16 [==============================] - 0s 1ms/step - loss: 2.4813\n16/16 [==============================] - 0s 801us/step - loss: 2.5444\n16/16 [==============================] - 0s 1ms/step - loss: 2.5367\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 779us/step - loss: 2.4343\n16/16 [==============================] - 0s 780us/step - loss: 2.4184\n16/16 [==============================] - 0s 809us/step - loss: 2.4137\n16/16 [==============================] - 0s 816us/step - loss: 2.4137\n\nTesting for epoch 51 index 2:\n79/79 [==============================] - 0s 544us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1094\n16/16 [==============================] - 0s 2ms/step - loss: 2.1884\n16/16 [==============================] - 0s 825us/step - loss: 2.5791\n16/16 [==============================] - 0s 1ms/step - loss: 2.6449\n16/16 [==============================] - 0s 837us/step - loss: 2.6358\n16/16 [==============================] - 0s 1ms/step - loss: 2.5744\n16/16 [==============================] - 0s 792us/step - loss: 2.5257\n16/16 [==============================] - 0s 2ms/step - loss: 2.5088\n16/16 [==============================] - 0s 807us/step - loss: 2.5036\n16/16 [==============================] - 0s 2ms/step - loss: 2.5035\n\nTesting for epoch 51 index 3:\n79/79 [==============================] - 0s 575us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1135\n16/16 [==============================] - 0s 918us/step - loss: 2.1417\n16/16 [==============================] - 0s 778us/step - loss: 2.5163\n16/16 [==============================] - 0s 839us/step - loss: 2.5775\n16/16 [==============================] - 0s 1ms/step - loss: 2.5668\n16/16 [==============================] - 0s 817us/step - loss: 2.5060\n16/16 [==============================] - 0s 820us/step - loss: 2.4582\n16/16 [==============================] - 0s 2ms/step - loss: 2.4420\n16/16 [==============================] - 0s 2ms/step - loss: 2.4372\n16/16 [==============================] - 0s 2ms/step - loss: 2.4371\n\nTesting for epoch 51 index 4:\n79/79 [==============================] - 0s 660us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1133\n16/16 [==============================] - 0s 2ms/step - loss: 2.1446\n16/16 [==============================] - 0s 780us/step - loss: 2.5259\n16/16 [==============================] - 0s 2ms/step - loss: 2.5907\n16/16 [==============================] - 0s 2ms/step - loss: 2.5826\n16/16 [==============================] - 0s 2ms/step - loss: 2.5259\n16/16 [==============================] - 0s 778us/step - loss: 2.4802\n16/16 [==============================] - 0s 945us/step - loss: 2.4642\n16/16 [==============================] - 0s 2ms/step - loss: 2.4593\n16/16 [==============================] - 0s 937us/step - loss: 2.4592\n\nTesting for epoch 51 index 5:\n79/79 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 867us/step - loss: 0.1097\n16/16 [==============================] - 0s 2ms/step - loss: 2.1334\n16/16 [==============================] - 0s 2ms/step - loss: 2.5077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5687\n16/16 [==============================] - 0s 814us/step - loss: 2.5580\n16/16 [==============================] - 0s 1ms/step - loss: 2.4978\n16/16 [==============================] - 0s 1ms/step - loss: 2.4505\n16/16 [==============================] - 0s 2ms/step - loss: 2.4342\n16/16 [==============================] - 0s 804us/step - loss: 2.4293\n16/16 [==============================] - 0s 831us/step - loss: 2.4292\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n79/79 [==============================] - 0s 964us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.1128\n16/16 [==============================] - 0s 2ms/step - loss: 2.1843\n16/16 [==============================] - 0s 1ms/step - loss: 2.5731\n16/16 [==============================] - 0s 992us/step - loss: 2.6381\n16/16 [==============================] - 0s 2ms/step - loss: 2.6285\n16/16 [==============================] - 0s 2ms/step - loss: 2.5692\n16/16 [==============================] - 0s 815us/step - loss: 2.5219\n16/16 [==============================] - 0s 944us/step - loss: 2.5053\n16/16 [==============================] - 0s 740us/step - loss: 2.5000\n16/16 [==============================] - 0s 799us/step - loss: 2.4998\n\nTesting for epoch 52 index 2:\n79/79 [==============================] - 0s 498us/step\n16/16 [==============================] - 0s 814us/step - loss: 0.1151\n16/16 [==============================] - 0s 662us/step - loss: 2.1366\n16/16 [==============================] - 0s 786us/step - loss: 2.5143\n16/16 [==============================] - 0s 832us/step - loss: 2.5790\n16/16 [==============================] - 0s 828us/step - loss: 2.5708\n16/16 [==============================] - 0s 772us/step - loss: 2.5126\n16/16 [==============================] - 0s 763us/step - loss: 2.4669\n16/16 [==============================] - 0s 761us/step - loss: 2.4509\n16/16 [==============================] - 0s 762us/step - loss: 2.4460\n16/16 [==============================] - 0s 765us/step - loss: 2.4459\n\nTesting for epoch 52 index 3:\n79/79 [==============================] - 0s 651us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1137\n16/16 [==============================] - 0s 776us/step - loss: 2.1214\n16/16 [==============================] - 0s 777us/step - loss: 2.4961\n16/16 [==============================] - 0s 810us/step - loss: 2.5559\n16/16 [==============================] - 0s 1ms/step - loss: 2.5443\n16/16 [==============================] - 0s 1ms/step - loss: 2.4830\n16/16 [==============================] - 0s 1ms/step - loss: 2.4348\n16/16 [==============================] - 0s 1ms/step - loss: 2.4184\n16/16 [==============================] - 0s 823us/step - loss: 2.4137\n16/16 [==============================] - 0s 786us/step - loss: 2.4137\n\nTesting for epoch 52 index 4:\n79/79 [==============================] - 0s 809us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1077\n16/16 [==============================] - 0s 1ms/step - loss: 2.2251\n16/16 [==============================] - 0s 765us/step - loss: 2.6189\n16/16 [==============================] - 0s 1ms/step - loss: 2.6792\n16/16 [==============================] - 0s 1ms/step - loss: 2.6652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5992\n16/16 [==============================] - 0s 1ms/step - loss: 2.5479\n16/16 [==============================] - 0s 787us/step - loss: 2.5304\n16/16 [==============================] - 0s 1ms/step - loss: 2.5253\n16/16 [==============================] - 0s 1ms/step - loss: 2.5253\n\nTesting for epoch 52 index 5:\n79/79 [==============================] - 0s 575us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1081\n16/16 [==============================] - 0s 787us/step - loss: 2.1911\n16/16 [==============================] - 0s 801us/step - loss: 2.5848\n16/16 [==============================] - 0s 776us/step - loss: 2.6481\n16/16 [==============================] - 0s 819us/step - loss: 2.6369\n16/16 [==============================] - 0s 784us/step - loss: 2.5737\n16/16 [==============================] - 0s 778us/step - loss: 2.5244\n16/16 [==============================] - 0s 774us/step - loss: 2.5073\n16/16 [==============================] - 0s 830us/step - loss: 2.5021\n16/16 [==============================] - 0s 783us/step - loss: 2.5019\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.1105\n16/16 [==============================] - 0s 798us/step - loss: 2.2424\n16/16 [==============================] - 0s 801us/step - loss: 2.6434\n16/16 [==============================] - 0s 782us/step - loss: 2.7071\n16/16 [==============================] - 0s 809us/step - loss: 2.6960\n16/16 [==============================] - 0s 781us/step - loss: 2.6329\n16/16 [==============================] - 0s 796us/step - loss: 2.5825\n16/16 [==============================] - 0s 785us/step - loss: 2.5653\n16/16 [==============================] - 0s 779us/step - loss: 2.5603\n16/16 [==============================] - 0s 780us/step - loss: 2.5603\n\nTesting for epoch 53 index 2:\n79/79 [==============================] - 0s 666us/step\n16/16 [==============================] - 0s 800us/step - loss: 0.1065\n16/16 [==============================] - 0s 773us/step - loss: 2.2126\n16/16 [==============================] - 0s 780us/step - loss: 2.5990\n16/16 [==============================] - 0s 799us/step - loss: 2.6537\n16/16 [==============================] - 0s 775us/step - loss: 2.6362\n16/16 [==============================] - 0s 778us/step - loss: 2.5665\n16/16 [==============================] - 0s 777us/step - loss: 2.5130\n16/16 [==============================] - 0s 782us/step - loss: 2.4951\n16/16 [==============================] - 0s 793us/step - loss: 2.4897\n16/16 [==============================] - 0s 783us/step - loss: 2.4896\n\nTesting for epoch 53 index 3:\n79/79 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1109\n16/16 [==============================] - 0s 783us/step - loss: 2.2409\n16/16 [==============================] - 0s 826us/step - loss: 2.6359\n16/16 [==============================] - 0s 802us/step - loss: 2.6951\n16/16 [==============================] - 0s 784us/step - loss: 2.6803\n16/16 [==============================] - 0s 818us/step - loss: 2.6154\n16/16 [==============================] - 0s 854us/step - loss: 2.5654\n16/16 [==============================] - 0s 824us/step - loss: 2.5480\n16/16 [==============================] - 0s 878us/step - loss: 2.5427\n16/16 [==============================] - 0s 823us/step - loss: 2.5425\n\nTesting for epoch 53 index 4:\n79/79 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 822us/step - loss: 0.1077\n16/16 [==============================] - 0s 774us/step - loss: 2.1988\n16/16 [==============================] - 0s 791us/step - loss: 2.5828\n16/16 [==============================] - 0s 824us/step - loss: 2.6395\n16/16 [==============================] - 0s 777us/step - loss: 2.6247\n16/16 [==============================] - 0s 786us/step - loss: 2.5585\n16/16 [==============================] - 0s 791us/step - loss: 2.5071\n16/16 [==============================] - 0s 796us/step - loss: 2.4895\n16/16 [==============================] - 0s 784us/step - loss: 2.4842\n16/16 [==============================] - 0s 781us/step - loss: 2.4840\n\nTesting for epoch 53 index 5:\n79/79 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.1101\n16/16 [==============================] - 0s 823us/step - loss: 2.1742\n16/16 [==============================] - 0s 806us/step - loss: 2.5541\n16/16 [==============================] - 0s 815us/step - loss: 2.6106\n16/16 [==============================] - 0s 786us/step - loss: 2.5974\n16/16 [==============================] - 0s 779us/step - loss: 2.5359\n16/16 [==============================] - 0s 777us/step - loss: 2.4884\n16/16 [==============================] - 0s 821us/step - loss: 2.4719\n16/16 [==============================] - 0s 831us/step - loss: 2.4668\n16/16 [==============================] - 0s 794us/step - loss: 2.4666\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n79/79 [==============================] - 0s 584us/step\n16/16 [==============================] - 0s 824us/step - loss: 0.1084\n16/16 [==============================] - 0s 791us/step - loss: 2.1517\n16/16 [==============================] - 0s 804us/step - loss: 2.5217\n16/16 [==============================] - 0s 781us/step - loss: 2.5735\n16/16 [==============================] - 0s 773us/step - loss: 2.5572\n16/16 [==============================] - 0s 860us/step - loss: 2.4921\n16/16 [==============================] - 0s 798us/step - loss: 2.4427\n16/16 [==============================] - 0s 783us/step - loss: 2.4259\n16/16 [==============================] - 0s 788us/step - loss: 2.4209\n16/16 [==============================] - 0s 779us/step - loss: 2.4208\n\nTesting for epoch 54 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 841us/step - loss: 0.1095\n16/16 [==============================] - 0s 791us/step - loss: 2.1899\n16/16 [==============================] - 0s 857us/step - loss: 2.5646\n16/16 [==============================] - 0s 832us/step - loss: 2.6178\n16/16 [==============================] - 0s 805us/step - loss: 2.5997\n16/16 [==============================] - 0s 811us/step - loss: 2.5326\n16/16 [==============================] - 0s 1ms/step - loss: 2.4819\n16/16 [==============================] - 0s 799us/step - loss: 2.4647\n16/16 [==============================] - 0s 810us/step - loss: 2.4596\n16/16 [==============================] - 0s 818us/step - loss: 2.4596\n\nTesting for epoch 54 index 3:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1083\n16/16 [==============================] - 0s 802us/step - loss: 2.1131\n16/16 [==============================] - 0s 796us/step - loss: 2.4631\n16/16 [==============================] - 0s 776us/step - loss: 2.5087\n16/16 [==============================] - 0s 791us/step - loss: 2.4890\n16/16 [==============================] - 0s 833us/step - loss: 2.4226\n16/16 [==============================] - 0s 784us/step - loss: 2.3731\n16/16 [==============================] - 0s 772us/step - loss: 2.3567\n16/16 [==============================] - 0s 772us/step - loss: 2.3520\n16/16 [==============================] - 0s 798us/step - loss: 2.3520\n\nTesting for epoch 54 index 4:\n79/79 [==============================] - 0s 592us/step\n16/16 [==============================] - 0s 813us/step - loss: 0.1097\n16/16 [==============================] - 0s 820us/step - loss: 2.2147\n16/16 [==============================] - 0s 790us/step - loss: 2.5931\n16/16 [==============================] - 0s 786us/step - loss: 2.6463\n16/16 [==============================] - 0s 793us/step - loss: 2.6278\n16/16 [==============================] - 0s 815us/step - loss: 2.5607\n16/16 [==============================] - 0s 786us/step - loss: 2.5099\n16/16 [==============================] - 0s 800us/step - loss: 2.4930\n16/16 [==============================] - 0s 804us/step - loss: 2.4882\n16/16 [==============================] - 0s 803us/step - loss: 2.4882\n\nTesting for epoch 54 index 5:\n79/79 [==============================] - 0s 598us/step\n16/16 [==============================] - 0s 865us/step - loss: 0.1090\n16/16 [==============================] - 0s 821us/step - loss: 2.2205\n16/16 [==============================] - 0s 781us/step - loss: 2.5931\n16/16 [==============================] - 0s 1ms/step - loss: 2.6411\n16/16 [==============================] - 0s 1ms/step - loss: 2.6206\n16/16 [==============================] - 0s 783us/step - loss: 2.5518\n16/16 [==============================] - 0s 789us/step - loss: 2.5000\n16/16 [==============================] - 0s 791us/step - loss: 2.4825\n16/16 [==============================] - 0s 786us/step - loss: 2.4773\n16/16 [==============================] - 0s 784us/step - loss: 2.4773\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.1066\n16/16 [==============================] - 0s 821us/step - loss: 2.2507\n16/16 [==============================] - 0s 780us/step - loss: 2.6376\n16/16 [==============================] - 0s 776us/step - loss: 2.6928\n16/16 [==============================] - 0s 775us/step - loss: 2.6741\n16/16 [==============================] - 0s 780us/step - loss: 2.6065\n16/16 [==============================] - 0s 778us/step - loss: 2.5550\n16/16 [==============================] - 0s 908us/step - loss: 2.5376\n16/16 [==============================] - 0s 1ms/step - loss: 2.5325\n16/16 [==============================] - 0s 1ms/step - loss: 2.5324\n\nTesting for epoch 55 index 2:\n79/79 [==============================] - 0s 827us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1066\n16/16 [==============================] - 0s 830us/step - loss: 2.2226\n16/16 [==============================] - 0s 782us/step - loss: 2.5906\n16/16 [==============================] - 0s 780us/step - loss: 2.6408\n16/16 [==============================] - 0s 1ms/step - loss: 2.6207\n16/16 [==============================] - 0s 1ms/step - loss: 2.5530\n16/16 [==============================] - 0s 1ms/step - loss: 2.5026\n16/16 [==============================] - 0s 1ms/step - loss: 2.4856\n16/16 [==============================] - 0s 1ms/step - loss: 2.4805\n16/16 [==============================] - 0s 1ms/step - loss: 2.4805\n\nTesting for epoch 55 index 3:\n79/79 [==============================] - 0s 733us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1096\n16/16 [==============================] - 0s 1ms/step - loss: 2.2626\n16/16 [==============================] - 0s 1ms/step - loss: 2.6387\n16/16 [==============================] - 0s 1ms/step - loss: 2.6881\n16/16 [==============================] - 0s 1ms/step - loss: 2.6669\n16/16 [==============================] - 0s 1ms/step - loss: 2.5970\n16/16 [==============================] - 0s 1ms/step - loss: 2.5450\n16/16 [==============================] - 0s 1ms/step - loss: 2.5276\n16/16 [==============================] - 0s 1ms/step - loss: 2.5226\n16/16 [==============================] - 0s 799us/step - loss: 2.5226\n\nTesting for epoch 55 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1016\n16/16 [==============================] - 0s 783us/step - loss: 2.2888\n16/16 [==============================] - 0s 782us/step - loss: 2.6711\n16/16 [==============================] - 0s 815us/step - loss: 2.7212\n16/16 [==============================] - 0s 1ms/step - loss: 2.6985\n16/16 [==============================] - 0s 848us/step - loss: 2.6265\n16/16 [==============================] - 0s 837us/step - loss: 2.5724\n16/16 [==============================] - 0s 788us/step - loss: 2.5543\n16/16 [==============================] - 0s 828us/step - loss: 2.5490\n16/16 [==============================] - 0s 827us/step - loss: 2.5490\n\nTesting for epoch 55 index 5:\n79/79 [==============================] - 0s 833us/step\n16/16 [==============================] - 0s 924us/step - loss: 0.1076\n16/16 [==============================] - 0s 874us/step - loss: 2.3363\n16/16 [==============================] - 0s 793us/step - loss: 2.7287\n16/16 [==============================] - 0s 798us/step - loss: 2.7820\n16/16 [==============================] - 0s 796us/step - loss: 2.7605\n16/16 [==============================] - 0s 836us/step - loss: 2.6894\n16/16 [==============================] - 0s 801us/step - loss: 2.6356\n16/16 [==============================] - 0s 797us/step - loss: 2.6175\n16/16 [==============================] - 0s 791us/step - loss: 2.6122\n16/16 [==============================] - 0s 794us/step - loss: 2.6122\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n79/79 [==============================] - 0s 588us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1053\n16/16 [==============================] - 0s 823us/step - loss: 2.2654\n16/16 [==============================] - 0s 784us/step - loss: 2.6376\n16/16 [==============================] - 0s 796us/step - loss: 2.6831\n16/16 [==============================] - 0s 798us/step - loss: 2.6585\n16/16 [==============================] - 0s 784us/step - loss: 2.5853\n16/16 [==============================] - 0s 784us/step - loss: 2.5317\n16/16 [==============================] - 0s 776us/step - loss: 2.5138\n16/16 [==============================] - 0s 788us/step - loss: 2.5086\n16/16 [==============================] - 0s 780us/step - loss: 2.5085\n\nTesting for epoch 56 index 2:\n79/79 [==============================] - 0s 601us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1091\n16/16 [==============================] - 0s 846us/step - loss: 2.2312\n16/16 [==============================] - 0s 782us/step - loss: 2.6027\n16/16 [==============================] - 0s 806us/step - loss: 2.6531\n16/16 [==============================] - 0s 791us/step - loss: 2.6318\n16/16 [==============================] - 0s 771us/step - loss: 2.5612\n16/16 [==============================] - 0s 795us/step - loss: 2.5079\n16/16 [==============================] - 0s 779us/step - loss: 2.4899\n16/16 [==============================] - 0s 788us/step - loss: 2.4844\n16/16 [==============================] - 0s 784us/step - loss: 2.4842\n\nTesting for epoch 56 index 3:\n79/79 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.1080\n16/16 [==============================] - 0s 804us/step - loss: 2.2179\n16/16 [==============================] - 0s 792us/step - loss: 2.5805\n16/16 [==============================] - 0s 778us/step - loss: 2.6276\n16/16 [==============================] - 0s 777us/step - loss: 2.6063\n16/16 [==============================] - 0s 784us/step - loss: 2.5380\n16/16 [==============================] - 0s 779us/step - loss: 2.4867\n16/16 [==============================] - 0s 795us/step - loss: 2.4695\n16/16 [==============================] - 0s 798us/step - loss: 2.4644\n16/16 [==============================] - 0s 791us/step - loss: 2.4644\n\nTesting for epoch 56 index 4:\n79/79 [==============================] - 0s 709us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1050\n16/16 [==============================] - 0s 1ms/step - loss: 2.2906\n16/16 [==============================] - 0s 1ms/step - loss: 2.6671\n16/16 [==============================] - 0s 1ms/step - loss: 2.7144\n16/16 [==============================] - 0s 1ms/step - loss: 2.6909\n16/16 [==============================] - 0s 1ms/step - loss: 2.6183\n16/16 [==============================] - 0s 787us/step - loss: 2.5653\n16/16 [==============================] - 0s 783us/step - loss: 2.5474\n16/16 [==============================] - 0s 800us/step - loss: 2.5423\n16/16 [==============================] - 0s 1ms/step - loss: 2.5422\n\nTesting for epoch 56 index 5:\n79/79 [==============================] - 0s 823us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1082\n16/16 [==============================] - 0s 831us/step - loss: 2.2431\n16/16 [==============================] - 0s 843us/step - loss: 2.6105\n16/16 [==============================] - 0s 781us/step - loss: 2.6582\n16/16 [==============================] - 0s 786us/step - loss: 2.6367\n16/16 [==============================] - 0s 790us/step - loss: 2.5673\n16/16 [==============================] - 0s 809us/step - loss: 2.5156\n16/16 [==============================] - 0s 805us/step - loss: 2.4986\n16/16 [==============================] - 0s 807us/step - loss: 2.4937\n16/16 [==============================] - 0s 804us/step - loss: 2.4937\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n79/79 [==============================] - 0s 582us/step\n16/16 [==============================] - 0s 792us/step - loss: 0.1051\n16/16 [==============================] - 0s 794us/step - loss: 2.3166\n16/16 [==============================] - 0s 852us/step - loss: 2.6952\n16/16 [==============================] - 0s 812us/step - loss: 2.7417\n16/16 [==============================] - 0s 788us/step - loss: 2.7163\n16/16 [==============================] - 0s 781us/step - loss: 2.6402\n16/16 [==============================] - 0s 775us/step - loss: 2.5838\n16/16 [==============================] - 0s 787us/step - loss: 2.5650\n16/16 [==============================] - 0s 783us/step - loss: 2.5596\n16/16 [==============================] - 0s 808us/step - loss: 2.5596\n\nTesting for epoch 57 index 2:\n79/79 [==============================] - 0s 614us/step\n16/16 [==============================] - 0s 798us/step - loss: 0.1056\n16/16 [==============================] - 0s 1ms/step - loss: 2.1999\n16/16 [==============================] - 0s 1ms/step - loss: 2.5532\n16/16 [==============================] - 0s 1ms/step - loss: 2.5957\n16/16 [==============================] - 0s 1ms/step - loss: 2.5734\n16/16 [==============================] - 0s 930us/step - loss: 2.5046\n16/16 [==============================] - 0s 902us/step - loss: 2.4545\n16/16 [==============================] - 0s 1ms/step - loss: 2.4380\n16/16 [==============================] - 0s 1ms/step - loss: 2.4332\n16/16 [==============================] - 0s 1ms/step - loss: 2.4332\n\nTesting for epoch 57 index 3:\n79/79 [==============================] - 0s 665us/step\n16/16 [==============================] - 0s 791us/step - loss: 0.1134\n16/16 [==============================] - 0s 842us/step - loss: 2.1538\n16/16 [==============================] - 0s 780us/step - loss: 2.5023\n16/16 [==============================] - 0s 775us/step - loss: 2.5460\n16/16 [==============================] - 0s 788us/step - loss: 2.5254\n16/16 [==============================] - 0s 775us/step - loss: 2.4601\n16/16 [==============================] - 0s 775us/step - loss: 2.4117\n16/16 [==============================] - 0s 789us/step - loss: 2.3954\n16/16 [==============================] - 0s 788us/step - loss: 2.3907\n16/16 [==============================] - 0s 787us/step - loss: 2.3906\n\nTesting for epoch 57 index 4:\n79/79 [==============================] - 0s 909us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.1055\n16/16 [==============================] - 0s 809us/step - loss: 2.3141\n16/16 [==============================] - 0s 817us/step - loss: 2.6890\n16/16 [==============================] - 0s 861us/step - loss: 2.7333\n16/16 [==============================] - 0s 789us/step - loss: 2.7077\n16/16 [==============================] - 0s 777us/step - loss: 2.6323\n16/16 [==============================] - 0s 780us/step - loss: 2.5774\n16/16 [==============================] - 0s 780us/step - loss: 2.5593\n16/16 [==============================] - 0s 802us/step - loss: 2.5541\n16/16 [==============================] - 0s 790us/step - loss: 2.5541\n\nTesting for epoch 57 index 5:\n79/79 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.1056\n16/16 [==============================] - 0s 789us/step - loss: 2.2966\n16/16 [==============================] - 0s 796us/step - loss: 2.6697\n16/16 [==============================] - 0s 781us/step - loss: 2.7157\n16/16 [==============================] - 0s 781us/step - loss: 2.6915\n16/16 [==============================] - 0s 1ms/step - loss: 2.6184\n16/16 [==============================] - 0s 1ms/step - loss: 2.5641\n16/16 [==============================] - 0s 803us/step - loss: 2.5462\n16/16 [==============================] - 0s 776us/step - loss: 2.5410\n16/16 [==============================] - 0s 805us/step - loss: 2.5409\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n79/79 [==============================] - 0s 585us/step\n16/16 [==============================] - 0s 781us/step - loss: 0.1061\n16/16 [==============================] - 0s 785us/step - loss: 2.3267\n16/16 [==============================] - 0s 777us/step - loss: 2.7069\n16/16 [==============================] - 0s 784us/step - loss: 2.7544\n16/16 [==============================] - 0s 782us/step - loss: 2.7306\n16/16 [==============================] - 0s 1ms/step - loss: 2.6573\n16/16 [==============================] - 0s 816us/step - loss: 2.6031\n16/16 [==============================] - 0s 1ms/step - loss: 2.5850\n16/16 [==============================] - 0s 1ms/step - loss: 2.5797\n16/16 [==============================] - 0s 1ms/step - loss: 2.5796\n\nTesting for epoch 58 index 2:\n79/79 [==============================] - 0s 578us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.1053\n16/16 [==============================] - 0s 1ms/step - loss: 2.2433\n16/16 [==============================] - 0s 778us/step - loss: 2.6007\n16/16 [==============================] - 0s 778us/step - loss: 2.6389\n16/16 [==============================] - 0s 782us/step - loss: 2.6116\n16/16 [==============================] - 0s 784us/step - loss: 2.5366\n16/16 [==============================] - 0s 777us/step - loss: 2.4824\n16/16 [==============================] - 0s 773us/step - loss: 2.4647\n16/16 [==============================] - 0s 780us/step - loss: 2.4596\n16/16 [==============================] - 0s 792us/step - loss: 2.4596\n\nTesting for epoch 58 index 3:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 796us/step - loss: 0.1060\n16/16 [==============================] - 0s 813us/step - loss: 2.2387\n16/16 [==============================] - 0s 788us/step - loss: 2.5997\n16/16 [==============================] - 0s 780us/step - loss: 2.6431\n16/16 [==============================] - 0s 827us/step - loss: 2.6195\n16/16 [==============================] - 0s 818us/step - loss: 2.5483\n16/16 [==============================] - 0s 820us/step - loss: 2.4955\n16/16 [==============================] - 0s 774us/step - loss: 2.4780\n16/16 [==============================] - 0s 791us/step - loss: 2.4729\n16/16 [==============================] - 0s 801us/step - loss: 2.4729\n\nTesting for epoch 58 index 4:\n79/79 [==============================] - 0s 586us/step\n16/16 [==============================] - 0s 812us/step - loss: 0.1044\n16/16 [==============================] - 0s 792us/step - loss: 2.3186\n16/16 [==============================] - 0s 778us/step - loss: 2.6976\n16/16 [==============================] - 0s 779us/step - loss: 2.7451\n16/16 [==============================] - 0s 783us/step - loss: 2.7220\n16/16 [==============================] - 0s 795us/step - loss: 2.6492\n16/16 [==============================] - 0s 787us/step - loss: 2.5949\n16/16 [==============================] - 0s 792us/step - loss: 2.5768\n16/16 [==============================] - 0s 1ms/step - loss: 2.5714\n16/16 [==============================] - 0s 807us/step - loss: 2.5713\n\nTesting for epoch 58 index 5:\n79/79 [==============================] - 0s 593us/step\n16/16 [==============================] - 0s 783us/step - loss: 0.1039\n16/16 [==============================] - 0s 794us/step - loss: 2.2733\n16/16 [==============================] - 0s 768us/step - loss: 2.6396\n16/16 [==============================] - 0s 790us/step - loss: 2.6824\n16/16 [==============================] - 0s 774us/step - loss: 2.6577\n16/16 [==============================] - 0s 780us/step - loss: 2.5860\n16/16 [==============================] - 0s 1ms/step - loss: 2.5336\n16/16 [==============================] - 0s 1ms/step - loss: 2.5162\n16/16 [==============================] - 0s 1ms/step - loss: 2.5110\n16/16 [==============================] - 0s 1ms/step - loss: 2.5109\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n79/79 [==============================] - 0s 574us/step\n16/16 [==============================] - 0s 785us/step - loss: 0.1015\n16/16 [==============================] - 0s 799us/step - loss: 2.2663\n16/16 [==============================] - 0s 786us/step - loss: 2.6320\n16/16 [==============================] - 0s 785us/step - loss: 2.6746\n16/16 [==============================] - 0s 782us/step - loss: 2.6500\n16/16 [==============================] - 0s 779us/step - loss: 2.5779\n16/16 [==============================] - 0s 776us/step - loss: 2.5255\n16/16 [==============================] - 0s 781us/step - loss: 2.5079\n16/16 [==============================] - 0s 780us/step - loss: 2.5025\n16/16 [==============================] - 0s 807us/step - loss: 2.5023\n\nTesting for epoch 59 index 2:\n79/79 [==============================] - 0s 578us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1025\n16/16 [==============================] - 0s 807us/step - loss: 2.3515\n16/16 [==============================] - 0s 777us/step - loss: 2.7275\n16/16 [==============================] - 0s 774us/step - loss: 2.7688\n16/16 [==============================] - 0s 1ms/step - loss: 2.7405\n16/16 [==============================] - 0s 1ms/step - loss: 2.6618\n16/16 [==============================] - 0s 776us/step - loss: 2.6044\n16/16 [==============================] - 0s 1ms/step - loss: 2.5857\n16/16 [==============================] - 0s 780us/step - loss: 2.5804\n16/16 [==============================] - 0s 786us/step - loss: 2.5804\n\nTesting for epoch 59 index 3:\n79/79 [==============================] - 0s 602us/step\n16/16 [==============================] - 0s 787us/step - loss: 0.1027\n16/16 [==============================] - 0s 791us/step - loss: 2.2619\n16/16 [==============================] - 0s 780us/step - loss: 2.6166\n16/16 [==============================] - 0s 783us/step - loss: 2.6521\n16/16 [==============================] - 0s 819us/step - loss: 2.6231\n16/16 [==============================] - 0s 796us/step - loss: 2.5477\n16/16 [==============================] - 0s 827us/step - loss: 2.4932\n16/16 [==============================] - 0s 795us/step - loss: 2.4756\n16/16 [==============================] - 0s 786us/step - loss: 2.4707\n16/16 [==============================] - 0s 778us/step - loss: 2.4708\n\nTesting for epoch 59 index 4:\n79/79 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 808us/step - loss: 0.1013\n16/16 [==============================] - 0s 800us/step - loss: 2.2814\n16/16 [==============================] - 0s 797us/step - loss: 2.6450\n16/16 [==============================] - 0s 797us/step - loss: 2.6843\n16/16 [==============================] - 0s 797us/step - loss: 2.6560\n16/16 [==============================] - 0s 801us/step - loss: 2.5800\n16/16 [==============================] - 0s 792us/step - loss: 2.5259\n16/16 [==============================] - 0s 796us/step - loss: 2.5080\n16/16 [==============================] - 0s 814us/step - loss: 2.5027\n16/16 [==============================] - 0s 820us/step - loss: 2.5026\n\nTesting for epoch 59 index 5:\n79/79 [==============================] - 0s 657us/step\n16/16 [==============================] - 0s 795us/step - loss: 0.1035\n16/16 [==============================] - 0s 785us/step - loss: 2.3241\n16/16 [==============================] - 0s 810us/step - loss: 2.7005\n16/16 [==============================] - 0s 802us/step - loss: 2.7443\n16/16 [==============================] - 0s 788us/step - loss: 2.7189\n16/16 [==============================] - 0s 785us/step - loss: 2.6445\n16/16 [==============================] - 0s 783us/step - loss: 2.5895\n16/16 [==============================] - 0s 787us/step - loss: 2.5711\n16/16 [==============================] - 0s 794us/step - loss: 2.5655\n16/16 [==============================] - 0s 1ms/step - loss: 2.5654\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n79/79 [==============================] - 0s 828us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0991\n16/16 [==============================] - 0s 797us/step - loss: 2.3587\n16/16 [==============================] - 0s 1ms/step - loss: 2.7350\n16/16 [==============================] - 0s 1ms/step - loss: 2.7747\n16/16 [==============================] - 0s 1ms/step - loss: 2.7463\n16/16 [==============================] - 0s 1ms/step - loss: 2.6678\n16/16 [==============================] - 0s 1ms/step - loss: 2.6113\n16/16 [==============================] - 0s 1ms/step - loss: 2.5929\n16/16 [==============================] - 0s 1ms/step - loss: 2.5877\n16/16 [==============================] - 0s 809us/step - loss: 2.5878\n\nTesting for epoch 60 index 2:\n79/79 [==============================] - 0s 576us/step\n16/16 [==============================] - 0s 828us/step - loss: 0.1038\n16/16 [==============================] - 0s 830us/step - loss: 2.2804\n16/16 [==============================] - 0s 783us/step - loss: 2.6366\n16/16 [==============================] - 0s 788us/step - loss: 2.6709\n16/16 [==============================] - 0s 1ms/step - loss: 2.6408\n16/16 [==============================] - 0s 1ms/step - loss: 2.5626\n16/16 [==============================] - 0s 1ms/step - loss: 2.5067\n16/16 [==============================] - 0s 1ms/step - loss: 2.4886\n16/16 [==============================] - 0s 1ms/step - loss: 2.4834\n16/16 [==============================] - 0s 803us/step - loss: 2.4834\n\nTesting for epoch 60 index 3:\n79/79 [==============================] - 0s 812us/step\n16/16 [==============================] - 0s 788us/step - loss: 0.0991\n16/16 [==============================] - 0s 1ms/step - loss: 2.3934\n16/16 [==============================] - 0s 1ms/step - loss: 2.7744\n16/16 [==============================] - 0s 1ms/step - loss: 2.8152\n16/16 [==============================] - 0s 1ms/step - loss: 2.7874\n16/16 [==============================] - 0s 1ms/step - loss: 2.7085\n16/16 [==============================] - 0s 777us/step - loss: 2.6519\n16/16 [==============================] - 0s 1ms/step - loss: 2.6333\n16/16 [==============================] - 0s 778us/step - loss: 2.6279\n16/16 [==============================] - 0s 1ms/step - loss: 2.6278\n\nTesting for epoch 60 index 4:\n79/79 [==============================] - 0s 579us/step\n16/16 [==============================] - 0s 793us/step - loss: 0.0991\n16/16 [==============================] - 0s 784us/step - loss: 2.3763\n16/16 [==============================] - 0s 782us/step - loss: 2.7524\n16/16 [==============================] - 0s 782us/step - loss: 2.7925\n16/16 [==============================] - 0s 1ms/step - loss: 2.7641\n16/16 [==============================] - 0s 1ms/step - loss: 2.6876\n16/16 [==============================] - 0s 1ms/step - loss: 2.6322\n16/16 [==============================] - 0s 1ms/step - loss: 2.6139\n16/16 [==============================] - 0s 1ms/step - loss: 2.6085\n16/16 [==============================] - 0s 1ms/step - loss: 2.6085\n\nTesting for epoch 60 index 5:\n79/79 [==============================] - 0s 581us/step\n16/16 [==============================] - 0s 786us/step - loss: 0.1005\n16/16 [==============================] - 0s 785us/step - loss: 2.3451\n16/16 [==============================] - 0s 785us/step - loss: 2.7153\n16/16 [==============================] - 0s 771us/step - loss: 2.7525\n16/16 [==============================] - 0s 774us/step - loss: 2.7234\n16/16 [==============================] - 0s 789us/step - loss: 2.6445\n16/16 [==============================] - 0s 784us/step - loss: 2.5884\n16/16 [==============================] - 0s 789us/step - loss: 2.5702\n16/16 [==============================] - 0s 789us/step - loss: 2.5652\n16/16 [==============================] - 0s 802us/step - loss: 2.5653\n79/79 [==============================] - 0s 580us/step\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nthirteen = twelve.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  thirteen = twelve.append(_conf.tab)\n\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors,contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.978\nPrecision: 0.990\nRecall: 0.987\nF1 Score: 0.989\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\n\nfourteen = thirteen.append(_conf.tab)\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  fourteen = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny-result",
    "href": "posts/GODE/2023-07-03-other_outlier_detection.html#bunny-result",
    "title": "Other Outlier Detection",
    "section": "Bunny Result",
    "text": "Bunny Result\n\nfourteen.round(3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.988\n      0.995\n      0.993\n      0.994\n    \n    \n      LOF (Breunig et al., 2000)\n      0.913\n      0.955\n      0.953\n      0.954\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.942\n      0.997\n      0.942\n      0.969\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.935\n      0.992\n      0.939\n      0.965\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.982\n      0.992\n      0.989\n      0.990\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.954\n      0.977\n      0.974\n      0.976\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.979\n      0.990\n      0.988\n      0.989\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.827\n      0.995\n      0.822\n      0.900\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.919\n      0.958\n      0.956\n      0.957\n    \n    \n      SOS (Janssens et al., 2012)\n      0.912\n      0.955\n      0.953\n      0.954\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.952\n      0.952\n      1.000\n      0.975\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.952\n      0.952\n      1.000\n      0.975\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.978\n      0.990\n      0.987\n      0.989\n    \n  \n\n\n\n\n\n\n\nBunny 5%\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nGODE\n0.988\n0.995\n0.993\n0.994\n\n\nLOF (Breunig et al., 2000)\n0.913\n0.955\n0.953\n0.954\n\n\nKNN\n\n\n\n\n\n\nCBLOF\n\n\n\n\n\n\nOCSVM (Sch Ìˆolkopf et al., 2001)\n\n\n\n\n\n\nMCD (Hardin and Rocke, 2004)\n0.982\n0.992\n0.989\n0.990\n\n\nFeature Bagging (Lazarevic and Kumar, 2005)\n0.954\n0.977\n0.975\n0.976\n\n\nABOD (Kriegel et al., 2008)\n0.977\n0.989\n0.987\n0.988\n\n\nIsolation Forest (Liu et al., 2008)\n0.802\n0.996\n0.795\n0.884\n\n\nHBOS (Goldstein and Dengel, 2012)\n0.919\n0.958\n0.956\n0.957\n\n\nSOS (Janssens et al., 2012)\n0.912\n0.955\n0.953\n0.954\n\n\nSO-GAAL (Liu et al., 2019)\n0.952\n0.952\n1.000\n0.975\n\n\nMO-GAAL (Liu et al., 2019)\n0.952\n0.952\n1.000\n0.975\n\n\nLSCP (Zhao et al., 2019)\n0.980\n0.991\n0.988\n0.989"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html",
    "title": "Graph code",
    "section": "",
    "text": "Poster"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#linear1",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#linear1",
    "title": "Graph code",
    "section": "Linear(1)",
    "text": "Linear(1)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5,ref=30,ymin=-5,ymax=20,cuts=0,cutf=995): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color í‘œí˜„ì€ ìœ„í•¸ í‘œì¤€í™”\n        self.df = self.df.assign(differ = self.differ)\n        \n        fig,ax = plt.subplots(figsize=(10,10))\n        ax.scatter(self.x,self.y,color='gray',s=50,alpha=0.7)\n        ax.scatter(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],color='red',s=50)\n        ax.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], '--k',lw=3)\n        ax.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=550,facecolors='none', edgecolors='r')\n        fig.tight_layout()\n        fig.savefig('fig1.eps',format='eps')\n\n\n_simul = SIMUL(df1)\n\n\n_simul.fit(sd=20,ref=25,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#linear2",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#linear2",
    "title": "Graph code",
    "section": "Linear(2)",
    "text": "Linear(2)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul2 = SIMUL(df2)\n\n\n_simul2.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#cos",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#cos",
    "title": "Graph code",
    "section": "COS",
    "text": "COS\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul4 = SIMUL(df4)\n\n\n_simul4.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#sin",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#sin",
    "title": "Graph code",
    "section": "SIN",
    "text": "SIN\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul5 = SIMUL(df5)\n\n\n_simul5.fit(ref=15,ymin=-10,ymax=15,cuts=5)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque."
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#d-manifold",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#d-manifold",
    "title": "Graph code",
    "section": "1D manifold",
    "text": "1D manifold\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n#         fig = plt.figure(figsize=(10,10))\n        # ax = fig.add_subplot(1,1,1, projection='3d')\n        #\n        fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,15),subplot_kw={\"projection\":\"3d\"})\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax1.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red')\n        ax1.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax1.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=60)\n        \n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax2.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax2.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax2.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=40)\n        \n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax3.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax3.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax3.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax3.view_init(elev=30., azim=10)\n        \n        fig.savefig('fig2.eps',format='eps')\n\n\n_simul3d = SIMUL(df)\n\n\n_simul3d.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 562.21it/s]\n\n\n\n_simul3d.get_weightmatrix(theta=(_simul3d.D[_simul3d.D>0].mean()),kappa=2500) \n\n\n(_simul3d.D[_simul3d.D>0].mean())\n\n6.453496488349201\n\n\n\n%%capture --no-display\n_simul3d.fit(sd=15,ref=20)"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#bunny",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#bunny",
    "title": "Graph code",
    "section": "Bunny",
    "text": "Bunny\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) # ê¼¬ë¦¬ë¶€ë¶„ì˜ ë¹¨ê°„ì‹ í˜¸ë¥¼ í¼ì§€ê²Œí•˜ëŠ” ì •ë„\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\n\n\nindex_of_trueoutlier_bool = (unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2022-11-10 21:12:29,879:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nW = G.W.toarray()\nx = G.coords[:,0]\ny = G.coords[:,1]\nz = -G.coords[:,2]\n\n\ndf = pd.DataFrame({'x' : x, 'y' : y, 'z' : z, 'f' : f, 'noise' : noise})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=2.5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig = plt.figure(figsize=(30,12),dpi=400)\n        ax1 = fig.add_subplot(251, projection='3d')\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax1.view_init(elev=60., azim=-90)\n\n        ax2= fig.add_subplot(252, projection='3d')\n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax2.view_init(elev=60., azim=-90)\n\n        ax3= fig.add_subplot(253, projection='3d')\n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax3.view_init(elev=60., azim=-90)\n        \n        ax4= fig.add_subplot(254, projection='3d')\n        ax4.grid(False)\n        ax4.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax4.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax4.view_init(elev=60., azim=-90)\n\n        ax5= fig.add_subplot(255, projection='3d')\n        ax5.grid(False)\n        ax5.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax5.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax5.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax5.view_init(elev=60., azim=-90)\n        \n        ax6 = fig.add_subplot(256, projection='3d')\n        ax6.grid(False)\n        ax6.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax6.view_init(elev=-60., azim=-90)\n\n        ax7= fig.add_subplot(257, projection='3d')\n        ax7.grid(False)\n        ax7.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax7.view_init(elev=-60., azim=-90)\n\n        ax8= fig.add_subplot(258, projection='3d')\n        ax8.grid(False)\n        ax8.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax8.view_init(elev=-60., azim=-90)\n        \n        ax9= fig.add_subplot(259, projection='3d')\n        ax9.grid(False)\n        ax9.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax9.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax9.view_init(elev=-60., azim=-90)\n\n        ax10= fig.add_subplot(2,5,10, projection='3d')\n        ax10.grid(False)\n        ax10.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax10.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax10.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax10.view_init(elev=-60., azim=-90)        \n        fig.savefig('fig_bunny.eps',format='eps')\n\n\n_simul = SIMUL(df)\n\n\nmax(_simul.f),max(_simul.fnoise)\n\n(-0.010827167666814895, 8.453057038638512)\n\n\n\nmin(_simul.f),min(_simul.fnoise)\n\n(-4.74620052476489, -11.196627043702925)\n\n\n\n%%capture --no-display\n_simul.fit(sd=20,ref=10)"
  },
  {
    "objectID": "posts/GODE/2022-12-01-graph_code_guebin.html#earthquake",
    "href": "posts/GODE/2022-12-01-graph_code_guebin.html#earthquake",
    "title": "Graph code",
    "section": "Earthquake",
    "text": "Earthquake\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\n\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh ê¸°ëŠ¥ì¶”ê°€\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\neach_location.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12498/12498 [03:24<00:00, 61.15it/s] \n\n\n\neach_location.D[each_location.D>0].mean()\n\n8810.865423093777\n\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n(array([14176290., 16005894., 21186674., 22331128., 19394182., 17548252.,\n        16668048., 13316436., 12973260.,  2582550.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig = each_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig.write_image('fig_haiti.png',scale=3)\n\n\neach_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_lquique.svg',scale=3)\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_sichuan.svg',scale=3)"
  },
  {
    "objectID": "posts/GODE/index.html",
    "href": "posts/GODE/index.html",
    "title": "GODE",
    "section": "",
    "text": "About GODE paper"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html",
    "title": "Class code for Comparison Study",
    "section": "",
    "text": "Simulation\nex - The Stanford bunny data generated using the pygsp package is a common graphics 3D test model and NN-graph. It has 2503 data. We use filter.Heat in this package and it calculate data by \\(\\hat{g}(x) = \\exp(\\frac{-\\tau x}{\\lambda_{max}})\\) and \\(\\tau\\) is 75. We use Chebyshev polynomial approximation on this filter. We make zero vector whixh size is 2503, and put -3000 to one value to use a Lanczos approximation. A Lanczos approximation will resize signals by flattened.\nref: https://pygsp.readthedocs.io/en/v0.5.1/reference/filters.html\n\\(r = 5 + \\cos(\\frac{12\\pi - (-\\pi)}{n})\\times i , (i=1,2,\\dots , n)\\)\n\\(r \\cos(\\frac{\\pi - 2\\times \\pi /n - (-\\pi) }{n}\\times i)),(i=1,2,\\dots ,n)\\)\n\\(r \\sin((\\frac{\\pi - 2\\times \\pi /n - (-\\pi) }{n}\\times i)),(i=1,2,\\dots ,n)\\)\n\\(f = 10 \\times (\\frac{6 \\pi}{n} \\times i),(i=1,2, \\dots , n)\\)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#import",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#import",
    "title": "Class code for Comparison Study",
    "section": "Import",
    "text": "Import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.linear_model import SGDOneClassSVM\nfrom sklearn.kernel_approximation import Nystroem\nfrom sklearn.pipeline import make_pipeline\n\nimport pandas as pd\nfrom sklearn.neighbors import LocalOutlierFactor\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\nfrom sklearn.datasets import fetch_kddcup99, fetch_covtype, fetch_openml\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport tqdm\n\nfrom pygsp import graphs, filters, plotting, utils\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\n\nimport plotly.express as px\n\nfrom sklearn.covariance import EmpiricalCovariance, MinCovDet\n\nfrom alibi_detect.od import IForest\n# from pyod.models.iforest import IForest\n\nfrom pyod.models.abod import ABOD\nfrom pyod.models.cblof import CBLOF\nimport seaborn as sns\n\nfrom PyNomaly import loop\n\nfrom sklearn import svm\n\nfrom pyod.models.lscp import LSCP\nfrom pyod.models.hbos import HBOS\n\nfrom pyod.models.so_gaal import SO_GAAL\nfrom pyod.models.mcd import MCD\nfrom pyod.models.mo_gaal import MO_GAAL\nfrom pyod.models.knn import KNN\nfrom pyod.models.lof import LOF\nfrom pyod.models.ocsvm import OCSVM\n\nfrom pyod.models.feature_bagging import FeatureBagging\nfrom pyod.models.sos import SOS"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#class-code",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#class-code",
    "title": "Class code for Comparison Study",
    "section": "Class Code",
    "text": "Class Code\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_orbit = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\ntab_bunny = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\nclass Conf_matrx:\n    def __init__(self,original,compare,tab):\n        self.original = original\n        self.compare = compare\n        self.tab = tab\n    def conf(self,name):\n        self.conf_matrix = confusion_matrix(self.original, self.compare)\n        \n        fig, ax = plt.subplots(figsize=(5, 5))\n        ax.matshow(self.conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n        for i in range(self.conf_matrix.shape[0]):\n            for j in range(self.conf_matrix.shape[1]):\n                ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n        plt.xlabel('Predictions', fontsize=18)\n        plt.ylabel('Actuals', fontsize=18)\n        plt.title('Confusion Matrix', fontsize=18)\n        plt.show()\n        \n        self.acc = accuracy_score(self.original, self.compare)\n        self.pre = precision_score(self.original, self.compare)\n        self.rec = recall_score(self.original, self.compare)\n        self.f1 = f1_score(self.original, self.compare)\n        \n        print('Accuracy: %.3f' % self.acc)\n        print('Precision: %.3f' % self.pre)\n        print('Recall: %.3f' % self.rec)\n        print('F1 Score: %.3f' % self.f1)\n        \n        self.tab = self.tab.append(pd.DataFrame({\"Accuracy\":[self.acc],\"Precision\":[self.pre],\"Recall\":[self.rec],\"F1\":[self.f1]},index = [name]))\n\n\nclass Linear:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        #self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=20): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n\n\nclass Orbit:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=20): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n\n\nclass BUNNY:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = _W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-ebayesthresh",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-ebayesthresh",
    "title": "Class code for Comparison Study",
    "section": "Linear EbayesThresh",
    "text": "Linear EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))\nindex_of_trueoutlier_1 = which(signal_1!=0)\nindex_of_trueoutlier_1\nx_1=signal_1+epsilon\n\n\n%R -o x_1\n%R -o index_of_trueoutlier_1\n%R -o signal_1\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\noutlier_true_index_1 = index_of_trueoutlier_1\n\n\noutlier_true_value_1 = x_1[index_of_trueoutlier_1]\n\n\noutlier_true_one_1 = signal_1.copy()\n\n\noutlier_true_one_1 = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one_1))"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear",
    "title": "Class code for Comparison Study",
    "section": "Linear",
    "text": "Linear\n\n_x_1 = np.linspace(0,2,1000)\n_y1_1 = 5*_x_1\n_y_1 = _y1_1 + x_1 # x is epsilon\n\n\n_df=pd.DataFrame({'x':_x_1, 'y':_y_1})\n\n\nX = np.array(_df)\n\n\nGODE\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n_Linear = Linear(_df)\n\n\n_Linear.fit(sd=5)\n\n\noutlier_simul_one = (_Linear.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 20 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.890\nPrecision: 0.973\nRecall: 0.909\nF1 Score: 0.940\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nfrom pyod.models.knn import KNN\n\n\nclf = KNN()\nclf.fit(_df[['x', 'y']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.979\nRecall: 0.927\nF1 Score: 0.952\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.920\nPrecision: 0.958\nRecall: 0.958\nF1 Score: 0.958\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.909\nPrecision: 0.978\nRecall: 0.925\nF1 Score: 0.951\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.982\nRecall: 0.931\nF1 Score: 0.956\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.982\nRecall: 0.931\nF1 Score: 0.956\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.946\nPrecision: 0.972\nRecall: 0.972\nF1 Score: 0.972\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y']])\n\n\npreds = od.predict(\n    _df[['x', 'y']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.800\nPrecision: 0.984\nRecall: 0.802\nF1 Score: 0.884\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.889\nPrecision: 0.960\nRecall: 0.921\nF1 Score: 0.940\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.889\nPrecision: 0.960\nRecall: 0.921\nF1 Score: 0.940\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3973\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 679us/step - loss: 1.4180\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4019\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4210\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4234\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 691us/step - loss: 1.4552\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 663us/step - loss: 1.4271\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 767us/step - loss: 1.4613\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 602us/step - loss: 1.4776\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 715us/step - loss: 1.4349\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4333\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4840\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5092\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4956\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5026\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 831us/step - loss: 1.5576\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 611us/step - loss: 1.5602\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 1.4791\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 619us/step - loss: 1.5625\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5635\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5925\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5807\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 844us/step - loss: 1.5739\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6122\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 657us/step - loss: 1.6156\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6021\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6237\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6302\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6586\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.6349\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6708\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 726us/step - loss: 1.7010\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 826us/step - loss: 1.6865\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 820us/step - loss: 1.6874\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 680us/step - loss: 1.7410\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 663us/step - loss: 1.7334\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 1.6871\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 621us/step - loss: 1.7771\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 1.7724\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7815\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 647us/step - loss: 1.7470\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 612us/step - loss: 1.7897\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 660us/step - loss: 1.8400\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8351\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 689us/step - loss: 1.8388\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8174\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 974us/step - loss: 1.8131\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 712us/step - loss: 1.8391\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 635us/step - loss: 1.7937\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 971us/step - loss: 1.8550\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 628us/step - loss: 1.8632\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8457\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 628us/step - loss: 1.8924\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 1.8481\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8722\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9405\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 640us/step - loss: 1.9428\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8585\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 638us/step - loss: 1.8806\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 608us/step - loss: 1.9145\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9380\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 615us/step - loss: 1.8934\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9282\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 651us/step - loss: 1.8956\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 630us/step - loss: 1.8997\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9230\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 671us/step - loss: 1.9290\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 885us/step - loss: 1.9631\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 1.9394\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9368\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9715\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9327\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 690us/step - loss: 1.9782\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 612us/step - loss: 1.9637\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 575us/step - loss: 1.9657\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 890us/step - loss: 1.9923\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9824\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.0536\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.868\nPrecision: 0.954\nRecall: 0.904\nF1 Score: 0.929\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 674us/step - loss: 0.5119\n16/16 [==============================] - 0s 1ms/step - loss: 0.8174\n16/16 [==============================] - 0s 1ms/step - loss: 1.0584\n16/16 [==============================] - 0s 1ms/step - loss: 1.2057\n16/16 [==============================] - 0s 1ms/step - loss: 1.2512\n16/16 [==============================] - 0s 653us/step - loss: 1.2690\n16/16 [==============================] - 0s 640us/step - loss: 1.2744\n16/16 [==============================] - 0s 846us/step - loss: 1.2761\n16/16 [==============================] - 0s 782us/step - loss: 1.2766\n16/16 [==============================] - 0s 1ms/step - loss: 1.2766\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 665us/step - loss: 0.5016\n16/16 [==============================] - 0s 1ms/step - loss: 0.8168\n16/16 [==============================] - 0s 729us/step - loss: 1.0701\n16/16 [==============================] - 0s 619us/step - loss: 1.2239\n16/16 [==============================] - 0s 952us/step - loss: 1.2703\n16/16 [==============================] - 0s 680us/step - loss: 1.2884\n16/16 [==============================] - 0s 1ms/step - loss: 1.2938\n16/16 [==============================] - 0s 1ms/step - loss: 1.2955\n16/16 [==============================] - 0s 674us/step - loss: 1.2959\n16/16 [==============================] - 0s 680us/step - loss: 1.2959\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.4978\n16/16 [==============================] - 0s 1ms/step - loss: 0.8174\n16/16 [==============================] - 0s 988us/step - loss: 1.0777\n16/16 [==============================] - 0s 683us/step - loss: 1.2388\n16/16 [==============================] - 0s 1ms/step - loss: 1.2871\n16/16 [==============================] - 0s 1ms/step - loss: 1.3063\n16/16 [==============================] - 0s 899us/step - loss: 1.3121\n16/16 [==============================] - 0s 701us/step - loss: 1.3140\n16/16 [==============================] - 0s 674us/step - loss: 1.3144\n16/16 [==============================] - 0s 894us/step - loss: 1.3144\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.4856\n16/16 [==============================] - 0s 911us/step - loss: 0.8190\n16/16 [==============================] - 0s 1ms/step - loss: 1.0913\n16/16 [==============================] - 0s 1ms/step - loss: 1.2605\n16/16 [==============================] - 0s 1ms/step - loss: 1.3112\n16/16 [==============================] - 0s 1ms/step - loss: 1.3310\n16/16 [==============================] - 0s 2ms/step - loss: 1.3370\n16/16 [==============================] - 0s 1ms/step - loss: 1.3389\n16/16 [==============================] - 0s 745us/step - loss: 1.3393\n16/16 [==============================] - 0s 964us/step - loss: 1.3393\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 0.4780\n16/16 [==============================] - 0s 851us/step - loss: 0.8265\n16/16 [==============================] - 0s 1ms/step - loss: 1.1094\n16/16 [==============================] - 0s 1ms/step - loss: 1.2901\n16/16 [==============================] - 0s 702us/step - loss: 1.3448\n16/16 [==============================] - 0s 939us/step - loss: 1.3665\n16/16 [==============================] - 0s 854us/step - loss: 1.3731\n16/16 [==============================] - 0s 872us/step - loss: 1.3753\n16/16 [==============================] - 0s 633us/step - loss: 1.3759\n16/16 [==============================] - 0s 1ms/step - loss: 1.3759\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 709us/step - loss: 0.4680\n16/16 [==============================] - 0s 964us/step - loss: 0.8342\n16/16 [==============================] - 0s 717us/step - loss: 1.1328\n16/16 [==============================] - 0s 631us/step - loss: 1.3245\n16/16 [==============================] - 0s 1ms/step - loss: 1.3825\n16/16 [==============================] - 0s 1ms/step - loss: 1.4056\n16/16 [==============================] - 0s 1ms/step - loss: 1.4125\n16/16 [==============================] - 0s 675us/step - loss: 1.4148\n16/16 [==============================] - 0s 1ms/step - loss: 1.4154\n16/16 [==============================] - 0s 1ms/step - loss: 1.4154\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 683us/step - loss: 0.4700\n16/16 [==============================] - 0s 1ms/step - loss: 0.8212\n16/16 [==============================] - 0s 608us/step - loss: 1.1067\n16/16 [==============================] - 0s 1ms/step - loss: 1.2919\n16/16 [==============================] - 0s 645us/step - loss: 1.3484\n16/16 [==============================] - 0s 655us/step - loss: 1.3713\n16/16 [==============================] - 0s 1ms/step - loss: 1.3780\n16/16 [==============================] - 0s 707us/step - loss: 1.3802\n16/16 [==============================] - 0s 1ms/step - loss: 1.3807\n16/16 [==============================] - 0s 1ms/step - loss: 1.3807\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4568\n16/16 [==============================] - 0s 1ms/step - loss: 0.8264\n16/16 [==============================] - 0s 866us/step - loss: 1.1304\n16/16 [==============================] - 0s 737us/step - loss: 1.3292\n16/16 [==============================] - 0s 1ms/step - loss: 1.3891\n16/16 [==============================] - 0s 859us/step - loss: 1.4139\n16/16 [==============================] - 0s 664us/step - loss: 1.4209\n16/16 [==============================] - 0s 1ms/step - loss: 1.4233\n16/16 [==============================] - 0s 632us/step - loss: 1.4239\n16/16 [==============================] - 0s 2ms/step - loss: 1.4239\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.4472\n16/16 [==============================] - 0s 613us/step - loss: 0.8308\n16/16 [==============================] - 0s 633us/step - loss: 1.1472\n16/16 [==============================] - 0s 640us/step - loss: 1.3580\n16/16 [==============================] - 0s 1ms/step - loss: 1.4212\n16/16 [==============================] - 0s 644us/step - loss: 1.4477\n16/16 [==============================] - 0s 621us/step - loss: 1.4553\n16/16 [==============================] - 0s 601us/step - loss: 1.4579\n16/16 [==============================] - 0s 799us/step - loss: 1.4585\n16/16 [==============================] - 0s 663us/step - loss: 1.4585\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4458\n16/16 [==============================] - 0s 639us/step - loss: 0.8332\n16/16 [==============================] - 0s 622us/step - loss: 1.1594\n16/16 [==============================] - 0s 620us/step - loss: 1.3754\n16/16 [==============================] - 0s 987us/step - loss: 1.4394\n16/16 [==============================] - 0s 652us/step - loss: 1.4660\n16/16 [==============================] - 0s 641us/step - loss: 1.4735\n16/16 [==============================] - 0s 628us/step - loss: 1.4761\n16/16 [==============================] - 0s 1ms/step - loss: 1.4766\n16/16 [==============================] - 0s 597us/step - loss: 1.4766\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4323\n16/16 [==============================] - 0s 1ms/step - loss: 0.8289\n16/16 [==============================] - 0s 1ms/step - loss: 1.1745\n16/16 [==============================] - 0s 2ms/step - loss: 1.4047\n16/16 [==============================] - 0s 1ms/step - loss: 1.4730\n16/16 [==============================] - 0s 835us/step - loss: 1.5017\n16/16 [==============================] - 0s 684us/step - loss: 1.5100\n16/16 [==============================] - 0s 643us/step - loss: 1.5128\n16/16 [==============================] - 0s 1ms/step - loss: 1.5135\n16/16 [==============================] - 0s 1ms/step - loss: 1.5135\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4311\n16/16 [==============================] - 0s 693us/step - loss: 0.8327\n16/16 [==============================] - 0s 639us/step - loss: 1.1867\n16/16 [==============================] - 0s 606us/step - loss: 1.4217\n16/16 [==============================] - 0s 816us/step - loss: 1.4904\n16/16 [==============================] - 0s 828us/step - loss: 1.5189\n16/16 [==============================] - 0s 1ms/step - loss: 1.5270\n16/16 [==============================] - 0s 1ms/step - loss: 1.5298\n16/16 [==============================] - 0s 1ms/step - loss: 1.5303\n16/16 [==============================] - 0s 779us/step - loss: 1.5303\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4224\n16/16 [==============================] - 0s 1ms/step - loss: 0.8208\n16/16 [==============================] - 0s 998us/step - loss: 1.1776\n16/16 [==============================] - 0s 1ms/step - loss: 1.4157\n16/16 [==============================] - 0s 635us/step - loss: 1.4850\n16/16 [==============================] - 0s 1ms/step - loss: 1.5136\n16/16 [==============================] - 0s 1ms/step - loss: 1.5217\n16/16 [==============================] - 0s 640us/step - loss: 1.5245\n16/16 [==============================] - 0s 590us/step - loss: 1.5251\n16/16 [==============================] - 0s 1ms/step - loss: 1.5251\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 707us/step - loss: 0.4220\n16/16 [==============================] - 0s 790us/step - loss: 0.8241\n16/16 [==============================] - 0s 1ms/step - loss: 1.1871\n16/16 [==============================] - 0s 829us/step - loss: 1.4277\n16/16 [==============================] - 0s 796us/step - loss: 1.4965\n16/16 [==============================] - 0s 1ms/step - loss: 1.5243\n16/16 [==============================] - 0s 1ms/step - loss: 1.5321\n16/16 [==============================] - 0s 1ms/step - loss: 1.5347\n16/16 [==============================] - 0s 611us/step - loss: 1.5352\n16/16 [==============================] - 0s 607us/step - loss: 1.5351\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4162\n16/16 [==============================] - 0s 765us/step - loss: 0.8240\n16/16 [==============================] - 0s 1ms/step - loss: 1.1967\n16/16 [==============================] - 0s 1ms/step - loss: 1.4447\n16/16 [==============================] - 0s 1ms/step - loss: 1.5154\n16/16 [==============================] - 0s 718us/step - loss: 1.5437\n16/16 [==============================] - 0s 1ms/step - loss: 1.5517\n16/16 [==============================] - 0s 1ms/step - loss: 1.5543\n16/16 [==============================] - 0s 659us/step - loss: 1.5548\n16/16 [==============================] - 0s 2ms/step - loss: 1.5547\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4156\n16/16 [==============================] - 0s 843us/step - loss: 0.8177\n16/16 [==============================] - 0s 623us/step - loss: 1.1876\n16/16 [==============================] - 0s 1ms/step - loss: 1.4313\n16/16 [==============================] - 0s 1ms/step - loss: 1.4993\n16/16 [==============================] - 0s 1ms/step - loss: 1.5259\n16/16 [==============================] - 0s 723us/step - loss: 1.5332\n16/16 [==============================] - 0s 640us/step - loss: 1.5355\n16/16 [==============================] - 0s 625us/step - loss: 1.5358\n16/16 [==============================] - 0s 634us/step - loss: 1.5357\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4090\n16/16 [==============================] - 0s 1ms/step - loss: 0.8233\n16/16 [==============================] - 0s 1ms/step - loss: 1.2093\n16/16 [==============================] - 0s 643us/step - loss: 1.4641\n16/16 [==============================] - 0s 627us/step - loss: 1.5348\n16/16 [==============================] - 0s 668us/step - loss: 1.5623\n16/16 [==============================] - 0s 885us/step - loss: 1.5697\n16/16 [==============================] - 0s 887us/step - loss: 1.5721\n16/16 [==============================] - 0s 640us/step - loss: 1.5724\n16/16 [==============================] - 0s 1ms/step - loss: 1.5724\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4023\n16/16 [==============================] - 0s 847us/step - loss: 0.8249\n16/16 [==============================] - 0s 1ms/step - loss: 1.2211\n16/16 [==============================] - 0s 669us/step - loss: 1.4795\n16/16 [==============================] - 0s 837us/step - loss: 1.5497\n16/16 [==============================] - 0s 1ms/step - loss: 1.5763\n16/16 [==============================] - 0s 792us/step - loss: 1.5833\n16/16 [==============================] - 0s 1ms/step - loss: 1.5854\n16/16 [==============================] - 0s 821us/step - loss: 1.5856\n16/16 [==============================] - 0s 654us/step - loss: 1.5855\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 815us/step - loss: 0.4039\n16/16 [==============================] - 0s 621us/step - loss: 0.8273\n16/16 [==============================] - 0s 636us/step - loss: 1.2286\n16/16 [==============================] - 0s 1ms/step - loss: 1.4900\n16/16 [==============================] - 0s 1ms/step - loss: 1.5605\n16/16 [==============================] - 0s 1ms/step - loss: 1.5869\n16/16 [==============================] - 0s 1ms/step - loss: 1.5938\n16/16 [==============================] - 0s 2ms/step - loss: 1.5958\n16/16 [==============================] - 0s 1ms/step - loss: 1.5960\n16/16 [==============================] - 0s 721us/step - loss: 1.5958\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 822us/step - loss: 0.3922\n16/16 [==============================] - 0s 618us/step - loss: 0.8303\n16/16 [==============================] - 0s 979us/step - loss: 1.2484\n16/16 [==============================] - 0s 594us/step - loss: 1.5177\n16/16 [==============================] - 0s 584us/step - loss: 1.5887\n16/16 [==============================] - 0s 886us/step - loss: 1.6148\n16/16 [==============================] - 0s 616us/step - loss: 1.6214\n16/16 [==============================] - 0s 986us/step - loss: 1.6232\n16/16 [==============================] - 0s 634us/step - loss: 1.6234\n16/16 [==============================] - 0s 647us/step - loss: 1.6232\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3917\n16/16 [==============================] - 0s 638us/step - loss: 0.8412\n16/16 [==============================] - 0s 1ms/step - loss: 1.2745\n16/16 [==============================] - 0s 1ms/step - loss: 1.5525\n16/16 [==============================] - 0s 597us/step - loss: 1.6251\n16/16 [==============================] - 0s 1ms/step - loss: 1.6514\n16/16 [==============================] - 0s 1ms/step - loss: 1.6580\n16/16 [==============================] - 0s 1ms/step - loss: 1.6598\n16/16 [==============================] - 0s 1ms/step - loss: 1.6598\n16/16 [==============================] - 0s 875us/step - loss: 1.6597\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 0.3861\n16/16 [==============================] - 0s 1ms/step - loss: 0.8410\n16/16 [==============================] - 0s 1ms/step - loss: 1.2819\n16/16 [==============================] - 0s 747us/step - loss: 1.5604\n16/16 [==============================] - 0s 1ms/step - loss: 1.6314\n16/16 [==============================] - 0s 2ms/step - loss: 1.6566\n16/16 [==============================] - 0s 1ms/step - loss: 1.6625\n16/16 [==============================] - 0s 1ms/step - loss: 1.6641\n16/16 [==============================] - 0s 682us/step - loss: 1.6641\n16/16 [==============================] - 0s 868us/step - loss: 1.6639\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3785\n16/16 [==============================] - 0s 640us/step - loss: 0.8366\n16/16 [==============================] - 0s 620us/step - loss: 1.2831\n16/16 [==============================] - 0s 630us/step - loss: 1.5628\n16/16 [==============================] - 0s 569us/step - loss: 1.6327\n16/16 [==============================] - 0s 1ms/step - loss: 1.6570\n16/16 [==============================] - 0s 1ms/step - loss: 1.6626\n16/16 [==============================] - 0s 671us/step - loss: 1.6639\n16/16 [==============================] - 0s 1ms/step - loss: 1.6638\n16/16 [==============================] - 0s 1ms/step - loss: 1.6636\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 686us/step - loss: 0.3794\n16/16 [==============================] - 0s 1ms/step - loss: 0.8368\n16/16 [==============================] - 0s 590us/step - loss: 1.2836\n16/16 [==============================] - 0s 1ms/step - loss: 1.5578\n16/16 [==============================] - 0s 1ms/step - loss: 1.6242\n16/16 [==============================] - 0s 1ms/step - loss: 1.6467\n16/16 [==============================] - 0s 1ms/step - loss: 1.6516\n16/16 [==============================] - 0s 880us/step - loss: 1.6526\n16/16 [==============================] - 0s 1ms/step - loss: 1.6524\n16/16 [==============================] - 0s 744us/step - loss: 1.6521\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 639us/step - loss: 0.3767\n16/16 [==============================] - 0s 675us/step - loss: 0.8386\n16/16 [==============================] - 0s 636us/step - loss: 1.2925\n16/16 [==============================] - 0s 667us/step - loss: 1.5686\n16/16 [==============================] - 0s 570us/step - loss: 1.6342\n16/16 [==============================] - 0s 650us/step - loss: 1.6560\n16/16 [==============================] - 0s 1ms/step - loss: 1.6605\n16/16 [==============================] - 0s 1ms/step - loss: 1.6614\n16/16 [==============================] - 0s 828us/step - loss: 1.6611\n16/16 [==============================] - 0s 754us/step - loss: 1.6608\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3785\n16/16 [==============================] - 0s 606us/step - loss: 0.8568\n16/16 [==============================] - 0s 1ms/step - loss: 1.3267\n16/16 [==============================] - 0s 1ms/step - loss: 1.6075\n16/16 [==============================] - 0s 632us/step - loss: 1.6723\n16/16 [==============================] - 0s 700us/step - loss: 1.6932\n16/16 [==============================] - 0s 814us/step - loss: 1.6974\n16/16 [==============================] - 0s 1ms/step - loss: 1.6980\n16/16 [==============================] - 0s 2ms/step - loss: 1.6977\n16/16 [==============================] - 0s 1ms/step - loss: 1.6974\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 611us/step - loss: 0.3640\n16/16 [==============================] - 0s 586us/step - loss: 0.8516\n16/16 [==============================] - 0s 613us/step - loss: 1.3334\n16/16 [==============================] - 0s 631us/step - loss: 1.6188\n16/16 [==============================] - 0s 635us/step - loss: 1.6834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7039\n16/16 [==============================] - 0s 600us/step - loss: 1.7078\n16/16 [==============================] - 0s 784us/step - loss: 1.7083\n16/16 [==============================] - 0s 1ms/step - loss: 1.7080\n16/16 [==============================] - 0s 654us/step - loss: 1.7076\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 642us/step - loss: 0.3623\n16/16 [==============================] - 0s 870us/step - loss: 0.8627\n16/16 [==============================] - 0s 1ms/step - loss: 1.3550\n16/16 [==============================] - 0s 935us/step - loss: 1.6411\n16/16 [==============================] - 0s 631us/step - loss: 1.7039\n16/16 [==============================] - 0s 1ms/step - loss: 1.7231\n16/16 [==============================] - 0s 659us/step - loss: 1.7264\n16/16 [==============================] - 0s 1ms/step - loss: 1.7267\n16/16 [==============================] - 0s 1ms/step - loss: 1.7262\n16/16 [==============================] - 0s 706us/step - loss: 1.7259\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3604\n16/16 [==============================] - 0s 635us/step - loss: 0.8668\n16/16 [==============================] - 0s 889us/step - loss: 1.3676\n16/16 [==============================] - 0s 1ms/step - loss: 1.6572\n16/16 [==============================] - 0s 947us/step - loss: 1.7200\n16/16 [==============================] - 0s 2ms/step - loss: 1.7389\n16/16 [==============================] - 0s 772us/step - loss: 1.7421\n16/16 [==============================] - 0s 1ms/step - loss: 1.7424\n16/16 [==============================] - 0s 1ms/step - loss: 1.7419\n16/16 [==============================] - 0s 744us/step - loss: 1.7415\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3571\n16/16 [==============================] - 0s 680us/step - loss: 0.8755\n16/16 [==============================] - 0s 751us/step - loss: 1.3899\n16/16 [==============================] - 0s 1ms/step - loss: 1.6814\n16/16 [==============================] - 0s 1ms/step - loss: 1.7429\n16/16 [==============================] - 0s 1ms/step - loss: 1.7609\n16/16 [==============================] - 0s 681us/step - loss: 1.7637\n16/16 [==============================] - 0s 677us/step - loss: 1.7638\n16/16 [==============================] - 0s 646us/step - loss: 1.7633\n16/16 [==============================] - 0s 1ms/step - loss: 1.7629\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3680\n16/16 [==============================] - 0s 623us/step - loss: 0.8560\n16/16 [==============================] - 0s 652us/step - loss: 1.3413\n16/16 [==============================] - 0s 605us/step - loss: 1.6123\n16/16 [==============================] - 0s 622us/step - loss: 1.6680\n16/16 [==============================] - 0s 808us/step - loss: 1.6837\n16/16 [==============================] - 0s 1ms/step - loss: 1.6859\n16/16 [==============================] - 0s 889us/step - loss: 1.6858\n16/16 [==============================] - 0s 633us/step - loss: 1.6852\n16/16 [==============================] - 0s 626us/step - loss: 1.6848\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3582\n16/16 [==============================] - 0s 660us/step - loss: 0.8667\n16/16 [==============================] - 0s 649us/step - loss: 1.3768\n16/16 [==============================] - 0s 1000us/step - loss: 1.6562\n16/16 [==============================] - 0s 1ms/step - loss: 1.7123\n16/16 [==============================] - 0s 634us/step - loss: 1.7277\n16/16 [==============================] - 0s 685us/step - loss: 1.7297\n16/16 [==============================] - 0s 1ms/step - loss: 1.7295\n16/16 [==============================] - 0s 1ms/step - loss: 1.7288\n16/16 [==============================] - 0s 628us/step - loss: 1.7284\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3583\n16/16 [==============================] - 0s 1ms/step - loss: 0.8671\n16/16 [==============================] - 0s 1ms/step - loss: 1.3803\n16/16 [==============================] - 0s 1ms/step - loss: 1.6596\n16/16 [==============================] - 0s 1ms/step - loss: 1.7150\n16/16 [==============================] - 0s 692us/step - loss: 1.7298\n16/16 [==============================] - 0s 979us/step - loss: 1.7317\n16/16 [==============================] - 0s 1ms/step - loss: 1.7314\n16/16 [==============================] - 0s 1ms/step - loss: 1.7308\n16/16 [==============================] - 0s 1ms/step - loss: 1.7304\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 863us/step - loss: 0.3471\n16/16 [==============================] - 0s 661us/step - loss: 0.8780\n16/16 [==============================] - 0s 659us/step - loss: 1.4219\n16/16 [==============================] - 0s 1ms/step - loss: 1.7117\n16/16 [==============================] - 0s 1ms/step - loss: 1.7680\n16/16 [==============================] - 0s 1ms/step - loss: 1.7827\n16/16 [==============================] - 0s 824us/step - loss: 1.7845\n16/16 [==============================] - 0s 1ms/step - loss: 1.7841\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 2ms/step - loss: 1.7830\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3466\n16/16 [==============================] - 0s 680us/step - loss: 0.8801\n16/16 [==============================] - 0s 1ms/step - loss: 1.4285\n16/16 [==============================] - 0s 615us/step - loss: 1.7186\n16/16 [==============================] - 0s 1ms/step - loss: 1.7739\n16/16 [==============================] - 0s 1ms/step - loss: 1.7880\n16/16 [==============================] - 0s 1ms/step - loss: 1.7895\n16/16 [==============================] - 0s 619us/step - loss: 1.7890\n16/16 [==============================] - 0s 1ms/step - loss: 1.7882\n16/16 [==============================] - 0s 587us/step - loss: 1.7878\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 861us/step - loss: 0.3492\n16/16 [==============================] - 0s 879us/step - loss: 0.8719\n16/16 [==============================] - 0s 664us/step - loss: 1.4147\n16/16 [==============================] - 0s 643us/step - loss: 1.6946\n16/16 [==============================] - 0s 1ms/step - loss: 1.7465\n16/16 [==============================] - 0s 621us/step - loss: 1.7591\n16/16 [==============================] - 0s 594us/step - loss: 1.7602\n16/16 [==============================] - 0s 612us/step - loss: 1.7596\n16/16 [==============================] - 0s 594us/step - loss: 1.7588\n16/16 [==============================] - 0s 660us/step - loss: 1.7584\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3448\n16/16 [==============================] - 0s 891us/step - loss: 0.8840\n16/16 [==============================] - 0s 1ms/step - loss: 1.4475\n16/16 [==============================] - 0s 634us/step - loss: 1.7374\n16/16 [==============================] - 0s 1ms/step - loss: 1.7907\n16/16 [==============================] - 0s 1ms/step - loss: 1.8035\n16/16 [==============================] - 0s 698us/step - loss: 1.8046\n16/16 [==============================] - 0s 660us/step - loss: 1.8040\n16/16 [==============================] - 0s 828us/step - loss: 1.8032\n16/16 [==============================] - 0s 1ms/step - loss: 1.8028\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 0.3427\n16/16 [==============================] - 0s 629us/step - loss: 0.8792\n16/16 [==============================] - 0s 613us/step - loss: 1.4449\n16/16 [==============================] - 0s 605us/step - loss: 1.7294\n16/16 [==============================] - 0s 1ms/step - loss: 1.7803\n16/16 [==============================] - 0s 1ms/step - loss: 1.7920\n16/16 [==============================] - 0s 670us/step - loss: 1.7928\n16/16 [==============================] - 0s 1ms/step - loss: 1.7921\n16/16 [==============================] - 0s 702us/step - loss: 1.7912\n16/16 [==============================] - 0s 978us/step - loss: 1.7908\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 884us/step - loss: 0.3356\n16/16 [==============================] - 0s 1ms/step - loss: 0.8885\n16/16 [==============================] - 0s 850us/step - loss: 1.4743\n16/16 [==============================] - 0s 730us/step - loss: 1.7694\n16/16 [==============================] - 0s 1ms/step - loss: 1.8221\n16/16 [==============================] - 0s 944us/step - loss: 1.8343\n16/16 [==============================] - 0s 932us/step - loss: 1.8352\n16/16 [==============================] - 0s 696us/step - loss: 1.8345\n16/16 [==============================] - 0s 1ms/step - loss: 1.8337\n16/16 [==============================] - 0s 1ms/step - loss: 1.8333\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 612us/step - loss: 0.3393\n16/16 [==============================] - 0s 595us/step - loss: 0.8775\n16/16 [==============================] - 0s 1ms/step - loss: 1.4502\n16/16 [==============================] - 0s 1ms/step - loss: 1.7321\n16/16 [==============================] - 0s 1ms/step - loss: 1.7808\n16/16 [==============================] - 0s 1ms/step - loss: 1.7913\n16/16 [==============================] - 0s 1ms/step - loss: 1.7917\n16/16 [==============================] - 0s 663us/step - loss: 1.7909\n16/16 [==============================] - 0s 688us/step - loss: 1.7900\n16/16 [==============================] - 0s 659us/step - loss: 1.7895\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3349\n16/16 [==============================] - 0s 913us/step - loss: 0.8782\n16/16 [==============================] - 0s 683us/step - loss: 1.4573\n16/16 [==============================] - 0s 2ms/step - loss: 1.7431\n16/16 [==============================] - 0s 1ms/step - loss: 1.7923\n16/16 [==============================] - 0s 1ms/step - loss: 1.8028\n16/16 [==============================] - 0s 647us/step - loss: 1.8033\n16/16 [==============================] - 0s 633us/step - loss: 1.8024\n16/16 [==============================] - 0s 573us/step - loss: 1.8015\n16/16 [==============================] - 0s 2ms/step - loss: 1.8011\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 712us/step - loss: 0.3296\n16/16 [==============================] - 0s 757us/step - loss: 0.8910\n16/16 [==============================] - 0s 1ms/step - loss: 1.4933\n16/16 [==============================] - 0s 676us/step - loss: 1.7869\n16/16 [==============================] - 0s 639us/step - loss: 1.8366\n16/16 [==============================] - 0s 622us/step - loss: 1.8470\n16/16 [==============================] - 0s 605us/step - loss: 1.8474\n16/16 [==============================] - 0s 1ms/step - loss: 1.8464\n16/16 [==============================] - 0s 1ms/step - loss: 1.8456\n16/16 [==============================] - 0s 1ms/step - loss: 1.8451\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3304\n16/16 [==============================] - 0s 1ms/step - loss: 0.8862\n16/16 [==============================] - 0s 704us/step - loss: 1.4818\n16/16 [==============================] - 0s 1ms/step - loss: 1.7733\n16/16 [==============================] - 0s 679us/step - loss: 1.8222\n16/16 [==============================] - 0s 644us/step - loss: 1.8324\n16/16 [==============================] - 0s 1ms/step - loss: 1.8327\n16/16 [==============================] - 0s 1ms/step - loss: 1.8318\n16/16 [==============================] - 0s 653us/step - loss: 1.8309\n16/16 [==============================] - 0s 1ms/step - loss: 1.8304\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 769us/step - loss: 0.3289\n16/16 [==============================] - 0s 1ms/step - loss: 0.8923\n16/16 [==============================] - 0s 889us/step - loss: 1.4981\n16/16 [==============================] - 0s 676us/step - loss: 1.7912\n16/16 [==============================] - 0s 576us/step - loss: 1.8395\n16/16 [==============================] - 0s 594us/step - loss: 1.8492\n16/16 [==============================] - 0s 614us/step - loss: 1.8493\n16/16 [==============================] - 0s 754us/step - loss: 1.8483\n16/16 [==============================] - 0s 1ms/step - loss: 1.8474\n16/16 [==============================] - 0s 620us/step - loss: 1.8469\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3236\n16/16 [==============================] - 0s 669us/step - loss: 0.8897\n16/16 [==============================] - 0s 1ms/step - loss: 1.4962\n16/16 [==============================] - 0s 622us/step - loss: 1.7918\n16/16 [==============================] - 0s 636us/step - loss: 1.8402\n16/16 [==============================] - 0s 609us/step - loss: 1.8499\n16/16 [==============================] - 0s 589us/step - loss: 1.8499\n16/16 [==============================] - 0s 1ms/step - loss: 1.8488\n16/16 [==============================] - 0s 1ms/step - loss: 1.8479\n16/16 [==============================] - 0s 1ms/step - loss: 1.8474\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3240\n16/16 [==============================] - 0s 1ms/step - loss: 0.9065\n16/16 [==============================] - 0s 1ms/step - loss: 1.5340\n16/16 [==============================] - 0s 699us/step - loss: 1.8380\n16/16 [==============================] - 0s 644us/step - loss: 1.8875\n16/16 [==============================] - 0s 603us/step - loss: 1.8973\n16/16 [==============================] - 0s 1ms/step - loss: 1.8974\n16/16 [==============================] - 0s 1ms/step - loss: 1.8964\n16/16 [==============================] - 0s 1ms/step - loss: 1.8954\n16/16 [==============================] - 0s 773us/step - loss: 1.8950\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3120\n16/16 [==============================] - 0s 980us/step - loss: 0.9140\n16/16 [==============================] - 0s 1ms/step - loss: 1.5655\n16/16 [==============================] - 0s 1ms/step - loss: 1.8840\n16/16 [==============================] - 0s 1ms/step - loss: 1.9360\n16/16 [==============================] - 0s 677us/step - loss: 1.9465\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 736us/step - loss: 1.9458\n16/16 [==============================] - 0s 645us/step - loss: 1.9449\n16/16 [==============================] - 0s 648us/step - loss: 1.9444\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 673us/step - loss: 0.3280\n16/16 [==============================] - 0s 651us/step - loss: 0.8989\n16/16 [==============================] - 0s 1ms/step - loss: 1.5171\n16/16 [==============================] - 0s 626us/step - loss: 1.8154\n16/16 [==============================] - 0s 1ms/step - loss: 1.8629\n16/16 [==============================] - 0s 629us/step - loss: 1.8720\n16/16 [==============================] - 0s 1ms/step - loss: 1.8720\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n16/16 [==============================] - 0s 1ms/step - loss: 1.8700\n16/16 [==============================] - 0s 632us/step - loss: 1.8696\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3253\n16/16 [==============================] - 0s 816us/step - loss: 0.8820\n16/16 [==============================] - 0s 782us/step - loss: 1.4859\n16/16 [==============================] - 0s 1ms/step - loss: 1.7760\n16/16 [==============================] - 0s 1ms/step - loss: 1.8211\n16/16 [==============================] - 0s 672us/step - loss: 1.8292\n16/16 [==============================] - 0s 2ms/step - loss: 1.8287\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 2ms/step - loss: 1.8265\n16/16 [==============================] - 0s 705us/step - loss: 1.8259\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.3018\n16/16 [==============================] - 0s 609us/step - loss: 0.9113\n16/16 [==============================] - 0s 1ms/step - loss: 1.5796\n16/16 [==============================] - 0s 1ms/step - loss: 1.8997\n16/16 [==============================] - 0s 1ms/step - loss: 1.9496\n16/16 [==============================] - 0s 657us/step - loss: 1.9589\n16/16 [==============================] - 0s 591us/step - loss: 1.9587\n16/16 [==============================] - 0s 1ms/step - loss: 1.9575\n16/16 [==============================] - 0s 2ms/step - loss: 1.9565\n16/16 [==============================] - 0s 893us/step - loss: 1.9560\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3160\n16/16 [==============================] - 0s 649us/step - loss: 0.8929\n16/16 [==============================] - 0s 663us/step - loss: 1.5280\n16/16 [==============================] - 0s 668us/step - loss: 1.8325\n16/16 [==============================] - 0s 1ms/step - loss: 1.8797\n16/16 [==============================] - 0s 698us/step - loss: 1.8884\n16/16 [==============================] - 0s 700us/step - loss: 1.8881\n16/16 [==============================] - 0s 631us/step - loss: 1.8869\n16/16 [==============================] - 0s 1ms/step - loss: 1.8859\n16/16 [==============================] - 0s 649us/step - loss: 1.8854\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 684us/step - loss: 0.3158\n16/16 [==============================] - 0s 627us/step - loss: 0.9064\n16/16 [==============================] - 0s 1ms/step - loss: 1.5588\n16/16 [==============================] - 0s 632us/step - loss: 1.8678\n16/16 [==============================] - 0s 618us/step - loss: 1.9149\n16/16 [==============================] - 0s 585us/step - loss: 1.9232\n16/16 [==============================] - 0s 1ms/step - loss: 1.9228\n16/16 [==============================] - 0s 1ms/step - loss: 1.9215\n16/16 [==============================] - 0s 1ms/step - loss: 1.9205\n16/16 [==============================] - 0s 694us/step - loss: 1.9200\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 695us/step - loss: 0.3114\n16/16 [==============================] - 0s 805us/step - loss: 0.8972\n16/16 [==============================] - 0s 899us/step - loss: 1.5487\n16/16 [==============================] - 0s 1ms/step - loss: 1.8577\n16/16 [==============================] - 0s 705us/step - loss: 1.9042\n16/16 [==============================] - 0s 597us/step - loss: 1.9123\n16/16 [==============================] - 0s 630us/step - loss: 1.9118\n16/16 [==============================] - 0s 706us/step - loss: 1.9105\n16/16 [==============================] - 0s 1ms/step - loss: 1.9094\n16/16 [==============================] - 0s 790us/step - loss: 1.9089\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3079\n16/16 [==============================] - 0s 1ms/step - loss: 0.9138\n16/16 [==============================] - 0s 610us/step - loss: 1.5910\n16/16 [==============================] - 0s 1ms/step - loss: 1.9092\n16/16 [==============================] - 0s 680us/step - loss: 1.9566\n16/16 [==============================] - 0s 609us/step - loss: 1.9647\n16/16 [==============================] - 0s 617us/step - loss: 1.9641\n16/16 [==============================] - 0s 620us/step - loss: 1.9628\n16/16 [==============================] - 0s 621us/step - loss: 1.9617\n16/16 [==============================] - 0s 639us/step - loss: 1.9612\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2996\n16/16 [==============================] - 0s 668us/step - loss: 0.9044\n16/16 [==============================] - 0s 1ms/step - loss: 1.5879\n16/16 [==============================] - 0s 1ms/step - loss: 1.9109\n16/16 [==============================] - 0s 1ms/step - loss: 1.9594\n16/16 [==============================] - 0s 1ms/step - loss: 1.9680\n16/16 [==============================] - 0s 677us/step - loss: 1.9676\n16/16 [==============================] - 0s 640us/step - loss: 1.9664\n16/16 [==============================] - 0s 630us/step - loss: 1.9654\n16/16 [==============================] - 0s 612us/step - loss: 1.9649\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.3126\n16/16 [==============================] - 0s 1ms/step - loss: 0.8881\n16/16 [==============================] - 0s 985us/step - loss: 1.5372\n16/16 [==============================] - 0s 2ms/step - loss: 1.8393\n16/16 [==============================] - 0s 621us/step - loss: 1.8833\n16/16 [==============================] - 0s 753us/step - loss: 1.8904\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 602us/step - loss: 1.8883\n16/16 [==============================] - 0s 689us/step - loss: 1.8872\n16/16 [==============================] - 0s 1ms/step - loss: 1.8867\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 0.3055\n16/16 [==============================] - 0s 641us/step - loss: 0.8975\n16/16 [==============================] - 0s 577us/step - loss: 1.5715\n16/16 [==============================] - 0s 612us/step - loss: 1.8861\n16/16 [==============================] - 0s 605us/step - loss: 1.9320\n16/16 [==============================] - 0s 997us/step - loss: 1.9395\n16/16 [==============================] - 0s 1ms/step - loss: 1.9388\n16/16 [==============================] - 0s 644us/step - loss: 1.9374\n16/16 [==============================] - 0s 952us/step - loss: 1.9364\n16/16 [==============================] - 0s 628us/step - loss: 1.9358\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 796us/step - loss: 0.2940\n16/16 [==============================] - 0s 649us/step - loss: 0.9002\n16/16 [==============================] - 0s 1ms/step - loss: 1.5930\n16/16 [==============================] - 0s 964us/step - loss: 1.9135\n16/16 [==============================] - 0s 1ms/step - loss: 1.9596\n16/16 [==============================] - 0s 674us/step - loss: 1.9670\n16/16 [==============================] - 0s 652us/step - loss: 1.9662\n16/16 [==============================] - 0s 642us/step - loss: 1.9648\n16/16 [==============================] - 0s 1ms/step - loss: 1.9638\n16/16 [==============================] - 0s 1ms/step - loss: 1.9633\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 665us/step - loss: 0.3044\n16/16 [==============================] - 0s 665us/step - loss: 0.9019\n16/16 [==============================] - 0s 1ms/step - loss: 1.5888\n16/16 [==============================] - 0s 665us/step - loss: 1.9064\n16/16 [==============================] - 0s 1ms/step - loss: 1.9517\n16/16 [==============================] - 0s 660us/step - loss: 1.9588\n16/16 [==============================] - 0s 691us/step - loss: 1.9579\n16/16 [==============================] - 0s 1ms/step - loss: 1.9565\n16/16 [==============================] - 0s 1ms/step - loss: 1.9554\n16/16 [==============================] - 0s 693us/step - loss: 1.9549\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 939us/step - loss: 0.3020\n16/16 [==============================] - 0s 739us/step - loss: 0.8987\n16/16 [==============================] - 0s 698us/step - loss: 1.5860\n16/16 [==============================] - 0s 1ms/step - loss: 1.9003\n16/16 [==============================] - 0s 652us/step - loss: 1.9445\n16/16 [==============================] - 0s 807us/step - loss: 1.9511\n16/16 [==============================] - 0s 1ms/step - loss: 1.9502\n16/16 [==============================] - 0s 1ms/step - loss: 1.9488\n16/16 [==============================] - 0s 669us/step - loss: 1.9477\n16/16 [==============================] - 0s 642us/step - loss: 1.9472\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 919us/step - loss: 0.2888\n16/16 [==============================] - 0s 799us/step - loss: 0.9191\n16/16 [==============================] - 0s 639us/step - loss: 1.6532\n16/16 [==============================] - 0s 1ms/step - loss: 1.9907\n16/16 [==============================] - 0s 617us/step - loss: 2.0383\n16/16 [==============================] - 0s 1000us/step - loss: 2.0458\n16/16 [==============================] - 0s 1ms/step - loss: 2.0449\n16/16 [==============================] - 0s 617us/step - loss: 2.0435\n16/16 [==============================] - 0s 1ms/step - loss: 2.0424\n16/16 [==============================] - 0s 617us/step - loss: 2.0419\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2896\n16/16 [==============================] - 0s 692us/step - loss: 0.9198\n16/16 [==============================] - 0s 662us/step - loss: 1.6543\n16/16 [==============================] - 0s 644us/step - loss: 1.9879\n16/16 [==============================] - 0s 1ms/step - loss: 2.0342\n16/16 [==============================] - 0s 642us/step - loss: 2.0410\n16/16 [==============================] - 0s 1ms/step - loss: 2.0401\n16/16 [==============================] - 0s 1ms/step - loss: 2.0387\n16/16 [==============================] - 0s 1ms/step - loss: 2.0376\n16/16 [==============================] - 0s 1ms/step - loss: 2.0371\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2887\n16/16 [==============================] - 0s 655us/step - loss: 0.9164\n16/16 [==============================] - 0s 625us/step - loss: 1.6524\n16/16 [==============================] - 0s 664us/step - loss: 1.9863\n16/16 [==============================] - 0s 1ms/step - loss: 2.0320\n16/16 [==============================] - 0s 1ms/step - loss: 2.0386\n16/16 [==============================] - 0s 695us/step - loss: 2.0375\n16/16 [==============================] - 0s 671us/step - loss: 2.0360\n16/16 [==============================] - 0s 593us/step - loss: 2.0348\n16/16 [==============================] - 0s 592us/step - loss: 2.0343\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2903\n16/16 [==============================] - 0s 652us/step - loss: 0.9111\n16/16 [==============================] - 0s 634us/step - loss: 1.6388\n16/16 [==============================] - 0s 820us/step - loss: 1.9646\n16/16 [==============================] - 0s 1ms/step - loss: 2.0082\n16/16 [==============================] - 0s 730us/step - loss: 2.0139\n16/16 [==============================] - 0s 592us/step - loss: 2.0126\n16/16 [==============================] - 0s 590us/step - loss: 2.0110\n16/16 [==============================] - 0s 854us/step - loss: 2.0098\n16/16 [==============================] - 0s 639us/step - loss: 2.0093\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2907\n16/16 [==============================] - 0s 1ms/step - loss: 0.9147\n16/16 [==============================] - 0s 719us/step - loss: 1.6530\n16/16 [==============================] - 0s 658us/step - loss: 1.9850\n16/16 [==============================] - 0s 634us/step - loss: 2.0298\n16/16 [==============================] - 0s 653us/step - loss: 2.0361\n16/16 [==============================] - 0s 2ms/step - loss: 2.0350\n16/16 [==============================] - 0s 1ms/step - loss: 2.0335\n16/16 [==============================] - 0s 625us/step - loss: 2.0324\n16/16 [==============================] - 0s 2ms/step - loss: 2.0319\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2956\n16/16 [==============================] - 0s 1ms/step - loss: 0.9136\n16/16 [==============================] - 0s 1ms/step - loss: 1.6438\n16/16 [==============================] - 0s 1ms/step - loss: 1.9674\n16/16 [==============================] - 0s 1ms/step - loss: 2.0101\n16/16 [==============================] - 0s 1ms/step - loss: 2.0156\n16/16 [==============================] - 0s 1ms/step - loss: 2.0143\n16/16 [==============================] - 0s 1ms/step - loss: 2.0127\n16/16 [==============================] - 0s 1ms/step - loss: 2.0116\n16/16 [==============================] - 0s 1ms/step - loss: 2.0111\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2939\n16/16 [==============================] - 0s 1ms/step - loss: 0.9110\n16/16 [==============================] - 0s 1ms/step - loss: 1.6463\n16/16 [==============================] - 0s 1ms/step - loss: 1.9729\n16/16 [==============================] - 0s 2ms/step - loss: 2.0161\n16/16 [==============================] - 0s 2ms/step - loss: 2.0218\n16/16 [==============================] - 0s 1ms/step - loss: 2.0206\n16/16 [==============================] - 0s 1ms/step - loss: 2.0191\n16/16 [==============================] - 0s 1ms/step - loss: 2.0180\n16/16 [==============================] - 0s 679us/step - loss: 2.0175\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2919\n16/16 [==============================] - 0s 2ms/step - loss: 0.9017\n16/16 [==============================] - 0s 1ms/step - loss: 1.6263\n16/16 [==============================] - 0s 1ms/step - loss: 1.9428\n16/16 [==============================] - 0s 1ms/step - loss: 1.9832\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 694us/step - loss: 1.9863\n16/16 [==============================] - 0s 642us/step - loss: 1.9846\n16/16 [==============================] - 0s 593us/step - loss: 1.9834\n16/16 [==============================] - 0s 607us/step - loss: 1.9829\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 627us/step - loss: 0.2932\n16/16 [==============================] - 0s 619us/step - loss: 0.8949\n16/16 [==============================] - 0s 621us/step - loss: 1.6136\n16/16 [==============================] - 0s 623us/step - loss: 1.9271\n16/16 [==============================] - 0s 610us/step - loss: 1.9666\n16/16 [==============================] - 0s 1ms/step - loss: 1.9708\n16/16 [==============================] - 0s 1ms/step - loss: 1.9692\n16/16 [==============================] - 0s 629us/step - loss: 1.9675\n16/16 [==============================] - 0s 1ms/step - loss: 1.9663\n16/16 [==============================] - 0s 580us/step - loss: 1.9658\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2877\n16/16 [==============================] - 0s 1ms/step - loss: 0.9139\n16/16 [==============================] - 0s 1ms/step - loss: 1.6633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9868\n16/16 [==============================] - 0s 1ms/step - loss: 2.0271\n16/16 [==============================] - 0s 654us/step - loss: 2.0314\n16/16 [==============================] - 0s 683us/step - loss: 2.0298\n16/16 [==============================] - 0s 615us/step - loss: 2.0281\n16/16 [==============================] - 0s 1ms/step - loss: 2.0269\n16/16 [==============================] - 0s 663us/step - loss: 2.0263\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 742us/step - loss: 0.2883\n16/16 [==============================] - 0s 641us/step - loss: 0.8940\n16/16 [==============================] - 0s 1ms/step - loss: 1.6224\n16/16 [==============================] - 0s 634us/step - loss: 1.9361\n16/16 [==============================] - 0s 617us/step - loss: 1.9749\n16/16 [==============================] - 0s 1ms/step - loss: 1.9788\n16/16 [==============================] - 0s 628us/step - loss: 1.9771\n16/16 [==============================] - 0s 628us/step - loss: 1.9755\n16/16 [==============================] - 0s 1ms/step - loss: 1.9743\n16/16 [==============================] - 0s 802us/step - loss: 1.9737\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 0.2843\n16/16 [==============================] - 0s 1ms/step - loss: 0.9090\n16/16 [==============================] - 0s 1ms/step - loss: 1.6600\n16/16 [==============================] - 0s 712us/step - loss: 1.9791\n16/16 [==============================] - 0s 648us/step - loss: 2.0175\n16/16 [==============================] - 0s 647us/step - loss: 2.0210\n16/16 [==============================] - 0s 613us/step - loss: 2.0192\n16/16 [==============================] - 0s 629us/step - loss: 2.0174\n16/16 [==============================] - 0s 1ms/step - loss: 2.0162\n16/16 [==============================] - 0s 859us/step - loss: 2.0156\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2836\n16/16 [==============================] - 0s 1ms/step - loss: 0.9146\n16/16 [==============================] - 0s 2ms/step - loss: 1.6782\n16/16 [==============================] - 0s 1ms/step - loss: 2.0028\n16/16 [==============================] - 0s 1ms/step - loss: 2.0419\n16/16 [==============================] - 0s 1ms/step - loss: 2.0457\n16/16 [==============================] - 0s 1ms/step - loss: 2.0439\n16/16 [==============================] - 0s 1ms/step - loss: 2.0422\n16/16 [==============================] - 0s 676us/step - loss: 2.0410\n16/16 [==============================] - 0s 2ms/step - loss: 2.0405\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 684us/step - loss: 0.2791\n16/16 [==============================] - 0s 1ms/step - loss: 0.9413\n16/16 [==============================] - 0s 1ms/step - loss: 1.7429\n16/16 [==============================] - 0s 1ms/step - loss: 2.0793\n16/16 [==============================] - 0s 748us/step - loss: 2.1192\n16/16 [==============================] - 0s 1ms/step - loss: 2.1229\n16/16 [==============================] - 0s 657us/step - loss: 2.1211\n16/16 [==============================] - 0s 826us/step - loss: 2.1193\n16/16 [==============================] - 0s 654us/step - loss: 2.1181\n16/16 [==============================] - 0s 662us/step - loss: 2.1176\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 623us/step - loss: 0.2745\n16/16 [==============================] - 0s 636us/step - loss: 0.9399\n16/16 [==============================] - 0s 604us/step - loss: 1.7502\n16/16 [==============================] - 0s 1ms/step - loss: 2.0900\n16/16 [==============================] - 0s 1ms/step - loss: 2.1304\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 2ms/step - loss: 2.1327\n16/16 [==============================] - 0s 1ms/step - loss: 2.1310\n16/16 [==============================] - 0s 1ms/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.1293\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 850us/step - loss: 0.2705\n16/16 [==============================] - 0s 624us/step - loss: 0.9431\n16/16 [==============================] - 0s 626us/step - loss: 1.7595\n16/16 [==============================] - 0s 946us/step - loss: 2.0960\n16/16 [==============================] - 0s 631us/step - loss: 2.1341\n16/16 [==============================] - 0s 653us/step - loss: 2.1372\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 745us/step - loss: 2.1335\n16/16 [==============================] - 0s 1ms/step - loss: 2.1322\n16/16 [==============================] - 0s 1ms/step - loss: 2.1317\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.2706\n16/16 [==============================] - 0s 1ms/step - loss: 0.9454\n16/16 [==============================] - 0s 1ms/step - loss: 1.7683\n16/16 [==============================] - 0s 1ms/step - loss: 2.1066\n16/16 [==============================] - 0s 1ms/step - loss: 2.1448\n16/16 [==============================] - 0s 1ms/step - loss: 2.1478\n16/16 [==============================] - 0s 1ms/step - loss: 2.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.1441\n16/16 [==============================] - 0s 676us/step - loss: 2.1429\n16/16 [==============================] - 0s 1ms/step - loss: 2.1423\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 0.2763\n16/16 [==============================] - 0s 1ms/step - loss: 0.9427\n16/16 [==============================] - 0s 690us/step - loss: 1.7522\n16/16 [==============================] - 0s 1ms/step - loss: 2.0797\n16/16 [==============================] - 0s 717us/step - loss: 2.1151\n16/16 [==============================] - 0s 650us/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.1151\n16/16 [==============================] - 0s 1ms/step - loss: 2.1133\n16/16 [==============================] - 0s 674us/step - loss: 2.1120\n16/16 [==============================] - 0s 1ms/step - loss: 2.1114\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.2810\n16/16 [==============================] - 0s 668us/step - loss: 0.9270\n16/16 [==============================] - 0s 615us/step - loss: 1.7161\n16/16 [==============================] - 0s 637us/step - loss: 2.0351\n16/16 [==============================] - 0s 1ms/step - loss: 2.0696\n16/16 [==============================] - 0s 694us/step - loss: 2.0717\n16/16 [==============================] - 0s 1ms/step - loss: 2.0696\n16/16 [==============================] - 0s 641us/step - loss: 2.0678\n16/16 [==============================] - 0s 599us/step - loss: 2.0666\n16/16 [==============================] - 0s 624us/step - loss: 2.0660\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.879\nPrecision: 0.955\nRecall: 0.916\nF1 Score: 0.935\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.908\nPrecision: 0.977\nRecall: 0.925\nF1 Score: 0.950\n\n\n\nfourteen_linear = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#linear-result",
    "title": "Class code for Comparison Study",
    "section": "Linear Result",
    "text": "Linear Result\n\nround(fourteen_linear,3)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.959\n      0.960\n      0.999\n      0.979\n    \n    \n      LOF (Breunig et al., 2000)\n      0.890\n      0.973\n      0.909\n      0.940\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.912\n      0.979\n      0.927\n      0.952\n    \n    \n      CBLOF (He et al., 2003)\n      0.920\n      0.958\n      0.958\n      0.958\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.909\n      0.978\n      0.925\n      0.951\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.918\n      0.982\n      0.931\n      0.956\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.918\n      0.982\n      0.931\n      0.956\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.946\n      0.972\n      0.972\n      0.972\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.800\n      0.984\n      0.802\n      0.884\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.889\n      0.960\n      0.921\n      0.940\n    \n    \n      SOS (Janssens et al., 2012)\n      0.889\n      0.960\n      0.921\n      0.940\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.868\n      0.954\n      0.904\n      0.929\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.879\n      0.955\n      0.916\n      0.935\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.908\n      0.977\n      0.925\n      0.950"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-ebayesthresh",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-ebayesthresh",
    "title": "Class code for Comparison Study",
    "section": "Orbit EbayesThresh",
    "text": "Orbit EbayesThresh\n\n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nepsilon = rnorm(1000)\nsignal = sample(c(runif(25,-7,-5), runif(25,5,7), rep(0,950)))\nindex_of_trueoutlier = which(signal!=0)\nindex_of_trueoutlier\nx=signal+epsilon\nplot(1:1000,x)\npoints(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)\n\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\n\n\n\n%R -o x\n%R -o index_of_trueoutlier\n%R -o signal\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n# plt.plot(x)\n# plt.plot(xhat)\n\n\noutlier_true_index = index_of_trueoutlier\n\n\noutlier_true_value = x[index_of_trueoutlier]\n\npackageì™€ ë¹„êµë¥¼ ìœ„í•´ outlierëŠ” -1, inlierëŠ” 1ë¡œ í‘œì‹œ\n\noutlier_true_one = signal.copy()\n\n\noutlier_true_one = list(map(lambda x: -1 if x!=0 else 1,outlier_true_one))"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit",
    "title": "Class code for Comparison Study",
    "section": "Orbit",
    "text": "Orbit\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\n_df = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f})\n\n\nX = np.array(_df)\n\n\nGODE\n\n_Orbit = Orbit(_df)\n\n\n_Orbit.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 497.54it/s]\n\n\n\n_Orbit.get_weightmatrix(theta=(_Orbit.D[_Orbit.D>0].mean()),kappa=2500) \n\n\n_Orbit.fit(sd=15,ref=20)\n\n\noutlier_simul_one = (_Orbit.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 20 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.997\nPrecision: 0.997\nRecall: 1.000\nF1 Score: 0.998\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.886\nPrecision: 0.987\nRecall: 0.892\nF1 Score: 0.937\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','f']])\n_df['knn_clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','f']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.918\nPrecision: 0.957\nRecall: 0.957\nF1 Score: 0.957\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.923\nPrecision: 0.988\nRecall: 0.931\nF1 Score: 0.958\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y','f']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.866\nPrecision: 0.953\nRecall: 0.903\nF1 Score: 0.928\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y','f']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.912\nPrecision: 0.979\nRecall: 0.927\nF1 Score: 0.952\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','f']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.988\nPrecision: 0.994\nRecall: 0.994\nF1 Score: 0.994\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y','f']])\n\n\npreds = od.predict(\n    _df[['x', 'y','f']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.378\nPrecision: 0.997\nRecall: 0.346\nF1 Score: 0.514\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y','f']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.881\nPrecision: 0.961\nRecall: 0.912\nF1 Score: 0.936\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y','f']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.881\nPrecision: 0.961\nRecall: 0.912\nF1 Score: 0.936\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y','f']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2135\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2178\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 891us/step - loss: 1.2227\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2138\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2244\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 917us/step - loss: 1.2068\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 1.2319\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2260\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2357\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 985us/step - loss: 1.2294\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2426\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2583\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 815us/step - loss: 1.2599\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2752\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 639us/step - loss: 1.3019\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.2905\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 635us/step - loss: 1.3191\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 781us/step - loss: 1.3229\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 1.3371\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3418\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 803us/step - loss: 1.3589\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3819\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.3966\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 956us/step - loss: 1.3947\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 609us/step - loss: 1.4201\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4322\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 617us/step - loss: 1.4333\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 626us/step - loss: 1.4465\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 640us/step - loss: 1.4560\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.4823\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 932us/step - loss: 1.4888\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 782us/step - loss: 1.5030\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5161\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 599us/step - loss: 1.5196\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5412\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 877us/step - loss: 1.5368\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 579us/step - loss: 1.5523\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5574\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 981us/step - loss: 1.5684\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 643us/step - loss: 1.5748\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5725\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.5772\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 1.5934\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6053\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 907us/step - loss: 1.6078\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6025\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6277\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 615us/step - loss: 1.6348\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 815us/step - loss: 1.6427\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 606us/step - loss: 1.6405\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 619us/step - loss: 1.6498\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 812us/step - loss: 1.6603\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 614us/step - loss: 1.6775\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 650us/step - loss: 1.6890\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6979\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.6971\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 624us/step - loss: 1.7076\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7120\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7271\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 863us/step - loss: 1.7406\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 623us/step - loss: 1.7534\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 677us/step - loss: 1.7597\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 741us/step - loss: 1.7555\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 678us/step - loss: 1.7716\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 827us/step - loss: 1.7776\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.7776\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8009\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 626us/step - loss: 1.8053\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8205\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8218\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 666us/step - loss: 1.8259\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8307\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8576\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8445\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 742us/step - loss: 1.8687\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8710\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8824\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8924\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.876\nPrecision: 0.959\nRecall: 0.908\nF1 Score: 0.933\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y','f']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.5986\n16/16 [==============================] - 0s 1ms/step - loss: 1.2168\n16/16 [==============================] - 0s 643us/step - loss: 1.2657\n16/16 [==============================] - 0s 637us/step - loss: 1.2688\n16/16 [==============================] - 0s 1ms/step - loss: 1.2695\n16/16 [==============================] - 0s 1ms/step - loss: 1.2696\n16/16 [==============================] - 0s 653us/step - loss: 1.2696\n16/16 [==============================] - 0s 649us/step - loss: 1.2696\n16/16 [==============================] - 0s 711us/step - loss: 1.2696\n16/16 [==============================] - 0s 1ms/step - loss: 1.2696\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6392\n16/16 [==============================] - 0s 664us/step - loss: 1.2086\n16/16 [==============================] - 0s 711us/step - loss: 1.2461\n16/16 [==============================] - 0s 2ms/step - loss: 1.2488\n16/16 [==============================] - 0s 707us/step - loss: 1.2493\n16/16 [==============================] - 0s 628us/step - loss: 1.2494\n16/16 [==============================] - 0s 642us/step - loss: 1.2494\n16/16 [==============================] - 0s 698us/step - loss: 1.2494\n16/16 [==============================] - 0s 674us/step - loss: 1.2494\n16/16 [==============================] - 0s 788us/step - loss: 1.2494\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 663us/step - loss: 0.6763\n16/16 [==============================] - 0s 1ms/step - loss: 1.2250\n16/16 [==============================] - 0s 1ms/step - loss: 1.2559\n16/16 [==============================] - 0s 642us/step - loss: 1.2583\n16/16 [==============================] - 0s 1ms/step - loss: 1.2588\n16/16 [==============================] - 0s 672us/step - loss: 1.2589\n16/16 [==============================] - 0s 629us/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\n16/16 [==============================] - 0s 1ms/step - loss: 1.2589\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 658us/step - loss: 0.7044\n16/16 [==============================] - 0s 682us/step - loss: 1.2426\n16/16 [==============================] - 0s 661us/step - loss: 1.2710\n16/16 [==============================] - 0s 1ms/step - loss: 1.2733\n16/16 [==============================] - 0s 757us/step - loss: 1.2738\n16/16 [==============================] - 0s 725us/step - loss: 1.2739\n16/16 [==============================] - 0s 1ms/step - loss: 1.2739\n16/16 [==============================] - 0s 1ms/step - loss: 1.2739\n16/16 [==============================] - 0s 638us/step - loss: 1.2739\n16/16 [==============================] - 0s 648us/step - loss: 1.2739\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 660us/step - loss: 0.7203\n16/16 [==============================] - 0s 878us/step - loss: 1.2467\n16/16 [==============================] - 0s 647us/step - loss: 1.2715\n16/16 [==============================] - 0s 1ms/step - loss: 1.2737\n16/16 [==============================] - 0s 1ms/step - loss: 1.2741\n16/16 [==============================] - 0s 637us/step - loss: 1.2742\n16/16 [==============================] - 0s 656us/step - loss: 1.2742\n16/16 [==============================] - 0s 1ms/step - loss: 1.2742\n16/16 [==============================] - 0s 645us/step - loss: 1.2742\n16/16 [==============================] - 0s 689us/step - loss: 1.2742\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 656us/step - loss: 0.7260\n16/16 [==============================] - 0s 1ms/step - loss: 1.2580\n16/16 [==============================] - 0s 655us/step - loss: 1.2817\n16/16 [==============================] - 0s 1ms/step - loss: 1.2839\n16/16 [==============================] - 0s 846us/step - loss: 1.2844\n16/16 [==============================] - 0s 696us/step - loss: 1.2844\n16/16 [==============================] - 0s 926us/step - loss: 1.2845\n16/16 [==============================] - 0s 661us/step - loss: 1.2845\n16/16 [==============================] - 0s 1ms/step - loss: 1.2845\n16/16 [==============================] - 0s 1ms/step - loss: 1.2845\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 641us/step - loss: 0.7292\n16/16 [==============================] - 0s 632us/step - loss: 1.2735\n16/16 [==============================] - 0s 780us/step - loss: 1.2970\n16/16 [==============================] - 0s 1ms/step - loss: 1.2995\n16/16 [==============================] - 0s 637us/step - loss: 1.2999\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 981us/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\n16/16 [==============================] - 0s 1ms/step - loss: 1.3000\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7228\n16/16 [==============================] - 0s 1ms/step - loss: 1.2928\n16/16 [==============================] - 0s 1ms/step - loss: 1.3171\n16/16 [==============================] - 0s 821us/step - loss: 1.3198\n16/16 [==============================] - 0s 611us/step - loss: 1.3203\n16/16 [==============================] - 0s 690us/step - loss: 1.3204\n16/16 [==============================] - 0s 647us/step - loss: 1.3204\n16/16 [==============================] - 0s 1ms/step - loss: 1.3204\n16/16 [==============================] - 0s 974us/step - loss: 1.3204\n16/16 [==============================] - 0s 589us/step - loss: 1.3204\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7136\n16/16 [==============================] - 0s 1ms/step - loss: 1.3031\n16/16 [==============================] - 0s 643us/step - loss: 1.3286\n16/16 [==============================] - 0s 1ms/step - loss: 1.3313\n16/16 [==============================] - 0s 948us/step - loss: 1.3319\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 802us/step - loss: 1.3320\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 1ms/step - loss: 1.3320\n16/16 [==============================] - 0s 837us/step - loss: 1.3320\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 631us/step - loss: 0.6966\n16/16 [==============================] - 0s 1ms/step - loss: 1.3288\n16/16 [==============================] - 0s 820us/step - loss: 1.3566\n16/16 [==============================] - 0s 934us/step - loss: 1.3598\n16/16 [==============================] - 0s 1ms/step - loss: 1.3604\n16/16 [==============================] - 0s 1ms/step - loss: 1.3605\n16/16 [==============================] - 0s 1ms/step - loss: 1.3605\n16/16 [==============================] - 0s 635us/step - loss: 1.3605\n16/16 [==============================] - 0s 865us/step - loss: 1.3605\n16/16 [==============================] - 0s 630us/step - loss: 1.3605\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6781\n16/16 [==============================] - 0s 1ms/step - loss: 1.3420\n16/16 [==============================] - 0s 862us/step - loss: 1.3719\n16/16 [==============================] - 0s 635us/step - loss: 1.3756\n16/16 [==============================] - 0s 611us/step - loss: 1.3763\n16/16 [==============================] - 0s 626us/step - loss: 1.3764\n16/16 [==============================] - 0s 796us/step - loss: 1.3764\n16/16 [==============================] - 0s 1ms/step - loss: 1.3764\n16/16 [==============================] - 0s 920us/step - loss: 1.3764\n16/16 [==============================] - 0s 596us/step - loss: 1.3764\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 0.6549\n16/16 [==============================] - 0s 1ms/step - loss: 1.3709\n16/16 [==============================] - 0s 712us/step - loss: 1.4048\n16/16 [==============================] - 0s 724us/step - loss: 1.4090\n16/16 [==============================] - 0s 749us/step - loss: 1.4098\n16/16 [==============================] - 0s 653us/step - loss: 1.4099\n16/16 [==============================] - 0s 629us/step - loss: 1.4099\n16/16 [==============================] - 0s 1ms/step - loss: 1.4099\n16/16 [==============================] - 0s 723us/step - loss: 1.4099\n16/16 [==============================] - 0s 634us/step - loss: 1.4099\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 0.6334\n16/16 [==============================] - 0s 618us/step - loss: 1.3962\n16/16 [==============================] - 0s 603us/step - loss: 1.4358\n16/16 [==============================] - 0s 1ms/step - loss: 1.4403\n16/16 [==============================] - 0s 1ms/step - loss: 1.4413\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\n16/16 [==============================] - 0s 893us/step - loss: 1.4415\n16/16 [==============================] - 0s 598us/step - loss: 1.4415\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\n16/16 [==============================] - 0s 1ms/step - loss: 1.4414\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 662us/step - loss: 0.6050\n16/16 [==============================] - 0s 1ms/step - loss: 1.4078\n16/16 [==============================] - 0s 1ms/step - loss: 1.4521\n16/16 [==============================] - 0s 818us/step - loss: 1.4572\n16/16 [==============================] - 0s 993us/step - loss: 1.4584\n16/16 [==============================] - 0s 1ms/step - loss: 1.4585\n16/16 [==============================] - 0s 1ms/step - loss: 1.4586\n16/16 [==============================] - 0s 1ms/step - loss: 1.4586\n16/16 [==============================] - 0s 765us/step - loss: 1.4585\n16/16 [==============================] - 0s 1ms/step - loss: 1.4585\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5843\n16/16 [==============================] - 0s 739us/step - loss: 1.4360\n16/16 [==============================] - 0s 1ms/step - loss: 1.4867\n16/16 [==============================] - 0s 582us/step - loss: 1.4928\n16/16 [==============================] - 0s 1ms/step - loss: 1.4941\n16/16 [==============================] - 0s 684us/step - loss: 1.4943\n16/16 [==============================] - 0s 884us/step - loss: 1.4943\n16/16 [==============================] - 0s 746us/step - loss: 1.4943\n16/16 [==============================] - 0s 997us/step - loss: 1.4943\n16/16 [==============================] - 0s 1ms/step - loss: 1.4942\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5581\n16/16 [==============================] - 0s 1ms/step - loss: 1.4546\n16/16 [==============================] - 0s 1ms/step - loss: 1.5115\n16/16 [==============================] - 0s 1ms/step - loss: 1.5182\n16/16 [==============================] - 0s 1ms/step - loss: 1.5197\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 1ms/step - loss: 1.5199\n16/16 [==============================] - 0s 612us/step - loss: 1.5199\n16/16 [==============================] - 0s 650us/step - loss: 1.5199\n16/16 [==============================] - 0s 642us/step - loss: 1.5199\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 601us/step - loss: 0.5402\n16/16 [==============================] - 0s 900us/step - loss: 1.4761\n16/16 [==============================] - 0s 1ms/step - loss: 1.5388\n16/16 [==============================] - 0s 1ms/step - loss: 1.5458\n16/16 [==============================] - 0s 1ms/step - loss: 1.5476\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 593us/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\n16/16 [==============================] - 0s 1ms/step - loss: 1.5478\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 769us/step - loss: 0.5184\n16/16 [==============================] - 0s 606us/step - loss: 1.5000\n16/16 [==============================] - 0s 908us/step - loss: 1.5668\n16/16 [==============================] - 0s 1ms/step - loss: 1.5748\n16/16 [==============================] - 0s 1ms/step - loss: 1.5767\n16/16 [==============================] - 0s 1ms/step - loss: 1.5769\n16/16 [==============================] - 0s 1ms/step - loss: 1.5769\n16/16 [==============================] - 0s 705us/step - loss: 1.5769\n16/16 [==============================] - 0s 613us/step - loss: 1.5769\n16/16 [==============================] - 0s 671us/step - loss: 1.5768\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 603us/step - loss: 0.5062\n16/16 [==============================] - 0s 629us/step - loss: 1.5280\n16/16 [==============================] - 0s 751us/step - loss: 1.5999\n16/16 [==============================] - 0s 615us/step - loss: 1.6088\n16/16 [==============================] - 0s 929us/step - loss: 1.6109\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 613us/step - loss: 1.6112\n16/16 [==============================] - 0s 1ms/step - loss: 1.6112\n16/16 [==============================] - 0s 876us/step - loss: 1.6112\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 663us/step - loss: 0.4910\n16/16 [==============================] - 0s 1ms/step - loss: 1.5266\n16/16 [==============================] - 0s 1ms/step - loss: 1.6021\n16/16 [==============================] - 0s 1ms/step - loss: 1.6113\n16/16 [==============================] - 0s 763us/step - loss: 1.6135\n16/16 [==============================] - 0s 956us/step - loss: 1.6138\n16/16 [==============================] - 0s 611us/step - loss: 1.6139\n16/16 [==============================] - 0s 613us/step - loss: 1.6139\n16/16 [==============================] - 0s 1ms/step - loss: 1.6138\n16/16 [==============================] - 0s 718us/step - loss: 1.6138\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4859\n16/16 [==============================] - 0s 622us/step - loss: 1.5514\n16/16 [==============================] - 0s 608us/step - loss: 1.6294\n16/16 [==============================] - 0s 1ms/step - loss: 1.6390\n16/16 [==============================] - 0s 634us/step - loss: 1.6414\n16/16 [==============================] - 0s 593us/step - loss: 1.6417\n16/16 [==============================] - 0s 656us/step - loss: 1.6417\n16/16 [==============================] - 0s 606us/step - loss: 1.6417\n16/16 [==============================] - 0s 627us/step - loss: 1.6417\n16/16 [==============================] - 0s 951us/step - loss: 1.6416\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 886us/step - loss: 0.4775\n16/16 [==============================] - 0s 631us/step - loss: 1.5698\n16/16 [==============================] - 0s 1ms/step - loss: 1.6491\n16/16 [==============================] - 0s 1ms/step - loss: 1.6591\n16/16 [==============================] - 0s 642us/step - loss: 1.6617\n16/16 [==============================] - 0s 1ms/step - loss: 1.6620\n16/16 [==============================] - 0s 606us/step - loss: 1.6621\n16/16 [==============================] - 0s 649us/step - loss: 1.6620\n16/16 [==============================] - 0s 622us/step - loss: 1.6620\n16/16 [==============================] - 0s 621us/step - loss: 1.6619\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 0.4795\n16/16 [==============================] - 0s 638us/step - loss: 1.5898\n16/16 [==============================] - 0s 634us/step - loss: 1.6681\n16/16 [==============================] - 0s 1ms/step - loss: 1.6781\n16/16 [==============================] - 0s 677us/step - loss: 1.6809\n16/16 [==============================] - 0s 977us/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\n16/16 [==============================] - 0s 1ms/step - loss: 1.6812\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4773\n16/16 [==============================] - 0s 634us/step - loss: 1.5951\n16/16 [==============================] - 0s 1ms/step - loss: 1.6703\n16/16 [==============================] - 0s 599us/step - loss: 1.6803\n16/16 [==============================] - 0s 685us/step - loss: 1.6830\n16/16 [==============================] - 0s 617us/step - loss: 1.6833\n16/16 [==============================] - 0s 945us/step - loss: 1.6833\n16/16 [==============================] - 0s 1ms/step - loss: 1.6833\n16/16 [==============================] - 0s 1ms/step - loss: 1.6833\n16/16 [==============================] - 0s 602us/step - loss: 1.6832\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4855\n16/16 [==============================] - 0s 1ms/step - loss: 1.6287\n16/16 [==============================] - 0s 1ms/step - loss: 1.7034\n16/16 [==============================] - 0s 1ms/step - loss: 1.7137\n16/16 [==============================] - 0s 639us/step - loss: 1.7163\n16/16 [==============================] - 0s 681us/step - loss: 1.7166\n16/16 [==============================] - 0s 620us/step - loss: 1.7167\n16/16 [==============================] - 0s 583us/step - loss: 1.7167\n16/16 [==============================] - 0s 1ms/step - loss: 1.7167\n16/16 [==============================] - 0s 1ms/step - loss: 1.7166\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.4900\n16/16 [==============================] - 0s 773us/step - loss: 1.6487\n16/16 [==============================] - 0s 624us/step - loss: 1.7219\n16/16 [==============================] - 0s 1ms/step - loss: 1.7322\n16/16 [==============================] - 0s 1ms/step - loss: 1.7348\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 1ms/step - loss: 1.7351\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5048\n16/16 [==============================] - 0s 1ms/step - loss: 1.6447\n16/16 [==============================] - 0s 1ms/step - loss: 1.7129\n16/16 [==============================] - 0s 1ms/step - loss: 1.7226\n16/16 [==============================] - 0s 1ms/step - loss: 1.7250\n16/16 [==============================] - 0s 1ms/step - loss: 1.7253\n16/16 [==============================] - 0s 717us/step - loss: 1.7253\n16/16 [==============================] - 0s 830us/step - loss: 1.7253\n16/16 [==============================] - 0s 624us/step - loss: 1.7253\n16/16 [==============================] - 0s 682us/step - loss: 1.7252\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 648us/step - loss: 0.5151\n16/16 [==============================] - 0s 1ms/step - loss: 1.6720\n16/16 [==============================] - 0s 838us/step - loss: 1.7389\n16/16 [==============================] - 0s 1ms/step - loss: 1.7487\n16/16 [==============================] - 0s 1ms/step - loss: 1.7510\n16/16 [==============================] - 0s 832us/step - loss: 1.7513\n16/16 [==============================] - 0s 1ms/step - loss: 1.7514\n16/16 [==============================] - 0s 595us/step - loss: 1.7514\n16/16 [==============================] - 0s 1ms/step - loss: 1.7514\n16/16 [==============================] - 0s 639us/step - loss: 1.7513\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5348\n16/16 [==============================] - 0s 870us/step - loss: 1.6661\n16/16 [==============================] - 0s 1ms/step - loss: 1.7277\n16/16 [==============================] - 0s 640us/step - loss: 1.7367\n16/16 [==============================] - 0s 897us/step - loss: 1.7389\n16/16 [==============================] - 0s 1ms/step - loss: 1.7391\n16/16 [==============================] - 0s 1ms/step - loss: 1.7392\n16/16 [==============================] - 0s 1ms/step - loss: 1.7392\n16/16 [==============================] - 0s 745us/step - loss: 1.7392\n16/16 [==============================] - 0s 1ms/step - loss: 1.7391\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 688us/step - loss: 0.5491\n16/16 [==============================] - 0s 635us/step - loss: 1.6837\n16/16 [==============================] - 0s 601us/step - loss: 1.7423\n16/16 [==============================] - 0s 601us/step - loss: 1.7511\n16/16 [==============================] - 0s 1ms/step - loss: 1.7531\n16/16 [==============================] - 0s 656us/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n16/16 [==============================] - 0s 1ms/step - loss: 1.7534\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.5738\n16/16 [==============================] - 0s 1ms/step - loss: 1.6942\n16/16 [==============================] - 0s 1ms/step - loss: 1.7482\n16/16 [==============================] - 0s 1ms/step - loss: 1.7566\n16/16 [==============================] - 0s 623us/step - loss: 1.7585\n16/16 [==============================] - 0s 741us/step - loss: 1.7588\n16/16 [==============================] - 0s 774us/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7588\n16/16 [==============================] - 0s 1ms/step - loss: 1.7587\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 604us/step - loss: 0.5910\n16/16 [==============================] - 0s 1ms/step - loss: 1.7056\n16/16 [==============================] - 0s 1ms/step - loss: 1.7570\n16/16 [==============================] - 0s 1ms/step - loss: 1.7652\n16/16 [==============================] - 0s 596us/step - loss: 1.7670\n16/16 [==============================] - 0s 944us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.7673\n16/16 [==============================] - 0s 619us/step - loss: 1.7673\n16/16 [==============================] - 0s 617us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.7673\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 648us/step - loss: 0.6175\n16/16 [==============================] - 0s 628us/step - loss: 1.7136\n16/16 [==============================] - 0s 666us/step - loss: 1.7615\n16/16 [==============================] - 0s 612us/step - loss: 1.7696\n16/16 [==============================] - 0s 1ms/step - loss: 1.7713\n16/16 [==============================] - 0s 742us/step - loss: 1.7715\n16/16 [==============================] - 0s 626us/step - loss: 1.7716\n16/16 [==============================] - 0s 614us/step - loss: 1.7716\n16/16 [==============================] - 0s 623us/step - loss: 1.7715\n16/16 [==============================] - 0s 932us/step - loss: 1.7715\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6365\n16/16 [==============================] - 0s 1ms/step - loss: 1.7285\n16/16 [==============================] - 0s 1ms/step - loss: 1.7737\n16/16 [==============================] - 0s 1ms/step - loss: 1.7815\n16/16 [==============================] - 0s 1ms/step - loss: 1.7831\n16/16 [==============================] - 0s 617us/step - loss: 1.7834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 1ms/step - loss: 1.7834\n16/16 [==============================] - 0s 601us/step - loss: 1.7834\n16/16 [==============================] - 0s 929us/step - loss: 1.7834\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.6645\n16/16 [==============================] - 0s 1ms/step - loss: 1.7425\n16/16 [==============================] - 0s 1ms/step - loss: 1.7848\n16/16 [==============================] - 0s 641us/step - loss: 1.7924\n16/16 [==============================] - 0s 1ms/step - loss: 1.7938\n16/16 [==============================] - 0s 1ms/step - loss: 1.7941\n16/16 [==============================] - 0s 821us/step - loss: 1.7941\n16/16 [==============================] - 0s 1ms/step - loss: 1.7941\n16/16 [==============================] - 0s 626us/step - loss: 1.7941\n16/16 [==============================] - 0s 636us/step - loss: 1.7941\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 634us/step - loss: 0.6840\n16/16 [==============================] - 0s 759us/step - loss: 1.7590\n16/16 [==============================] - 0s 1ms/step - loss: 1.7997\n16/16 [==============================] - 0s 1ms/step - loss: 1.8070\n16/16 [==============================] - 0s 1ms/step - loss: 1.8084\n16/16 [==============================] - 0s 1ms/step - loss: 1.8086\n16/16 [==============================] - 0s 639us/step - loss: 1.8086\n16/16 [==============================] - 0s 621us/step - loss: 1.8086\n16/16 [==============================] - 0s 670us/step - loss: 1.8086\n16/16 [==============================] - 0s 1ms/step - loss: 1.8086\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7124\n16/16 [==============================] - 0s 999us/step - loss: 1.7783\n16/16 [==============================] - 0s 1ms/step - loss: 1.8175\n16/16 [==============================] - 0s 688us/step - loss: 1.8245\n16/16 [==============================] - 0s 1ms/step - loss: 1.8258\n16/16 [==============================] - 0s 1ms/step - loss: 1.8261\n16/16 [==============================] - 0s 716us/step - loss: 1.8261\n16/16 [==============================] - 0s 658us/step - loss: 1.8261\n16/16 [==============================] - 0s 632us/step - loss: 1.8261\n16/16 [==============================] - 0s 635us/step - loss: 1.8261\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 921us/step - loss: 0.7273\n16/16 [==============================] - 0s 863us/step - loss: 1.7767\n16/16 [==============================] - 0s 995us/step - loss: 1.8143\n16/16 [==============================] - 0s 593us/step - loss: 1.8210\n16/16 [==============================] - 0s 1ms/step - loss: 1.8223\n16/16 [==============================] - 0s 877us/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8226\n16/16 [==============================] - 0s 820us/step - loss: 1.8226\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 688us/step - loss: 0.7514\n16/16 [==============================] - 0s 1ms/step - loss: 1.7804\n16/16 [==============================] - 0s 1ms/step - loss: 1.8152\n16/16 [==============================] - 0s 585us/step - loss: 1.8214\n16/16 [==============================] - 0s 1ms/step - loss: 1.8225\n16/16 [==============================] - 0s 619us/step - loss: 1.8227\n16/16 [==============================] - 0s 1ms/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8227\n16/16 [==============================] - 0s 852us/step - loss: 1.8227\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7649\n16/16 [==============================] - 0s 1ms/step - loss: 1.7944\n16/16 [==============================] - 0s 1ms/step - loss: 1.8299\n16/16 [==============================] - 0s 804us/step - loss: 1.8361\n16/16 [==============================] - 0s 1ms/step - loss: 1.8372\n16/16 [==============================] - 0s 612us/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 1ms/step - loss: 1.8375\n16/16 [==============================] - 0s 641us/step - loss: 1.8375\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7882\n16/16 [==============================] - 0s 853us/step - loss: 1.8148\n16/16 [==============================] - 0s 659us/step - loss: 1.8491\n16/16 [==============================] - 0s 615us/step - loss: 1.8553\n16/16 [==============================] - 0s 931us/step - loss: 1.8563\n16/16 [==============================] - 0s 1ms/step - loss: 1.8566\n16/16 [==============================] - 0s 634us/step - loss: 1.8566\n16/16 [==============================] - 0s 861us/step - loss: 1.8566\n16/16 [==============================] - 0s 960us/step - loss: 1.8566\n16/16 [==============================] - 0s 1ms/step - loss: 1.8566\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.7975\n16/16 [==============================] - 0s 646us/step - loss: 1.8225\n16/16 [==============================] - 0s 1ms/step - loss: 1.8555\n16/16 [==============================] - 0s 588us/step - loss: 1.8616\n16/16 [==============================] - 0s 898us/step - loss: 1.8626\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 1ms/step - loss: 1.8628\n16/16 [==============================] - 0s 661us/step - loss: 1.8628\n16/16 [==============================] - 0s 636us/step - loss: 1.8628\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 590us/step - loss: 0.8169\n16/16 [==============================] - 0s 1ms/step - loss: 1.8391\n16/16 [==============================] - 0s 633us/step - loss: 1.8715\n16/16 [==============================] - 0s 585us/step - loss: 1.8774\n16/16 [==============================] - 0s 615us/step - loss: 1.8784\n16/16 [==============================] - 0s 596us/step - loss: 1.8786\n16/16 [==============================] - 0s 1ms/step - loss: 1.8787\n16/16 [==============================] - 0s 1ms/step - loss: 1.8787\n16/16 [==============================] - 0s 631us/step - loss: 1.8787\n16/16 [==============================] - 0s 671us/step - loss: 1.8787\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 865us/step - loss: 0.8231\n16/16 [==============================] - 0s 1ms/step - loss: 1.8496\n16/16 [==============================] - 0s 620us/step - loss: 1.8823\n16/16 [==============================] - 0s 664us/step - loss: 1.8883\n16/16 [==============================] - 0s 600us/step - loss: 1.8893\n16/16 [==============================] - 0s 1ms/step - loss: 1.8895\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 1ms/step - loss: 1.8896\n16/16 [==============================] - 0s 628us/step - loss: 1.8896\n16/16 [==============================] - 0s 1ms/step - loss: 1.8895\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8391\n16/16 [==============================] - 0s 609us/step - loss: 1.8681\n16/16 [==============================] - 0s 871us/step - loss: 1.9009\n16/16 [==============================] - 0s 565us/step - loss: 1.9070\n16/16 [==============================] - 0s 1ms/step - loss: 1.9079\n16/16 [==============================] - 0s 610us/step - loss: 1.9081\n16/16 [==============================] - 0s 637us/step - loss: 1.9082\n16/16 [==============================] - 0s 1ms/step - loss: 1.9082\n16/16 [==============================] - 0s 1ms/step - loss: 1.9082\n16/16 [==============================] - 0s 880us/step - loss: 1.9082\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8437\n16/16 [==============================] - 0s 1ms/step - loss: 1.8798\n16/16 [==============================] - 0s 923us/step - loss: 1.9120\n16/16 [==============================] - 0s 1ms/step - loss: 1.9179\n16/16 [==============================] - 0s 612us/step - loss: 1.9189\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 681us/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n16/16 [==============================] - 0s 1ms/step - loss: 1.9191\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8544\n16/16 [==============================] - 0s 645us/step - loss: 1.8871\n16/16 [==============================] - 0s 632us/step - loss: 1.9189\n16/16 [==============================] - 0s 1ms/step - loss: 1.9248\n16/16 [==============================] - 0s 1ms/step - loss: 1.9257\n16/16 [==============================] - 0s 1ms/step - loss: 1.9259\n16/16 [==============================] - 0s 836us/step - loss: 1.9259\n16/16 [==============================] - 0s 695us/step - loss: 1.9259\n16/16 [==============================] - 0s 1ms/step - loss: 1.9259\n16/16 [==============================] - 0s 808us/step - loss: 1.9259\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8583\n16/16 [==============================] - 0s 1ms/step - loss: 1.9099\n16/16 [==============================] - 0s 785us/step - loss: 1.9431\n16/16 [==============================] - 0s 782us/step - loss: 1.9491\n16/16 [==============================] - 0s 1ms/step - loss: 1.9501\n16/16 [==============================] - 0s 711us/step - loss: 1.9503\n16/16 [==============================] - 0s 617us/step - loss: 1.9503\n16/16 [==============================] - 0s 601us/step - loss: 1.9503\n16/16 [==============================] - 0s 671us/step - loss: 1.9503\n16/16 [==============================] - 0s 602us/step - loss: 1.9504\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8705\n16/16 [==============================] - 0s 1ms/step - loss: 1.9270\n16/16 [==============================] - 0s 928us/step - loss: 1.9599\n16/16 [==============================] - 0s 758us/step - loss: 1.9658\n16/16 [==============================] - 0s 2ms/step - loss: 1.9668\n16/16 [==============================] - 0s 1ms/step - loss: 1.9670\n16/16 [==============================] - 0s 594us/step - loss: 1.9670\n16/16 [==============================] - 0s 600us/step - loss: 1.9670\n16/16 [==============================] - 0s 599us/step - loss: 1.9670\n16/16 [==============================] - 0s 924us/step - loss: 1.9670\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 643us/step - loss: 0.8683\n16/16 [==============================] - 0s 1ms/step - loss: 1.9287\n16/16 [==============================] - 0s 665us/step - loss: 1.9614\n16/16 [==============================] - 0s 1ms/step - loss: 1.9673\n16/16 [==============================] - 0s 1ms/step - loss: 1.9683\n16/16 [==============================] - 0s 1ms/step - loss: 1.9685\n16/16 [==============================] - 0s 654us/step - loss: 1.9685\n16/16 [==============================] - 0s 762us/step - loss: 1.9685\n16/16 [==============================] - 0s 628us/step - loss: 1.9685\n16/16 [==============================] - 0s 654us/step - loss: 1.9685\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 659us/step - loss: 0.8815\n16/16 [==============================] - 0s 1ms/step - loss: 1.9514\n16/16 [==============================] - 0s 1ms/step - loss: 1.9846\n16/16 [==============================] - 0s 1ms/step - loss: 1.9905\n16/16 [==============================] - 0s 1ms/step - loss: 1.9915\n16/16 [==============================] - 0s 786us/step - loss: 1.9916\n16/16 [==============================] - 0s 655us/step - loss: 1.9917\n16/16 [==============================] - 0s 1ms/step - loss: 1.9917\n16/16 [==============================] - 0s 973us/step - loss: 1.9917\n16/16 [==============================] - 0s 1ms/step - loss: 1.9917\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 741us/step - loss: 0.8773\n16/16 [==============================] - 0s 672us/step - loss: 1.9488\n16/16 [==============================] - 0s 660us/step - loss: 1.9816\n16/16 [==============================] - 0s 1ms/step - loss: 1.9875\n16/16 [==============================] - 0s 899us/step - loss: 1.9885\n16/16 [==============================] - 0s 1ms/step - loss: 1.9887\n16/16 [==============================] - 0s 885us/step - loss: 1.9887\n16/16 [==============================] - 0s 661us/step - loss: 1.9887\n16/16 [==============================] - 0s 1ms/step - loss: 1.9887\n16/16 [==============================] - 0s 972us/step - loss: 1.9887\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.8923\n16/16 [==============================] - 0s 802us/step - loss: 1.9764\n16/16 [==============================] - 0s 733us/step - loss: 2.0094\n16/16 [==============================] - 0s 878us/step - loss: 2.0152\n16/16 [==============================] - 0s 667us/step - loss: 2.0162\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 831us/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0164\n16/16 [==============================] - 0s 1ms/step - loss: 2.0165\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.8980\n16/16 [==============================] - 0s 829us/step - loss: 2.0059\n16/16 [==============================] - 0s 1ms/step - loss: 2.0403\n16/16 [==============================] - 0s 1ms/step - loss: 2.0464\n16/16 [==============================] - 0s 991us/step - loss: 2.0474\n16/16 [==============================] - 0s 657us/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n16/16 [==============================] - 0s 625us/step - loss: 2.0476\n16/16 [==============================] - 0s 1ms/step - loss: 2.0476\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 0.9077\n16/16 [==============================] - 0s 1ms/step - loss: 2.0130\n16/16 [==============================] - 0s 1ms/step - loss: 2.0470\n16/16 [==============================] - 0s 953us/step - loss: 2.0530\n16/16 [==============================] - 0s 1ms/step - loss: 2.0539\n16/16 [==============================] - 0s 1ms/step - loss: 2.0541\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\n16/16 [==============================] - 0s 1ms/step - loss: 2.0542\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9081\n16/16 [==============================] - 0s 1ms/step - loss: 2.0204\n16/16 [==============================] - 0s 1ms/step - loss: 2.0543\n16/16 [==============================] - 0s 694us/step - loss: 2.0602\n16/16 [==============================] - 0s 1ms/step - loss: 2.0611\n16/16 [==============================] - 0s 1ms/step - loss: 2.0613\n16/16 [==============================] - 0s 815us/step - loss: 2.0614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0614\n16/16 [==============================] - 0s 804us/step - loss: 2.0614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0614\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9192\n16/16 [==============================] - 0s 2ms/step - loss: 2.0292\n16/16 [==============================] - 0s 1ms/step - loss: 2.0625\n16/16 [==============================] - 0s 1ms/step - loss: 2.0683\n16/16 [==============================] - 0s 1ms/step - loss: 2.0692\n16/16 [==============================] - 0s 1ms/step - loss: 2.0693\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\n16/16 [==============================] - 0s 1ms/step - loss: 2.0694\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9220\n16/16 [==============================] - 0s 1ms/step - loss: 2.0413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0749\n16/16 [==============================] - 0s 1ms/step - loss: 2.0807\n16/16 [==============================] - 0s 1ms/step - loss: 2.0816\n16/16 [==============================] - 0s 1ms/step - loss: 2.0818\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n16/16 [==============================] - 0s 1ms/step - loss: 2.0819\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.9344\n16/16 [==============================] - 0s 2ms/step - loss: 2.0501\n16/16 [==============================] - 0s 2ms/step - loss: 2.0831\n16/16 [==============================] - 0s 2ms/step - loss: 2.0889\n16/16 [==============================] - 0s 2ms/step - loss: 2.0898\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\n16/16 [==============================] - 0s 2ms/step - loss: 2.0900\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.9430\n16/16 [==============================] - 0s 2ms/step - loss: 2.0784\n16/16 [==============================] - 0s 1ms/step - loss: 2.1121\n16/16 [==============================] - 0s 1ms/step - loss: 2.1180\n16/16 [==============================] - 0s 1ms/step - loss: 2.1189\n16/16 [==============================] - 0s 670us/step - loss: 2.1191\n16/16 [==============================] - 0s 707us/step - loss: 2.1191\n16/16 [==============================] - 0s 720us/step - loss: 2.1191\n16/16 [==============================] - 0s 685us/step - loss: 2.1191\n16/16 [==============================] - 0s 600us/step - loss: 2.1191\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9590\n16/16 [==============================] - 0s 1ms/step - loss: 2.0944\n16/16 [==============================] - 0s 2ms/step - loss: 2.1283\n16/16 [==============================] - 0s 1ms/step - loss: 2.1342\n16/16 [==============================] - 0s 2ms/step - loss: 2.1351\n16/16 [==============================] - 0s 2ms/step - loss: 2.1353\n16/16 [==============================] - 0s 2ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1353\n16/16 [==============================] - 0s 1ms/step - loss: 2.1354\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.9632\n16/16 [==============================] - 0s 1ms/step - loss: 2.1018\n16/16 [==============================] - 0s 1ms/step - loss: 2.1355\n16/16 [==============================] - 0s 1ms/step - loss: 2.1415\n16/16 [==============================] - 0s 1ms/step - loss: 2.1424\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 2ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1426\n16/16 [==============================] - 0s 1ms/step - loss: 2.1427\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 593us/step - loss: 0.9811\n16/16 [==============================] - 0s 1ms/step - loss: 2.1158\n16/16 [==============================] - 0s 601us/step - loss: 2.1494\n16/16 [==============================] - 0s 604us/step - loss: 2.1553\n16/16 [==============================] - 0s 1ms/step - loss: 2.1562\n16/16 [==============================] - 0s 580us/step - loss: 2.1564\n16/16 [==============================] - 0s 606us/step - loss: 2.1564\n16/16 [==============================] - 0s 669us/step - loss: 2.1565\n16/16 [==============================] - 0s 933us/step - loss: 2.1565\n16/16 [==============================] - 0s 604us/step - loss: 2.1565\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 617us/step - loss: 0.9849\n16/16 [==============================] - 0s 874us/step - loss: 2.1127\n16/16 [==============================] - 0s 601us/step - loss: 2.1443\n16/16 [==============================] - 0s 721us/step - loss: 2.1500\n16/16 [==============================] - 0s 709us/step - loss: 2.1508\n16/16 [==============================] - 0s 636us/step - loss: 2.1510\n16/16 [==============================] - 0s 641us/step - loss: 2.1510\n16/16 [==============================] - 0s 3ms/step - loss: 2.1510\n16/16 [==============================] - 0s 832us/step - loss: 2.1510\n16/16 [==============================] - 0s 943us/step - loss: 2.1511\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 960us/step - loss: 1.0029\n16/16 [==============================] - 0s 847us/step - loss: 2.1223\n16/16 [==============================] - 0s 1ms/step - loss: 2.1535\n16/16 [==============================] - 0s 663us/step - loss: 2.1592\n16/16 [==============================] - 0s 1ms/step - loss: 2.1600\n16/16 [==============================] - 0s 1ms/step - loss: 2.1601\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\n16/16 [==============================] - 0s 1ms/step - loss: 2.1602\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.0201\n16/16 [==============================] - 0s 2ms/step - loss: 2.1555\n16/16 [==============================] - 0s 698us/step - loss: 2.1869\n16/16 [==============================] - 0s 738us/step - loss: 2.1925\n16/16 [==============================] - 0s 974us/step - loss: 2.1933\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 811us/step - loss: 2.1935\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 1ms/step - loss: 2.1935\n16/16 [==============================] - 0s 685us/step - loss: 2.1935\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 644us/step - loss: 1.0391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1625\n16/16 [==============================] - 0s 1ms/step - loss: 2.1931\n16/16 [==============================] - 0s 894us/step - loss: 2.1987\n16/16 [==============================] - 0s 2ms/step - loss: 2.1995\n16/16 [==============================] - 0s 700us/step - loss: 2.1996\n16/16 [==============================] - 0s 1ms/step - loss: 2.1997\n16/16 [==============================] - 0s 851us/step - loss: 2.1997\n16/16 [==============================] - 0s 925us/step - loss: 2.1997\n16/16 [==============================] - 0s 868us/step - loss: 2.1997\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.0520\n16/16 [==============================] - 0s 627us/step - loss: 2.1801\n16/16 [==============================] - 0s 1ms/step - loss: 2.2107\n16/16 [==============================] - 0s 633us/step - loss: 2.2163\n16/16 [==============================] - 0s 899us/step - loss: 2.2171\n16/16 [==============================] - 0s 711us/step - loss: 2.2172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n16/16 [==============================] - 0s 664us/step - loss: 2.2173\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n16/16 [==============================] - 0s 1ms/step - loss: 2.2173\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 589us/step - loss: 1.0727\n16/16 [==============================] - 0s 603us/step - loss: 2.1879\n16/16 [==============================] - 0s 581us/step - loss: 2.2176\n16/16 [==============================] - 0s 580us/step - loss: 2.2229\n16/16 [==============================] - 0s 582us/step - loss: 2.2236\n16/16 [==============================] - 0s 571us/step - loss: 2.2238\n16/16 [==============================] - 0s 574us/step - loss: 2.2238\n16/16 [==============================] - 0s 561us/step - loss: 2.2238\n16/16 [==============================] - 0s 506us/step - loss: 2.2238\n16/16 [==============================] - 0s 526us/step - loss: 2.2239\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.0790\n16/16 [==============================] - 0s 1ms/step - loss: 2.1883\n16/16 [==============================] - 0s 2ms/step - loss: 2.2177\n16/16 [==============================] - 0s 2ms/step - loss: 2.2230\n16/16 [==============================] - 0s 2ms/step - loss: 2.2237\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2239\n16/16 [==============================] - 0s 2ms/step - loss: 2.2240\n16/16 [==============================] - 0s 2ms/step - loss: 2.2240\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1019\n16/16 [==============================] - 0s 2ms/step - loss: 2.2025\n16/16 [==============================] - 0s 2ms/step - loss: 2.2310\n16/16 [==============================] - 0s 2ms/step - loss: 2.2362\n16/16 [==============================] - 0s 2ms/step - loss: 2.2369\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2371\n16/16 [==============================] - 0s 2ms/step - loss: 2.2372\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1130\n16/16 [==============================] - 0s 2ms/step - loss: 2.2126\n16/16 [==============================] - 0s 2ms/step - loss: 2.2408\n16/16 [==============================] - 0s 2ms/step - loss: 2.2460\n16/16 [==============================] - 0s 2ms/step - loss: 2.2466\n16/16 [==============================] - 0s 2ms/step - loss: 2.2468\n16/16 [==============================] - 0s 2ms/step - loss: 2.2468\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n16/16 [==============================] - 0s 2ms/step - loss: 2.2469\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1360\n16/16 [==============================] - 0s 2ms/step - loss: 2.2253\n16/16 [==============================] - 0s 2ms/step - loss: 2.2519\n16/16 [==============================] - 0s 2ms/step - loss: 2.2569\n16/16 [==============================] - 0s 2ms/step - loss: 2.2576\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n16/16 [==============================] - 0s 2ms/step - loss: 2.2578\n16/16 [==============================] - 0s 1ms/step - loss: 2.2578\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.1524\n16/16 [==============================] - 0s 2ms/step - loss: 2.2520\n16/16 [==============================] - 0s 1ms/step - loss: 2.2798\n16/16 [==============================] - 0s 2ms/step - loss: 2.2850\n16/16 [==============================] - 0s 2ms/step - loss: 2.2857\n16/16 [==============================] - 0s 1ms/step - loss: 2.2858\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n16/16 [==============================] - 0s 966us/step - loss: 2.2859\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n16/16 [==============================] - 0s 2ms/step - loss: 2.2859\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1690\n16/16 [==============================] - 0s 984us/step - loss: 2.2519\n16/16 [==============================] - 0s 2ms/step - loss: 2.2784\n16/16 [==============================] - 0s 2ms/step - loss: 2.2834\n16/16 [==============================] - 0s 925us/step - loss: 2.2840\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 2ms/step - loss: 2.2842\n16/16 [==============================] - 0s 767us/step - loss: 2.2842\n16/16 [==============================] - 0s 1ms/step - loss: 2.2843\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.1811\n16/16 [==============================] - 0s 2ms/step - loss: 2.2676\n16/16 [==============================] - 0s 2ms/step - loss: 2.2948\n16/16 [==============================] - 0s 2ms/step - loss: 2.2999\n16/16 [==============================] - 0s 2ms/step - loss: 2.3005\n16/16 [==============================] - 0s 2ms/step - loss: 2.3007\n16/16 [==============================] - 0s 2ms/step - loss: 2.3008\n16/16 [==============================] - 0s 1ms/step - loss: 2.3008\n16/16 [==============================] - 0s 657us/step - loss: 2.3008\n16/16 [==============================] - 0s 654us/step - loss: 2.3008\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 1.1986\n16/16 [==============================] - 0s 600us/step - loss: 2.2691\n16/16 [==============================] - 0s 579us/step - loss: 2.2946\n16/16 [==============================] - 0s 2ms/step - loss: 2.2995\n16/16 [==============================] - 0s 2ms/step - loss: 2.3001\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3003\n16/16 [==============================] - 0s 2ms/step - loss: 2.3004\n16/16 [==============================] - 0s 2ms/step - loss: 2.3004\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 1.2123\n16/16 [==============================] - 0s 2ms/step - loss: 2.2903\n16/16 [==============================] - 0s 2ms/step - loss: 2.3163\n16/16 [==============================] - 0s 2ms/step - loss: 2.3213\n16/16 [==============================] - 0s 2ms/step - loss: 2.3219\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3221\n16/16 [==============================] - 0s 2ms/step - loss: 2.3222\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 795us/step - loss: 1.2301\n16/16 [==============================] - 0s 1ms/step - loss: 2.2941\n16/16 [==============================] - 0s 597us/step - loss: 2.3188\n16/16 [==============================] - 0s 524us/step - loss: 2.3236\n16/16 [==============================] - 0s 889us/step - loss: 2.3242\n16/16 [==============================] - 0s 675us/step - loss: 2.3243\n16/16 [==============================] - 0s 523us/step - loss: 2.3243\n16/16 [==============================] - 0s 577us/step - loss: 2.3243\n16/16 [==============================] - 0s 531us/step - loss: 2.3243\n16/16 [==============================] - 0s 646us/step - loss: 2.3244\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.950\nPrecision: 0.950\nRecall: 1.000\nF1 Score: 0.974\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y','f']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.948\nPrecision: 0.999\nRecall: 0.946\nF1 Score: 0.972\n\n\n\nfourteen_orbit = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#orbit-result",
    "title": "Class code for Comparison Study",
    "section": "Orbit Result",
    "text": "Orbit Result\n\nround(fourteen_orbit,4)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.997\n      0.9969\n      1.0000\n      0.9984\n    \n    \n      LOF (Breunig et al., 2000)\n      0.886\n      0.9872\n      0.8916\n      0.9369\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.948\n      0.9989\n      0.9463\n      0.9719\n    \n    \n      CBLOF (He et al., 2003)\n      0.918\n      0.9568\n      0.9568\n      0.9568\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.923\n      0.9877\n      0.9305\n      0.9583\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.866\n      0.9533\n      0.9032\n      0.9276\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.912\n      0.9789\n      0.9274\n      0.9524\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.988\n      0.9937\n      0.9937\n      0.9937\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.378\n      0.9970\n      0.3463\n      0.5141\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.881\n      0.9612\n      0.9116\n      0.9357\n    \n    \n      SOS (Janssens et al., 2012)\n      0.881\n      0.9612\n      0.9116\n      0.9357\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.876\n      0.9589\n      0.9084\n      0.9330\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.950\n      0.9500\n      1.0000\n      0.9744\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.948\n      0.9989\n      0.9463\n      0.9719"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny",
    "title": "Class code for Comparison Study",
    "section": "Bunny",
    "text": "Bunny\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) \n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\nindex_of_trueoutlier2 = np.where(unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n2022-11-26 07:54:05,353:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.\n\n\n\nG.coords.shape\n\n(2503, 3)\n\n\n\n_W = G.W.toarray()\n_x = G.coords[:,0]\n_y = G.coords[:,1]\n_z = -G.coords[:,2]\n\n\n_df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})\n\n\noutlier_true_one_2 = unif.copy()\n\n\noutlier_true_one_2 = list(map(lambda x: -1 if x !=0  else 1,outlier_true_one_2))\n\n\nX = np.array(_df)[:,:4]\n\n\nGODE\n\n_BUNNY = BUNNY(_df)\n\n\n_BUNNY.fit(sd=20,ref=10)\n\n\noutlier_simul_one = (_BUNNY.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 10 else 1,outlier_simul_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.995\nPrecision: 0.995\nRecall: 0.999\nF1 Score: 0.997\n\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\n_conf = Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\n\n\nAccuracy: 0.928\nPrecision: 0.957\nRecall: 0.969\nF1 Score: 0.963\n\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['knn_Clf'] = clf.labels_\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.996\nRecall: 0.941\nF1 Score: 0.968\n\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['CBLOF_Clf'] = clf.labels_\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)\n\n\n_conf.conf(\"CBLOF (He et al., 2003)\")\n\n\n\n\nAccuracy: 0.978\nPrecision: 0.989\nRecall: 0.987\nF1 Score: 0.988\n\n\n\nfour = three.append(_conf.tab)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(X)\n\nOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(X))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\n\n\nAccuracy: 0.932\nPrecision: 0.991\nRecall: 0.937\nF1 Score: 0.963\n\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MCD_clf'] = clf.labels_\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\n\n\nAccuracy: 0.935\nPrecision: 0.993\nRecall: 0.938\nF1 Score: 0.965\n\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['FeatureBagging_clf'] = clf.labels_\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\n\n\nAccuracy: 0.915\nPrecision: 0.982\nRecall: 0.928\nF1 Score: 0.954\n\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['ABOD_Clf'] = clf.labels_\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\n\n\nAccuracy: 0.977\nPrecision: 0.989\nRecall: 0.987\nF1 Score: 0.988\n\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['x', 'y','fnoise']])\n\n\npreds = od.predict(\n    _df[['x', 'y','fnoise']],\n    return_instance_score=True\n)\n\n\n_df['IF_alibi'] = preds['data']['is_outlier']\n\n\noutlier_alibi_one = _df['IF_alibi']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\n\n\nAccuracy: 0.794\nPrecision: 0.995\nRecall: 0.788\nF1 Score: 0.879\n\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['HBOS_clf'] = clf.labels_\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\n\n\nAccuracy: 0.895\nPrecision: 0.969\nRecall: 0.919\nF1 Score: 0.944\n\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SOS_clf'] = clf.labels_\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\n\n\nAccuracy: 0.895\nPrecision: 0.969\nRecall: 0.919\nF1 Score: 0.944\n\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['SO_GAAL_clf'] = clf.labels_\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 894us/step - loss: 1.8529\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8921\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9309\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 690us/step - loss: 1.8584\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 1.8820\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9128\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9055\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9463\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9150\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 755us/step - loss: 1.9138\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 636us/step - loss: 2.0252\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 1.9456\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 701us/step - loss: 1.9662\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9841\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0037\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 1.9889\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 871us/step - loss: 1.9856\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0014\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 778us/step - loss: 2.0162\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 664us/step - loss: 2.0739\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 2.0179\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0133\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0655\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 2.0657\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0669\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0880\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 800us/step - loss: 2.0889\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1112\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0641\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0520\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0533\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 601us/step - loss: 2.1067\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 645us/step - loss: 2.1065\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 634us/step - loss: 2.0811\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 633us/step - loss: 2.0727\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 687us/step - loss: 2.1834\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.0984\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 599us/step - loss: 2.1578\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1489\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 671us/step - loss: 2.1636\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1516\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 636us/step - loss: 2.1534\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 776us/step - loss: 2.1465\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1006\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 768us/step - loss: 2.1580\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1679\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 932us/step - loss: 2.1854\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1869\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 600us/step - loss: 2.1570\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 701us/step - loss: 2.2004\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 664us/step - loss: 2.2094\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.2316\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.1808\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 606us/step - loss: 2.2633\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2481\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 2.2154\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2065\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 632us/step - loss: 2.2313\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 728us/step - loss: 2.2298\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 651us/step - loss: 2.2541\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2413\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.1930\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 607us/step - loss: 2.2856\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 650us/step - loss: 2.2537\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2461\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 654us/step - loss: 2.3097\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 831us/step - loss: 2.3159\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 934us/step - loss: 2.2306\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 654us/step - loss: 2.2956\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2296\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2378\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 926us/step - loss: 2.2114\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 716us/step - loss: 2.2166\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2483\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2669\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 718us/step - loss: 2.2966\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 776us/step - loss: 2.2346\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3040\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 780us/step - loss: 2.3003\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2809\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 789us/step - loss: 2.2804\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2915\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.2829\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 923us/step - loss: 2.3199\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 980us/step - loss: 2.2642\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3208\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3127\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3514\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 829us/step - loss: 2.3363\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 629us/step - loss: 2.3203\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.3100\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 625us/step - loss: 2.2837\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 640us/step - loss: 2.2877\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3374\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3149\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 658us/step - loss: 2.3535\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 652us/step - loss: 2.3861\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 723us/step - loss: 2.3328\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3450\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 641us/step - loss: 2.3578\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3235\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 958us/step - loss: 2.3421\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 593us/step - loss: 2.3656\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 623us/step - loss: 2.3044\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3273\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3797\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 654us/step - loss: 2.3372\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3387\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 608us/step - loss: 2.4377\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 965us/step - loss: 2.4568\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 640us/step - loss: 2.4050\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 943us/step - loss: 2.3936\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3910\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4026\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 647us/step - loss: 2.4177\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 941us/step - loss: 2.4015\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3971\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 678us/step - loss: 2.3933\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4488\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 594us/step - loss: 2.3598\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 655us/step - loss: 2.4883\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4234\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3641\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 649us/step - loss: 2.4212\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 828us/step - loss: 2.5119\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 2.4255\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4828\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4336\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3916\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 630us/step - loss: 2.4157\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 621us/step - loss: 2.4543\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 672us/step - loss: 2.3956\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4783\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 630us/step - loss: 2.4045\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4787\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 880us/step - loss: 2.4557\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4497\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 635us/step - loss: 2.4115\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 613us/step - loss: 2.4469\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 764us/step - loss: 2.4250\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4706\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 620us/step - loss: 2.3919\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 698us/step - loss: 2.4463\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 958us/step - loss: 2.4810\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4359\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4080\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4634\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5226\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 894us/step - loss: 2.4385\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 856us/step - loss: 2.5063\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4672\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5011\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 618us/step - loss: 2.5610\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 679us/step - loss: 2.5239\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5248\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 990us/step - loss: 2.5142\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5164\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.3996\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 894us/step - loss: 2.4939\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4897\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 617us/step - loss: 2.5320\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 619us/step - loss: 2.5544\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4986\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 648us/step - loss: 2.5618\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5605\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4780\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 665us/step - loss: 2.4659\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4696\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 643us/step - loss: 2.5610\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4586\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 665us/step - loss: 2.4735\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 964us/step - loss: 2.5013\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 840us/step - loss: 2.4765\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 908us/step - loss: 2.5925\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 644us/step - loss: 2.5213\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 624us/step - loss: 2.5540\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5273\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 665us/step - loss: 2.5155\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5001\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5154\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5593\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 653us/step - loss: 2.4897\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 621us/step - loss: 2.5391\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5966\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5325\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5563\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 2.4993\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 625us/step - loss: 2.5589\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 2.5403\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 833us/step - loss: 2.5143\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 808us/step - loss: 2.5618\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 796us/step - loss: 2.5960\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 599us/step - loss: 2.5405\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 650us/step - loss: 2.5440\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['x', 'y','fnoise']])\n_df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(SGD, self).__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n16/16 [==============================] - 0s 839us/step - loss: 0.2862\n16/16 [==============================] - 0s 1ms/step - loss: 1.3562\n16/16 [==============================] - 0s 879us/step - loss: 1.6391\n16/16 [==============================] - 0s 676us/step - loss: 1.7457\n16/16 [==============================] - 0s 668us/step - loss: 1.7800\n16/16 [==============================] - 0s 797us/step - loss: 1.7893\n16/16 [==============================] - 0s 1ms/step - loss: 1.7882\n16/16 [==============================] - 0s 750us/step - loss: 1.7810\n16/16 [==============================] - 0s 661us/step - loss: 1.7768\n16/16 [==============================] - 0s 1ms/step - loss: 1.7746\n\nTesting for epoch 21 index 3:\n16/16 [==============================] - 0s 709us/step - loss: 0.2829\n16/16 [==============================] - 0s 1ms/step - loss: 1.3627\n16/16 [==============================] - 0s 1ms/step - loss: 1.6520\n16/16 [==============================] - 0s 1ms/step - loss: 1.7617\n16/16 [==============================] - 0s 648us/step - loss: 1.7969\n16/16 [==============================] - 0s 655us/step - loss: 1.8064\n16/16 [==============================] - 0s 1ms/step - loss: 1.8050\n16/16 [==============================] - 0s 1ms/step - loss: 1.7975\n16/16 [==============================] - 0s 1ms/step - loss: 1.7932\n16/16 [==============================] - 0s 1ms/step - loss: 1.7909\n\nTesting for epoch 21 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2819\n16/16 [==============================] - 0s 662us/step - loss: 1.3750\n16/16 [==============================] - 0s 649us/step - loss: 1.6692\n16/16 [==============================] - 0s 664us/step - loss: 1.7821\n16/16 [==============================] - 0s 644us/step - loss: 1.8194\n16/16 [==============================] - 0s 671us/step - loss: 1.8316\n16/16 [==============================] - 0s 651us/step - loss: 1.8318\n16/16 [==============================] - 0s 661us/step - loss: 1.8249\n16/16 [==============================] - 0s 990us/step - loss: 1.8208\n16/16 [==============================] - 0s 1ms/step - loss: 1.8185\n\nTesting for epoch 21 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2784\n16/16 [==============================] - 0s 1ms/step - loss: 1.3590\n16/16 [==============================] - 0s 645us/step - loss: 1.6490\n16/16 [==============================] - 0s 1ms/step - loss: 1.7586\n16/16 [==============================] - 0s 655us/step - loss: 1.7914\n16/16 [==============================] - 0s 1ms/step - loss: 1.7998\n16/16 [==============================] - 0s 1ms/step - loss: 1.7975\n16/16 [==============================] - 0s 653us/step - loss: 1.7896\n16/16 [==============================] - 0s 675us/step - loss: 1.7852\n16/16 [==============================] - 0s 1ms/step - loss: 1.7829\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2787\n16/16 [==============================] - 0s 1ms/step - loss: 1.3475\n16/16 [==============================] - 0s 646us/step - loss: 1.6341\n16/16 [==============================] - 0s 690us/step - loss: 1.7422\n16/16 [==============================] - 0s 1ms/step - loss: 1.7757\n16/16 [==============================] - 0s 1ms/step - loss: 1.7855\n16/16 [==============================] - 0s 1ms/step - loss: 1.7843\n16/16 [==============================] - 0s 1ms/step - loss: 1.7771\n16/16 [==============================] - 0s 1ms/step - loss: 1.7729\n16/16 [==============================] - 0s 1ms/step - loss: 1.7708\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 680us/step - loss: 0.2756\n16/16 [==============================] - 0s 1ms/step - loss: 1.3616\n16/16 [==============================] - 0s 678us/step - loss: 1.6485\n16/16 [==============================] - 0s 946us/step - loss: 1.7539\n16/16 [==============================] - 0s 673us/step - loss: 1.7847\n16/16 [==============================] - 0s 656us/step - loss: 1.7921\n16/16 [==============================] - 0s 1ms/step - loss: 1.7895\n16/16 [==============================] - 0s 660us/step - loss: 1.7812\n16/16 [==============================] - 0s 1ms/step - loss: 1.7768\n16/16 [==============================] - 0s 730us/step - loss: 1.7745\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 660us/step - loss: 0.2723\n16/16 [==============================] - 0s 1ms/step - loss: 1.3959\n16/16 [==============================] - 0s 642us/step - loss: 1.7002\n16/16 [==============================] - 0s 874us/step - loss: 1.8105\n16/16 [==============================] - 0s 1ms/step - loss: 1.8423\n16/16 [==============================] - 0s 1ms/step - loss: 1.8494\n16/16 [==============================] - 0s 657us/step - loss: 1.8460\n16/16 [==============================] - 0s 940us/step - loss: 1.8371\n16/16 [==============================] - 0s 634us/step - loss: 1.8324\n16/16 [==============================] - 0s 905us/step - loss: 1.8299\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2702\n16/16 [==============================] - 0s 649us/step - loss: 1.3792\n16/16 [==============================] - 0s 867us/step - loss: 1.6818\n16/16 [==============================] - 0s 619us/step - loss: 1.7923\n16/16 [==============================] - 0s 859us/step - loss: 1.8248\n16/16 [==============================] - 0s 609us/step - loss: 1.8327\n16/16 [==============================] - 0s 1ms/step - loss: 1.8298\n16/16 [==============================] - 0s 584us/step - loss: 1.8209\n16/16 [==============================] - 0s 590us/step - loss: 1.8163\n16/16 [==============================] - 0s 602us/step - loss: 1.8139\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 683us/step - loss: 0.2694\n16/16 [==============================] - 0s 794us/step - loss: 1.3853\n16/16 [==============================] - 0s 1ms/step - loss: 1.6907\n16/16 [==============================] - 0s 1ms/step - loss: 1.8014\n16/16 [==============================] - 0s 634us/step - loss: 1.8329\n16/16 [==============================] - 0s 1ms/step - loss: 1.8400\n16/16 [==============================] - 0s 694us/step - loss: 1.8367\n16/16 [==============================] - 0s 1ms/step - loss: 1.8275\n16/16 [==============================] - 0s 589us/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.8204\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2679\n16/16 [==============================] - 0s 1ms/step - loss: 1.4280\n16/16 [==============================] - 0s 1ms/step - loss: 1.7530\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n16/16 [==============================] - 0s 1ms/step - loss: 1.9036\n16/16 [==============================] - 0s 643us/step - loss: 1.9107\n16/16 [==============================] - 0s 1ms/step - loss: 1.9074\n16/16 [==============================] - 0s 1ms/step - loss: 1.8981\n16/16 [==============================] - 0s 1ms/step - loss: 1.8933\n16/16 [==============================] - 0s 1ms/step - loss: 1.8908\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2673\n16/16 [==============================] - 0s 974us/step - loss: 1.4127\n16/16 [==============================] - 0s 820us/step - loss: 1.7343\n16/16 [==============================] - 0s 630us/step - loss: 1.8524\n16/16 [==============================] - 0s 606us/step - loss: 1.8844\n16/16 [==============================] - 0s 719us/step - loss: 1.8917\n16/16 [==============================] - 0s 1ms/step - loss: 1.8882\n16/16 [==============================] - 0s 611us/step - loss: 1.8784\n16/16 [==============================] - 0s 666us/step - loss: 1.8735\n16/16 [==============================] - 0s 1ms/step - loss: 1.8709\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2645\n16/16 [==============================] - 0s 1ms/step - loss: 1.4021\n16/16 [==============================] - 0s 594us/step - loss: 1.7169\n16/16 [==============================] - 0s 587us/step - loss: 1.8300\n16/16 [==============================] - 0s 613us/step - loss: 1.8582\n16/16 [==============================] - 0s 1ms/step - loss: 1.8634\n16/16 [==============================] - 0s 1ms/step - loss: 1.8590\n16/16 [==============================] - 0s 644us/step - loss: 1.8494\n16/16 [==============================] - 0s 622us/step - loss: 1.8445\n16/16 [==============================] - 0s 617us/step - loss: 1.8420\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2641\n16/16 [==============================] - 0s 1ms/step - loss: 1.4346\n16/16 [==============================] - 0s 1ms/step - loss: 1.7641\n16/16 [==============================] - 0s 860us/step - loss: 1.8848\n16/16 [==============================] - 0s 1ms/step - loss: 1.9154\n16/16 [==============================] - 0s 962us/step - loss: 1.9222\n16/16 [==============================] - 0s 634us/step - loss: 1.9176\n16/16 [==============================] - 0s 1ms/step - loss: 1.9075\n16/16 [==============================] - 0s 640us/step - loss: 1.9024\n16/16 [==============================] - 0s 1ms/step - loss: 1.8998\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 935us/step - loss: 0.2571\n16/16 [==============================] - 0s 600us/step - loss: 1.4423\n16/16 [==============================] - 0s 1ms/step - loss: 1.7744\n16/16 [==============================] - 0s 1ms/step - loss: 1.8942\n16/16 [==============================] - 0s 1ms/step - loss: 1.9222\n16/16 [==============================] - 0s 1ms/step - loss: 1.9268\n16/16 [==============================] - 0s 702us/step - loss: 1.9205\n16/16 [==============================] - 0s 637us/step - loss: 1.9092\n16/16 [==============================] - 0s 1ms/step - loss: 1.9038\n16/16 [==============================] - 0s 638us/step - loss: 1.9011\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2576\n16/16 [==============================] - 0s 1ms/step - loss: 1.4150\n16/16 [==============================] - 0s 586us/step - loss: 1.7381\n16/16 [==============================] - 0s 825us/step - loss: 1.8529\n16/16 [==============================] - 0s 848us/step - loss: 1.8794\n16/16 [==============================] - 0s 716us/step - loss: 1.8834\n16/16 [==============================] - 0s 1ms/step - loss: 1.8775\n16/16 [==============================] - 0s 598us/step - loss: 1.8670\n16/16 [==============================] - 0s 614us/step - loss: 1.8618\n16/16 [==============================] - 0s 1ms/step - loss: 1.8593\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 604us/step - loss: 0.2602\n16/16 [==============================] - 0s 1ms/step - loss: 1.4321\n16/16 [==============================] - 0s 1ms/step - loss: 1.7581\n16/16 [==============================] - 0s 1ms/step - loss: 1.8731\n16/16 [==============================] - 0s 636us/step - loss: 1.8998\n16/16 [==============================] - 0s 1ms/step - loss: 1.9035\n16/16 [==============================] - 0s 607us/step - loss: 1.8975\n16/16 [==============================] - 0s 1ms/step - loss: 1.8867\n16/16 [==============================] - 0s 646us/step - loss: 1.8815\n16/16 [==============================] - 0s 1ms/step - loss: 1.8790\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2559\n16/16 [==============================] - 0s 1ms/step - loss: 1.4384\n16/16 [==============================] - 0s 610us/step - loss: 1.7673\n16/16 [==============================] - 0s 1ms/step - loss: 1.8808\n16/16 [==============================] - 0s 663us/step - loss: 1.9062\n16/16 [==============================] - 0s 844us/step - loss: 1.9082\n16/16 [==============================] - 0s 780us/step - loss: 1.9007\n16/16 [==============================] - 0s 602us/step - loss: 1.8887\n16/16 [==============================] - 0s 735us/step - loss: 1.8831\n16/16 [==============================] - 0s 1ms/step - loss: 1.8805\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 828us/step - loss: 0.2595\n16/16 [==============================] - 0s 1ms/step - loss: 1.4660\n16/16 [==============================] - 0s 1ms/step - loss: 1.8046\n16/16 [==============================] - 0s 1ms/step - loss: 1.9238\n16/16 [==============================] - 0s 613us/step - loss: 1.9510\n16/16 [==============================] - 0s 613us/step - loss: 1.9550\n16/16 [==============================] - 0s 607us/step - loss: 1.9486\n16/16 [==============================] - 0s 600us/step - loss: 1.9375\n16/16 [==============================] - 0s 1ms/step - loss: 1.9321\n16/16 [==============================] - 0s 1ms/step - loss: 1.9295\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 602us/step - loss: 0.2490\n16/16 [==============================] - 0s 783us/step - loss: 1.4405\n16/16 [==============================] - 0s 962us/step - loss: 1.7687\n16/16 [==============================] - 0s 1ms/step - loss: 1.8795\n16/16 [==============================] - 0s 1ms/step - loss: 1.9005\n16/16 [==============================] - 0s 1ms/step - loss: 1.8995\n16/16 [==============================] - 0s 1ms/step - loss: 1.8901\n16/16 [==============================] - 0s 1ms/step - loss: 1.8774\n16/16 [==============================] - 0s 1ms/step - loss: 1.8717\n16/16 [==============================] - 0s 1ms/step - loss: 1.8690\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 951us/step - loss: 0.2496\n16/16 [==============================] - 0s 610us/step - loss: 1.4539\n16/16 [==============================] - 0s 1ms/step - loss: 1.7891\n16/16 [==============================] - 0s 1ms/step - loss: 1.9046\n16/16 [==============================] - 0s 628us/step - loss: 1.9285\n16/16 [==============================] - 0s 645us/step - loss: 1.9295\n16/16 [==============================] - 0s 1ms/step - loss: 1.9219\n16/16 [==============================] - 0s 602us/step - loss: 1.9101\n16/16 [==============================] - 0s 1ms/step - loss: 1.9046\n16/16 [==============================] - 0s 888us/step - loss: 1.9020\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 647us/step - loss: 0.2496\n16/16 [==============================] - 0s 600us/step - loss: 1.4771\n16/16 [==============================] - 0s 677us/step - loss: 1.8228\n16/16 [==============================] - 0s 1ms/step - loss: 1.9419\n16/16 [==============================] - 0s 663us/step - loss: 1.9656\n16/16 [==============================] - 0s 1ms/step - loss: 1.9663\n16/16 [==============================] - 0s 1ms/step - loss: 1.9579\n16/16 [==============================] - 0s 629us/step - loss: 1.9450\n16/16 [==============================] - 0s 638us/step - loss: 1.9393\n16/16 [==============================] - 0s 1ms/step - loss: 1.9365\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 652us/step - loss: 0.2531\n16/16 [==============================] - 0s 591us/step - loss: 1.4810\n16/16 [==============================] - 0s 613us/step - loss: 1.8268\n16/16 [==============================] - 0s 1ms/step - loss: 1.9468\n16/16 [==============================] - 0s 992us/step - loss: 1.9711\n16/16 [==============================] - 0s 1ms/step - loss: 1.9715\n16/16 [==============================] - 0s 595us/step - loss: 1.9633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9507\n16/16 [==============================] - 0s 638us/step - loss: 1.9451\n16/16 [==============================] - 0s 1ms/step - loss: 1.9424\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 642us/step - loss: 0.2477\n16/16 [==============================] - 0s 608us/step - loss: 1.4965\n16/16 [==============================] - 0s 1ms/step - loss: 1.8427\n16/16 [==============================] - 0s 1ms/step - loss: 1.9619\n16/16 [==============================] - 0s 707us/step - loss: 1.9847\n16/16 [==============================] - 0s 1ms/step - loss: 1.9844\n16/16 [==============================] - 0s 1ms/step - loss: 1.9761\n16/16 [==============================] - 0s 627us/step - loss: 1.9633\n16/16 [==============================] - 0s 604us/step - loss: 1.9575\n16/16 [==============================] - 0s 1ms/step - loss: 1.9548\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 666us/step - loss: 0.2442\n16/16 [==============================] - 0s 1ms/step - loss: 1.5123\n16/16 [==============================] - 0s 663us/step - loss: 1.8671\n16/16 [==============================] - 0s 868us/step - loss: 1.9886\n16/16 [==============================] - 0s 1ms/step - loss: 2.0106\n16/16 [==============================] - 0s 1ms/step - loss: 2.0090\n16/16 [==============================] - 0s 1ms/step - loss: 1.9998\n16/16 [==============================] - 0s 1ms/step - loss: 1.9861\n16/16 [==============================] - 0s 1ms/step - loss: 1.9801\n16/16 [==============================] - 0s 897us/step - loss: 1.9772\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2455\n16/16 [==============================] - 0s 641us/step - loss: 1.4842\n16/16 [==============================] - 0s 1ms/step - loss: 1.8252\n16/16 [==============================] - 0s 604us/step - loss: 1.9429\n16/16 [==============================] - 0s 853us/step - loss: 1.9640\n16/16 [==============================] - 0s 1ms/step - loss: 1.9625\n16/16 [==============================] - 0s 616us/step - loss: 1.9538\n16/16 [==============================] - 0s 861us/step - loss: 1.9412\n16/16 [==============================] - 0s 1ms/step - loss: 1.9356\n16/16 [==============================] - 0s 1ms/step - loss: 1.9330\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2433\n16/16 [==============================] - 0s 1ms/step - loss: 1.4858\n16/16 [==============================] - 0s 837us/step - loss: 1.8253\n16/16 [==============================] - 0s 1ms/step - loss: 1.9440\n16/16 [==============================] - 0s 1ms/step - loss: 1.9633\n16/16 [==============================] - 0s 1ms/step - loss: 1.9608\n16/16 [==============================] - 0s 1ms/step - loss: 1.9512\n16/16 [==============================] - 0s 595us/step - loss: 1.9375\n16/16 [==============================] - 0s 623us/step - loss: 1.9316\n16/16 [==============================] - 0s 632us/step - loss: 1.9289\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 947us/step - loss: 0.2431\n16/16 [==============================] - 0s 727us/step - loss: 1.5060\n16/16 [==============================] - 0s 614us/step - loss: 1.8472\n16/16 [==============================] - 0s 619us/step - loss: 1.9665\n16/16 [==============================] - 0s 1ms/step - loss: 1.9845\n16/16 [==============================] - 0s 1ms/step - loss: 1.9803\n16/16 [==============================] - 0s 1ms/step - loss: 1.9697\n16/16 [==============================] - 0s 640us/step - loss: 1.9554\n16/16 [==============================] - 0s 1ms/step - loss: 1.9494\n16/16 [==============================] - 0s 1ms/step - loss: 1.9467\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2399\n16/16 [==============================] - 0s 1ms/step - loss: 1.4785\n16/16 [==============================] - 0s 1ms/step - loss: 1.8107\n16/16 [==============================] - 0s 571us/step - loss: 1.9298\n16/16 [==============================] - 0s 1ms/step - loss: 1.9481\n16/16 [==============================] - 0s 1ms/step - loss: 1.9445\n16/16 [==============================] - 0s 625us/step - loss: 1.9342\n16/16 [==============================] - 0s 631us/step - loss: 1.9201\n16/16 [==============================] - 0s 646us/step - loss: 1.9141\n16/16 [==============================] - 0s 626us/step - loss: 1.9114\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 880us/step - loss: 0.2394\n16/16 [==============================] - 0s 1ms/step - loss: 1.5075\n16/16 [==============================] - 0s 632us/step - loss: 1.8517\n16/16 [==============================] - 0s 687us/step - loss: 1.9741\n16/16 [==============================] - 0s 644us/step - loss: 1.9911\n16/16 [==============================] - 0s 671us/step - loss: 1.9874\n16/16 [==============================] - 0s 621us/step - loss: 1.9765\n16/16 [==============================] - 0s 604us/step - loss: 1.9621\n16/16 [==============================] - 0s 610us/step - loss: 1.9561\n16/16 [==============================] - 0s 1ms/step - loss: 1.9533\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 626us/step - loss: 0.2399\n16/16 [==============================] - 0s 1ms/step - loss: 1.5196\n16/16 [==============================] - 0s 1ms/step - loss: 1.8658\n16/16 [==============================] - 0s 1ms/step - loss: 1.9878\n16/16 [==============================] - 0s 937us/step - loss: 2.0043\n16/16 [==============================] - 0s 1ms/step - loss: 2.0001\n16/16 [==============================] - 0s 755us/step - loss: 1.9881\n16/16 [==============================] - 0s 607us/step - loss: 1.9734\n16/16 [==============================] - 0s 1ms/step - loss: 1.9673\n16/16 [==============================] - 0s 675us/step - loss: 1.9644\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 584us/step - loss: 0.2383\n16/16 [==============================] - 0s 1ms/step - loss: 1.5491\n16/16 [==============================] - 0s 1ms/step - loss: 1.9024\n16/16 [==============================] - 0s 587us/step - loss: 2.0252\n16/16 [==============================] - 0s 793us/step - loss: 2.0399\n16/16 [==============================] - 0s 1ms/step - loss: 2.0364\n16/16 [==============================] - 0s 589us/step - loss: 2.0246\n16/16 [==============================] - 0s 625us/step - loss: 2.0102\n16/16 [==============================] - 0s 604us/step - loss: 2.0042\n16/16 [==============================] - 0s 600us/step - loss: 2.0014\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2373\n16/16 [==============================] - 0s 1ms/step - loss: 1.5548\n16/16 [==============================] - 0s 1ms/step - loss: 1.9083\n16/16 [==============================] - 0s 1ms/step - loss: 2.0331\n16/16 [==============================] - 0s 594us/step - loss: 2.0485\n16/16 [==============================] - 0s 609us/step - loss: 2.0460\n16/16 [==============================] - 0s 917us/step - loss: 2.0331\n16/16 [==============================] - 0s 1ms/step - loss: 2.0181\n16/16 [==============================] - 0s 1ms/step - loss: 2.0119\n16/16 [==============================] - 0s 1ms/step - loss: 2.0090\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2391\n16/16 [==============================] - 0s 713us/step - loss: 1.5529\n16/16 [==============================] - 0s 1ms/step - loss: 1.9056\n16/16 [==============================] - 0s 666us/step - loss: 2.0294\n16/16 [==============================] - 0s 1ms/step - loss: 2.0429\n16/16 [==============================] - 0s 1ms/step - loss: 2.0388\n16/16 [==============================] - 0s 1ms/step - loss: 2.0248\n16/16 [==============================] - 0s 1ms/step - loss: 2.0092\n16/16 [==============================] - 0s 1ms/step - loss: 2.0028\n16/16 [==============================] - 0s 1ms/step - loss: 1.9998\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 643us/step - loss: 0.2391\n16/16 [==============================] - 0s 1ms/step - loss: 1.5363\n16/16 [==============================] - 0s 896us/step - loss: 1.8850\n16/16 [==============================] - 0s 1ms/step - loss: 2.0052\n16/16 [==============================] - 0s 610us/step - loss: 2.0195\n16/16 [==============================] - 0s 1ms/step - loss: 2.0152\n16/16 [==============================] - 0s 1ms/step - loss: 2.0012\n16/16 [==============================] - 0s 1ms/step - loss: 1.9857\n16/16 [==============================] - 0s 619us/step - loss: 1.9794\n16/16 [==============================] - 0s 1ms/step - loss: 1.9765\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2338\n16/16 [==============================] - 0s 1ms/step - loss: 1.5579\n16/16 [==============================] - 0s 624us/step - loss: 1.9117\n16/16 [==============================] - 0s 1ms/step - loss: 2.0320\n16/16 [==============================] - 0s 612us/step - loss: 2.0450\n16/16 [==============================] - 0s 645us/step - loss: 2.0389\n16/16 [==============================] - 0s 721us/step - loss: 2.0244\n16/16 [==============================] - 0s 696us/step - loss: 2.0088\n16/16 [==============================] - 0s 608us/step - loss: 2.0024\n16/16 [==============================] - 0s 826us/step - loss: 1.9995\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 748us/step - loss: 0.2338\n16/16 [==============================] - 0s 1ms/step - loss: 1.5385\n16/16 [==============================] - 0s 1ms/step - loss: 1.8839\n16/16 [==============================] - 0s 670us/step - loss: 2.0016\n16/16 [==============================] - 0s 626us/step - loss: 2.0138\n16/16 [==============================] - 0s 625us/step - loss: 2.0076\n16/16 [==============================] - 0s 1ms/step - loss: 1.9939\n16/16 [==============================] - 0s 579us/step - loss: 1.9788\n16/16 [==============================] - 0s 898us/step - loss: 1.9727\n16/16 [==============================] - 0s 1ms/step - loss: 1.9699\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2316\n16/16 [==============================] - 0s 590us/step - loss: 1.5536\n16/16 [==============================] - 0s 627us/step - loss: 1.9020\n16/16 [==============================] - 0s 1ms/step - loss: 2.0198\n16/16 [==============================] - 0s 1ms/step - loss: 2.0311\n16/16 [==============================] - 0s 1ms/step - loss: 2.0229\n16/16 [==============================] - 0s 646us/step - loss: 2.0074\n16/16 [==============================] - 0s 606us/step - loss: 1.9907\n16/16 [==============================] - 0s 591us/step - loss: 1.9841\n16/16 [==============================] - 0s 1ms/step - loss: 1.9812\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 618us/step - loss: 0.2325\n16/16 [==============================] - 0s 1ms/step - loss: 1.5661\n16/16 [==============================] - 0s 654us/step - loss: 1.9179\n16/16 [==============================] - 0s 1ms/step - loss: 2.0361\n16/16 [==============================] - 0s 1ms/step - loss: 2.0486\n16/16 [==============================] - 0s 589us/step - loss: 2.0418\n16/16 [==============================] - 0s 676us/step - loss: 2.0272\n16/16 [==============================] - 0s 686us/step - loss: 2.0113\n16/16 [==============================] - 0s 664us/step - loss: 2.0049\n16/16 [==============================] - 0s 1ms/step - loss: 2.0020\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2280\n16/16 [==============================] - 0s 1ms/step - loss: 1.5553\n16/16 [==============================] - 0s 646us/step - loss: 1.9013\n16/16 [==============================] - 0s 1ms/step - loss: 2.0131\n16/16 [==============================] - 0s 929us/step - loss: 2.0218\n16/16 [==============================] - 0s 838us/step - loss: 2.0122\n16/16 [==============================] - 0s 882us/step - loss: 1.9958\n16/16 [==============================] - 0s 602us/step - loss: 1.9791\n16/16 [==============================] - 0s 608us/step - loss: 1.9725\n16/16 [==============================] - 0s 657us/step - loss: 1.9696\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2275\n16/16 [==============================] - 0s 767us/step - loss: 1.6042\n16/16 [==============================] - 0s 629us/step - loss: 1.9618\n16/16 [==============================] - 0s 1ms/step - loss: 2.0777\n16/16 [==============================] - 0s 1ms/step - loss: 2.0859\n16/16 [==============================] - 0s 645us/step - loss: 2.0750\n16/16 [==============================] - 0s 646us/step - loss: 2.0571\n16/16 [==============================] - 0s 900us/step - loss: 2.0390\n16/16 [==============================] - 0s 1ms/step - loss: 2.0319\n16/16 [==============================] - 0s 1ms/step - loss: 2.0288\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 600us/step - loss: 0.2278\n16/16 [==============================] - 0s 625us/step - loss: 1.6003\n16/16 [==============================] - 0s 627us/step - loss: 1.9580\n16/16 [==============================] - 0s 599us/step - loss: 2.0748\n16/16 [==============================] - 0s 608us/step - loss: 2.0844\n16/16 [==============================] - 0s 1ms/step - loss: 2.0744\n16/16 [==============================] - 0s 911us/step - loss: 2.0568\n16/16 [==============================] - 0s 1ms/step - loss: 2.0391\n16/16 [==============================] - 0s 1ms/step - loss: 2.0323\n16/16 [==============================] - 0s 632us/step - loss: 2.0293\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 606us/step - loss: 0.2275\n16/16 [==============================] - 0s 640us/step - loss: 1.5908\n16/16 [==============================] - 0s 787us/step - loss: 1.9416\n16/16 [==============================] - 0s 614us/step - loss: 2.0550\n16/16 [==============================] - 0s 655us/step - loss: 2.0633\n16/16 [==============================] - 0s 1ms/step - loss: 2.0544\n16/16 [==============================] - 0s 624us/step - loss: 2.0373\n16/16 [==============================] - 0s 590us/step - loss: 2.0202\n16/16 [==============================] - 0s 665us/step - loss: 2.0135\n16/16 [==============================] - 0s 1ms/step - loss: 2.0105\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 0.2262\n16/16 [==============================] - 0s 1ms/step - loss: 1.6456\n16/16 [==============================] - 0s 861us/step - loss: 2.0122\n16/16 [==============================] - 0s 1ms/step - loss: 2.1306\n16/16 [==============================] - 0s 1ms/step - loss: 2.1391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1297\n16/16 [==============================] - 0s 621us/step - loss: 2.1118\n16/16 [==============================] - 0s 608us/step - loss: 2.0941\n16/16 [==============================] - 0s 1ms/step - loss: 2.0872\n16/16 [==============================] - 0s 652us/step - loss: 2.0842\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 876us/step - loss: 0.2207\n16/16 [==============================] - 0s 656us/step - loss: 1.5952\n16/16 [==============================] - 0s 647us/step - loss: 1.9409\n16/16 [==============================] - 0s 611us/step - loss: 2.0496\n16/16 [==============================] - 0s 616us/step - loss: 2.0545\n16/16 [==============================] - 0s 1ms/step - loss: 2.0428\n16/16 [==============================] - 0s 599us/step - loss: 2.0236\n16/16 [==============================] - 0s 625us/step - loss: 2.0050\n16/16 [==============================] - 0s 897us/step - loss: 1.9980\n16/16 [==============================] - 0s 1ms/step - loss: 1.9949\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 595us/step - loss: 0.2217\n16/16 [==============================] - 0s 1ms/step - loss: 1.6089\n16/16 [==============================] - 0s 1ms/step - loss: 1.9546\n16/16 [==============================] - 0s 1ms/step - loss: 2.0641\n16/16 [==============================] - 0s 638us/step - loss: 2.0694\n16/16 [==============================] - 0s 636us/step - loss: 2.0580\n16/16 [==============================] - 0s 1ms/step - loss: 2.0394\n16/16 [==============================] - 0s 1ms/step - loss: 2.0217\n16/16 [==============================] - 0s 673us/step - loss: 2.0150\n16/16 [==============================] - 0s 1ms/step - loss: 2.0120\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2210\n16/16 [==============================] - 0s 828us/step - loss: 1.6202\n16/16 [==============================] - 0s 1ms/step - loss: 1.9660\n16/16 [==============================] - 0s 1ms/step - loss: 2.0750\n16/16 [==============================] - 0s 1ms/step - loss: 2.0805\n16/16 [==============================] - 0s 655us/step - loss: 2.0695\n16/16 [==============================] - 0s 1ms/step - loss: 2.0510\n16/16 [==============================] - 0s 1ms/step - loss: 2.0329\n16/16 [==============================] - 0s 681us/step - loss: 2.0260\n16/16 [==============================] - 0s 660us/step - loss: 2.0231\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2210\n16/16 [==============================] - 0s 1ms/step - loss: 1.6647\n16/16 [==============================] - 0s 1ms/step - loss: 2.0279\n16/16 [==============================] - 0s 1ms/step - loss: 2.1422\n16/16 [==============================] - 0s 638us/step - loss: 2.1469\n16/16 [==============================] - 0s 1ms/step - loss: 2.1338\n16/16 [==============================] - 0s 787us/step - loss: 2.1132\n16/16 [==============================] - 0s 1ms/step - loss: 2.0938\n16/16 [==============================] - 0s 1ms/step - loss: 2.0865\n16/16 [==============================] - 0s 1ms/step - loss: 2.0833\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 636us/step - loss: 0.2203\n16/16 [==============================] - 0s 640us/step - loss: 1.6660\n16/16 [==============================] - 0s 629us/step - loss: 2.0216\n16/16 [==============================] - 0s 1ms/step - loss: 2.1328\n16/16 [==============================] - 0s 607us/step - loss: 2.1365\n16/16 [==============================] - 0s 1ms/step - loss: 2.1239\n16/16 [==============================] - 0s 1ms/step - loss: 2.1042\n16/16 [==============================] - 0s 1ms/step - loss: 2.0851\n16/16 [==============================] - 0s 637us/step - loss: 2.0778\n16/16 [==============================] - 0s 1ms/step - loss: 2.0747\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 975us/step - loss: 0.2161\n16/16 [==============================] - 0s 1ms/step - loss: 1.6263\n16/16 [==============================] - 0s 1ms/step - loss: 1.9708\n16/16 [==============================] - 0s 601us/step - loss: 2.0786\n16/16 [==============================] - 0s 806us/step - loss: 2.0799\n16/16 [==============================] - 0s 787us/step - loss: 2.0658\n16/16 [==============================] - 0s 870us/step - loss: 2.0449\n16/16 [==============================] - 0s 1ms/step - loss: 2.0250\n16/16 [==============================] - 0s 1ms/step - loss: 2.0177\n16/16 [==============================] - 0s 826us/step - loss: 2.0146\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 611us/step - loss: 0.2170\n16/16 [==============================] - 0s 1ms/step - loss: 1.6675\n16/16 [==============================] - 0s 814us/step - loss: 2.0171\n16/16 [==============================] - 0s 610us/step - loss: 2.1244\n16/16 [==============================] - 0s 619us/step - loss: 2.1233\n16/16 [==============================] - 0s 1ms/step - loss: 2.1079\n16/16 [==============================] - 0s 856us/step - loss: 2.0871\n16/16 [==============================] - 0s 1ms/step - loss: 2.0677\n16/16 [==============================] - 0s 632us/step - loss: 2.0605\n16/16 [==============================] - 0s 602us/step - loss: 2.0574\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 636us/step - loss: 0.2144\n16/16 [==============================] - 0s 709us/step - loss: 1.6430\n16/16 [==============================] - 0s 667us/step - loss: 1.9817\n16/16 [==============================] - 0s 682us/step - loss: 2.0881\n16/16 [==============================] - 0s 1ms/step - loss: 2.0878\n16/16 [==============================] - 0s 1ms/step - loss: 2.0724\n16/16 [==============================] - 0s 629us/step - loss: 2.0513\n16/16 [==============================] - 0s 1ms/step - loss: 2.0314\n16/16 [==============================] - 0s 884us/step - loss: 2.0241\n16/16 [==============================] - 0s 585us/step - loss: 2.0210\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 726us/step - loss: 0.2157\n16/16 [==============================] - 0s 1ms/step - loss: 1.6566\n16/16 [==============================] - 0s 1ms/step - loss: 2.0048\n16/16 [==============================] - 0s 708us/step - loss: 2.1166\n16/16 [==============================] - 0s 1ms/step - loss: 2.1189\n16/16 [==============================] - 0s 1ms/step - loss: 2.1054\n16/16 [==============================] - 0s 684us/step - loss: 2.0858\n16/16 [==============================] - 0s 922us/step - loss: 2.0670\n16/16 [==============================] - 0s 1ms/step - loss: 2.0600\n16/16 [==============================] - 0s 602us/step - loss: 2.0569\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2162\n16/16 [==============================] - 0s 1ms/step - loss: 1.6785\n16/16 [==============================] - 0s 1ms/step - loss: 2.0249\n16/16 [==============================] - 0s 1ms/step - loss: 2.1348\n16/16 [==============================] - 0s 630us/step - loss: 2.1339\n16/16 [==============================] - 0s 1ms/step - loss: 2.1192\n16/16 [==============================] - 0s 604us/step - loss: 2.0985\n16/16 [==============================] - 0s 660us/step - loss: 2.0787\n16/16 [==============================] - 0s 741us/step - loss: 2.0714\n16/16 [==============================] - 0s 1ms/step - loss: 2.0683\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 636us/step - loss: 0.2121\n16/16 [==============================] - 0s 1ms/step - loss: 1.7297\n16/16 [==============================] - 0s 1ms/step - loss: 2.0914\n16/16 [==============================] - 0s 1ms/step - loss: 2.2077\n16/16 [==============================] - 0s 615us/step - loss: 2.2066\n16/16 [==============================] - 0s 615us/step - loss: 2.1895\n16/16 [==============================] - 0s 1ms/step - loss: 2.1665\n16/16 [==============================] - 0s 659us/step - loss: 2.1450\n16/16 [==============================] - 0s 1ms/step - loss: 2.1372\n16/16 [==============================] - 0s 911us/step - loss: 2.1339\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2120\n16/16 [==============================] - 0s 787us/step - loss: 1.7164\n16/16 [==============================] - 0s 644us/step - loss: 2.0674\n16/16 [==============================] - 0s 629us/step - loss: 2.1800\n16/16 [==============================] - 0s 1ms/step - loss: 2.1770\n16/16 [==============================] - 0s 652us/step - loss: 2.1600\n16/16 [==============================] - 0s 620us/step - loss: 2.1373\n16/16 [==============================] - 0s 784us/step - loss: 2.1164\n16/16 [==============================] - 0s 644us/step - loss: 2.1088\n16/16 [==============================] - 0s 606us/step - loss: 2.1055\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 685us/step - loss: 0.2108\n16/16 [==============================] - 0s 789us/step - loss: 1.7226\n16/16 [==============================] - 0s 653us/step - loss: 2.0726\n16/16 [==============================] - 0s 1ms/step - loss: 2.1850\n16/16 [==============================] - 0s 737us/step - loss: 2.1834\n16/16 [==============================] - 0s 659us/step - loss: 2.1657\n16/16 [==============================] - 0s 633us/step - loss: 2.1428\n16/16 [==============================] - 0s 851us/step - loss: 2.1217\n16/16 [==============================] - 0s 636us/step - loss: 2.1141\n16/16 [==============================] - 0s 599us/step - loss: 2.1108\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2095\n16/16 [==============================] - 0s 894us/step - loss: 1.7267\n16/16 [==============================] - 0s 693us/step - loss: 2.0755\n16/16 [==============================] - 0s 1ms/step - loss: 2.1840\n16/16 [==============================] - 0s 1ms/step - loss: 2.1795\n16/16 [==============================] - 0s 932us/step - loss: 2.1586\n16/16 [==============================] - 0s 617us/step - loss: 2.1342\n16/16 [==============================] - 0s 1ms/step - loss: 2.1125\n16/16 [==============================] - 0s 672us/step - loss: 2.1046\n16/16 [==============================] - 0s 1ms/step - loss: 2.1013\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 629us/step - loss: 0.2097\n16/16 [==============================] - 0s 656us/step - loss: 1.7201\n16/16 [==============================] - 0s 725us/step - loss: 2.0713\n16/16 [==============================] - 0s 610us/step - loss: 2.1837\n16/16 [==============================] - 0s 857us/step - loss: 2.1826\n16/16 [==============================] - 0s 1ms/step - loss: 2.1660\n16/16 [==============================] - 0s 619us/step - loss: 2.1441\n16/16 [==============================] - 0s 1ms/step - loss: 2.1235\n16/16 [==============================] - 0s 759us/step - loss: 2.1159\n16/16 [==============================] - 0s 1ms/step - loss: 2.1127\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 617us/step - loss: 0.2078\n16/16 [==============================] - 0s 1ms/step - loss: 1.7352\n16/16 [==============================] - 0s 633us/step - loss: 2.0834\n16/16 [==============================] - 0s 617us/step - loss: 2.1909\n16/16 [==============================] - 0s 661us/step - loss: 2.1858\n16/16 [==============================] - 0s 635us/step - loss: 2.1659\n16/16 [==============================] - 0s 675us/step - loss: 2.1419\n16/16 [==============================] - 0s 1ms/step - loss: 2.1201\n16/16 [==============================] - 0s 638us/step - loss: 2.1122\n16/16 [==============================] - 0s 924us/step - loss: 2.1089\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2075\n16/16 [==============================] - 0s 1ms/step - loss: 1.7201\n16/16 [==============================] - 0s 808us/step - loss: 2.0682\n16/16 [==============================] - 0s 1ms/step - loss: 2.1789\n16/16 [==============================] - 0s 1ms/step - loss: 2.1772\n16/16 [==============================] - 0s 832us/step - loss: 2.1596\n16/16 [==============================] - 0s 1ms/step - loss: 2.1366\n16/16 [==============================] - 0s 631us/step - loss: 2.1155\n16/16 [==============================] - 0s 1ms/step - loss: 2.1079\n16/16 [==============================] - 0s 717us/step - loss: 2.1048\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2033\n16/16 [==============================] - 0s 880us/step - loss: 1.7117\n16/16 [==============================] - 0s 689us/step - loss: 2.0529\n16/16 [==============================] - 0s 646us/step - loss: 2.1588\n16/16 [==============================] - 0s 629us/step - loss: 2.1535\n16/16 [==============================] - 0s 977us/step - loss: 2.1332\n16/16 [==============================] - 0s 564us/step - loss: 2.1092\n16/16 [==============================] - 0s 647us/step - loss: 2.0876\n16/16 [==============================] - 0s 1ms/step - loss: 2.0798\n16/16 [==============================] - 0s 591us/step - loss: 2.0766\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 990us/step - loss: 0.2022\n16/16 [==============================] - 0s 1ms/step - loss: 1.7204\n16/16 [==============================] - 0s 612us/step - loss: 2.0604\n16/16 [==============================] - 0s 631us/step - loss: 2.1673\n16/16 [==============================] - 0s 1ms/step - loss: 2.1620\n16/16 [==============================] - 0s 629us/step - loss: 2.1416\n16/16 [==============================] - 0s 929us/step - loss: 2.1173\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n16/16 [==============================] - 0s 1ms/step - loss: 2.0879\n16/16 [==============================] - 0s 617us/step - loss: 2.0846\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.2030\n16/16 [==============================] - 0s 1ms/step - loss: 1.7209\n16/16 [==============================] - 0s 605us/step - loss: 2.0625\n16/16 [==============================] - 0s 1ms/step - loss: 2.1710\n16/16 [==============================] - 0s 700us/step - loss: 2.1667\n16/16 [==============================] - 0s 1ms/step - loss: 2.1474\n16/16 [==============================] - 0s 902us/step - loss: 2.1242\n16/16 [==============================] - 0s 667us/step - loss: 2.1033\n16/16 [==============================] - 0s 1ms/step - loss: 2.0957\n16/16 [==============================] - 0s 1ms/step - loss: 2.0925\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 621us/step - loss: 0.2029\n16/16 [==============================] - 0s 610us/step - loss: 1.7547\n16/16 [==============================] - 0s 611us/step - loss: 2.1118\n16/16 [==============================] - 0s 597us/step - loss: 2.2254\n16/16 [==============================] - 0s 576us/step - loss: 2.2233\n16/16 [==============================] - 0s 580us/step - loss: 2.2050\n16/16 [==============================] - 0s 612us/step - loss: 2.1821\n16/16 [==============================] - 0s 605us/step - loss: 2.1610\n16/16 [==============================] - 0s 807us/step - loss: 2.1534\n16/16 [==============================] - 0s 1ms/step - loss: 2.1502\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1969\n16/16 [==============================] - 0s 955us/step - loss: 1.7401\n16/16 [==============================] - 0s 642us/step - loss: 2.0891\n16/16 [==============================] - 0s 691us/step - loss: 2.1926\n16/16 [==============================] - 0s 1ms/step - loss: 2.1827\n16/16 [==============================] - 0s 706us/step - loss: 2.1592\n16/16 [==============================] - 0s 1ms/step - loss: 2.1331\n16/16 [==============================] - 0s 835us/step - loss: 2.1100\n16/16 [==============================] - 0s 1ms/step - loss: 2.1018\n16/16 [==============================] - 0s 1ms/step - loss: 2.0983\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 659us/step - loss: 0.1983\n16/16 [==============================] - 0s 664us/step - loss: 1.7511\n16/16 [==============================] - 0s 1ms/step - loss: 2.1021\n16/16 [==============================] - 0s 632us/step - loss: 2.2065\n16/16 [==============================] - 0s 1ms/step - loss: 2.1983\n16/16 [==============================] - 0s 1ms/step - loss: 2.1764\n16/16 [==============================] - 0s 1ms/step - loss: 2.1510\n16/16 [==============================] - 0s 639us/step - loss: 2.1285\n16/16 [==============================] - 0s 641us/step - loss: 2.1205\n16/16 [==============================] - 0s 1ms/step - loss: 2.1171\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 774us/step - loss: 0.1992\n16/16 [==============================] - 0s 643us/step - loss: 1.7271\n16/16 [==============================] - 0s 1ms/step - loss: 2.0661\n16/16 [==============================] - 0s 1ms/step - loss: 2.1656\n16/16 [==============================] - 0s 1ms/step - loss: 2.1575\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 620us/step - loss: 2.1083\n16/16 [==============================] - 0s 675us/step - loss: 2.0856\n16/16 [==============================] - 0s 1ms/step - loss: 2.0776\n16/16 [==============================] - 0s 641us/step - loss: 2.0743\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1973\n16/16 [==============================] - 0s 634us/step - loss: 1.7673\n16/16 [==============================] - 0s 641us/step - loss: 2.1133\n16/16 [==============================] - 0s 807us/step - loss: 2.2143\n16/16 [==============================] - 0s 1ms/step - loss: 2.2060\n16/16 [==============================] - 0s 680us/step - loss: 2.1823\n16/16 [==============================] - 0s 915us/step - loss: 2.1568\n16/16 [==============================] - 0s 1ms/step - loss: 2.1343\n16/16 [==============================] - 0s 637us/step - loss: 2.1262\n16/16 [==============================] - 0s 1ms/step - loss: 2.1229\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1957\n16/16 [==============================] - 0s 1ms/step - loss: 1.7630\n16/16 [==============================] - 0s 1ms/step - loss: 2.1149\n16/16 [==============================] - 0s 1ms/step - loss: 2.2172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2101\n16/16 [==============================] - 0s 785us/step - loss: 2.1867\n16/16 [==============================] - 0s 767us/step - loss: 2.1611\n16/16 [==============================] - 0s 1ms/step - loss: 2.1384\n16/16 [==============================] - 0s 1ms/step - loss: 2.1303\n16/16 [==============================] - 0s 835us/step - loss: 2.1270\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 659us/step - loss: 0.1958\n16/16 [==============================] - 0s 636us/step - loss: 1.7773\n16/16 [==============================] - 0s 580us/step - loss: 2.1316\n16/16 [==============================] - 0s 632us/step - loss: 2.2359\n16/16 [==============================] - 0s 699us/step - loss: 2.2285\n16/16 [==============================] - 0s 642us/step - loss: 2.2029\n16/16 [==============================] - 0s 953us/step - loss: 2.1759\n16/16 [==============================] - 0s 1ms/step - loss: 2.1522\n16/16 [==============================] - 0s 1ms/step - loss: 2.1437\n16/16 [==============================] - 0s 843us/step - loss: 2.1402\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1914\n16/16 [==============================] - 0s 908us/step - loss: 1.7573\n16/16 [==============================] - 0s 718us/step - loss: 2.1000\n16/16 [==============================] - 0s 1ms/step - loss: 2.1991\n16/16 [==============================] - 0s 626us/step - loss: 2.1890\n16/16 [==============================] - 0s 746us/step - loss: 2.1621\n16/16 [==============================] - 0s 649us/step - loss: 2.1343\n16/16 [==============================] - 0s 653us/step - loss: 2.1108\n16/16 [==============================] - 0s 1ms/step - loss: 2.1026\n16/16 [==============================] - 0s 1ms/step - loss: 2.0992\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 615us/step - loss: 0.1948\n16/16 [==============================] - 0s 637us/step - loss: 1.8010\n16/16 [==============================] - 0s 1ms/step - loss: 2.1603\n16/16 [==============================] - 0s 628us/step - loss: 2.2660\n16/16 [==============================] - 0s 1ms/step - loss: 2.2587\n16/16 [==============================] - 0s 706us/step - loss: 2.2337\n16/16 [==============================] - 0s 637us/step - loss: 2.2068\n16/16 [==============================] - 0s 631us/step - loss: 2.1834\n16/16 [==============================] - 0s 1ms/step - loss: 2.1750\n16/16 [==============================] - 0s 1ms/step - loss: 2.1716\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1911\n16/16 [==============================] - 0s 641us/step - loss: 1.7696\n16/16 [==============================] - 0s 841us/step - loss: 2.1178\n16/16 [==============================] - 0s 778us/step - loss: 2.2186\n16/16 [==============================] - 0s 1ms/step - loss: 2.2089\n16/16 [==============================] - 0s 1ms/step - loss: 2.1826\n16/16 [==============================] - 0s 1ms/step - loss: 2.1555\n16/16 [==============================] - 0s 1ms/step - loss: 2.1326\n16/16 [==============================] - 0s 1ms/step - loss: 2.1245\n16/16 [==============================] - 0s 1ms/step - loss: 2.1212\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 728us/step - loss: 0.1921\n16/16 [==============================] - 0s 635us/step - loss: 1.8098\n16/16 [==============================] - 0s 1ms/step - loss: 2.1669\n16/16 [==============================] - 0s 661us/step - loss: 2.2703\n16/16 [==============================] - 0s 1ms/step - loss: 2.2623\n16/16 [==============================] - 0s 664us/step - loss: 2.2363\n16/16 [==============================] - 0s 650us/step - loss: 2.2087\n16/16 [==============================] - 0s 648us/step - loss: 2.1849\n16/16 [==============================] - 0s 642us/step - loss: 2.1766\n16/16 [==============================] - 0s 662us/step - loss: 2.1732\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1943\n16/16 [==============================] - 0s 873us/step - loss: 1.7990\n16/16 [==============================] - 0s 1ms/step - loss: 2.1590\n16/16 [==============================] - 0s 1ms/step - loss: 2.2620\n16/16 [==============================] - 0s 1ms/step - loss: 2.2528\n16/16 [==============================] - 0s 600us/step - loss: 2.2259\n16/16 [==============================] - 0s 584us/step - loss: 2.1981\n16/16 [==============================] - 0s 1ms/step - loss: 2.1742\n16/16 [==============================] - 0s 1ms/step - loss: 2.1658\n16/16 [==============================] - 0s 1ms/step - loss: 2.1623\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1929\n16/16 [==============================] - 0s 1ms/step - loss: 1.7656\n16/16 [==============================] - 0s 784us/step - loss: 2.1149\n16/16 [==============================] - 0s 619us/step - loss: 2.2138\n16/16 [==============================] - 0s 587us/step - loss: 2.2056\n16/16 [==============================] - 0s 590us/step - loss: 2.1795\n16/16 [==============================] - 0s 567us/step - loss: 2.1526\n16/16 [==============================] - 0s 616us/step - loss: 2.1299\n16/16 [==============================] - 0s 1ms/step - loss: 2.1219\n16/16 [==============================] - 0s 594us/step - loss: 2.1186\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 761us/step - loss: 0.1915\n16/16 [==============================] - 0s 1ms/step - loss: 1.7777\n16/16 [==============================] - 0s 1ms/step - loss: 2.1276\n16/16 [==============================] - 0s 1ms/step - loss: 2.2233\n16/16 [==============================] - 0s 1ms/step - loss: 2.2119\n16/16 [==============================] - 0s 1ms/step - loss: 2.1831\n16/16 [==============================] - 0s 1ms/step - loss: 2.1549\n16/16 [==============================] - 0s 1ms/step - loss: 2.1315\n16/16 [==============================] - 0s 1ms/step - loss: 2.1235\n16/16 [==============================] - 0s 1ms/step - loss: 2.1202\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1890\n16/16 [==============================] - 0s 947us/step - loss: 1.7926\n16/16 [==============================] - 0s 1ms/step - loss: 2.1436\n16/16 [==============================] - 0s 1ms/step - loss: 2.2395\n16/16 [==============================] - 0s 625us/step - loss: 2.2279\n16/16 [==============================] - 0s 1ms/step - loss: 2.1978\n16/16 [==============================] - 0s 1ms/step - loss: 2.1692\n16/16 [==============================] - 0s 1ms/step - loss: 2.1451\n16/16 [==============================] - 0s 1ms/step - loss: 2.1368\n16/16 [==============================] - 0s 1ms/step - loss: 2.1334\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1867\n16/16 [==============================] - 0s 1ms/step - loss: 1.8739\n16/16 [==============================] - 0s 1ms/step - loss: 2.2491\n16/16 [==============================] - 0s 992us/step - loss: 2.3538\n16/16 [==============================] - 0s 1ms/step - loss: 2.3422\n16/16 [==============================] - 0s 870us/step - loss: 2.3119\n16/16 [==============================] - 0s 1ms/step - loss: 2.2828\n16/16 [==============================] - 0s 627us/step - loss: 2.2576\n16/16 [==============================] - 0s 615us/step - loss: 2.2488\n16/16 [==============================] - 0s 748us/step - loss: 2.2452\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1852\n16/16 [==============================] - 0s 725us/step - loss: 1.8347\n16/16 [==============================] - 0s 646us/step - loss: 2.1942\n16/16 [==============================] - 0s 856us/step - loss: 2.2953\n16/16 [==============================] - 0s 661us/step - loss: 2.2842\n16/16 [==============================] - 0s 604us/step - loss: 2.2557\n16/16 [==============================] - 0s 602us/step - loss: 2.2280\n16/16 [==============================] - 0s 908us/step - loss: 2.2039\n16/16 [==============================] - 0s 1ms/step - loss: 2.1955\n16/16 [==============================] - 0s 1ms/step - loss: 2.1921\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 896us/step - loss: 0.1867\n16/16 [==============================] - 0s 668us/step - loss: 1.7861\n16/16 [==============================] - 0s 1ms/step - loss: 2.1329\n16/16 [==============================] - 0s 777us/step - loss: 2.2272\n16/16 [==============================] - 0s 1ms/step - loss: 2.2136\n16/16 [==============================] - 0s 736us/step - loss: 2.1838\n16/16 [==============================] - 0s 606us/step - loss: 2.1556\n16/16 [==============================] - 0s 1ms/step - loss: 2.1315\n16/16 [==============================] - 0s 1ms/step - loss: 2.1232\n16/16 [==============================] - 0s 626us/step - loss: 2.1198\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 579us/step - loss: 0.1835\n16/16 [==============================] - 0s 1ms/step - loss: 1.8104\n16/16 [==============================] - 0s 1ms/step - loss: 2.1585\n16/16 [==============================] - 0s 634us/step - loss: 2.2523\n16/16 [==============================] - 0s 702us/step - loss: 2.2377\n16/16 [==============================] - 0s 635us/step - loss: 2.2062\n16/16 [==============================] - 0s 604us/step - loss: 2.1763\n16/16 [==============================] - 0s 1ms/step - loss: 2.1511\n16/16 [==============================] - 0s 1ms/step - loss: 2.1427\n16/16 [==============================] - 0s 625us/step - loss: 2.1392\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 613us/step - loss: 0.1853\n16/16 [==============================] - 0s 700us/step - loss: 1.8215\n16/16 [==============================] - 0s 1ms/step - loss: 2.1727\n16/16 [==============================] - 0s 723us/step - loss: 2.2672\n16/16 [==============================] - 0s 714us/step - loss: 2.2522\n16/16 [==============================] - 0s 621us/step - loss: 2.2214\n16/16 [==============================] - 0s 669us/step - loss: 2.1932\n16/16 [==============================] - 0s 607us/step - loss: 2.1690\n16/16 [==============================] - 0s 700us/step - loss: 2.1607\n16/16 [==============================] - 0s 651us/step - loss: 2.1573\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 628us/step - loss: 0.1840\n16/16 [==============================] - 0s 600us/step - loss: 1.8633\n16/16 [==============================] - 0s 622us/step - loss: 2.2307\n16/16 [==============================] - 0s 620us/step - loss: 2.3265\n16/16 [==============================] - 0s 622us/step - loss: 2.3089\n16/16 [==============================] - 0s 652us/step - loss: 2.2739\n16/16 [==============================] - 0s 1ms/step - loss: 2.2421\n16/16 [==============================] - 0s 968us/step - loss: 2.2152\n16/16 [==============================] - 0s 1ms/step - loss: 2.2061\n16/16 [==============================] - 0s 851us/step - loss: 2.2024\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 639us/step - loss: 0.1830\n16/16 [==============================] - 0s 1ms/step - loss: 1.8733\n16/16 [==============================] - 0s 621us/step - loss: 2.2434\n16/16 [==============================] - 0s 966us/step - loss: 2.3381\n16/16 [==============================] - 0s 1ms/step - loss: 2.3205\n16/16 [==============================] - 0s 1ms/step - loss: 2.2861\n16/16 [==============================] - 0s 1ms/step - loss: 2.2544\n16/16 [==============================] - 0s 1ms/step - loss: 2.2276\n16/16 [==============================] - 0s 936us/step - loss: 2.2186\n16/16 [==============================] - 0s 617us/step - loss: 2.2149\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1816\n16/16 [==============================] - 0s 618us/step - loss: 1.8904\n16/16 [==============================] - 0s 1ms/step - loss: 2.2667\n16/16 [==============================] - 0s 707us/step - loss: 2.3649\n16/16 [==============================] - 0s 1ms/step - loss: 2.3499\n16/16 [==============================] - 0s 1ms/step - loss: 2.3184\n16/16 [==============================] - 0s 1ms/step - loss: 2.2894\n16/16 [==============================] - 0s 1ms/step - loss: 2.2641\n16/16 [==============================] - 0s 1ms/step - loss: 2.2555\n16/16 [==============================] - 0s 632us/step - loss: 2.2520\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 607us/step - loss: 0.1833\n16/16 [==============================] - 0s 641us/step - loss: 1.8758\n16/16 [==============================] - 0s 1ms/step - loss: 2.2495\n16/16 [==============================] - 0s 617us/step - loss: 2.3460\n16/16 [==============================] - 0s 639us/step - loss: 2.3310\n16/16 [==============================] - 0s 930us/step - loss: 2.2983\n16/16 [==============================] - 0s 622us/step - loss: 2.2679\n16/16 [==============================] - 0s 1ms/step - loss: 2.2418\n16/16 [==============================] - 0s 624us/step - loss: 2.2328\n16/16 [==============================] - 0s 1ms/step - loss: 2.2291\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 969us/step - loss: 0.1794\n16/16 [==============================] - 0s 1ms/step - loss: 1.9049\n16/16 [==============================] - 0s 1ms/step - loss: 2.2851\n16/16 [==============================] - 0s 615us/step - loss: 2.3832\n16/16 [==============================] - 0s 712us/step - loss: 2.3669\n16/16 [==============================] - 0s 616us/step - loss: 2.3326\n16/16 [==============================] - 0s 1ms/step - loss: 2.3017\n16/16 [==============================] - 0s 630us/step - loss: 2.2754\n16/16 [==============================] - 0s 837us/step - loss: 2.2665\n16/16 [==============================] - 0s 1ms/step - loss: 2.2628\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 632us/step - loss: 0.1800\n16/16 [==============================] - 0s 626us/step - loss: 1.8637\n16/16 [==============================] - 0s 904us/step - loss: 2.2352\n16/16 [==============================] - 0s 1ms/step - loss: 2.3308\n16/16 [==============================] - 0s 1ms/step - loss: 2.3141\n16/16 [==============================] - 0s 1ms/step - loss: 2.2801\n16/16 [==============================] - 0s 1ms/step - loss: 2.2488\n16/16 [==============================] - 0s 1ms/step - loss: 2.2227\n16/16 [==============================] - 0s 919us/step - loss: 2.2139\n16/16 [==============================] - 0s 966us/step - loss: 2.2103\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1775\n16/16 [==============================] - 0s 644us/step - loss: 1.9059\n16/16 [==============================] - 0s 669us/step - loss: 2.2860\n16/16 [==============================] - 0s 1ms/step - loss: 2.3835\n16/16 [==============================] - 0s 664us/step - loss: 2.3656\n16/16 [==============================] - 0s 1ms/step - loss: 2.3309\n16/16 [==============================] - 0s 689us/step - loss: 2.2992\n16/16 [==============================] - 0s 1ms/step - loss: 2.2725\n16/16 [==============================] - 0s 1ms/step - loss: 2.2635\n16/16 [==============================] - 0s 1ms/step - loss: 2.2598\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1770\n16/16 [==============================] - 0s 882us/step - loss: 1.8485\n16/16 [==============================] - 0s 1ms/step - loss: 2.2087\n16/16 [==============================] - 0s 843us/step - loss: 2.3001\n16/16 [==============================] - 0s 1ms/step - loss: 2.2820\n16/16 [==============================] - 0s 1ms/step - loss: 2.2470\n16/16 [==============================] - 0s 808us/step - loss: 2.2158\n16/16 [==============================] - 0s 674us/step - loss: 2.1898\n16/16 [==============================] - 0s 665us/step - loss: 2.1810\n16/16 [==============================] - 0s 666us/step - loss: 2.1774\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 702us/step - loss: 0.1778\n16/16 [==============================] - 0s 1ms/step - loss: 1.8604\n16/16 [==============================] - 0s 1ms/step - loss: 2.2199\n16/16 [==============================] - 0s 1ms/step - loss: 2.3081\n16/16 [==============================] - 0s 1ms/step - loss: 2.2886\n16/16 [==============================] - 0s 1ms/step - loss: 2.2537\n16/16 [==============================] - 0s 899us/step - loss: 2.2230\n16/16 [==============================] - 0s 847us/step - loss: 2.1975\n16/16 [==============================] - 0s 674us/step - loss: 2.1890\n16/16 [==============================] - 0s 648us/step - loss: 2.1856\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1772\n16/16 [==============================] - 0s 1ms/step - loss: 1.9029\n16/16 [==============================] - 0s 1ms/step - loss: 2.2795\n16/16 [==============================] - 0s 929us/step - loss: 2.3721\n16/16 [==============================] - 0s 656us/step - loss: 2.3526\n16/16 [==============================] - 0s 685us/step - loss: 2.3171\n16/16 [==============================] - 0s 697us/step - loss: 2.2856\n16/16 [==============================] - 0s 686us/step - loss: 2.2594\n16/16 [==============================] - 0s 1ms/step - loss: 2.2505\n16/16 [==============================] - 0s 938us/step - loss: 2.2469\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 736us/step - loss: 0.1773\n16/16 [==============================] - 0s 1ms/step - loss: 1.8690\n16/16 [==============================] - 0s 1ms/step - loss: 2.2337\n16/16 [==============================] - 0s 997us/step - loss: 2.3199\n16/16 [==============================] - 0s 1ms/step - loss: 2.2990\n16/16 [==============================] - 0s 965us/step - loss: 2.2626\n16/16 [==============================] - 0s 1ms/step - loss: 2.2305\n16/16 [==============================] - 0s 681us/step - loss: 2.2046\n16/16 [==============================] - 0s 701us/step - loss: 2.1959\n16/16 [==============================] - 0s 684us/step - loss: 2.1924\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 857us/step - loss: 0.1749\n16/16 [==============================] - 0s 647us/step - loss: 1.8422\n16/16 [==============================] - 0s 695us/step - loss: 2.2055\n16/16 [==============================] - 0s 1ms/step - loss: 2.2933\n16/16 [==============================] - 0s 858us/step - loss: 2.2752\n16/16 [==============================] - 0s 1ms/step - loss: 2.2414\n16/16 [==============================] - 0s 1ms/step - loss: 2.2106\n16/16 [==============================] - 0s 702us/step - loss: 2.1853\n16/16 [==============================] - 0s 1ms/step - loss: 2.1768\n16/16 [==============================] - 0s 653us/step - loss: 2.1733\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1735\n16/16 [==============================] - 0s 2ms/step - loss: 1.8843\n16/16 [==============================] - 0s 2ms/step - loss: 2.2440\n16/16 [==============================] - 0s 2ms/step - loss: 2.3291\n16/16 [==============================] - 0s 2ms/step - loss: 2.3069\n16/16 [==============================] - 0s 2ms/step - loss: 2.2710\n16/16 [==============================] - 0s 2ms/step - loss: 2.2398\n16/16 [==============================] - 0s 2ms/step - loss: 2.2144\n16/16 [==============================] - 0s 2ms/step - loss: 2.2058\n16/16 [==============================] - 0s 1ms/step - loss: 2.2023\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 776us/step - loss: 0.1737\n16/16 [==============================] - 0s 2ms/step - loss: 1.8765\n16/16 [==============================] - 0s 2ms/step - loss: 2.2332\n16/16 [==============================] - 0s 2ms/step - loss: 2.3172\n16/16 [==============================] - 0s 2ms/step - loss: 2.2945\n16/16 [==============================] - 0s 2ms/step - loss: 2.2569\n16/16 [==============================] - 0s 3ms/step - loss: 2.2234\n16/16 [==============================] - 0s 2ms/step - loss: 2.1967\n16/16 [==============================] - 0s 2ms/step - loss: 2.1880\n16/16 [==============================] - 0s 2ms/step - loss: 2.1844\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1761\n16/16 [==============================] - 0s 716us/step - loss: 1.8934\n16/16 [==============================] - 0s 703us/step - loss: 2.2560\n16/16 [==============================] - 0s 675us/step - loss: 2.3469\n16/16 [==============================] - 0s 683us/step - loss: 2.3263\n16/16 [==============================] - 0s 735us/step - loss: 2.2914\n16/16 [==============================] - 0s 2ms/step - loss: 2.2595\n16/16 [==============================] - 0s 2ms/step - loss: 2.2333\n16/16 [==============================] - 0s 2ms/step - loss: 2.2245\n16/16 [==============================] - 0s 1ms/step - loss: 2.2209\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1722\n16/16 [==============================] - 0s 2ms/step - loss: 1.9280\n16/16 [==============================] - 0s 1ms/step - loss: 2.2976\n16/16 [==============================] - 0s 1ms/step - loss: 2.3871\n16/16 [==============================] - 0s 1ms/step - loss: 2.3629\n16/16 [==============================] - 0s 1ms/step - loss: 2.3248\n16/16 [==============================] - 0s 2ms/step - loss: 2.2908\n16/16 [==============================] - 0s 1ms/step - loss: 2.2634\n16/16 [==============================] - 0s 2ms/step - loss: 2.2542\n16/16 [==============================] - 0s 2ms/step - loss: 2.2505\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 665us/step - loss: 0.1699\n16/16 [==============================] - 0s 649us/step - loss: 1.9410\n16/16 [==============================] - 0s 642us/step - loss: 2.3137\n16/16 [==============================] - 0s 647us/step - loss: 2.4031\n16/16 [==============================] - 0s 634us/step - loss: 2.3771\n16/16 [==============================] - 0s 655us/step - loss: 2.3376\n16/16 [==============================] - 0s 2ms/step - loss: 2.3020\n16/16 [==============================] - 0s 1ms/step - loss: 2.2737\n16/16 [==============================] - 0s 670us/step - loss: 2.2643\n16/16 [==============================] - 0s 643us/step - loss: 2.2604\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 629us/step - loss: 0.1723\n16/16 [==============================] - 0s 2ms/step - loss: 1.8916\n16/16 [==============================] - 0s 807us/step - loss: 2.2597\n16/16 [==============================] - 0s 933us/step - loss: 2.3476\n16/16 [==============================] - 0s 933us/step - loss: 2.3238\n16/16 [==============================] - 0s 923us/step - loss: 2.2886\n16/16 [==============================] - 0s 952us/step - loss: 2.2566\n16/16 [==============================] - 0s 1ms/step - loss: 2.2308\n16/16 [==============================] - 0s 995us/step - loss: 2.2222\n16/16 [==============================] - 0s 911us/step - loss: 2.2188\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1698\n16/16 [==============================] - 0s 2ms/step - loss: 1.9182\n16/16 [==============================] - 0s 1ms/step - loss: 2.2868\n16/16 [==============================] - 0s 755us/step - loss: 2.3684\n16/16 [==============================] - 0s 652us/step - loss: 2.3398\n16/16 [==============================] - 0s 650us/step - loss: 2.3013\n16/16 [==============================] - 0s 648us/step - loss: 2.2666\n16/16 [==============================] - 0s 660us/step - loss: 2.2391\n16/16 [==============================] - 0s 1ms/step - loss: 2.2300\n16/16 [==============================] - 0s 2ms/step - loss: 2.2264\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1686\n16/16 [==============================] - 0s 648us/step - loss: 1.9577\n16/16 [==============================] - 0s 887us/step - loss: 2.3428\n16/16 [==============================] - 0s 1ms/step - loss: 2.4313\n16/16 [==============================] - 0s 645us/step - loss: 2.4052\n16/16 [==============================] - 0s 1ms/step - loss: 2.3674\n16/16 [==============================] - 0s 2ms/step - loss: 2.3327\n16/16 [==============================] - 0s 653us/step - loss: 2.3051\n16/16 [==============================] - 0s 2ms/step - loss: 2.2958\n16/16 [==============================] - 0s 2ms/step - loss: 2.2921\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1707\n16/16 [==============================] - 0s 1ms/step - loss: 1.9381\n16/16 [==============================] - 0s 626us/step - loss: 2.3141\n16/16 [==============================] - 0s 2ms/step - loss: 2.3976\n16/16 [==============================] - 0s 1ms/step - loss: 2.3711\n16/16 [==============================] - 0s 2ms/step - loss: 2.3333\n16/16 [==============================] - 0s 2ms/step - loss: 2.2988\n16/16 [==============================] - 0s 2ms/step - loss: 2.2715\n16/16 [==============================] - 0s 1ms/step - loss: 2.2624\n16/16 [==============================] - 0s 2ms/step - loss: 2.2588\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1687\n16/16 [==============================] - 0s 2ms/step - loss: 1.9747\n16/16 [==============================] - 0s 2ms/step - loss: 2.3635\n16/16 [==============================] - 0s 2ms/step - loss: 2.4468\n16/16 [==============================] - 0s 2ms/step - loss: 2.4175\n16/16 [==============================] - 0s 2ms/step - loss: 2.3761\n16/16 [==============================] - 0s 1ms/step - loss: 2.3383\n16/16 [==============================] - 0s 2ms/step - loss: 2.3088\n16/16 [==============================] - 0s 1ms/step - loss: 2.2990\n16/16 [==============================] - 0s 2ms/step - loss: 2.2950\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1671\n16/16 [==============================] - 0s 1ms/step - loss: 1.9391\n16/16 [==============================] - 0s 2ms/step - loss: 2.3156\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n16/16 [==============================] - 0s 2ms/step - loss: 2.3719\n16/16 [==============================] - 0s 2ms/step - loss: 2.3335\n16/16 [==============================] - 0s 2ms/step - loss: 2.2984\n16/16 [==============================] - 0s 2ms/step - loss: 2.2707\n16/16 [==============================] - 0s 2ms/step - loss: 2.2614\n16/16 [==============================] - 0s 2ms/step - loss: 2.2577\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1662\n16/16 [==============================] - 0s 1ms/step - loss: 1.9564\n16/16 [==============================] - 0s 1ms/step - loss: 2.3366\n16/16 [==============================] - 0s 2ms/step - loss: 2.4170\n16/16 [==============================] - 0s 2ms/step - loss: 2.3906\n16/16 [==============================] - 0s 2ms/step - loss: 2.3517\n16/16 [==============================] - 0s 1ms/step - loss: 2.3168\n16/16 [==============================] - 0s 1ms/step - loss: 2.2891\n16/16 [==============================] - 0s 2ms/step - loss: 2.2799\n16/16 [==============================] - 0s 3ms/step - loss: 2.2762\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1664\n16/16 [==============================] - 0s 836us/step - loss: 1.9228\n16/16 [==============================] - 0s 857us/step - loss: 2.2967\n16/16 [==============================] - 0s 827us/step - loss: 2.3769\n16/16 [==============================] - 0s 2ms/step - loss: 2.3522\n16/16 [==============================] - 0s 2ms/step - loss: 2.3146\n16/16 [==============================] - 0s 2ms/step - loss: 2.2804\n16/16 [==============================] - 0s 2ms/step - loss: 2.2535\n16/16 [==============================] - 0s 2ms/step - loss: 2.2446\n16/16 [==============================] - 0s 2ms/step - loss: 2.2410\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 968us/step - loss: 0.1647\n16/16 [==============================] - 0s 836us/step - loss: 1.9825\n16/16 [==============================] - 0s 1ms/step - loss: 2.3655\n16/16 [==============================] - 0s 991us/step - loss: 2.4400\n16/16 [==============================] - 0s 708us/step - loss: 2.4065\n16/16 [==============================] - 0s 988us/step - loss: 2.3618\n16/16 [==============================] - 0s 1ms/step - loss: 2.3236\n16/16 [==============================] - 0s 769us/step - loss: 2.2942\n16/16 [==============================] - 0s 630us/step - loss: 2.2846\n16/16 [==============================] - 0s 832us/step - loss: 2.2808\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 0.1616\n16/16 [==============================] - 0s 2ms/step - loss: 1.9799\n16/16 [==============================] - 0s 2ms/step - loss: 2.3682\n16/16 [==============================] - 0s 2ms/step - loss: 2.4457\n16/16 [==============================] - 0s 2ms/step - loss: 2.4156\n16/16 [==============================] - 0s 2ms/step - loss: 2.3727\n16/16 [==============================] - 0s 2ms/step - loss: 2.3349\n16/16 [==============================] - 0s 2ms/step - loss: 2.3056\n16/16 [==============================] - 0s 2ms/step - loss: 2.2959\n16/16 [==============================] - 0s 2ms/step - loss: 2.2921\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 594us/step - loss: 0.1670\n16/16 [==============================] - 0s 542us/step - loss: 1.9252\n16/16 [==============================] - 0s 603us/step - loss: 2.3035\n16/16 [==============================] - 0s 638us/step - loss: 2.3810\n16/16 [==============================] - 0s 646us/step - loss: 2.3532\n16/16 [==============================] - 0s 490us/step - loss: 2.3132\n16/16 [==============================] - 0s 517us/step - loss: 2.2779\n16/16 [==============================] - 0s 1ms/step - loss: 2.2503\n16/16 [==============================] - 0s 895us/step - loss: 2.2412\n16/16 [==============================] - 0s 570us/step - loss: 2.2376\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 626us/step - loss: 0.1649\n16/16 [==============================] - 0s 921us/step - loss: 1.9655\n16/16 [==============================] - 0s 1ms/step - loss: 2.3495\n16/16 [==============================] - 0s 708us/step - loss: 2.4250\n16/16 [==============================] - 0s 1ms/step - loss: 2.3950\n16/16 [==============================] - 0s 1ms/step - loss: 2.3532\n16/16 [==============================] - 0s 681us/step - loss: 2.3167\n16/16 [==============================] - 0s 632us/step - loss: 2.2886\n16/16 [==============================] - 0s 1ms/step - loss: 2.2794\n16/16 [==============================] - 0s 644us/step - loss: 2.2756\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 716us/step - loss: 0.1628\n16/16 [==============================] - 0s 631us/step - loss: 1.9172\n16/16 [==============================] - 0s 634us/step - loss: 2.2852\n16/16 [==============================] - 0s 601us/step - loss: 2.3543\n16/16 [==============================] - 0s 1ms/step - loss: 2.3241\n16/16 [==============================] - 0s 1ms/step - loss: 2.2817\n16/16 [==============================] - 0s 1ms/step - loss: 2.2446\n16/16 [==============================] - 0s 637us/step - loss: 2.2162\n16/16 [==============================] - 0s 1ms/step - loss: 2.2068\n16/16 [==============================] - 0s 622us/step - loss: 2.2031\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1632\n16/16 [==============================] - 0s 614us/step - loss: 1.9494\n16/16 [==============================] - 0s 585us/step - loss: 2.3248\n16/16 [==============================] - 0s 1ms/step - loss: 2.3958\n16/16 [==============================] - 0s 605us/step - loss: 2.3639\n16/16 [==============================] - 0s 1ms/step - loss: 2.3212\n16/16 [==============================] - 0s 659us/step - loss: 2.2846\n16/16 [==============================] - 0s 920us/step - loss: 2.2564\n16/16 [==============================] - 0s 642us/step - loss: 2.2472\n16/16 [==============================] - 0s 1ms/step - loss: 2.2436\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1623\n16/16 [==============================] - 0s 632us/step - loss: 1.9453\n16/16 [==============================] - 0s 701us/step - loss: 2.3227\n16/16 [==============================] - 0s 1ms/step - loss: 2.3937\n16/16 [==============================] - 0s 598us/step - loss: 2.3616\n16/16 [==============================] - 0s 623us/step - loss: 2.3172\n16/16 [==============================] - 0s 1ms/step - loss: 2.2785\n16/16 [==============================] - 0s 802us/step - loss: 2.2493\n16/16 [==============================] - 0s 1ms/step - loss: 2.2398\n16/16 [==============================] - 0s 900us/step - loss: 2.2360\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 639us/step - loss: 0.1612\n16/16 [==============================] - 0s 709us/step - loss: 1.9442\n16/16 [==============================] - 0s 617us/step - loss: 2.3257\n16/16 [==============================] - 0s 598us/step - loss: 2.4020\n16/16 [==============================] - 0s 1ms/step - loss: 2.3753\n16/16 [==============================] - 0s 625us/step - loss: 2.3369\n16/16 [==============================] - 0s 611us/step - loss: 2.3024\n16/16 [==============================] - 0s 601us/step - loss: 2.2753\n16/16 [==============================] - 0s 764us/step - loss: 2.2663\n16/16 [==============================] - 0s 1ms/step - loss: 2.2626\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1585\n16/16 [==============================] - 0s 1ms/step - loss: 2.0528\n16/16 [==============================] - 0s 609us/step - loss: 2.4585\n16/16 [==============================] - 0s 789us/step - loss: 2.5358\n16/16 [==============================] - 0s 587us/step - loss: 2.5023\n16/16 [==============================] - 0s 672us/step - loss: 2.4563\n16/16 [==============================] - 0s 805us/step - loss: 2.4162\n16/16 [==============================] - 0s 1ms/step - loss: 2.3857\n16/16 [==============================] - 0s 1ms/step - loss: 2.3757\n16/16 [==============================] - 0s 1ms/step - loss: 2.3718\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 735us/step - loss: 0.1614\n16/16 [==============================] - 0s 1ms/step - loss: 2.0477\n16/16 [==============================] - 0s 646us/step - loss: 2.4531\n16/16 [==============================] - 0s 1ms/step - loss: 2.5273\n16/16 [==============================] - 0s 560us/step - loss: 2.4941\n16/16 [==============================] - 0s 604us/step - loss: 2.4496\n16/16 [==============================] - 0s 1ms/step - loss: 2.4104\n16/16 [==============================] - 0s 599us/step - loss: 2.3801\n16/16 [==============================] - 0s 1ms/step - loss: 2.3702\n16/16 [==============================] - 0s 1ms/step - loss: 2.3661\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1584\n16/16 [==============================] - 0s 1ms/step - loss: 2.0297\n16/16 [==============================] - 0s 1ms/step - loss: 2.4309\n16/16 [==============================] - 0s 1ms/step - loss: 2.5028\n16/16 [==============================] - 0s 844us/step - loss: 2.4704\n16/16 [==============================] - 0s 721us/step - loss: 2.4258\n16/16 [==============================] - 0s 1ms/step - loss: 2.3870\n16/16 [==============================] - 0s 724us/step - loss: 2.3575\n16/16 [==============================] - 0s 1ms/step - loss: 2.3479\n16/16 [==============================] - 0s 1ms/step - loss: 2.3440\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1607\n16/16 [==============================] - 0s 1ms/step - loss: 1.9936\n16/16 [==============================] - 0s 1ms/step - loss: 2.3817\n16/16 [==============================] - 0s 618us/step - loss: 2.4495\n16/16 [==============================] - 0s 1ms/step - loss: 2.4171\n16/16 [==============================] - 0s 1ms/step - loss: 2.3735\n16/16 [==============================] - 0s 929us/step - loss: 2.3355\n16/16 [==============================] - 0s 1ms/step - loss: 2.3067\n16/16 [==============================] - 0s 1ms/step - loss: 2.2974\n16/16 [==============================] - 0s 967us/step - loss: 2.2937\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 625us/step - loss: 0.1592\n16/16 [==============================] - 0s 748us/step - loss: 2.0080\n16/16 [==============================] - 0s 948us/step - loss: 2.3934\n16/16 [==============================] - 0s 626us/step - loss: 2.4562\n16/16 [==============================] - 0s 1ms/step - loss: 2.4202\n16/16 [==============================] - 0s 1ms/step - loss: 2.3733\n16/16 [==============================] - 0s 600us/step - loss: 2.3338\n16/16 [==============================] - 0s 1ms/step - loss: 2.3041\n16/16 [==============================] - 0s 1ms/step - loss: 2.2945\n16/16 [==============================] - 0s 579us/step - loss: 2.2907\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1563\n16/16 [==============================] - 0s 1ms/step - loss: 1.9989\n16/16 [==============================] - 0s 791us/step - loss: 2.3823\n16/16 [==============================] - 0s 592us/step - loss: 2.4454\n16/16 [==============================] - 0s 657us/step - loss: 2.4112\n16/16 [==============================] - 0s 731us/step - loss: 2.3670\n16/16 [==============================] - 0s 1ms/step - loss: 2.3288\n16/16 [==============================] - 0s 745us/step - loss: 2.2995\n16/16 [==============================] - 0s 595us/step - loss: 2.2900\n16/16 [==============================] - 0s 629us/step - loss: 2.2862\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 948us/step - loss: 0.1570\n16/16 [==============================] - 0s 860us/step - loss: 1.9843\n16/16 [==============================] - 0s 836us/step - loss: 2.3656\n16/16 [==============================] - 0s 1ms/step - loss: 2.4254\n16/16 [==============================] - 0s 1ms/step - loss: 2.3894\n16/16 [==============================] - 0s 1ms/step - loss: 2.3424\n16/16 [==============================] - 0s 644us/step - loss: 2.3025\n16/16 [==============================] - 0s 606us/step - loss: 2.2727\n16/16 [==============================] - 0s 1ms/step - loss: 2.2631\n16/16 [==============================] - 0s 810us/step - loss: 2.2593\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1540\n16/16 [==============================] - 0s 621us/step - loss: 2.0578\n16/16 [==============================] - 0s 754us/step - loss: 2.4644\n16/16 [==============================] - 0s 1ms/step - loss: 2.5294\n16/16 [==============================] - 0s 1ms/step - loss: 2.4946\n16/16 [==============================] - 0s 1ms/step - loss: 2.4481\n16/16 [==============================] - 0s 1ms/step - loss: 2.4079\n16/16 [==============================] - 0s 759us/step - loss: 2.3773\n16/16 [==============================] - 0s 1ms/step - loss: 2.3674\n16/16 [==============================] - 0s 634us/step - loss: 2.3635\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1569\n16/16 [==============================] - 0s 624us/step - loss: 2.0009\n16/16 [==============================] - 0s 644us/step - loss: 2.3983\n16/16 [==============================] - 0s 620us/step - loss: 2.4650\n16/16 [==============================] - 0s 1ms/step - loss: 2.4337\n16/16 [==============================] - 0s 657us/step - loss: 2.3895\n16/16 [==============================] - 0s 662us/step - loss: 2.3506\n16/16 [==============================] - 0s 1ms/step - loss: 2.3207\n16/16 [==============================] - 0s 826us/step - loss: 2.3109\n16/16 [==============================] - 0s 1ms/step - loss: 2.3070\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 648us/step - loss: 0.1564\n16/16 [==============================] - 0s 906us/step - loss: 1.9920\n16/16 [==============================] - 0s 1ms/step - loss: 2.3850\n16/16 [==============================] - 0s 632us/step - loss: 2.4473\n16/16 [==============================] - 0s 914us/step - loss: 2.4129\n16/16 [==============================] - 0s 650us/step - loss: 2.3665\n16/16 [==============================] - 0s 1ms/step - loss: 2.3262\n16/16 [==============================] - 0s 1ms/step - loss: 2.2963\n16/16 [==============================] - 0s 631us/step - loss: 2.2867\n16/16 [==============================] - 0s 1ms/step - loss: 2.2828\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1523\n16/16 [==============================] - 0s 610us/step - loss: 1.9810\n16/16 [==============================] - 0s 1ms/step - loss: 2.3695\n16/16 [==============================] - 0s 599us/step - loss: 2.4291\n16/16 [==============================] - 0s 1ms/step - loss: 2.3939\n16/16 [==============================] - 0s 596us/step - loss: 2.3485\n16/16 [==============================] - 0s 651us/step - loss: 2.3100\n16/16 [==============================] - 0s 1ms/step - loss: 2.2810\n16/16 [==============================] - 0s 1ms/step - loss: 2.2716\n16/16 [==============================] - 0s 789us/step - loss: 2.2678\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 605us/step - loss: 0.1539\n16/16 [==============================] - 0s 946us/step - loss: 2.0070\n16/16 [==============================] - 0s 1ms/step - loss: 2.3983\n16/16 [==============================] - 0s 562us/step - loss: 2.4547\n16/16 [==============================] - 0s 1ms/step - loss: 2.4185\n16/16 [==============================] - 0s 646us/step - loss: 2.3714\n16/16 [==============================] - 0s 1ms/step - loss: 2.3316\n16/16 [==============================] - 0s 1ms/step - loss: 2.3019\n16/16 [==============================] - 0s 1ms/step - loss: 2.2923\n16/16 [==============================] - 0s 629us/step - loss: 2.2885\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1531\n16/16 [==============================] - 0s 1ms/step - loss: 2.0956\n16/16 [==============================] - 0s 1ms/step - loss: 2.5234\n16/16 [==============================] - 0s 649us/step - loss: 2.5872\n16/16 [==============================] - 0s 1ms/step - loss: 2.5491\n16/16 [==============================] - 0s 1ms/step - loss: 2.4983\n16/16 [==============================] - 0s 1ms/step - loss: 2.4550\n16/16 [==============================] - 0s 1ms/step - loss: 2.4226\n16/16 [==============================] - 0s 1ms/step - loss: 2.4122\n16/16 [==============================] - 0s 1ms/step - loss: 2.4080\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 631us/step - loss: 0.1539\n16/16 [==============================] - 0s 877us/step - loss: 2.0259\n16/16 [==============================] - 0s 1ms/step - loss: 2.4331\n16/16 [==============================] - 0s 724us/step - loss: 2.4907\n16/16 [==============================] - 0s 631us/step - loss: 2.4546\n16/16 [==============================] - 0s 631us/step - loss: 2.4070\n16/16 [==============================] - 0s 1ms/step - loss: 2.3665\n16/16 [==============================] - 0s 1ms/step - loss: 2.3359\n16/16 [==============================] - 0s 995us/step - loss: 2.3261\n16/16 [==============================] - 0s 1ms/step - loss: 2.3222\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1519\n16/16 [==============================] - 0s 639us/step - loss: 2.0542\n16/16 [==============================] - 0s 934us/step - loss: 2.4779\n16/16 [==============================] - 0s 1ms/step - loss: 2.5430\n16/16 [==============================] - 0s 666us/step - loss: 2.5111\n16/16 [==============================] - 0s 645us/step - loss: 2.4667\n16/16 [==============================] - 0s 606us/step - loss: 2.4283\n16/16 [==============================] - 0s 842us/step - loss: 2.3987\n16/16 [==============================] - 0s 617us/step - loss: 2.3890\n16/16 [==============================] - 0s 1ms/step - loss: 2.3851\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1528\n16/16 [==============================] - 0s 957us/step - loss: 2.0201\n16/16 [==============================] - 0s 1ms/step - loss: 2.4226\n16/16 [==============================] - 0s 610us/step - loss: 2.4747\n16/16 [==============================] - 0s 626us/step - loss: 2.4384\n16/16 [==============================] - 0s 1ms/step - loss: 2.3899\n16/16 [==============================] - 0s 1ms/step - loss: 2.3487\n16/16 [==============================] - 0s 1ms/step - loss: 2.3181\n16/16 [==============================] - 0s 1ms/step - loss: 2.3083\n16/16 [==============================] - 0s 635us/step - loss: 2.3044\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1513\n16/16 [==============================] - 0s 1ms/step - loss: 2.0221\n16/16 [==============================] - 0s 953us/step - loss: 2.4286\n16/16 [==============================] - 0s 584us/step - loss: 2.4816\n16/16 [==============================] - 0s 794us/step - loss: 2.4463\n16/16 [==============================] - 0s 1ms/step - loss: 2.3995\n16/16 [==============================] - 0s 1ms/step - loss: 2.3596\n16/16 [==============================] - 0s 1ms/step - loss: 2.3298\n16/16 [==============================] - 0s 635us/step - loss: 2.3202\n16/16 [==============================] - 0s 1ms/step - loss: 2.3163\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1505\n16/16 [==============================] - 0s 1ms/step - loss: 2.0238\n16/16 [==============================] - 0s 1ms/step - loss: 2.4319\n16/16 [==============================] - 0s 1ms/step - loss: 2.4849\n16/16 [==============================] - 0s 628us/step - loss: 2.4502\n16/16 [==============================] - 0s 1ms/step - loss: 2.4034\n16/16 [==============================] - 0s 660us/step - loss: 2.3643\n16/16 [==============================] - 0s 614us/step - loss: 2.3350\n16/16 [==============================] - 0s 628us/step - loss: 2.3256\n16/16 [==============================] - 0s 1ms/step - loss: 2.3218\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 637us/step - loss: 0.1506\n16/16 [==============================] - 0s 929us/step - loss: 2.0292\n16/16 [==============================] - 0s 635us/step - loss: 2.4452\n16/16 [==============================] - 0s 625us/step - loss: 2.5006\n16/16 [==============================] - 0s 639us/step - loss: 2.4658\n16/16 [==============================] - 0s 1ms/step - loss: 2.4185\n16/16 [==============================] - 0s 640us/step - loss: 2.3780\n16/16 [==============================] - 0s 1ms/step - loss: 2.3475\n16/16 [==============================] - 0s 593us/step - loss: 2.3377\n16/16 [==============================] - 0s 947us/step - loss: 2.3338\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 642us/step - loss: 0.1520\n16/16 [==============================] - 0s 927us/step - loss: 2.0468\n16/16 [==============================] - 0s 907us/step - loss: 2.4645\n16/16 [==============================] - 0s 1ms/step - loss: 2.5202\n16/16 [==============================] - 0s 721us/step - loss: 2.4857\n16/16 [==============================] - 0s 1ms/step - loss: 2.4381\n16/16 [==============================] - 0s 1ms/step - loss: 2.3972\n16/16 [==============================] - 0s 1ms/step - loss: 2.3664\n16/16 [==============================] - 0s 755us/step - loss: 2.3565\n16/16 [==============================] - 0s 1ms/step - loss: 2.3525\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 836us/step - loss: 0.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.0895\n16/16 [==============================] - 0s 1ms/step - loss: 2.5139\n16/16 [==============================] - 0s 1ms/step - loss: 2.5640\n16/16 [==============================] - 0s 773us/step - loss: 2.5243\n16/16 [==============================] - 0s 754us/step - loss: 2.4719\n16/16 [==============================] - 0s 617us/step - loss: 2.4279\n16/16 [==============================] - 0s 1ms/step - loss: 2.3952\n16/16 [==============================] - 0s 935us/step - loss: 2.3847\n16/16 [==============================] - 0s 1ms/step - loss: 2.3804\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 635us/step - loss: 0.1465\n16/16 [==============================] - 0s 640us/step - loss: 2.0292\n16/16 [==============================] - 0s 610us/step - loss: 2.4415\n16/16 [==============================] - 0s 635us/step - loss: 2.4915\n16/16 [==============================] - 0s 634us/step - loss: 2.4547\n16/16 [==============================] - 0s 621us/step - loss: 2.4048\n16/16 [==============================] - 0s 644us/step - loss: 2.3627\n16/16 [==============================] - 0s 750us/step - loss: 2.3313\n16/16 [==============================] - 0s 1ms/step - loss: 2.3213\n16/16 [==============================] - 0s 705us/step - loss: 2.3173\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 624us/step - loss: 0.1449\n16/16 [==============================] - 0s 1ms/step - loss: 2.0603\n16/16 [==============================] - 0s 1ms/step - loss: 2.4760\n16/16 [==============================] - 0s 1ms/step - loss: 2.5243\n16/16 [==============================] - 0s 1ms/step - loss: 2.4877\n16/16 [==============================] - 0s 1ms/step - loss: 2.4388\n16/16 [==============================] - 0s 1ms/step - loss: 2.3979\n16/16 [==============================] - 0s 615us/step - loss: 2.3674\n16/16 [==============================] - 0s 1ms/step - loss: 2.3576\n16/16 [==============================] - 0s 1ms/step - loss: 2.3537\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1456\n16/16 [==============================] - 0s 1ms/step - loss: 2.1177\n16/16 [==============================] - 0s 1ms/step - loss: 2.5539\n16/16 [==============================] - 0s 1ms/step - loss: 2.6038\n16/16 [==============================] - 0s 641us/step - loss: 2.5627\n16/16 [==============================] - 0s 1ms/step - loss: 2.5085\n16/16 [==============================] - 0s 1ms/step - loss: 2.4635\n16/16 [==============================] - 0s 1ms/step - loss: 2.4301\n16/16 [==============================] - 0s 1ms/step - loss: 2.4196\n16/16 [==============================] - 0s 1ms/step - loss: 2.4155\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 633us/step - loss: 0.1446\n16/16 [==============================] - 0s 650us/step - loss: 2.0868\n16/16 [==============================] - 0s 634us/step - loss: 2.5135\n16/16 [==============================] - 0s 605us/step - loss: 2.5636\n16/16 [==============================] - 0s 1ms/step - loss: 2.5272\n16/16 [==============================] - 0s 640us/step - loss: 2.4769\n16/16 [==============================] - 0s 1ms/step - loss: 2.4353\n16/16 [==============================] - 0s 608us/step - loss: 2.4045\n16/16 [==============================] - 0s 1ms/step - loss: 2.3946\n16/16 [==============================] - 0s 1ms/step - loss: 2.3907\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 649us/step - loss: 0.1457\n16/16 [==============================] - 0s 624us/step - loss: 2.0862\n16/16 [==============================] - 0s 875us/step - loss: 2.5107\n16/16 [==============================] - 0s 590us/step - loss: 2.5578\n16/16 [==============================] - 0s 573us/step - loss: 2.5165\n16/16 [==============================] - 0s 1ms/step - loss: 2.4632\n16/16 [==============================] - 0s 1ms/step - loss: 2.4191\n16/16 [==============================] - 0s 1ms/step - loss: 2.3864\n16/16 [==============================] - 0s 1ms/step - loss: 2.3760\n16/16 [==============================] - 0s 611us/step - loss: 2.3718\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 664us/step - loss: 0.1438\n16/16 [==============================] - 0s 610us/step - loss: 2.0347\n16/16 [==============================] - 0s 601us/step - loss: 2.4431\n16/16 [==============================] - 0s 1ms/step - loss: 2.4871\n16/16 [==============================] - 0s 636us/step - loss: 2.4479\n16/16 [==============================] - 0s 606us/step - loss: 2.3982\n16/16 [==============================] - 0s 618us/step - loss: 2.3571\n16/16 [==============================] - 0s 639us/step - loss: 2.3267\n16/16 [==============================] - 0s 657us/step - loss: 2.3170\n16/16 [==============================] - 0s 629us/step - loss: 2.3131\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 641us/step - loss: 0.1474\n16/16 [==============================] - 0s 988us/step - loss: 2.0366\n16/16 [==============================] - 0s 1ms/step - loss: 2.4480\n16/16 [==============================] - 0s 903us/step - loss: 2.4936\n16/16 [==============================] - 0s 1ms/step - loss: 2.4559\n16/16 [==============================] - 0s 1ms/step - loss: 2.4066\n16/16 [==============================] - 0s 635us/step - loss: 2.3658\n16/16 [==============================] - 0s 1ms/step - loss: 2.3355\n16/16 [==============================] - 0s 797us/step - loss: 2.3259\n16/16 [==============================] - 0s 735us/step - loss: 2.3222\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 696us/step - loss: 0.1436\n16/16 [==============================] - 0s 905us/step - loss: 2.1021\n16/16 [==============================] - 0s 841us/step - loss: 2.5288\n16/16 [==============================] - 0s 1ms/step - loss: 2.5741\n16/16 [==============================] - 0s 623us/step - loss: 2.5332\n16/16 [==============================] - 0s 637us/step - loss: 2.4820\n16/16 [==============================] - 0s 644us/step - loss: 2.4395\n16/16 [==============================] - 0s 949us/step - loss: 2.4076\n16/16 [==============================] - 0s 640us/step - loss: 2.3974\n16/16 [==============================] - 0s 1ms/step - loss: 2.3933\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 745us/step - loss: 0.1413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0536\n16/16 [==============================] - 0s 1ms/step - loss: 2.4615\n16/16 [==============================] - 0s 1ms/step - loss: 2.4976\n16/16 [==============================] - 0s 1ms/step - loss: 2.4550\n16/16 [==============================] - 0s 1ms/step - loss: 2.4020\n16/16 [==============================] - 0s 1ms/step - loss: 2.3590\n16/16 [==============================] - 0s 1ms/step - loss: 2.3276\n16/16 [==============================] - 0s 1ms/step - loss: 2.3176\n16/16 [==============================] - 0s 1ms/step - loss: 2.3137\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 624us/step - loss: 0.1436\n16/16 [==============================] - 0s 1ms/step - loss: 2.0689\n16/16 [==============================] - 0s 1ms/step - loss: 2.4842\n16/16 [==============================] - 0s 1ms/step - loss: 2.5212\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 613us/step - loss: 2.4299\n16/16 [==============================] - 0s 614us/step - loss: 2.3885\n16/16 [==============================] - 0s 622us/step - loss: 2.3575\n16/16 [==============================] - 0s 1ms/step - loss: 2.3477\n16/16 [==============================] - 0s 1ms/step - loss: 2.3438\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 636us/step - loss: 0.1412\n16/16 [==============================] - 0s 622us/step - loss: 2.0655\n16/16 [==============================] - 0s 584us/step - loss: 2.4782\n16/16 [==============================] - 0s 999us/step - loss: 2.5137\n16/16 [==============================] - 0s 648us/step - loss: 2.4722\n16/16 [==============================] - 0s 843us/step - loss: 2.4209\n16/16 [==============================] - 0s 889us/step - loss: 2.3791\n16/16 [==============================] - 0s 1ms/step - loss: 2.3482\n16/16 [==============================] - 0s 1ms/step - loss: 2.3383\n16/16 [==============================] - 0s 1ms/step - loss: 2.3344\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1411\n16/16 [==============================] - 0s 608us/step - loss: 2.0600\n16/16 [==============================] - 0s 591us/step - loss: 2.4682\n16/16 [==============================] - 0s 1ms/step - loss: 2.5009\n16/16 [==============================] - 0s 885us/step - loss: 2.4578\n16/16 [==============================] - 0s 1ms/step - loss: 2.4045\n16/16 [==============================] - 0s 918us/step - loss: 2.3612\n16/16 [==============================] - 0s 1ms/step - loss: 2.3293\n16/16 [==============================] - 0s 1ms/step - loss: 2.3193\n16/16 [==============================] - 0s 648us/step - loss: 2.3153\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 658us/step - loss: 0.1459\n16/16 [==============================] - 0s 1ms/step - loss: 2.0524\n16/16 [==============================] - 0s 593us/step - loss: 2.4624\n16/16 [==============================] - 0s 1ms/step - loss: 2.4994\n16/16 [==============================] - 0s 1ms/step - loss: 2.4614\n16/16 [==============================] - 0s 647us/step - loss: 2.4144\n16/16 [==============================] - 0s 956us/step - loss: 2.3751\n16/16 [==============================] - 0s 619us/step - loss: 2.3456\n16/16 [==============================] - 0s 1ms/step - loss: 2.3363\n16/16 [==============================] - 0s 1ms/step - loss: 2.3326\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1414\n16/16 [==============================] - 0s 691us/step - loss: 2.1374\n16/16 [==============================] - 0s 586us/step - loss: 2.5654\n16/16 [==============================] - 0s 1ms/step - loss: 2.5987\n16/16 [==============================] - 0s 601us/step - loss: 2.5514\n16/16 [==============================] - 0s 615us/step - loss: 2.4948\n16/16 [==============================] - 0s 952us/step - loss: 2.4484\n16/16 [==============================] - 0s 996us/step - loss: 2.4143\n16/16 [==============================] - 0s 1ms/step - loss: 2.4035\n16/16 [==============================] - 0s 1ms/step - loss: 2.3993\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1408\n16/16 [==============================] - 0s 1ms/step - loss: 2.1433\n16/16 [==============================] - 0s 1ms/step - loss: 2.5741\n16/16 [==============================] - 0s 1ms/step - loss: 2.6115\n16/16 [==============================] - 0s 684us/step - loss: 2.5677\n16/16 [==============================] - 0s 566us/step - loss: 2.5132\n16/16 [==============================] - 0s 617us/step - loss: 2.4685\n16/16 [==============================] - 0s 1ms/step - loss: 2.4356\n16/16 [==============================] - 0s 1ms/step - loss: 2.4250\n16/16 [==============================] - 0s 977us/step - loss: 2.4208\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1386\n16/16 [==============================] - 0s 626us/step - loss: 2.2159\n16/16 [==============================] - 0s 607us/step - loss: 2.6627\n16/16 [==============================] - 0s 1ms/step - loss: 2.7016\n16/16 [==============================] - 0s 616us/step - loss: 2.6579\n16/16 [==============================] - 0s 624us/step - loss: 2.6043\n16/16 [==============================] - 0s 593us/step - loss: 2.5597\n16/16 [==============================] - 0s 1ms/step - loss: 2.5264\n16/16 [==============================] - 0s 596us/step - loss: 2.5158\n16/16 [==============================] - 0s 1ms/step - loss: 2.5116\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 988us/step - loss: 0.1406\n16/16 [==============================] - 0s 819us/step - loss: 2.1877\n16/16 [==============================] - 0s 1ms/step - loss: 2.6298\n16/16 [==============================] - 0s 1ms/step - loss: 2.6666\n16/16 [==============================] - 0s 1ms/step - loss: 2.6212\n16/16 [==============================] - 0s 611us/step - loss: 2.5652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5194\n16/16 [==============================] - 0s 1ms/step - loss: 2.4854\n16/16 [==============================] - 0s 787us/step - loss: 2.4747\n16/16 [==============================] - 0s 1ms/step - loss: 2.4704\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1391\n16/16 [==============================] - 0s 1ms/step - loss: 2.1726\n16/16 [==============================] - 0s 1ms/step - loss: 2.6126\n16/16 [==============================] - 0s 1ms/step - loss: 2.6499\n16/16 [==============================] - 0s 622us/step - loss: 2.6046\n16/16 [==============================] - 0s 1ms/step - loss: 2.5491\n16/16 [==============================] - 0s 602us/step - loss: 2.5038\n16/16 [==============================] - 0s 1ms/step - loss: 2.4703\n16/16 [==============================] - 0s 1ms/step - loss: 2.4596\n16/16 [==============================] - 0s 625us/step - loss: 2.4553\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 722us/step - loss: 0.1402\n16/16 [==============================] - 0s 1ms/step - loss: 2.1077\n16/16 [==============================] - 0s 1ms/step - loss: 2.5214\n16/16 [==============================] - 0s 1ms/step - loss: 2.5507\n16/16 [==============================] - 0s 1ms/step - loss: 2.5038\n16/16 [==============================] - 0s 638us/step - loss: 2.4486\n16/16 [==============================] - 0s 1ms/step - loss: 2.4039\n16/16 [==============================] - 0s 1ms/step - loss: 2.3711\n16/16 [==============================] - 0s 1ms/step - loss: 2.3608\n16/16 [==============================] - 0s 806us/step - loss: 2.3567\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1413\n16/16 [==============================] - 0s 1ms/step - loss: 2.0789\n16/16 [==============================] - 0s 635us/step - loss: 2.4879\n16/16 [==============================] - 0s 827us/step - loss: 2.5226\n16/16 [==============================] - 0s 1ms/step - loss: 2.4818\n16/16 [==============================] - 0s 1ms/step - loss: 2.4316\n16/16 [==============================] - 0s 1ms/step - loss: 2.3905\n16/16 [==============================] - 0s 1ms/step - loss: 2.3598\n16/16 [==============================] - 0s 702us/step - loss: 2.3501\n16/16 [==============================] - 0s 672us/step - loss: 2.3462\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 645us/step - loss: 0.1397\n16/16 [==============================] - 0s 615us/step - loss: 2.2173\n16/16 [==============================] - 0s 828us/step - loss: 2.6506\n16/16 [==============================] - 0s 1ms/step - loss: 2.6828\n16/16 [==============================] - 0s 1ms/step - loss: 2.6351\n16/16 [==============================] - 0s 1ms/step - loss: 2.5777\n16/16 [==============================] - 0s 603us/step - loss: 2.5312\n16/16 [==============================] - 0s 586us/step - loss: 2.4972\n16/16 [==============================] - 0s 874us/step - loss: 2.4864\n16/16 [==============================] - 0s 806us/step - loss: 2.4822\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1400\n16/16 [==============================] - 0s 1ms/step - loss: 2.1024\n16/16 [==============================] - 0s 1ms/step - loss: 2.5108\n16/16 [==============================] - 0s 1ms/step - loss: 2.5405\n16/16 [==============================] - 0s 656us/step - loss: 2.4959\n16/16 [==============================] - 0s 1ms/step - loss: 2.4414\n16/16 [==============================] - 0s 1ms/step - loss: 2.3972\n16/16 [==============================] - 0s 928us/step - loss: 2.3648\n16/16 [==============================] - 0s 1ms/step - loss: 2.3547\n16/16 [==============================] - 0s 1ms/step - loss: 2.3508\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 638us/step - loss: 0.1365\n16/16 [==============================] - 0s 618us/step - loss: 2.0904\n16/16 [==============================] - 0s 1ms/step - loss: 2.4896\n16/16 [==============================] - 0s 894us/step - loss: 2.5170\n16/16 [==============================] - 0s 1ms/step - loss: 2.4731\n16/16 [==============================] - 0s 995us/step - loss: 2.4215\n16/16 [==============================] - 0s 1ms/step - loss: 2.3790\n16/16 [==============================] - 0s 625us/step - loss: 2.3476\n16/16 [==============================] - 0s 634us/step - loss: 2.3377\n16/16 [==============================] - 0s 645us/step - loss: 2.3337\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1351\n16/16 [==============================] - 0s 1ms/step - loss: 2.1565\n16/16 [==============================] - 0s 618us/step - loss: 2.5687\n16/16 [==============================] - 0s 762us/step - loss: 2.5966\n16/16 [==============================] - 0s 1ms/step - loss: 2.5494\n16/16 [==============================] - 0s 1ms/step - loss: 2.4930\n16/16 [==============================] - 0s 648us/step - loss: 2.4471\n16/16 [==============================] - 0s 608us/step - loss: 2.4134\n16/16 [==============================] - 0s 959us/step - loss: 2.4028\n16/16 [==============================] - 0s 1ms/step - loss: 2.3986\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 809us/step - loss: 0.1389\n16/16 [==============================] - 0s 1ms/step - loss: 2.1419\n16/16 [==============================] - 0s 1ms/step - loss: 2.5512\n16/16 [==============================] - 0s 677us/step - loss: 2.5797\n16/16 [==============================] - 0s 668us/step - loss: 2.5344\n16/16 [==============================] - 0s 671us/step - loss: 2.4806\n16/16 [==============================] - 0s 657us/step - loss: 2.4371\n16/16 [==============================] - 0s 1ms/step - loss: 2.4050\n16/16 [==============================] - 0s 652us/step - loss: 2.3948\n16/16 [==============================] - 0s 1ms/step - loss: 2.3908\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1349\n16/16 [==============================] - 0s 1ms/step - loss: 2.1901\n16/16 [==============================] - 0s 716us/step - loss: 2.6044\n16/16 [==============================] - 0s 1ms/step - loss: 2.6295\n16/16 [==============================] - 0s 1ms/step - loss: 2.5800\n16/16 [==============================] - 0s 632us/step - loss: 2.5219\n16/16 [==============================] - 0s 1ms/step - loss: 2.4752\n16/16 [==============================] - 0s 1ms/step - loss: 2.4411\n16/16 [==============================] - 0s 1ms/step - loss: 2.4303\n16/16 [==============================] - 0s 608us/step - loss: 2.4260\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 626us/step - loss: 0.1361\n16/16 [==============================] - 0s 1ms/step - loss: 2.1862\n16/16 [==============================] - 0s 634us/step - loss: 2.6026\n16/16 [==============================] - 0s 1ms/step - loss: 2.6289\n16/16 [==============================] - 0s 602us/step - loss: 2.5794\n16/16 [==============================] - 0s 608us/step - loss: 2.5210\n16/16 [==============================] - 0s 945us/step - loss: 2.4747\n16/16 [==============================] - 0s 1ms/step - loss: 2.4412\n16/16 [==============================] - 0s 1ms/step - loss: 2.4307\n16/16 [==============================] - 0s 1ms/step - loss: 2.4265\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 591us/step - loss: 0.1354\n16/16 [==============================] - 0s 716us/step - loss: 2.1140\n16/16 [==============================] - 0s 645us/step - loss: 2.5078\n16/16 [==============================] - 0s 1ms/step - loss: 2.5307\n16/16 [==============================] - 0s 576us/step - loss: 2.4835\n16/16 [==============================] - 0s 1ms/step - loss: 2.4278\n16/16 [==============================] - 0s 1ms/step - loss: 2.3835\n16/16 [==============================] - 0s 721us/step - loss: 2.3512\n16/16 [==============================] - 0s 683us/step - loss: 2.3411\n16/16 [==============================] - 0s 973us/step - loss: 2.3371\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 746us/step - loss: 0.1375\n16/16 [==============================] - 0s 1ms/step - loss: 2.1227\n16/16 [==============================] - 0s 1ms/step - loss: 2.5193\n16/16 [==============================] - 0s 1ms/step - loss: 2.5434\n16/16 [==============================] - 0s 1ms/step - loss: 2.4969\n16/16 [==============================] - 0s 928us/step - loss: 2.4432\n16/16 [==============================] - 0s 851us/step - loss: 2.4006\n16/16 [==============================] - 0s 661us/step - loss: 2.3696\n16/16 [==============================] - 0s 980us/step - loss: 2.3598\n16/16 [==============================] - 0s 1ms/step - loss: 2.3560\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 939us/step - loss: 0.1385\n16/16 [==============================] - 0s 1ms/step - loss: 2.1281\n16/16 [==============================] - 0s 629us/step - loss: 2.5285\n16/16 [==============================] - 0s 1ms/step - loss: 2.5562\n16/16 [==============================] - 0s 598us/step - loss: 2.5119\n16/16 [==============================] - 0s 633us/step - loss: 2.4583\n16/16 [==============================] - 0s 638us/step - loss: 2.4151\n16/16 [==============================] - 0s 639us/step - loss: 2.3836\n16/16 [==============================] - 0s 900us/step - loss: 2.3737\n16/16 [==============================] - 0s 1ms/step - loss: 2.3698\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 650us/step - loss: 0.1350\n16/16 [==============================] - 0s 636us/step - loss: 2.1239\n16/16 [==============================] - 0s 1ms/step - loss: 2.5171\n16/16 [==============================] - 0s 853us/step - loss: 2.5400\n16/16 [==============================] - 0s 596us/step - loss: 2.4914\n16/16 [==============================] - 0s 619us/step - loss: 2.4353\n16/16 [==============================] - 0s 1ms/step - loss: 2.3913\n16/16 [==============================] - 0s 1ms/step - loss: 2.3594\n16/16 [==============================] - 0s 1ms/step - loss: 2.3494\n16/16 [==============================] - 0s 665us/step - loss: 2.3455\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1328\n16/16 [==============================] - 0s 1ms/step - loss: 2.1880\n16/16 [==============================] - 0s 1ms/step - loss: 2.5967\n16/16 [==============================] - 0s 619us/step - loss: 2.6189\n16/16 [==============================] - 0s 603us/step - loss: 2.5676\n16/16 [==============================] - 0s 1ms/step - loss: 2.5074\n16/16 [==============================] - 0s 1ms/step - loss: 2.4597\n16/16 [==============================] - 0s 1ms/step - loss: 2.4251\n16/16 [==============================] - 0s 1ms/step - loss: 2.4143\n16/16 [==============================] - 0s 1ms/step - loss: 2.4100\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1320\n16/16 [==============================] - 0s 624us/step - loss: 2.2799\n16/16 [==============================] - 0s 824us/step - loss: 2.7184\n16/16 [==============================] - 0s 644us/step - loss: 2.7484\n16/16 [==============================] - 0s 655us/step - loss: 2.6979\n16/16 [==============================] - 0s 690us/step - loss: 2.6378\n16/16 [==============================] - 0s 1ms/step - loss: 2.5895\n16/16 [==============================] - 0s 637us/step - loss: 2.5547\n16/16 [==============================] - 0s 806us/step - loss: 2.5438\n16/16 [==============================] - 0s 757us/step - loss: 2.5395\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1319\n16/16 [==============================] - 0s 1ms/step - loss: 2.2685\n16/16 [==============================] - 0s 1ms/step - loss: 2.6951\n16/16 [==============================] - 0s 1ms/step - loss: 2.7210\n16/16 [==============================] - 0s 1ms/step - loss: 2.6693\n16/16 [==============================] - 0s 905us/step - loss: 2.6086\n16/16 [==============================] - 0s 985us/step - loss: 2.5598\n16/16 [==============================] - 0s 897us/step - loss: 2.5247\n16/16 [==============================] - 0s 1ms/step - loss: 2.5138\n16/16 [==============================] - 0s 726us/step - loss: 2.5094\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1306\n16/16 [==============================] - 0s 628us/step - loss: 2.1294\n16/16 [==============================] - 0s 571us/step - loss: 2.5162\n16/16 [==============================] - 0s 651us/step - loss: 2.5364\n16/16 [==============================] - 0s 657us/step - loss: 2.4872\n16/16 [==============================] - 0s 620us/step - loss: 2.4317\n16/16 [==============================] - 0s 627us/step - loss: 2.3874\n16/16 [==============================] - 0s 631us/step - loss: 2.3554\n16/16 [==============================] - 0s 911us/step - loss: 2.3455\n16/16 [==============================] - 0s 1ms/step - loss: 2.3416\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1298\n16/16 [==============================] - 0s 633us/step - loss: 2.2952\n16/16 [==============================] - 0s 1ms/step - loss: 2.7216\n16/16 [==============================] - 0s 1ms/step - loss: 2.7446\n16/16 [==============================] - 0s 1ms/step - loss: 2.6897\n16/16 [==============================] - 0s 611us/step - loss: 2.6254\n16/16 [==============================] - 0s 1ms/step - loss: 2.5745\n16/16 [==============================] - 0s 1ms/step - loss: 2.5375\n16/16 [==============================] - 0s 1ms/step - loss: 2.5260\n16/16 [==============================] - 0s 935us/step - loss: 2.5215\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 604us/step - loss: 0.1304\n16/16 [==============================] - 0s 1ms/step - loss: 2.1990\n16/16 [==============================] - 0s 598us/step - loss: 2.6016\n16/16 [==============================] - 0s 1ms/step - loss: 2.6241\n16/16 [==============================] - 0s 1ms/step - loss: 2.5736\n16/16 [==============================] - 0s 753us/step - loss: 2.5147\n16/16 [==============================] - 0s 1ms/step - loss: 2.4677\n16/16 [==============================] - 0s 626us/step - loss: 2.4338\n16/16 [==============================] - 0s 718us/step - loss: 2.4233\n16/16 [==============================] - 0s 852us/step - loss: 2.4191\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1279\n16/16 [==============================] - 0s 629us/step - loss: 2.1722\n16/16 [==============================] - 0s 1ms/step - loss: 2.5696\n16/16 [==============================] - 0s 1ms/step - loss: 2.5888\n16/16 [==============================] - 0s 687us/step - loss: 2.5353\n16/16 [==============================] - 0s 644us/step - loss: 2.4735\n16/16 [==============================] - 0s 1ms/step - loss: 2.4255\n16/16 [==============================] - 0s 1ms/step - loss: 2.3910\n16/16 [==============================] - 0s 1ms/step - loss: 2.3803\n16/16 [==============================] - 0s 1ms/step - loss: 2.3761\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 725us/step - loss: 0.1313\n16/16 [==============================] - 0s 1ms/step - loss: 2.1862\n16/16 [==============================] - 0s 644us/step - loss: 2.5858\n16/16 [==============================] - 0s 1ms/step - loss: 2.6081\n16/16 [==============================] - 0s 1ms/step - loss: 2.5577\n16/16 [==============================] - 0s 1ms/step - loss: 2.4986\n16/16 [==============================] - 0s 1ms/step - loss: 2.4523\n16/16 [==============================] - 0s 1ms/step - loss: 2.4191\n16/16 [==============================] - 0s 708us/step - loss: 2.4087\n16/16 [==============================] - 0s 632us/step - loss: 2.4046\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 620us/step - loss: 0.1281\n16/16 [==============================] - 0s 632us/step - loss: 2.2017\n16/16 [==============================] - 0s 607us/step - loss: 2.5988\n16/16 [==============================] - 0s 573us/step - loss: 2.6178\n16/16 [==============================] - 0s 653us/step - loss: 2.5652\n16/16 [==============================] - 0s 1ms/step - loss: 2.5044\n16/16 [==============================] - 0s 808us/step - loss: 2.4563\n16/16 [==============================] - 0s 648us/step - loss: 2.4216\n16/16 [==============================] - 0s 724us/step - loss: 2.4108\n16/16 [==============================] - 0s 727us/step - loss: 2.4066\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1283\n16/16 [==============================] - 0s 643us/step - loss: 2.2432\n16/16 [==============================] - 0s 1ms/step - loss: 2.6497\n16/16 [==============================] - 0s 612us/step - loss: 2.6688\n16/16 [==============================] - 0s 1ms/step - loss: 2.6142\n16/16 [==============================] - 0s 837us/step - loss: 2.5514\n16/16 [==============================] - 0s 836us/step - loss: 2.5023\n16/16 [==============================] - 0s 1ms/step - loss: 2.4675\n16/16 [==============================] - 0s 641us/step - loss: 2.4567\n16/16 [==============================] - 0s 1ms/step - loss: 2.4524\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 876us/step - loss: 0.1307\n16/16 [==============================] - 0s 1ms/step - loss: 2.2389\n16/16 [==============================] - 0s 1ms/step - loss: 2.6476\n16/16 [==============================] - 0s 1ms/step - loss: 2.6694\n16/16 [==============================] - 0s 646us/step - loss: 2.6174\n16/16 [==============================] - 0s 651us/step - loss: 2.5567\n16/16 [==============================] - 0s 630us/step - loss: 2.5086\n16/16 [==============================] - 0s 645us/step - loss: 2.4744\n16/16 [==============================] - 0s 1ms/step - loss: 2.4637\n16/16 [==============================] - 0s 634us/step - loss: 2.4595\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1294\n16/16 [==============================] - 0s 1ms/step - loss: 2.2039\n16/16 [==============================] - 0s 1ms/step - loss: 2.6016\n16/16 [==============================] - 0s 1ms/step - loss: 2.6199\n16/16 [==============================] - 0s 618us/step - loss: 2.5666\n16/16 [==============================] - 0s 1ms/step - loss: 2.5066\n16/16 [==============================] - 0s 1ms/step - loss: 2.4594\n16/16 [==============================] - 0s 1ms/step - loss: 2.4255\n16/16 [==============================] - 0s 967us/step - loss: 2.4150\n16/16 [==============================] - 0s 594us/step - loss: 2.4109\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 638us/step - loss: 0.1284\n16/16 [==============================] - 0s 633us/step - loss: 2.2483\n16/16 [==============================] - 0s 996us/step - loss: 2.6576\n16/16 [==============================] - 0s 1ms/step - loss: 2.6801\n16/16 [==============================] - 0s 610us/step - loss: 2.6274\n16/16 [==============================] - 0s 1ms/step - loss: 2.5661\n16/16 [==============================] - 0s 1ms/step - loss: 2.5171\n16/16 [==============================] - 0s 905us/step - loss: 2.4817\n16/16 [==============================] - 0s 1ms/step - loss: 2.4707\n16/16 [==============================] - 0s 1ms/step - loss: 2.4664\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 629us/step - loss: 0.1308\n16/16 [==============================] - 0s 1ms/step - loss: 2.2241\n16/16 [==============================] - 0s 776us/step - loss: 2.6243\n16/16 [==============================] - 0s 1ms/step - loss: 2.6430\n16/16 [==============================] - 0s 1ms/step - loss: 2.5906\n16/16 [==============================] - 0s 647us/step - loss: 2.5309\n16/16 [==============================] - 0s 632us/step - loss: 2.4834\n16/16 [==============================] - 0s 617us/step - loss: 2.4493\n16/16 [==============================] - 0s 622us/step - loss: 2.4387\n16/16 [==============================] - 0s 619us/step - loss: 2.4346\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1249\n16/16 [==============================] - 0s 1ms/step - loss: 2.2824\n16/16 [==============================] - 0s 886us/step - loss: 2.6944\n16/16 [==============================] - 0s 1ms/step - loss: 2.7119\n16/16 [==============================] - 0s 840us/step - loss: 2.6561\n16/16 [==============================] - 0s 1ms/step - loss: 2.5941\n16/16 [==============================] - 0s 749us/step - loss: 2.5456\n16/16 [==============================] - 0s 633us/step - loss: 2.5112\n16/16 [==============================] - 0s 631us/step - loss: 2.5004\n16/16 [==============================] - 0s 598us/step - loss: 2.4962\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1268\n16/16 [==============================] - 0s 641us/step - loss: 2.2303\n16/16 [==============================] - 0s 987us/step - loss: 2.6315\n16/16 [==============================] - 0s 755us/step - loss: 2.6520\n16/16 [==============================] - 0s 1ms/step - loss: 2.6023\n16/16 [==============================] - 0s 1ms/step - loss: 2.5447\n16/16 [==============================] - 0s 1ms/step - loss: 2.4980\n16/16 [==============================] - 0s 1ms/step - loss: 2.4644\n16/16 [==============================] - 0s 1ms/step - loss: 2.4540\n16/16 [==============================] - 0s 1ms/step - loss: 2.4499\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1253\n16/16 [==============================] - 0s 1ms/step - loss: 2.2804\n16/16 [==============================] - 0s 1ms/step - loss: 2.6909\n16/16 [==============================] - 0s 1ms/step - loss: 2.7047\n16/16 [==============================] - 0s 1ms/step - loss: 2.6461\n16/16 [==============================] - 0s 890us/step - loss: 2.5810\n16/16 [==============================] - 0s 1ms/step - loss: 2.5304\n16/16 [==============================] - 0s 1ms/step - loss: 2.4944\n16/16 [==============================] - 0s 1ms/step - loss: 2.4833\n16/16 [==============================] - 0s 1ms/step - loss: 2.4788\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 749us/step - loss: 0.1268\n16/16 [==============================] - 0s 1ms/step - loss: 2.2590\n16/16 [==============================] - 0s 613us/step - loss: 2.6587\n16/16 [==============================] - 0s 617us/step - loss: 2.6734\n16/16 [==============================] - 0s 1ms/step - loss: 2.6186\n16/16 [==============================] - 0s 1ms/step - loss: 2.5570\n16/16 [==============================] - 0s 950us/step - loss: 2.5081\n16/16 [==============================] - 0s 1ms/step - loss: 2.4730\n16/16 [==============================] - 0s 661us/step - loss: 2.4621\n16/16 [==============================] - 0s 623us/step - loss: 2.4579\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1254\n16/16 [==============================] - 0s 854us/step - loss: 2.2600\n16/16 [==============================] - 0s 1ms/step - loss: 2.6602\n16/16 [==============================] - 0s 655us/step - loss: 2.6753\n16/16 [==============================] - 0s 1ms/step - loss: 2.6206\n16/16 [==============================] - 0s 1ms/step - loss: 2.5580\n16/16 [==============================] - 0s 706us/step - loss: 2.5089\n16/16 [==============================] - 0s 1ms/step - loss: 2.4739\n16/16 [==============================] - 0s 1ms/step - loss: 2.4630\n16/16 [==============================] - 0s 1ms/step - loss: 2.4588\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 681us/step - loss: 0.1267\n16/16 [==============================] - 0s 775us/step - loss: 2.2358\n16/16 [==============================] - 0s 608us/step - loss: 2.6324\n16/16 [==============================] - 0s 628us/step - loss: 2.6479\n16/16 [==============================] - 0s 610us/step - loss: 2.5940\n16/16 [==============================] - 0s 608us/step - loss: 2.5341\n16/16 [==============================] - 0s 637us/step - loss: 2.4871\n16/16 [==============================] - 0s 611us/step - loss: 2.4534\n16/16 [==============================] - 0s 641us/step - loss: 2.4430\n16/16 [==============================] - 0s 763us/step - loss: 2.4389\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1232\n16/16 [==============================] - 0s 1ms/step - loss: 2.3007\n16/16 [==============================] - 0s 1ms/step - loss: 2.7090\n16/16 [==============================] - 0s 631us/step - loss: 2.7214\n16/16 [==============================] - 0s 973us/step - loss: 2.6639\n16/16 [==============================] - 0s 667us/step - loss: 2.5993\n16/16 [==============================] - 0s 1ms/step - loss: 2.5482\n16/16 [==============================] - 0s 1ms/step - loss: 2.5115\n16/16 [==============================] - 0s 1ms/step - loss: 2.5002\n16/16 [==============================] - 0s 1ms/step - loss: 2.4957\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1249\n16/16 [==============================] - 0s 703us/step - loss: 2.2634\n16/16 [==============================] - 0s 1ms/step - loss: 2.6562\n16/16 [==============================] - 0s 1ms/step - loss: 2.6629\n16/16 [==============================] - 0s 1ms/step - loss: 2.6041\n16/16 [==============================] - 0s 872us/step - loss: 2.5390\n16/16 [==============================] - 0s 617us/step - loss: 2.4883\n16/16 [==============================] - 0s 687us/step - loss: 2.4527\n16/16 [==============================] - 0s 615us/step - loss: 2.4419\n16/16 [==============================] - 0s 783us/step - loss: 2.4376\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 700us/step - loss: 0.1249\n16/16 [==============================] - 0s 601us/step - loss: 2.2865\n16/16 [==============================] - 0s 625us/step - loss: 2.6880\n16/16 [==============================] - 0s 581us/step - loss: 2.7004\n16/16 [==============================] - 0s 1ms/step - loss: 2.6446\n16/16 [==============================] - 0s 714us/step - loss: 2.5815\n16/16 [==============================] - 0s 1ms/step - loss: 2.5315\n16/16 [==============================] - 0s 1ms/step - loss: 2.4957\n16/16 [==============================] - 0s 740us/step - loss: 2.4847\n16/16 [==============================] - 0s 1ms/step - loss: 2.4803\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 584us/step - loss: 0.1245\n16/16 [==============================] - 0s 787us/step - loss: 2.2729\n16/16 [==============================] - 0s 1ms/step - loss: 2.6637\n16/16 [==============================] - 0s 1ms/step - loss: 2.6712\n16/16 [==============================] - 0s 608us/step - loss: 2.6147\n16/16 [==============================] - 0s 654us/step - loss: 2.5526\n16/16 [==============================] - 0s 1ms/step - loss: 2.5033\n16/16 [==============================] - 0s 891us/step - loss: 2.4684\n16/16 [==============================] - 0s 697us/step - loss: 2.4576\n16/16 [==============================] - 0s 639us/step - loss: 2.4534\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 637us/step - loss: 0.1250\n16/16 [==============================] - 0s 941us/step - loss: 2.2686\n16/16 [==============================] - 0s 599us/step - loss: 2.6612\n16/16 [==============================] - 0s 1ms/step - loss: 2.6698\n16/16 [==============================] - 0s 778us/step - loss: 2.6129\n16/16 [==============================] - 0s 691us/step - loss: 2.5509\n16/16 [==============================] - 0s 1ms/step - loss: 2.5026\n16/16 [==============================] - 0s 623us/step - loss: 2.4683\n16/16 [==============================] - 0s 885us/step - loss: 2.4578\n16/16 [==============================] - 0s 701us/step - loss: 2.4537\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1234\n16/16 [==============================] - 0s 1ms/step - loss: 2.3238\n16/16 [==============================] - 0s 803us/step - loss: 2.7242\n16/16 [==============================] - 0s 601us/step - loss: 2.7327\n16/16 [==============================] - 0s 647us/step - loss: 2.6743\n16/16 [==============================] - 0s 970us/step - loss: 2.6098\n16/16 [==============================] - 0s 926us/step - loss: 2.5591\n16/16 [==============================] - 0s 1ms/step - loss: 2.5229\n16/16 [==============================] - 0s 1ms/step - loss: 2.5118\n16/16 [==============================] - 0s 678us/step - loss: 2.5074\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 642us/step - loss: 0.1248\n16/16 [==============================] - 0s 597us/step - loss: 2.2835\n16/16 [==============================] - 0s 629us/step - loss: 2.6774\n16/16 [==============================] - 0s 1ms/step - loss: 2.6863\n16/16 [==============================] - 0s 644us/step - loss: 2.6273\n16/16 [==============================] - 0s 1ms/step - loss: 2.5622\n16/16 [==============================] - 0s 956us/step - loss: 2.5114\n16/16 [==============================] - 0s 664us/step - loss: 2.4755\n16/16 [==============================] - 0s 875us/step - loss: 2.4643\n16/16 [==============================] - 0s 593us/step - loss: 2.4600\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 716us/step - loss: 0.1237\n16/16 [==============================] - 0s 626us/step - loss: 2.2727\n16/16 [==============================] - 0s 1ms/step - loss: 2.6608\n16/16 [==============================] - 0s 1ms/step - loss: 2.6688\n16/16 [==============================] - 0s 1ms/step - loss: 2.6110\n16/16 [==============================] - 0s 919us/step - loss: 2.5473\n16/16 [==============================] - 0s 1ms/step - loss: 2.4975\n16/16 [==============================] - 0s 780us/step - loss: 2.4622\n16/16 [==============================] - 0s 716us/step - loss: 2.4513\n16/16 [==============================] - 0s 638us/step - loss: 2.4470\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1213\n16/16 [==============================] - 0s 616us/step - loss: 2.3241\n16/16 [==============================] - 0s 618us/step - loss: 2.7152\n16/16 [==============================] - 0s 1ms/step - loss: 2.7211\n16/16 [==============================] - 0s 1ms/step - loss: 2.6613\n16/16 [==============================] - 0s 631us/step - loss: 2.5967\n16/16 [==============================] - 0s 741us/step - loss: 2.5461\n16/16 [==============================] - 0s 633us/step - loss: 2.5105\n16/16 [==============================] - 0s 2ms/step - loss: 2.4996\n16/16 [==============================] - 0s 599us/step - loss: 2.4952\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1217\n16/16 [==============================] - 0s 1ms/step - loss: 2.3310\n16/16 [==============================] - 0s 1ms/step - loss: 2.7333\n16/16 [==============================] - 0s 1ms/step - loss: 2.7466\n16/16 [==============================] - 0s 1ms/step - loss: 2.6903\n16/16 [==============================] - 0s 833us/step - loss: 2.6273\n16/16 [==============================] - 0s 608us/step - loss: 2.5776\n16/16 [==============================] - 0s 1ms/step - loss: 2.5424\n16/16 [==============================] - 0s 626us/step - loss: 2.5314\n16/16 [==============================] - 0s 709us/step - loss: 2.5270\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 0.1211\n16/16 [==============================] - 0s 1ms/step - loss: 2.2989\n16/16 [==============================] - 0s 1ms/step - loss: 2.6855\n16/16 [==============================] - 0s 1ms/step - loss: 2.6923\n16/16 [==============================] - 0s 1ms/step - loss: 2.6322\n16/16 [==============================] - 0s 650us/step - loss: 2.5665\n16/16 [==============================] - 0s 1ms/step - loss: 2.5155\n16/16 [==============================] - 0s 1ms/step - loss: 2.4800\n16/16 [==============================] - 0s 844us/step - loss: 2.4690\n16/16 [==============================] - 0s 593us/step - loss: 2.4647\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\n\n\nAccuracy: 0.952\nPrecision: 0.952\nRecall: 1.000\nF1 Score: 0.975\n\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['x', 'y','fnoise']])\n_df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\n_conf = Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\n\n\nAccuracy: 0.940\nPrecision: 0.996\nRecall: 0.941\nF1 Score: 0.967\n\n\n\nfourteen_bunny = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny-result",
    "href": "posts/GODE/2022-11-19-class_code_for_paper.html#bunny-result",
    "title": "Class code for Comparison Study",
    "section": "Bunny Result",
    "text": "Bunny Result\n\nround(fourteen_bunny,4)\n\n\n\n\n\n  \n    \n      \n      Accuracy\n      Precision\n      Recall\n      F1\n    \n  \n  \n    \n      GODE\n      0.9948\n      0.9954\n      0.9992\n      0.9973\n    \n    \n      LOF (Breunig et al., 2000)\n      0.9285\n      0.9569\n      0.9685\n      0.9627\n    \n    \n      kNN (Ramaswamy et al., 2000)\n      0.9405\n      0.9960\n      0.9413\n      0.9679\n    \n    \n      CBLOF (He et al., 2003)\n      0.9776\n      0.9895\n      0.9870\n      0.9882\n    \n    \n      OCSVM (Sch Ìˆolkopf et al., 2001)\n      0.9321\n      0.9911\n      0.9371\n      0.9633\n    \n    \n      MCD (Hardin and Rocke, 2004)\n      0.9349\n      0.9929\n      0.9383\n      0.9648\n    \n    \n      Feature Bagging (Lazarevic and Kumar, 2005)\n      0.9149\n      0.9818\n      0.9278\n      0.9540\n    \n    \n      ABOD (Kriegel et al., 2008)\n      0.9768\n      0.9891\n      0.9866\n      0.9878\n    \n    \n      Isolation Forest (Liu et al., 2008)\n      0.7942\n      0.9947\n      0.7881\n      0.8794\n    \n    \n      HBOS (Goldstein and Dengel, 2012)\n      0.8953\n      0.9695\n      0.9190\n      0.9436\n    \n    \n      SOS (Janssens et al., 2012)\n      0.8953\n      0.9695\n      0.9190\n      0.9436\n    \n    \n      SO-GAAL (Liu et al., 2019)\n      0.9521\n      0.9521\n      1.0000\n      0.9754\n    \n    \n      MO-GAAL (Liu et al., 2019)\n      0.9521\n      0.9521\n      1.0000\n      0.9754\n    \n    \n      LSCP (Zhao et al., 2019)\n      0.9397\n      0.9956\n      0.9408\n      0.9674"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html",
    "href": "posts/GODE/2022-09-02-paper_simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#imports",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#imports",
    "title": "Simulation",
    "section": "imports",
    "text": "imports\n\nimport rpy2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.graph_objects as go\n\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\nfrom plotly.subplots import make_subplots"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ebayesthresh",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ebayesthresh",
    "title": "Simulation",
    "section": "EbayesThresh",
    "text": "EbayesThresh\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(EbayesThresh)\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\n#plot(x,type='l')\n#mu <- EbayesThresh::ebayesthresh(x,sdev=2)\n#lines(mu,col=2,lty=2,lwd=2)\n\n\nR + python\n- Rí™˜ê²½ì— ìˆë˜ xë¥¼ ê°€ì§€ê³  ì˜¤ê¸°\n\n%R -o x \n\n- Rí™˜ê²½ì— ìˆëŠ” ebayesthresh í•¨ìˆ˜ë¥¼ ê°€ì§€ê³  ì˜¤ê¸°\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nxhat = np.array(ebayesthresh(FloatVector(x)))\n\n\n#plt.plot(x)\n#plt.plot(xhat)"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-1",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-1",
    "title": "Simulation",
    "section": "ì‹œë„ 1",
    "text": "ì‹œë„ 1\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color í‘œí˜„ì€ ìœ„í•¸ í‘œì¤€í™”\n        self.df = self.df.assign(differ = self.differ)\n        #with plt.style.context('seaborn-dark'):\n            #plt.figure(figsize=(16,10))\n            #plt.scatter(self.x,self.y,c=self.differ3,cmap='Purples',s=50)\n            #plt.plot(self.x,self.yhat, 'k--')\n    def vis(self,ref=60):\n        fig = go.Figure()\n        fig.add_scatter(x=self.x,y=self.y,mode=\"markers\",marker=dict(size=2, color=\"#9fc5e8\"),name='y',opacity=0.7)\n        fig.add_scatter(x=self.x,y=self.yhat,mode=\"markers\",marker=dict(size=2, color=\"#000000\"),name='yhat',opacity=0.7)\n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#0000FF',name='underline'))\n        fig.update_layout(width=1000,height=1000,autosize=False,margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def sub(self):\n        fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n        axs[0,0].plot(self.power)\n        axs[0,0].plot(self.power_threshed)\n        axs[0,0].set_title('power_threshed')\n\n        axs[0,1].plot(self.power[1:])\n        axs[0,1].plot(self.power_threshed[1:])\n        axs[0,1].set_title('power_threshed 1:')\n\n        axs[1,0].plot(self.power[2:])\n        axs[1,0].plot(self.power_threshed[2:])\n        axs[1,0].set_title('power_threshed 2:')\n\n        axs[1,1].plot((self.df.Residual)**2)\n        axs[1,1].set_title('Residual square')\n\n        plt.tight_layout()\n        plt.show()\n    def subvis(self,ref=60):\n        fig = make_subplots(rows=2, cols=2, subplot_titles=(\"y\", \"yhat\", \"Residual Square\", \"Graph\"))\n                            \n        fig.add_scatter(x=self.x,y=self.y, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='y',opacity=0.7,row=1,col=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=1,col=1)\n        \n        fig.add_scatter(x=self.x,y=self.yhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='yhat',opacity=0.7,row=1,col=2)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=1,col=2)\n        \n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=1)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=2,col=1)\n        \n        fig.add_scatter(x=self.x,y=self.y, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='y',opacity=0.7,row=2,col=2)        \n        fig.add_scatter(x=self.x,y=self.yhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='yhat',opacity=0.7,row=2,col=2)        \n        fig.add_scatter(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=2)\n        fig.add_trace(go.Scatter(x=self.x,y=self.y1,mode='lines',line_color='#000000',name='underline'),row=2,col=2)\n        \n        fig.update_xaxes(range=[0, 2], row=1, col=1)\n        fig.update_yaxes(range=[-5, 15], row=1, col=1)\n        \n        fig.update_xaxes(range=[0, 2], row=1, col=2)\n        fig.update_yaxes(range=[-5, 15], row=1, col=2)\n        \n        fig.update_xaxes(range=[0, 2], row=2, col=1)\n        fig.update_yaxes(range=[-5, 15], row=2, col=1)\n        \n        fig.update_xaxes(range=[0, 2], row=2, col=2)\n        fig.update_yaxes(range=[-5, 15], row=2, col=2)\n        \n        fig.update_layout(width=1000,height=1000,autosize=False,showlegend=False,title_text=\"The result\")\n        \n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\nclass SIMUL2(SIMUL):\n    def fit2(self,sd=5,ref=60,cuts=0,cutf=995):\n        self.fit()\n        with plt.style.context('seaborn-dark'):\n            plt.figure(figsize=(16,10))\n            plt.scatter(self.x,self.y,c=self.differ3,cmap='Purples',s=50)\n            plt.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50)\n            plt.plot(self.x,self.y1,'b--')\n            plt.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k--')\n    def fit3(self,sd=5,ref=30,ymin=-5,ymax=20,cuts=0,cutf=995):\n        self.fit()\n        with plt.style.context('seaborn-dark'):\n            fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n            axs[0,0].scatter(self.x,self.y,c=self.differ,cmap='Purples',s=50)\n            axs[0,0].set_title('y')\n            axs[0,0].set_ylim([ymin,ymax])\n            \n\n            axs[0,1].plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k')\n            axs[0,1].plot(self.x[cuts:cutf],self.y1[cuts:cutf], 'b',alpha=0.5)\n            axs[0,1].set_title('yhat')\n            axs[0,1].set_ylim([ymin,ymax])\n\n            axs[1,0].scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50,marker='*')\n            axs[1,0].plot(self.x[cuts:cutf],self.y1[cuts:cutf], 'b',alpha=0.5)\n            axs[1,0].set_title('Residual square')\n            axs[1,0].set_ylim([ymin,ymax])\n\n            axs[1,1].scatter(self.x,self.y,c=self.differ,cmap='Purples',s=50)\n            axs[1,1].plot(self.x[cuts:cutf],self.yhat[cuts:cutf], 'k')\n            axs[1,1].scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=50,marker='*')\n            axs[1,1].set_title('Graph')\n            axs[1,1].set_ylim([ymin,ymax])\n\n            plt.tight_layout()\n            plt.show()\n\n\n_simul = SIMUL2(df1)\n\n\n_simul.fit3(sd=5,ref=20,ymin=-10,ymax=15)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-2",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-2",
    "title": "Simulation",
    "section": "ì‹œë„ 2",
    "text": "ì‹œë„ 2\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df2)\n\n\n_simul.fit3(sd=6,ref=20,ymin=-10,ymax=25)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-3",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-3",
    "title": "Simulation",
    "section": "ì‹œë„ 3",
    "text": "ì‹œë„ 3\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**3 \n_y = _y1 + x # x is epsilon\n\n\ndf3=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df3)\n\n\n_simul.fit3(ymin=-10,ymax=45)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-4",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-4",
    "title": "Simulation",
    "section": "ì‹œë„ 4",
    "text": "ì‹œë„ 4\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\n# _x = np.linspace(0,2,1000)\n# _y1 = 5*np.sin(_x) \n# _y = _y1 + x # x is epsilon\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df4)\n\n\n_simul.fit3(ref=10,ymin=-15,ymax=10)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-5",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#ì‹œë„-5",
    "title": "Simulation",
    "section": "ì‹œë„ 5",
    "text": "ì‹œë„ 5\n\n# _x = np.linspace(0,2,1000)\n# _y1 =  3*np.cos(_x) + 1*np.cos(_x**2) + 0.5*np.cos(5*_x) \n# _y = _y1 + x # x is epsilon\n\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul = SIMUL2(df5)\n\n\n_simul.fit3(ref=15,ymin=-10,ymax=15,cuts=5)\n\n\n\n\n\n#_simul.vis()\n\n\n_simul.sub()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-1",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-1",
    "title": "Simulation",
    "section": "3D ì‹œë„ 1",
    "text": "3D ì‹œë„ 1\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,6*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,3*pi,n))\nf = f1 + x\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=200)  # Make figure object \n\n# 2. \nax=p.add_subplot(1,1,1, projection='3d')\nax.grid(False)\nax.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = f\nbottom = np.zeros_like(top)\nwidth=depth=0.05\n#ax.bar3d(vx, vy, bottom, width, depth, top, shade=False)\nax.scatter3D(vx,vy,f,zdir='z',s=10,marker='.')\nax.scatter3D(vx,vy,f1,zdir='z',s=10,marker='.')\nax.bar3d(vx, vy, bottom, width, depth, 0, color='Black',shade=False)\nax.set_xlim(-3,3)\nax.set_ylim(-3,3)\nax.set_zlim(-10,10)\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig, axs = plt.subplots(2,2,figsize=(16,16),subplot_kw={\"projection\":\"3d\"})\n        axs[0,0].grid(False)\n        axs[0,0].scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[0,0].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[0,0].set_xlim(-3,3)\n        axs[0,0].set_ylim(-3,3)\n        axs[0,0].set_zlim(-10,10)\n        axs[0,0].view_init(elev=20., azim=40)\n        \n        axs[0,1].grid(False)\n        axs[0,1].scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[0,1].plot3D(self.x,self.y,self.f1,'blue')\n        axs[0,1].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[0,1].set_xlim(-3,3)\n        axs[0,1].set_ylim(-3,3)\n        axs[0,1].set_zlim(-10,10)\n        axs[0,1].view_init(elev=20., azim=40)\n        \n        axs[1,0].grid(False)\n        axs[1,0].scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        axs[1,0].plot3D(self.x,self.y,self.f1,'blue')\n        axs[1,0].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[1,0].set_xlim(-3,3)\n        axs[1,0].set_ylim(-3,3)\n        axs[1,0].set_zlim(-10,10)\n        axs[1,0].view_init(elev=20., azim=40)\n        \n        axs[1,1].grid(False)\n        axs[1,1].scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[1,1].scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        axs[1,1].scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        axs[1,1].plot3D(self.x,self.y,self.f1,'black')\n        axs[1,1].plot3D(self.x,self.y,[0]*1000,'black')\n        axs[1,1].set_xlim(-3,3)\n        axs[1,1].set_ylim(-3,3)\n        axs[1,1].set_zlim(-10,10)\n        axs[1,1].view_init(elev=20., azim=40)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # p = plt.figure(figsize=(16,16))\n        # ax = p.add_subplot(1,1,1, projection='3d')\n        # ax.grid(False)\n        # ax.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\n        # ax.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\n        # ax.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\n        # ax.scatter3D(self.x,self.y,self.f,c=self.dif,cmap='winter',zdir='z',s=50,marker='.',alpha=0.2)\n        # ax.scatter3D(self.x,self.y,self.fhat,color='black',zdir='z',s=50,marker='.',alpha=0.2)\n        # #ax.plot3D(self.x,self.y,self.fhat,'black')\n        # ax.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],color='red',zdir='z',s=100,marker='.',alpha=1)\n        # ax.plot3D(self.x,self.y,self.f1,'black')\n        # ax.plot3D(self.x,self.y,[0]*1000,'black')\n        # ax.set_xlim(-3,3)\n        # ax.set_ylim(-3,3)\n        # ax.set_zlim(-10,10)\n    def vis(self,ref=60):\n        fig = go.Figure()\n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2)\n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2)\n        #fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.fhat,mode='lines',line_color='#000000'))\n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'))\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'))\n        fig.update_layout(width=1000,height=1000,autosize=False,margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def sub(self):\n        fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n        axs[0,0].plot(_simul.power)\n        axs[0,0].plot(_simul.power_threshed)\n        axs[0,0].set_title('power_threshed')\n\n        axs[0,1].plot(_simul.power[1:])\n        axs[0,1].plot(_simul.power_threshed[1:])\n        axs[0,1].set_title('power_threshed 1:')\n\n        axs[1,0].plot(_simul.power[2:])\n        axs[1,0].plot(_simul.power_threshed[2:])\n        axs[1,0].set_title('power_threshed 2:')\n\n        axs[1,1].plot((_simul.df.Residual)**2)\n        axs[1,1].set_title('Residual square')\n\n        plt.tight_layout()\n        plt.show()\n    def subvis(self,ref=60):\n        fig = make_subplots(2,2,specs=[[{'type': 'surface'}, {'type': 'surface'}],[{'type': 'surface'}, {'type': 'surface'}]],subplot_titles=(\"f\", \"fhat\", \"Residual Square\", \"Graph\"))\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2,row=1,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=1,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=1,col=1)\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2,row=1,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=1,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=1,col=2)\n        \n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=2,col=1)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=2,col=1)\n        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.f, mode=\"markers\",marker=dict(size=3, color=\"#9fc5e8\"),name='f',opacity=0.2,row=2,col=2)        \n        fig.add_scatter3d(x=self.x,y=self.y,z=self.fhat, mode=\"markers\",marker=dict(size=3, color=\"#999999\"),name='fhat',opacity=0.2,row=2,col=2)        \n        fig.add_scatter3d(x=self.df.query('Residual**2>@ref')['x'],y=self.df.query('Residual**2>@ref')['y'],z=self.df.query('Residual**2>@ref')['f'], mode=\"markers\",marker=dict(size=3, color=\"#f20505\"),name='R square',opacity=1,row=2,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=self.f1,mode='lines',line_color='#000000',name='underline'),row=2,col=2)\n        fig.add_trace(go.Scatter3d(x=self.x,y=self.y,z=[0]*1000,mode='lines',line_color='#000000',name='z=0'),row=2,col=2)\n        \n        fig.update_layout(scene = dict(xaxis = dict(range=[-3,3],),\n                                         yaxis = dict(range=[-3,3],),\n                                         zaxis = dict(range=[-10,10],),),\n                                      width=1000,height=1000,autosize=False)\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\n_simul = SIMUL(df)\n\n\n_simul.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 532.20it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6888234729389295\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 66308.,  64352.,  68358., 177302., 166964., 114648.,  94344.,\n        111136.,  75508.,  60080.]),\n array([0.00628415, 0.54637775, 1.08647135, 1.62656495, 2.16665855,\n        2.70675214, 3.24684574, 3.78693934, 4.32703294, 4.86712654,\n        5.40722013]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6888234729389295),kappa=2500) \n\n\n_simul.fit(sd=5,ref=20)\n\n\n\n\n\n#_simul.vis(ref=20)\n\n\n#_simul.subvis(ref=20)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-2",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-2",
    "title": "Simulation",
    "section": "3D ì‹œë„ 2",
    "text": "3D ì‹œë„ 2\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,8*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,3*pi,n))\nf = f1 + x\n\n\ndf1 = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f,'f1':f1})\n\n\n_simul = SIMUL(df1)\n\n\n_simul.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 521.69it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6984753461932702\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 63450.,  64118., 146970., 169756., 138202., 126198., 162650.,\n         75642.,  28416.,  23598.]),\n array([0.0062838 , 0.60565122, 1.20501864, 1.80438605, 2.40375347,\n        3.00312089, 3.6024883 , 4.20185572, 4.80122314, 5.40059055,\n        5.99995797]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6984753461932702),kappa=2500) \n\n\n_simul.fit(sd=5,ref=30)\n\n\n\n\n\n#_simul.vis(ref=50)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-3",
    "href": "posts/GODE/2022-09-02-paper_simulation.html#d-ì‹œë„-3",
    "title": "Simulation",
    "section": "3D ì‹œë„ 3",
    "text": "3D ì‹œë„ 3\n\n### Example 2\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=2+np.sin(np.linspace(0,6*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf2 = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f,'f1':f1})\n\n\n_simul = SIMUL(df2)\n\n\n_simul.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 463.80it/s]\n\n\n\n_simul.D[_simul.D>0].mean()\n\n2.6888234729389295\n\n\n\nplt.hist(_simul.D[_simul.D>0])\n\n(array([ 66308.,  64352.,  68358., 177302., 166964., 114648.,  94344.,\n        111136.,  75508.,  60080.]),\n array([0.00628415, 0.54637775, 1.08647135, 1.62656495, 2.16665855,\n        2.70675214, 3.24684574, 3.78693934, 4.32703294, 4.86712654,\n        5.40722013]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n_simul.get_weightmatrix(theta=(2.6984753461932702),kappa=2500) \n\n\n_simul.fit(sd=5,ref=30)\n\n\n\n\n\n#_simul.vis(ref=50)\n\n\n_simul.sub()\n\n\n\n\n\n#_simul.subvis()"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html",
    "title": "Earthquake",
    "section": "",
    "text": "Real analysis"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#imports",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#imports",
    "title": "Earthquake",
    "section": "imports",
    "text": "imports\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\nimport plotly.graph_objects as go\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#load-data-and-clean-it",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#load-data-and-clean-it",
    "title": "Earthquake",
    "section": "load data and clean it",
    "text": "load data and clean it\n- load\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n    \n  \n\n23412 rows Ã— 4 columns\n\n\n\n\ndf_korea= pd.read_csv('earthquake_korea2.csv').iloc[:,[1,2,5,6]].rename(columns={'ê·œëª¨':'Magnitude'})\n\nhttps://www.weather.go.kr/w/eqk-vol/search/korea.do?schOption=&xls=0&startTm=2012-01-02&endTm=2022-06-17&startSize=2&endSize=&startLat=&endLat=&startLon=&endLon=&lat=&lon=&dist=&keyword=&dpType=m\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\nhttps://www.usgs.gov/programs/earthquake-hazards/lists-maps-and-statistics\n- cleaning\n\ndf.Date[df.Date == '1975-02-23T02:58:41.000Z']\n\n3378    1975-02-23T02:58:41.000Z\nName: Date, dtype: object\n\n\n\ndf.iloc[3378,0] = '02/03/1975'\n\n\ndf.Date[df.Date == '1985-04-28T02:53:41.530Z']\n\n7512    1985-04-28T02:53:41.530Z\nName: Date, dtype: object\n\n\n\ndf.iloc[7512,0] = '04/28/1985'\n\n\ndf.Date[df.Date == '2011-03-13T02:23:34.520Z']\n\n20650    2011-03-13T02:23:34.520Z\nName: Date, dtype: object\n\n\n\ndf.iloc[20650,0] = '03/13/2011'\n\n\ndf= df.assign(Year=list(map(lambda x: x.split('/')[-1], df.Date))).iloc[:,1:]\ndf\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows Ã— 4 columns\n\n\n\n\ndf.Year = df.Year.astype(np.float64)\n\n\ndf_korea = df_korea.assign(Year=list(map(lambda x: x.split('/')[0], df_korea.ë°œìƒì‹œê°))).iloc[:,1:]\ndf_korea = df_korea.assign(Latitude=list(map(lambda x: x.split(' ')[0], df_korea.ìœ„ë„))).iloc[:,[0,2,3,4]]\ndf_korea = df_korea.assign(Longitude=list(map(lambda x: x.split(' ')[0], df_korea.ê²½ë„))).iloc[:,[0,2,3,4]]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_korea.Year = df_korea.Year.astype(np.float64)\ndf_korea.Latitude = df_korea.Latitude.astype(np.float64)\ndf_korea.Longitude = df_korea.Longitude.astype(np.float64)\ndf_global.Year = df_global.Year.astype(np.float64)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#define-class",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#define-class",
    "title": "Earthquake",
    "section": "define class",
    "text": "define class\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n        \n    def vis(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.4,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'red',\n                      opacity = 0.6\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.5\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visf(self):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visfhat(self):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='MagnitudeHat', \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n    def visres(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z=[0] * len(self.df), \n                        radius=5,\n                        center=dict(lat=37, lon=160), \n                        zoom=1.5,\n                        height=900,\n                        opacity = 0.7,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.7\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh ê¸°ëŠ¥ì¶”ê°€\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n        #plt.plot(self.f,'.')\n        #plt.plot(self.fhat,'x')\n\n#         fig, axs = plt.subplots(2,2,figsize=(16,10))\n\n#         axs[0,0].plot(self.f,'b')\n#         axs[0,0].set_title('Magnitude')\n#         axs[0,0].set_ylim([4.5,9])\n\n#         axs[0,1].plot(self.fhat,'k')\n#         axs[0,1].set_title('MagnitudeHat')\n#         axs[0,1].set_ylim([4.5,9])\n\n#         axs[1,0].plot(self.con,'r*')\n#         axs[1,0].set_title('Residual square')\n\n#         axs[1,1].plot(self.f,'b')\n#         axs[1,1].plot(self.fhat,'k')\n#         axs[1,1].plot(self.con,'r*')\n#         axs[1,1].set_title('Graph')\n#         axs[1,1].set_ylim([4.5,9])\n\n#         plt.tight_layout()\n#         plt.show()\n\n\nclass MooYaHo3(MooYaHo2):\n    def vis(self,MagThresh=7,ResThresh=1):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=5,\n                        center=dict(lat=37, lon=126), \n                        zoom=5.7,\n                        height=900,\n                        opacity = 0.3,\n                        mapbox_style=\"stamen-terrain\")\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'red',\n                      opacity = 0.5\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= 8,\n                      marker_color= 'blue',\n                      opacity = 0.5\n                      )\n        return HTML(fig.to_html(include_mathjax=False, config=dict({'scrollZoom':False})))\n\n\n       ebayesthresh = importr('EbayesThresh').ebayesthresh"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20102015",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20102015",
    "title": "Earthquake",
    "section": "analysis_df_global(2010~2015)",
    "text": "analysis_df_global(2010~2015)\n- make instance for analysis\n\nmoo_global=MooYaHo2(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\nmoo_global.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10762/10762 [05:32<00:00, 32.36it/s] \n\n\n\nmoo_global.D[moo_global.D>0].mean()\n\n8746.68756693945\n\n\n\nplt.hist(moo_global.D[moo_global.D>0])\n\n(array([10857854., 11686138., 15883516., 16913862., 14592080., 12938904.,\n        11847394.,  9636694.,  9649504.,  1799146.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\nmoo_global.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\nmoo_global.fit2()\n\n\nmoo_global.df.sort_values(\"Residual\",ascending=False).iloc[:40,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      30311\n      38.2970\n      142.3730\n      9.1\n      2011.0\n      7.625067\n      1.474933\n    \n    \n      11094\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.638469\n      1.161531\n    \n    \n      32803\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.789231\n      1.010769\n    \n    \n      32436\n      -36.2170\n      -73.2570\n      6.7\n      2010.0\n      5.841501\n      0.858499\n    \n    \n      26564\n      14.1290\n      -92.1640\n      6.5\n      2012.0\n      5.653542\n      0.846458\n    \n    \n      27513\n      0.8020\n      92.4630\n      8.2\n      2012.0\n      7.368113\n      0.831887\n    \n    \n      30347\n      38.4350\n      142.8420\n      7.3\n      2011.0\n      6.490603\n      0.809397\n    \n    \n      30296\n      36.2810\n      141.1110\n      7.9\n      2011.0\n      7.156346\n      0.743654\n    \n    \n      10292\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.766319\n      0.733681\n    \n    \n      9193\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.667897\n      0.732103\n    \n    \n      32554\n      -36.6650\n      -73.3740\n      6.6\n      2010.0\n      5.873441\n      0.726559\n    \n    \n      30301\n      38.9690\n      143.3700\n      6.7\n      2011.0\n      5.984234\n      0.715766\n    \n    \n      32001\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.793936\n      0.706064\n    \n    \n      31229\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.100594\n      0.699406\n    \n    \n      28229\n      37.3650\n      141.3680\n      6.1\n      2011.0\n      5.403952\n      0.696048\n    \n    \n      9283\n      -56.4120\n      -25.7410\n      6.3\n      2010.0\n      5.607381\n      0.692619\n    \n    \n      9520\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.111591\n      0.688409\n    \n    \n      30827\n      -19.7020\n      167.9470\n      7.3\n      2010.0\n      6.615744\n      0.684256\n    \n    \n      30295\n      36.0230\n      142.2690\n      6.6\n      2011.0\n      5.917664\n      0.682336\n    \n    \n      27456\n      2.5810\n      90.2690\n      6.2\n      2012.0\n      5.521275\n      0.678725\n    \n    \n      30017\n      37.5940\n      142.6480\n      6.5\n      2011.0\n      5.828617\n      0.671383\n    \n    \n      10135\n      -22.1460\n      -68.2160\n      6.3\n      2010.0\n      5.631982\n      0.668018\n    \n    \n      24958\n      -60.2738\n      -46.4011\n      7.7\n      2013.0\n      7.041204\n      0.658796\n    \n    \n      10783\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.241810\n      0.658190\n    \n    \n      29019\n      -29.3370\n      -177.0510\n      6.0\n      2011.0\n      5.347355\n      0.652645\n    \n    \n      32492\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.250075\n      0.649925\n    \n    \n      30902\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.758872\n      0.641128\n    \n    \n      28931\n      52.8810\n      108.4400\n      5.3\n      2011.0\n      4.661692\n      0.638308\n    \n    \n      29004\n      38.0340\n      143.2640\n      7.0\n      2011.0\n      6.368649\n      0.631351\n    \n    \n      30992\n      -56.4120\n      -25.7410\n      6.3\n      2010.0\n      5.680727\n      0.619273\n    \n    \n      30893\n      27.2030\n      143.4550\n      5.3\n      2010.0\n      4.681926\n      0.618074\n    \n    \n      9665\n      -4.9630\n      133.7600\n      7.0\n      2010.0\n      6.382904\n      0.617096\n    \n    \n      29640\n      38.2760\n      141.5880\n      7.1\n      2011.0\n      6.485066\n      0.614934\n    \n    \n      26354\n      55.2280\n      -134.8591\n      7.5\n      2013.0\n      6.890518\n      0.609482\n    \n    \n      27527\n      2.3270\n      93.0630\n      8.6\n      2012.0\n      7.992761\n      0.607239\n    \n    \n      25452\n      -60.8570\n      -25.0700\n      7.3\n      2013.0\n      6.693727\n      0.606273\n    \n    \n      29536\n      -10.3750\n      161.2000\n      6.8\n      2011.0\n      6.197847\n      0.602153\n    \n    \n      26468\n      37.8900\n      143.9490\n      7.3\n      2012.0\n      6.698942\n      0.601058\n    \n    \n      32231\n      -15.2710\n      -173.2190\n      6.1\n      2010.0\n      5.502608\n      0.597392\n    \n    \n      26234\n      -11.1830\n      164.8820\n      7.1\n      2013.0\n      6.507029\n      0.592971\n    \n  \n\n\n\n\n(2010~2014 ì‹œë„) - 21ë²ˆì§¸ Ouest Department, Haiti ì•„ì´í‹° ì§€ì§„ 2010ë…„ ì§„ë„ 7.0 - 24ë²ˆì§¸ Puchuncavi, ValparaÃ­so, Chile ì¹ ë ˆ ì§€ì§„ 2014ë…„ ì§„ë„ 6.4 - 28ë²ˆì§¸ Baoxing County, Yaan, Sichuan, China ì¤‘êµ­ ì“°ì´¨ì„± ì§€ì§„ 2013ë…„ ì§„ë„ 6.6\n(2010~2015 ì‹œë„_ê²°ê³¼ ì¢‹ì§€ ì•ŠìŒ?!) - 23ë²ˆì§¸ 2010ë…„ West New Britain Province, Papua New Guinea ì§„ë„ 7.3 - 24ë²ˆì§¸ 2011ë…„ Kuzawa Terayama, Tanagura, Higashishirakawa District, Fukushima 963-5671, Japan ì§„ë„ 6.6 - 29ë²ˆì§¸ 2015ë…„ Kishim, Afghanistan ì§„ë„ 7.5\n- vis\n\n#moo_global.visf()\n\n\n#moo_global.visfhat()\n\n\n#moo_global.visres()\n\n\n#moo_global.vis(MagThresh=6.9,ResThresh=0.5)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20152020",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#analysis_df_global20152020",
    "title": "Earthquake",
    "section": "analysis_df_global(2015~2020)",
    "text": "analysis_df_global(2015~2020)\n- make instance for analysis\n\nmoo_global=MooYaHo2(df_global.query(\"2015 <= Year <= 2020\"))\n\n- get distance\n\nmoo_global.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11239/11239 [04:35<00:00, 40.84it/s] \n\n\n\nmoo_global.D[moo_global.D>0].mean()\n\n8814.318793468068\n\n\n\nplt.hist(moo_global.D[moo_global.D>0])\n\n(array([10894274., 13618924., 16426520., 17583818., 16025000., 15684642.,\n        13794372., 10946494.,  9072574.,  2254138.]),\n array([2.54728455e-02, 2.00123511e+03, 4.00244475e+03, 6.00365439e+03,\n        8.00486402e+03, 1.00060737e+04, 1.20072833e+04, 1.40084929e+04,\n        1.60097026e+04, 1.80109122e+04, 2.00121218e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\nmoo_global.get_weightmatrix(theta=(8814.318793468068),kappa=2500) \n\n- fit\n\nmoo_global.fit2()\n\n\nmoo_global.df.sort_values(\"Residual\",ascending=False).iloc[:30,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      21952\n      -31.5729\n      -71.6744\n      8.3\n      2015.0\n      7.294011\n      1.005989\n    \n    \n      36363\n      -21.9496\n      169.4266\n      7.5\n      2018.0\n      6.523828\n      0.976172\n    \n    \n      36993\n      -18.1125\n      -178.1530\n      8.2\n      2018.0\n      7.311720\n      0.888280\n    \n    \n      39932\n      -42.7373\n      173.0540\n      7.8\n      2016.0\n      6.951928\n      0.848072\n    \n    \n      36263\n      55.0999\n      164.6993\n      7.3\n      2018.0\n      6.470796\n      0.829204\n    \n    \n      35004\n      -30.1733\n      -177.8625\n      6.1\n      2019.0\n      5.285797\n      0.814203\n    \n    \n      41015\n      -4.9521\n      94.3299\n      7.8\n      2016.0\n      6.993888\n      0.806112\n    \n    \n      21719\n      -8.3381\n      124.8754\n      6.5\n      2015.0\n      5.698526\n      0.801474\n    \n    \n      33404\n      54.6020\n      -159.6258\n      7.6\n      2020.0\n      6.819466\n      0.780534\n    \n    \n      41735\n      -31.5729\n      -71.6744\n      8.3\n      2015.0\n      7.547595\n      0.752405\n    \n    \n      40113\n      -19.7819\n      -178.2443\n      6.9\n      2016.0\n      6.148672\n      0.751328\n    \n    \n      41695\n      -31.5173\n      -71.8040\n      6.7\n      2015.0\n      5.951922\n      0.748078\n    \n    \n      37927\n      56.0039\n      -149.1658\n      7.9\n      2018.0\n      7.170056\n      0.729944\n    \n    \n      36848\n      -18.4743\n      179.3502\n      7.9\n      2018.0\n      7.173844\n      0.726156\n    \n    \n      21945\n      -31.5622\n      -71.4262\n      7.0\n      2015.0\n      6.291422\n      0.708578\n    \n    \n      41502\n      -8.3381\n      124.8754\n      6.5\n      2015.0\n      5.812161\n      0.687839\n    \n    \n      33896\n      -33.2927\n      -177.8571\n      7.4\n      2020.0\n      6.715142\n      0.684858\n    \n    \n      22560\n      -5.4912\n      151.8715\n      6.0\n      2015.0\n      5.316904\n      0.683096\n    \n    \n      39584\n      -43.4064\n      -73.9413\n      7.6\n      2016.0\n      6.921775\n      0.678225\n    \n    \n      36777\n      -25.4150\n      178.1991\n      6.5\n      2018.0\n      5.833282\n      0.666718\n    \n    \n      35487\n      -30.6441\n      -178.0995\n      7.3\n      2019.0\n      6.638342\n      0.661658\n    \n    \n      39771\n      -10.6812\n      161.3273\n      7.8\n      2016.0\n      7.145371\n      0.654629\n    \n    \n      38827\n      -30.5156\n      -178.0563\n      6.0\n      2017.0\n      5.351325\n      0.648675\n    \n    \n      41963\n      52.3760\n      -169.4458\n      6.9\n      2015.0\n      6.256523\n      0.643477\n    \n    \n      22488\n      27.8087\n      86.0655\n      7.3\n      2015.0\n      6.662980\n      0.637020\n    \n    \n      21795\n      -54.4856\n      -135.7080\n      6.1\n      2015.0\n      5.468025\n      0.631975\n    \n    \n      22839\n      -10.7598\n      164.1216\n      6.1\n      2015.0\n      5.468139\n      0.631861\n    \n    \n      41423\n      38.6700\n      20.6000\n      6.5\n      2015.0\n      5.874436\n      0.625564\n    \n    \n      36101\n      -30.0404\n      -71.3815\n      6.7\n      2019.0\n      6.081398\n      0.618602\n    \n    \n      36602\n      -21.7427\n      169.5217\n      6.5\n      2018.0\n      5.882525\n      0.617475\n    \n  \n\n\n\n\në°”ë‹¤ ì•„ë‹Œ ê±° - 8ë²ˆì§¸ 2016ë…„ Rotherham, New Zealand ë‰´ì§ˆëœë“œ ì¹´ì´ì½”ìš°ë¼ ì§€ì§„ ì§„ë„ 7.8 - 9ë²ˆì§¸ 2015ë…„ Langkuru Utara, Pureman, Alor Regency, East Nusa Tenggara, Indonesia ìˆ˜ë§ˆíŠ¸ë¼ ì§„ë„ 6.5 - 15ë²ˆì§¸ 2018ë…„ Hela Province, Papua New Guinea íŒŒí‘¸ì•„ë‰´ê¸°ë‹ˆ ì§„ë„ 7.5 - 20ë²ˆì§¸ 2015ë…„ Kalinchok, Nepal ë„¤íŒ” ì§„ë„ 7.3 - 26ë²ˆì§¸ 2019ë…„ Coquimbo, Chile ì¹ ë ˆ ì½”í‚´ë³´ì£¼ ì§„ë„ 6.7\n- vis\n\n#moo_global.vis(MagThresh=7,ResThresh=0.3)\n\n\n\npd.read_html('https://en.wikipedia.org/wiki/Lists_of_21st-century_earthquakes',encoding='utf-8')[0].query('Magnitude<=7')# List of deadliest earthquakes\n\n\npd.read_html('https://en.wikipedia.org/wiki/Lists_of_21st-century_earthquakes',encoding='utf-8')[3] # Deadliest earthquakes by year\n\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n- get distance\n\neach_location.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12498/12498 [05:55<00:00, 35.16it/s] \n\n\n\neach_location.D[each_location.D>0].mean()\n\n8810.865423093777\n\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n(array([14176290., 16005894., 21186674., 22331128., 19394182., 17548252.,\n        16668048., 13316436., 12973260.,  2582550.]),\n array([8.97930163e-02, 2.00141141e+03, 4.00273303e+03, 6.00405465e+03,\n        8.00537626e+03, 1.00066979e+04, 1.20080195e+04, 1.40093411e+04,\n        1.60106627e+04, 1.80119844e+04, 2.00133060e+04]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- weight matrix\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n- fit\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5)\n\n\n                                                \n\n\n\neach_location.lquique(MagThresh=8,ResThresh=0.4,adjzoom=4.3)\n\n\n                                                \n\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4)"
  },
  {
    "objectID": "posts/GODE/2022-10-02-Earthquake_real.html#ì¹ ë ˆ",
    "href": "posts/GODE/2022-10-02-Earthquake_real.html#ì¹ ë ˆ",
    "title": "Earthquake",
    "section": "ì¹ ë ˆ",
    "text": "ì¹ ë ˆ\n\ndf_chile_ex= pd.concat([pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_chile = df_chile_ex.assign(Year=list(map(lambda x: x.split('-')[0], df_chile_ex.time))).iloc[:,1:]\n\n\ndf_chile = df_chile.assign(Month=list(map(lambda x: x.split('-')[1], df_chile_ex.time)))\n\n\ndf_chile.Year = df_chile.Year.astype(np.float64)\ndf_chile.Month = df_chile.Month.astype(np.float64)\n\n\nchile_location=eachlocation(df_chile.query(\"2010 <= Year < 2015\"))\n\n\nchile_location.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12498/12498 [06:28<00:00, 32.19it/s] \n\n\n\nchile_location.get_weightmatrix(theta=(chile_location.D[chile_location.D>0].mean()),kappa=2500) \n\n\nchile_location.fit2()\n\nì•„ì´í‹°\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().iloc[2324:2330,:]\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      2324\n      2324\n      18.463\n      -72.626\n      5.0\n      2010.0\n      1.0\n      5.105168\n      -0.105168\n      0.011060\n    \n    \n      2325\n      2325\n      18.387\n      -72.784\n      6.0\n      2010.0\n      1.0\n      5.703460\n      0.296540\n      0.087936\n    \n    \n      2326\n      2326\n      18.443\n      -72.571\n      7.0\n      2010.0\n      1.0\n      6.659386\n      0.340614\n      0.116018\n    \n    \n      2327\n      2327\n      -5.417\n      133.731\n      5.5\n      2010.0\n      1.0\n      5.604103\n      -0.104103\n      0.010837\n    \n    \n      2328\n      2328\n      15.437\n      -88.761\n      5.1\n      2010.0\n      1.0\n      4.964642\n      0.135358\n      0.018322\n    \n    \n      2329\n      2329\n      -16.861\n      -174.228\n      5.3\n      2010.0\n      1.0\n      5.340902\n      -0.040902\n      0.001673\n    \n  \n\n\n\n\nì¹ ë ˆ\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().query(\"-56.5 < Latitude & Latitude <-17.4 & -81.5 < Longitude & Longitude < -61.5 & Year == 2014 & Month == 8\")\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      2997\n      14603\n      -32.6953\n      -71.4416\n      6.4\n      2014.0\n      8.0\n      6.088353\n      0.311647\n      0.097124\n    \n    \n      2999\n      14605\n      -20.1745\n      -69.0385\n      5.6\n      2014.0\n      8.0\n      5.553419\n      0.046581\n      0.002170\n    \n    \n      3032\n      14638\n      -20.1580\n      -70.0230\n      5.3\n      2014.0\n      8.0\n      5.251934\n      0.048066\n      0.002310\n    \n    \n      3046\n      14652\n      -23.9047\n      -66.7371\n      5.0\n      2014.0\n      8.0\n      5.210380\n      -0.210380\n      0.044260\n    \n    \n      3057\n      14663\n      -33.7770\n      -72.2030\n      5.2\n      2014.0\n      8.0\n      5.065422\n      0.134578\n      0.018111\n    \n  \n\n\n\n\nì¤‘êµ­\n\nchile_location.df.assign(Residual2 = chile_location.df.Residual**2).reset_index().iloc[5136:5142,:]\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      Month\n      MagnitudeHat\n      Residual\n      Residual2\n    \n  \n  \n    \n      5136\n      16742\n      30.209\n      102.862\n      5.0\n      2013.0\n      4.0\n      4.943022\n      0.056978\n      0.003247\n    \n    \n      5137\n      16743\n      30.308\n      102.888\n      6.6\n      2013.0\n      4.0\n      5.904218\n      0.695782\n      0.484113\n    \n    \n      5138\n      16744\n      39.693\n      143.258\n      5.0\n      2013.0\n      4.0\n      5.118611\n      -0.118611\n      0.014068\n    \n    \n      5139\n      16745\n      49.965\n      157.652\n      6.1\n      2013.0\n      4.0\n      5.852776\n      0.247224\n      0.061120\n    \n    \n      5140\n      16746\n      -11.976\n      121.632\n      5.8\n      2013.0\n      4.0\n      5.809708\n      -0.009708\n      0.000094\n    \n    \n      5141\n      16747\n      -14.966\n      166.857\n      5.2\n      2013.0\n      4.0\n      5.145590\n      0.054410\n      0.002960"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html",
    "title": "Comparison Results on Real Data",
    "section": "",
    "text": "Comparison at real data"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html#load-data-and-clean-it",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html#load-data-and-clean-it",
    "title": "Comparison Results on Real Data",
    "section": "load data and clean it",
    "text": "load data and clean it\n- load\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n- cleaning\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\ndf_global_10 = df_global.copy()\ndf_global_10 = df_global_10.query(\"2010 <= Year < 2015\").reset_index().iloc[:,1:];df_global_10\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n    \n  \n\n12498 rows Ã— 4 columns\n\n\n\n\nGODE\n\ngode_global = earthquake_func(df_global_10)\n\n- get distance\n\ngode_global.get_distance()\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12498/12498 [07:20<00:00, 28.35it/s] \n\n\n\ngode_global.D[gode_global.D>0].mean()\n\n8810.865423093777\n\n\n- weight matrix\n\ngode_global.get_weightmatrix(theta=(gode_global.D[gode_global.D>0].mean()),kappa=2500) \n\n- fit\n\ngode_global.fit()\n\n\n_df = gode_global.df.copy()\n\n\n_df.sort_values(\"Residual\",ascending=False).iloc[:40,:]\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n    \n  \n  \n    \n      2064\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.572545\n      1.227455\n    \n    \n      3752\n      -19.6097\n      -70.7691\n      8.2\n      2014.0\n      7.075499\n      1.124501\n    \n    \n      12167\n      -36.1220\n      -72.8980\n      8.8\n      2010.0\n      7.742429\n      1.057571\n    \n    \n      9660\n      36.2810\n      141.1110\n      7.9\n      2011.0\n      6.912847\n      0.987153\n    \n    \n      6877\n      0.8020\n      92.4630\n      8.2\n      2012.0\n      7.353106\n      0.846894\n    \n    \n      7938\n      -21.6110\n      -179.5280\n      7.3\n      2011.0\n      6.497713\n      0.802287\n    \n    \n      10593\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.008107\n      0.791893\n    \n    \n      3835\n      -19.9807\n      -70.7022\n      6.7\n      2014.0\n      5.913563\n      0.786437\n    \n    \n      3281\n      -29.9772\n      -177.7247\n      6.9\n      2014.0\n      6.129969\n      0.770031\n    \n    \n      4997\n      -23.0090\n      -177.2320\n      7.4\n      2013.0\n      6.648946\n      0.751054\n    \n    \n      11365\n      7.8810\n      91.9360\n      7.5\n      2010.0\n      6.759298\n      0.740702\n    \n    \n      3723\n      -20.5709\n      -70.4931\n      7.7\n      2014.0\n      6.991148\n      0.708852\n    \n    \n      490\n      -3.4870\n      100.0820\n      7.8\n      2010.0\n      7.092844\n      0.707156\n    \n    \n      11856\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.197441\n      0.702559\n    \n    \n      6443\n      -21.2220\n      -179.2870\n      5.6\n      2012.0\n      4.900729\n      0.699271\n    \n    \n      9598\n      36.5690\n      141.4860\n      6.2\n      2011.0\n      5.502811\n      0.697189\n    \n    \n      5137\n      30.3080\n      102.8880\n      6.6\n      2013.0\n      5.904218\n      0.695782\n    \n    \n      7772\n      -28.9930\n      -176.2380\n      7.4\n      2011.0\n      6.711309\n      0.688691\n    \n    \n      4881\n      10.7010\n      -42.5940\n      6.6\n      2013.0\n      5.915735\n      0.684265\n    \n    \n      6940\n      -35.2000\n      -72.2170\n      7.1\n      2012.0\n      6.422078\n      0.677922\n    \n    \n      4816\n      -60.8570\n      -25.0700\n      7.3\n      2013.0\n      6.626735\n      0.673265\n    \n    \n      6963\n      16.4930\n      -98.2310\n      7.4\n      2012.0\n      6.727272\n      0.672728\n    \n    \n      8207\n      36.9420\n      140.9550\n      6.3\n      2011.0\n      5.644833\n      0.655167\n    \n    \n      9675\n      38.2970\n      142.3730\n      9.1\n      2011.0\n      8.452726\n      0.647274\n    \n    \n      163\n      26.9010\n      143.6980\n      7.4\n      2010.0\n      6.758782\n      0.641218\n    \n    \n      7365\n      -10.6170\n      165.1600\n      6.4\n      2012.0\n      5.760128\n      0.639872\n    \n    \n      19\n      -19.6610\n      168.1400\n      6.4\n      2010.0\n      5.761124\n      0.638876\n    \n    \n      7739\n      -17.9410\n      -179.5310\n      6.0\n      2011.0\n      5.361437\n      0.638563\n    \n    \n      8787\n      -20.1290\n      168.2570\n      5.3\n      2011.0\n      4.674700\n      0.625300\n    \n    \n      5447\n      -10.9940\n      165.7410\n      6.6\n      2013.0\n      5.975600\n      0.624400\n    \n    \n      8094\n      -18.3650\n      168.1430\n      7.2\n      2011.0\n      6.578651\n      0.621349\n    \n    \n      2699\n      -19.6903\n      -177.7587\n      7.1\n      2014.0\n      6.485400\n      0.614600\n    \n    \n      1751\n      -34.3260\n      -71.7990\n      7.0\n      2010.0\n      6.386349\n      0.613651\n    \n    \n      12429\n      18.4430\n      -72.5710\n      7.0\n      2010.0\n      6.386632\n      0.613368\n    \n    \n      6307\n      2.1900\n      126.8370\n      6.6\n      2012.0\n      5.993919\n      0.606081\n    \n    \n      9366\n      40.0820\n      143.2020\n      5.7\n      2011.0\n      5.096812\n      0.603188\n    \n    \n      9867\n      -7.1540\n      155.1840\n      6.4\n      2011.0\n      5.798634\n      0.601366\n    \n    \n      1753\n      -34.2900\n      -71.8910\n      6.9\n      2010.0\n      6.310787\n      0.589213\n    \n    \n      9050\n      -16.5410\n      -177.5170\n      6.3\n      2011.0\n      5.717719\n      0.582281\n    \n    \n      11823\n      -37.5510\n      -73.4650\n      5.8\n      2010.0\n      5.219236\n      0.580764\n    \n  \n\n\n\n\n\noutlier_simul_one = (_df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 0.04 else 1,outlier_simul_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one)],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n    \n  \n\n12498 rows Ã— 8 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_simul_one,tab_gode)\n\n\n_conf.conf(\"GODE\")\n\n\none = _conf.tab\n\n\n\nLOF\n\nclf = LocalOutlierFactor(n_neighbors=2)\n\n\nlof_rst = clf.fit_predict(_df)\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n    \n  \n\n12498 rows Ã— 9 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)\n\n\n_conf.conf(\"LOF (Breunig et al., 2000)\")\n\n\ntwo = one.append(_conf.tab)\n\n\n\nKNN\n\nclf = KNN()\nclf.fit(_df[['Latitude', 'Longitude','Magnitude']])\n# _df['knn_clf'] = clf.labels_\n\nKNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n  radius=1.0)\n\n\n\noutlier_KNN_one = list(clf.labels_)\n\n\noutlier_KNN_one = list(map(lambda x: 1 if x==0  else -1,outlier_KNN_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n    \n  \n\n12498 rows Ã— 10 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)\n\n\n_conf.conf(\"kNN (Ramaswamy et al., 2000)\")\n\n\nthree = two.append(_conf.tab)\n\n\n\nCBLOF\n\nclf = CBLOF(contamination=0.05,check_estimator=False, random_state=77)\nclf.fit(df_global_10[['Latitude', 'Longitude','Magnitude']])\ndf_global_10['CBLOF_Clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\noutlier_CBLOF_one = list(clf.labels_)\n\n\noutlier_CBLOF_one = list(map(lambda x: 1 if x==0  else -1,outlier_CBLOF_one))\n\n\noutlier_CBLOF_one_t = pd.DataFrame([outlier_CBLOF_one]).T.rename(columns={0:'CBLOF'});outlier_CBLOF_one_t\n\n\n\n\n\n  \n    \n      \n      CBLOF\n    \n  \n  \n    \n      0\n      1\n    \n    \n      1\n      1\n    \n    \n      2\n      1\n    \n    \n      3\n      1\n    \n    \n      4\n      1\n    \n    \n      ...\n      ...\n    \n    \n      12493\n      1\n    \n    \n      12494\n      1\n    \n    \n      12495\n      1\n    \n    \n      12496\n      1\n    \n    \n      12497\n      1\n    \n  \n\n12498 rows Ã— 1 columns\n\n\n\n\n# outlier_CBLOF_one_t.to_csv('outlier_CBLOF_one.csv',index=False)\n\n\n\nOCSVM\n\nclf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n\n\nclf.fit(_df)\n\nOneClassSVM(gamma=0.1, nu=0.1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneClassSVMOneClassSVM(gamma=0.1, nu=0.1)\n\n\n\noutlier_OSVM_one = list(clf.predict(_df))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n    \n  \n\n12498 rows Ã— 11 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)\n\n\n_conf.conf(\"OCSVM (Sch Ìˆolkopf et al., 2001)\")\n\n\nfive = four.append(_conf.tab)\n\n\n\nMCD\n\nclf = MCD()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['MCD_clf'] = clf.labels_\n\nMCD(assume_centered=False, contamination=0.1, random_state=None,\n  store_precision=True, support_fraction=None)\n\n\n\noutlier_MCD_one = list(clf.labels_)\n\n\noutlier_MCD_one = list(map(lambda x: 1 if x==0  else -1,outlier_MCD_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n    \n  \n\n12498 rows Ã— 12 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)\n\n\n_conf.conf(\"MCD (Hardin and Rocke, 2004)\")\n\n\nsix = five.append(_conf.tab)\n\n\n\nFeature Bagging\n\nclf = FeatureBagging()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['FeatureBagging_clf'] = clf.labels_\n\nFeatureBagging(base_estimator=None, bootstrap_features=False,\n        check_detector=True, check_estimator=False, combination='average',\n        contamination=0.1, estimator_params={}, max_features=1.0,\n        n_estimators=10, n_jobs=1, random_state=None, verbose=0)\n\n\n\noutlier_FeatureBagging_one = list(clf.labels_)\n\n\noutlier_FeatureBagging_one = list(map(lambda x: 1 if x==0  else -1,outlier_FeatureBagging_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 13 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)\n\n\n_conf.conf(\"Feature Bagging (Lazarevic and Kumar, 2005)\")\n\n\nseven = six.append(_conf.tab)\n\n\n\nABOD\n\nclf = ABOD(contamination=0.05)\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['ABOD_Clf'] = clf.labels_\n\nABOD(contamination=0.05, method='fast', n_neighbors=5)\n\n\n\noutlier_ABOD_one = list(clf.labels_)\n\n\noutlier_ABOD_one = list(map(lambda x: 1 if x==0  else -1,outlier_ABOD_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 14 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)\n\n\n_conf.conf(\"ABOD (Kriegel et al., 2008)\")\n\n\neight = seven.append(_conf.tab)\n\n\n\nIForest\n\nod = IForest(\n    threshold=0.,\n    n_estimators=100\n)\n\n\nod.fit(_df[['Latitude','Longitude','Magnitude']])\n\n\npreds = od.predict(\n    _df[['Latitude','Longitude','Magnitude']],\n    return_instance_score=True\n)\n\n\n# _df['IF_alibi'] = preds['data']['is_outlier']\n\n\n# outlier_alibi_one = _df['IF_alibi']\noutlier_alibi_one = preds['data']['is_outlier']\n\n\noutlier_alibi_one = list(map(lambda x: 1 if x==0  else -1,outlier_alibi_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 15 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)\n\n\n_conf.conf(\"Isolation Forest (Liu et al., 2008)\")\n\n\nnine = eight.append(_conf.tab)\n\n\n\nHBOS\n\nclf = HBOS()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['HBOS_clf'] = clf.labels_\n\nHBOS(alpha=0.1, contamination=0.1, n_bins=10, tol=0.5)\n\n\n\noutlier_HBOS_one = list(clf.labels_)\n\n\noutlier_HBOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_HBOS_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 16 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)\n\n\n_conf.conf(\"HBOS (Goldstein and Dengel, 2012)\")\n\n\nten = nine.append(_conf.tab)\n\n\n\nSOS\n\noutlier_SOS_one = list(clf.labels_)\n\n\noutlier_SOS_one = list(map(lambda x: 1 if x==0  else -1,outlier_SOS_one))\n\n\nclf = SOS()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['SOS_clf'] = clf.labels_\n\nSOS(contamination=0.1, eps=1e-05, metric='euclidean', perplexity=4.5)\n\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 17 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)\n\n\n_conf.conf(\"SOS (Janssens et al., 2012)\")\n\n\neleven = ten.append(_conf.tab)\n\n\n\nSO_GAAL\n\nclf = SO_GAAL()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['SO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\n\nTesting for epoch 1 index 2:\n\nTesting for epoch 1 index 3:\n\nTesting for epoch 1 index 4:\n\nTesting for epoch 1 index 5:\n\nTesting for epoch 1 index 6:\n\nTesting for epoch 1 index 7:\n\nTesting for epoch 1 index 8:\n\nTesting for epoch 1 index 9:\n\nTesting for epoch 1 index 10:\n\nTesting for epoch 1 index 11:\n\nTesting for epoch 1 index 12:\n\nTesting for epoch 1 index 13:\n\nTesting for epoch 1 index 14:\n\nTesting for epoch 1 index 15:\n\nTesting for epoch 1 index 16:\n\nTesting for epoch 1 index 17:\n\nTesting for epoch 1 index 18:\n\nTesting for epoch 1 index 19:\n\nTesting for epoch 1 index 20:\n\nTesting for epoch 1 index 21:\n\nTesting for epoch 1 index 22:\n\nTesting for epoch 1 index 23:\n\nTesting for epoch 1 index 24:\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n\nTesting for epoch 2 index 2:\n\nTesting for epoch 2 index 3:\n\nTesting for epoch 2 index 4:\n\nTesting for epoch 2 index 5:\n\nTesting for epoch 2 index 6:\n\nTesting for epoch 2 index 7:\n\nTesting for epoch 2 index 8:\n\nTesting for epoch 2 index 9:\n\nTesting for epoch 2 index 10:\n\nTesting for epoch 2 index 11:\n\nTesting for epoch 2 index 12:\n\nTesting for epoch 2 index 13:\n\nTesting for epoch 2 index 14:\n\nTesting for epoch 2 index 15:\n\nTesting for epoch 2 index 16:\n\nTesting for epoch 2 index 17:\n\nTesting for epoch 2 index 18:\n\nTesting for epoch 2 index 19:\n\nTesting for epoch 2 index 20:\n\nTesting for epoch 2 index 21:\n\nTesting for epoch 2 index 22:\n\nTesting for epoch 2 index 23:\n\nTesting for epoch 2 index 24:\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n\nTesting for epoch 3 index 2:\n\nTesting for epoch 3 index 3:\n\nTesting for epoch 3 index 4:\n\nTesting for epoch 3 index 5:\n\nTesting for epoch 3 index 6:\n\nTesting for epoch 3 index 7:\n\nTesting for epoch 3 index 8:\n\nTesting for epoch 3 index 9:\n\nTesting for epoch 3 index 10:\n\nTesting for epoch 3 index 11:\n\nTesting for epoch 3 index 12:\n\nTesting for epoch 3 index 13:\n\nTesting for epoch 3 index 14:\n\nTesting for epoch 3 index 15:\n\nTesting for epoch 3 index 16:\n\nTesting for epoch 3 index 17:\n\nTesting for epoch 3 index 18:\n\nTesting for epoch 3 index 19:\n\nTesting for epoch 3 index 20:\n\nTesting for epoch 3 index 21:\n\nTesting for epoch 3 index 22:\n\nTesting for epoch 3 index 23:\n\nTesting for epoch 3 index 24:\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n\nTesting for epoch 4 index 2:\n\nTesting for epoch 4 index 3:\n\nTesting for epoch 4 index 4:\n\nTesting for epoch 4 index 5:\n\nTesting for epoch 4 index 6:\n\nTesting for epoch 4 index 7:\n\nTesting for epoch 4 index 8:\n\nTesting for epoch 4 index 9:\n\nTesting for epoch 4 index 10:\n\nTesting for epoch 4 index 11:\n\nTesting for epoch 4 index 12:\n\nTesting for epoch 4 index 13:\n\nTesting for epoch 4 index 14:\n\nTesting for epoch 4 index 15:\n\nTesting for epoch 4 index 16:\n\nTesting for epoch 4 index 17:\n\nTesting for epoch 4 index 18:\n\nTesting for epoch 4 index 19:\n\nTesting for epoch 4 index 20:\n\nTesting for epoch 4 index 21:\n\nTesting for epoch 4 index 22:\n\nTesting for epoch 4 index 23:\n\nTesting for epoch 4 index 24:\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n\nTesting for epoch 5 index 2:\n\nTesting for epoch 5 index 3:\n\nTesting for epoch 5 index 4:\n\nTesting for epoch 5 index 5:\n\nTesting for epoch 5 index 6:\n\nTesting for epoch 5 index 7:\n\nTesting for epoch 5 index 8:\n\nTesting for epoch 5 index 9:\n\nTesting for epoch 5 index 10:\n\nTesting for epoch 5 index 11:\n\nTesting for epoch 5 index 12:\n\nTesting for epoch 5 index 13:\n\nTesting for epoch 5 index 14:\n\nTesting for epoch 5 index 15:\n\nTesting for epoch 5 index 16:\n\nTesting for epoch 5 index 17:\n\nTesting for epoch 5 index 18:\n\nTesting for epoch 5 index 19:\n\nTesting for epoch 5 index 20:\n\nTesting for epoch 5 index 21:\n\nTesting for epoch 5 index 22:\n\nTesting for epoch 5 index 23:\n\nTesting for epoch 5 index 24:\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n\nTesting for epoch 6 index 2:\n\nTesting for epoch 6 index 3:\n\nTesting for epoch 6 index 4:\n\nTesting for epoch 6 index 5:\n\nTesting for epoch 6 index 6:\n\nTesting for epoch 6 index 7:\n\nTesting for epoch 6 index 8:\n\nTesting for epoch 6 index 9:\n\nTesting for epoch 6 index 10:\n\nTesting for epoch 6 index 11:\n\nTesting for epoch 6 index 12:\n\nTesting for epoch 6 index 13:\n\nTesting for epoch 6 index 14:\n\nTesting for epoch 6 index 15:\n\nTesting for epoch 6 index 16:\n\nTesting for epoch 6 index 17:\n\nTesting for epoch 6 index 18:\n\nTesting for epoch 6 index 19:\n\nTesting for epoch 6 index 20:\n\nTesting for epoch 6 index 21:\n\nTesting for epoch 6 index 22:\n\nTesting for epoch 6 index 23:\n\nTesting for epoch 6 index 24:\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n\nTesting for epoch 7 index 2:\n\nTesting for epoch 7 index 3:\n\nTesting for epoch 7 index 4:\n\nTesting for epoch 7 index 5:\n\nTesting for epoch 7 index 6:\n\nTesting for epoch 7 index 7:\n\nTesting for epoch 7 index 8:\n\nTesting for epoch 7 index 9:\n\nTesting for epoch 7 index 10:\n\nTesting for epoch 7 index 11:\n\nTesting for epoch 7 index 12:\n\nTesting for epoch 7 index 13:\n\nTesting for epoch 7 index 14:\n\nTesting for epoch 7 index 15:\n\nTesting for epoch 7 index 16:\n\nTesting for epoch 7 index 17:\n\nTesting for epoch 7 index 18:\n\nTesting for epoch 7 index 19:\n\nTesting for epoch 7 index 20:\n\nTesting for epoch 7 index 21:\n\nTesting for epoch 7 index 22:\n\nTesting for epoch 7 index 23:\n\nTesting for epoch 7 index 24:\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n\nTesting for epoch 8 index 2:\n\nTesting for epoch 8 index 3:\n\nTesting for epoch 8 index 4:\n\nTesting for epoch 8 index 5:\n\nTesting for epoch 8 index 6:\n\nTesting for epoch 8 index 7:\n\nTesting for epoch 8 index 8:\n\nTesting for epoch 8 index 9:\n\nTesting for epoch 8 index 10:\n\nTesting for epoch 8 index 11:\n\nTesting for epoch 8 index 12:\n\nTesting for epoch 8 index 13:\n\nTesting for epoch 8 index 14:\n\nTesting for epoch 8 index 15:\n\nTesting for epoch 8 index 16:\n\nTesting for epoch 8 index 17:\n\nTesting for epoch 8 index 18:\n\nTesting for epoch 8 index 19:\n\nTesting for epoch 8 index 20:\n\nTesting for epoch 8 index 21:\n\nTesting for epoch 8 index 22:\n\nTesting for epoch 8 index 23:\n\nTesting for epoch 8 index 24:\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n\nTesting for epoch 9 index 2:\n\nTesting for epoch 9 index 3:\n\nTesting for epoch 9 index 4:\n\nTesting for epoch 9 index 5:\n\nTesting for epoch 9 index 6:\n\nTesting for epoch 9 index 7:\n\nTesting for epoch 9 index 8:\n\nTesting for epoch 9 index 9:\n\nTesting for epoch 9 index 10:\n\nTesting for epoch 9 index 11:\n\nTesting for epoch 9 index 12:\n\nTesting for epoch 9 index 13:\n\nTesting for epoch 9 index 14:\n\nTesting for epoch 9 index 15:\n\nTesting for epoch 9 index 16:\n\nTesting for epoch 9 index 17:\n\nTesting for epoch 9 index 18:\n\nTesting for epoch 9 index 19:\n\nTesting for epoch 9 index 20:\n\nTesting for epoch 9 index 21:\n\nTesting for epoch 9 index 22:\n\nTesting for epoch 9 index 23:\n\nTesting for epoch 9 index 24:\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n\nTesting for epoch 10 index 2:\n\nTesting for epoch 10 index 3:\n\nTesting for epoch 10 index 4:\n\nTesting for epoch 10 index 5:\n\nTesting for epoch 10 index 6:\n\nTesting for epoch 10 index 7:\n\nTesting for epoch 10 index 8:\n\nTesting for epoch 10 index 9:\n\nTesting for epoch 10 index 10:\n\nTesting for epoch 10 index 11:\n\nTesting for epoch 10 index 12:\n\nTesting for epoch 10 index 13:\n\nTesting for epoch 10 index 14:\n\nTesting for epoch 10 index 15:\n\nTesting for epoch 10 index 16:\n\nTesting for epoch 10 index 17:\n\nTesting for epoch 10 index 18:\n\nTesting for epoch 10 index 19:\n\nTesting for epoch 10 index 20:\n\nTesting for epoch 10 index 21:\n\nTesting for epoch 10 index 22:\n\nTesting for epoch 10 index 23:\n\nTesting for epoch 10 index 24:\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n\nTesting for epoch 11 index 2:\n\nTesting for epoch 11 index 3:\n\nTesting for epoch 11 index 4:\n\nTesting for epoch 11 index 5:\n\nTesting for epoch 11 index 6:\n\nTesting for epoch 11 index 7:\n\nTesting for epoch 11 index 8:\n\nTesting for epoch 11 index 9:\n\nTesting for epoch 11 index 10:\n\nTesting for epoch 11 index 11:\n\nTesting for epoch 11 index 12:\n\nTesting for epoch 11 index 13:\n\nTesting for epoch 11 index 14:\n\nTesting for epoch 11 index 15:\n\nTesting for epoch 11 index 16:\n\nTesting for epoch 11 index 17:\n\nTesting for epoch 11 index 18:\n\nTesting for epoch 11 index 19:\n\nTesting for epoch 11 index 20:\n\nTesting for epoch 11 index 21:\n\nTesting for epoch 11 index 22:\n\nTesting for epoch 11 index 23:\n\nTesting for epoch 11 index 24:\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n\nTesting for epoch 12 index 2:\n\nTesting for epoch 12 index 3:\n\nTesting for epoch 12 index 4:\n\nTesting for epoch 12 index 5:\n\nTesting for epoch 12 index 6:\n\nTesting for epoch 12 index 7:\n\nTesting for epoch 12 index 8:\n\nTesting for epoch 12 index 9:\n\nTesting for epoch 12 index 10:\n\nTesting for epoch 12 index 11:\n\nTesting for epoch 12 index 12:\n\nTesting for epoch 12 index 13:\n\nTesting for epoch 12 index 14:\n\nTesting for epoch 12 index 15:\n\nTesting for epoch 12 index 16:\n\nTesting for epoch 12 index 17:\n\nTesting for epoch 12 index 18:\n\nTesting for epoch 12 index 19:\n\nTesting for epoch 12 index 20:\n\nTesting for epoch 12 index 21:\n\nTesting for epoch 12 index 22:\n\nTesting for epoch 12 index 23:\n\nTesting for epoch 12 index 24:\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n\nTesting for epoch 13 index 2:\n\nTesting for epoch 13 index 3:\n\nTesting for epoch 13 index 4:\n\nTesting for epoch 13 index 5:\n\nTesting for epoch 13 index 6:\n\nTesting for epoch 13 index 7:\n\nTesting for epoch 13 index 8:\n\nTesting for epoch 13 index 9:\n\nTesting for epoch 13 index 10:\n\nTesting for epoch 13 index 11:\n\nTesting for epoch 13 index 12:\n\nTesting for epoch 13 index 13:\n\nTesting for epoch 13 index 14:\n\nTesting for epoch 13 index 15:\n\nTesting for epoch 13 index 16:\n\nTesting for epoch 13 index 17:\n\nTesting for epoch 13 index 18:\n\nTesting for epoch 13 index 19:\n\nTesting for epoch 13 index 20:\n\nTesting for epoch 13 index 21:\n\nTesting for epoch 13 index 22:\n\nTesting for epoch 13 index 23:\n\nTesting for epoch 13 index 24:\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n\nTesting for epoch 14 index 2:\n\nTesting for epoch 14 index 3:\n\nTesting for epoch 14 index 4:\n\nTesting for epoch 14 index 5:\n\nTesting for epoch 14 index 6:\n\nTesting for epoch 14 index 7:\n\nTesting for epoch 14 index 8:\n\nTesting for epoch 14 index 9:\n\nTesting for epoch 14 index 10:\n\nTesting for epoch 14 index 11:\n\nTesting for epoch 14 index 12:\n\nTesting for epoch 14 index 13:\n\nTesting for epoch 14 index 14:\n\nTesting for epoch 14 index 15:\n\nTesting for epoch 14 index 16:\n\nTesting for epoch 14 index 17:\n\nTesting for epoch 14 index 18:\n\nTesting for epoch 14 index 19:\n\nTesting for epoch 14 index 20:\n\nTesting for epoch 14 index 21:\n\nTesting for epoch 14 index 22:\n\nTesting for epoch 14 index 23:\n\nTesting for epoch 14 index 24:\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n\nTesting for epoch 15 index 2:\n\nTesting for epoch 15 index 3:\n\nTesting for epoch 15 index 4:\n\nTesting for epoch 15 index 5:\n\nTesting for epoch 15 index 6:\n\nTesting for epoch 15 index 7:\n\nTesting for epoch 15 index 8:\n\nTesting for epoch 15 index 9:\n\nTesting for epoch 15 index 10:\n\nTesting for epoch 15 index 11:\n\nTesting for epoch 15 index 12:\n\nTesting for epoch 15 index 13:\n\nTesting for epoch 15 index 14:\n\nTesting for epoch 15 index 15:\n\nTesting for epoch 15 index 16:\n\nTesting for epoch 15 index 17:\n\nTesting for epoch 15 index 18:\n\nTesting for epoch 15 index 19:\n\nTesting for epoch 15 index 20:\n\nTesting for epoch 15 index 21:\n\nTesting for epoch 15 index 22:\n\nTesting for epoch 15 index 23:\n\nTesting for epoch 15 index 24:\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n\nTesting for epoch 16 index 2:\n\nTesting for epoch 16 index 3:\n\nTesting for epoch 16 index 4:\n\nTesting for epoch 16 index 5:\n\nTesting for epoch 16 index 6:\n\nTesting for epoch 16 index 7:\n\nTesting for epoch 16 index 8:\n\nTesting for epoch 16 index 9:\n\nTesting for epoch 16 index 10:\n\nTesting for epoch 16 index 11:\n\nTesting for epoch 16 index 12:\n\nTesting for epoch 16 index 13:\n\nTesting for epoch 16 index 14:\n\nTesting for epoch 16 index 15:\n\nTesting for epoch 16 index 16:\n\nTesting for epoch 16 index 17:\n\nTesting for epoch 16 index 18:\n\nTesting for epoch 16 index 19:\n\nTesting for epoch 16 index 20:\n\nTesting for epoch 16 index 21:\n\nTesting for epoch 16 index 22:\n\nTesting for epoch 16 index 23:\n\nTesting for epoch 16 index 24:\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n\nTesting for epoch 17 index 2:\n\nTesting for epoch 17 index 3:\n\nTesting for epoch 17 index 4:\n\nTesting for epoch 17 index 5:\n\nTesting for epoch 17 index 6:\n\nTesting for epoch 17 index 7:\n\nTesting for epoch 17 index 8:\n\nTesting for epoch 17 index 9:\n\nTesting for epoch 17 index 10:\n\nTesting for epoch 17 index 11:\n\nTesting for epoch 17 index 12:\n\nTesting for epoch 17 index 13:\n\nTesting for epoch 17 index 14:\n\nTesting for epoch 17 index 15:\n\nTesting for epoch 17 index 16:\n\nTesting for epoch 17 index 17:\n\nTesting for epoch 17 index 18:\n\nTesting for epoch 17 index 19:\n\nTesting for epoch 17 index 20:\n\nTesting for epoch 17 index 21:\n\nTesting for epoch 17 index 22:\n\nTesting for epoch 17 index 23:\n\nTesting for epoch 17 index 24:\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n\nTesting for epoch 18 index 2:\n\nTesting for epoch 18 index 3:\n\nTesting for epoch 18 index 4:\n\nTesting for epoch 18 index 5:\n\nTesting for epoch 18 index 6:\n\nTesting for epoch 18 index 7:\n\nTesting for epoch 18 index 8:\n\nTesting for epoch 18 index 9:\n\nTesting for epoch 18 index 10:\n\nTesting for epoch 18 index 11:\n\nTesting for epoch 18 index 12:\n\nTesting for epoch 18 index 13:\n\nTesting for epoch 18 index 14:\n\nTesting for epoch 18 index 15:\n\nTesting for epoch 18 index 16:\n\nTesting for epoch 18 index 17:\n\nTesting for epoch 18 index 18:\n\nTesting for epoch 18 index 19:\n\nTesting for epoch 18 index 20:\n\nTesting for epoch 18 index 21:\n\nTesting for epoch 18 index 22:\n\nTesting for epoch 18 index 23:\n\nTesting for epoch 18 index 24:\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n\nTesting for epoch 19 index 2:\n\nTesting for epoch 19 index 3:\n\nTesting for epoch 19 index 4:\n\nTesting for epoch 19 index 5:\n\nTesting for epoch 19 index 6:\n\nTesting for epoch 19 index 7:\n\nTesting for epoch 19 index 8:\n\nTesting for epoch 19 index 9:\n\nTesting for epoch 19 index 10:\n\nTesting for epoch 19 index 11:\n\nTesting for epoch 19 index 12:\n\nTesting for epoch 19 index 13:\n\nTesting for epoch 19 index 14:\n\nTesting for epoch 19 index 15:\n\nTesting for epoch 19 index 16:\n\nTesting for epoch 19 index 17:\n\nTesting for epoch 19 index 18:\n\nTesting for epoch 19 index 19:\n\nTesting for epoch 19 index 20:\n\nTesting for epoch 19 index 21:\n\nTesting for epoch 19 index 22:\n\nTesting for epoch 19 index 23:\n\nTesting for epoch 19 index 24:\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n\nTesting for epoch 20 index 2:\n\nTesting for epoch 20 index 3:\n\nTesting for epoch 20 index 4:\n\nTesting for epoch 20 index 5:\n\nTesting for epoch 20 index 6:\n\nTesting for epoch 20 index 7:\n\nTesting for epoch 20 index 8:\n\nTesting for epoch 20 index 9:\n\nTesting for epoch 20 index 10:\n\nTesting for epoch 20 index 11:\n\nTesting for epoch 20 index 12:\n\nTesting for epoch 20 index 13:\n\nTesting for epoch 20 index 14:\n\nTesting for epoch 20 index 15:\n\nTesting for epoch 20 index 16:\n\nTesting for epoch 20 index 17:\n\nTesting for epoch 20 index 18:\n\nTesting for epoch 20 index 19:\n\nTesting for epoch 20 index 20:\n\nTesting for epoch 20 index 21:\n\nTesting for epoch 20 index 22:\n\nTesting for epoch 20 index 23:\n\nTesting for epoch 20 index 24:\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n\nTesting for epoch 21 index 2:\n\nTesting for epoch 21 index 3:\n\nTesting for epoch 21 index 4:\n\nTesting for epoch 21 index 5:\n\nTesting for epoch 21 index 6:\n\nTesting for epoch 21 index 7:\n\nTesting for epoch 21 index 8:\n\nTesting for epoch 21 index 9:\n\nTesting for epoch 21 index 10:\n\nTesting for epoch 21 index 11:\n\nTesting for epoch 21 index 12:\n\nTesting for epoch 21 index 13:\n\nTesting for epoch 21 index 14:\n\nTesting for epoch 21 index 15:\n\nTesting for epoch 21 index 16:\n\nTesting for epoch 21 index 17:\n\nTesting for epoch 21 index 18:\n\nTesting for epoch 21 index 19:\n\nTesting for epoch 21 index 20:\n\nTesting for epoch 21 index 21:\n\nTesting for epoch 21 index 22:\n\nTesting for epoch 21 index 23:\n\nTesting for epoch 21 index 24:\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8535\n\nTesting for epoch 22 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8579\n\nTesting for epoch 22 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8627\n\nTesting for epoch 22 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8612\n\nTesting for epoch 22 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8499\n\nTesting for epoch 22 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8604\n\nTesting for epoch 22 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8870\n\nTesting for epoch 22 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 4.8985\n\nTesting for epoch 22 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8793\n\nTesting for epoch 22 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 4.8671\n\nTesting for epoch 22 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8616\n\nTesting for epoch 22 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8623\n\nTesting for epoch 22 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8959\n\nTesting for epoch 22 index 14:\n16/16 [==============================] - 0s 5ms/step - loss: 4.8903\n\nTesting for epoch 22 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8863\n\nTesting for epoch 22 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9047\n\nTesting for epoch 22 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8914\n\nTesting for epoch 22 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9103\n\nTesting for epoch 22 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8898\n\nTesting for epoch 22 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 4.8972\n\nTesting for epoch 22 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9112\n\nTesting for epoch 22 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 4.8815\n\nTesting for epoch 22 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9102\n\nTesting for epoch 22 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9271\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9269\n\nTesting for epoch 23 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9297\n\nTesting for epoch 23 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9328\n\nTesting for epoch 23 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9300\n\nTesting for epoch 23 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 4.9258\n\nTesting for epoch 23 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9478\n\nTesting for epoch 23 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9551\n\nTesting for epoch 23 index 8:\n16/16 [==============================] - 0s 6ms/step - loss: 4.9404\n\nTesting for epoch 23 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9310\n\nTesting for epoch 23 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9559\n\nTesting for epoch 23 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9254\n\nTesting for epoch 23 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9674\n\nTesting for epoch 23 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9145\n\nTesting for epoch 23 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9604\n\nTesting for epoch 23 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9518\n\nTesting for epoch 23 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9819\n\nTesting for epoch 23 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9684\n\nTesting for epoch 23 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 4.9730\n\nTesting for epoch 23 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 4.9850\n\nTesting for epoch 23 index 20:\n16/16 [==============================] - 0s 948us/step - loss: 4.9600\n\nTesting for epoch 23 index 21:\n16/16 [==============================] - 0s 971us/step - loss: 4.9775\n\nTesting for epoch 23 index 22:\n16/16 [==============================] - 0s 973us/step - loss: 4.9805\n\nTesting for epoch 23 index 23:\n16/16 [==============================] - 0s 964us/step - loss: 4.9943\n\nTesting for epoch 23 index 24:\n16/16 [==============================] - 0s 964us/step - loss: 4.9783\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n16/16 [==============================] - 0s 924us/step - loss: 4.9912\n\nTesting for epoch 24 index 2:\n16/16 [==============================] - 0s 954us/step - loss: 5.0385\n\nTesting for epoch 24 index 3:\n16/16 [==============================] - 0s 965us/step - loss: 5.0175\n\nTesting for epoch 24 index 4:\n16/16 [==============================] - 0s 948us/step - loss: 4.9888\n\nTesting for epoch 24 index 5:\n16/16 [==============================] - 0s 942us/step - loss: 4.9810\n\nTesting for epoch 24 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0312\n\nTesting for epoch 24 index 7:\n16/16 [==============================] - 0s 873us/step - loss: 5.0304\n\nTesting for epoch 24 index 8:\n16/16 [==============================] - 0s 988us/step - loss: 5.0057\n\nTesting for epoch 24 index 9:\n16/16 [==============================] - 0s 924us/step - loss: 5.0251\n\nTesting for epoch 24 index 10:\n16/16 [==============================] - 0s 963us/step - loss: 5.0155\n\nTesting for epoch 24 index 11:\n16/16 [==============================] - 0s 975us/step - loss: 5.0163\n\nTesting for epoch 24 index 12:\n16/16 [==============================] - 0s 941us/step - loss: 5.0397\n\nTesting for epoch 24 index 13:\n16/16 [==============================] - 0s 901us/step - loss: 5.0455\n\nTesting for epoch 24 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0304\n\nTesting for epoch 24 index 15:\n16/16 [==============================] - 0s 878us/step - loss: 5.0359\n\nTesting for epoch 24 index 16:\n16/16 [==============================] - 0s 900us/step - loss: 5.0382\n\nTesting for epoch 24 index 17:\n16/16 [==============================] - 0s 880us/step - loss: 5.0440\n\nTesting for epoch 24 index 18:\n16/16 [==============================] - 0s 916us/step - loss: 5.0342\n\nTesting for epoch 24 index 19:\n16/16 [==============================] - 0s 921us/step - loss: 5.0470\n\nTesting for epoch 24 index 20:\n16/16 [==============================] - 0s 853us/step - loss: 5.0636\n\nTesting for epoch 24 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0384\n\nTesting for epoch 24 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0632\n\nTesting for epoch 24 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0551\n\nTesting for epoch 24 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0674\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0658\n\nTesting for epoch 25 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0720\n\nTesting for epoch 25 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 5.0970\n\nTesting for epoch 25 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1021\n\nTesting for epoch 25 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0690\n\nTesting for epoch 25 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0667\n\nTesting for epoch 25 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.0819\n\nTesting for epoch 25 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.0758\n\nTesting for epoch 25 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1001\n\nTesting for epoch 25 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1026\n\nTesting for epoch 25 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0995\n\nTesting for epoch 25 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0909\n\nTesting for epoch 25 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0748\n\nTesting for epoch 25 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1088\n\nTesting for epoch 25 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1024\n\nTesting for epoch 25 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1040\n\nTesting for epoch 25 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1178\n\nTesting for epoch 25 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1198\n\nTesting for epoch 25 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1089\n\nTesting for epoch 25 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1391\n\nTesting for epoch 25 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1187\n\nTesting for epoch 25 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.0872\n\nTesting for epoch 25 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1059\n\nTesting for epoch 25 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1363\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1288\n\nTesting for epoch 26 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1096\n\nTesting for epoch 26 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1230\n\nTesting for epoch 26 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1359\n\nTesting for epoch 26 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1324\n\nTesting for epoch 26 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1345\n\nTesting for epoch 26 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1585\n\nTesting for epoch 26 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1325\n\nTesting for epoch 26 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1634\n\nTesting for epoch 26 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1488\n\nTesting for epoch 26 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1563\n\nTesting for epoch 26 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1734\n\nTesting for epoch 26 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1643\n\nTesting for epoch 26 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1657\n\nTesting for epoch 26 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1636\n\nTesting for epoch 26 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1958\n\nTesting for epoch 26 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1432\n\nTesting for epoch 26 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1720\n\nTesting for epoch 26 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1909\n\nTesting for epoch 26 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.1622\n\nTesting for epoch 26 index 21:\n16/16 [==============================] - 0s 988us/step - loss: 5.1711\n\nTesting for epoch 26 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2015\n\nTesting for epoch 26 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1616\n\nTesting for epoch 26 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1611\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1688\n\nTesting for epoch 27 index 2:\n16/16 [==============================] - 0s 973us/step - loss: 5.1927\n\nTesting for epoch 27 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1881\n\nTesting for epoch 27 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2126\n\nTesting for epoch 27 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2083\n\nTesting for epoch 27 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.1934\n\nTesting for epoch 27 index 7:\n16/16 [==============================] - 0s 736us/step - loss: 5.1712\n\nTesting for epoch 27 index 8:\n16/16 [==============================] - 0s 886us/step - loss: 5.2049\n\nTesting for epoch 27 index 9:\n16/16 [==============================] - 0s 910us/step - loss: 5.2330\n\nTesting for epoch 27 index 10:\n16/16 [==============================] - 0s 896us/step - loss: 5.2123\n\nTesting for epoch 27 index 11:\n16/16 [==============================] - 0s 831us/step - loss: 5.2265\n\nTesting for epoch 27 index 12:\n16/16 [==============================] - 0s 912us/step - loss: 5.1898\n\nTesting for epoch 27 index 13:\n16/16 [==============================] - 0s 917us/step - loss: 5.2358\n\nTesting for epoch 27 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2279\n\nTesting for epoch 27 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2258\n\nTesting for epoch 27 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2379\n\nTesting for epoch 27 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2032\n\nTesting for epoch 27 index 18:\n16/16 [==============================] - 0s 923us/step - loss: 5.2329\n\nTesting for epoch 27 index 19:\n16/16 [==============================] - 0s 876us/step - loss: 5.2238\n\nTesting for epoch 27 index 20:\n16/16 [==============================] - 0s 845us/step - loss: 5.2310\n\nTesting for epoch 27 index 21:\n16/16 [==============================] - 0s 866us/step - loss: 5.2555\n\nTesting for epoch 27 index 22:\n16/16 [==============================] - 0s 865us/step - loss: 5.2506\n\nTesting for epoch 27 index 23:\n16/16 [==============================] - 0s 861us/step - loss: 5.2298\n\nTesting for epoch 27 index 24:\n16/16 [==============================] - 0s 899us/step - loss: 5.2571\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n16/16 [==============================] - 0s 885us/step - loss: 5.2601\n\nTesting for epoch 28 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2272\n\nTesting for epoch 28 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2099\n\nTesting for epoch 28 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2475\n\nTesting for epoch 28 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2595\n\nTesting for epoch 28 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2686\n\nTesting for epoch 28 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2621\n\nTesting for epoch 28 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2553\n\nTesting for epoch 28 index 9:\n16/16 [==============================] - 0s 3ms/step - loss: 5.2640\n\nTesting for epoch 28 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2939\n\nTesting for epoch 28 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2480\n\nTesting for epoch 28 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2600\n\nTesting for epoch 28 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2769\n\nTesting for epoch 28 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2909\n\nTesting for epoch 28 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3053\n\nTesting for epoch 28 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2796\n\nTesting for epoch 28 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3058\n\nTesting for epoch 28 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2567\n\nTesting for epoch 28 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3181\n\nTesting for epoch 28 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2960\n\nTesting for epoch 28 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3114\n\nTesting for epoch 28 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3035\n\nTesting for epoch 28 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2829\n\nTesting for epoch 28 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3213\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3131\n\nTesting for epoch 29 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.2918\n\nTesting for epoch 29 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3130\n\nTesting for epoch 29 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3074\n\nTesting for epoch 29 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3050\n\nTesting for epoch 29 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3056\n\nTesting for epoch 29 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3180\n\nTesting for epoch 29 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3132\n\nTesting for epoch 29 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3342\n\nTesting for epoch 29 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3181\n\nTesting for epoch 29 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3207\n\nTesting for epoch 29 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3322\n\nTesting for epoch 29 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3407\n\nTesting for epoch 29 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.2953\n\nTesting for epoch 29 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3182\n\nTesting for epoch 29 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3612\n\nTesting for epoch 29 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3317\n\nTesting for epoch 29 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3261\n\nTesting for epoch 29 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3377\n\nTesting for epoch 29 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3426\n\nTesting for epoch 29 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3247\n\nTesting for epoch 29 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3645\n\nTesting for epoch 29 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3567\n\nTesting for epoch 29 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3648\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3892\n\nTesting for epoch 30 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.3744\n\nTesting for epoch 30 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3550\n\nTesting for epoch 30 index 4:\n16/16 [==============================] - 0s 4ms/step - loss: 5.3625\n\nTesting for epoch 30 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3735\n\nTesting for epoch 30 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3469\n\nTesting for epoch 30 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3726\n\nTesting for epoch 30 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3694\n\nTesting for epoch 30 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3997\n\nTesting for epoch 30 index 10:\n16/16 [==============================] - 0s 954us/step - loss: 5.3930\n\nTesting for epoch 30 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3818\n\nTesting for epoch 30 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3895\n\nTesting for epoch 30 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3934\n\nTesting for epoch 30 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3513\n\nTesting for epoch 30 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.3578\n\nTesting for epoch 30 index 16:\n16/16 [==============================] - 0s 4ms/step - loss: 5.3932\n\nTesting for epoch 30 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3803\n\nTesting for epoch 30 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3644\n\nTesting for epoch 30 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3941\n\nTesting for epoch 30 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3916\n\nTesting for epoch 30 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4229\n\nTesting for epoch 30 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3823\n\nTesting for epoch 30 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.3990\n\nTesting for epoch 30 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4237\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4052\n\nTesting for epoch 31 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4002\n\nTesting for epoch 31 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4178\n\nTesting for epoch 31 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4004\n\nTesting for epoch 31 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4048\n\nTesting for epoch 31 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4361\n\nTesting for epoch 31 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4403\n\nTesting for epoch 31 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4431\n\nTesting for epoch 31 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4361\n\nTesting for epoch 31 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 5.4131\n\nTesting for epoch 31 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4242\n\nTesting for epoch 31 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4213\n\nTesting for epoch 31 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4208\n\nTesting for epoch 31 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4083\n\nTesting for epoch 31 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4338\n\nTesting for epoch 31 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4388\n\nTesting for epoch 31 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4298\n\nTesting for epoch 31 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4476\n\nTesting for epoch 31 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4494\n\nTesting for epoch 31 index 20:\n16/16 [==============================] - 0s 895us/step - loss: 5.4731\n\nTesting for epoch 31 index 21:\n16/16 [==============================] - 0s 977us/step - loss: 5.4403\n\nTesting for epoch 31 index 22:\n16/16 [==============================] - 0s 836us/step - loss: 5.4519\n\nTesting for epoch 31 index 23:\n16/16 [==============================] - 0s 921us/step - loss: 5.4354\n\nTesting for epoch 31 index 24:\n16/16 [==============================] - 0s 822us/step - loss: 5.4255\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n16/16 [==============================] - 0s 839us/step - loss: 5.4622\n\nTesting for epoch 32 index 2:\n16/16 [==============================] - 0s 864us/step - loss: 5.4706\n\nTesting for epoch 32 index 3:\n16/16 [==============================] - 0s 849us/step - loss: 5.4524\n\nTesting for epoch 32 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4741\n\nTesting for epoch 32 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4610\n\nTesting for epoch 32 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.4661\n\nTesting for epoch 32 index 7:\n16/16 [==============================] - 0s 889us/step - loss: 5.4742\n\nTesting for epoch 32 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4768\n\nTesting for epoch 32 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4899\n\nTesting for epoch 32 index 10:\n16/16 [==============================] - 0s 836us/step - loss: 5.4828\n\nTesting for epoch 32 index 11:\n16/16 [==============================] - 0s 957us/step - loss: 5.4510\n\nTesting for epoch 32 index 12:\n16/16 [==============================] - 0s 836us/step - loss: 5.4928\n\nTesting for epoch 32 index 13:\n16/16 [==============================] - 0s 829us/step - loss: 5.5070\n\nTesting for epoch 32 index 14:\n16/16 [==============================] - 0s 823us/step - loss: 5.5029\n\nTesting for epoch 32 index 15:\n16/16 [==============================] - 0s 854us/step - loss: 5.4948\n\nTesting for epoch 32 index 16:\n16/16 [==============================] - 0s 828us/step - loss: 5.4771\n\nTesting for epoch 32 index 17:\n16/16 [==============================] - 0s 882us/step - loss: 5.4984\n\nTesting for epoch 32 index 18:\n16/16 [==============================] - 0s 857us/step - loss: 5.5006\n\nTesting for epoch 32 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5135\n\nTesting for epoch 32 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4983\n\nTesting for epoch 32 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5173\n\nTesting for epoch 32 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.4870\n\nTesting for epoch 32 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5119\n\nTesting for epoch 32 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5019\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5101\n\nTesting for epoch 33 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.4904\n\nTesting for epoch 33 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.4961\n\nTesting for epoch 33 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5127\n\nTesting for epoch 33 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5139\n\nTesting for epoch 33 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5097\n\nTesting for epoch 33 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5135\n\nTesting for epoch 33 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5580\n\nTesting for epoch 33 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5463\n\nTesting for epoch 33 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5466\n\nTesting for epoch 33 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5086\n\nTesting for epoch 33 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n\nTesting for epoch 33 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5444\n\nTesting for epoch 33 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5245\n\nTesting for epoch 33 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5179\n\nTesting for epoch 33 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5350\n\nTesting for epoch 33 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5319\n\nTesting for epoch 33 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5096\n\nTesting for epoch 33 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5171\n\nTesting for epoch 33 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5487\n\nTesting for epoch 33 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5386\n\nTesting for epoch 33 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5608\n\nTesting for epoch 33 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5531\n\nTesting for epoch 33 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5569\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5679\n\nTesting for epoch 34 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5848\n\nTesting for epoch 34 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5654\n\nTesting for epoch 34 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5561\n\nTesting for epoch 34 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5359\n\nTesting for epoch 34 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5381\n\nTesting for epoch 34 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5742\n\nTesting for epoch 34 index 8:\n16/16 [==============================] - 0s 974us/step - loss: 5.5597\n\nTesting for epoch 34 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5576\n\nTesting for epoch 34 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5693\n\nTesting for epoch 34 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5456\n\nTesting for epoch 34 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5895\n\nTesting for epoch 34 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5786\n\nTesting for epoch 34 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6051\n\nTesting for epoch 34 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5843\n\nTesting for epoch 34 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5701\n\nTesting for epoch 34 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6106\n\nTesting for epoch 34 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6000\n\nTesting for epoch 34 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5551\n\nTesting for epoch 34 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5947\n\nTesting for epoch 34 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5761\n\nTesting for epoch 34 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5775\n\nTesting for epoch 34 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6234\n\nTesting for epoch 34 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5912\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5936\n\nTesting for epoch 35 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.5926\n\nTesting for epoch 35 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5801\n\nTesting for epoch 35 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6047\n\nTesting for epoch 35 index 5:\n16/16 [==============================] - 0s 5ms/step - loss: 5.6045\n\nTesting for epoch 35 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6162\n\nTesting for epoch 35 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5970\n\nTesting for epoch 35 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.5918\n\nTesting for epoch 35 index 9:\n16/16 [==============================] - 0s 984us/step - loss: 5.6380\n\nTesting for epoch 35 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6081\n\nTesting for epoch 35 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6398\n\nTesting for epoch 35 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5785\n\nTesting for epoch 35 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 5.5853\n\nTesting for epoch 35 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6186\n\nTesting for epoch 35 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6222\n\nTesting for epoch 35 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6164\n\nTesting for epoch 35 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6302\n\nTesting for epoch 35 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6211\n\nTesting for epoch 35 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6531\n\nTesting for epoch 35 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6420\n\nTesting for epoch 35 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6193\n\nTesting for epoch 35 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6251\n\nTesting for epoch 35 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6568\n\nTesting for epoch 35 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6580\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6132\n\nTesting for epoch 36 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6358\n\nTesting for epoch 36 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6630\n\nTesting for epoch 36 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6440\n\nTesting for epoch 36 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6226\n\nTesting for epoch 36 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6221\n\nTesting for epoch 36 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n\nTesting for epoch 36 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6482\n\nTesting for epoch 36 index 9:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6486\n\nTesting for epoch 36 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6605\n\nTesting for epoch 36 index 11:\n16/16 [==============================] - 0s 891us/step - loss: 5.6862\n\nTesting for epoch 36 index 12:\n16/16 [==============================] - 0s 909us/step - loss: 5.6638\n\nTesting for epoch 36 index 13:\n16/16 [==============================] - 0s 949us/step - loss: 5.6434\n\nTesting for epoch 36 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6738\n\nTesting for epoch 36 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6927\n\nTesting for epoch 36 index 16:\n16/16 [==============================] - 0s 908us/step - loss: 5.6958\n\nTesting for epoch 36 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.6790\n\nTesting for epoch 36 index 18:\n16/16 [==============================] - 0s 851us/step - loss: 5.6752\n\nTesting for epoch 36 index 19:\n16/16 [==============================] - 0s 819us/step - loss: 5.6844\n\nTesting for epoch 36 index 20:\n16/16 [==============================] - 0s 6ms/step - loss: 5.6507\n\nTesting for epoch 36 index 21:\n16/16 [==============================] - 0s 864us/step - loss: 5.6467\n\nTesting for epoch 36 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6941\n\nTesting for epoch 36 index 23:\n16/16 [==============================] - 0s 874us/step - loss: 5.6967\n\nTesting for epoch 36 index 24:\n16/16 [==============================] - 0s 881us/step - loss: 5.6670\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n16/16 [==============================] - 0s 825us/step - loss: 5.7009\n\nTesting for epoch 37 index 2:\n16/16 [==============================] - 0s 831us/step - loss: 5.6850\n\nTesting for epoch 37 index 3:\n16/16 [==============================] - 0s 881us/step - loss: 5.6797\n\nTesting for epoch 37 index 4:\n16/16 [==============================] - 0s 900us/step - loss: 5.6818\n\nTesting for epoch 37 index 5:\n16/16 [==============================] - 0s 893us/step - loss: 5.6605\n\nTesting for epoch 37 index 6:\n16/16 [==============================] - 0s 870us/step - loss: 5.7199\n\nTesting for epoch 37 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6550\n\nTesting for epoch 37 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.6696\n\nTesting for epoch 37 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6838\n\nTesting for epoch 37 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7124\n\nTesting for epoch 37 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7032\n\nTesting for epoch 37 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7217\n\nTesting for epoch 37 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7134\n\nTesting for epoch 37 index 14:\n16/16 [==============================] - 0s 4ms/step - loss: 5.6758\n\nTesting for epoch 37 index 15:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7049\n\nTesting for epoch 37 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7058\n\nTesting for epoch 37 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.6949\n\nTesting for epoch 37 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7414\n\nTesting for epoch 37 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7083\n\nTesting for epoch 37 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7027\n\nTesting for epoch 37 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7252\n\nTesting for epoch 37 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7341\n\nTesting for epoch 37 index 23:\n16/16 [==============================] - 0s 4ms/step - loss: 5.6999\n\nTesting for epoch 37 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7178\nEpoch 38 of 60\n\nTesting for epoch 38 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7195\n\nTesting for epoch 38 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7255\n\nTesting for epoch 38 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7030\n\nTesting for epoch 38 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7160\n\nTesting for epoch 38 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7259\n\nTesting for epoch 38 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7310\n\nTesting for epoch 38 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7167\n\nTesting for epoch 38 index 8:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7205\n\nTesting for epoch 38 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7377\n\nTesting for epoch 38 index 10:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7480\n\nTesting for epoch 38 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7311\n\nTesting for epoch 38 index 12:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7670\n\nTesting for epoch 38 index 13:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7334\n\nTesting for epoch 38 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7235\n\nTesting for epoch 38 index 15:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7380\n\nTesting for epoch 38 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7558\n\nTesting for epoch 38 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7787\n\nTesting for epoch 38 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7349\n\nTesting for epoch 38 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7661\n\nTesting for epoch 38 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7622\n\nTesting for epoch 38 index 21:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7841\n\nTesting for epoch 38 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7477\n\nTesting for epoch 38 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7299\n\nTesting for epoch 38 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7486\nEpoch 39 of 60\n\nTesting for epoch 39 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7355\n\nTesting for epoch 39 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7274\n\nTesting for epoch 39 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7831\n\nTesting for epoch 39 index 4:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7784\n\nTesting for epoch 39 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7559\n\nTesting for epoch 39 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7877\n\nTesting for epoch 39 index 7:\n16/16 [==============================] - 0s 5ms/step - loss: 5.7659\n\nTesting for epoch 39 index 8:\n16/16 [==============================] - 0s 4ms/step - loss: 5.7575\n\nTesting for epoch 39 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7910\n\nTesting for epoch 39 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7704\n\nTesting for epoch 39 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7690\n\nTesting for epoch 39 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7950\n\nTesting for epoch 39 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 5.7558\n\nTesting for epoch 39 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7891\n\nTesting for epoch 39 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7960\n\nTesting for epoch 39 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7617\n\nTesting for epoch 39 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7877\n\nTesting for epoch 39 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7571\n\nTesting for epoch 39 index 19:\n16/16 [==============================] - 0s 6ms/step - loss: 5.7956\n\nTesting for epoch 39 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7831\n\nTesting for epoch 39 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7889\n\nTesting for epoch 39 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8032\n\nTesting for epoch 39 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7833\n\nTesting for epoch 39 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8251\nEpoch 40 of 60\n\nTesting for epoch 40 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7939\n\nTesting for epoch 40 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7849\n\nTesting for epoch 40 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7914\n\nTesting for epoch 40 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8011\n\nTesting for epoch 40 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.7967\n\nTesting for epoch 40 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7908\n\nTesting for epoch 40 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8090\n\nTesting for epoch 40 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8014\n\nTesting for epoch 40 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7900\n\nTesting for epoch 40 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8104\n\nTesting for epoch 40 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8398\n\nTesting for epoch 40 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8279\n\nTesting for epoch 40 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.7970\n\nTesting for epoch 40 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8229\n\nTesting for epoch 40 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8302\n\nTesting for epoch 40 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8061\n\nTesting for epoch 40 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8306\n\nTesting for epoch 40 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8196\n\nTesting for epoch 40 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8551\n\nTesting for epoch 40 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8235\n\nTesting for epoch 40 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8419\n\nTesting for epoch 40 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8338\n\nTesting for epoch 40 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8127\n\nTesting for epoch 40 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8348\nEpoch 41 of 60\n\nTesting for epoch 41 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8301\n\nTesting for epoch 41 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8534\n\nTesting for epoch 41 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8247\n\nTesting for epoch 41 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8221\n\nTesting for epoch 41 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8441\n\nTesting for epoch 41 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8420\n\nTesting for epoch 41 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8326\n\nTesting for epoch 41 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8481\n\nTesting for epoch 41 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8424\n\nTesting for epoch 41 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8379\n\nTesting for epoch 41 index 11:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8776\n\nTesting for epoch 41 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8380\n\nTesting for epoch 41 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8470\n\nTesting for epoch 41 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8805\n\nTesting for epoch 41 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8361\n\nTesting for epoch 41 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8703\n\nTesting for epoch 41 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8674\n\nTesting for epoch 41 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8865\n\nTesting for epoch 41 index 19:\n16/16 [==============================] - 0s 4ms/step - loss: 5.8704\n\nTesting for epoch 41 index 20:\n16/16 [==============================] - 0s 5ms/step - loss: 5.9158\n\nTesting for epoch 41 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8653\n\nTesting for epoch 41 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8605\n\nTesting for epoch 41 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8391\n\nTesting for epoch 41 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8287\nEpoch 42 of 60\n\nTesting for epoch 42 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8514\n\nTesting for epoch 42 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8873\n\nTesting for epoch 42 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8739\n\nTesting for epoch 42 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8964\n\nTesting for epoch 42 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9038\n\nTesting for epoch 42 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8840\n\nTesting for epoch 42 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8768\n\nTesting for epoch 42 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9105\n\nTesting for epoch 42 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9081\n\nTesting for epoch 42 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8595\n\nTesting for epoch 42 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8721\n\nTesting for epoch 42 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8720\n\nTesting for epoch 42 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8938\n\nTesting for epoch 42 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8642\n\nTesting for epoch 42 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8529\n\nTesting for epoch 42 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9287\n\nTesting for epoch 42 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8928\n\nTesting for epoch 42 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8888\n\nTesting for epoch 42 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 5.8941\n\nTesting for epoch 42 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9118\n\nTesting for epoch 42 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9074\n\nTesting for epoch 42 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8974\n\nTesting for epoch 42 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9163\n\nTesting for epoch 42 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9176\nEpoch 43 of 60\n\nTesting for epoch 43 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9020\n\nTesting for epoch 43 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8887\n\nTesting for epoch 43 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8954\n\nTesting for epoch 43 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 5.8828\n\nTesting for epoch 43 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9241\n\nTesting for epoch 43 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9199\n\nTesting for epoch 43 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9037\n\nTesting for epoch 43 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9194\n\nTesting for epoch 43 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 5.8892\n\nTesting for epoch 43 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9011\n\nTesting for epoch 43 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9293\n\nTesting for epoch 43 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9526\n\nTesting for epoch 43 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9206\n\nTesting for epoch 43 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9310\n\nTesting for epoch 43 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9005\n\nTesting for epoch 43 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9265\n\nTesting for epoch 43 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9172\n\nTesting for epoch 43 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9574\n\nTesting for epoch 43 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9223\n\nTesting for epoch 43 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9191\n\nTesting for epoch 43 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9312\n\nTesting for epoch 43 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9225\n\nTesting for epoch 43 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9196\n\nTesting for epoch 43 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9712\nEpoch 44 of 60\n\nTesting for epoch 44 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9398\n\nTesting for epoch 44 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9369\n\nTesting for epoch 44 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9296\n\nTesting for epoch 44 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9298\n\nTesting for epoch 44 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9565\n\nTesting for epoch 44 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9331\n\nTesting for epoch 44 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9333\n\nTesting for epoch 44 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9800\n\nTesting for epoch 44 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9548\n\nTesting for epoch 44 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9907\n\nTesting for epoch 44 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9742\n\nTesting for epoch 44 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9679\n\nTesting for epoch 44 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9404\n\nTesting for epoch 44 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9540\n\nTesting for epoch 44 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9697\n\nTesting for epoch 44 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9573\n\nTesting for epoch 44 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9611\n\nTesting for epoch 44 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9501\n\nTesting for epoch 44 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9725\n\nTesting for epoch 44 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9704\n\nTesting for epoch 44 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9715\n\nTesting for epoch 44 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9377\n\nTesting for epoch 44 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9567\n\nTesting for epoch 44 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9600\nEpoch 45 of 60\n\nTesting for epoch 45 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9695\n\nTesting for epoch 45 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9845\n\nTesting for epoch 45 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9872\n\nTesting for epoch 45 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9660\n\nTesting for epoch 45 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9648\n\nTesting for epoch 45 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0025\n\nTesting for epoch 45 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9845\n\nTesting for epoch 45 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9770\n\nTesting for epoch 45 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9950\n\nTesting for epoch 45 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9825\n\nTesting for epoch 45 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0264\n\nTesting for epoch 45 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9860\n\nTesting for epoch 45 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9844\n\nTesting for epoch 45 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9831\n\nTesting for epoch 45 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 5.9743\n\nTesting for epoch 45 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9902\n\nTesting for epoch 45 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9655\n\nTesting for epoch 45 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9730\n\nTesting for epoch 45 index 19:\n16/16 [==============================] - 0s 4ms/step - loss: 5.9888\n\nTesting for epoch 45 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0239\n\nTesting for epoch 45 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9866\n\nTesting for epoch 45 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9779\n\nTesting for epoch 45 index 23:\n16/16 [==============================] - 0s 6ms/step - loss: 5.9982\n\nTesting for epoch 45 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0143\nEpoch 46 of 60\n\nTesting for epoch 46 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0295\n\nTesting for epoch 46 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 5.9825\n\nTesting for epoch 46 index 3:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0014\n\nTesting for epoch 46 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0107\n\nTesting for epoch 46 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0311\n\nTesting for epoch 46 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9898\n\nTesting for epoch 46 index 7:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0510\n\nTesting for epoch 46 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0030\n\nTesting for epoch 46 index 9:\n16/16 [==============================] - 0s 4ms/step - loss: 5.9883\n\nTesting for epoch 46 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0342\n\nTesting for epoch 46 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0171\n\nTesting for epoch 46 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0030\n\nTesting for epoch 46 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0223\n\nTesting for epoch 46 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0418\n\nTesting for epoch 46 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0316\n\nTesting for epoch 46 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0310\n\nTesting for epoch 46 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0164\n\nTesting for epoch 46 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0290\n\nTesting for epoch 46 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0211\n\nTesting for epoch 46 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0173\n\nTesting for epoch 46 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0238\n\nTesting for epoch 46 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0549\n\nTesting for epoch 46 index 23:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0234\n\nTesting for epoch 46 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0092\nEpoch 47 of 60\n\nTesting for epoch 47 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0113\n\nTesting for epoch 47 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0467\n\nTesting for epoch 47 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0790\n\nTesting for epoch 47 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0722\n\nTesting for epoch 47 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0378\n\nTesting for epoch 47 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0637\n\nTesting for epoch 47 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0557\n\nTesting for epoch 47 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 5.9965\n\nTesting for epoch 47 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0327\n\nTesting for epoch 47 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0582\n\nTesting for epoch 47 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0292\n\nTesting for epoch 47 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0484\n\nTesting for epoch 47 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0690\n\nTesting for epoch 47 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0508\n\nTesting for epoch 47 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0544\n\nTesting for epoch 47 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0439\n\nTesting for epoch 47 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0742\n\nTesting for epoch 47 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0572\n\nTesting for epoch 47 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0591\n\nTesting for epoch 47 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0431\n\nTesting for epoch 47 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0831\n\nTesting for epoch 47 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0684\n\nTesting for epoch 47 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0573\n\nTesting for epoch 47 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0923\nEpoch 48 of 60\n\nTesting for epoch 48 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0847\n\nTesting for epoch 48 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0703\n\nTesting for epoch 48 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0454\n\nTesting for epoch 48 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0552\n\nTesting for epoch 48 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0849\n\nTesting for epoch 48 index 6:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0517\n\nTesting for epoch 48 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0866\n\nTesting for epoch 48 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0758\n\nTesting for epoch 48 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1111\n\nTesting for epoch 48 index 10:\n16/16 [==============================] - 0s 4ms/step - loss: 6.0674\n\nTesting for epoch 48 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0838\n\nTesting for epoch 48 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1128\n\nTesting for epoch 48 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0590\n\nTesting for epoch 48 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0739\n\nTesting for epoch 48 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0620\n\nTesting for epoch 48 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0717\n\nTesting for epoch 48 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0845\n\nTesting for epoch 48 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0742\n\nTesting for epoch 48 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0991\n\nTesting for epoch 48 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0545\n\nTesting for epoch 48 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1073\n\nTesting for epoch 48 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0958\n\nTesting for epoch 48 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0572\n\nTesting for epoch 48 index 24:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1371\nEpoch 49 of 60\n\nTesting for epoch 49 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1035\n\nTesting for epoch 49 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0675\n\nTesting for epoch 49 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0999\n\nTesting for epoch 49 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1191\n\nTesting for epoch 49 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1210\n\nTesting for epoch 49 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1135\n\nTesting for epoch 49 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1262\n\nTesting for epoch 49 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0831\n\nTesting for epoch 49 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1058\n\nTesting for epoch 49 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1090\n\nTesting for epoch 49 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1057\n\nTesting for epoch 49 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1088\n\nTesting for epoch 49 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1232\n\nTesting for epoch 49 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0894\n\nTesting for epoch 49 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1116\n\nTesting for epoch 49 index 16:\n16/16 [==============================] - 0s 5ms/step - loss: 6.1392\n\nTesting for epoch 49 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1318\n\nTesting for epoch 49 index 18:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1031\n\nTesting for epoch 49 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1547\n\nTesting for epoch 49 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0960\n\nTesting for epoch 49 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1555\n\nTesting for epoch 49 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1379\n\nTesting for epoch 49 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.0967\n\nTesting for epoch 49 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1399\nEpoch 50 of 60\n\nTesting for epoch 50 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.0987\n\nTesting for epoch 50 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1329\n\nTesting for epoch 50 index 3:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1105\n\nTesting for epoch 50 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1310\n\nTesting for epoch 50 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0889\n\nTesting for epoch 50 index 6:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1469\n\nTesting for epoch 50 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1347\n\nTesting for epoch 50 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1192\n\nTesting for epoch 50 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1290\n\nTesting for epoch 50 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1286\n\nTesting for epoch 50 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1321\n\nTesting for epoch 50 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1555\n\nTesting for epoch 50 index 13:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1481\n\nTesting for epoch 50 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1589\n\nTesting for epoch 50 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1314\n\nTesting for epoch 50 index 16:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1347\n\nTesting for epoch 50 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1325\n\nTesting for epoch 50 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1575\n\nTesting for epoch 50 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1620\n\nTesting for epoch 50 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1571\n\nTesting for epoch 50 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.0978\n\nTesting for epoch 50 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1696\n\nTesting for epoch 50 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1205\n\nTesting for epoch 50 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1326\nEpoch 51 of 60\n\nTesting for epoch 51 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1536\n\nTesting for epoch 51 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1668\n\nTesting for epoch 51 index 3:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1308\n\nTesting for epoch 51 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1492\n\nTesting for epoch 51 index 5:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1592\n\nTesting for epoch 51 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1718\n\nTesting for epoch 51 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1811\n\nTesting for epoch 51 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1576\n\nTesting for epoch 51 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1344\n\nTesting for epoch 51 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1463\n\nTesting for epoch 51 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1708\n\nTesting for epoch 51 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1972\n\nTesting for epoch 51 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1650\n\nTesting for epoch 51 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1533\n\nTesting for epoch 51 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1549\n\nTesting for epoch 51 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1492\n\nTesting for epoch 51 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1474\n\nTesting for epoch 51 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1446\n\nTesting for epoch 51 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2000\n\nTesting for epoch 51 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1578\n\nTesting for epoch 51 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1328\n\nTesting for epoch 51 index 22:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1692\n\nTesting for epoch 51 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1752\n\nTesting for epoch 51 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1524\nEpoch 52 of 60\n\nTesting for epoch 52 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2224\n\nTesting for epoch 52 index 2:\n16/16 [==============================] - 0s 4ms/step - loss: 6.1998\n\nTesting for epoch 52 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1916\n\nTesting for epoch 52 index 4:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1728\n\nTesting for epoch 52 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1997\n\nTesting for epoch 52 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1800\n\nTesting for epoch 52 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1960\n\nTesting for epoch 52 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1573\n\nTesting for epoch 52 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1822\n\nTesting for epoch 52 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2128\n\nTesting for epoch 52 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2226\n\nTesting for epoch 52 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2022\n\nTesting for epoch 52 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1782\n\nTesting for epoch 52 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1693\n\nTesting for epoch 52 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1917\n\nTesting for epoch 52 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1940\n\nTesting for epoch 52 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1999\n\nTesting for epoch 52 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1842\n\nTesting for epoch 52 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.1996\n\nTesting for epoch 52 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2104\n\nTesting for epoch 52 index 21:\n16/16 [==============================] - 0s 4ms/step - loss: 6.2201\n\nTesting for epoch 52 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1933\n\nTesting for epoch 52 index 23:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1899\n\nTesting for epoch 52 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1887\nEpoch 53 of 60\n\nTesting for epoch 53 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2112\n\nTesting for epoch 53 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2016\n\nTesting for epoch 53 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2237\n\nTesting for epoch 53 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1912\n\nTesting for epoch 53 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1927\n\nTesting for epoch 53 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2141\n\nTesting for epoch 53 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2289\n\nTesting for epoch 53 index 8:\n16/16 [==============================] - 0s 3ms/step - loss: 6.1993\n\nTesting for epoch 53 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2175\n\nTesting for epoch 53 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2142\n\nTesting for epoch 53 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2280\n\nTesting for epoch 53 index 12:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2100\n\nTesting for epoch 53 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2253\n\nTesting for epoch 53 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2261\n\nTesting for epoch 53 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2624\n\nTesting for epoch 53 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2173\n\nTesting for epoch 53 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2413\n\nTesting for epoch 53 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2174\n\nTesting for epoch 53 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1991\n\nTesting for epoch 53 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2263\n\nTesting for epoch 53 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2499\n\nTesting for epoch 53 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2003\n\nTesting for epoch 53 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2449\n\nTesting for epoch 53 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2249\nEpoch 54 of 60\n\nTesting for epoch 54 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2472\n\nTesting for epoch 54 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2382\n\nTesting for epoch 54 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2188\n\nTesting for epoch 54 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2338\n\nTesting for epoch 54 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2704\n\nTesting for epoch 54 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2055\n\nTesting for epoch 54 index 7:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2565\n\nTesting for epoch 54 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2524\n\nTesting for epoch 54 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2573\n\nTesting for epoch 54 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2544\n\nTesting for epoch 54 index 11:\n16/16 [==============================] - 0s 5ms/step - loss: 6.2302\n\nTesting for epoch 54 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2331\n\nTesting for epoch 54 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2060\n\nTesting for epoch 54 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2518\n\nTesting for epoch 54 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2465\n\nTesting for epoch 54 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.1940\n\nTesting for epoch 54 index 17:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2579\n\nTesting for epoch 54 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2417\n\nTesting for epoch 54 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2534\n\nTesting for epoch 54 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2519\n\nTesting for epoch 54 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2425\n\nTesting for epoch 54 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2399\n\nTesting for epoch 54 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2673\n\nTesting for epoch 54 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2722\nEpoch 55 of 60\n\nTesting for epoch 55 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2730\n\nTesting for epoch 55 index 2:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2662\n\nTesting for epoch 55 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2780\n\nTesting for epoch 55 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2703\n\nTesting for epoch 55 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2788\n\nTesting for epoch 55 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2653\n\nTesting for epoch 55 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2738\n\nTesting for epoch 55 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2662\n\nTesting for epoch 55 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2842\n\nTesting for epoch 55 index 10:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2755\n\nTesting for epoch 55 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3159\n\nTesting for epoch 55 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2817\n\nTesting for epoch 55 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2706\n\nTesting for epoch 55 index 14:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2826\n\nTesting for epoch 55 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3087\n\nTesting for epoch 55 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2827\n\nTesting for epoch 55 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2835\n\nTesting for epoch 55 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2455\n\nTesting for epoch 55 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3109\n\nTesting for epoch 55 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3139\n\nTesting for epoch 55 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2777\n\nTesting for epoch 55 index 22:\n16/16 [==============================] - 0s 5ms/step - loss: 6.2460\n\nTesting for epoch 55 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3135\n\nTesting for epoch 55 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2767\nEpoch 56 of 60\n\nTesting for epoch 56 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2638\n\nTesting for epoch 56 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2505\n\nTesting for epoch 56 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2844\n\nTesting for epoch 56 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2828\n\nTesting for epoch 56 index 5:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2526\n\nTesting for epoch 56 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2842\n\nTesting for epoch 56 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2845\n\nTesting for epoch 56 index 8:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2939\n\nTesting for epoch 56 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3070\n\nTesting for epoch 56 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2890\n\nTesting for epoch 56 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2758\n\nTesting for epoch 56 index 12:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2841\n\nTesting for epoch 56 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2826\n\nTesting for epoch 56 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3053\n\nTesting for epoch 56 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2991\n\nTesting for epoch 56 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3194\n\nTesting for epoch 56 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2705\n\nTesting for epoch 56 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3355\n\nTesting for epoch 56 index 19:\n16/16 [==============================] - 0s 3ms/step - loss: 6.2967\n\nTesting for epoch 56 index 20:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3052\n\nTesting for epoch 56 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3010\n\nTesting for epoch 56 index 22:\n16/16 [==============================] - 0s 4ms/step - loss: 6.3093\n\nTesting for epoch 56 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2840\n\nTesting for epoch 56 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3039\nEpoch 57 of 60\n\nTesting for epoch 57 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3050\n\nTesting for epoch 57 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3247\n\nTesting for epoch 57 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2988\n\nTesting for epoch 57 index 4:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3270\n\nTesting for epoch 57 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2958\n\nTesting for epoch 57 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3076\n\nTesting for epoch 57 index 7:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3457\n\nTesting for epoch 57 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3354\n\nTesting for epoch 57 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2985\n\nTesting for epoch 57 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3025\n\nTesting for epoch 57 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3405\n\nTesting for epoch 57 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2959\n\nTesting for epoch 57 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3136\n\nTesting for epoch 57 index 14:\n16/16 [==============================] - 0s 1ms/step - loss: 6.2957\n\nTesting for epoch 57 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3203\n\nTesting for epoch 57 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3019\n\nTesting for epoch 57 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3213\n\nTesting for epoch 57 index 18:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3553\n\nTesting for epoch 57 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3161\n\nTesting for epoch 57 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3244\n\nTesting for epoch 57 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3466\n\nTesting for epoch 57 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3135\n\nTesting for epoch 57 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3334\n\nTesting for epoch 57 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3397\nEpoch 58 of 60\n\nTesting for epoch 58 index 1:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3440\n\nTesting for epoch 58 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.2834\n\nTesting for epoch 58 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3472\n\nTesting for epoch 58 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3389\n\nTesting for epoch 58 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3400\n\nTesting for epoch 58 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3246\n\nTesting for epoch 58 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3517\n\nTesting for epoch 58 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3424\n\nTesting for epoch 58 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3409\n\nTesting for epoch 58 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3381\n\nTesting for epoch 58 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3355\n\nTesting for epoch 58 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3424\n\nTesting for epoch 58 index 13:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3348\n\nTesting for epoch 58 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3517\n\nTesting for epoch 58 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3255\n\nTesting for epoch 58 index 16:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3588\n\nTesting for epoch 58 index 17:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3528\n\nTesting for epoch 58 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3602\n\nTesting for epoch 58 index 19:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3422\n\nTesting for epoch 58 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3357\n\nTesting for epoch 58 index 21:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3733\n\nTesting for epoch 58 index 22:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3791\n\nTesting for epoch 58 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3722\n\nTesting for epoch 58 index 24:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3484\nEpoch 59 of 60\n\nTesting for epoch 59 index 1:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3491\n\nTesting for epoch 59 index 2:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3330\n\nTesting for epoch 59 index 3:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3484\n\nTesting for epoch 59 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3475\n\nTesting for epoch 59 index 5:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3823\n\nTesting for epoch 59 index 6:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3682\n\nTesting for epoch 59 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.4005\n\nTesting for epoch 59 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3112\n\nTesting for epoch 59 index 9:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3412\n\nTesting for epoch 59 index 10:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3998\n\nTesting for epoch 59 index 11:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3618\n\nTesting for epoch 59 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3380\n\nTesting for epoch 59 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3868\n\nTesting for epoch 59 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3758\n\nTesting for epoch 59 index 15:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3380\n\nTesting for epoch 59 index 16:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3763\n\nTesting for epoch 59 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3430\n\nTesting for epoch 59 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3584\n\nTesting for epoch 59 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3702\n\nTesting for epoch 59 index 20:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3720\n\nTesting for epoch 59 index 21:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3751\n\nTesting for epoch 59 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3632\n\nTesting for epoch 59 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3836\n\nTesting for epoch 59 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3873\nEpoch 60 of 60\n\nTesting for epoch 60 index 1:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3778\n\nTesting for epoch 60 index 2:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3940\n\nTesting for epoch 60 index 3:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3929\n\nTesting for epoch 60 index 4:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3982\n\nTesting for epoch 60 index 5:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4078\n\nTesting for epoch 60 index 6:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4026\n\nTesting for epoch 60 index 7:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3660\n\nTesting for epoch 60 index 8:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4115\n\nTesting for epoch 60 index 9:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3733\n\nTesting for epoch 60 index 10:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3655\n\nTesting for epoch 60 index 11:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3825\n\nTesting for epoch 60 index 12:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4040\n\nTesting for epoch 60 index 13:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3846\n\nTesting for epoch 60 index 14:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4046\n\nTesting for epoch 60 index 15:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3785\n\nTesting for epoch 60 index 16:\n16/16 [==============================] - 0s 3ms/step - loss: 6.3916\n\nTesting for epoch 60 index 17:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3746\n\nTesting for epoch 60 index 18:\n16/16 [==============================] - 0s 1ms/step - loss: 6.4338\n\nTesting for epoch 60 index 19:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4148\n\nTesting for epoch 60 index 20:\n16/16 [==============================] - 0s 1ms/step - loss: 6.3923\n\nTesting for epoch 60 index 21:\n16/16 [==============================] - 0s 2ms/step - loss: 6.4398\n\nTesting for epoch 60 index 22:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3963\n\nTesting for epoch 60 index 23:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3854\n\nTesting for epoch 60 index 24:\n16/16 [==============================] - 0s 2ms/step - loss: 6.3949\n391/391 [==============================] - 1s 1ms/step\n\n\nSO_GAAL(contamination=0.1, lr_d=0.01, lr_g=0.0001, momentum=0.9,\n    stop_epochs=20)\n\n\n\noutlier_SO_GAAL_one = list(clf.labels_)\n\n\noutlier_SO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_SO_GAAL_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 18 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"SO-GAAL (Liu et al., 2019)\")\n\n\ntwelve = eleven.append(_conf.tab)\n\n\n\nMO_GAAL\n\nclf = MO_GAAL()\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['MO_GAAL_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n\n\nEpoch 1 of 60\n\nTesting for epoch 1 index 1:\nWARNING:tensorflow:5 out of the last 401 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f42a90bb9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f42a90bb8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n391/391 [==============================] - 1s 1ms/step\nWARNING:tensorflow:5 out of the last 1947 calls to <function Model.make_train_function.<locals>.train_function at 0x7f428c173040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 1948 calls to <function Model.make_train_function.<locals>.train_function at 0x7f42d2fba040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\nTesting for epoch 1 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 11:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 14:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 16:\n391/391 [==============================] - 0s 977us/step\n\nTesting for epoch 1 index 17:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 1 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 1 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 2 of 60\n\nTesting for epoch 2 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 5:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 9:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 16:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 19:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 2 index 20:\n391/391 [==============================] - 0s 997us/step\n\nTesting for epoch 2 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 2 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 3 of 60\n\nTesting for epoch 3 index 1:\n391/391 [==============================] - 0s 942us/step\n\nTesting for epoch 3 index 2:\n391/391 [==============================] - 0s 967us/step\n\nTesting for epoch 3 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 10:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 3 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 17:\n391/391 [==============================] - 0s 949us/step\n\nTesting for epoch 3 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 22:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 3 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 3 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 4 of 60\n\nTesting for epoch 4 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 4:\n391/391 [==============================] - 0s 682us/step\n\nTesting for epoch 4 index 5:\n391/391 [==============================] - 0s 943us/step\n\nTesting for epoch 4 index 6:\n391/391 [==============================] - 0s 842us/step\n\nTesting for epoch 4 index 7:\n391/391 [==============================] - 0s 622us/step\n\nTesting for epoch 4 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 9:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 10:\n391/391 [==============================] - 0s 612us/step\n\nTesting for epoch 4 index 11:\n391/391 [==============================] - 0s 670us/step\n\nTesting for epoch 4 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 15:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 16:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 4 index 17:\n391/391 [==============================] - 0s 865us/step\n\nTesting for epoch 4 index 18:\n391/391 [==============================] - 0s 898us/step\n\nTesting for epoch 4 index 19:\n391/391 [==============================] - 0s 931us/step\n\nTesting for epoch 4 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 4 index 21:\n391/391 [==============================] - 0s 970us/step\n\nTesting for epoch 4 index 22:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 4 index 23:\n391/391 [==============================] - 0s 887us/step\n\nTesting for epoch 4 index 24:\n391/391 [==============================] - 0s 976us/step\nEpoch 5 of 60\n\nTesting for epoch 5 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 6:\n391/391 [==============================] - 0s 959us/step\n\nTesting for epoch 5 index 7:\n391/391 [==============================] - 0s 934us/step\n\nTesting for epoch 5 index 8:\n391/391 [==============================] - 0s 989us/step\n\nTesting for epoch 5 index 9:\n391/391 [==============================] - 0s 860us/step\n\nTesting for epoch 5 index 10:\n391/391 [==============================] - 0s 908us/step\n\nTesting for epoch 5 index 11:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 5 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 13:\n391/391 [==============================] - 0s 929us/step\n\nTesting for epoch 5 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 15:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 5 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 17:\n391/391 [==============================] - 0s 926us/step\n\nTesting for epoch 5 index 18:\n391/391 [==============================] - 0s 899us/step\n\nTesting for epoch 5 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 21:\n391/391 [==============================] - 0s 964us/step\n\nTesting for epoch 5 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 5 index 23:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 5 index 24:\n391/391 [==============================] - 0s 930us/step\nEpoch 6 of 60\n\nTesting for epoch 6 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 2:\n391/391 [==============================] - 0s 958us/step\n\nTesting for epoch 6 index 3:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 6 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 5:\n391/391 [==============================] - 0s 904us/step\n\nTesting for epoch 6 index 6:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 6 index 7:\n391/391 [==============================] - 0s 903us/step\n\nTesting for epoch 6 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 18:\n391/391 [==============================] - 0s 987us/step\n\nTesting for epoch 6 index 19:\n391/391 [==============================] - 0s 978us/step\n\nTesting for epoch 6 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 6 index 21:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 6 index 22:\n391/391 [==============================] - 0s 956us/step\n\nTesting for epoch 6 index 23:\n391/391 [==============================] - 0s 994us/step\n\nTesting for epoch 6 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 7 of 60\n\nTesting for epoch 7 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 3:\n391/391 [==============================] - 0s 846us/step\n\nTesting for epoch 7 index 4:\n391/391 [==============================] - 0s 991us/step\n\nTesting for epoch 7 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 16:\n391/391 [==============================] - 0s 901us/step\n\nTesting for epoch 7 index 17:\n391/391 [==============================] - 0s 920us/step\n\nTesting for epoch 7 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 7 index 21:\n391/391 [==============================] - 0s 715us/step\n\nTesting for epoch 7 index 22:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 23:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 7 index 24:\n391/391 [==============================] - 1s 1ms/step\nEpoch 8 of 60\n\nTesting for epoch 8 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 4:\n391/391 [==============================] - 0s 972us/step\n\nTesting for epoch 8 index 5:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 8:\n391/391 [==============================] - 0s 851us/step\n\nTesting for epoch 8 index 9:\n391/391 [==============================] - 0s 946us/step\n\nTesting for epoch 8 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 11:\n391/391 [==============================] - 0s 848us/step\n\nTesting for epoch 8 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 14:\n391/391 [==============================] - 0s 938us/step\n\nTesting for epoch 8 index 15:\n391/391 [==============================] - 0s 993us/step\n\nTesting for epoch 8 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 17:\n391/391 [==============================] - 0s 823us/step\n\nTesting for epoch 8 index 18:\n391/391 [==============================] - 0s 783us/step\n\nTesting for epoch 8 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 8 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 8 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 9 of 60\n\nTesting for epoch 9 index 1:\n391/391 [==============================] - 0s 948us/step\n\nTesting for epoch 9 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 3:\n391/391 [==============================] - 0s 894us/step\n\nTesting for epoch 9 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 12:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 13:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 14:\n391/391 [==============================] - 0s 916us/step\n\nTesting for epoch 9 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 16:\n391/391 [==============================] - 0s 964us/step\n\nTesting for epoch 9 index 17:\n391/391 [==============================] - 0s 951us/step\n\nTesting for epoch 9 index 18:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 19:\n391/391 [==============================] - 0s 985us/step\n\nTesting for epoch 9 index 20:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 9 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 9 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 10 of 60\n\nTesting for epoch 10 index 1:\n391/391 [==============================] - 0s 999us/step\n\nTesting for epoch 10 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 3:\n391/391 [==============================] - 0s 932us/step\n\nTesting for epoch 10 index 4:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 10 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 10 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 10 index 20:\n391/391 [==============================] - 0s 945us/step\n\nTesting for epoch 10 index 21:\n391/391 [==============================] - 0s 880us/step\n\nTesting for epoch 10 index 22:\n391/391 [==============================] - 0s 875us/step\n\nTesting for epoch 10 index 23:\n391/391 [==============================] - 0s 959us/step\n\nTesting for epoch 10 index 24:\n391/391 [==============================] - 0s 987us/step\nEpoch 11 of 60\n\nTesting for epoch 11 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 7:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 11 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 10:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 11 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 13:\n391/391 [==============================] - 0s 980us/step\n\nTesting for epoch 11 index 14:\n391/391 [==============================] - 0s 952us/step\n\nTesting for epoch 11 index 15:\n391/391 [==============================] - 0s 1000us/step\n\nTesting for epoch 11 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 17:\n391/391 [==============================] - 0s 832us/step\n\nTesting for epoch 11 index 18:\n391/391 [==============================] - 0s 890us/step\n\nTesting for epoch 11 index 19:\n391/391 [==============================] - 0s 921us/step\n\nTesting for epoch 11 index 20:\n391/391 [==============================] - 0s 996us/step\n\nTesting for epoch 11 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 11 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 12 of 60\n\nTesting for epoch 12 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 3:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 7:\n391/391 [==============================] - 0s 901us/step\n\nTesting for epoch 12 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 15:\n391/391 [==============================] - 0s 956us/step\n\nTesting for epoch 12 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 18:\n391/391 [==============================] - 0s 902us/step\n\nTesting for epoch 12 index 19:\n391/391 [==============================] - 0s 976us/step\n\nTesting for epoch 12 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 12 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 13 of 60\n\nTesting for epoch 13 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 2:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 3:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 5:\n391/391 [==============================] - 0s 938us/step\n\nTesting for epoch 13 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 8:\n391/391 [==============================] - 0s 876us/step\n\nTesting for epoch 13 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 10:\n391/391 [==============================] - 0s 912us/step\n\nTesting for epoch 13 index 11:\n391/391 [==============================] - 0s 930us/step\n\nTesting for epoch 13 index 12:\n391/391 [==============================] - 0s 980us/step\n\nTesting for epoch 13 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 14:\n391/391 [==============================] - 0s 940us/step\n\nTesting for epoch 13 index 15:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 16:\n391/391 [==============================] - 0s 843us/step\n\nTesting for epoch 13 index 17:\n391/391 [==============================] - 0s 870us/step\n\nTesting for epoch 13 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 13 index 20:\n391/391 [==============================] - 0s 918us/step\n\nTesting for epoch 13 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 13 index 22:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 13 index 23:\n391/391 [==============================] - 0s 644us/step\n\nTesting for epoch 13 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 14 of 60\n\nTesting for epoch 14 index 1:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 14 index 2:\n391/391 [==============================] - 0s 867us/step\n\nTesting for epoch 14 index 3:\n391/391 [==============================] - 1s 2ms/step\n\nTesting for epoch 14 index 4:\n391/391 [==============================] - 0s 992us/step\n\nTesting for epoch 14 index 5:\n391/391 [==============================] - 0s 892us/step\n\nTesting for epoch 14 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 8:\n391/391 [==============================] - 0s 966us/step\n\nTesting for epoch 14 index 9:\n391/391 [==============================] - 0s 993us/step\n\nTesting for epoch 14 index 10:\n391/391 [==============================] - 0s 988us/step\n\nTesting for epoch 14 index 11:\n391/391 [==============================] - 0s 919us/step\n\nTesting for epoch 14 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 17:\n391/391 [==============================] - 0s 982us/step\n\nTesting for epoch 14 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 19:\n391/391 [==============================] - 0s 994us/step\n\nTesting for epoch 14 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 14 index 21:\n391/391 [==============================] - 0s 895us/step\n\nTesting for epoch 14 index 22:\n391/391 [==============================] - 0s 894us/step\n\nTesting for epoch 14 index 23:\n391/391 [==============================] - 0s 966us/step\n\nTesting for epoch 14 index 24:\n391/391 [==============================] - 0s 891us/step\nEpoch 15 of 60\n\nTesting for epoch 15 index 1:\n391/391 [==============================] - 0s 999us/step\n\nTesting for epoch 15 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 3:\n391/391 [==============================] - 0s 981us/step\n\nTesting for epoch 15 index 4:\n391/391 [==============================] - 0s 967us/step\n\nTesting for epoch 15 index 5:\n391/391 [==============================] - 0s 928us/step\n\nTesting for epoch 15 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 10:\n391/391 [==============================] - 0s 951us/step\n\nTesting for epoch 15 index 11:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 12:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 15 index 13:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 14:\n391/391 [==============================] - 0s 982us/step\n\nTesting for epoch 15 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 19:\n391/391 [==============================] - 0s 963us/step\n\nTesting for epoch 15 index 20:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 21:\n391/391 [==============================] - 0s 978us/step\n\nTesting for epoch 15 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 15 index 24:\n391/391 [==============================] - 0s 969us/step\nEpoch 16 of 60\n\nTesting for epoch 16 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 2:\n391/391 [==============================] - 0s 998us/step\n\nTesting for epoch 16 index 3:\n391/391 [==============================] - 0s 897us/step\n\nTesting for epoch 16 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 7:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 8:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 9:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 10:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 11:\n391/391 [==============================] - 0s 933us/step\n\nTesting for epoch 16 index 12:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 13:\n391/391 [==============================] - 0s 987us/step\n\nTesting for epoch 16 index 14:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 15:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 17:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 19:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 20:\n391/391 [==============================] - 0s 895us/step\n\nTesting for epoch 16 index 21:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 22:\n391/391 [==============================] - 0s 882us/step\n\nTesting for epoch 16 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 16 index 24:\n391/391 [==============================] - 0s 1ms/step\nEpoch 17 of 60\n\nTesting for epoch 17 index 1:\n391/391 [==============================] - 0s 992us/step\n\nTesting for epoch 17 index 2:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 3:\n391/391 [==============================] - 0s 916us/step\n\nTesting for epoch 17 index 4:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 5:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 6:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 17 index 7:\n391/391 [==============================] - 0s 854us/step\n\nTesting for epoch 17 index 8:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 17 index 9:\n391/391 [==============================] - 0s 931us/step\n\nTesting for epoch 17 index 10:\n391/391 [==============================] - 0s 615us/step\n\nTesting for epoch 17 index 11:\n391/391 [==============================] - 0s 636us/step\n\nTesting for epoch 17 index 12:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 17 index 13:\n391/391 [==============================] - 0s 645us/step\n\nTesting for epoch 17 index 14:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 17 index 15:\n391/391 [==============================] - 0s 638us/step\n\nTesting for epoch 17 index 16:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 17 index 17:\n391/391 [==============================] - 0s 632us/step\n\nTesting for epoch 17 index 18:\n391/391 [==============================] - 0s 620us/step\n\nTesting for epoch 17 index 19:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 17 index 20:\n391/391 [==============================] - 0s 612us/step\n\nTesting for epoch 17 index 21:\n391/391 [==============================] - 0s 613us/step\n\nTesting for epoch 17 index 22:\n391/391 [==============================] - 0s 601us/step\n\nTesting for epoch 17 index 23:\n391/391 [==============================] - 0s 608us/step\n\nTesting for epoch 17 index 24:\n391/391 [==============================] - 0s 598us/step\nEpoch 18 of 60\n\nTesting for epoch 18 index 1:\n391/391 [==============================] - 0s 781us/step\n\nTesting for epoch 18 index 2:\n391/391 [==============================] - 0s 656us/step\n\nTesting for epoch 18 index 3:\n391/391 [==============================] - 0s 604us/step\n\nTesting for epoch 18 index 4:\n391/391 [==============================] - 0s 611us/step\n\nTesting for epoch 18 index 5:\n391/391 [==============================] - 0s 619us/step\n\nTesting for epoch 18 index 6:\n391/391 [==============================] - 0s 613us/step\n\nTesting for epoch 18 index 7:\n391/391 [==============================] - 0s 645us/step\n\nTesting for epoch 18 index 8:\n391/391 [==============================] - 0s 625us/step\n\nTesting for epoch 18 index 9:\n391/391 [==============================] - 0s 619us/step\n\nTesting for epoch 18 index 10:\n391/391 [==============================] - 0s 603us/step\n\nTesting for epoch 18 index 11:\n391/391 [==============================] - 0s 606us/step\n\nTesting for epoch 18 index 12:\n391/391 [==============================] - 0s 662us/step\n\nTesting for epoch 18 index 13:\n391/391 [==============================] - 0s 643us/step\n\nTesting for epoch 18 index 14:\n391/391 [==============================] - 0s 826us/step\n\nTesting for epoch 18 index 15:\n391/391 [==============================] - 0s 638us/step\n\nTesting for epoch 18 index 16:\n391/391 [==============================] - 0s 631us/step\n\nTesting for epoch 18 index 17:\n391/391 [==============================] - 0s 640us/step\n\nTesting for epoch 18 index 18:\n391/391 [==============================] - 0s 688us/step\n\nTesting for epoch 18 index 19:\n391/391 [==============================] - 0s 603us/step\n\nTesting for epoch 18 index 20:\n391/391 [==============================] - 0s 633us/step\n\nTesting for epoch 18 index 21:\n391/391 [==============================] - 0s 630us/step\n\nTesting for epoch 18 index 22:\n391/391 [==============================] - 0s 655us/step\n\nTesting for epoch 18 index 23:\n391/391 [==============================] - 0s 608us/step\n\nTesting for epoch 18 index 24:\n391/391 [==============================] - 0s 602us/step\nEpoch 19 of 60\n\nTesting for epoch 19 index 1:\n391/391 [==============================] - 0s 617us/step\n\nTesting for epoch 19 index 2:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 19 index 3:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 19 index 4:\n391/391 [==============================] - 0s 609us/step\n\nTesting for epoch 19 index 5:\n391/391 [==============================] - 0s 639us/step\n\nTesting for epoch 19 index 6:\n391/391 [==============================] - 0s 618us/step\n\nTesting for epoch 19 index 7:\n391/391 [==============================] - 0s 630us/step\n\nTesting for epoch 19 index 8:\n391/391 [==============================] - 0s 624us/step\n\nTesting for epoch 19 index 9:\n391/391 [==============================] - 0s 764us/step\n\nTesting for epoch 19 index 10:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 19 index 11:\n391/391 [==============================] - 0s 738us/step\n\nTesting for epoch 19 index 12:\n391/391 [==============================] - 0s 629us/step\n\nTesting for epoch 19 index 13:\n391/391 [==============================] - 0s 831us/step\n\nTesting for epoch 19 index 14:\n391/391 [==============================] - 0s 621us/step\n\nTesting for epoch 19 index 15:\n391/391 [==============================] - 0s 636us/step\n\nTesting for epoch 19 index 16:\n391/391 [==============================] - 0s 652us/step\n\nTesting for epoch 19 index 17:\n391/391 [==============================] - 0s 646us/step\n\nTesting for epoch 19 index 18:\n391/391 [==============================] - 0s 652us/step\n\nTesting for epoch 19 index 19:\n391/391 [==============================] - 0s 639us/step\n\nTesting for epoch 19 index 20:\n391/391 [==============================] - 0s 649us/step\n\nTesting for epoch 19 index 21:\n391/391 [==============================] - 0s 659us/step\n\nTesting for epoch 19 index 22:\n391/391 [==============================] - 0s 836us/step\n\nTesting for epoch 19 index 23:\n391/391 [==============================] - 0s 655us/step\n\nTesting for epoch 19 index 24:\n391/391 [==============================] - 0s 640us/step\nEpoch 20 of 60\n\nTesting for epoch 20 index 1:\n391/391 [==============================] - 0s 618us/step\n\nTesting for epoch 20 index 2:\n391/391 [==============================] - 0s 649us/step\n\nTesting for epoch 20 index 3:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 4:\n391/391 [==============================] - 0s 688us/step\n\nTesting for epoch 20 index 5:\n391/391 [==============================] - 0s 610us/step\n\nTesting for epoch 20 index 6:\n391/391 [==============================] - 0s 622us/step\n\nTesting for epoch 20 index 7:\n391/391 [==============================] - 0s 654us/step\n\nTesting for epoch 20 index 8:\n391/391 [==============================] - 0s 634us/step\n\nTesting for epoch 20 index 9:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 10:\n391/391 [==============================] - 0s 667us/step\n\nTesting for epoch 20 index 11:\n391/391 [==============================] - 0s 673us/step\n\nTesting for epoch 20 index 12:\n391/391 [==============================] - 0s 672us/step\n\nTesting for epoch 20 index 13:\n391/391 [==============================] - 0s 646us/step\n\nTesting for epoch 20 index 14:\n391/391 [==============================] - 0s 628us/step\n\nTesting for epoch 20 index 15:\n391/391 [==============================] - 0s 635us/step\n\nTesting for epoch 20 index 16:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 17:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 18:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 19:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 20:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 21:\n391/391 [==============================] - 1s 1ms/step\n\nTesting for epoch 20 index 22:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 23:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 20 index 24:\n391/391 [==============================] - 1s 1ms/step\nEpoch 21 of 60\n\nTesting for epoch 21 index 1:\n391/391 [==============================] - 0s 1ms/step\n\nTesting for epoch 21 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0053\n16/16 [==============================] - 0s 3ms/step - loss: 4.1893\n16/16 [==============================] - 0s 4ms/step - loss: 4.1896\n16/16 [==============================] - 0s 1ms/step - loss: 4.5660\n16/16 [==============================] - 0s 1ms/step - loss: 4.5671\n16/16 [==============================] - 0s 1ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 2ms/step - loss: 4.5671\n16/16 [==============================] - 0s 4ms/step - loss: 4.5671\n\nTesting for epoch 21 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0072\n16/16 [==============================] - 0s 3ms/step - loss: 4.2069\n16/16 [==============================] - 0s 3ms/step - loss: 4.2071\n16/16 [==============================] - 0s 5ms/step - loss: 4.5838\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 3ms/step - loss: 4.5849\n16/16 [==============================] - 0s 3ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n16/16 [==============================] - 0s 2ms/step - loss: 4.5849\n\nTesting for epoch 21 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0059\n16/16 [==============================] - 0s 3ms/step - loss: 4.1521\n16/16 [==============================] - 0s 930us/step - loss: 4.1524\n16/16 [==============================] - 0s 1ms/step - loss: 4.5355\n16/16 [==============================] - 0s 827us/step - loss: 4.5366\n16/16 [==============================] - 0s 907us/step - loss: 4.5366\n16/16 [==============================] - 0s 974us/step - loss: 4.5366\n16/16 [==============================] - 0s 1ms/step - loss: 4.5366\n16/16 [==============================] - 0s 987us/step - loss: 4.5366\n16/16 [==============================] - 0s 1ms/step - loss: 4.5366\n\nTesting for epoch 21 index 5:\n391/391 [==============================] - 0s 673us/step\n16/16 [==============================] - 0s 968us/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.1369\n16/16 [==============================] - 0s 1ms/step - loss: 4.1371\n16/16 [==============================] - 0s 1ms/step - loss: 4.5217\n16/16 [==============================] - 0s 1ms/step - loss: 4.5228\n16/16 [==============================] - 0s 1ms/step - loss: 4.5228\n16/16 [==============================] - 0s 997us/step - loss: 4.5228\n16/16 [==============================] - 0s 3ms/step - loss: 4.5228\n16/16 [==============================] - 0s 3ms/step - loss: 4.5228\n16/16 [==============================] - 0s 2ms/step - loss: 4.5228\n\nTesting for epoch 21 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0067\n16/16 [==============================] - 0s 3ms/step - loss: 4.1889\n16/16 [==============================] - 0s 2ms/step - loss: 4.1892\n16/16 [==============================] - 0s 2ms/step - loss: 4.5693\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 2ms/step - loss: 4.5704\n16/16 [==============================] - 0s 2ms/step - loss: 4.5704\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 3ms/step - loss: 4.5704\n16/16 [==============================] - 0s 4ms/step - loss: 4.5704\n\nTesting for epoch 21 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 4ms/step - loss: 4.1930\n16/16 [==============================] - 0s 2ms/step - loss: 4.1932\n16/16 [==============================] - 0s 3ms/step - loss: 4.5745\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 3ms/step - loss: 4.5756\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 2ms/step - loss: 4.5756\n16/16 [==============================] - 0s 3ms/step - loss: 4.5756\n16/16 [==============================] - 0s 5ms/step - loss: 4.5756\n\nTesting for epoch 21 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 4.1874\n16/16 [==============================] - 0s 2ms/step - loss: 4.1877\n16/16 [==============================] - 0s 2ms/step - loss: 4.5691\n16/16 [==============================] - 0s 3ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 4ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n\nTesting for epoch 21 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.1984\n16/16 [==============================] - 0s 2ms/step - loss: 4.1986\n16/16 [==============================] - 0s 2ms/step - loss: 4.5770\n16/16 [==============================] - 0s 3ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n16/16 [==============================] - 0s 1ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n16/16 [==============================] - 0s 1ms/step - loss: 4.5781\n16/16 [==============================] - 0s 2ms/step - loss: 4.5781\n\nTesting for epoch 21 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.1775\n16/16 [==============================] - 0s 2ms/step - loss: 4.1778\n16/16 [==============================] - 0s 3ms/step - loss: 4.5610\n16/16 [==============================] - 0s 1ms/step - loss: 4.5621\n16/16 [==============================] - 0s 3ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n16/16 [==============================] - 0s 1ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n16/16 [==============================] - 0s 2ms/step - loss: 4.5621\n\nTesting for epoch 21 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.1644\n16/16 [==============================] - 0s 2ms/step - loss: 4.1646\n16/16 [==============================] - 0s 2ms/step - loss: 4.5477\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 2ms/step - loss: 4.5488\n16/16 [==============================] - 0s 1ms/step - loss: 4.5488\n\nTesting for epoch 21 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.1831\n16/16 [==============================] - 0s 2ms/step - loss: 4.1833\n16/16 [==============================] - 0s 3ms/step - loss: 4.5658\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 2ms/step - loss: 4.5669\n16/16 [==============================] - 0s 4ms/step - loss: 4.5669\n16/16 [==============================] - 0s 1ms/step - loss: 4.5669\n\nTesting for epoch 21 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 4.2442\n16/16 [==============================] - 0s 3ms/step - loss: 4.2445\n16/16 [==============================] - 0s 1ms/step - loss: 4.6221\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 1ms/step - loss: 4.6232\n16/16 [==============================] - 0s 1ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n16/16 [==============================] - 0s 2ms/step - loss: 4.6232\n\nTesting for epoch 21 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0063\n16/16 [==============================] - 0s 1ms/step - loss: 4.2739\n16/16 [==============================] - 0s 2ms/step - loss: 4.2742\n16/16 [==============================] - 0s 2ms/step - loss: 4.6488\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 2ms/step - loss: 4.6499\n16/16 [==============================] - 0s 4ms/step - loss: 4.6499\n\nTesting for epoch 21 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0056\n16/16 [==============================] - 0s 3ms/step - loss: 4.2872\n16/16 [==============================] - 0s 2ms/step - loss: 4.2875\n16/16 [==============================] - 0s 2ms/step - loss: 4.6619\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n16/16 [==============================] - 0s 1ms/step - loss: 4.6629\n16/16 [==============================] - 0s 5ms/step - loss: 4.6629\n16/16 [==============================] - 0s 2ms/step - loss: 4.6629\n\nTesting for epoch 21 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 4.2823\n16/16 [==============================] - 0s 2ms/step - loss: 4.2825\n16/16 [==============================] - 0s 2ms/step - loss: 4.6577\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n\nTesting for epoch 21 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0051\n16/16 [==============================] - 0s 1ms/step - loss: 4.2732\n16/16 [==============================] - 0s 2ms/step - loss: 4.2735\n16/16 [==============================] - 0s 2ms/step - loss: 4.6472\n16/16 [==============================] - 0s 3ms/step - loss: 4.6483\n16/16 [==============================] - 0s 2ms/step - loss: 4.6483\n16/16 [==============================] - 0s 1ms/step - loss: 4.6483\n16/16 [==============================] - 0s 2ms/step - loss: 4.6483\n16/16 [==============================] - 0s 4ms/step - loss: 4.6483\n16/16 [==============================] - 0s 3ms/step - loss: 4.6483\n\nTesting for epoch 21 index 18:\n391/391 [==============================] - 0s 945us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3485\n16/16 [==============================] - 0s 2ms/step - loss: 4.3488\n16/16 [==============================] - 0s 2ms/step - loss: 4.7173\n16/16 [==============================] - 0s 2ms/step - loss: 4.7184\n16/16 [==============================] - 0s 3ms/step - loss: 4.7184\n16/16 [==============================] - 0s 1ms/step - loss: 4.7184\n16/16 [==============================] - 0s 1ms/step - loss: 4.7184\n16/16 [==============================] - 0s 4ms/step - loss: 4.7184\n16/16 [==============================] - 0s 2ms/step - loss: 4.7184\n\nTesting for epoch 21 index 19:\n391/391 [==============================] - 0s 983us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.3035\n16/16 [==============================] - 0s 2ms/step - loss: 4.3038\n16/16 [==============================] - 0s 2ms/step - loss: 4.6748\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n16/16 [==============================] - 0s 2ms/step - loss: 4.6758\n\nTesting for epoch 21 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 4.3505\n16/16 [==============================] - 0s 2ms/step - loss: 4.3507\n16/16 [==============================] - 0s 2ms/step - loss: 4.7176\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 2ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n16/16 [==============================] - 0s 2ms/step - loss: 4.7187\n16/16 [==============================] - 0s 1ms/step - loss: 4.7187\n\nTesting for epoch 21 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0064\n16/16 [==============================] - 0s 2ms/step - loss: 4.3991\n16/16 [==============================] - 0s 4ms/step - loss: 4.3993\n16/16 [==============================] - 0s 2ms/step - loss: 4.7654\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 2ms/step - loss: 4.7665\n16/16 [==============================] - 0s 3ms/step - loss: 4.7665\n\nTesting for epoch 21 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 4.3672\n16/16 [==============================] - 0s 3ms/step - loss: 4.3675\n16/16 [==============================] - 0s 2ms/step - loss: 4.7352\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 1ms/step - loss: 4.7362\n16/16 [==============================] - 0s 3ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n16/16 [==============================] - 0s 2ms/step - loss: 4.7362\n\nTesting for epoch 21 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 4.3807\n16/16 [==============================] - 0s 2ms/step - loss: 4.3810\n16/16 [==============================] - 0s 2ms/step - loss: 4.7456\n16/16 [==============================] - 0s 2ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 2ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n16/16 [==============================] - 0s 1ms/step - loss: 4.7467\n\nTesting for epoch 21 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.3179\n16/16 [==============================] - 0s 2ms/step - loss: 4.3181\n16/16 [==============================] - 0s 2ms/step - loss: 4.6918\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\n16/16 [==============================] - 0s 3ms/step - loss: 4.6929\n16/16 [==============================] - 0s 1ms/step - loss: 4.6929\n16/16 [==============================] - 0s 1ms/step - loss: 4.6929\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\n16/16 [==============================] - 0s 2ms/step - loss: 4.6929\nEpoch 22 of 60\n\nTesting for epoch 22 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.3862\n16/16 [==============================] - 0s 2ms/step - loss: 4.3865\n16/16 [==============================] - 0s 2ms/step - loss: 4.7532\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n16/16 [==============================] - 0s 2ms/step - loss: 4.7542\n\nTesting for epoch 22 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3229\n16/16 [==============================] - 0s 2ms/step - loss: 4.3231\n16/16 [==============================] - 0s 2ms/step - loss: 4.6981\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 1ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n16/16 [==============================] - 0s 2ms/step - loss: 4.6992\n\nTesting for epoch 22 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.2999\n16/16 [==============================] - 0s 1ms/step - loss: 4.3002\n16/16 [==============================] - 0s 1ms/step - loss: 4.6792\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 3ms/step - loss: 4.6803\n16/16 [==============================] - 0s 3ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n16/16 [==============================] - 0s 2ms/step - loss: 4.6803\n\nTesting for epoch 22 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.2638\n16/16 [==============================] - 0s 2ms/step - loss: 4.2640\n16/16 [==============================] - 0s 2ms/step - loss: 4.6468\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 2ms/step - loss: 4.6479\n16/16 [==============================] - 0s 1ms/step - loss: 4.6479\n16/16 [==============================] - 0s 1ms/step - loss: 4.6479\n\nTesting for epoch 22 index 5:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 3ms/step - loss: 4.2638\n16/16 [==============================] - 0s 2ms/step - loss: 4.2641\n16/16 [==============================] - 0s 2ms/step - loss: 4.6476\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 1ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n16/16 [==============================] - 0s 1ms/step - loss: 4.6487\n16/16 [==============================] - 0s 2ms/step - loss: 4.6487\n\nTesting for epoch 22 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.2891\n16/16 [==============================] - 0s 1ms/step - loss: 4.2893\n16/16 [==============================] - 0s 2ms/step - loss: 4.6713\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n16/16 [==============================] - 0s 2ms/step - loss: 4.6724\n16/16 [==============================] - 0s 3ms/step - loss: 4.6724\n\nTesting for epoch 22 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.2911\n16/16 [==============================] - 0s 2ms/step - loss: 4.2914\n16/16 [==============================] - 0s 2ms/step - loss: 4.6719\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 1ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 1ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n16/16 [==============================] - 0s 2ms/step - loss: 4.6730\n\nTesting for epoch 22 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3165\n16/16 [==============================] - 0s 2ms/step - loss: 4.3168\n16/16 [==============================] - 0s 2ms/step - loss: 4.6965\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n16/16 [==============================] - 0s 2ms/step - loss: 4.6976\n16/16 [==============================] - 0s 1ms/step - loss: 4.6976\n\nTesting for epoch 22 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 1ms/step - loss: 4.3859\n16/16 [==============================] - 0s 2ms/step - loss: 4.3862\n16/16 [==============================] - 0s 3ms/step - loss: 4.7585\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 1ms/step - loss: 4.7596\n16/16 [==============================] - 0s 2ms/step - loss: 4.7596\n16/16 [==============================] - 0s 1ms/step - loss: 4.7596\n\nTesting for epoch 22 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.3127\n16/16 [==============================] - 0s 1ms/step - loss: 4.3130\n16/16 [==============================] - 0s 1ms/step - loss: 4.6926\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n16/16 [==============================] - 0s 1ms/step - loss: 4.6937\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n16/16 [==============================] - 0s 1ms/step - loss: 4.6937\n16/16 [==============================] - 0s 3ms/step - loss: 4.6937\n16/16 [==============================] - 0s 2ms/step - loss: 4.6937\n\nTesting for epoch 22 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0052\n16/16 [==============================] - 0s 1ms/step - loss: 4.3202\n16/16 [==============================] - 0s 2ms/step - loss: 4.3205\n16/16 [==============================] - 0s 2ms/step - loss: 4.7029\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 3ms/step - loss: 4.7040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7040\n16/16 [==============================] - 0s 3ms/step - loss: 4.7040\n\nTesting for epoch 22 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.2978\n16/16 [==============================] - 0s 2ms/step - loss: 4.2981\n16/16 [==============================] - 0s 2ms/step - loss: 4.6837\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n16/16 [==============================] - 0s 3ms/step - loss: 4.6848\n16/16 [==============================] - 0s 2ms/step - loss: 4.6848\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n16/16 [==============================] - 0s 2ms/step - loss: 4.6848\n16/16 [==============================] - 0s 1ms/step - loss: 4.6848\n\nTesting for epoch 22 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.3087\n16/16 [==============================] - 0s 3ms/step - loss: 4.3090\n16/16 [==============================] - 0s 3ms/step - loss: 4.6928\n16/16 [==============================] - 0s 1ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 1ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n16/16 [==============================] - 0s 2ms/step - loss: 4.6939\n\nTesting for epoch 22 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3293\n16/16 [==============================] - 0s 3ms/step - loss: 4.3296\n16/16 [==============================] - 0s 2ms/step - loss: 4.7114\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n16/16 [==============================] - 0s 2ms/step - loss: 4.7125\n\nTesting for epoch 22 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 4.3222\n16/16 [==============================] - 0s 2ms/step - loss: 4.3225\n16/16 [==============================] - 0s 2ms/step - loss: 4.7039\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 3ms/step - loss: 4.7050\n16/16 [==============================] - 0s 3ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n\nTesting for epoch 22 index 16:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.3243\n16/16 [==============================] - 0s 2ms/step - loss: 4.3246\n16/16 [==============================] - 0s 2ms/step - loss: 4.7087\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 1ms/step - loss: 4.7098\n16/16 [==============================] - 0s 2ms/step - loss: 4.7098\n\nTesting for epoch 22 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3615\n16/16 [==============================] - 0s 2ms/step - loss: 4.3617\n16/16 [==============================] - 0s 3ms/step - loss: 4.7409\n16/16 [==============================] - 0s 1ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 2ms/step - loss: 4.7420\n16/16 [==============================] - 0s 1ms/step - loss: 4.7420\n\nTesting for epoch 22 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 2ms/step - loss: 4.3704\n16/16 [==============================] - 0s 2ms/step - loss: 4.3707\n16/16 [==============================] - 0s 2ms/step - loss: 4.7505\n16/16 [==============================] - 0s 4ms/step - loss: 4.7516\n16/16 [==============================] - 0s 2ms/step - loss: 4.7516\n16/16 [==============================] - 0s 3ms/step - loss: 4.7516\n16/16 [==============================] - 0s 1ms/step - loss: 4.7516\n16/16 [==============================] - 0s 2ms/step - loss: 4.7516\n16/16 [==============================] - 0s 3ms/step - loss: 4.7516\n\nTesting for epoch 22 index 19:\n391/391 [==============================] - 0s 993us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.3239\n16/16 [==============================] - 0s 1ms/step - loss: 4.3242\n16/16 [==============================] - 0s 3ms/step - loss: 4.7060\n16/16 [==============================] - 0s 3ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n16/16 [==============================] - 0s 3ms/step - loss: 4.7071\n16/16 [==============================] - 0s 2ms/step - loss: 4.7071\n\nTesting for epoch 22 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.3742\n16/16 [==============================] - 0s 2ms/step - loss: 4.3744\n16/16 [==============================] - 0s 2ms/step - loss: 4.7507\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 3ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n16/16 [==============================] - 0s 2ms/step - loss: 4.7518\n16/16 [==============================] - 0s 1ms/step - loss: 4.7518\n\nTesting for epoch 22 index 21:\n391/391 [==============================] - 0s 918us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.4461\n16/16 [==============================] - 0s 1ms/step - loss: 4.4464\n16/16 [==============================] - 0s 2ms/step - loss: 4.8190\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 3ms/step - loss: 4.8201\n16/16 [==============================] - 0s 2ms/step - loss: 4.8201\n16/16 [==============================] - 0s 1ms/step - loss: 4.8201\n\nTesting for epoch 22 index 22:\n391/391 [==============================] - 0s 965us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.4383\n16/16 [==============================] - 0s 2ms/step - loss: 4.4386\n16/16 [==============================] - 0s 2ms/step - loss: 4.8103\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 3ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n\nTesting for epoch 22 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 4ms/step - loss: 4.4555\n16/16 [==============================] - 0s 1ms/step - loss: 4.4558\n16/16 [==============================] - 0s 2ms/step - loss: 4.8272\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 2ms/step - loss: 4.8283\n16/16 [==============================] - 0s 4ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n16/16 [==============================] - 0s 1ms/step - loss: 4.8283\n\nTesting for epoch 22 index 24:\n391/391 [==============================] - 0s 989us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.4925\n16/16 [==============================] - 0s 3ms/step - loss: 4.4928\n16/16 [==============================] - 0s 3ms/step - loss: 4.8605\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 1ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\n16/16 [==============================] - 0s 2ms/step - loss: 4.8615\nEpoch 23 of 60\n\nTesting for epoch 23 index 1:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 3ms/step - loss: 4.4335\n16/16 [==============================] - 0s 1ms/step - loss: 4.4337\n16/16 [==============================] - 0s 2ms/step - loss: 4.8087\n16/16 [==============================] - 0s 2ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 3ms/step - loss: 4.8098\n16/16 [==============================] - 0s 2ms/step - loss: 4.8098\n\nTesting for epoch 23 index 2:\n391/391 [==============================] - 0s 951us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4281\n16/16 [==============================] - 0s 1ms/step - loss: 4.4284\n16/16 [==============================] - 0s 1ms/step - loss: 4.8030\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8041\n\nTesting for epoch 23 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4436\n16/16 [==============================] - 0s 2ms/step - loss: 4.4439\n16/16 [==============================] - 0s 2ms/step - loss: 4.8185\n16/16 [==============================] - 0s 3ms/step - loss: 4.8196\n16/16 [==============================] - 0s 1ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n\nTesting for epoch 23 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 1ms/step - loss: 4.4666\n16/16 [==============================] - 0s 1ms/step - loss: 4.4669\n16/16 [==============================] - 0s 1ms/step - loss: 4.8390\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n16/16 [==============================] - 0s 4ms/step - loss: 4.8401\n16/16 [==============================] - 0s 3ms/step - loss: 4.8401\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n16/16 [==============================] - 0s 1ms/step - loss: 4.8401\n16/16 [==============================] - 0s 2ms/step - loss: 4.8401\n\nTesting for epoch 23 index 5:\n391/391 [==============================] - 0s 997us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 1ms/step - loss: 4.4613\n16/16 [==============================] - 0s 2ms/step - loss: 4.4616\n16/16 [==============================] - 0s 1ms/step - loss: 4.8346\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n16/16 [==============================] - 0s 1ms/step - loss: 4.8357\n16/16 [==============================] - 0s 1ms/step - loss: 4.8357\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n16/16 [==============================] - 0s 3ms/step - loss: 4.8357\n16/16 [==============================] - 0s 2ms/step - loss: 4.8357\n\nTesting for epoch 23 index 6:\n391/391 [==============================] - 0s 986us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.4197\n16/16 [==============================] - 0s 1ms/step - loss: 4.4200\n16/16 [==============================] - 0s 2ms/step - loss: 4.7974\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n16/16 [==============================] - 0s 2ms/step - loss: 4.7984\n\nTesting for epoch 23 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 4.4492\n16/16 [==============================] - 0s 2ms/step - loss: 4.4495\n16/16 [==============================] - 0s 2ms/step - loss: 4.8234\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 1ms/step - loss: 4.8245\n16/16 [==============================] - 0s 4ms/step - loss: 4.8245\n\nTesting for epoch 23 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.4667\n16/16 [==============================] - 0s 3ms/step - loss: 4.4670\n16/16 [==============================] - 0s 3ms/step - loss: 4.8407\n16/16 [==============================] - 0s 1ms/step - loss: 4.8418\n16/16 [==============================] - 0s 3ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n16/16 [==============================] - 0s 1ms/step - loss: 4.8418\n16/16 [==============================] - 0s 2ms/step - loss: 4.8418\n\nTesting for epoch 23 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 1ms/step - loss: 4.4875\n16/16 [==============================] - 0s 3ms/step - loss: 4.4878\n16/16 [==============================] - 0s 2ms/step - loss: 4.8594\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 3ms/step - loss: 4.8605\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 2ms/step - loss: 4.8605\n16/16 [==============================] - 0s 1ms/step - loss: 4.8605\n16/16 [==============================] - 0s 5ms/step - loss: 4.8605\n\nTesting for epoch 23 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.4148\n16/16 [==============================] - 0s 2ms/step - loss: 4.4150\n16/16 [==============================] - 0s 2ms/step - loss: 4.7937\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 4ms/step - loss: 4.7948\n16/16 [==============================] - 0s 2ms/step - loss: 4.7948\n16/16 [==============================] - 0s 3ms/step - loss: 4.7948\n\nTesting for epoch 23 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.3964\n16/16 [==============================] - 0s 2ms/step - loss: 4.3967\n16/16 [==============================] - 0s 1ms/step - loss: 4.7782\n16/16 [==============================] - 0s 1ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 4ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n16/16 [==============================] - 0s 2ms/step - loss: 4.7793\n\nTesting for epoch 23 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 3ms/step - loss: 4.4029\n16/16 [==============================] - 0s 2ms/step - loss: 4.4032\n16/16 [==============================] - 0s 1ms/step - loss: 4.7863\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 1ms/step - loss: 4.7874\n16/16 [==============================] - 0s 4ms/step - loss: 4.7874\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 2ms/step - loss: 4.7874\n16/16 [==============================] - 0s 1ms/step - loss: 4.7874\n\nTesting for epoch 23 index 13:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 4.4024\n16/16 [==============================] - 0s 2ms/step - loss: 4.4027\n16/16 [==============================] - 0s 2ms/step - loss: 4.7849\n16/16 [==============================] - 0s 1ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 2ms/step - loss: 4.7860\n16/16 [==============================] - 0s 1ms/step - loss: 4.7860\n\nTesting for epoch 23 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 1ms/step - loss: 4.4157\n16/16 [==============================] - 0s 2ms/step - loss: 4.4160\n16/16 [==============================] - 0s 2ms/step - loss: 4.7979\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n16/16 [==============================] - 0s 2ms/step - loss: 4.7990\n\nTesting for epoch 23 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0050\n16/16 [==============================] - 0s 2ms/step - loss: 4.4537\n16/16 [==============================] - 0s 1ms/step - loss: 4.4539\n16/16 [==============================] - 0s 2ms/step - loss: 4.8338\n16/16 [==============================] - 0s 1ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 2ms/step - loss: 4.8349\n16/16 [==============================] - 0s 3ms/step - loss: 4.8349\n\nTesting for epoch 23 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 4.4932\n16/16 [==============================] - 0s 2ms/step - loss: 4.4934\n16/16 [==============================] - 0s 1ms/step - loss: 4.8687\n16/16 [==============================] - 0s 3ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n16/16 [==============================] - 0s 3ms/step - loss: 4.8697\n16/16 [==============================] - 0s 2ms/step - loss: 4.8697\n\nTesting for epoch 23 index 17:\n391/391 [==============================] - 0s 1000us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.4651\n16/16 [==============================] - 0s 1ms/step - loss: 4.4654\n16/16 [==============================] - 0s 1ms/step - loss: 4.8447\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 2ms/step - loss: 4.8458\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 3ms/step - loss: 4.8458\n16/16 [==============================] - 0s 1ms/step - loss: 4.8458\n16/16 [==============================] - 0s 2ms/step - loss: 4.8458\n\nTesting for epoch 23 index 18:\n391/391 [==============================] - 0s 936us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4351\n16/16 [==============================] - 0s 1ms/step - loss: 4.4354\n16/16 [==============================] - 0s 2ms/step - loss: 4.8153\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 1ms/step - loss: 4.8164\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n16/16 [==============================] - 0s 2ms/step - loss: 4.8164\n\nTesting for epoch 23 index 19:\n391/391 [==============================] - 0s 952us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5066\n16/16 [==============================] - 0s 2ms/step - loss: 4.5068\n16/16 [==============================] - 0s 2ms/step - loss: 4.8831\n16/16 [==============================] - 0s 1ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 2ms/step - loss: 4.8842\n16/16 [==============================] - 0s 3ms/step - loss: 4.8842\n\nTesting for epoch 23 index 20:\n391/391 [==============================] - 0s 939us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 4.4556\n16/16 [==============================] - 0s 2ms/step - loss: 4.4559\n16/16 [==============================] - 0s 2ms/step - loss: 4.8344\n16/16 [==============================] - 0s 3ms/step - loss: 4.8355\n16/16 [==============================] - 0s 3ms/step - loss: 4.8355\n16/16 [==============================] - 0s 2ms/step - loss: 4.8355\n16/16 [==============================] - 0s 1ms/step - loss: 4.8355\n16/16 [==============================] - 0s 1ms/step - loss: 4.8355\n16/16 [==============================] - 0s 2ms/step - loss: 4.8355\n\nTesting for epoch 23 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.5131\n16/16 [==============================] - 0s 1ms/step - loss: 4.5133\n16/16 [==============================] - 0s 728us/step - loss: 4.8877\n16/16 [==============================] - 0s 1ms/step - loss: 4.8887\n16/16 [==============================] - 0s 2ms/step - loss: 4.8887\n16/16 [==============================] - 0s 889us/step - loss: 4.8887\n16/16 [==============================] - 0s 772us/step - loss: 4.8887\n16/16 [==============================] - 0s 838us/step - loss: 4.8887\n16/16 [==============================] - 0s 849us/step - loss: 4.8887\n\nTesting for epoch 23 index 22:\n391/391 [==============================] - 0s 893us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 4.4867\n16/16 [==============================] - 0s 1ms/step - loss: 4.4870\n16/16 [==============================] - 0s 902us/step - loss: 4.8632\n16/16 [==============================] - 0s 2ms/step - loss: 4.8643\n16/16 [==============================] - 0s 1ms/step - loss: 4.8643\n16/16 [==============================] - 0s 3ms/step - loss: 4.8643\n16/16 [==============================] - 0s 3ms/step - loss: 4.8643\n16/16 [==============================] - 0s 2ms/step - loss: 4.8643\n16/16 [==============================] - 0s 928us/step - loss: 4.8643\n\nTesting for epoch 23 index 23:\n391/391 [==============================] - 0s 903us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0052\n16/16 [==============================] - 0s 1ms/step - loss: 4.5020\n16/16 [==============================] - 0s 778us/step - loss: 4.5023\n16/16 [==============================] - 0s 851us/step - loss: 4.8761\n16/16 [==============================] - 0s 917us/step - loss: 4.8772\n16/16 [==============================] - 0s 969us/step - loss: 4.8772\n16/16 [==============================] - 0s 1ms/step - loss: 4.8772\n16/16 [==============================] - 0s 935us/step - loss: 4.8772\n16/16 [==============================] - 0s 4ms/step - loss: 4.8772\n16/16 [==============================] - 0s 3ms/step - loss: 4.8772\n\nTesting for epoch 23 index 24:\n391/391 [==============================] - 0s 647us/step\n16/16 [==============================] - 0s 955us/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.5345\n16/16 [==============================] - 0s 909us/step - loss: 4.5348\n16/16 [==============================] - 0s 2ms/step - loss: 4.9093\n16/16 [==============================] - 0s 867us/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 2ms/step - loss: 4.9104\n16/16 [==============================] - 0s 3ms/step - loss: 4.9104\n16/16 [==============================] - 0s 1ms/step - loss: 4.9104\nEpoch 24 of 60\n\nTesting for epoch 24 index 1:\n391/391 [==============================] - 0s 672us/step\n16/16 [==============================] - 0s 927us/step - loss: 0.0042\n16/16 [==============================] - 0s 916us/step - loss: 4.5175\n16/16 [==============================] - 0s 913us/step - loss: 4.5178\n16/16 [==============================] - 0s 900us/step - loss: 4.8923\n16/16 [==============================] - 0s 892us/step - loss: 4.8934\n16/16 [==============================] - 0s 925us/step - loss: 4.8934\n16/16 [==============================] - 0s 879us/step - loss: 4.8934\n16/16 [==============================] - 0s 876us/step - loss: 4.8934\n16/16 [==============================] - 0s 881us/step - loss: 4.8934\n16/16 [==============================] - 0s 879us/step - loss: 4.8934\n\nTesting for epoch 24 index 2:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 902us/step - loss: 0.0049\n16/16 [==============================] - 0s 904us/step - loss: 4.5500\n16/16 [==============================] - 0s 916us/step - loss: 4.5503\n16/16 [==============================] - 0s 944us/step - loss: 4.9224\n16/16 [==============================] - 0s 910us/step - loss: 4.9234\n16/16 [==============================] - 0s 918us/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n16/16 [==============================] - 0s 6ms/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n16/16 [==============================] - 0s 2ms/step - loss: 4.9234\n\nTesting for epoch 24 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 5ms/step - loss: 4.5574\n16/16 [==============================] - 0s 2ms/step - loss: 4.5577\n16/16 [==============================] - 0s 2ms/step - loss: 4.9311\n16/16 [==============================] - 0s 3ms/step - loss: 4.9322\n16/16 [==============================] - 0s 2ms/step - loss: 4.9322\n16/16 [==============================] - 0s 3ms/step - loss: 4.9322\n16/16 [==============================] - 0s 2ms/step - loss: 4.9322\n16/16 [==============================] - 0s 1ms/step - loss: 4.9322\n16/16 [==============================] - 0s 994us/step - loss: 4.9322\n\nTesting for epoch 24 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 5ms/step - loss: 4.5304\n16/16 [==============================] - 0s 2ms/step - loss: 4.5307\n16/16 [==============================] - 0s 2ms/step - loss: 4.9069\n16/16 [==============================] - 0s 4ms/step - loss: 4.9079\n16/16 [==============================] - 0s 2ms/step - loss: 4.9079\n16/16 [==============================] - 0s 5ms/step - loss: 4.9079\n16/16 [==============================] - 0s 4ms/step - loss: 4.9079\n16/16 [==============================] - 0s 3ms/step - loss: 4.9079\n16/16 [==============================] - 0s 2ms/step - loss: 4.9079\n\nTesting for epoch 24 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 982us/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.4956\n16/16 [==============================] - 0s 796us/step - loss: 4.4959\n16/16 [==============================] - 0s 758us/step - loss: 4.8745\n16/16 [==============================] - 0s 754us/step - loss: 4.8756\n16/16 [==============================] - 0s 768us/step - loss: 4.8756\n16/16 [==============================] - 0s 726us/step - loss: 4.8756\n16/16 [==============================] - 0s 842us/step - loss: 4.8756\n16/16 [==============================] - 0s 4ms/step - loss: 4.8756\n16/16 [==============================] - 0s 2ms/step - loss: 4.8756\n\nTesting for epoch 24 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0053\n16/16 [==============================] - 0s 1ms/step - loss: 4.5620\n16/16 [==============================] - 0s 991us/step - loss: 4.5623\n16/16 [==============================] - 0s 1ms/step - loss: 4.9368\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n16/16 [==============================] - 0s 2ms/step - loss: 4.9379\n16/16 [==============================] - 0s 1ms/step - loss: 4.9379\n\nTesting for epoch 24 index 7:\n391/391 [==============================] - 0s 914us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5452\n16/16 [==============================] - 0s 2ms/step - loss: 4.5454\n16/16 [==============================] - 0s 2ms/step - loss: 4.9175\n16/16 [==============================] - 0s 3ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 1ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n16/16 [==============================] - 0s 2ms/step - loss: 4.9186\n\nTesting for epoch 24 index 8:\n391/391 [==============================] - 0s 881us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.5784\n16/16 [==============================] - 0s 3ms/step - loss: 4.5786\n16/16 [==============================] - 0s 3ms/step - loss: 4.9519\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 3ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n\nTesting for epoch 24 index 9:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.5186\n16/16 [==============================] - 0s 1ms/step - loss: 4.5188\n16/16 [==============================] - 0s 1ms/step - loss: 4.8953\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 3ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 2ms/step - loss: 4.8963\n16/16 [==============================] - 0s 4ms/step - loss: 4.8963\n\nTesting for epoch 24 index 10:\n391/391 [==============================] - 0s 903us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 4.4716\n16/16 [==============================] - 0s 2ms/step - loss: 4.4719\n16/16 [==============================] - 0s 1ms/step - loss: 4.8556\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n16/16 [==============================] - 0s 1ms/step - loss: 4.8567\n16/16 [==============================] - 0s 1ms/step - loss: 4.8567\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n16/16 [==============================] - 0s 3ms/step - loss: 4.8567\n16/16 [==============================] - 0s 2ms/step - loss: 4.8567\n\nTesting for epoch 24 index 11:\n391/391 [==============================] - 0s 949us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.5166\n16/16 [==============================] - 0s 3ms/step - loss: 4.5169\n16/16 [==============================] - 0s 2ms/step - loss: 4.8974\n16/16 [==============================] - 0s 1ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 3ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n\nTesting for epoch 24 index 12:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0044\n16/16 [==============================] - 0s 3ms/step - loss: 4.5020\n16/16 [==============================] - 0s 2ms/step - loss: 4.5023\n16/16 [==============================] - 0s 2ms/step - loss: 4.8845\n16/16 [==============================] - 0s 1ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n16/16 [==============================] - 0s 1ms/step - loss: 4.8856\n16/16 [==============================] - 0s 3ms/step - loss: 4.8856\n16/16 [==============================] - 0s 2ms/step - loss: 4.8856\n\nTesting for epoch 24 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0049\n16/16 [==============================] - 0s 3ms/step - loss: 4.5226\n16/16 [==============================] - 0s 2ms/step - loss: 4.5229\n16/16 [==============================] - 0s 1ms/step - loss: 4.9059\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n16/16 [==============================] - 0s 2ms/step - loss: 4.9070\n\nTesting for epoch 24 index 14:\n391/391 [==============================] - 0s 960us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.4661\n16/16 [==============================] - 0s 1ms/step - loss: 4.4663\n16/16 [==============================] - 0s 2ms/step - loss: 4.8525\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 1ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n16/16 [==============================] - 0s 2ms/step - loss: 4.8536\n\nTesting for epoch 24 index 15:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 1ms/step - loss: 4.5250\n16/16 [==============================] - 0s 1ms/step - loss: 4.5253\n16/16 [==============================] - 0s 2ms/step - loss: 4.9072\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 2ms/step - loss: 4.9083\n16/16 [==============================] - 0s 1ms/step - loss: 4.9083\n16/16 [==============================] - 0s 3ms/step - loss: 4.9083\n16/16 [==============================] - 0s 3ms/step - loss: 4.9083\n\nTesting for epoch 24 index 16:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.5276\n16/16 [==============================] - 0s 3ms/step - loss: 4.5278\n16/16 [==============================] - 0s 3ms/step - loss: 4.9098\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 2ms/step - loss: 4.9109\n16/16 [==============================] - 0s 3ms/step - loss: 4.9109\n16/16 [==============================] - 0s 3ms/step - loss: 4.9109\n\nTesting for epoch 24 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0050\n16/16 [==============================] - 0s 4ms/step - loss: 4.5145\n16/16 [==============================] - 0s 2ms/step - loss: 4.5148\n16/16 [==============================] - 0s 2ms/step - loss: 4.8985\n16/16 [==============================] - 0s 4ms/step - loss: 4.8996\n16/16 [==============================] - 0s 1ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n16/16 [==============================] - 0s 1ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n16/16 [==============================] - 0s 2ms/step - loss: 4.8996\n\nTesting for epoch 24 index 18:\n391/391 [==============================] - 0s 969us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.5528\n16/16 [==============================] - 0s 2ms/step - loss: 4.5531\n16/16 [==============================] - 0s 2ms/step - loss: 4.9327\n16/16 [==============================] - 0s 4ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 3ms/step - loss: 4.9338\n16/16 [==============================] - 0s 4ms/step - loss: 4.9338\n16/16 [==============================] - 0s 2ms/step - loss: 4.9338\n\nTesting for epoch 24 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.5499\n16/16 [==============================] - 0s 4ms/step - loss: 4.5501\n16/16 [==============================] - 0s 3ms/step - loss: 4.9307\n16/16 [==============================] - 0s 1ms/step - loss: 4.9318\n16/16 [==============================] - 0s 3ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 4ms/step - loss: 4.9318\n16/16 [==============================] - 0s 3ms/step - loss: 4.9318\n\nTesting for epoch 24 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.5648\n16/16 [==============================] - 0s 4ms/step - loss: 4.5651\n16/16 [==============================] - 0s 4ms/step - loss: 4.9456\n16/16 [==============================] - 0s 1ms/step - loss: 4.9467\n16/16 [==============================] - 0s 4ms/step - loss: 4.9467\n16/16 [==============================] - 0s 2ms/step - loss: 4.9467\n16/16 [==============================] - 0s 1ms/step - loss: 4.9467\n16/16 [==============================] - 0s 3ms/step - loss: 4.9467\n16/16 [==============================] - 0s 2ms/step - loss: 4.9467\n\nTesting for epoch 24 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.5633\n16/16 [==============================] - 0s 2ms/step - loss: 4.5635\n16/16 [==============================] - 0s 2ms/step - loss: 4.9406\n16/16 [==============================] - 0s 3ms/step - loss: 4.9417\n16/16 [==============================] - 0s 4ms/step - loss: 4.9417\n16/16 [==============================] - 0s 1ms/step - loss: 4.9417\n16/16 [==============================] - 0s 2ms/step - loss: 4.9417\n16/16 [==============================] - 0s 4ms/step - loss: 4.9417\n16/16 [==============================] - 0s 2ms/step - loss: 4.9417\n\nTesting for epoch 24 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6313\n16/16 [==============================] - 0s 2ms/step - loss: 4.6316\n16/16 [==============================] - 0s 1ms/step - loss: 5.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.0056\n16/16 [==============================] - 0s 2ms/step - loss: 5.0056\n16/16 [==============================] - 0s 6ms/step - loss: 5.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.0056\n16/16 [==============================] - 0s 4ms/step - loss: 5.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.0056\n\nTesting for epoch 24 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.5702\n16/16 [==============================] - 0s 4ms/step - loss: 4.5705\n16/16 [==============================] - 0s 4ms/step - loss: 4.9485\n16/16 [==============================] - 0s 5ms/step - loss: 4.9496\n16/16 [==============================] - 0s 6ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n16/16 [==============================] - 0s 1ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n16/16 [==============================] - 0s 2ms/step - loss: 4.9496\n\nTesting for epoch 24 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 4ms/step - loss: 4.6156\n16/16 [==============================] - 0s 2ms/step - loss: 4.6158\n16/16 [==============================] - 0s 3ms/step - loss: 4.9893\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\n16/16 [==============================] - 0s 3ms/step - loss: 4.9903\n16/16 [==============================] - 0s 3ms/step - loss: 4.9903\n16/16 [==============================] - 0s 2ms/step - loss: 4.9903\nEpoch 25 of 60\n\nTesting for epoch 25 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.5986\n16/16 [==============================] - 0s 1ms/step - loss: 4.5989\n16/16 [==============================] - 0s 2ms/step - loss: 4.9743\n16/16 [==============================] - 0s 4ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n16/16 [==============================] - 0s 1ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n16/16 [==============================] - 0s 3ms/step - loss: 4.9754\n16/16 [==============================] - 0s 2ms/step - loss: 4.9754\n\nTesting for epoch 25 index 2:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.6342\n16/16 [==============================] - 0s 3ms/step - loss: 4.6345\n16/16 [==============================] - 0s 2ms/step - loss: 5.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 4ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.0054\n16/16 [==============================] - 0s 3ms/step - loss: 5.0054\n\nTesting for epoch 25 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 3ms/step - loss: 4.5546\n16/16 [==============================] - 0s 2ms/step - loss: 4.5548\n16/16 [==============================] - 0s 2ms/step - loss: 4.9358\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 2ms/step - loss: 4.9369\n16/16 [==============================] - 0s 4ms/step - loss: 4.9369\n16/16 [==============================] - 0s 3ms/step - loss: 4.9369\n16/16 [==============================] - 0s 2ms/step - loss: 4.9369\n\nTesting for epoch 25 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 4ms/step - loss: 4.5968\n16/16 [==============================] - 0s 2ms/step - loss: 4.5971\n16/16 [==============================] - 0s 2ms/step - loss: 4.9745\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 3ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 3ms/step - loss: 4.9755\n\nTesting for epoch 25 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.6556\n16/16 [==============================] - 0s 2ms/step - loss: 4.6558\n16/16 [==============================] - 0s 2ms/step - loss: 5.0294\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 3ms/step - loss: 5.0305\n16/16 [==============================] - 0s 4ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n16/16 [==============================] - 0s 2ms/step - loss: 5.0305\n\nTesting for epoch 25 index 6:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6253\n16/16 [==============================] - 0s 1ms/step - loss: 4.6255\n16/16 [==============================] - 0s 3ms/step - loss: 5.0007\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 4ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 2ms/step - loss: 5.0018\n16/16 [==============================] - 0s 4ms/step - loss: 5.0018\n\nTesting for epoch 25 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6650\n16/16 [==============================] - 0s 2ms/step - loss: 4.6652\n16/16 [==============================] - 0s 3ms/step - loss: 5.0360\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n16/16 [==============================] - 0s 3ms/step - loss: 5.0371\n16/16 [==============================] - 0s 2ms/step - loss: 5.0371\n\nTesting for epoch 25 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 4.6731\n16/16 [==============================] - 0s 2ms/step - loss: 4.6734\n16/16 [==============================] - 0s 2ms/step - loss: 5.0440\n16/16 [==============================] - 0s 4ms/step - loss: 5.0451\n16/16 [==============================] - 0s 2ms/step - loss: 5.0451\n16/16 [==============================] - 0s 2ms/step - loss: 5.0451\n16/16 [==============================] - 0s 1ms/step - loss: 5.0451\n16/16 [==============================] - 0s 1ms/step - loss: 5.0451\n16/16 [==============================] - 0s 3ms/step - loss: 5.0451\n\nTesting for epoch 25 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.6489\n16/16 [==============================] - 0s 2ms/step - loss: 4.6492\n16/16 [==============================] - 0s 3ms/step - loss: 5.0231\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 3ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n16/16 [==============================] - 0s 2ms/step - loss: 5.0242\n\nTesting for epoch 25 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.6536\n16/16 [==============================] - 0s 2ms/step - loss: 4.6538\n16/16 [==============================] - 0s 1ms/step - loss: 5.0274\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 4ms/step - loss: 5.0285\n16/16 [==============================] - 0s 3ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n16/16 [==============================] - 0s 2ms/step - loss: 5.0285\n\nTesting for epoch 25 index 11:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.6177\n16/16 [==============================] - 0s 3ms/step - loss: 4.6180\n16/16 [==============================] - 0s 2ms/step - loss: 4.9958\n16/16 [==============================] - 0s 1ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 3ms/step - loss: 4.9969\n16/16 [==============================] - 0s 2ms/step - loss: 4.9969\n16/16 [==============================] - 0s 2ms/step - loss: 4.9969\n\nTesting for epoch 25 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 4.5564\n16/16 [==============================] - 0s 2ms/step - loss: 4.5567\n16/16 [==============================] - 0s 2ms/step - loss: 4.9399\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 3ms/step - loss: 4.9410\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 2ms/step - loss: 4.9410\n16/16 [==============================] - 0s 5ms/step - loss: 4.9410\n16/16 [==============================] - 0s 1ms/step - loss: 4.9410\n\nTesting for epoch 25 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 4ms/step - loss: 4.5990\n16/16 [==============================] - 0s 1ms/step - loss: 4.5992\n16/16 [==============================] - 0s 2ms/step - loss: 4.9798\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n16/16 [==============================] - 0s 2ms/step - loss: 4.9809\n\nTesting for epoch 25 index 14:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.5691\n16/16 [==============================] - 0s 3ms/step - loss: 4.5694\n16/16 [==============================] - 0s 1ms/step - loss: 4.9532\n16/16 [==============================] - 0s 3ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 2ms/step - loss: 4.9543\n16/16 [==============================] - 0s 1ms/step - loss: 4.9543\n\nTesting for epoch 25 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.5771\n16/16 [==============================] - 0s 2ms/step - loss: 4.5773\n16/16 [==============================] - 0s 3ms/step - loss: 4.9612\n16/16 [==============================] - 0s 6ms/step - loss: 4.9623\n16/16 [==============================] - 0s 1ms/step - loss: 4.9623\n16/16 [==============================] - 0s 4ms/step - loss: 4.9623\n16/16 [==============================] - 0s 2ms/step - loss: 4.9623\n16/16 [==============================] - 0s 4ms/step - loss: 4.9623\n16/16 [==============================] - 0s 2ms/step - loss: 4.9623\n\nTesting for epoch 25 index 16:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.6363\n16/16 [==============================] - 0s 3ms/step - loss: 4.6366\n16/16 [==============================] - 0s 2ms/step - loss: 5.0167\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n16/16 [==============================] - 0s 4ms/step - loss: 5.0178\n16/16 [==============================] - 0s 4ms/step - loss: 5.0178\n16/16 [==============================] - 0s 3ms/step - loss: 5.0178\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n16/16 [==============================] - 0s 2ms/step - loss: 5.0178\n\nTesting for epoch 25 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.5898\n16/16 [==============================] - 0s 4ms/step - loss: 4.5900\n16/16 [==============================] - 0s 2ms/step - loss: 4.9764\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 2ms/step - loss: 4.9775\n16/16 [==============================] - 0s 5ms/step - loss: 4.9775\n\nTesting for epoch 25 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0052\n16/16 [==============================] - 0s 2ms/step - loss: 4.6715\n16/16 [==============================] - 0s 1ms/step - loss: 4.6718\n16/16 [==============================] - 0s 4ms/step - loss: 5.0505\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 1ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n16/16 [==============================] - 0s 2ms/step - loss: 5.0516\n\nTesting for epoch 25 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.5936\n16/16 [==============================] - 0s 3ms/step - loss: 4.5939\n16/16 [==============================] - 0s 3ms/step - loss: 4.9759\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n16/16 [==============================] - 0s 3ms/step - loss: 4.9770\n16/16 [==============================] - 0s 3ms/step - loss: 4.9770\n16/16 [==============================] - 0s 2ms/step - loss: 4.9770\n\nTesting for epoch 25 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.6637\n16/16 [==============================] - 0s 2ms/step - loss: 4.6639\n16/16 [==============================] - 0s 1ms/step - loss: 5.0420\n16/16 [==============================] - 0s 1ms/step - loss: 5.0431\n16/16 [==============================] - 0s 3ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 2ms/step - loss: 5.0431\n16/16 [==============================] - 0s 3ms/step - loss: 5.0431\n\nTesting for epoch 25 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.6343\n16/16 [==============================] - 0s 2ms/step - loss: 4.6346\n16/16 [==============================] - 0s 2ms/step - loss: 5.0134\n16/16 [==============================] - 0s 2ms/step - loss: 5.0145\n16/16 [==============================] - 0s 3ms/step - loss: 5.0145\n16/16 [==============================] - 0s 5ms/step - loss: 5.0145\n16/16 [==============================] - 0s 4ms/step - loss: 5.0145\n16/16 [==============================] - 0s 2ms/step - loss: 5.0145\n16/16 [==============================] - 0s 3ms/step - loss: 5.0145\n\nTesting for epoch 25 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 5ms/step - loss: 4.6510\n16/16 [==============================] - 0s 1ms/step - loss: 4.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.0289\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 2ms/step - loss: 5.0300\n16/16 [==============================] - 0s 3ms/step - loss: 5.0300\n\nTesting for epoch 25 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6468\n16/16 [==============================] - 0s 2ms/step - loss: 4.6470\n16/16 [==============================] - 0s 2ms/step - loss: 5.0261\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 4ms/step - loss: 5.0272\n16/16 [==============================] - 0s 3ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n16/16 [==============================] - 0s 2ms/step - loss: 5.0272\n\nTesting for epoch 25 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.6585\n16/16 [==============================] - 0s 2ms/step - loss: 4.6588\n16/16 [==============================] - 0s 3ms/step - loss: 5.0362\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 3ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\n16/16 [==============================] - 0s 2ms/step - loss: 5.0373\nEpoch 26 of 60\n\nTesting for epoch 26 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.6691\n16/16 [==============================] - 0s 4ms/step - loss: 4.6694\n16/16 [==============================] - 0s 1ms/step - loss: 5.0468\n16/16 [==============================] - 0s 3ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 2ms/step - loss: 5.0479\n16/16 [==============================] - 0s 4ms/step - loss: 5.0479\n\nTesting for epoch 26 index 2:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7218\n16/16 [==============================] - 0s 2ms/step - loss: 4.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.0958\n16/16 [==============================] - 0s 4ms/step - loss: 5.0969\n16/16 [==============================] - 0s 1ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 2ms/step - loss: 5.0969\n16/16 [==============================] - 0s 3ms/step - loss: 5.0969\n\nTesting for epoch 26 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7019\n16/16 [==============================] - 0s 2ms/step - loss: 4.7021\n16/16 [==============================] - 0s 2ms/step - loss: 5.0772\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 2ms/step - loss: 5.0783\n16/16 [==============================] - 0s 3ms/step - loss: 5.0783\n\nTesting for epoch 26 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.7218\n16/16 [==============================] - 0s 3ms/step - loss: 4.7220\n16/16 [==============================] - 0s 1ms/step - loss: 5.0965\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 4ms/step - loss: 5.0976\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 2ms/step - loss: 5.0976\n16/16 [==============================] - 0s 4ms/step - loss: 5.0976\n16/16 [==============================] - 0s 3ms/step - loss: 5.0976\n\nTesting for epoch 26 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 4.6918\n16/16 [==============================] - 0s 4ms/step - loss: 4.6921\n16/16 [==============================] - 0s 3ms/step - loss: 5.0687\n16/16 [==============================] - 0s 1ms/step - loss: 5.0698\n16/16 [==============================] - 0s 3ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 2ms/step - loss: 5.0698\n16/16 [==============================] - 0s 3ms/step - loss: 5.0698\n\nTesting for epoch 26 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.6579\n16/16 [==============================] - 0s 3ms/step - loss: 4.6582\n16/16 [==============================] - 0s 2ms/step - loss: 5.0385\n16/16 [==============================] - 0s 4ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 2ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 3ms/step - loss: 5.0396\n16/16 [==============================] - 0s 2ms/step - loss: 5.0396\n\nTesting for epoch 26 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.7216\n16/16 [==============================] - 0s 2ms/step - loss: 4.7219\n16/16 [==============================] - 0s 4ms/step - loss: 5.0961\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 4ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 4ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n16/16 [==============================] - 0s 2ms/step - loss: 5.0972\n\nTesting for epoch 26 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.7682\n16/16 [==============================] - 0s 2ms/step - loss: 4.7685\n16/16 [==============================] - 0s 2ms/step - loss: 5.1377\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 3ms/step - loss: 5.1387\n\nTesting for epoch 26 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.7503\n16/16 [==============================] - 0s 2ms/step - loss: 4.7506\n16/16 [==============================] - 0s 2ms/step - loss: 5.1235\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 3ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 3ms/step - loss: 5.1245\n\nTesting for epoch 26 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.7142\n16/16 [==============================] - 0s 4ms/step - loss: 4.7145\n16/16 [==============================] - 0s 2ms/step - loss: 5.0894\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 3ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n16/16 [==============================] - 0s 2ms/step - loss: 5.0905\n\nTesting for epoch 26 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.6726\n16/16 [==============================] - 0s 3ms/step - loss: 4.6729\n16/16 [==============================] - 0s 3ms/step - loss: 5.0553\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n16/16 [==============================] - 0s 2ms/step - loss: 5.0564\n\nTesting for epoch 26 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 3ms/step - loss: 4.6940\n16/16 [==============================] - 0s 2ms/step - loss: 4.6943\n16/16 [==============================] - 0s 5ms/step - loss: 5.0759\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 1ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n16/16 [==============================] - 0s 1ms/step - loss: 5.0770\n16/16 [==============================] - 0s 2ms/step - loss: 5.0770\n\nTesting for epoch 26 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.6016\n16/16 [==============================] - 0s 4ms/step - loss: 4.6019\n16/16 [==============================] - 0s 2ms/step - loss: 4.9925\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n16/16 [==============================] - 0s 2ms/step - loss: 4.9937\n\nTesting for epoch 26 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 4.7050\n16/16 [==============================] - 0s 2ms/step - loss: 4.7053\n16/16 [==============================] - 0s 1ms/step - loss: 5.0868\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 1ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n16/16 [==============================] - 0s 2ms/step - loss: 5.0879\n\nTesting for epoch 26 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.5845\n16/16 [==============================] - 0s 2ms/step - loss: 4.5848\n16/16 [==============================] - 0s 2ms/step - loss: 4.9755\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n16/16 [==============================] - 0s 3ms/step - loss: 4.9766\n16/16 [==============================] - 0s 2ms/step - loss: 4.9766\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n16/16 [==============================] - 0s 2ms/step - loss: 4.9766\n16/16 [==============================] - 0s 1ms/step - loss: 4.9766\n\nTesting for epoch 26 index 16:\n391/391 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 4.6562\n16/16 [==============================] - 0s 2ms/step - loss: 4.6565\n16/16 [==============================] - 0s 2ms/step - loss: 5.0419\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 2ms/step - loss: 5.0430\n16/16 [==============================] - 0s 2ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n16/16 [==============================] - 0s 1ms/step - loss: 5.0430\n\nTesting for epoch 26 index 17:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.6432\n16/16 [==============================] - 0s 1ms/step - loss: 4.6435\n16/16 [==============================] - 0s 4ms/step - loss: 5.0313\n16/16 [==============================] - 0s 1ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n16/16 [==============================] - 0s 2ms/step - loss: 5.0325\n\nTesting for epoch 26 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.6592\n16/16 [==============================] - 0s 3ms/step - loss: 4.6595\n16/16 [==============================] - 0s 2ms/step - loss: 5.0458\n16/16 [==============================] - 0s 3ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n16/16 [==============================] - 0s 1ms/step - loss: 5.0469\n16/16 [==============================] - 0s 1ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n16/16 [==============================] - 0s 2ms/step - loss: 5.0469\n\nTesting for epoch 26 index 19:\n391/391 [==============================] - 0s 958us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 4.6840\n16/16 [==============================] - 0s 3ms/step - loss: 4.6842\n16/16 [==============================] - 0s 1ms/step - loss: 5.0688\n16/16 [==============================] - 0s 1ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n16/16 [==============================] - 0s 3ms/step - loss: 5.0699\n16/16 [==============================] - 0s 2ms/step - loss: 5.0699\n\nTesting for epoch 26 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.6582\n16/16 [==============================] - 0s 2ms/step - loss: 4.6584\n16/16 [==============================] - 0s 2ms/step - loss: 5.0441\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 3ms/step - loss: 5.0452\n16/16 [==============================] - 0s 1ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n16/16 [==============================] - 0s 2ms/step - loss: 5.0452\n\nTesting for epoch 26 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7166\n16/16 [==============================] - 0s 2ms/step - loss: 4.7169\n16/16 [==============================] - 0s 2ms/step - loss: 5.0947\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n16/16 [==============================] - 0s 2ms/step - loss: 5.0958\n\nTesting for epoch 26 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.7097\n16/16 [==============================] - 0s 1ms/step - loss: 4.7099\n16/16 [==============================] - 0s 2ms/step - loss: 5.0892\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 3ms/step - loss: 5.0903\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 1ms/step - loss: 5.0903\n16/16 [==============================] - 0s 2ms/step - loss: 5.0903\n16/16 [==============================] - 0s 3ms/step - loss: 5.0903\n\nTesting for epoch 26 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.7441\n16/16 [==============================] - 0s 3ms/step - loss: 4.7444\n16/16 [==============================] - 0s 1ms/step - loss: 5.1225\n16/16 [==============================] - 0s 2ms/step - loss: 5.1236\n16/16 [==============================] - 0s 1ms/step - loss: 5.1236\n16/16 [==============================] - 0s 1ms/step - loss: 5.1236\n16/16 [==============================] - 0s 3ms/step - loss: 5.1236\n16/16 [==============================] - 0s 2ms/step - loss: 5.1236\n16/16 [==============================] - 0s 4ms/step - loss: 5.1236\n\nTesting for epoch 26 index 24:\n391/391 [==============================] - 0s 961us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.6765\n16/16 [==============================] - 0s 2ms/step - loss: 4.6768\n16/16 [==============================] - 0s 2ms/step - loss: 5.0600\n16/16 [==============================] - 0s 2ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 1ms/step - loss: 5.0611\n16/16 [==============================] - 0s 2ms/step - loss: 5.0611\nEpoch 27 of 60\n\nTesting for epoch 27 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.7939\n16/16 [==============================] - 0s 1ms/step - loss: 4.7942\n16/16 [==============================] - 0s 2ms/step - loss: 5.1696\n16/16 [==============================] - 0s 1ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n16/16 [==============================] - 0s 1ms/step - loss: 5.1707\n16/16 [==============================] - 0s 2ms/step - loss: 5.1707\n\nTesting for epoch 27 index 2:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.7837\n16/16 [==============================] - 0s 1ms/step - loss: 4.7840\n16/16 [==============================] - 0s 1ms/step - loss: 5.1585\n16/16 [==============================] - 0s 1ms/step - loss: 5.1595\n16/16 [==============================] - 0s 2ms/step - loss: 5.1595\n16/16 [==============================] - 0s 3ms/step - loss: 5.1595\n16/16 [==============================] - 0s 2ms/step - loss: 5.1595\n16/16 [==============================] - 0s 3ms/step - loss: 5.1595\n16/16 [==============================] - 0s 1ms/step - loss: 5.1595\n\nTesting for epoch 27 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.7597\n16/16 [==============================] - 0s 2ms/step - loss: 4.7600\n16/16 [==============================] - 0s 2ms/step - loss: 5.1369\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n16/16 [==============================] - 0s 2ms/step - loss: 5.1380\n\nTesting for epoch 27 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.7954\n16/16 [==============================] - 0s 1ms/step - loss: 4.7957\n16/16 [==============================] - 0s 1ms/step - loss: 5.1705\n16/16 [==============================] - 0s 3ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n16/16 [==============================] - 0s 2ms/step - loss: 5.1716\n16/16 [==============================] - 0s 3ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n16/16 [==============================] - 0s 1ms/step - loss: 5.1716\n\nTesting for epoch 27 index 5:\n391/391 [==============================] - 0s 919us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 4.7403\n16/16 [==============================] - 0s 1ms/step - loss: 4.7406\n16/16 [==============================] - 0s 2ms/step - loss: 5.1187\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n16/16 [==============================] - 0s 3ms/step - loss: 5.1198\n16/16 [==============================] - 0s 3ms/step - loss: 5.1198\n16/16 [==============================] - 0s 2ms/step - loss: 5.1198\n\nTesting for epoch 27 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.7506\n16/16 [==============================] - 0s 3ms/step - loss: 4.7508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1292\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 1ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n16/16 [==============================] - 0s 2ms/step - loss: 5.1303\n\nTesting for epoch 27 index 7:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 4.8474\n16/16 [==============================] - 0s 1ms/step - loss: 4.8477\n16/16 [==============================] - 0s 2ms/step - loss: 5.2182\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 2ms/step - loss: 5.2193\n16/16 [==============================] - 0s 2ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n16/16 [==============================] - 0s 1ms/step - loss: 5.2193\n\nTesting for epoch 27 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7643\n16/16 [==============================] - 0s 2ms/step - loss: 4.7645\n16/16 [==============================] - 0s 3ms/step - loss: 5.1389\n16/16 [==============================] - 0s 3ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 2ms/step - loss: 5.1400\n16/16 [==============================] - 0s 3ms/step - loss: 5.1400\n16/16 [==============================] - 0s 1ms/step - loss: 5.1400\n\nTesting for epoch 27 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.8146\n16/16 [==============================] - 0s 2ms/step - loss: 4.8149\n16/16 [==============================] - 0s 2ms/step - loss: 5.1850\n16/16 [==============================] - 0s 4ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 2ms/step - loss: 5.1861\n16/16 [==============================] - 0s 3ms/step - loss: 5.1861\n\nTesting for epoch 27 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8055\n16/16 [==============================] - 0s 2ms/step - loss: 4.8058\n16/16 [==============================] - 0s 3ms/step - loss: 5.1807\n16/16 [==============================] - 0s 1ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n16/16 [==============================] - 0s 2ms/step - loss: 5.1818\n\nTesting for epoch 27 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 3ms/step - loss: 4.7670\n16/16 [==============================] - 0s 1ms/step - loss: 4.7673\n16/16 [==============================] - 0s 2ms/step - loss: 5.1448\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 1ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n16/16 [==============================] - 0s 2ms/step - loss: 5.1459\n\nTesting for epoch 27 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.7561\n16/16 [==============================] - 0s 1ms/step - loss: 4.7563\n16/16 [==============================] - 0s 2ms/step - loss: 5.1377\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 2ms/step - loss: 5.1388\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 1ms/step - loss: 5.1388\n16/16 [==============================] - 0s 2ms/step - loss: 5.1388\n16/16 [==============================] - 0s 3ms/step - loss: 5.1388\n\nTesting for epoch 27 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7256\n16/16 [==============================] - 0s 3ms/step - loss: 4.7259\n16/16 [==============================] - 0s 2ms/step - loss: 5.1121\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 2ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n16/16 [==============================] - 0s 1ms/step - loss: 5.1132\n\nTesting for epoch 27 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.7529\n16/16 [==============================] - 0s 2ms/step - loss: 4.7532\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 2ms/step - loss: 5.1398\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 3ms/step - loss: 5.1398\n16/16 [==============================] - 0s 1ms/step - loss: 5.1398\n16/16 [==============================] - 0s 2ms/step - loss: 5.1398\n\nTesting for epoch 27 index 15:\n391/391 [==============================] - 0s 884us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.8032\n16/16 [==============================] - 0s 2ms/step - loss: 4.8035\n16/16 [==============================] - 0s 1ms/step - loss: 5.1820\n16/16 [==============================] - 0s 1ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 3ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 2ms/step - loss: 5.1831\n16/16 [==============================] - 0s 3ms/step - loss: 5.1831\n\nTesting for epoch 27 index 16:\n391/391 [==============================] - 0s 991us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7280\n16/16 [==============================] - 0s 1ms/step - loss: 4.7282\n16/16 [==============================] - 0s 3ms/step - loss: 5.1128\n16/16 [==============================] - 0s 1ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 1ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n16/16 [==============================] - 0s 2ms/step - loss: 5.1139\n\nTesting for epoch 27 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 4.7865\n16/16 [==============================] - 0s 3ms/step - loss: 4.7867\n16/16 [==============================] - 0s 3ms/step - loss: 5.1673\n16/16 [==============================] - 0s 3ms/step - loss: 5.1684\n16/16 [==============================] - 0s 1ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n16/16 [==============================] - 0s 2ms/step - loss: 5.1684\n\nTesting for epoch 27 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.7361\n16/16 [==============================] - 0s 1ms/step - loss: 4.7364\n16/16 [==============================] - 0s 5ms/step - loss: 5.1233\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 1ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n16/16 [==============================] - 0s 3ms/step - loss: 5.1244\n16/16 [==============================] - 0s 2ms/step - loss: 5.1244\n\nTesting for epoch 27 index 19:\n391/391 [==============================] - 0s 898us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 4.7381\n16/16 [==============================] - 0s 2ms/step - loss: 4.7384\n16/16 [==============================] - 0s 2ms/step - loss: 5.1245\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n16/16 [==============================] - 0s 1ms/step - loss: 5.1256\n16/16 [==============================] - 0s 3ms/step - loss: 5.1256\n16/16 [==============================] - 0s 1ms/step - loss: 5.1256\n16/16 [==============================] - 0s 2ms/step - loss: 5.1256\n\nTesting for epoch 27 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.7522\n16/16 [==============================] - 0s 2ms/step - loss: 4.7525\n16/16 [==============================] - 0s 2ms/step - loss: 5.1390\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 3ms/step - loss: 5.1401\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 4ms/step - loss: 5.1401\n16/16 [==============================] - 0s 2ms/step - loss: 5.1401\n16/16 [==============================] - 0s 4ms/step - loss: 5.1401\n\nTesting for epoch 27 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.7685\n16/16 [==============================] - 0s 2ms/step - loss: 4.7688\n16/16 [==============================] - 0s 3ms/step - loss: 5.1497\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n16/16 [==============================] - 0s 1ms/step - loss: 5.1508\n16/16 [==============================] - 0s 2ms/step - loss: 5.1508\n\nTesting for epoch 27 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 4.7937\n16/16 [==============================] - 0s 3ms/step - loss: 4.7940\n16/16 [==============================] - 0s 1ms/step - loss: 5.1733\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 4ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n16/16 [==============================] - 0s 2ms/step - loss: 5.1744\n\nTesting for epoch 27 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.8606\n16/16 [==============================] - 0s 2ms/step - loss: 4.8609\n16/16 [==============================] - 0s 2ms/step - loss: 5.2362\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 3ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n\nTesting for epoch 27 index 24:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 4ms/step - loss: 4.8014\n16/16 [==============================] - 0s 1ms/step - loss: 4.8016\n16/16 [==============================] - 0s 5ms/step - loss: 5.1823\n16/16 [==============================] - 0s 4ms/step - loss: 5.1834\n16/16 [==============================] - 0s 4ms/step - loss: 5.1834\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\n16/16 [==============================] - 0s 3ms/step - loss: 5.1834\nEpoch 28 of 60\n\nTesting for epoch 28 index 1:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8196\n16/16 [==============================] - 0s 2ms/step - loss: 4.8199\n16/16 [==============================] - 0s 2ms/step - loss: 5.1984\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 2ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n16/16 [==============================] - 0s 1ms/step - loss: 5.1995\n\nTesting for epoch 28 index 2:\n391/391 [==============================] - 0s 888us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 4.8614\n16/16 [==============================] - 0s 2ms/step - loss: 4.8616\n16/16 [==============================] - 0s 2ms/step - loss: 5.2371\n16/16 [==============================] - 0s 2ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 1ms/step - loss: 5.2382\n16/16 [==============================] - 0s 3ms/step - loss: 5.2382\n16/16 [==============================] - 0s 2ms/step - loss: 5.2382\n\nTesting for epoch 28 index 3:\n391/391 [==============================] - 0s 943us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0046\n16/16 [==============================] - 0s 3ms/step - loss: 4.8859\n16/16 [==============================] - 0s 1ms/step - loss: 4.8862\n16/16 [==============================] - 0s 3ms/step - loss: 5.2595\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n16/16 [==============================] - 0s 2ms/step - loss: 5.2606\n16/16 [==============================] - 0s 4ms/step - loss: 5.2606\n16/16 [==============================] - 0s 2ms/step - loss: 5.2606\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n16/16 [==============================] - 0s 1ms/step - loss: 5.2606\n\nTesting for epoch 28 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.8114\n16/16 [==============================] - 0s 2ms/step - loss: 4.8116\n16/16 [==============================] - 0s 3ms/step - loss: 5.1907\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 1ms/step - loss: 5.1918\n\nTesting for epoch 28 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8099\n16/16 [==============================] - 0s 1ms/step - loss: 4.8102\n16/16 [==============================] - 0s 2ms/step - loss: 5.1918\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 2ms/step - loss: 5.1929\n16/16 [==============================] - 0s 1ms/step - loss: 5.1929\n16/16 [==============================] - 0s 4ms/step - loss: 5.1929\n16/16 [==============================] - 0s 3ms/step - loss: 5.1929\n\nTesting for epoch 28 index 6:\n391/391 [==============================] - 0s 792us/step\n16/16 [==============================] - 0s 858us/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8763\n16/16 [==============================] - 0s 1ms/step - loss: 4.8765\n16/16 [==============================] - 0s 1ms/step - loss: 5.2511\n16/16 [==============================] - 0s 868us/step - loss: 5.2522\n16/16 [==============================] - 0s 995us/step - loss: 5.2522\n16/16 [==============================] - 0s 1ms/step - loss: 5.2522\n16/16 [==============================] - 0s 1ms/step - loss: 5.2522\n16/16 [==============================] - 0s 923us/step - loss: 5.2522\n16/16 [==============================] - 0s 3ms/step - loss: 5.2522\n\nTesting for epoch 28 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8858\n16/16 [==============================] - 0s 2ms/step - loss: 4.8860\n16/16 [==============================] - 0s 2ms/step - loss: 5.2610\n16/16 [==============================] - 0s 3ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n16/16 [==============================] - 0s 3ms/step - loss: 5.2620\n16/16 [==============================] - 0s 4ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n16/16 [==============================] - 0s 2ms/step - loss: 5.2620\n\nTesting for epoch 28 index 8:\n391/391 [==============================] - 0s 989us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.9409\n16/16 [==============================] - 0s 3ms/step - loss: 4.9412\n16/16 [==============================] - 0s 2ms/step - loss: 5.3099\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n16/16 [==============================] - 0s 4ms/step - loss: 5.3110\n16/16 [==============================] - 0s 2ms/step - loss: 5.3110\n16/16 [==============================] - 0s 2ms/step - loss: 5.3110\n16/16 [==============================] - 0s 3ms/step - loss: 5.3110\n\nTesting for epoch 28 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.9478\n16/16 [==============================] - 0s 2ms/step - loss: 4.9481\n16/16 [==============================] - 0s 3ms/step - loss: 5.3130\n16/16 [==============================] - 0s 4ms/step - loss: 5.3141\n16/16 [==============================] - 0s 1ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n16/16 [==============================] - 0s 3ms/step - loss: 5.3141\n16/16 [==============================] - 0s 2ms/step - loss: 5.3141\n\nTesting for epoch 28 index 10:\n391/391 [==============================] - 0s 923us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8533\n16/16 [==============================] - 0s 2ms/step - loss: 4.8535\n16/16 [==============================] - 0s 2ms/step - loss: 5.2304\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n16/16 [==============================] - 0s 3ms/step - loss: 5.2314\n16/16 [==============================] - 0s 2ms/step - loss: 5.2314\n16/16 [==============================] - 0s 2ms/step - loss: 5.2314\n16/16 [==============================] - 0s 1ms/step - loss: 5.2314\n\nTesting for epoch 28 index 11:\n391/391 [==============================] - 0s 941us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8440\n16/16 [==============================] - 0s 2ms/step - loss: 4.8443\n16/16 [==============================] - 0s 1ms/step - loss: 5.2260\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 3ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 2ms/step - loss: 5.2271\n16/16 [==============================] - 0s 1ms/step - loss: 5.2271\n\nTesting for epoch 28 index 12:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.8436\n16/16 [==============================] - 0s 1ms/step - loss: 4.8439\n16/16 [==============================] - 0s 1ms/step - loss: 5.2253\n16/16 [==============================] - 0s 1ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n16/16 [==============================] - 0s 1ms/step - loss: 5.2264\n16/16 [==============================] - 0s 3ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n16/16 [==============================] - 0s 2ms/step - loss: 5.2264\n\nTesting for epoch 28 index 13:\n391/391 [==============================] - 0s 995us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.8591\n16/16 [==============================] - 0s 3ms/step - loss: 4.8593\n16/16 [==============================] - 0s 3ms/step - loss: 5.2395\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 1ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n16/16 [==============================] - 0s 2ms/step - loss: 5.2406\n\nTesting for epoch 28 index 14:\n391/391 [==============================] - 0s 925us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.8373\n16/16 [==============================] - 0s 1ms/step - loss: 4.8376\n16/16 [==============================] - 0s 2ms/step - loss: 5.2207\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n16/16 [==============================] - 0s 2ms/step - loss: 5.2218\n\nTesting for epoch 28 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 4.7881\n16/16 [==============================] - 0s 3ms/step - loss: 4.7884\n16/16 [==============================] - 0s 2ms/step - loss: 5.1765\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 2ms/step - loss: 5.1777\n16/16 [==============================] - 0s 3ms/step - loss: 5.1777\n16/16 [==============================] - 0s 1ms/step - loss: 5.1777\n\nTesting for epoch 28 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.7353\n16/16 [==============================] - 0s 2ms/step - loss: 4.7356\n16/16 [==============================] - 0s 2ms/step - loss: 5.1269\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 1ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 2ms/step - loss: 5.1280\n16/16 [==============================] - 0s 4ms/step - loss: 5.1280\n\nTesting for epoch 28 index 17:\n391/391 [==============================] - 0s 982us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8065\n16/16 [==============================] - 0s 1ms/step - loss: 4.8068\n16/16 [==============================] - 0s 2ms/step - loss: 5.1913\n16/16 [==============================] - 0s 1ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 4ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n16/16 [==============================] - 0s 2ms/step - loss: 5.1924\n\nTesting for epoch 28 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 4.7947\n16/16 [==============================] - 0s 2ms/step - loss: 4.7950\n16/16 [==============================] - 0s 2ms/step - loss: 5.1822\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 1ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n16/16 [==============================] - 0s 2ms/step - loss: 5.1834\n\nTesting for epoch 28 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 4.8317\n16/16 [==============================] - 0s 2ms/step - loss: 4.8319\n16/16 [==============================] - 0s 2ms/step - loss: 5.2162\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 1ms/step - loss: 5.2173\n16/16 [==============================] - 0s 1ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n16/16 [==============================] - 0s 2ms/step - loss: 5.2173\n\nTesting for epoch 28 index 20:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 4.8778\n16/16 [==============================] - 0s 2ms/step - loss: 4.8781\n16/16 [==============================] - 0s 3ms/step - loss: 5.2583\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 4ms/step - loss: 5.2594\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 1ms/step - loss: 5.2594\n16/16 [==============================] - 0s 3ms/step - loss: 5.2594\n16/16 [==============================] - 0s 4ms/step - loss: 5.2594\n\nTesting for epoch 28 index 21:\n391/391 [==============================] - 0s 947us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.8472\n16/16 [==============================] - 0s 1ms/step - loss: 4.8475\n16/16 [==============================] - 0s 1ms/step - loss: 5.2298\n16/16 [==============================] - 0s 3ms/step - loss: 5.2309\n16/16 [==============================] - 0s 2ms/step - loss: 5.2309\n16/16 [==============================] - 0s 1ms/step - loss: 5.2309\n16/16 [==============================] - 0s 2ms/step - loss: 5.2309\n16/16 [==============================] - 0s 3ms/step - loss: 5.2309\n16/16 [==============================] - 0s 1ms/step - loss: 5.2309\n\nTesting for epoch 28 index 22:\n391/391 [==============================] - 0s 864us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 4.8267\n16/16 [==============================] - 0s 2ms/step - loss: 4.8270\n16/16 [==============================] - 0s 2ms/step - loss: 5.2118\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 5ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n16/16 [==============================] - 0s 2ms/step - loss: 5.2129\n\nTesting for epoch 28 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8366\n16/16 [==============================] - 0s 1ms/step - loss: 4.8369\n16/16 [==============================] - 0s 1ms/step - loss: 5.2208\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 1ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n16/16 [==============================] - 0s 1ms/step - loss: 5.2219\n16/16 [==============================] - 0s 2ms/step - loss: 5.2219\n\nTesting for epoch 28 index 24:\n391/391 [==============================] - 0s 872us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.8866\n16/16 [==============================] - 0s 2ms/step - loss: 4.8869\n16/16 [==============================] - 0s 2ms/step - loss: 5.2674\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 1ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\n16/16 [==============================] - 0s 2ms/step - loss: 5.2685\nEpoch 29 of 60\n\nTesting for epoch 29 index 1:\n391/391 [==============================] - 0s 999us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.9052\n16/16 [==============================] - 0s 1ms/step - loss: 4.9055\n16/16 [==============================] - 0s 2ms/step - loss: 5.2822\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 4ms/step - loss: 5.2833\n16/16 [==============================] - 0s 3ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n16/16 [==============================] - 0s 2ms/step - loss: 5.2833\n\nTesting for epoch 29 index 2:\n391/391 [==============================] - 0s 992us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0033\n16/16 [==============================] - 0s 1ms/step - loss: 4.8451\n16/16 [==============================] - 0s 3ms/step - loss: 4.8454\n16/16 [==============================] - 0s 3ms/step - loss: 5.2292\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n16/16 [==============================] - 0s 2ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n16/16 [==============================] - 0s 1ms/step - loss: 5.2303\n\nTesting for epoch 29 index 3:\n391/391 [==============================] - 0s 948us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 3ms/step - loss: 4.9049\n16/16 [==============================] - 0s 2ms/step - loss: 4.9052\n16/16 [==============================] - 0s 2ms/step - loss: 5.2825\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 2ms/step - loss: 5.2836\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 1ms/step - loss: 5.2836\n16/16 [==============================] - 0s 2ms/step - loss: 5.2836\n16/16 [==============================] - 0s 3ms/step - loss: 5.2836\n\nTesting for epoch 29 index 4:\n391/391 [==============================] - 0s 971us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.9077\n16/16 [==============================] - 0s 2ms/step - loss: 4.9080\n16/16 [==============================] - 0s 2ms/step - loss: 5.2864\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 3ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n16/16 [==============================] - 0s 2ms/step - loss: 5.2875\n\nTesting for epoch 29 index 5:\n391/391 [==============================] - 0s 978us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 4.9268\n16/16 [==============================] - 0s 2ms/step - loss: 4.9271\n16/16 [==============================] - 0s 1ms/step - loss: 5.3043\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 1ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n16/16 [==============================] - 0s 2ms/step - loss: 5.3053\n\nTesting for epoch 29 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 4.9045\n16/16 [==============================] - 0s 1ms/step - loss: 4.9048\n16/16 [==============================] - 0s 1ms/step - loss: 5.2824\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 1ms/step - loss: 5.2835\n16/16 [==============================] - 0s 2ms/step - loss: 5.2835\n\nTesting for epoch 29 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.9455\n16/16 [==============================] - 0s 2ms/step - loss: 4.9457\n16/16 [==============================] - 0s 2ms/step - loss: 5.3194\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n16/16 [==============================] - 0s 1ms/step - loss: 5.3205\n16/16 [==============================] - 0s 1ms/step - loss: 5.3205\n16/16 [==============================] - 0s 2ms/step - loss: 5.3205\n\nTesting for epoch 29 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 4.9236\n16/16 [==============================] - 0s 2ms/step - loss: 4.9239\n16/16 [==============================] - 0s 1ms/step - loss: 5.2999\n16/16 [==============================] - 0s 2ms/step - loss: 5.3009\n16/16 [==============================] - 0s 1ms/step - loss: 5.3009\n16/16 [==============================] - 0s 3ms/step - loss: 5.3009\n16/16 [==============================] - 0s 4ms/step - loss: 5.3009\n16/16 [==============================] - 0s 1ms/step - loss: 5.3009\n16/16 [==============================] - 0s 4ms/step - loss: 5.3009\n\nTesting for epoch 29 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 5.0180\n16/16 [==============================] - 0s 2ms/step - loss: 5.0183\n16/16 [==============================] - 0s 1ms/step - loss: 5.3855\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 1ms/step - loss: 5.3866\n16/16 [==============================] - 0s 2ms/step - loss: 5.3866\n\nTesting for epoch 29 index 10:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 4.9382\n16/16 [==============================] - 0s 2ms/step - loss: 4.9385\n16/16 [==============================] - 0s 2ms/step - loss: 5.3124\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 3ms/step - loss: 5.3135\n16/16 [==============================] - 0s 4ms/step - loss: 5.3135\n16/16 [==============================] - 0s 2ms/step - loss: 5.3135\n16/16 [==============================] - 0s 3ms/step - loss: 5.3135\n\nTesting for epoch 29 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 3ms/step - loss: 4.8424\n16/16 [==============================] - 0s 1ms/step - loss: 4.8427\n16/16 [==============================] - 0s 1ms/step - loss: 5.2288\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 3ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 3ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n16/16 [==============================] - 0s 2ms/step - loss: 5.2299\n\nTesting for epoch 29 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8817\n16/16 [==============================] - 0s 2ms/step - loss: 4.8820\n16/16 [==============================] - 0s 2ms/step - loss: 5.2647\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 3ms/step - loss: 5.2658\n16/16 [==============================] - 0s 4ms/step - loss: 5.2658\n16/16 [==============================] - 0s 1ms/step - loss: 5.2658\n16/16 [==============================] - 0s 2ms/step - loss: 5.2658\n\nTesting for epoch 29 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 4.9375\n16/16 [==============================] - 0s 2ms/step - loss: 4.9377\n16/16 [==============================] - 0s 2ms/step - loss: 5.3164\n16/16 [==============================] - 0s 3ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 3ms/step - loss: 5.3175\n16/16 [==============================] - 0s 2ms/step - loss: 5.3175\n16/16 [==============================] - 0s 1ms/step - loss: 5.3175\n\nTesting for epoch 29 index 14:\n391/391 [==============================] - 0s 973us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.8467\n16/16 [==============================] - 0s 1ms/step - loss: 4.8470\n16/16 [==============================] - 0s 1ms/step - loss: 5.2326\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 1ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2337\n\nTesting for epoch 29 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.8782\n16/16 [==============================] - 0s 2ms/step - loss: 4.8785\n16/16 [==============================] - 0s 2ms/step - loss: 5.2636\n16/16 [==============================] - 0s 2ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 3ms/step - loss: 5.2647\n16/16 [==============================] - 0s 1ms/step - loss: 5.2647\n16/16 [==============================] - 0s 4ms/step - loss: 5.2647\n\nTesting for epoch 29 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 4.7841\n16/16 [==============================] - 0s 3ms/step - loss: 4.7844\n16/16 [==============================] - 0s 2ms/step - loss: 5.1782\n16/16 [==============================] - 0s 3ms/step - loss: 5.1794\n16/16 [==============================] - 0s 3ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n16/16 [==============================] - 0s 2ms/step - loss: 5.1794\n\nTesting for epoch 29 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 4.8728\n16/16 [==============================] - 0s 2ms/step - loss: 4.8731\n16/16 [==============================] - 0s 2ms/step - loss: 5.2604\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 5ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n16/16 [==============================] - 0s 2ms/step - loss: 5.2615\n\nTesting for epoch 29 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 4.9268\n16/16 [==============================] - 0s 2ms/step - loss: 4.9271\n16/16 [==============================] - 0s 2ms/step - loss: 5.3090\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 1ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 1ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n\nTesting for epoch 29 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.8500\n16/16 [==============================] - 0s 2ms/step - loss: 4.8503\n16/16 [==============================] - 0s 1ms/step - loss: 5.2378\n16/16 [==============================] - 0s 1ms/step - loss: 5.2389\n16/16 [==============================] - 0s 2ms/step - loss: 5.2389\n16/16 [==============================] - 0s 4ms/step - loss: 5.2389\n16/16 [==============================] - 0s 1ms/step - loss: 5.2389\n16/16 [==============================] - 0s 4ms/step - loss: 5.2389\n16/16 [==============================] - 0s 3ms/step - loss: 5.2389\n\nTesting for epoch 29 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0038\n16/16 [==============================] - 0s 1ms/step - loss: 4.8735\n16/16 [==============================] - 0s 1ms/step - loss: 4.8738\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 2ms/step - loss: 5.2643\n16/16 [==============================] - 0s 1ms/step - loss: 5.2643\n16/16 [==============================] - 0s 1ms/step - loss: 5.2643\n\nTesting for epoch 29 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 4.9486\n16/16 [==============================] - 0s 3ms/step - loss: 4.9489\n16/16 [==============================] - 0s 2ms/step - loss: 5.3304\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 1ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 2ms/step - loss: 5.3315\n16/16 [==============================] - 0s 1ms/step - loss: 5.3315\n\nTesting for epoch 29 index 22:\n391/391 [==============================] - 0s 926us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0035\n16/16 [==============================] - 0s 1ms/step - loss: 4.9416\n16/16 [==============================] - 0s 2ms/step - loss: 4.9419\n16/16 [==============================] - 0s 2ms/step - loss: 5.3233\n16/16 [==============================] - 0s 1ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 3ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 2ms/step - loss: 5.3244\n16/16 [==============================] - 0s 1ms/step - loss: 5.3244\n\nTesting for epoch 29 index 23:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 4.8742\n16/16 [==============================] - 0s 1ms/step - loss: 4.8745\n16/16 [==============================] - 0s 2ms/step - loss: 5.2621\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 2ms/step - loss: 5.2632\n16/16 [==============================] - 0s 1ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2632\n16/16 [==============================] - 0s 3ms/step - loss: 5.2632\n\nTesting for epoch 29 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 4.9565\n16/16 [==============================] - 0s 1ms/step - loss: 4.9568\n16/16 [==============================] - 0s 2ms/step - loss: 5.3350\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 2ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\n16/16 [==============================] - 0s 1ms/step - loss: 5.3361\n16/16 [==============================] - 0s 3ms/step - loss: 5.3361\nEpoch 30 of 60\n\nTesting for epoch 30 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 3ms/step - loss: 4.8851\n16/16 [==============================] - 0s 2ms/step - loss: 4.8853\n16/16 [==============================] - 0s 2ms/step - loss: 5.2712\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 3ms/step - loss: 5.2723\n16/16 [==============================] - 0s 2ms/step - loss: 5.2723\n16/16 [==============================] - 0s 3ms/step - loss: 5.2723\n\nTesting for epoch 30 index 2:\n391/391 [==============================] - 0s 896us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 4.9527\n16/16 [==============================] - 0s 2ms/step - loss: 4.9530\n16/16 [==============================] - 0s 2ms/step - loss: 5.3307\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 4ms/step - loss: 5.3318\n16/16 [==============================] - 0s 2ms/step - loss: 5.3318\n16/16 [==============================] - 0s 3ms/step - loss: 5.3318\n\nTesting for epoch 30 index 3:\n391/391 [==============================] - 0s 952us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 4.9269\n16/16 [==============================] - 0s 1ms/step - loss: 4.9272\n16/16 [==============================] - 0s 2ms/step - loss: 5.3092\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 4ms/step - loss: 5.3103\n16/16 [==============================] - 0s 1ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n16/16 [==============================] - 0s 2ms/step - loss: 5.3103\n\nTesting for epoch 30 index 4:\n391/391 [==============================] - 0s 916us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.0097\n16/16 [==============================] - 0s 1ms/step - loss: 5.0100\n16/16 [==============================] - 0s 3ms/step - loss: 5.3843\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n16/16 [==============================] - 0s 3ms/step - loss: 5.3854\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n16/16 [==============================] - 0s 1ms/step - loss: 5.3854\n16/16 [==============================] - 0s 1ms/step - loss: 5.3854\n16/16 [==============================] - 0s 2ms/step - loss: 5.3854\n\nTesting for epoch 30 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 4.9155\n16/16 [==============================] - 0s 1ms/step - loss: 4.9158\n16/16 [==============================] - 0s 1ms/step - loss: 5.3003\n16/16 [==============================] - 0s 3ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 3ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n16/16 [==============================] - 0s 2ms/step - loss: 5.3015\n\nTesting for epoch 30 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0034\n16/16 [==============================] - 0s 3ms/step - loss: 4.9720\n16/16 [==============================] - 0s 2ms/step - loss: 4.9723\n16/16 [==============================] - 0s 1ms/step - loss: 5.3508\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 3ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 3ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n16/16 [==============================] - 0s 2ms/step - loss: 5.3519\n\nTesting for epoch 30 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 5ms/step - loss: 4.9881\n16/16 [==============================] - 0s 1ms/step - loss: 4.9884\n16/16 [==============================] - 0s 895us/step - loss: 5.3639\n16/16 [==============================] - 0s 931us/step - loss: 5.3650\n16/16 [==============================] - 0s 929us/step - loss: 5.3650\n16/16 [==============================] - 0s 928us/step - loss: 5.3650\n16/16 [==============================] - 0s 975us/step - loss: 5.3650\n16/16 [==============================] - 0s 988us/step - loss: 5.3650\n16/16 [==============================] - 0s 924us/step - loss: 5.3650\n\nTesting for epoch 30 index 8:\n391/391 [==============================] - 0s 649us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0030\n16/16 [==============================] - 0s 900us/step - loss: 4.9993\n16/16 [==============================] - 0s 3ms/step - loss: 4.9996\n16/16 [==============================] - 0s 1ms/step - loss: 5.3733\n16/16 [==============================] - 0s 962us/step - loss: 5.3744\n16/16 [==============================] - 0s 942us/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n16/16 [==============================] - 0s 993us/step - loss: 5.3744\n16/16 [==============================] - 0s 1ms/step - loss: 5.3744\n\nTesting for epoch 30 index 9:\n391/391 [==============================] - 0s 634us/step\n16/16 [==============================] - 0s 868us/step - loss: 0.0034\n16/16 [==============================] - 0s 809us/step - loss: 5.0234\n16/16 [==============================] - 0s 843us/step - loss: 5.0237\n16/16 [==============================] - 0s 669us/step - loss: 5.3964\n16/16 [==============================] - 0s 816us/step - loss: 5.3975\n16/16 [==============================] - 0s 780us/step - loss: 5.3975\n16/16 [==============================] - 0s 994us/step - loss: 5.3975\n16/16 [==============================] - 0s 959us/step - loss: 5.3975\n16/16 [==============================] - 0s 1ms/step - loss: 5.3975\n16/16 [==============================] - 0s 1ms/step - loss: 5.3975\n\nTesting for epoch 30 index 10:\n391/391 [==============================] - 0s 612us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0030\n16/16 [==============================] - 0s 710us/step - loss: 4.9789\n16/16 [==============================] - 0s 2ms/step - loss: 4.9791\n16/16 [==============================] - 0s 823us/step - loss: 5.3572\n16/16 [==============================] - 0s 2ms/step - loss: 5.3583\n16/16 [==============================] - 0s 816us/step - loss: 5.3583\n16/16 [==============================] - 0s 819us/step - loss: 5.3583\n16/16 [==============================] - 0s 854us/step - loss: 5.3583\n16/16 [==============================] - 0s 881us/step - loss: 5.3583\n16/16 [==============================] - 0s 793us/step - loss: 5.3583\n\nTesting for epoch 30 index 11:\n391/391 [==============================] - 0s 733us/step\n16/16 [==============================] - 0s 934us/step - loss: 0.0032\n16/16 [==============================] - 0s 887us/step - loss: 4.8994\n16/16 [==============================] - 0s 937us/step - loss: 4.8997\n16/16 [==============================] - 0s 920us/step - loss: 5.2879\n16/16 [==============================] - 0s 893us/step - loss: 5.2890\n16/16 [==============================] - 0s 936us/step - loss: 5.2890\n16/16 [==============================] - 0s 909us/step - loss: 5.2890\n16/16 [==============================] - 0s 970us/step - loss: 5.2890\n16/16 [==============================] - 0s 917us/step - loss: 5.2890\n16/16 [==============================] - 0s 974us/step - loss: 5.2890\n\nTesting for epoch 30 index 12:\n391/391 [==============================] - 0s 607us/step\n16/16 [==============================] - 0s 876us/step - loss: 0.0038\n16/16 [==============================] - 0s 852us/step - loss: 4.9208\n16/16 [==============================] - 0s 1ms/step - loss: 4.9210\n16/16 [==============================] - 0s 996us/step - loss: 5.3081\n16/16 [==============================] - 0s 977us/step - loss: 5.3092\n16/16 [==============================] - 0s 982us/step - loss: 5.3092\n16/16 [==============================] - 0s 999us/step - loss: 5.3092\n16/16 [==============================] - 0s 893us/step - loss: 5.3092\n16/16 [==============================] - 0s 1ms/step - loss: 5.3092\n16/16 [==============================] - 0s 1ms/step - loss: 5.3092\n\nTesting for epoch 30 index 13:\n391/391 [==============================] - 0s 766us/step\n16/16 [==============================] - 0s 898us/step - loss: 0.0038\n16/16 [==============================] - 0s 862us/step - loss: 4.9108\n16/16 [==============================] - 0s 888us/step - loss: 4.9111\n16/16 [==============================] - 0s 878us/step - loss: 5.2985\n16/16 [==============================] - 0s 874us/step - loss: 5.2997\n16/16 [==============================] - 0s 858us/step - loss: 5.2997\n16/16 [==============================] - 0s 1ms/step - loss: 5.2997\n16/16 [==============================] - 0s 1ms/step - loss: 5.2997\n16/16 [==============================] - 0s 965us/step - loss: 5.2997\n16/16 [==============================] - 0s 910us/step - loss: 5.2997\n\nTesting for epoch 30 index 14:\n391/391 [==============================] - 0s 678us/step\n16/16 [==============================] - 0s 979us/step - loss: 0.0037\n16/16 [==============================] - 0s 955us/step - loss: 4.8813\n16/16 [==============================] - 0s 872us/step - loss: 4.8816\n16/16 [==============================] - 0s 923us/step - loss: 5.2721\n16/16 [==============================] - 0s 918us/step - loss: 5.2732\n16/16 [==============================] - 0s 925us/step - loss: 5.2732\n16/16 [==============================] - 0s 896us/step - loss: 5.2732\n16/16 [==============================] - 0s 901us/step - loss: 5.2732\n16/16 [==============================] - 0s 963us/step - loss: 5.2732\n16/16 [==============================] - 0s 885us/step - loss: 5.2732\n\nTesting for epoch 30 index 15:\n391/391 [==============================] - 0s 608us/step\n16/16 [==============================] - 0s 869us/step - loss: 0.0046\n16/16 [==============================] - 0s 842us/step - loss: 4.9268\n16/16 [==============================] - 0s 858us/step - loss: 4.9271\n16/16 [==============================] - 0s 861us/step - loss: 5.3143\n16/16 [==============================] - 0s 861us/step - loss: 5.3154\n16/16 [==============================] - 0s 845us/step - loss: 5.3154\n16/16 [==============================] - 0s 885us/step - loss: 5.3154\n16/16 [==============================] - 0s 902us/step - loss: 5.3154\n16/16 [==============================] - 0s 888us/step - loss: 5.3154\n16/16 [==============================] - 0s 901us/step - loss: 5.3154\n\nTesting for epoch 30 index 16:\n391/391 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 853us/step - loss: 0.0037\n16/16 [==============================] - 0s 846us/step - loss: 4.8905\n16/16 [==============================] - 0s 831us/step - loss: 4.8908\n16/16 [==============================] - 0s 827us/step - loss: 5.2830\n16/16 [==============================] - 0s 847us/step - loss: 5.2841\n16/16 [==============================] - 0s 825us/step - loss: 5.2841\n16/16 [==============================] - 0s 832us/step - loss: 5.2841\n16/16 [==============================] - 0s 830us/step - loss: 5.2841\n16/16 [==============================] - 0s 850us/step - loss: 5.2841\n16/16 [==============================] - 0s 851us/step - loss: 5.2841\n\nTesting for epoch 30 index 17:\n391/391 [==============================] - 0s 615us/step\n16/16 [==============================] - 0s 865us/step - loss: 0.0042\n16/16 [==============================] - 0s 871us/step - loss: 4.9525\n16/16 [==============================] - 0s 841us/step - loss: 4.9528\n16/16 [==============================] - 0s 853us/step - loss: 5.3379\n16/16 [==============================] - 0s 864us/step - loss: 5.3391\n16/16 [==============================] - 0s 857us/step - loss: 5.3391\n16/16 [==============================] - 0s 842us/step - loss: 5.3391\n16/16 [==============================] - 0s 879us/step - loss: 5.3391\n16/16 [==============================] - 0s 839us/step - loss: 5.3391\n16/16 [==============================] - 0s 821us/step - loss: 5.3391\n\nTesting for epoch 30 index 18:\n391/391 [==============================] - 0s 609us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0038\n16/16 [==============================] - 0s 849us/step - loss: 4.9449\n16/16 [==============================] - 0s 1ms/step - loss: 4.9452\n16/16 [==============================] - 0s 844us/step - loss: 5.3284\n16/16 [==============================] - 0s 937us/step - loss: 5.3296\n16/16 [==============================] - 0s 866us/step - loss: 5.3296\n16/16 [==============================] - 0s 859us/step - loss: 5.3296\n16/16 [==============================] - 0s 840us/step - loss: 5.3296\n16/16 [==============================] - 0s 850us/step - loss: 5.3296\n16/16 [==============================] - 0s 851us/step - loss: 5.3296\n\nTesting for epoch 30 index 19:\n391/391 [==============================] - 0s 819us/step\n16/16 [==============================] - 0s 801us/step - loss: 0.0042\n16/16 [==============================] - 0s 799us/step - loss: 4.9416\n16/16 [==============================] - 0s 793us/step - loss: 4.9419\n16/16 [==============================] - 0s 818us/step - loss: 5.3295\n16/16 [==============================] - 0s 1ms/step - loss: 5.3306\n16/16 [==============================] - 0s 768us/step - loss: 5.3306\n16/16 [==============================] - 0s 760us/step - loss: 5.3306\n16/16 [==============================] - 0s 761us/step - loss: 5.3306\n16/16 [==============================] - 0s 815us/step - loss: 5.3306\n16/16 [==============================] - 0s 973us/step - loss: 5.3306\n\nTesting for epoch 30 index 20:\n391/391 [==============================] - 0s 911us/step\n16/16 [==============================] - 0s 804us/step - loss: 0.0039\n16/16 [==============================] - 0s 810us/step - loss: 4.8870\n16/16 [==============================] - 0s 810us/step - loss: 4.8872\n16/16 [==============================] - 0s 2ms/step - loss: 5.2787\n16/16 [==============================] - 0s 925us/step - loss: 5.2798\n16/16 [==============================] - 0s 4ms/step - loss: 5.2798\n16/16 [==============================] - 0s 681us/step - loss: 5.2798\n16/16 [==============================] - 0s 835us/step - loss: 5.2798\n16/16 [==============================] - 0s 2ms/step - loss: 5.2798\n16/16 [==============================] - 0s 779us/step - loss: 5.2798\n\nTesting for epoch 30 index 21:\n391/391 [==============================] - 0s 637us/step\n16/16 [==============================] - 0s 916us/step - loss: 0.0037\n16/16 [==============================] - 0s 917us/step - loss: 4.9127\n16/16 [==============================] - 0s 928us/step - loss: 4.9130\n16/16 [==============================] - 0s 925us/step - loss: 5.3022\n16/16 [==============================] - 0s 918us/step - loss: 5.3033\n16/16 [==============================] - 0s 920us/step - loss: 5.3033\n16/16 [==============================] - 0s 926us/step - loss: 5.3033\n16/16 [==============================] - 0s 917us/step - loss: 5.3033\n16/16 [==============================] - 0s 906us/step - loss: 5.3033\n16/16 [==============================] - 0s 906us/step - loss: 5.3033\n\nTesting for epoch 30 index 22:\n391/391 [==============================] - 0s 732us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 1ms/step - loss: 4.9835\n16/16 [==============================] - 0s 1ms/step - loss: 4.9838\n16/16 [==============================] - 0s 879us/step - loss: 5.3653\n16/16 [==============================] - 0s 891us/step - loss: 5.3664\n16/16 [==============================] - 0s 892us/step - loss: 5.3664\n16/16 [==============================] - 0s 900us/step - loss: 5.3664\n16/16 [==============================] - 0s 1ms/step - loss: 5.3664\n16/16 [==============================] - 0s 1ms/step - loss: 5.3664\n16/16 [==============================] - 0s 862us/step - loss: 5.3664\n\nTesting for epoch 30 index 23:\n391/391 [==============================] - 0s 648us/step\n16/16 [==============================] - 0s 889us/step - loss: 0.0037\n16/16 [==============================] - 0s 960us/step - loss: 4.9286\n16/16 [==============================] - 0s 895us/step - loss: 4.9289\n16/16 [==============================] - 0s 1ms/step - loss: 5.3178\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 1ms/step - loss: 5.3189\n16/16 [==============================] - 0s 902us/step - loss: 5.3189\n16/16 [==============================] - 0s 890us/step - loss: 5.3189\n16/16 [==============================] - 0s 871us/step - loss: 5.3189\n\nTesting for epoch 30 index 24:\n391/391 [==============================] - 0s 605us/step\n16/16 [==============================] - 0s 835us/step - loss: 0.0038\n16/16 [==============================] - 0s 882us/step - loss: 4.9576\n16/16 [==============================] - 0s 867us/step - loss: 4.9578\n16/16 [==============================] - 0s 1ms/step - loss: 5.3417\n16/16 [==============================] - 0s 906us/step - loss: 5.3428\n16/16 [==============================] - 0s 1ms/step - loss: 5.3428\n16/16 [==============================] - 0s 846us/step - loss: 5.3428\n16/16 [==============================] - 0s 884us/step - loss: 5.3428\n16/16 [==============================] - 0s 834us/step - loss: 5.3428\n16/16 [==============================] - 0s 904us/step - loss: 5.3428\nEpoch 31 of 60\n\nTesting for epoch 31 index 1:\n391/391 [==============================] - 0s 603us/step\n16/16 [==============================] - 0s 854us/step - loss: 0.0035\n16/16 [==============================] - 0s 866us/step - loss: 4.9590\n16/16 [==============================] - 0s 876us/step - loss: 4.9593\n16/16 [==============================] - 0s 885us/step - loss: 5.3430\n16/16 [==============================] - 0s 887us/step - loss: 5.3441\n16/16 [==============================] - 0s 937us/step - loss: 5.3441\n16/16 [==============================] - 0s 894us/step - loss: 5.3441\n16/16 [==============================] - 0s 895us/step - loss: 5.3441\n16/16 [==============================] - 0s 923us/step - loss: 5.3441\n16/16 [==============================] - 0s 1ms/step - loss: 5.3441\n\nTesting for epoch 31 index 2:\n391/391 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 838us/step - loss: 0.0035\n16/16 [==============================] - 0s 848us/step - loss: 4.9721\n16/16 [==============================] - 0s 836us/step - loss: 4.9724\n16/16 [==============================] - 0s 850us/step - loss: 5.3553\n16/16 [==============================] - 0s 842us/step - loss: 5.3564\n16/16 [==============================] - 0s 867us/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n16/16 [==============================] - 0s 1ms/step - loss: 5.3564\n\nTesting for epoch 31 index 3:\n391/391 [==============================] - 0s 840us/step\n16/16 [==============================] - 0s 789us/step - loss: 0.0038\n16/16 [==============================] - 0s 819us/step - loss: 5.0099\n16/16 [==============================] - 0s 796us/step - loss: 5.0102\n16/16 [==============================] - 0s 2ms/step - loss: 5.3919\n16/16 [==============================] - 0s 1ms/step - loss: 5.3930\n16/16 [==============================] - 0s 708us/step - loss: 5.3930\n16/16 [==============================] - 0s 764us/step - loss: 5.3930\n16/16 [==============================] - 0s 770us/step - loss: 5.3930\n16/16 [==============================] - 0s 771us/step - loss: 5.3930\n16/16 [==============================] - 0s 2ms/step - loss: 5.3930\n\nTesting for epoch 31 index 4:\n391/391 [==============================] - 0s 737us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0035\n16/16 [==============================] - 0s 822us/step - loss: 4.9931\n16/16 [==============================] - 0s 2ms/step - loss: 4.9933\n16/16 [==============================] - 0s 2ms/step - loss: 5.3732\n16/16 [==============================] - 0s 2ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 860us/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n16/16 [==============================] - 0s 1ms/step - loss: 5.3743\n\nTesting for epoch 31 index 5:\n391/391 [==============================] - 0s 731us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 872us/step - loss: 5.0456\n16/16 [==============================] - 0s 874us/step - loss: 5.0459\n16/16 [==============================] - 0s 862us/step - loss: 5.4229\n16/16 [==============================] - 0s 880us/step - loss: 5.4240\n16/16 [==============================] - 0s 893us/step - loss: 5.4240\n16/16 [==============================] - 0s 872us/step - loss: 5.4240\n16/16 [==============================] - 0s 1ms/step - loss: 5.4240\n16/16 [==============================] - 0s 844us/step - loss: 5.4240\n16/16 [==============================] - 0s 856us/step - loss: 5.4240\n\nTesting for epoch 31 index 6:\n391/391 [==============================] - 0s 657us/step\n16/16 [==============================] - 0s 900us/step - loss: 0.0033\n16/16 [==============================] - 0s 918us/step - loss: 5.0333\n16/16 [==============================] - 0s 868us/step - loss: 5.0336\n16/16 [==============================] - 0s 872us/step - loss: 5.4113\n16/16 [==============================] - 0s 885us/step - loss: 5.4124\n16/16 [==============================] - 0s 873us/step - loss: 5.4124\n16/16 [==============================] - 0s 893us/step - loss: 5.4124\n16/16 [==============================] - 0s 892us/step - loss: 5.4124\n16/16 [==============================] - 0s 875us/step - loss: 5.4124\n16/16 [==============================] - 0s 859us/step - loss: 5.4124\n\nTesting for epoch 31 index 7:\n391/391 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 877us/step - loss: 0.0036\n16/16 [==============================] - 0s 883us/step - loss: 5.0652\n16/16 [==============================] - 0s 900us/step - loss: 5.0655\n16/16 [==============================] - 0s 910us/step - loss: 5.4405\n16/16 [==============================] - 0s 849us/step - loss: 5.4416\n16/16 [==============================] - 0s 867us/step - loss: 5.4416\n16/16 [==============================] - 0s 840us/step - loss: 5.4416\n16/16 [==============================] - 0s 872us/step - loss: 5.4416\n16/16 [==============================] - 0s 876us/step - loss: 5.4416\n16/16 [==============================] - 0s 891us/step - loss: 5.4416\n\nTesting for epoch 31 index 8:\n391/391 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0031\n16/16 [==============================] - 0s 892us/step - loss: 5.0470\n16/16 [==============================] - 0s 894us/step - loss: 5.0473\n16/16 [==============================] - 0s 873us/step - loss: 5.4234\n16/16 [==============================] - 0s 883us/step - loss: 5.4245\n16/16 [==============================] - 0s 885us/step - loss: 5.4245\n16/16 [==============================] - 0s 874us/step - loss: 5.4245\n16/16 [==============================] - 0s 871us/step - loss: 5.4245\n16/16 [==============================] - 0s 876us/step - loss: 5.4245\n16/16 [==============================] - 0s 851us/step - loss: 5.4245\n\nTesting for epoch 31 index 9:\n391/391 [==============================] - 0s 640us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0037\n16/16 [==============================] - 0s 879us/step - loss: 5.1318\n16/16 [==============================] - 0s 910us/step - loss: 5.1321\n16/16 [==============================] - 0s 1ms/step - loss: 5.5008\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n16/16 [==============================] - 0s 1ms/step - loss: 5.5018\n\nTesting for epoch 31 index 10:\n391/391 [==============================] - 0s 624us/step\n16/16 [==============================] - 0s 908us/step - loss: 0.0035\n16/16 [==============================] - 0s 889us/step - loss: 5.0184\n16/16 [==============================] - 0s 907us/step - loss: 5.0186\n16/16 [==============================] - 0s 906us/step - loss: 5.3973\n16/16 [==============================] - 0s 913us/step - loss: 5.3984\n16/16 [==============================] - 0s 958us/step - loss: 5.3984\n16/16 [==============================] - 0s 895us/step - loss: 5.3984\n16/16 [==============================] - 0s 856us/step - loss: 5.3984\n16/16 [==============================] - 0s 897us/step - loss: 5.3984\n16/16 [==============================] - 0s 880us/step - loss: 5.3984\n\nTesting for epoch 31 index 11:\n391/391 [==============================] - 0s 981us/step\n16/16 [==============================] - 0s 823us/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.0033\n16/16 [==============================] - 0s 1ms/step - loss: 5.3850\n16/16 [==============================] - 0s 849us/step - loss: 5.3861\n16/16 [==============================] - 0s 842us/step - loss: 5.3861\n16/16 [==============================] - 0s 784us/step - loss: 5.3861\n16/16 [==============================] - 0s 660us/step - loss: 5.3861\n16/16 [==============================] - 0s 2ms/step - loss: 5.3861\n16/16 [==============================] - 0s 656us/step - loss: 5.3861\n\nTesting for epoch 31 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 932us/step - loss: 5.0029\n16/16 [==============================] - 0s 1ms/step - loss: 5.0032\n16/16 [==============================] - 0s 1ms/step - loss: 5.3889\n16/16 [==============================] - 0s 803us/step - loss: 5.3900\n16/16 [==============================] - 0s 2ms/step - loss: 5.3900\n16/16 [==============================] - 0s 897us/step - loss: 5.3900\n16/16 [==============================] - 0s 895us/step - loss: 5.3900\n16/16 [==============================] - 0s 884us/step - loss: 5.3900\n16/16 [==============================] - 0s 887us/step - loss: 5.3900\n\nTesting for epoch 31 index 13:\n391/391 [==============================] - 0s 691us/step\n16/16 [==============================] - 0s 933us/step - loss: 0.0038\n16/16 [==============================] - 0s 901us/step - loss: 4.9968\n16/16 [==============================] - 0s 891us/step - loss: 4.9970\n16/16 [==============================] - 0s 892us/step - loss: 5.3825\n16/16 [==============================] - 0s 905us/step - loss: 5.3836\n16/16 [==============================] - 0s 866us/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n16/16 [==============================] - 0s 1ms/step - loss: 5.3836\n\nTesting for epoch 31 index 14:\n391/391 [==============================] - 0s 725us/step\n16/16 [==============================] - 0s 875us/step - loss: 0.0045\n16/16 [==============================] - 0s 858us/step - loss: 4.9823\n16/16 [==============================] - 0s 854us/step - loss: 4.9826\n16/16 [==============================] - 0s 897us/step - loss: 5.3690\n16/16 [==============================] - 0s 884us/step - loss: 5.3701\n16/16 [==============================] - 0s 886us/step - loss: 5.3701\n16/16 [==============================] - 0s 907us/step - loss: 5.3701\n16/16 [==============================] - 0s 899us/step - loss: 5.3701\n16/16 [==============================] - 0s 864us/step - loss: 5.3701\n16/16 [==============================] - 0s 875us/step - loss: 5.3701\n\nTesting for epoch 31 index 15:\n391/391 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 861us/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 4.9342\n16/16 [==============================] - 0s 917us/step - loss: 4.9344\n16/16 [==============================] - 0s 860us/step - loss: 5.3283\n16/16 [==============================] - 0s 855us/step - loss: 5.3294\n16/16 [==============================] - 0s 857us/step - loss: 5.3294\n16/16 [==============================] - 0s 854us/step - loss: 5.3294\n16/16 [==============================] - 0s 849us/step - loss: 5.3294\n16/16 [==============================] - 0s 842us/step - loss: 5.3294\n16/16 [==============================] - 0s 1ms/step - loss: 5.3294\n\nTesting for epoch 31 index 16:\n391/391 [==============================] - 0s 623us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 878us/step - loss: 4.9532\n16/16 [==============================] - 0s 858us/step - loss: 4.9535\n16/16 [==============================] - 0s 858us/step - loss: 5.3453\n16/16 [==============================] - 0s 864us/step - loss: 5.3464\n16/16 [==============================] - 0s 832us/step - loss: 5.3464\n16/16 [==============================] - 0s 886us/step - loss: 5.3464\n16/16 [==============================] - 0s 876us/step - loss: 5.3464\n16/16 [==============================] - 0s 856us/step - loss: 5.3464\n16/16 [==============================] - 0s 856us/step - loss: 5.3464\n\nTesting for epoch 31 index 17:\n391/391 [==============================] - 0s 651us/step\n16/16 [==============================] - 0s 895us/step - loss: 0.0042\n16/16 [==============================] - 0s 901us/step - loss: 4.9573\n16/16 [==============================] - 0s 910us/step - loss: 4.9576\n16/16 [==============================] - 0s 910us/step - loss: 5.3480\n16/16 [==============================] - 0s 902us/step - loss: 5.3491\n16/16 [==============================] - 0s 883us/step - loss: 5.3491\n16/16 [==============================] - 0s 885us/step - loss: 5.3491\n16/16 [==============================] - 0s 840us/step - loss: 5.3491\n16/16 [==============================] - 0s 853us/step - loss: 5.3491\n16/16 [==============================] - 0s 860us/step - loss: 5.3491\n\nTesting for epoch 31 index 18:\n391/391 [==============================] - 0s 627us/step\n16/16 [==============================] - 0s 928us/step - loss: 0.0043\n16/16 [==============================] - 0s 888us/step - loss: 5.0424\n16/16 [==============================] - 0s 864us/step - loss: 5.0427\n16/16 [==============================] - 0s 876us/step - loss: 5.4280\n16/16 [==============================] - 0s 884us/step - loss: 5.4291\n16/16 [==============================] - 0s 928us/step - loss: 5.4291\n16/16 [==============================] - 0s 882us/step - loss: 5.4291\n16/16 [==============================] - 0s 880us/step - loss: 5.4291\n16/16 [==============================] - 0s 928us/step - loss: 5.4291\n16/16 [==============================] - 0s 885us/step - loss: 5.4291\n\nTesting for epoch 31 index 19:\n391/391 [==============================] - 0s 693us/step\n16/16 [==============================] - 0s 818us/step - loss: 0.0043\n16/16 [==============================] - 0s 783us/step - loss: 4.9765\n16/16 [==============================] - 0s 781us/step - loss: 4.9768\n16/16 [==============================] - 0s 1ms/step - loss: 5.3659\n16/16 [==============================] - 0s 2ms/step - loss: 5.3670\n16/16 [==============================] - 0s 749us/step - loss: 5.3670\n16/16 [==============================] - 0s 837us/step - loss: 5.3670\n16/16 [==============================] - 0s 1ms/step - loss: 5.3670\n16/16 [==============================] - 0s 665us/step - loss: 5.3670\n16/16 [==============================] - 0s 2ms/step - loss: 5.3670\n\nTesting for epoch 31 index 20:\n391/391 [==============================] - 0s 870us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 821us/step - loss: 4.9601\n16/16 [==============================] - 0s 819us/step - loss: 4.9603\n16/16 [==============================] - 0s 821us/step - loss: 5.3521\n16/16 [==============================] - 0s 781us/step - loss: 5.3532\n16/16 [==============================] - 0s 1ms/step - loss: 5.3532\n16/16 [==============================] - 0s 953us/step - loss: 5.3532\n16/16 [==============================] - 0s 1ms/step - loss: 5.3532\n16/16 [==============================] - 0s 2ms/step - loss: 5.3532\n16/16 [==============================] - 0s 767us/step - loss: 5.3532\n\nTesting for epoch 31 index 21:\n391/391 [==============================] - 0s 621us/step\n16/16 [==============================] - 0s 908us/step - loss: 0.0042\n16/16 [==============================] - 0s 874us/step - loss: 4.9714\n16/16 [==============================] - 0s 1ms/step - loss: 4.9717\n16/16 [==============================] - 0s 1ms/step - loss: 5.3639\n16/16 [==============================] - 0s 1ms/step - loss: 5.3651\n16/16 [==============================] - 0s 895us/step - loss: 5.3651\n16/16 [==============================] - 0s 888us/step - loss: 5.3651\n16/16 [==============================] - 0s 886us/step - loss: 5.3651\n16/16 [==============================] - 0s 1ms/step - loss: 5.3651\n16/16 [==============================] - 0s 883us/step - loss: 5.3651\n\nTesting for epoch 31 index 22:\n391/391 [==============================] - 0s 783us/step\n16/16 [==============================] - 0s 873us/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 5.0220\n16/16 [==============================] - 0s 894us/step - loss: 5.0223\n16/16 [==============================] - 0s 1ms/step - loss: 5.4104\n16/16 [==============================] - 0s 1ms/step - loss: 5.4115\n16/16 [==============================] - 0s 1ms/step - loss: 5.4115\n16/16 [==============================] - 0s 862us/step - loss: 5.4115\n16/16 [==============================] - 0s 873us/step - loss: 5.4115\n16/16 [==============================] - 0s 877us/step - loss: 5.4115\n16/16 [==============================] - 0s 865us/step - loss: 5.4115\n\nTesting for epoch 31 index 23:\n391/391 [==============================] - 0s 670us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0040\n16/16 [==============================] - 0s 914us/step - loss: 5.0154\n16/16 [==============================] - 0s 904us/step - loss: 5.0157\n16/16 [==============================] - 0s 929us/step - loss: 5.4035\n16/16 [==============================] - 0s 920us/step - loss: 5.4046\n16/16 [==============================] - 0s 899us/step - loss: 5.4046\n16/16 [==============================] - 0s 881us/step - loss: 5.4046\n16/16 [==============================] - 0s 884us/step - loss: 5.4046\n16/16 [==============================] - 0s 930us/step - loss: 5.4046\n16/16 [==============================] - 0s 937us/step - loss: 5.4046\n\nTesting for epoch 31 index 24:\n391/391 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 891us/step - loss: 0.0037\n16/16 [==============================] - 0s 870us/step - loss: 5.0249\n16/16 [==============================] - 0s 891us/step - loss: 5.0252\n16/16 [==============================] - 0s 888us/step - loss: 5.4131\n16/16 [==============================] - 0s 880us/step - loss: 5.4142\n16/16 [==============================] - 0s 857us/step - loss: 5.4142\n16/16 [==============================] - 0s 844us/step - loss: 5.4142\n16/16 [==============================] - 0s 881us/step - loss: 5.4142\n16/16 [==============================] - 0s 853us/step - loss: 5.4142\n16/16 [==============================] - 0s 864us/step - loss: 5.4142\nEpoch 32 of 60\n\nTesting for epoch 32 index 1:\n391/391 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 832us/step - loss: 0.0037\n16/16 [==============================] - 0s 900us/step - loss: 5.0944\n16/16 [==============================] - 0s 884us/step - loss: 5.0947\n16/16 [==============================] - 0s 925us/step - loss: 5.4751\n16/16 [==============================] - 0s 917us/step - loss: 5.4762\n16/16 [==============================] - 0s 907us/step - loss: 5.4762\n16/16 [==============================] - 0s 922us/step - loss: 5.4762\n16/16 [==============================] - 0s 929us/step - loss: 5.4762\n16/16 [==============================] - 0s 910us/step - loss: 5.4762\n16/16 [==============================] - 0s 911us/step - loss: 5.4762\n\nTesting for epoch 32 index 2:\n391/391 [==============================] - 0s 604us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.0033\n16/16 [==============================] - 0s 858us/step - loss: 5.0400\n16/16 [==============================] - 0s 866us/step - loss: 5.0403\n16/16 [==============================] - 0s 862us/step - loss: 5.4251\n16/16 [==============================] - 0s 860us/step - loss: 5.4262\n16/16 [==============================] - 0s 874us/step - loss: 5.4262\n16/16 [==============================] - 0s 844us/step - loss: 5.4262\n16/16 [==============================] - 0s 931us/step - loss: 5.4262\n16/16 [==============================] - 0s 883us/step - loss: 5.4262\n16/16 [==============================] - 0s 842us/step - loss: 5.4262\n\nTesting for epoch 32 index 3:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 859us/step - loss: 0.0034\n16/16 [==============================] - 0s 1ms/step - loss: 5.0175\n16/16 [==============================] - 0s 857us/step - loss: 5.0178\n16/16 [==============================] - 0s 1ms/step - loss: 5.4025\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 949us/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n16/16 [==============================] - 0s 1ms/step - loss: 5.4036\n\nTesting for epoch 32 index 4:\n391/391 [==============================] - 0s 639us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 682us/step - loss: 5.0523\n16/16 [==============================] - 0s 793us/step - loss: 5.0525\n16/16 [==============================] - 0s 798us/step - loss: 5.4323\n16/16 [==============================] - 0s 1ms/step - loss: 5.4334\n16/16 [==============================] - 0s 762us/step - loss: 5.4334\n16/16 [==============================] - 0s 931us/step - loss: 5.4334\n16/16 [==============================] - 0s 936us/step - loss: 5.4334\n16/16 [==============================] - 0s 910us/step - loss: 5.4334\n16/16 [==============================] - 0s 798us/step - loss: 5.4334\n\nTesting for epoch 32 index 5:\n391/391 [==============================] - 0s 735us/step\n16/16 [==============================] - 0s 770us/step - loss: 0.0036\n16/16 [==============================] - 0s 1ms/step - loss: 5.1095\n16/16 [==============================] - 0s 2ms/step - loss: 5.1098\n16/16 [==============================] - 0s 2ms/step - loss: 5.4870\n16/16 [==============================] - 0s 874us/step - loss: 5.4881\n16/16 [==============================] - 0s 2ms/step - loss: 5.4881\n16/16 [==============================] - 0s 789us/step - loss: 5.4881\n16/16 [==============================] - 0s 1ms/step - loss: 5.4881\n16/16 [==============================] - 0s 809us/step - loss: 5.4881\n16/16 [==============================] - 0s 2ms/step - loss: 5.4881\n\nTesting for epoch 32 index 6:\n391/391 [==============================] - 0s 735us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0034\n16/16 [==============================] - 0s 755us/step - loss: 5.0918\n16/16 [==============================] - 0s 817us/step - loss: 5.0921\n16/16 [==============================] - 0s 815us/step - loss: 5.4724\n16/16 [==============================] - 0s 716us/step - loss: 5.4735\n16/16 [==============================] - 0s 739us/step - loss: 5.4735\n16/16 [==============================] - 0s 722us/step - loss: 5.4735\n16/16 [==============================] - 0s 873us/step - loss: 5.4735\n16/16 [==============================] - 0s 885us/step - loss: 5.4735\n16/16 [==============================] - 0s 929us/step - loss: 5.4735\n\nTesting for epoch 32 index 7:\n391/391 [==============================] - 0s 652us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0031\n16/16 [==============================] - 0s 903us/step - loss: 5.0698\n16/16 [==============================] - 0s 929us/step - loss: 5.0701\n16/16 [==============================] - 0s 922us/step - loss: 5.4505\n16/16 [==============================] - 0s 889us/step - loss: 5.4516\n16/16 [==============================] - 0s 888us/step - loss: 5.4516\n16/16 [==============================] - 0s 884us/step - loss: 5.4516\n16/16 [==============================] - 0s 866us/step - loss: 5.4516\n16/16 [==============================] - 0s 941us/step - loss: 5.4516\n16/16 [==============================] - 0s 926us/step - loss: 5.4516\n\nTesting for epoch 32 index 8:\n391/391 [==============================] - 0s 633us/step\n16/16 [==============================] - 0s 945us/step - loss: 0.0030\n16/16 [==============================] - 0s 926us/step - loss: 5.0715\n16/16 [==============================] - 0s 940us/step - loss: 5.0718\n16/16 [==============================] - 0s 933us/step - loss: 5.4501\n16/16 [==============================] - 0s 938us/step - loss: 5.4512\n16/16 [==============================] - 0s 908us/step - loss: 5.4512\n16/16 [==============================] - 0s 902us/step - loss: 5.4512\n16/16 [==============================] - 0s 876us/step - loss: 5.4512\n16/16 [==============================] - 0s 959us/step - loss: 5.4512\n16/16 [==============================] - 0s 935us/step - loss: 5.4512\n\nTesting for epoch 32 index 9:\n391/391 [==============================] - 0s 635us/step\n16/16 [==============================] - 0s 919us/step - loss: 0.0030\n16/16 [==============================] - 0s 852us/step - loss: 5.1353\n16/16 [==============================] - 0s 870us/step - loss: 5.1356\n16/16 [==============================] - 0s 880us/step - loss: 5.5097\n16/16 [==============================] - 0s 894us/step - loss: 5.5107\n16/16 [==============================] - 0s 904us/step - loss: 5.5107\n16/16 [==============================] - 0s 878us/step - loss: 5.5107\n16/16 [==============================] - 0s 939us/step - loss: 5.5107\n16/16 [==============================] - 0s 889us/step - loss: 5.5107\n16/16 [==============================] - 0s 907us/step - loss: 5.5107\n\nTesting for epoch 32 index 10:\n391/391 [==============================] - 0s 641us/step\n16/16 [==============================] - 0s 919us/step - loss: 0.0031\n16/16 [==============================] - 0s 918us/step - loss: 5.0857\n16/16 [==============================] - 0s 894us/step - loss: 5.0860\n16/16 [==============================] - 0s 895us/step - loss: 5.4657\n16/16 [==============================] - 0s 904us/step - loss: 5.4668\n16/16 [==============================] - 0s 900us/step - loss: 5.4668\n16/16 [==============================] - 0s 900us/step - loss: 5.4668\n16/16 [==============================] - 0s 905us/step - loss: 5.4668\n16/16 [==============================] - 0s 868us/step - loss: 5.4668\n16/16 [==============================] - 0s 884us/step - loss: 5.4668\n\nTesting for epoch 32 index 11:\n391/391 [==============================] - 0s 689us/step\n16/16 [==============================] - 0s 932us/step - loss: 0.0037\n16/16 [==============================] - 0s 928us/step - loss: 5.0737\n16/16 [==============================] - 0s 928us/step - loss: 5.0740\n16/16 [==============================] - 0s 949us/step - loss: 5.4543\n16/16 [==============================] - 0s 899us/step - loss: 5.4553\n16/16 [==============================] - 0s 908us/step - loss: 5.4553\n16/16 [==============================] - 0s 898us/step - loss: 5.4553\n16/16 [==============================] - 0s 893us/step - loss: 5.4553\n16/16 [==============================] - 0s 903us/step - loss: 5.4553\n16/16 [==============================] - 0s 877us/step - loss: 5.4553\n\nTesting for epoch 32 index 12:\n391/391 [==============================] - 0s 614us/step\n16/16 [==============================] - 0s 952us/step - loss: 0.0037\n16/16 [==============================] - 0s 841us/step - loss: 5.0692\n16/16 [==============================] - 0s 876us/step - loss: 5.0694\n16/16 [==============================] - 0s 866us/step - loss: 5.4520\n16/16 [==============================] - 0s 863us/step - loss: 5.4531\n16/16 [==============================] - 0s 855us/step - loss: 5.4531\n16/16 [==============================] - 0s 969us/step - loss: 5.4531\n16/16 [==============================] - 0s 917us/step - loss: 5.4531\n16/16 [==============================] - 0s 937us/step - loss: 5.4531\n16/16 [==============================] - 0s 959us/step - loss: 5.4531\n\nTesting for epoch 32 index 13:\n391/391 [==============================] - 0s 886us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 777us/step - loss: 5.0091\n16/16 [==============================] - 0s 771us/step - loss: 5.0094\n16/16 [==============================] - 0s 787us/step - loss: 5.3983\n16/16 [==============================] - 0s 2ms/step - loss: 5.3994\n16/16 [==============================] - 0s 1ms/step - loss: 5.3994\n16/16 [==============================] - 0s 687us/step - loss: 5.3994\n16/16 [==============================] - 0s 2ms/step - loss: 5.3994\n16/16 [==============================] - 0s 775us/step - loss: 5.3994\n16/16 [==============================] - 0s 759us/step - loss: 5.3994\n\nTesting for epoch 32 index 14:\n391/391 [==============================] - 0s 829us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0040\n16/16 [==============================] - 0s 761us/step - loss: 5.0421\n16/16 [==============================] - 0s 1ms/step - loss: 5.0424\n16/16 [==============================] - 0s 910us/step - loss: 5.4300\n16/16 [==============================] - 0s 905us/step - loss: 5.4311\n16/16 [==============================] - 0s 918us/step - loss: 5.4311\n16/16 [==============================] - 0s 916us/step - loss: 5.4311\n16/16 [==============================] - 0s 913us/step - loss: 5.4311\n16/16 [==============================] - 0s 904us/step - loss: 5.4311\n16/16 [==============================] - 0s 903us/step - loss: 5.4311\n\nTesting for epoch 32 index 15:\n391/391 [==============================] - 0s 596us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 872us/step - loss: 5.0083\n16/16 [==============================] - 0s 922us/step - loss: 5.0085\n16/16 [==============================] - 0s 854us/step - loss: 5.3998\n16/16 [==============================] - 0s 843us/step - loss: 5.4009\n16/16 [==============================] - 0s 925us/step - loss: 5.4009\n16/16 [==============================] - 0s 917us/step - loss: 5.4009\n16/16 [==============================] - 0s 963us/step - loss: 5.4009\n16/16 [==============================] - 0s 927us/step - loss: 5.4009\n16/16 [==============================] - 0s 922us/step - loss: 5.4009\n\nTesting for epoch 32 index 16:\n391/391 [==============================] - 0s 654us/step\n16/16 [==============================] - 0s 921us/step - loss: 0.0042\n16/16 [==============================] - 0s 906us/step - loss: 5.0189\n16/16 [==============================] - 0s 924us/step - loss: 5.0192\n16/16 [==============================] - 0s 919us/step - loss: 5.4121\n16/16 [==============================] - 0s 933us/step - loss: 5.4133\n16/16 [==============================] - 0s 932us/step - loss: 5.4133\n16/16 [==============================] - 0s 910us/step - loss: 5.4133\n16/16 [==============================] - 0s 876us/step - loss: 5.4133\n16/16 [==============================] - 0s 899us/step - loss: 5.4133\n16/16 [==============================] - 0s 901us/step - loss: 5.4133\n\nTesting for epoch 32 index 17:\n391/391 [==============================] - 0s 653us/step\n16/16 [==============================] - 0s 923us/step - loss: 0.0043\n16/16 [==============================] - 0s 904us/step - loss: 5.0400\n16/16 [==============================] - 0s 935us/step - loss: 5.0403\n16/16 [==============================] - 0s 900us/step - loss: 5.4291\n16/16 [==============================] - 0s 956us/step - loss: 5.4302\n16/16 [==============================] - 0s 921us/step - loss: 5.4302\n16/16 [==============================] - 0s 908us/step - loss: 5.4302\n16/16 [==============================] - 0s 892us/step - loss: 5.4302\n16/16 [==============================] - 0s 903us/step - loss: 5.4302\n16/16 [==============================] - 0s 877us/step - loss: 5.4302\n\nTesting for epoch 32 index 18:\n391/391 [==============================] - 0s 638us/step\n16/16 [==============================] - 0s 863us/step - loss: 0.0041\n16/16 [==============================] - 0s 858us/step - loss: 5.0363\n16/16 [==============================] - 0s 912us/step - loss: 5.0366\n16/16 [==============================] - 0s 869us/step - loss: 5.4261\n16/16 [==============================] - 0s 872us/step - loss: 5.4272\n16/16 [==============================] - 0s 876us/step - loss: 5.4272\n16/16 [==============================] - 0s 868us/step - loss: 5.4272\n16/16 [==============================] - 0s 881us/step - loss: 5.4272\n16/16 [==============================] - 0s 887us/step - loss: 5.4272\n16/16 [==============================] - 0s 885us/step - loss: 5.4272\n\nTesting for epoch 32 index 19:\n391/391 [==============================] - 0s 643us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0042\n16/16 [==============================] - 0s 890us/step - loss: 5.0048\n16/16 [==============================] - 0s 889us/step - loss: 5.0051\n16/16 [==============================] - 0s 911us/step - loss: 5.3996\n16/16 [==============================] - 0s 904us/step - loss: 5.4007\n16/16 [==============================] - 0s 904us/step - loss: 5.4007\n16/16 [==============================] - 0s 880us/step - loss: 5.4007\n16/16 [==============================] - 0s 912us/step - loss: 5.4007\n16/16 [==============================] - 0s 913us/step - loss: 5.4007\n16/16 [==============================] - 0s 892us/step - loss: 5.4007\n\nTesting for epoch 32 index 20:\n391/391 [==============================] - 0s 680us/step\n16/16 [==============================] - 0s 963us/step - loss: 0.0041\n16/16 [==============================] - 0s 913us/step - loss: 4.9931\n16/16 [==============================] - 0s 979us/step - loss: 4.9934\n16/16 [==============================] - 0s 943us/step - loss: 5.3873\n16/16 [==============================] - 0s 928us/step - loss: 5.3884\n16/16 [==============================] - 0s 938us/step - loss: 5.3884\n16/16 [==============================] - 0s 932us/step - loss: 5.3884\n16/16 [==============================] - 0s 908us/step - loss: 5.3884\n16/16 [==============================] - 0s 926us/step - loss: 5.3884\n16/16 [==============================] - 0s 931us/step - loss: 5.3884\n\nTesting for epoch 32 index 21:\n391/391 [==============================] - 0s 856us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 778us/step - loss: 5.0216\n16/16 [==============================] - 0s 798us/step - loss: 5.0219\n16/16 [==============================] - 0s 751us/step - loss: 5.4141\n16/16 [==============================] - 0s 790us/step - loss: 5.4152\n16/16 [==============================] - 0s 834us/step - loss: 5.4152\n16/16 [==============================] - 0s 764us/step - loss: 5.4152\n16/16 [==============================] - 0s 761us/step - loss: 5.4152\n16/16 [==============================] - 0s 769us/step - loss: 5.4152\n16/16 [==============================] - 0s 617us/step - loss: 5.4152\n\nTesting for epoch 32 index 22:\n391/391 [==============================] - 0s 954us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.0627\n16/16 [==============================] - 0s 2ms/step - loss: 5.0629\n16/16 [==============================] - 0s 773us/step - loss: 5.4517\n16/16 [==============================] - 0s 774us/step - loss: 5.4528\n16/16 [==============================] - 0s 2ms/step - loss: 5.4528\n16/16 [==============================] - 0s 1ms/step - loss: 5.4528\n16/16 [==============================] - 0s 855us/step - loss: 5.4528\n16/16 [==============================] - 0s 973us/step - loss: 5.4528\n16/16 [==============================] - 0s 925us/step - loss: 5.4528\n\nTesting for epoch 32 index 23:\n391/391 [==============================] - 0s 619us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0040\n16/16 [==============================] - 0s 903us/step - loss: 5.0166\n16/16 [==============================] - 0s 904us/step - loss: 5.0168\n16/16 [==============================] - 0s 845us/step - loss: 5.4091\n16/16 [==============================] - 0s 918us/step - loss: 5.4103\n16/16 [==============================] - 0s 947us/step - loss: 5.4103\n16/16 [==============================] - 0s 914us/step - loss: 5.4103\n16/16 [==============================] - 0s 1ms/step - loss: 5.4103\n16/16 [==============================] - 0s 843us/step - loss: 5.4103\n16/16 [==============================] - 0s 844us/step - loss: 5.4103\n\nTesting for epoch 32 index 24:\n391/391 [==============================] - 0s 664us/step\n16/16 [==============================] - 0s 909us/step - loss: 0.0043\n16/16 [==============================] - 0s 881us/step - loss: 5.0208\n16/16 [==============================] - 0s 886us/step - loss: 5.0211\n16/16 [==============================] - 0s 885us/step - loss: 5.4131\n16/16 [==============================] - 0s 861us/step - loss: 5.4143\n16/16 [==============================] - 0s 891us/step - loss: 5.4143\n16/16 [==============================] - 0s 860us/step - loss: 5.4143\n16/16 [==============================] - 0s 897us/step - loss: 5.4143\n16/16 [==============================] - 0s 866us/step - loss: 5.4143\n16/16 [==============================] - 0s 885us/step - loss: 5.4143\nEpoch 33 of 60\n\nTesting for epoch 33 index 1:\n391/391 [==============================] - 0s 655us/step\n16/16 [==============================] - 0s 912us/step - loss: 0.0040\n16/16 [==============================] - 0s 926us/step - loss: 5.1051\n16/16 [==============================] - 0s 908us/step - loss: 5.1053\n16/16 [==============================] - 0s 943us/step - loss: 5.4884\n16/16 [==============================] - 0s 960us/step - loss: 5.4895\n16/16 [==============================] - 0s 932us/step - loss: 5.4895\n16/16 [==============================] - 0s 930us/step - loss: 5.4895\n16/16 [==============================] - 0s 932us/step - loss: 5.4895\n16/16 [==============================] - 0s 914us/step - loss: 5.4895\n16/16 [==============================] - 0s 909us/step - loss: 5.4895\n\nTesting for epoch 33 index 2:\n391/391 [==============================] - 0s 677us/step\n16/16 [==============================] - 0s 907us/step - loss: 0.0038\n16/16 [==============================] - 0s 891us/step - loss: 5.0842\n16/16 [==============================] - 0s 864us/step - loss: 5.0845\n16/16 [==============================] - 0s 885us/step - loss: 5.4717\n16/16 [==============================] - 0s 949us/step - loss: 5.4729\n16/16 [==============================] - 0s 882us/step - loss: 5.4729\n16/16 [==============================] - 0s 899us/step - loss: 5.4729\n16/16 [==============================] - 0s 900us/step - loss: 5.4729\n16/16 [==============================] - 0s 884us/step - loss: 5.4729\n16/16 [==============================] - 0s 879us/step - loss: 5.4729\n\nTesting for epoch 33 index 3:\n391/391 [==============================] - 0s 667us/step\n16/16 [==============================] - 0s 956us/step - loss: 0.0039\n16/16 [==============================] - 0s 895us/step - loss: 5.1186\n16/16 [==============================] - 0s 935us/step - loss: 5.1189\n16/16 [==============================] - 0s 926us/step - loss: 5.5018\n16/16 [==============================] - 0s 925us/step - loss: 5.5029\n16/16 [==============================] - 0s 921us/step - loss: 5.5029\n16/16 [==============================] - 0s 939us/step - loss: 5.5029\n16/16 [==============================] - 0s 914us/step - loss: 5.5029\n16/16 [==============================] - 0s 940us/step - loss: 5.5029\n16/16 [==============================] - 0s 897us/step - loss: 5.5029\n\nTesting for epoch 33 index 4:\n391/391 [==============================] - 0s 675us/step\n16/16 [==============================] - 0s 910us/step - loss: 0.0035\n16/16 [==============================] - 0s 892us/step - loss: 5.1270\n16/16 [==============================] - 0s 904us/step - loss: 5.1273\n16/16 [==============================] - 0s 908us/step - loss: 5.5075\n16/16 [==============================] - 0s 851us/step - loss: 5.5086\n16/16 [==============================] - 0s 862us/step - loss: 5.5086\n16/16 [==============================] - 0s 923us/step - loss: 5.5086\n16/16 [==============================] - 0s 917us/step - loss: 5.5086\n16/16 [==============================] - 0s 941us/step - loss: 5.5086\n16/16 [==============================] - 0s 921us/step - loss: 5.5086\n\nTesting for epoch 33 index 5:\n391/391 [==============================] - 0s 625us/step\n16/16 [==============================] - 0s 672us/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1427\n16/16 [==============================] - 0s 2ms/step - loss: 5.1430\n16/16 [==============================] - 0s 774us/step - loss: 5.5224\n16/16 [==============================] - 0s 775us/step - loss: 5.5235\n16/16 [==============================] - 0s 763us/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n16/16 [==============================] - 0s 2ms/step - loss: 5.5235\n\nTesting for epoch 33 index 6:\n391/391 [==============================] - 0s 683us/step\n16/16 [==============================] - 0s 781us/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1995\n16/16 [==============================] - 0s 2ms/step - loss: 5.1998\n16/16 [==============================] - 0s 2ms/step - loss: 5.5734\n16/16 [==============================] - 0s 1ms/step - loss: 5.5745\n16/16 [==============================] - 0s 876us/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n16/16 [==============================] - 0s 811us/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n16/16 [==============================] - 0s 2ms/step - loss: 5.5745\n\nTesting for epoch 33 index 7:\n391/391 [==============================] - 0s 617us/step\n16/16 [==============================] - 0s 848us/step - loss: 0.0032\n16/16 [==============================] - 0s 854us/step - loss: 5.1523\n16/16 [==============================] - 0s 888us/step - loss: 5.1526\n16/16 [==============================] - 0s 830us/step - loss: 5.5310\n16/16 [==============================] - 0s 824us/step - loss: 5.5321\n16/16 [==============================] - 0s 840us/step - loss: 5.5321\n16/16 [==============================] - 0s 842us/step - loss: 5.5321\n16/16 [==============================] - 0s 831us/step - loss: 5.5321\n16/16 [==============================] - 0s 828us/step - loss: 5.5321\n16/16 [==============================] - 0s 828us/step - loss: 5.5321\n\nTesting for epoch 33 index 8:\n391/391 [==============================] - 0s 626us/step\n16/16 [==============================] - 0s 914us/step - loss: 0.0033\n16/16 [==============================] - 0s 878us/step - loss: 5.1870\n16/16 [==============================] - 0s 905us/step - loss: 5.1873\n16/16 [==============================] - 0s 905us/step - loss: 5.5616\n16/16 [==============================] - 0s 905us/step - loss: 5.5626\n16/16 [==============================] - 0s 933us/step - loss: 5.5626\n16/16 [==============================] - 0s 903us/step - loss: 5.5626\n16/16 [==============================] - 0s 894us/step - loss: 5.5626\n16/16 [==============================] - 0s 899us/step - loss: 5.5626\n16/16 [==============================] - 0s 880us/step - loss: 5.5626\n\nTesting for epoch 33 index 9:\n391/391 [==============================] - 0s 631us/step\n16/16 [==============================] - 0s 869us/step - loss: 0.0037\n16/16 [==============================] - 0s 881us/step - loss: 5.2072\n16/16 [==============================] - 0s 885us/step - loss: 5.2075\n16/16 [==============================] - 0s 895us/step - loss: 5.5808\n16/16 [==============================] - 0s 943us/step - loss: 5.5819\n16/16 [==============================] - 0s 904us/step - loss: 5.5819\n16/16 [==============================] - 0s 927us/step - loss: 5.5819\n16/16 [==============================] - 0s 930us/step - loss: 5.5819\n16/16 [==============================] - 0s 921us/step - loss: 5.5819\n16/16 [==============================] - 0s 884us/step - loss: 5.5819\n\nTesting for epoch 33 index 10:\n391/391 [==============================] - 0s 632us/step\n16/16 [==============================] - 0s 894us/step - loss: 0.0033\n16/16 [==============================] - 0s 879us/step - loss: 5.1693\n16/16 [==============================] - 0s 874us/step - loss: 5.1695\n16/16 [==============================] - 0s 906us/step - loss: 5.5473\n16/16 [==============================] - 0s 860us/step - loss: 5.5483\n16/16 [==============================] - 0s 875us/step - loss: 5.5483\n16/16 [==============================] - 0s 866us/step - loss: 5.5483\n16/16 [==============================] - 0s 924us/step - loss: 5.5483\n16/16 [==============================] - 0s 939us/step - loss: 5.5483\n16/16 [==============================] - 0s 911us/step - loss: 5.5483\n\nTesting for epoch 33 index 11:\n391/391 [==============================] - 0s 662us/step\n16/16 [==============================] - 0s 890us/step - loss: 0.0031\n16/16 [==============================] - 0s 892us/step - loss: 5.0956\n16/16 [==============================] - 0s 907us/step - loss: 5.0958\n16/16 [==============================] - 0s 898us/step - loss: 5.4831\n16/16 [==============================] - 0s 893us/step - loss: 5.4842\n16/16 [==============================] - 0s 922us/step - loss: 5.4842\n16/16 [==============================] - 0s 940us/step - loss: 5.4842\n16/16 [==============================] - 0s 927us/step - loss: 5.4842\n16/16 [==============================] - 0s 936us/step - loss: 5.4842\n16/16 [==============================] - 0s 965us/step - loss: 5.4842\n\nTesting for epoch 33 index 12:\n391/391 [==============================] - 0s 672us/step\n16/16 [==============================] - 0s 890us/step - loss: 0.0036\n16/16 [==============================] - 0s 900us/step - loss: 5.1193\n16/16 [==============================] - 0s 946us/step - loss: 5.1196\n16/16 [==============================] - 0s 911us/step - loss: 5.5051\n16/16 [==============================] - 0s 931us/step - loss: 5.5062\n16/16 [==============================] - 0s 935us/step - loss: 5.5062\n16/16 [==============================] - 0s 925us/step - loss: 5.5062\n16/16 [==============================] - 0s 938us/step - loss: 5.5062\n16/16 [==============================] - 0s 951us/step - loss: 5.5062\n16/16 [==============================] - 0s 876us/step - loss: 5.5062\n\nTesting for epoch 33 index 13:\n391/391 [==============================] - 0s 662us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 941us/step - loss: 5.1050\n16/16 [==============================] - 0s 938us/step - loss: 5.1052\n16/16 [==============================] - 0s 895us/step - loss: 5.4916\n16/16 [==============================] - 0s 826us/step - loss: 5.4927\n16/16 [==============================] - 0s 912us/step - loss: 5.4927\n16/16 [==============================] - 0s 886us/step - loss: 5.4927\n16/16 [==============================] - 0s 649us/step - loss: 5.4927\n16/16 [==============================] - 0s 2ms/step - loss: 5.4927\n16/16 [==============================] - 0s 804us/step - loss: 5.4927\n\nTesting for epoch 33 index 14:\n391/391 [==============================] - 0s 696us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0039\n16/16 [==============================] - 0s 1ms/step - loss: 5.0968\n16/16 [==============================] - 0s 689us/step - loss: 5.0971\n16/16 [==============================] - 0s 774us/step - loss: 5.4853\n16/16 [==============================] - 0s 764us/step - loss: 5.4864\n16/16 [==============================] - 0s 806us/step - loss: 5.4864\n16/16 [==============================] - 0s 2ms/step - loss: 5.4864\n16/16 [==============================] - 0s 2ms/step - loss: 5.4864\n16/16 [==============================] - 0s 805us/step - loss: 5.4864\n16/16 [==============================] - 0s 984us/step - loss: 5.4864\n\nTesting for epoch 33 index 15:\n391/391 [==============================] - 0s 780us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 755us/step - loss: 5.0582\n16/16 [==============================] - 0s 834us/step - loss: 5.0585\n16/16 [==============================] - 0s 861us/step - loss: 5.4500\n16/16 [==============================] - 0s 858us/step - loss: 5.4511\n16/16 [==============================] - 0s 871us/step - loss: 5.4511\n16/16 [==============================] - 0s 860us/step - loss: 5.4511\n16/16 [==============================] - 0s 886us/step - loss: 5.4511\n16/16 [==============================] - 0s 854us/step - loss: 5.4511\n16/16 [==============================] - 0s 916us/step - loss: 5.4511\n\nTesting for epoch 33 index 16:\n391/391 [==============================] - 0s 600us/step\n16/16 [==============================] - 0s 852us/step - loss: 0.0038\n16/16 [==============================] - 0s 852us/step - loss: 5.0006\n16/16 [==============================] - 0s 843us/step - loss: 5.0009\n16/16 [==============================] - 0s 848us/step - loss: 5.3994\n16/16 [==============================] - 0s 851us/step - loss: 5.4005\n16/16 [==============================] - 0s 847us/step - loss: 5.4005\n16/16 [==============================] - 0s 847us/step - loss: 5.4005\n16/16 [==============================] - 0s 853us/step - loss: 5.4005\n16/16 [==============================] - 0s 890us/step - loss: 5.4005\n16/16 [==============================] - 0s 883us/step - loss: 5.4005\n\nTesting for epoch 33 index 17:\n391/391 [==============================] - 0s 618us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0042\n16/16 [==============================] - 0s 868us/step - loss: 5.0322\n16/16 [==============================] - 0s 841us/step - loss: 5.0325\n16/16 [==============================] - 0s 824us/step - loss: 5.4265\n16/16 [==============================] - 0s 879us/step - loss: 5.4276\n16/16 [==============================] - 0s 893us/step - loss: 5.4276\n16/16 [==============================] - 0s 879us/step - loss: 5.4276\n16/16 [==============================] - 0s 894us/step - loss: 5.4276\n16/16 [==============================] - 0s 902us/step - loss: 5.4276\n16/16 [==============================] - 0s 896us/step - loss: 5.4276\n\nTesting for epoch 33 index 18:\n391/391 [==============================] - 0s 636us/step\n16/16 [==============================] - 0s 906us/step - loss: 0.0043\n16/16 [==============================] - 0s 882us/step - loss: 5.0743\n16/16 [==============================] - 0s 940us/step - loss: 5.0745\n16/16 [==============================] - 0s 893us/step - loss: 5.4673\n16/16 [==============================] - 0s 891us/step - loss: 5.4684\n16/16 [==============================] - 0s 908us/step - loss: 5.4684\n16/16 [==============================] - 0s 875us/step - loss: 5.4684\n16/16 [==============================] - 0s 885us/step - loss: 5.4684\n16/16 [==============================] - 0s 888us/step - loss: 5.4684\n16/16 [==============================] - 0s 860us/step - loss: 5.4684\n\nTesting for epoch 33 index 19:\n391/391 [==============================] - 0s 606us/step\n16/16 [==============================] - 0s 860us/step - loss: 0.0040\n16/16 [==============================] - 0s 852us/step - loss: 5.0430\n16/16 [==============================] - 0s 885us/step - loss: 5.0433\n16/16 [==============================] - 0s 843us/step - loss: 5.4392\n16/16 [==============================] - 0s 855us/step - loss: 5.4403\n16/16 [==============================] - 0s 844us/step - loss: 5.4403\n16/16 [==============================] - 0s 851us/step - loss: 5.4403\n16/16 [==============================] - 0s 853us/step - loss: 5.4403\n16/16 [==============================] - 0s 875us/step - loss: 5.4403\n16/16 [==============================] - 0s 847us/step - loss: 5.4403\n\nTesting for epoch 33 index 20:\n391/391 [==============================] - 0s 707us/step\n16/16 [==============================] - 0s 971us/step - loss: 0.0042\n16/16 [==============================] - 0s 968us/step - loss: 5.0666\n16/16 [==============================] - 0s 901us/step - loss: 5.0669\n16/16 [==============================] - 0s 886us/step - loss: 5.4589\n16/16 [==============================] - 0s 870us/step - loss: 5.4600\n16/16 [==============================] - 0s 860us/step - loss: 5.4600\n16/16 [==============================] - 0s 857us/step - loss: 5.4600\n16/16 [==============================] - 0s 870us/step - loss: 5.4600\n16/16 [==============================] - 0s 860us/step - loss: 5.4600\n16/16 [==============================] - 0s 842us/step - loss: 5.4600\n\nTesting for epoch 33 index 21:\n391/391 [==============================] - 0s 644us/step\n16/16 [==============================] - 0s 886us/step - loss: 0.0048\n16/16 [==============================] - 0s 858us/step - loss: 5.0766\n16/16 [==============================] - 0s 873us/step - loss: 5.0768\n16/16 [==============================] - 0s 877us/step - loss: 5.4688\n16/16 [==============================] - 0s 893us/step - loss: 5.4699\n16/16 [==============================] - 0s 956us/step - loss: 5.4699\n16/16 [==============================] - 0s 955us/step - loss: 5.4699\n16/16 [==============================] - 0s 921us/step - loss: 5.4699\n16/16 [==============================] - 0s 885us/step - loss: 5.4699\n16/16 [==============================] - 0s 847us/step - loss: 5.4699\n\nTesting for epoch 33 index 22:\n391/391 [==============================] - 0s 704us/step\n16/16 [==============================] - 0s 928us/step - loss: 0.0043\n16/16 [==============================] - 0s 912us/step - loss: 5.0861\n16/16 [==============================] - 0s 908us/step - loss: 5.0863\n16/16 [==============================] - 0s 653us/step - loss: 5.4772\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n16/16 [==============================] - 0s 703us/step - loss: 5.4783\n16/16 [==============================] - 0s 697us/step - loss: 5.4783\n16/16 [==============================] - 0s 707us/step - loss: 5.4783\n16/16 [==============================] - 0s 2ms/step - loss: 5.4783\n\nTesting for epoch 33 index 23:\n391/391 [==============================] - 0s 570us/step\n16/16 [==============================] - 0s 837us/step - loss: 0.0048\n16/16 [==============================] - 0s 802us/step - loss: 5.1277\n16/16 [==============================] - 0s 790us/step - loss: 5.1280\n16/16 [==============================] - 0s 978us/step - loss: 5.5173\n16/16 [==============================] - 0s 2ms/step - loss: 5.5185\n16/16 [==============================] - 0s 2ms/step - loss: 5.5185\n16/16 [==============================] - 0s 832us/step - loss: 5.5185\n16/16 [==============================] - 0s 958us/step - loss: 5.5185\n16/16 [==============================] - 0s 804us/step - loss: 5.5185\n16/16 [==============================] - 0s 828us/step - loss: 5.5185\n\nTesting for epoch 33 index 24:\n391/391 [==============================] - 0s 756us/step\n16/16 [==============================] - 0s 883us/step - loss: 0.0042\n16/16 [==============================] - 0s 871us/step - loss: 5.1430\n16/16 [==============================] - 0s 851us/step - loss: 5.1432\n16/16 [==============================] - 0s 931us/step - loss: 5.5293\n16/16 [==============================] - 0s 854us/step - loss: 5.5304\n16/16 [==============================] - 0s 930us/step - loss: 5.5304\n16/16 [==============================] - 0s 857us/step - loss: 5.5304\n16/16 [==============================] - 0s 906us/step - loss: 5.5304\n16/16 [==============================] - 0s 907us/step - loss: 5.5304\n16/16 [==============================] - 0s 843us/step - loss: 5.5304\nEpoch 34 of 60\n\nTesting for epoch 34 index 1:\n391/391 [==============================] - 0s 616us/step\n16/16 [==============================] - 0s 851us/step - loss: 0.0043\n16/16 [==============================] - 0s 871us/step - loss: 5.1314\n16/16 [==============================] - 0s 844us/step - loss: 5.1317\n16/16 [==============================] - 0s 856us/step - loss: 5.5177\n16/16 [==============================] - 0s 843us/step - loss: 5.5188\n16/16 [==============================] - 0s 865us/step - loss: 5.5188\n16/16 [==============================] - 0s 845us/step - loss: 5.5188\n16/16 [==============================] - 0s 891us/step - loss: 5.5188\n16/16 [==============================] - 0s 891us/step - loss: 5.5188\n16/16 [==============================] - 0s 913us/step - loss: 5.5188\n\nTesting for epoch 34 index 2:\n391/391 [==============================] - 0s 689us/step\n16/16 [==============================] - 0s 993us/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.1465\n16/16 [==============================] - 0s 1ms/step - loss: 5.1467\n16/16 [==============================] - 0s 1ms/step - loss: 5.5313\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 991us/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n16/16 [==============================] - 0s 988us/step - loss: 5.5324\n16/16 [==============================] - 0s 1ms/step - loss: 5.5324\n\nTesting for epoch 34 index 3:\n391/391 [==============================] - 0s 627us/step\n16/16 [==============================] - 0s 917us/step - loss: 0.0037\n16/16 [==============================] - 0s 11ms/step - loss: 5.1429\n16/16 [==============================] - 0s 3ms/step - loss: 5.1432\n16/16 [==============================] - 0s 2ms/step - loss: 5.5281\n16/16 [==============================] - 0s 2ms/step - loss: 5.5292\n16/16 [==============================] - 0s 4ms/step - loss: 5.5292\n16/16 [==============================] - 0s 2ms/step - loss: 5.5292\n16/16 [==============================] - 0s 5ms/step - loss: 5.5292\n16/16 [==============================] - 0s 4ms/step - loss: 5.5292\n16/16 [==============================] - 0s 5ms/step - loss: 5.5292\n\nTesting for epoch 34 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2030\n16/16 [==============================] - 0s 1ms/step - loss: 5.2033\n16/16 [==============================] - 0s 4ms/step - loss: 5.5839\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n16/16 [==============================] - 0s 2ms/step - loss: 5.5850\n\nTesting for epoch 34 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 5ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 5.2007\n16/16 [==============================] - 0s 2ms/step - loss: 5.2010\n16/16 [==============================] - 0s 5ms/step - loss: 5.5812\n16/16 [==============================] - 0s 4ms/step - loss: 5.5823\n16/16 [==============================] - 0s 5ms/step - loss: 5.5823\n16/16 [==============================] - 0s 2ms/step - loss: 5.5823\n16/16 [==============================] - 0s 1ms/step - loss: 5.5823\n16/16 [==============================] - 0s 1ms/step - loss: 5.5823\n16/16 [==============================] - 0s 2ms/step - loss: 5.5823\n\nTesting for epoch 34 index 6:\n391/391 [==============================] - 0s 961us/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0030\n16/16 [==============================] - 0s 4ms/step - loss: 5.1687\n16/16 [==============================] - 0s 4ms/step - loss: 5.1690\n16/16 [==============================] - 0s 3ms/step - loss: 5.5517\n16/16 [==============================] - 0s 9ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n16/16 [==============================] - 0s 2ms/step - loss: 5.5528\n\nTesting for epoch 34 index 7:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.2596\n16/16 [==============================] - 0s 2ms/step - loss: 5.2599\n16/16 [==============================] - 0s 1ms/step - loss: 5.6327\n16/16 [==============================] - 0s 1ms/step - loss: 5.6338\n16/16 [==============================] - 0s 5ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 2ms/step - loss: 5.6338\n16/16 [==============================] - 0s 3ms/step - loss: 5.6338\n\nTesting for epoch 34 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0030\n16/16 [==============================] - 0s 2ms/step - loss: 5.2214\n16/16 [==============================] - 0s 3ms/step - loss: 5.2217\n16/16 [==============================] - 0s 2ms/step - loss: 5.5986\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 3ms/step - loss: 5.5997\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 4ms/step - loss: 5.5997\n16/16 [==============================] - 0s 2ms/step - loss: 5.5997\n16/16 [==============================] - 0s 1ms/step - loss: 5.5997\n\nTesting for epoch 34 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0032\n16/16 [==============================] - 0s 2ms/step - loss: 5.2985\n16/16 [==============================] - 0s 3ms/step - loss: 5.2988\n16/16 [==============================] - 0s 2ms/step - loss: 5.6699\n16/16 [==============================] - 0s 5ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 3ms/step - loss: 5.6710\n16/16 [==============================] - 0s 2ms/step - loss: 5.6710\n16/16 [==============================] - 0s 1ms/step - loss: 5.6710\n\nTesting for epoch 34 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 5.1981\n16/16 [==============================] - 0s 3ms/step - loss: 5.1983\n16/16 [==============================] - 0s 6ms/step - loss: 5.5782\n16/16 [==============================] - 0s 1ms/step - loss: 5.5793\n16/16 [==============================] - 0s 6ms/step - loss: 5.5793\n16/16 [==============================] - 0s 6ms/step - loss: 5.5793\n16/16 [==============================] - 0s 2ms/step - loss: 5.5793\n16/16 [==============================] - 0s 4ms/step - loss: 5.5793\n16/16 [==============================] - 0s 2ms/step - loss: 5.5793\n\nTesting for epoch 34 index 11:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1648\n16/16 [==============================] - 0s 3ms/step - loss: 5.1651\n16/16 [==============================] - 0s 3ms/step - loss: 5.5503\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 1ms/step - loss: 5.5514\n16/16 [==============================] - 0s 2ms/step - loss: 5.5514\n\nTesting for epoch 34 index 12:\n391/391 [==============================] - 0s 561us/step\n16/16 [==============================] - 0s 851us/step - loss: 0.0040\n16/16 [==============================] - 0s 1ms/step - loss: 5.0803\n16/16 [==============================] - 0s 3ms/step - loss: 5.0806\n16/16 [==============================] - 0s 1ms/step - loss: 5.4738\n16/16 [==============================] - 0s 917us/step - loss: 5.4750\n16/16 [==============================] - 0s 877us/step - loss: 5.4750\n16/16 [==============================] - 0s 902us/step - loss: 5.4750\n16/16 [==============================] - 0s 884us/step - loss: 5.4750\n16/16 [==============================] - 0s 880us/step - loss: 5.4750\n16/16 [==============================] - 0s 854us/step - loss: 5.4750\n\nTesting for epoch 34 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.1099\n16/16 [==============================] - 0s 1ms/step - loss: 5.1101\n16/16 [==============================] - 0s 2ms/step - loss: 5.5011\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n16/16 [==============================] - 0s 1ms/step - loss: 5.5023\n16/16 [==============================] - 0s 1ms/step - loss: 5.5023\n16/16 [==============================] - 0s 3ms/step - loss: 5.5023\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n16/16 [==============================] - 0s 2ms/step - loss: 5.5023\n\nTesting for epoch 34 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.1171\n16/16 [==============================] - 0s 2ms/step - loss: 5.1174\n16/16 [==============================] - 0s 3ms/step - loss: 5.5125\n16/16 [==============================] - 0s 1ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n16/16 [==============================] - 0s 4ms/step - loss: 5.5136\n16/16 [==============================] - 0s 3ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n16/16 [==============================] - 0s 2ms/step - loss: 5.5136\n\nTesting for epoch 34 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0042\n16/16 [==============================] - 0s 2ms/step - loss: 5.0741\n16/16 [==============================] - 0s 2ms/step - loss: 5.0744\n16/16 [==============================] - 0s 2ms/step - loss: 5.4716\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n16/16 [==============================] - 0s 1ms/step - loss: 5.4728\n\nTesting for epoch 34 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 5.1080\n16/16 [==============================] - 0s 2ms/step - loss: 5.1082\n16/16 [==============================] - 0s 2ms/step - loss: 5.5019\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 2ms/step - loss: 5.5031\n16/16 [==============================] - 0s 1ms/step - loss: 5.5031\n\nTesting for epoch 34 index 17:\n391/391 [==============================] - 0s 967us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0043\n16/16 [==============================] - 0s 3ms/step - loss: 5.0988\n16/16 [==============================] - 0s 2ms/step - loss: 5.0991\n16/16 [==============================] - 0s 2ms/step - loss: 5.4935\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 3ms/step - loss: 5.4946\n16/16 [==============================] - 0s 3ms/step - loss: 5.4946\n16/16 [==============================] - 0s 2ms/step - loss: 5.4946\n16/16 [==============================] - 0s 4ms/step - loss: 5.4946\n\nTesting for epoch 34 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0045\n16/16 [==============================] - 0s 3ms/step - loss: 5.1042\n16/16 [==============================] - 0s 2ms/step - loss: 5.1045\n16/16 [==============================] - 0s 2ms/step - loss: 5.4982\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 1ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n16/16 [==============================] - 0s 3ms/step - loss: 5.4993\n16/16 [==============================] - 0s 2ms/step - loss: 5.4993\n\nTesting for epoch 34 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.1307\n16/16 [==============================] - 0s 3ms/step - loss: 5.1310\n16/16 [==============================] - 0s 2ms/step - loss: 5.5242\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n16/16 [==============================] - 0s 2ms/step - loss: 5.5254\n\nTesting for epoch 34 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0048\n16/16 [==============================] - 0s 5ms/step - loss: 5.1453\n16/16 [==============================] - 0s 1ms/step - loss: 5.1456\n16/16 [==============================] - 0s 2ms/step - loss: 5.5352\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 1ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n16/16 [==============================] - 0s 2ms/step - loss: 5.5363\n\nTesting for epoch 34 index 21:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.0928\n16/16 [==============================] - 0s 4ms/step - loss: 5.0931\n16/16 [==============================] - 0s 3ms/step - loss: 5.4911\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n16/16 [==============================] - 0s 2ms/step - loss: 5.4923\n\nTesting for epoch 34 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 5.1369\n16/16 [==============================] - 0s 3ms/step - loss: 5.1372\n16/16 [==============================] - 0s 2ms/step - loss: 5.5283\n16/16 [==============================] - 0s 3ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 2ms/step - loss: 5.5294\n16/16 [==============================] - 0s 3ms/step - loss: 5.5294\n\nTesting for epoch 34 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.1408\n16/16 [==============================] - 0s 2ms/step - loss: 5.1411\n16/16 [==============================] - 0s 1ms/step - loss: 5.5335\n16/16 [==============================] - 0s 3ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n16/16 [==============================] - 0s 2ms/step - loss: 5.5346\n\nTesting for epoch 34 index 24:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 3ms/step - loss: 5.1474\n16/16 [==============================] - 0s 2ms/step - loss: 5.1477\n16/16 [==============================] - 0s 2ms/step - loss: 5.5387\n16/16 [==============================] - 0s 3ms/step - loss: 5.5398\n16/16 [==============================] - 0s 4ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\n16/16 [==============================] - 0s 1ms/step - loss: 5.5398\n16/16 [==============================] - 0s 2ms/step - loss: 5.5398\nEpoch 35 of 60\n\nTesting for epoch 35 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1018\n16/16 [==============================] - 0s 2ms/step - loss: 5.1021\n16/16 [==============================] - 0s 2ms/step - loss: 5.4957\n16/16 [==============================] - 0s 3ms/step - loss: 5.4968\n16/16 [==============================] - 0s 2ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n16/16 [==============================] - 0s 1ms/step - loss: 5.4968\n\nTesting for epoch 35 index 2:\n391/391 [==============================] - 0s 988us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 2ms/step - loss: 5.1292\n16/16 [==============================] - 0s 2ms/step - loss: 5.1295\n16/16 [==============================] - 0s 2ms/step - loss: 5.5215\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n16/16 [==============================] - 0s 2ms/step - loss: 5.5226\n\nTesting for epoch 35 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0040\n16/16 [==============================] - 0s 2ms/step - loss: 5.2224\n16/16 [==============================] - 0s 3ms/step - loss: 5.2227\n16/16 [==============================] - 0s 5ms/step - loss: 5.6059\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 3ms/step - loss: 5.6070\n16/16 [==============================] - 0s 1ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n16/16 [==============================] - 0s 2ms/step - loss: 5.6070\n\nTesting for epoch 35 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 3ms/step - loss: 5.2198\n16/16 [==============================] - 0s 3ms/step - loss: 5.2201\n16/16 [==============================] - 0s 3ms/step - loss: 5.6026\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n16/16 [==============================] - 0s 2ms/step - loss: 5.6037\n\nTesting for epoch 35 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2748\n16/16 [==============================] - 0s 2ms/step - loss: 5.2751\n16/16 [==============================] - 0s 2ms/step - loss: 5.6519\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 1ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n16/16 [==============================] - 0s 2ms/step - loss: 5.6530\n\nTesting for epoch 35 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3099\n16/16 [==============================] - 0s 2ms/step - loss: 5.3101\n16/16 [==============================] - 0s 2ms/step - loss: 5.6837\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 3ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 2ms/step - loss: 5.6848\n16/16 [==============================] - 0s 1ms/step - loss: 5.6848\n\nTesting for epoch 35 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0032\n16/16 [==============================] - 0s 3ms/step - loss: 5.2094\n16/16 [==============================] - 0s 1ms/step - loss: 5.2097\n16/16 [==============================] - 0s 1ms/step - loss: 5.5912\n16/16 [==============================] - 0s 3ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n16/16 [==============================] - 0s 2ms/step - loss: 5.5923\n\nTesting for epoch 35 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0033\n16/16 [==============================] - 0s 2ms/step - loss: 5.2987\n16/16 [==============================] - 0s 1ms/step - loss: 5.2989\n16/16 [==============================] - 0s 1ms/step - loss: 5.6727\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n16/16 [==============================] - 0s 2ms/step - loss: 5.6738\n\nTesting for epoch 35 index 9:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0031\n16/16 [==============================] - 0s 2ms/step - loss: 5.2803\n16/16 [==============================] - 0s 4ms/step - loss: 5.2806\n16/16 [==============================] - 0s 2ms/step - loss: 5.6550\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 2ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n16/16 [==============================] - 0s 1ms/step - loss: 5.6561\n\nTesting for epoch 35 index 10:\n391/391 [==============================] - 0s 969us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3117\n16/16 [==============================] - 0s 3ms/step - loss: 5.3120\n16/16 [==============================] - 0s 2ms/step - loss: 5.6855\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 3ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n16/16 [==============================] - 0s 2ms/step - loss: 5.6865\n\nTesting for epoch 35 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0042\n16/16 [==============================] - 0s 4ms/step - loss: 5.2815\n16/16 [==============================] - 0s 2ms/step - loss: 5.2818\n16/16 [==============================] - 0s 4ms/step - loss: 5.6609\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 2ms/step - loss: 5.6620\n16/16 [==============================] - 0s 1ms/step - loss: 5.6620\n\nTesting for epoch 35 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 1ms/step - loss: 5.1691\n16/16 [==============================] - 0s 1ms/step - loss: 5.1694\n16/16 [==============================] - 0s 2ms/step - loss: 5.5604\n16/16 [==============================] - 0s 3ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n16/16 [==============================] - 0s 1ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n16/16 [==============================] - 0s 3ms/step - loss: 5.5616\n16/16 [==============================] - 0s 2ms/step - loss: 5.5616\n\nTesting for epoch 35 index 13:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.1483\n16/16 [==============================] - 0s 3ms/step - loss: 5.1486\n16/16 [==============================] - 0s 1ms/step - loss: 5.5406\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 1ms/step - loss: 5.5417\n16/16 [==============================] - 0s 2ms/step - loss: 5.5417\n16/16 [==============================] - 0s 5ms/step - loss: 5.5417\n16/16 [==============================] - 0s 1ms/step - loss: 5.5417\n\nTesting for epoch 35 index 14:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 5.1045\n16/16 [==============================] - 0s 2ms/step - loss: 5.1048\n16/16 [==============================] - 0s 1ms/step - loss: 5.5010\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n16/16 [==============================] - 0s 3ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n16/16 [==============================] - 0s 2ms/step - loss: 5.5021\n\nTesting for epoch 35 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0045\n16/16 [==============================] - 0s 1ms/step - loss: 5.1899\n16/16 [==============================] - 0s 2ms/step - loss: 5.1902\n16/16 [==============================] - 0s 1ms/step - loss: 5.5811\n16/16 [==============================] - 0s 4ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n16/16 [==============================] - 0s 2ms/step - loss: 5.5822\n\nTesting for epoch 35 index 16:\n391/391 [==============================] - 0s 987us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.1636\n16/16 [==============================] - 0s 1ms/step - loss: 5.1639\n16/16 [==============================] - 0s 2ms/step - loss: 5.5574\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 3ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n16/16 [==============================] - 0s 2ms/step - loss: 5.5586\n\nTesting for epoch 35 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.0845\n16/16 [==============================] - 0s 4ms/step - loss: 5.0848\n16/16 [==============================] - 0s 2ms/step - loss: 5.4835\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 1ms/step - loss: 5.4846\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 2ms/step - loss: 5.4846\n16/16 [==============================] - 0s 4ms/step - loss: 5.4846\n16/16 [==============================] - 0s 1ms/step - loss: 5.4846\n\nTesting for epoch 35 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0044\n16/16 [==============================] - 0s 2ms/step - loss: 5.1642\n16/16 [==============================] - 0s 3ms/step - loss: 5.1645\n16/16 [==============================] - 0s 1ms/step - loss: 5.5587\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 2ms/step - loss: 5.5599\n16/16 [==============================] - 0s 1ms/step - loss: 5.5599\n16/16 [==============================] - 0s 1ms/step - loss: 5.5599\n16/16 [==============================] - 0s 3ms/step - loss: 5.5599\n\nTesting for epoch 35 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0046\n16/16 [==============================] - 0s 2ms/step - loss: 5.2019\n16/16 [==============================] - 0s 2ms/step - loss: 5.2022\n16/16 [==============================] - 0s 2ms/step - loss: 5.5945\n16/16 [==============================] - 0s 4ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n16/16 [==============================] - 0s 2ms/step - loss: 5.5956\n\nTesting for epoch 35 index 20:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.1387\n16/16 [==============================] - 0s 2ms/step - loss: 5.1390\n16/16 [==============================] - 0s 2ms/step - loss: 5.5356\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n16/16 [==============================] - 0s 2ms/step - loss: 5.5368\n\nTesting for epoch 35 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.2111\n16/16 [==============================] - 0s 2ms/step - loss: 5.2114\n16/16 [==============================] - 0s 2ms/step - loss: 5.6002\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 2ms/step - loss: 5.6014\n16/16 [==============================] - 0s 3ms/step - loss: 5.6014\n\nTesting for epoch 35 index 22:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.1603\n16/16 [==============================] - 0s 2ms/step - loss: 5.1606\n16/16 [==============================] - 0s 2ms/step - loss: 5.5549\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n16/16 [==============================] - 0s 2ms/step - loss: 5.5560\n\nTesting for epoch 35 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0048\n16/16 [==============================] - 0s 2ms/step - loss: 5.2077\n16/16 [==============================] - 0s 2ms/step - loss: 5.2080\n16/16 [==============================] - 0s 3ms/step - loss: 5.6009\n16/16 [==============================] - 0s 4ms/step - loss: 5.6021\n16/16 [==============================] - 0s 3ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n\nTesting for epoch 35 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.1479\n16/16 [==============================] - 0s 1ms/step - loss: 5.1481\n16/16 [==============================] - 0s 3ms/step - loss: 5.5449\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 4ms/step - loss: 5.5460\n16/16 [==============================] - 0s 4ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\n16/16 [==============================] - 0s 2ms/step - loss: 5.5460\nEpoch 36 of 60\n\nTesting for epoch 36 index 1:\n391/391 [==============================] - 0s 992us/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0044\n16/16 [==============================] - 0s 1ms/step - loss: 5.1958\n16/16 [==============================] - 0s 1ms/step - loss: 5.1961\n16/16 [==============================] - 0s 2ms/step - loss: 5.5883\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n16/16 [==============================] - 0s 1ms/step - loss: 5.5895\n16/16 [==============================] - 0s 3ms/step - loss: 5.5895\n16/16 [==============================] - 0s 2ms/step - loss: 5.5895\n\nTesting for epoch 36 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 1ms/step - loss: 5.1905\n16/16 [==============================] - 0s 1ms/step - loss: 5.1907\n16/16 [==============================] - 0s 1ms/step - loss: 5.5819\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 2ms/step - loss: 5.5830\n16/16 [==============================] - 0s 1ms/step - loss: 5.5830\n16/16 [==============================] - 0s 3ms/step - loss: 5.5830\n16/16 [==============================] - 0s 2ms/step - loss: 5.5830\n\nTesting for epoch 36 index 3:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 2ms/step - loss: 5.2484\n16/16 [==============================] - 0s 4ms/step - loss: 5.2486\n16/16 [==============================] - 0s 2ms/step - loss: 5.6346\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 1ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 1ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n16/16 [==============================] - 0s 2ms/step - loss: 5.6357\n\nTesting for epoch 36 index 4:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2164\n16/16 [==============================] - 0s 4ms/step - loss: 5.2167\n16/16 [==============================] - 0s 2ms/step - loss: 5.6083\n16/16 [==============================] - 0s 3ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 1ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 2ms/step - loss: 5.6095\n16/16 [==============================] - 0s 3ms/step - loss: 5.6095\n\nTesting for epoch 36 index 5:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0034\n16/16 [==============================] - 0s 1ms/step - loss: 5.2337\n16/16 [==============================] - 0s 2ms/step - loss: 5.2340\n16/16 [==============================] - 0s 3ms/step - loss: 5.6202\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 4ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n16/16 [==============================] - 0s 2ms/step - loss: 5.6213\n\nTesting for epoch 36 index 6:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 4ms/step - loss: 5.2283\n16/16 [==============================] - 0s 2ms/step - loss: 5.2286\n16/16 [==============================] - 0s 4ms/step - loss: 5.6135\n16/16 [==============================] - 0s 3ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n16/16 [==============================] - 0s 3ms/step - loss: 5.6146\n16/16 [==============================] - 0s 2ms/step - loss: 5.6146\n\nTesting for epoch 36 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0033\n16/16 [==============================] - 0s 2ms/step - loss: 5.3007\n16/16 [==============================] - 0s 5ms/step - loss: 5.3010\n16/16 [==============================] - 0s 2ms/step - loss: 5.6787\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 3ms/step - loss: 5.6798\n16/16 [==============================] - 0s 2ms/step - loss: 5.6798\n\nTesting for epoch 36 index 8:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0032\n16/16 [==============================] - 0s 3ms/step - loss: 5.3333\n16/16 [==============================] - 0s 2ms/step - loss: 5.3335\n16/16 [==============================] - 0s 2ms/step - loss: 5.7093\n16/16 [==============================] - 0s 2ms/step - loss: 5.7104\n16/16 [==============================] - 0s 6ms/step - loss: 5.7104\n16/16 [==============================] - 0s 1ms/step - loss: 5.7104\n16/16 [==============================] - 0s 4ms/step - loss: 5.7104\n16/16 [==============================] - 0s 3ms/step - loss: 5.7104\n16/16 [==============================] - 0s 1ms/step - loss: 5.7104\n\nTesting for epoch 36 index 9:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 5.3853\n16/16 [==============================] - 0s 3ms/step - loss: 5.3856\n16/16 [==============================] - 0s 2ms/step - loss: 5.7582\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n\nTesting for epoch 36 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0034\n16/16 [==============================] - 0s 2ms/step - loss: 5.3235\n16/16 [==============================] - 0s 2ms/step - loss: 5.3238\n16/16 [==============================] - 0s 2ms/step - loss: 5.7020\n16/16 [==============================] - 0s 5ms/step - loss: 5.7031\n16/16 [==============================] - 0s 4ms/step - loss: 5.7031\n16/16 [==============================] - 0s 2ms/step - loss: 5.7031\n16/16 [==============================] - 0s 3ms/step - loss: 5.7031\n16/16 [==============================] - 0s 4ms/step - loss: 5.7031\n16/16 [==============================] - 0s 1ms/step - loss: 5.7031\n\nTesting for epoch 36 index 11:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0039\n16/16 [==============================] - 0s 2ms/step - loss: 5.2989\n16/16 [==============================] - 0s 2ms/step - loss: 5.2992\n16/16 [==============================] - 0s 2ms/step - loss: 5.6815\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 3ms/step - loss: 5.6826\n16/16 [==============================] - 0s 2ms/step - loss: 5.6826\n\nTesting for epoch 36 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2038\n16/16 [==============================] - 0s 2ms/step - loss: 5.2041\n16/16 [==============================] - 0s 2ms/step - loss: 5.5978\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 1ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 2ms/step - loss: 5.5989\n16/16 [==============================] - 0s 1ms/step - loss: 5.5989\n\nTesting for epoch 36 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0042\n16/16 [==============================] - 0s 1ms/step - loss: 5.2300\n16/16 [==============================] - 0s 2ms/step - loss: 5.2302\n16/16 [==============================] - 0s 2ms/step - loss: 5.6212\n16/16 [==============================] - 0s 8ms/step - loss: 5.6223\n16/16 [==============================] - 0s 4ms/step - loss: 5.6223\n16/16 [==============================] - 0s 4ms/step - loss: 5.6223\n16/16 [==============================] - 0s 2ms/step - loss: 5.6223\n16/16 [==============================] - 0s 2ms/step - loss: 5.6223\n16/16 [==============================] - 0s 3ms/step - loss: 5.6223\n\nTesting for epoch 36 index 14:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.2473\n16/16 [==============================] - 0s 2ms/step - loss: 5.2476\n16/16 [==============================] - 0s 2ms/step - loss: 5.6383\n16/16 [==============================] - 0s 2ms/step - loss: 5.6394\n16/16 [==============================] - 0s 3ms/step - loss: 5.6394\n16/16 [==============================] - 0s 2ms/step - loss: 5.6394\n16/16 [==============================] - 0s 8ms/step - loss: 5.6394\n16/16 [==============================] - 0s 5ms/step - loss: 5.6394\n16/16 [==============================] - 0s 1ms/step - loss: 5.6394\n\nTesting for epoch 36 index 15:\n391/391 [==============================] - 0s 998us/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.1690\n16/16 [==============================] - 0s 1ms/step - loss: 5.1693\n16/16 [==============================] - 0s 2ms/step - loss: 5.5663\n16/16 [==============================] - 0s 4ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 3ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n16/16 [==============================] - 0s 2ms/step - loss: 5.5675\n\nTesting for epoch 36 index 16:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0048\n16/16 [==============================] - 0s 1ms/step - loss: 5.1451\n16/16 [==============================] - 0s 2ms/step - loss: 5.1454\n16/16 [==============================] - 0s 2ms/step - loss: 5.5470\n16/16 [==============================] - 0s 3ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 2ms/step - loss: 5.5482\n16/16 [==============================] - 0s 3ms/step - loss: 5.5482\n\nTesting for epoch 36 index 17:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.2356\n16/16 [==============================] - 0s 3ms/step - loss: 5.2359\n16/16 [==============================] - 0s 2ms/step - loss: 5.6304\n16/16 [==============================] - 0s 4ms/step - loss: 5.6315\n16/16 [==============================] - 0s 2ms/step - loss: 5.6315\n16/16 [==============================] - 0s 5ms/step - loss: 5.6315\n16/16 [==============================] - 0s 5ms/step - loss: 5.6315\n16/16 [==============================] - 0s 3ms/step - loss: 5.6315\n16/16 [==============================] - 0s 2ms/step - loss: 5.6315\n\nTesting for epoch 36 index 18:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 5.1895\n16/16 [==============================] - 0s 2ms/step - loss: 5.1898\n16/16 [==============================] - 0s 2ms/step - loss: 5.5869\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n16/16 [==============================] - 0s 2ms/step - loss: 5.5880\n16/16 [==============================] - 0s 1ms/step - loss: 5.5880\n16/16 [==============================] - 0s 1ms/step - loss: 5.5880\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n16/16 [==============================] - 0s 3ms/step - loss: 5.5880\n\nTesting for epoch 36 index 19:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.1761\n16/16 [==============================] - 0s 2ms/step - loss: 5.1764\n16/16 [==============================] - 0s 2ms/step - loss: 5.5768\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n16/16 [==============================] - 0s 3ms/step - loss: 5.5780\n16/16 [==============================] - 0s 2ms/step - loss: 5.5780\n\nTesting for epoch 36 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 3ms/step - loss: 5.1661\n16/16 [==============================] - 0s 3ms/step - loss: 5.1664\n16/16 [==============================] - 0s 2ms/step - loss: 5.5653\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 3ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 2ms/step - loss: 5.5665\n16/16 [==============================] - 0s 3ms/step - loss: 5.5665\n\nTesting for epoch 36 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.1874\n16/16 [==============================] - 0s 2ms/step - loss: 5.1877\n16/16 [==============================] - 0s 3ms/step - loss: 5.5857\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 3ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n16/16 [==============================] - 0s 2ms/step - loss: 5.5868\n\nTesting for epoch 36 index 22:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0055\n16/16 [==============================] - 0s 2ms/step - loss: 5.2373\n16/16 [==============================] - 0s 2ms/step - loss: 5.2376\n16/16 [==============================] - 0s 2ms/step - loss: 5.6301\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 3ms/step - loss: 5.6312\n16/16 [==============================] - 0s 1ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n16/16 [==============================] - 0s 2ms/step - loss: 5.6312\n\nTesting for epoch 36 index 23:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0049\n16/16 [==============================] - 0s 2ms/step - loss: 5.1576\n16/16 [==============================] - 0s 2ms/step - loss: 5.1579\n16/16 [==============================] - 0s 2ms/step - loss: 5.5571\n16/16 [==============================] - 0s 5ms/step - loss: 5.5582\n16/16 [==============================] - 0s 2ms/step - loss: 5.5582\n16/16 [==============================] - 0s 2ms/step - loss: 5.5582\n16/16 [==============================] - 0s 4ms/step - loss: 5.5582\n16/16 [==============================] - 0s 3ms/step - loss: 5.5582\n16/16 [==============================] - 0s 1ms/step - loss: 5.5582\n\nTesting for epoch 36 index 24:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 1ms/step - loss: 5.1952\n16/16 [==============================] - 0s 2ms/step - loss: 5.1955\n16/16 [==============================] - 0s 2ms/step - loss: 5.5931\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 1ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\n16/16 [==============================] - 0s 2ms/step - loss: 5.5943\nEpoch 37 of 60\n\nTesting for epoch 37 index 1:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0051\n16/16 [==============================] - 0s 2ms/step - loss: 5.2008\n16/16 [==============================] - 0s 2ms/step - loss: 5.2011\n16/16 [==============================] - 0s 1ms/step - loss: 5.6013\n16/16 [==============================] - 0s 1ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n16/16 [==============================] - 0s 2ms/step - loss: 5.6024\n\nTesting for epoch 37 index 2:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0047\n16/16 [==============================] - 0s 2ms/step - loss: 5.2213\n16/16 [==============================] - 0s 2ms/step - loss: 5.2216\n16/16 [==============================] - 0s 1ms/step - loss: 5.6126\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 2ms/step - loss: 5.6138\n16/16 [==============================] - 0s 3ms/step - loss: 5.6138\n16/16 [==============================] - 0s 3ms/step - loss: 5.6138\n\nTesting for epoch 37 index 3:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 5.2441\n16/16 [==============================] - 0s 2ms/step - loss: 5.2444\n16/16 [==============================] - 0s 2ms/step - loss: 5.6347\n16/16 [==============================] - 0s 4ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 2ms/step - loss: 5.6358\n16/16 [==============================] - 0s 1ms/step - loss: 5.6358\n\nTesting for epoch 37 index 4:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0043\n16/16 [==============================] - 0s 2ms/step - loss: 5.3030\n16/16 [==============================] - 0s 2ms/step - loss: 5.3032\n16/16 [==============================] - 0s 2ms/step - loss: 5.6918\n16/16 [==============================] - 0s 3ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n16/16 [==============================] - 0s 2ms/step - loss: 5.6930\n\nTesting for epoch 37 index 5:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 3ms/step - loss: 5.3149\n16/16 [==============================] - 0s 3ms/step - loss: 5.3152\n16/16 [==============================] - 0s 2ms/step - loss: 5.7013\n16/16 [==============================] - 0s 2ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 4ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 3ms/step - loss: 5.7024\n16/16 [==============================] - 0s 2ms/step - loss: 5.7024\n\nTesting for epoch 37 index 6:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0041\n16/16 [==============================] - 0s 4ms/step - loss: 5.3506\n16/16 [==============================] - 0s 3ms/step - loss: 5.3509\n16/16 [==============================] - 0s 2ms/step - loss: 5.7317\n16/16 [==============================] - 0s 4ms/step - loss: 5.7328\n16/16 [==============================] - 0s 4ms/step - loss: 5.7328\n16/16 [==============================] - 0s 2ms/step - loss: 5.7328\n16/16 [==============================] - 0s 2ms/step - loss: 5.7328\n16/16 [==============================] - 0s 3ms/step - loss: 5.7328\n16/16 [==============================] - 0s 3ms/step - loss: 5.7328\n\nTesting for epoch 37 index 7:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0037\n16/16 [==============================] - 0s 1ms/step - loss: 5.3807\n16/16 [==============================] - 0s 4ms/step - loss: 5.3810\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 1ms/step - loss: 5.7592\n16/16 [==============================] - 0s 3ms/step - loss: 5.7592\n16/16 [==============================] - 0s 2ms/step - loss: 5.7592\n16/16 [==============================] - 0s 4ms/step - loss: 5.7592\n\nTesting for epoch 37 index 8:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0035\n16/16 [==============================] - 0s 2ms/step - loss: 5.3407\n16/16 [==============================] - 0s 2ms/step - loss: 5.3410\n16/16 [==============================] - 0s 2ms/step - loss: 5.7210\n16/16 [==============================] - 0s 5ms/step - loss: 5.7221\n16/16 [==============================] - 0s 2ms/step - loss: 5.7221\n16/16 [==============================] - 0s 4ms/step - loss: 5.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.7221\n16/16 [==============================] - 0s 4ms/step - loss: 5.7221\n16/16 [==============================] - 0s 3ms/step - loss: 5.7221\n\nTesting for epoch 37 index 9:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0032\n16/16 [==============================] - 0s 2ms/step - loss: 5.3797\n16/16 [==============================] - 0s 3ms/step - loss: 5.3799\n16/16 [==============================] - 0s 3ms/step - loss: 5.7570\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 4ms/step - loss: 5.7581\n16/16 [==============================] - 0s 4ms/step - loss: 5.7581\n16/16 [==============================] - 0s 3ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n16/16 [==============================] - 0s 2ms/step - loss: 5.7581\n\nTesting for epoch 37 index 10:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.3347\n16/16 [==============================] - 0s 2ms/step - loss: 5.3350\n16/16 [==============================] - 0s 2ms/step - loss: 5.7160\n16/16 [==============================] - 0s 3ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 3ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n16/16 [==============================] - 0s 2ms/step - loss: 5.7171\n\nTesting for epoch 37 index 11:\n391/391 [==============================] - 0s 948us/step\n16/16 [==============================] - 0s 1ms/step - loss: 0.0036\n16/16 [==============================] - 0s 2ms/step - loss: 5.2534\n16/16 [==============================] - 0s 1ms/step - loss: 5.2537\n16/16 [==============================] - 0s 2ms/step - loss: 5.6468\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 3ms/step - loss: 5.6479\n16/16 [==============================] - 0s 3ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n16/16 [==============================] - 0s 2ms/step - loss: 5.6479\n\nTesting for epoch 37 index 12:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n16/16 [==============================] - 0s 2ms/step - loss: 5.2714\n16/16 [==============================] - 0s 2ms/step - loss: 5.2717\n16/16 [==============================] - 0s 4ms/step - loss: 5.6632\n16/16 [==============================] - 0s 1ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n16/16 [==============================] - 0s 2ms/step - loss: 5.6643\n\nTesting for epoch 37 index 13:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0047\n16/16 [==============================] - 0s 3ms/step - loss: 5.2741\n16/16 [==============================] - 0s 3ms/step - loss: 5.2744\n16/16 [==============================] - 0s 2ms/step - loss: 5.6662\n16/16 [==============================] - 0s 4ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n16/16 [==============================] - 0s 4ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n16/16 [==============================] - 0s 7ms/step - loss: 5.6673\n16/16 [==============================] - 0s 2ms/step - loss: 5.6673\n\nTesting for epoch 37 index 14:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0050\n16/16 [==============================] - 0s 3ms/step - loss: 5.2619\n16/16 [==============================] - 0s 2ms/step - loss: 5.2622\n16/16 [==============================] - 0s 2ms/step - loss: 5.6577\n16/16 [==============================] - 0s 4ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n16/16 [==============================] - 0s 2ms/step - loss: 5.6589\n\nTesting for epoch 37 index 15:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0054\n16/16 [==============================] - 0s 2ms/step - loss: 5.2003\n16/16 [==============================] - 0s 2ms/step - loss: 5.2006\n16/16 [==============================] - 0s 2ms/step - loss: 5.6010\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n16/16 [==============================] - 0s 2ms/step - loss: 5.6021\n\nTesting for epoch 37 index 16:\n391/391 [==============================] - 1s 2ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0056\n16/16 [==============================] - 0s 3ms/step - loss: 5.2178\n16/16 [==============================] - 0s 2ms/step - loss: 5.2181\n16/16 [==============================] - 0s 4ms/step - loss: 5.6178\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 2ms/step - loss: 5.6190\n16/16 [==============================] - 0s 2ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n16/16 [==============================] - 0s 3ms/step - loss: 5.6190\n\nTesting for epoch 37 index 17:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0058\n16/16 [==============================] - 0s 2ms/step - loss: 5.2434\n16/16 [==============================] - 0s 2ms/step - loss: 5.2437\n16/16 [==============================] - 0s 2ms/step - loss: 5.6415\n16/16 [==============================] - 0s 1ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 2ms/step - loss: 5.6426\n16/16 [==============================] - 0s 5ms/step - loss: 5.6426\n\nTesting for epoch 37 index 18:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0055\n16/16 [==============================] - 0s 3ms/step - loss: 5.2580\n16/16 [==============================] - 0s 2ms/step - loss: 5.2583\n16/16 [==============================] - 0s 4ms/step - loss: 5.6514\n16/16 [==============================] - 0s 2ms/step - loss: 5.6525\n16/16 [==============================] - 0s 3ms/step - loss: 5.6525\n16/16 [==============================] - 0s 2ms/step - loss: 5.6525\n16/16 [==============================] - 0s 1ms/step - loss: 5.6525\n16/16 [==============================] - 0s 5ms/step - loss: 5.6525\n16/16 [==============================] - 0s 3ms/step - loss: 5.6525\n\nTesting for epoch 37 index 19:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 2ms/step - loss: 0.0057\n16/16 [==============================] - 0s 2ms/step - loss: 5.1768\n16/16 [==============================] - 0s 3ms/step - loss: 5.1771\n16/16 [==============================] - 0s 2ms/step - loss: 5.5801\n16/16 [==============================] - 0s 5ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 1ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n16/16 [==============================] - 0s 2ms/step - loss: 5.5813\n\nTesting for epoch 37 index 20:\n391/391 [==============================] - 1s 1ms/step\n16/16 [==============================] - 0s 3ms/step - loss: 0.0059\n16/16 [==============================] - 0s 1ms/step - loss: 5.2710\n16/16 [==============================] - 0s 3ms/step - loss: 5.2713\n16/16 [==============================] - 0s 4ms/step - loss: 5.6685\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n16/16 [==============================] - 0s 3ms/step - loss: 5.6697\n16/16 [==============================] - 0s 2ms/step - loss: 5.6697\n\nTesting for epoch 37 index 21:\n391/391 [==============================] - 0s 1ms/step\n16/16 [==============================] - 0s 4ms/step - loss: 0.0060\n16/16 [==============================] - 0s 2ms/step - loss: 5.2523\n16/16 [==============================] - 0s 1ms/step - loss: 5.2526\n16/16 [==============================] - 0s 2ms/step - loss: 5.6502\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n16/16 [==============================] - 0s 2ms/step - loss: 5.6513\n16/16 [==============================] - 0s 3ms/step - loss: 5.6513\n\nTesting for epoch 37 index 22:\n\n\n\noutlier_MO_GAAL_one = list(clf.labels_)\n\n\noutlier_MO_GAAL_one = list(map(lambda x: 1 if x==0  else -1,outlier_MO_GAAL_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n  \n\n12498 rows Ã— 19 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)\n\n\n_conf.conf(\"MO-GAAL (Liu et al., 2019)\")\n\n\nthirteen = twelve.append(_conf.tab)\n\n\n\nLSCP\n\ndetectors = [KNN(), LOF(), OCSVM()]\nclf = LSCP(detectors)\nclf.fit(_df[['Latitude','Longitude','Magnitude']])\n# _df['LSCP_clf'] = clf.labels_\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4461: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n  warnings.warn(stats.NearConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(msg))\n\n\nLSCP(contamination=0.1,\n   detector_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n  metric_params=None, n_jobs=1, n_neighbors=20, novelty=True, p=2), OCSVM(cache_size=200, coef0=0.0, contamination=0.1, degree=3, gamma='auto',\n   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n   verbose=False)],\n   local_max_features=1.0, local_region_size=30, n_bins=3,\n   random_state=RandomState(MT19937) at 0x7F44245B8240)\n\n\n\noutlier_LSCP_one = list(clf.labels_)\n\n\noutlier_LSCP_one = list(map(lambda x: 1 if x==0  else -1,outlier_LSCP_one))\n\n\npd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'}),\n          pd.DataFrame(outlier_LSCP_one).rename(columns={0:'LSCP'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL',\n                         'LSCP':'LSCP'})\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      0\n      0.663\n      -26.045\n      5.5\n      2010.0\n      5.514405\n      -0.014405\n      0.000207\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      1\n      -19.209\n      167.902\n      5.1\n      2010.0\n      5.114861\n      -0.014861\n      0.000221\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      2\n      -31.830\n      -178.135\n      5.0\n      2010.0\n      5.159778\n      -0.159778\n      0.025529\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      3\n      -19.984\n      168.353\n      5.0\n      2010.0\n      5.214340\n      -0.214340\n      0.045942\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      4\n      50.380\n      153.964\n      5.0\n      2010.0\n      5.099783\n      -0.099783\n      0.009957\n      1\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12493\n      -22.874\n      69.345\n      5.2\n      2010.0\n      5.039599\n      0.160401\n      0.025728\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      12494\n      42.360\n      -30.462\n      5.0\n      2010.0\n      5.104141\n      -0.104141\n      0.010845\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12495\n      40.726\n      51.925\n      5.0\n      2010.0\n      4.926934\n      0.073066\n      0.005339\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n    \n    \n      12496\n      30.646\n      83.791\n      5.2\n      2010.0\n      5.240853\n      -0.040853\n      0.001669\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n    \n    \n      12497\n      26.290\n      99.866\n      5.0\n      2010.0\n      4.983210\n      0.016790\n      0.000282\n      1\n      -1\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n    \n  \n\n12498 rows Ã— 20 columns\n\n\n\n\n_conf = Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)\n\n\n_conf.conf(\"LSCP (Zhao et al., 2019)\")\n\n\nfourteen_orbit = thirteen.append(_conf.tab)"
  },
  {
    "objectID": "posts/GODE/2023-06-22-comparison_earthquake.html#result",
    "href": "posts/GODE/2023-06-22-comparison_earthquake.html#result",
    "title": "Comparison Results on Real Data",
    "section": "Result",
    "text": "Result\n\n_df_rst = pd.concat([_df,pd.DataFrame(_df['Residual']**2).rename(columns={'Residual':'rst'}),pd.DataFrame(outlier_simul_one),\n          pd.DataFrame(lof_rst).rename(columns={0:'LOF'}),\n          pd.DataFrame(outlier_KNN_one).rename(columns={0:'KNN'}),\n          pd.DataFrame(outlier_OSVM_one).rename(columns={0:'OCSVM'}),\n          pd.DataFrame(outlier_MCD_one).rename(columns={0:'MCD'}),\n          pd.DataFrame(outlier_FeatureBagging_one).rename(columns={0:'Feature Bagging'}),\n          pd.DataFrame(outlier_ABOD_one).rename(columns={0:'ABOD'}),\n          pd.DataFrame(outlier_alibi_one).rename(columns={0:'IForest'}),\n          pd.DataFrame(outlier_HBOS_one).rename(columns={0:'HBOS'}),\n          pd.DataFrame(outlier_SOS_one).rename(columns={0:'SOS'}),\n          pd.DataFrame(outlier_SO_GAAL_one).rename(columns={0:'SO_GAAL'}),\n          pd.DataFrame(outlier_MO_GAAL_one).rename(columns={0:'MO_GAAL'}),\n          pd.DataFrame(outlier_LSCP_one).rename(columns={0:'LSCP'})],axis=1).\\\n          rename(columns={'Latitude':'Latitude',\n                          'Longitude':'Longitude',\n                          'Magnitude':'Magnitude',\n                          'Year':'Year',\n                          'MagnitudeHat':'MagnitudeHat',\n                          'Residual':'Residual',\n                          'rst':'Anomalious Score',\n                          0:'GODE',\n                          'LOF':'LOF',\n                         'KNN':'KNN',\n                         'OCSVM':'OCSVM',\n                         'MCD':'MCD',\n                         'Feature Bagging':'Feature Bagging',\n                         'ABOD':'ABOD',\n                         'IForest':'IForest',\n                         'HBOS':'HBOS',\n                         'SOS':'SOS',\n                         'SO_GAAL':'SO_GAAL',\n                         'MO_GAAL':'MO_GAAL',\n                         'LSCP':'LSCP'})\n\n\n_df_compa = _df_rst.copy()\n\n\ncmp = pd.concat([pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ncmp\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      2010-12-31T16:30:54.520Z\n      0.663\n      -26.045\n      5.5\n    \n    \n      1\n      2010-12-31T04:11:03.180Z\n      -19.209\n      167.902\n      5.1\n    \n    \n      2\n      2010-12-30T23:47:03.930Z\n      -31.830\n      -178.135\n      5.0\n    \n    \n      3\n      2010-12-30T21:22:30.350Z\n      -19.984\n      168.353\n      5.0\n    \n    \n      4\n      2010-12-30T19:56:36.380Z\n      50.380\n      153.964\n      5.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      24099\n      2010-01-01T14:31:10.130Z\n      -22.874\n      69.345\n      5.2\n    \n    \n      24100\n      2010-01-01T09:37:11.290Z\n      42.360\n      -30.462\n      5.0\n    \n    \n      24101\n      2010-01-01T02:34:56.050Z\n      40.726\n      51.925\n      5.0\n    \n    \n      24102\n      2010-01-01T02:22:23.820Z\n      30.646\n      83.791\n      5.2\n    \n    \n      24103\n      2010-01-01T02:08:21.900Z\n      26.290\n      99.866\n      5.0\n    \n  \n\n24104 rows Ã— 4 columns\n\n\n\n\npd.read_csv('outlier_CBLOF_one.csv')\n\n\n_df_compa.to_csv('earthquake_comparison.csv')\n\n\nHaiti\n\n_df_compa[_df_compa['Latitude']==18.443] # Haiti(lat=18.4430, lon=-72.5710)\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      2326\n      18.443\n      -72.571\n      7.0\n      2010.0\n      6.659386\n      0.340614\n      0.116018\n      -1\n      -1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      12429\n      18.443\n      -72.571\n      7.0\n      2010.0\n      6.386632\n      0.613368\n      0.376220\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==18.443]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      2326\n      2010-01-12T21:53:10.060Z\n      18.443\n      -72.571\n      7.0\n    \n    \n      24035\n      2010-01-12T21:53:10.060Z\n      18.443\n      -72.571\n      7.0\n    \n  \n\n\n\n\n\n\nIquique\n\n_df_compa[_df_compa['Latitude']==-32.6953] # Iquiqeu lat=-32.6953, lon=-71.4416\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      2997\n      -32.6953\n      -71.4416\n      6.4\n      2014.0\n      6.088353\n      0.311647\n      0.097124\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==-32.6953]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      14603\n      2014-08-23T22:32:23.320Z\n      -32.6953\n      -71.4416\n      6.4\n    \n  \n\n\n\n\n\n_df_compa[_df_compa['Latitude']==-20.5709] # Iquiqeu lat=-32.6953, lon=-71.4416\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      3723\n      -20.5709\n      -70.4931\n      7.7\n      2014.0\n      6.991148\n      0.708852\n      0.502471\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==-20.5709]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      15329\n      2014-04-03T02:43:13.110Z\n      -20.5709\n      -70.4931\n      7.7\n    \n  \n\n\n\n\n\n\nSichan\n\n_df_compa[_df_compa['Latitude']==30.3080] # sichan(lat=30.3080, lon=102.8880)\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      KNN\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      5137\n      30.308\n      102.888\n      6.6\n      2013.0\n      5.904218\n      0.695782\n      0.484113\n      -1\n      -1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n  \n\n\n\n\n\ncmp[cmp['Latitude']==30.3080]\n\n\n\n\n\n  \n    \n      \n      time\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      16743\n      2013-04-20T00:02:47.540Z\n      30.308\n      102.888\n      6.6\n    \n  \n\n\n\n\n\n_df_compa.sort_values('Anomalious Score',ascending=False).iloc[:50,:].reset_index()\n\n\n\n\n\n  \n    \n      \n      index\n      Latitude\n      Longitude\n      Magnitude\n      Year\n      MagnitudeHat\n      Residual\n      Anomalious Score\n      GODE\n      LOF\n      ...\n      OCSVM\n      MCD\n      Feature Bagging\n      ABOD\n      IForest\n      HBOS\n      SOS\n      SO_GAAL\n      MO_GAAL\n      LSCP\n    \n  \n  \n    \n      0\n      2064\n      -36.122000\n      -72.898000\n      8.8\n      2010.0\n      7.572545\n      1.227455\n      1.506646\n      -1\n      -1\n      ...\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      1\n      3752\n      -19.609700\n      -70.769100\n      8.2\n      2014.0\n      7.075499\n      1.124501\n      1.264504\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      2\n      12167\n      -36.122000\n      -72.898000\n      8.8\n      2010.0\n      7.742429\n      1.057571\n      1.118457\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      3\n      9660\n      36.281000\n      141.111000\n      7.9\n      2011.0\n      6.912847\n      0.987153\n      0.974470\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      4\n      6877\n      0.802000\n      92.463000\n      8.2\n      2012.0\n      7.353106\n      0.846894\n      0.717230\n      -1\n      1\n      ...\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      5\n      7938\n      -21.611000\n      -179.528000\n      7.3\n      2011.0\n      6.497713\n      0.802287\n      0.643665\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      6\n      10593\n      -3.487000\n      100.082000\n      7.8\n      2010.0\n      7.008107\n      0.791893\n      0.627095\n      -1\n      -1\n      ...\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      7\n      3835\n      -19.980700\n      -70.702200\n      6.7\n      2014.0\n      5.913563\n      0.786437\n      0.618483\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      8\n      3281\n      -29.977200\n      -177.724700\n      6.9\n      2014.0\n      6.129969\n      0.770031\n      0.592947\n      -1\n      1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      1\n    \n    \n      9\n      4997\n      -23.009000\n      -177.232000\n      7.4\n      2013.0\n      6.648946\n      0.751054\n      0.564082\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      10\n      11365\n      7.881000\n      91.936000\n      7.5\n      2010.0\n      6.759298\n      0.740702\n      0.548640\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      11\n      3723\n      -20.570900\n      -70.493100\n      7.7\n      2014.0\n      6.991148\n      0.708852\n      0.502471\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      12\n      490\n      -3.487000\n      100.082000\n      7.8\n      2010.0\n      7.092844\n      0.707156\n      0.500069\n      -1\n      -1\n      ...\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      13\n      11856\n      -34.290000\n      -71.891000\n      6.9\n      2010.0\n      6.197441\n      0.702559\n      0.493590\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      14\n      6443\n      -21.222000\n      -179.287000\n      5.6\n      2012.0\n      4.900729\n      0.699271\n      0.488980\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      15\n      9598\n      36.569000\n      141.486000\n      6.2\n      2011.0\n      5.502811\n      0.697189\n      0.486072\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      16\n      5137\n      30.308000\n      102.888000\n      6.6\n      2013.0\n      5.904218\n      0.695782\n      0.484113\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      17\n      7772\n      -28.993000\n      -176.238000\n      7.4\n      2011.0\n      6.711309\n      0.688691\n      0.474295\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      18\n      4881\n      10.701000\n      -42.594000\n      6.6\n      2013.0\n      5.915735\n      0.684265\n      0.468219\n      -1\n      -1\n      ...\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      1\n    \n    \n      19\n      4330\n      39.306700\n      142.095400\n      5.0\n      2013.0\n      5.682094\n      -0.682094\n      0.465252\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      20\n      7768\n      -55.261000\n      -28.106000\n      5.0\n      2011.0\n      5.680237\n      -0.680237\n      0.462723\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      21\n      6940\n      -35.200000\n      -72.217000\n      7.1\n      2012.0\n      6.422078\n      0.677922\n      0.459578\n      -1\n      1\n      ...\n      1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      22\n      4816\n      -60.857000\n      -25.070000\n      7.3\n      2013.0\n      6.626735\n      0.673265\n      0.453286\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      23\n      6963\n      16.493000\n      -98.231000\n      7.4\n      2012.0\n      6.727272\n      0.672728\n      0.452563\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      24\n      8207\n      36.942000\n      140.955000\n      6.3\n      2011.0\n      5.644833\n      0.655167\n      0.429243\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      25\n      2670\n      -23.393700\n      -179.852400\n      5.0\n      2014.0\n      5.647693\n      -0.647693\n      0.419507\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      26\n      9675\n      38.297000\n      142.373000\n      9.1\n      2011.0\n      8.452726\n      0.647274\n      0.418963\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      27\n      163\n      26.901000\n      143.698000\n      7.4\n      2010.0\n      6.758782\n      0.641218\n      0.411160\n      -1\n      1\n      ...\n      -1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      28\n      7365\n      -10.617000\n      165.160000\n      6.4\n      2012.0\n      5.760128\n      0.639872\n      0.409436\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      29\n      19\n      -19.661000\n      168.140000\n      6.4\n      2010.0\n      5.761124\n      0.638876\n      0.408163\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      30\n      7739\n      -17.941000\n      -179.531000\n      6.0\n      2011.0\n      5.361437\n      0.638563\n      0.407763\n      -1\n      -1\n      ...\n      1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      31\n      8787\n      -20.129000\n      168.257000\n      5.3\n      2011.0\n      4.674700\n      0.625300\n      0.391000\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      32\n      5447\n      -10.994000\n      165.741000\n      6.6\n      2013.0\n      5.975600\n      0.624400\n      0.389875\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      33\n      8094\n      -18.365000\n      168.143000\n      7.2\n      2011.0\n      6.578651\n      0.621349\n      0.386075\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      34\n      2699\n      -19.690300\n      -177.758700\n      7.1\n      2014.0\n      6.485400\n      0.614600\n      0.377733\n      -1\n      -1\n      ...\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      35\n      1751\n      -34.326000\n      -71.799000\n      7.0\n      2010.0\n      6.386349\n      0.613651\n      0.376567\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      36\n      12429\n      18.443000\n      -72.571000\n      7.0\n      2010.0\n      6.386632\n      0.613368\n      0.376220\n      -1\n      -1\n      ...\n      1\n      1\n      -1\n      -1\n      -1\n      -1\n      -1\n      1\n      -1\n      -1\n    \n    \n      37\n      6307\n      2.190000\n      126.837000\n      6.6\n      2012.0\n      5.993919\n      0.606081\n      0.367334\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      38\n      9366\n      40.082000\n      143.202000\n      5.7\n      2011.0\n      5.096812\n      0.603188\n      0.363836\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n    \n    \n      39\n      9867\n      -7.154000\n      155.184000\n      6.4\n      2011.0\n      5.798634\n      0.601366\n      0.361641\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      40\n      581\n      29.715000\n      69.587000\n      5.2\n      2010.0\n      5.794321\n      -0.594321\n      0.353217\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      41\n      1753\n      -34.290000\n      -71.891000\n      6.9\n      2010.0\n      6.310787\n      0.589213\n      0.347172\n      -1\n      1\n      ...\n      1\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      42\n      9050\n      -16.541000\n      -177.517000\n      6.3\n      2011.0\n      5.717719\n      0.582281\n      0.339052\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      43\n      11823\n      -37.551000\n      -73.465000\n      5.8\n      2010.0\n      5.219236\n      0.580764\n      0.337287\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      44\n      11689\n      32.286167\n      -115.295333\n      7.2\n      2010.0\n      6.620076\n      0.579924\n      0.336312\n      -1\n      -1\n      ...\n      1\n      -1\n      1\n      -1\n      -1\n      -1\n      -1\n      1\n      1\n      -1\n    \n    \n      45\n      1439\n      -23.067000\n      169.426000\n      5.0\n      2010.0\n      5.579354\n      -0.579354\n      0.335651\n      -1\n      1\n      ...\n      -1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      46\n      8456\n      36.261000\n      137.679000\n      5.0\n      2011.0\n      5.576525\n      -0.576525\n      0.332381\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      47\n      3164\n      37.005200\n      142.452500\n      6.5\n      2014.0\n      5.923529\n      0.576471\n      0.332319\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      48\n      6349\n      35.661000\n      82.518000\n      6.2\n      2012.0\n      5.623699\n      0.576301\n      0.332123\n      -1\n      1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n    \n      49\n      11803\n      -35.802000\n      -73.158000\n      6.2\n      2010.0\n      5.624964\n      0.575036\n      0.330667\n      -1\n      -1\n      ...\n      1\n      1\n      1\n      1\n      -1\n      -1\n      -1\n      1\n      1\n      1\n    \n  \n\n50 rows Ã— 21 columns"
  },
  {
    "objectID": "posts/GODE/2022-12-27-DFT_study.html",
    "href": "posts/GODE/2022-12-27-DFT_study.html",
    "title": "Discrete Fourier Transform",
    "section": "",
    "text": "DFT\nhttps://miruetoto.quarto.pub/yechan/posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#fnref1\nhttps://miruetoto.github.io/yechan/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88/2019/11/24/(%EB%85%B8%ED%8A%B8)-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%EC%B6%94%EB%A1%A0-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88.html"
  },
  {
    "objectID": "posts/GODE/2022-12-27-DFT_study.html#import",
    "href": "posts/GODE/2022-12-27-DFT_study.html#import",
    "title": "Discrete Fourier Transform",
    "section": "import",
    "text": "import\n\nimport numpy as np\n\n\nForward operator A\n\nA = np.array([[0, 0, 0, 0, 1],\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 0, 1, 0]])\nA\n\narray([[0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0]])\n\n\n\nnp.transpose(A)@A\n\narray([[1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 1]])\n\n\n\nnote: A is orthogonal matrix\n\n\ns = np.array([[1],[22],[333],[4444],[55555]])\ns\n\narray([[    1],\n       [   22],\n       [  333],\n       [ 4444],\n       [55555]])\n\n\n\nA@s\n\narray([[55555],\n       [    1],\n       [   22],\n       [  333],\n       [ 4444]])\n\n\n\nA@A@s\n\narray([[ 4444],\n       [55555],\n       [    1],\n       [   22],\n       [  333]])\n\n\n\nA@A@A@s\n\narray([[  333],\n       [ 4444],\n       [55555],\n       [    1],\n       [   22]])\n\n\n\nnote : thus A is a forward operator,A* is a backward operator.\n\n\n\nDFT\n\\(A = DFT^* \\Lambda DFT\\)\n\nÎ», Ïˆ = np.linalg.eig(A)\nÎ», Ïˆ\n\n(array([-0.80901699+0.58778525j, -0.80901699-0.58778525j,\n         0.30901699+0.95105652j,  0.30901699-0.95105652j,\n         1.        +0.j        ]),\n array([[-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n         -0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.4472136+0.j        ],\n        [ 0.4472136+0.j        ,  0.4472136-0.j        ,\n         -0.3618034+0.26286556j, -0.3618034-0.26286556j,\n          0.4472136+0.j        ],\n        [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.1381966+0.4253254j ,  0.1381966-0.4253254j ,\n          0.4472136+0.j        ],\n        [ 0.1381966+0.4253254j ,  0.1381966-0.4253254j ,\n          0.4472136+0.j        ,  0.4472136-0.j        ,\n          0.4472136+0.j        ],\n        [ 0.1381966-0.4253254j ,  0.1381966+0.4253254j ,\n          0.1381966-0.4253254j ,  0.1381966+0.4253254j ,\n          0.4472136+0.j        ]]))\n\n\n\nÎ».shape, Ïˆ.shape\n\n((5,), (5, 5))\n\n\n\nA \n\narray([[0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0]])\n\n\n\n(Ïˆ @ np.diag(Î») @ Ïˆ.transpose()).round(2)\n\narray([[-0.  +0.j,  0.45+0.j,  0.28+0.j,  0.72+0.j, -0.45+0.j],\n       [ 0.45+0.j,  0.28+0.j,  0.72+0.j, -0.45+0.j, -0.  +0.j],\n       [ 0.28+0.j,  0.72+0.j, -0.45+0.j,  0.  +0.j,  0.45+0.j],\n       [ 0.72+0.j, -0.45+0.j,  0.  +0.j,  0.45+0.j,  0.28+0.j],\n       [-0.45+0.j, -0.  +0.j,  0.45+0.j,  0.28+0.j,  0.72+0.j]])\n\n\n?\ndefine \\(\\psi^* = DFT\\)\n\nDFT = np.transpose(Ïˆ)\nDFT\n\narray([[-0.3618034+0.26286556j,  0.4472136+0.j        ,\n        -0.3618034-0.26286556j,  0.1381966+0.4253254j ,\n         0.1381966-0.4253254j ],\n       [-0.3618034-0.26286556j,  0.4472136-0.j        ,\n        -0.3618034+0.26286556j,  0.1381966-0.4253254j ,\n         0.1381966+0.4253254j ],\n       [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n         0.1381966+0.4253254j ,  0.4472136+0.j        ,\n         0.1381966-0.4253254j ],\n       [-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n         0.1381966-0.4253254j ,  0.4472136-0.j        ,\n         0.1381966+0.4253254j ],\n       [ 0.4472136+0.j        ,  0.4472136+0.j        ,\n         0.4472136+0.j        ,  0.4472136+0.j        ,\n         0.4472136+0.j        ]])\n\n\n\nÎ»[3,]\n\n(0.30901699437494734-0.9510565162951535j)\n\n\n\na=np.array([1,2,3,4])\nnp.diag(np.diag(a))\n\narray([1, 2, 3, 4])\n\n\n\nÎ»\n\narray([-0.80901699+0.58778525j, -0.80901699-0.58778525j,\n        0.30901699+0.95105652j,  0.30901699-0.95105652j,\n        1.        +0.j        ])\n\n\n\n(np.matrix(Ïˆ)@np.matrix(np.diag(Î»))@np.matrix(Ïˆ).H).round(3)\n\nmatrix([[-0.+0.j,  0.+0.j, -0.+0.j,  0.+0.j,  1.+0.j],\n        [ 1.+0.j, -0.+0.j,  0.+0.j, -0.+0.j, -0.+0.j],\n        [-0.+0.j,  1.+0.j, -0.+0.j,  0.+0.j,  0.+0.j],\n        [ 0.+0.j, -0.+0.j,  1.+0.j,  0.+0.j, -0.+0.j],\n        [-0.+0.j, -0.+0.j,  0.+0.j,  1.+0.j, -0.+0.j]])\n\n\n\nnp.matrix(Ïˆ).H\n\nmatrix([[-0.3618034-0.26286556j,  0.4472136-0.j        ,\n         -0.3618034+0.26286556j,  0.1381966-0.4253254j ,\n          0.1381966+0.4253254j ],\n        [-0.3618034+0.26286556j,  0.4472136+0.j        ,\n         -0.3618034-0.26286556j,  0.1381966+0.4253254j ,\n          0.1381966-0.4253254j ],\n        [-0.3618034+0.26286556j, -0.3618034-0.26286556j,\n          0.1381966-0.4253254j ,  0.4472136-0.j        ,\n          0.1381966+0.4253254j ],\n        [-0.3618034-0.26286556j, -0.3618034+0.26286556j,\n          0.1381966+0.4253254j ,  0.4472136+0.j        ,\n          0.1381966-0.4253254j ],\n        [ 0.4472136-0.j        ,  0.4472136-0.j        ,\n          0.4472136-0.j        ,  0.4472136-0.j        ,\n          0.4472136-0.j        ]])\n\n\n\n\nSpectral components and Frequencies\n\\[\\{ 1,\\psi_1, \\psi_2, \\psi_3,\\dots, \\psi_{N-1} \\}\\]\nThese vectors are called spectral components.\nIn Physics and in operator theory, these eigenvalues are the frequencies of the signal.\nEigenvalues of \\(A\\)"
  },
  {
    "objectID": "posts/GODE/Untitled.html",
    "href": "posts/GODE/Untitled.html",
    "title": "Seoyeon's Blog for study",
    "section": "",
    "text": "import numpy as np\n\n\na=10\nb=20\nn=200\n\n\narr1 = np.array([a+(b-a)/(n-1) * (i-1) for i in range(1,n+1)])\n\n\\[a+\\frac{(b-a)i}{n-1}\\] for \\(i=1,2,3,\\dots, n\\)\n\narr2 = np.linspace(a,b,n)\n\n\narr1[:5]\n\narray([10.        , 10.05025126, 10.10050251, 10.15075377, 10.20100503])\n\n\n\narr2[:5]\n\narray([10.        , 10.05025126, 10.10050251, 10.15075377, 10.20100503])"
  },
  {
    "objectID": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html",
    "href": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html",
    "title": "Linear Graph code for Paper",
    "section": "",
    "text": "None\n%%R set.seed(1) epsilon = rnorm(1000) signal = sample(c(runif(25,-7,-2.5), runif(25,2.5,7), rep(0,950))) index_of_trueoutlier = which(signal!=0) index_of_trueoutlier_bool = signal!=0\nx=signal+epsilon plot(1:1000,x) points(index_of_trueoutlier,x[index_of_trueoutlier],col=2,cex=4)"
  },
  {
    "objectID": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html#linear1",
    "href": "posts/GODE/2023-06-27-Linear_graph_code_for_paper.html#linear1",
    "title": "Linear Graph code for Paper",
    "section": "Linear(1)",
    "text": "Linear(1)\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x\n_y = _y1 + x # x is epsilon\n\n\ndf1=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\nw=np.zeros((1000,1000))\n\n\nfor i in range(1000):\n    for j in range(1000):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df\n        self.y = df.y.to_numpy()\n        self.y1 = df.y1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.n = len(self.y)\n        self.W = w\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)      \n    def fit(self,sd=5,ref=20,ymin=-5,ymax=20,cuts=0,cutf=995): # fit with ebayesthresh\n        self._eigen()\n        self.ybar = self.Psi.T @ self.y # fbar := graph fourier transform of f\n        self.power = self.ybar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.ybar**2),sd=sd))\n        self.ybar_threshed = np.where(self.power_threshed>0,self.ybar,0)\n        self.yhat = self.Psi@self.ybar_threshed\n        self.df = self.df.assign(yHat = self.yhat)\n        self.df = self.df.assign(Residual = self.df.y- self.df.yHat)\n        self.differ=(np.abs(self.y-self.yhat)-np.min(np.abs(self.y-self.yhat)))/(np.max(np.abs(self.y-self.yhat))-np.min(np.abs(self.y-self.yhat))) #color í‘œí˜„ì€ ìœ„í•¸ í‘œì¤€í™”\n        self.df = self.df.assign(differ = self.differ)\n        \n        fig,ax = plt.subplots(figsize=(10,10))\n        ax.scatter(self.x,self.y,color='gray',s=50,alpha=0.7)\n        ax.scatter(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],color='red',s=50)\n        ax.plot(self.x[cuts:cutf],self.yhat[cuts:cutf], '--k',lw=3)\n        ax.scatter(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],color='red',s=550,facecolors='none', edgecolors='r')\n        fig.tight_layout()\n        fig.savefig('fig1.eps',format='eps')\n\n\n_simul = SIMUL(df1)\n\n\n_simul.fit(sd=20,ref=9.8)\n\nThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n\n\n\n\n\n\noutlier_simul_one = (_simul.df['Residual']**2).tolist()\n\n\noutlier_simul_one = list(map(lambda x: -1 if x > 9.8 else 1,outlier_simul_one))\n\n\ntab_linear = pd.DataFrame(columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n\n\n_signal = list(map(lambda x: -1 if x!=0 else 1,signal))\n\n\n_conf = Conf_matrx(_signal,outlier_simul_one,tab_linear)\n\n\nfrom sklearn.metrics import confusion_matrix\n\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\n\n_conf.conf(\"GODE\")\n\n\n\n\nAccuracy: 0.998\nPrecision: 0.999\nRecall: 0.999\nF1 Score: 0.999\n\n\n\n\n\n\n\n\n\n\n\n## Linear(2)\n\n\n_x = np.linspace(0,2,1000)\n_y1 = 5*_x**2\n_y = _y1 + x # x is epsilon\n\n\ndf2=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul2 = SIMUL(df2)\n\n\n_simul2.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\n\n## COS\n\n\n_x = np.linspace(0,2,1000)\n_y1 = -2+ 3*np.cos(_x) + 1*np.cos(2*_x) + 5*np.cos(5*_x)\n_y = _y1 + x\n\n\ndf4=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul4 = SIMUL(df4)\n\n\n_simul4.fit(sd=20,ref=20,ymin=-10,ymax=15)\n\n\n## SIN\n\n\n_x = np.linspace(0,2,1000)\n_y1 =  3*np.sin(_x) + 1*np.sin(_x**2) + 5*np.sin(5*_x) \n_y = _y1 + x # x is epsilon\n\n\ndf5=pd.DataFrame({'x':_x, 'y':_y, 'y1':_y1})\n\n\n_simul5 = SIMUL(df5)\n\n\n_simul5.fit(ref=15,ymin=-10,ymax=15,cuts=5)\n\n\n## 1D manifold\n\n\nnp.random.seed(777)\npi=np.pi\nn=1000\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + x\n\n\ndf = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f, 'f1' : f1})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.f1 = df.f1.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D < kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5,ref=60): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n        self.dif=(np.abs(self.f-self.fhat)-np.min(np.abs(self.f-self.fhat)))/(np.max(np.abs(self.f-self.fhat))-np.min(np.abs(self.f-self.fhat)))\n        self.df = self.df.assign(dif = self.dif)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n#         fig = plt.figure(figsize=(10,10))\n        # ax = fig.add_subplot(1,1,1, projection='3d')\n        #\n        fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,15),subplot_kw={\"projection\":\"3d\"})\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax1.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red')\n        ax1.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax1.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=60)\n        \n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax2.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax2.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax2.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax2.view_init(elev=30., azim=40)\n        \n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.f,zdir='z',s=50,marker='.',color='gray')\n        ax3.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.f[index_of_trueoutlier_bool],zdir='z',s=50,marker='.',color='red') \n        ax3.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['f'],edgecolors='red',zdir='z',s=50,facecolors='none')\n        ax3.plot3D(self.x,self.y,self.f1,'--k',lw=3)\n        ax3.view_init(elev=30., azim=10)\n        \n        fig.savefig('fig2.eps',format='eps')\n\n\n_simul3d = SIMUL(df)\n\n\n_simul3d.get_distance()\n\n\n_simul3d.get_weightmatrix(theta=(_simul3d.D[_simul3d.D>0].mean()),kappa=2500) \n\n\n(_simul3d.D[_simul3d.D>0].mean())\n\n\n%%capture --no-display\n_simul3d.fit(sd=15,ref=20)\n\n\n## Bunny\n\n\nG = graphs.Bunny()\nn = G.N\n\n\ng = filters.Heat(G, tau=75) # ê¼¬ë¦¬ë¶€ë¶„ì˜ ë¹¨ê°„ì‹ í˜¸ë¥¼ í¼ì§€ê²Œí•˜ëŠ” ì •ë„\n\n\nnormal = np.random.randn(n)\nunif = np.concatenate([np.random.uniform(low=3,high=7,size=60), np.random.uniform(low=-7,high=-3,size=60),np.zeros(n-120)]); np.random.shuffle(unif)\nnoise = normal + unif\n\n\nindex_of_trueoutlier_bool = (unif!=0)\n\n\nf = np.zeros(n)\nf[1000] = -3234\nf = g.filter(f, method='chebyshev') \n\n\nW = G.W.toarray()\nx = G.coords[:,0]\ny = G.coords[:,1]\nz = -G.coords[:,2]\n\n\ndf = pd.DataFrame({'x' : x, 'y' : y, 'z' : z, 'f' : f, 'noise' : noise})\n\n\nclass SIMUL:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.z = df.z.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.noise = df.noise.to_numpy()\n        self.fnoise = self.f + self.noise\n        self.W = W\n        self.n = len(self.f)\n        self.theta= None\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=2.5,ref=6): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.fnoise # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fnoise = self.fnoise)\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f + self.df.noise - self.df.fHat)\n        self.bottom = np.zeros_like(self.f)\n        self.width=0.05\n        self.depth=0.05\n        \n        fig = plt.figure(figsize=(30,12),dpi=400)\n        ax1 = fig.add_subplot(251, projection='3d')\n        ax1.grid(False)\n        ax1.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax1.view_init(elev=60., azim=-90)\n\n        ax2= fig.add_subplot(252, projection='3d')\n        ax2.grid(False)\n        ax2.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax2.view_init(elev=60., azim=-90)\n\n        ax3= fig.add_subplot(253, projection='3d')\n        ax3.grid(False)\n        ax3.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax3.view_init(elev=60., azim=-90)\n        \n        ax4= fig.add_subplot(254, projection='3d')\n        ax4.grid(False)\n        ax4.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax4.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax4.view_init(elev=60., azim=-90)\n\n        ax5= fig.add_subplot(255, projection='3d')\n        ax5.grid(False)\n        ax5.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax5.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax5.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax5.view_init(elev=60., azim=-90)\n        \n        ax6 = fig.add_subplot(256, projection='3d')\n        ax6.grid(False)\n        ax6.scatter3D(self.x,self.y,self.z,c='gray',zdir='z',alpha=0.5,marker='.')\n        ax6.view_init(elev=-60., azim=-90)\n\n        ax7= fig.add_subplot(257, projection='3d')\n        ax7.grid(False)\n        ax7.scatter3D(self.x,self.y,self.z,c=self.f,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax7.view_init(elev=-60., azim=-90)\n\n        ax8= fig.add_subplot(258, projection='3d')\n        ax8.grid(False)\n        ax8.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',alpha=0.5,vmin=-12,vmax=10)\n        ax8.view_init(elev=-60., azim=-90)\n        \n        ax9= fig.add_subplot(259, projection='3d')\n        ax9.grid(False)\n        ax9.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax9.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax9.view_init(elev=-60., azim=-90)\n\n        ax10= fig.add_subplot(2,5,10, projection='3d')\n        ax10.grid(False)\n        ax10.scatter3D(self.x,self.y,self.z,c=self.fnoise,cmap='hsv',zdir='z',marker='.',vmin=-12,vmax=10,s=1)\n        ax10.scatter3D(self.x[index_of_trueoutlier_bool],self.y[index_of_trueoutlier_bool],self.z[index_of_trueoutlier_bool],c=self.fnoise[index_of_trueoutlier_bool],cmap='hsv',zdir='z',marker='.',s=50)\n        ax10.scatter3D(self.df.query('Residual**2>@ref')['x'],self.df.query('Residual**2>@ref')['y'],self.df.query('Residual**2>@ref')['z'],zdir='z',s=550,marker='.',edgecolors='red',facecolors='none')\n        ax10.view_init(elev=-60., azim=-90)        \n        fig.savefig('fig_bunny.eps',format='eps')\n\n\n_simul = SIMUL(df)\n\n\nmax(_simul.f),max(_simul.fnoise)\n\n\nmin(_simul.f),min(_simul.fnoise)\n\n\n%%capture --no-display\n_simul.fit(sd=20,ref=10)\n\n\n## Earthquake\n\n\ndf= pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\n\n\ndf_global= pd.concat([pd.read_csv('00_05.csv'),pd.read_csv('05_10.csv'),pd.read_csv('10_15.csv'),pd.read_csv('15_20.csv')]).iloc[:,[0,1,2,4]].rename(columns={'latitude':'Latitude','longitude':'Longitude','mag':'Magnitude'}).reset_index().iloc[:,1:]\n\n\ndf_global = df_global.assign(Year=list(map(lambda x: x.split('-')[0], df_global.time))).iloc[:,1:]\n\n\ndf_global.Year = df_global.Year.astype(np.float64)\n\n\nclass MooYaHo:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.Magnitude.to_numpy()\n        self.year = df.Year.to_numpy()\n        self.lat = df.Latitude.to_numpy()\n        self.long = df.Longitude.to_numpy()\n        self.n = len(self.f)\n        \n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.lat, self.long],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n): \n                self.D[i,j]=haversine(locations[i],locations[j])\n        self.D = self.D+self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D<kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)        \n    def fit(self,m):\n        self._eigen()\n        self.fhat = self.Psi[:,0:m]@self.Psi[:,0:m].T@self.f\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        plt.plot(self.f,'.')\n        plt.plot(self.fhat,'x')\n\n\nclass MooYaHo2(MooYaHo): # ebayesthresh ê¸°ëŠ¥ì¶”ê°€\n    def fit2(self,ref=0.5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.fbar**2)))\n        self.fbar_threshed = np.where(self.power_threshed>0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(MagnitudeHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.Magnitude- self.df.MagnitudeHat)\n        self.con = np.where(self.df.Residual>0.7,1,0)\n\n\nclass eachlocation(MooYaHo2):\n    def haiti(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize = 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=18.4430, lon=-72.5710), \n                        zoom= adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-3,3])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.4\n                    )\n                ))\n        return fig \n    def lquique(self,MagThresh=7,ResThresh=1,adjzoom=5, adjmarkersize= 40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=-32.6953, lon=-71.4416), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.8,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n    def sichuan(self,MagThresh=7,ResThresh=1,adjzoom=5,adjmarkersize=40):\n        fig = px.density_mapbox(self.df, \n                        lat='Latitude', \n                        lon='Longitude', \n                        z='Magnitude', \n                        radius=15,\n                        center=dict(lat=30.3080, lon=102.8880), \n                        zoom=adjzoom,\n                        height=900,\n                        opacity = 0.6,\n                        mapbox_style=\"stamen-terrain\",\n                        range_color=[-7,7])\n        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n        fig.add_scattermapbox(lat = self.df.query('Magnitude > @MagThresh')['Latitude'],\n                      lon = self.df.query('Magnitude > @MagThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @MagThresh')['Magnitude'],\n                      marker_size= 5,\n                      marker_color= 'blue',\n                      opacity = 0.1\n                      )\n        fig.add_scattermapbox(lat = self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                      lon = self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                      text = self.df.query('Magnitude > @ResThresh')['Magnitude'],\n                      marker_size= adjmarkersize,\n                      marker_color= 'red',\n                      opacity = 0.8\n                      )\n        fig.add_trace(go.Scattermapbox(\n                    lat=self.df.query('Residual**2 > @ResThresh')['Latitude'],\n                    lon=self.df.query('Residual**2 > @ResThresh')['Longitude'],\n                    mode='markers',\n                    marker=go.scattermapbox.Marker(\n                        size=20,\n                        color='rgb(255, 255, 255)',\n                        opacity=0.8\n                    )\n                ))\n        return fig \n\n\neach_location=eachlocation(df_global.query(\"2010 <= Year < 2015\"))\n\n\n`-` get distance \n\n\neach_location.get_distance()\n\n\neach_location.D[each_location.D>0].mean()\n\n\nplt.hist(each_location.D[each_location.D>0])\n\n\n`-` weight matrix\n\n\neach_location.get_weightmatrix(theta=(8810.865423093777),kappa=2500) \n\n\n`-` fit\n\n\neach_location.fit2()\n\n\neach_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig = each_location.haiti(MagThresh=6.9,ResThresh=0.5,adjzoom=5,adjmarkersize=40)\nfig.write_image('fig_haiti.png',scale=3)\n\n\neach_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.lquique(MagThresh=6.4,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_lquique.svg',scale=3)\n\n\neach_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=40)\n# fig = each_location.sichuan(MagThresh=6.5,ResThresh=0.4,adjzoom=5,adjmarkersize=20)\n# fig.write_image('fig_sichuan.svg',scale=3)"
  },
  {
    "objectID": "posts/RESEARCHES/index.html",
    "href": "posts/RESEARCHES/index.html",
    "title": "RESEARCHES",
    "section": "",
    "text": "About RESEARCHES"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html",
    "title": "Stock on Graph",
    "section": "",
    "text": "import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\nimport plotly.graph_objects as go\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#korea",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#korea",
    "title": "Stock on Graph",
    "section": "Korea",
    "text": "Korea\n\ndf_korea = pd.read_csv('./dataset/korea_kospi.csv')\n\n\ndf_korea = pd.concat([df_korea,pd.DataFrame({'Country': \"Korea\",\n                                             'Value':(df_korea['Close'] - df_korea['Close'].mean())/df_korea['Close'].std()})],axis=1)\n\n\ndf_korea_add = df_korea.assign(Year = list(map(lambda x: x.split('-')[0],df_korea['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_korea['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_korea['Date'])))\n\n\ndf_korea_add.Year = df_korea_add.Year.astype(np.float64)\ndf_korea_add.Mon = df_korea_add.Mon.astype(np.float64)\ndf_korea_add.Day = df_korea_add.Day.astype(np.float64)\n\n\ndf_korea_covid = df_korea_add.query(\"Year>=2020 and Year <= 2022\");df_korea_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      364\n      2020-01-02\n      2201.209961\n      2202.320068\n      2171.840088\n      2175.169922\n      2175.169922\n      494700\n      Korea\n      -0.719054\n      2020.0\n      1.0\n      2.0\n    \n    \n      365\n      2020-01-03\n      2192.580078\n      2203.379883\n      2165.389893\n      2176.459961\n      2176.459961\n      631600\n      Korea\n      -0.715806\n      2020.0\n      1.0\n      3.0\n    \n    \n      366\n      2020-01-06\n      2154.969971\n      2164.419922\n      2149.949951\n      2155.070068\n      2155.070068\n      592700\n      Korea\n      -0.769651\n      2020.0\n      1.0\n      6.0\n    \n    \n      367\n      2020-01-07\n      2166.600098\n      2181.620117\n      2164.270020\n      2175.540039\n      2175.540039\n      568200\n      Korea\n      -0.718122\n      2020.0\n      1.0\n      7.0\n    \n    \n      368\n      2020-01-08\n      2156.270020\n      2162.320068\n      2137.719971\n      2151.310059\n      2151.310059\n      913800\n      Korea\n      -0.779116\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1099\n      2022-12-23\n      2325.860107\n      2333.080078\n      2311.899902\n      2313.689941\n      2313.689941\n      367000\n      Korea\n      -0.370356\n      2022.0\n      12.0\n      23.0\n    \n    \n      1100\n      2022-12-26\n      2312.540039\n      2321.919922\n      2304.199951\n      2317.139893\n      2317.139893\n      427600\n      Korea\n      -0.361672\n      2022.0\n      12.0\n      26.0\n    \n    \n      1101\n      2022-12-27\n      2327.520020\n      2335.989990\n      2321.479980\n      2332.790039\n      2332.790039\n      448300\n      Korea\n      -0.322276\n      2022.0\n      12.0\n      27.0\n    \n    \n      1102\n      2022-12-28\n      2296.449951\n      2296.449951\n      2276.899902\n      2280.449951\n      2280.449951\n      405700\n      Korea\n      -0.454032\n      2022.0\n      12.0\n      28.0\n    \n    \n      1103\n      2022-12-29\n      2265.729980\n      2272.669922\n      2236.379883\n      2236.399902\n      2236.399902\n      361000\n      Korea\n      -0.564919\n      2022.0\n      12.0\n      29.0\n    \n  \n\n740 rows Ã— 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('Korea (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_korea_covid['Date'], df_korea_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#us",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#us",
    "title": "Stock on Graph",
    "section": "US",
    "text": "US\n\ndf_us = pd.read_csv('./dataset/us_nasdaq.csv')\n\n\ndf_us = pd.concat([df_us,pd.DataFrame({'Country': 'United States of America',\n                                             'Value':(df_us['Close'] - df_us['Close'].mean())/df_us['Close'].std()})],axis=1)\n\n\ndf_us_add = df_us.assign(Year = list(map(lambda x: x.split('-')[0],df_us['Date'])),\\\n                            Mon = list(map(lambda x: x.split('-')[1],df_us['Date'])),\\\n                            Day = list(map(lambda x: x.split('-')[2],df_us['Date'])))\n\n\ndf_us_add.Year = df_us_add.Year.astype(np.float64)\ndf_us_add.Mon = df_us_add.Mon.astype(np.float64)\ndf_us_add.Day = df_us_add.Day.astype(np.float64)\n\n\ndf_us_covid = df_us_add.query(\"Year>=2020 and Year <=2022\");df_us_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      374\n      2020-01-02\n      9039.459961\n      9093.429688\n      9010.889648\n      9092.190430\n      9092.190430\n      2862700000\n      United States of America\n      -0.695392\n      2020.0\n      1.0\n      2.0\n    \n    \n      375\n      2020-01-03\n      8976.429688\n      9065.759766\n      8976.429688\n      9020.769531\n      9020.769531\n      2586520000\n      United States of America\n      -0.722486\n      2020.0\n      1.0\n      3.0\n    \n    \n      376\n      2020-01-06\n      8943.500000\n      9072.410156\n      8943.500000\n      9071.469727\n      9071.469727\n      2810450000\n      United States of America\n      -0.703253\n      2020.0\n      1.0\n      6.0\n    \n    \n      377\n      2020-01-07\n      9076.639648\n      9091.929688\n      9042.549805\n      9068.580078\n      9068.580078\n      2381740000\n      United States of America\n      -0.704349\n      2020.0\n      1.0\n      7.0\n    \n    \n      378\n      2020-01-08\n      9068.030273\n      9168.889648\n      9059.379883\n      9129.240234\n      9129.240234\n      2472620000\n      United States of America\n      -0.681336\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1125\n      2022-12-23\n      10437.750000\n      10514.759766\n      10361.820313\n      10497.860352\n      10497.860352\n      3544680000\n      United States of America\n      -0.162131\n      2022.0\n      12.0\n      23.0\n    \n    \n      1126\n      2022-12-27\n      10462.190430\n      10472.320313\n      10340.730469\n      10353.230469\n      10353.230469\n      3827290000\n      United States of America\n      -0.216999\n      2022.0\n      12.0\n      27.0\n    \n    \n      1127\n      2022-12-28\n      10339.200195\n      10414.820313\n      10207.469727\n      10213.290039\n      10213.290039\n      3842970000\n      United States of America\n      -0.270087\n      2022.0\n      12.0\n      28.0\n    \n    \n      1128\n      2022-12-29\n      10321.459961\n      10502.080078\n      10301.059570\n      10478.089844\n      10478.089844\n      4154100000\n      United States of America\n      -0.169631\n      2022.0\n      12.0\n      29.0\n    \n    \n      1129\n      2022-12-30\n      10368.370117\n      10468.309570\n      10324.700195\n      10466.480469\n      10466.480469\n      3959030000\n      United States of America\n      -0.174036\n      2022.0\n      12.0\n      30.0\n    \n  \n\n756 rows Ã— 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('US (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_us_covid['Date'], df_us_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#china",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#china",
    "title": "Stock on Graph",
    "section": "China",
    "text": "China\n\ndf_china = pd.read_csv('./dataset/china_ssec.csv')\n\n\ndf_china = pd.concat([df_china,pd.DataFrame({'Country': 'China',\n                                             'Value':(df_china['Close'] - df_china['Close'].mean())/df_china['Close'].std()})],axis=1)\n\n\ndf_china_add = df_china.assign(Year = list(map(lambda x: x.split('-')[0],df_china['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_china['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_china['Date'])))\n\n\ndf_china_add.Year = df_china_add.Year.astype(np.float64)\ndf_china_add.Mon = df_china_add.Mon.astype(np.float64)\ndf_china_add.Day = df_china_add.Day.astype(np.float64)\n\n\ndf_china_covid = df_china_add.query(\"Year>=2020 and Year <=2022\");df_china_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      361\n      2020-01-02\n      3066.335938\n      3098.100098\n      3066.335938\n      3085.197998\n      3085.197998\n      292500\n      China\n      -0.244680\n      2020.0\n      1.0\n      2.0\n    \n    \n      362\n      2020-01-03\n      3089.021973\n      3093.819092\n      3074.518066\n      3083.785889\n      3083.785889\n      261500\n      China\n      -0.249433\n      2020.0\n      1.0\n      3.0\n    \n    \n      363\n      2020-01-06\n      3070.908936\n      3107.202881\n      3065.309082\n      3083.407959\n      3083.407959\n      312600\n      China\n      -0.250705\n      2020.0\n      1.0\n      6.0\n    \n    \n      364\n      2020-01-07\n      3085.488037\n      3105.450928\n      3084.329102\n      3104.802002\n      3104.802002\n      276600\n      China\n      -0.178700\n      2020.0\n      1.0\n      7.0\n    \n    \n      365\n      2020-01-08\n      3094.239014\n      3094.239014\n      3059.131104\n      3066.893066\n      3066.893066\n      297900\n      China\n      -0.306289\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1084\n      2022-12-26\n      3048.196045\n      3071.835938\n      3047.349121\n      3065.562988\n      3065.562988\n      206500\n      China\n      -0.310766\n      2022.0\n      12.0\n      26.0\n    \n    \n      1085\n      2022-12-27\n      3077.750000\n      3098.080078\n      3074.310059\n      3095.570068\n      3095.570068\n      222200\n      China\n      -0.209771\n      2022.0\n      12.0\n      27.0\n    \n    \n      1086\n      2022-12-28\n      3088.620117\n      3098.649902\n      3079.429932\n      3087.399902\n      3087.399902\n      224600\n      China\n      -0.237270\n      2022.0\n      12.0\n      28.0\n    \n    \n      1087\n      2022-12-29\n      3076.729980\n      3086.000000\n      3064.459961\n      3073.699951\n      3073.699951\n      215600\n      China\n      -0.283379\n      2022.0\n      12.0\n      29.0\n    \n    \n      1088\n      2022-12-30\n      3084.520020\n      3096.310059\n      3082.199951\n      3089.260010\n      3089.260010\n      217500\n      China\n      -0.231009\n      2022.0\n      12.0\n      30.0\n    \n  \n\n728 rows Ã— 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('China (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_china_covid['Date'], df_china_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#japan",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#japan",
    "title": "Stock on Graph",
    "section": "Japan",
    "text": "Japan\n\ndf_japan = pd.read_csv('./dataset/japan_n225.csv')\n\n\ndf_japan = pd.concat([df_japan,pd.DataFrame({'Country': 'Japan',\n                                             'Value':(df_japan['Close'] - df_japan['Close'].mean())/df_japan['Close'].std()})],axis=1)\n\n\ndf_japan_add = df_japan.assign(Year = list(map(lambda x: x.split('-')[0],df_japan['Date'])),\\\n                                    Mon = list(map(lambda x: x.split('-')[1],df_japan['Date'])),\\\n                                    Day = list(map(lambda x: x.split('-')[2],df_japan['Date'])))\n\n\ndf_japan_add.Year = df_japan_add.Year.astype(np.float64)\ndf_japan_add.Mon = df_japan_add.Mon.astype(np.float64)\ndf_japan_add.Day = df_japan_add.Day.astype(np.float64)\n\n\ndf_japan_covid = df_japan_add.query(\"Year>=2020 and Year<=2022\");df_japan_covid\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      367\n      2020-01-06\n      23319.759766\n      23365.359375\n      23148.529297\n      23204.859375\n      23204.859375\n      72800000.0\n      Japan\n      -0.604658\n      2020.0\n      1.0\n      6.0\n    \n    \n      368\n      2020-01-07\n      23320.119141\n      23577.439453\n      23299.919922\n      23575.720703\n      23575.720703\n      64300000.0\n      Japan\n      -0.496240\n      2020.0\n      1.0\n      7.0\n    \n    \n      369\n      2020-01-08\n      23217.490234\n      23303.210938\n      22951.179688\n      23204.759766\n      23204.759766\n      79400000.0\n      Japan\n      -0.604687\n      2020.0\n      1.0\n      8.0\n    \n    \n      370\n      2020-01-09\n      23530.289063\n      23767.089844\n      23506.150391\n      23739.869141\n      23739.869141\n      62200000.0\n      Japan\n      -0.448252\n      2020.0\n      1.0\n      9.0\n    \n    \n      371\n      2020-01-10\n      23813.279297\n      23903.289063\n      23761.080078\n      23850.570313\n      23850.570313\n      55900000.0\n      Japan\n      -0.415890\n      2020.0\n      1.0\n      10.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1093\n      2022-12-26\n      26299.539063\n      26438.650391\n      26294.849609\n      26405.869141\n      26405.869141\n      47300000.0\n      Japan\n      0.331131\n      2022.0\n      12.0\n      26.0\n    \n    \n      1094\n      2022-12-27\n      26570.779297\n      26620.490234\n      26447.869141\n      26447.869141\n      26447.869141\n      50200000.0\n      Japan\n      0.343410\n      2022.0\n      12.0\n      27.0\n    \n    \n      1095\n      2022-12-28\n      26309.339844\n      26354.269531\n      26199.669922\n      26340.500000\n      26340.500000\n      61500000.0\n      Japan\n      0.312021\n      2022.0\n      12.0\n      28.0\n    \n    \n      1096\n      2022-12-29\n      26074.900391\n      26126.699219\n      25953.919922\n      26093.669922\n      26093.669922\n      63100000.0\n      Japan\n      0.239862\n      2022.0\n      12.0\n      29.0\n    \n    \n      1097\n      2022-12-30\n      26288.000000\n      26321.369141\n      26067.919922\n      26094.500000\n      26094.500000\n      52700000.0\n      Japan\n      0.240105\n      2022.0\n      12.0\n      30.0\n    \n  \n\n731 rows Ã— 12 columns\n\n\n\n\n# plt.figure(figsize=(30, 8)) \n# plt.title('Japan (close)')\n# plt.xticks(rotation=45) \n# plt.plot(df_japan_covid['Date'], df_japan_covid['Close'], 'co-')\n# plt.grid(color='gray', linestyle='--')\n\n\n# with plt.style.context('seaborn-white'):\n#     fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(30,15))\n#     ax1.plot(df_korea_covid['Date'], df_korea_covid['Close'])\n#     ax2.plot(df_us_covid['Date'], df_us_covid['Close'])\n#     ax3.plot(df_china_covid['Date'], df_china_covid['Close'])\n#     ax4.plot(df_japan_covid['Date'], df_japan_covid['Close'])\n\n\ndf = pd.concat([df_korea_covid,df_us_covid,df_china_covid,df_japan_covid]);df\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n      Country\n      Value\n      Year\n      Mon\n      Day\n    \n  \n  \n    \n      364\n      2020-01-02\n      2201.209961\n      2202.320068\n      2171.840088\n      2175.169922\n      2175.169922\n      494700.0\n      Korea\n      -0.719054\n      2020.0\n      1.0\n      2.0\n    \n    \n      365\n      2020-01-03\n      2192.580078\n      2203.379883\n      2165.389893\n      2176.459961\n      2176.459961\n      631600.0\n      Korea\n      -0.715806\n      2020.0\n      1.0\n      3.0\n    \n    \n      366\n      2020-01-06\n      2154.969971\n      2164.419922\n      2149.949951\n      2155.070068\n      2155.070068\n      592700.0\n      Korea\n      -0.769651\n      2020.0\n      1.0\n      6.0\n    \n    \n      367\n      2020-01-07\n      2166.600098\n      2181.620117\n      2164.270020\n      2175.540039\n      2175.540039\n      568200.0\n      Korea\n      -0.718122\n      2020.0\n      1.0\n      7.0\n    \n    \n      368\n      2020-01-08\n      2156.270020\n      2162.320068\n      2137.719971\n      2151.310059\n      2151.310059\n      913800.0\n      Korea\n      -0.779116\n      2020.0\n      1.0\n      8.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1093\n      2022-12-26\n      26299.539063\n      26438.650391\n      26294.849609\n      26405.869141\n      26405.869141\n      47300000.0\n      Japan\n      0.331131\n      2022.0\n      12.0\n      26.0\n    \n    \n      1094\n      2022-12-27\n      26570.779297\n      26620.490234\n      26447.869141\n      26447.869141\n      26447.869141\n      50200000.0\n      Japan\n      0.343410\n      2022.0\n      12.0\n      27.0\n    \n    \n      1095\n      2022-12-28\n      26309.339844\n      26354.269531\n      26199.669922\n      26340.500000\n      26340.500000\n      61500000.0\n      Japan\n      0.312021\n      2022.0\n      12.0\n      28.0\n    \n    \n      1096\n      2022-12-29\n      26074.900391\n      26126.699219\n      25953.919922\n      26093.669922\n      26093.669922\n      63100000.0\n      Japan\n      0.239862\n      2022.0\n      12.0\n      29.0\n    \n    \n      1097\n      2022-12-30\n      26288.000000\n      26321.369141\n      26067.919922\n      26094.500000\n      26094.500000\n      52700000.0\n      Japan\n      0.240105\n      2022.0\n      12.0\n      30.0\n    \n  \n\n2955 rows Ã— 12 columns\n\n\n\n\ndf['Country'].unique()\n\narray(['Korea', 'United States of America', 'China', 'Japan'],\n      dtype=object)"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result",
    "title": "Stock on Graph",
    "section": "Result",
    "text": "Result\n\nrst.df.merge(covid_final_add,on='Date').sort_values(\"Residual\",ascending=False).iloc[:30,:]"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result-1",
    "href": "posts/RESEARCHES/2023-07-08-stock_on_graph.html#result-1",
    "title": "Stock on Graph",
    "section": "Result",
    "text": "Result\n\ncovid_final_add"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-07-Stock_Crawling.html",
    "href": "posts/RESEARCHES/2023-07-07-Stock_Crawling.html",
    "title": "Stock Crawling",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport requests\nfrom datetime import datetime\nfrom matplotlib import dates as mdates\nfrom bs4 import BeautifulSoup as bs\n\n\n\nKorea(KOSPI)\n\nurl = 'https://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=1'\n\n\nheaders = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}\nresponse = requests.get(url, headers=headers)\n\n\nresponse.text\n\n'<html lang=\"ko\">\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=euc-kr\">\\n<title>ë„¤ì´ë²„ ì¦ê¶Œ</title>\\n\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/common.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/layout.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/main.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock2.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock3.css\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/world.css\">\\n</head>\\n<body>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindo.min.ns.1.5.3.euckr.js\"></script>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/lcslog.js\"></script>\\n\\t\\t\\t\\t<!-- ì¼ë³„ì‹œì„¸ -->\\n\\t\\t\\t\\t<div class=\"box_type_m\">\\n\\t\\t\\t\\t\\t<h4 class=\"top_tlt\" style=\"text-align:left;\"><em>ì¼ë³„</em>ì‹œì„¸</h4>\\n\\t\\t\\t\\t\\t<table summary=\"ì¼ë³„ ì‹œì„¸í‘œ:ë‚ ì§œì— ë”°ë¥¸ ì²´ê²°ê°€ ì „ì¼ë¹„ ë“±ë½ë¥  ê±°ë˜ëŸ‰ ê±°ë˜ëŒ€ê¸ˆ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\" cellpadding=\"0\" cellspacing=\"0\" class=\"type_1\">\\n\\t\\t\\t\\t\\t<caption>ì¼ë³„ì‹œì„¸</caption>\\n\\t\\t\\t\\t\\t<col width=\"15%\"><col width=\"14%\"><col width=\"18%\"><col width=\"14%\"><col width=\"*\"><col width=\"18%\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<th>ë‚ ì§œ</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>ì²´ê²°ê°€</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>ì „ì¼ë¹„</th>\\n\\t\\t\\t\\t\\t\\t\\t<th>ë“±ë½ë¥ </th>\\n\\t\\t\\t\\t\\t\\t\\t<th>ê±°ë˜ëŸ‰<span class=\"add_txt\">(ì²œì£¼)</span></th>\\n\\t\\t\\t\\t\\t\\t\\t<th>ê±°ë˜ëŒ€ê¸ˆ<span class=\"add_txt\">(ë°±ë§Œ)</span></th>\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_07\"></td></tr>\\n\\n\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.07</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,526.71</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"í•˜ë½\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t29.58\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-1.16%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">613,265</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,367,353</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.06</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,556.29</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"í•˜ë½\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t22.71\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.88%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">531,900</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,291,029</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.05</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,579.00</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"í•˜ë½\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t14.31\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.55%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">601,089</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">10,257,664</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_08\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"division_line\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_08\"></td></tr>\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.04</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,593.31</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"í•˜ë½\"><span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t9.16\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 nv01\">\\n\\t\\t\\t\\t-0.35%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">674,411</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">9,160,796</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.07.03</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,602.47</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"ìƒìŠ¹\"><span class=\"tah p11 red02\">\\n\\t\\t\\t\\t38.19\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 red01\">\\n\\t\\t\\t\\t+1.49%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">618,006</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">8,973,590</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t<td class=\"date\">2023.06.30</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">2,564.28</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"rate_down\" style=\"padding-right:35px;\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" width=\"7\" height=\"6\" style=\"margin-right:4px;\" alt=\"ìƒìŠ¹\"><span class=\"tah p11 red02\">\\n\\t\\t\\t\\t14.26\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\">\\n\\t\\t\\t\\t<span class=\"tah p11 red01\">\\n\\t\\t\\t\\t+0.56%\\n\\t\\t\\t\\t</span>\\n\\t\\t\\t</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:40px;\">510,934</td>\\n\\t\\t\\t\\t\\t\\t<td class=\"number_1\" style=\"padding-right:30px;\">8,209,121</td>\\n\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"blank_09\"></td></tr>\\n\\t\\t\\t\\t\\t<tr><td colspan=\"6\" class=\"division_line\"></td></tr>\\n\\t\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<!--- í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ì‹œì‘--->\\n\\t\\t\\t\\t<table summary=\"í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ë¦¬ìŠ¤íŠ¸\" class=\"Nnavi\" align=\"center\">\\n\\t\\t\\t\\t<caption>í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜</caption>\\n\\t\\t\\t\\t<tr>\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n                \\n                <td class=\"on\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=1\"  >1</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=2\"  >2</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=3\"  >3</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=4\"  >4</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=5\"  >5</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=6\"  >6</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=7\"  >7</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=8\"  >8</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=9\"  >9</a>\\n\\t\\t\\t\\t</td>\\n<td>\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=10\"  >10</a>\\n\\t\\t\\t\\t</td>\\n\\n                <td class=\"pgR\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=11\"  >\\n\\t\\t\\t\\të‹¤ìŒ<img src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarR.gif\" width=\"3\" height=\"5\" alt=\"\" border=\"0\">\\n\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t</td>\\n\\n                <td class=\"pgRR\">\\n\\t\\t\\t\\t<a href=\"/sise/sise_index_day.naver?code=KOSPI&amp;page=1449\"  >ë§¨ë’¤\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarRR.gif\" width=\"8\" height=\"5\" alt=\"\" border=\"0\">\\n\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t</td>\\n\\n            \\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<!--- í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ë--->\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<!-- //ì¼ë³„ì‹œì„¸ -->\\n\\t\\t\\t\\t\\n<script type=\"text/javascript\">\\n    ;(function(){\\n        var eventType = \"onpageshow\" in window ? \"pageshow\" : \"load\";\\n        jindo.$Fn(function(){\\n            lcs_do();\\n        }).attach(window, eventType);\\n    })();\\n</script>\\n\\n</body>\\n</html>\\n'\n\n\n\nhtml = bs(response.text, 'html.parser')\nhtml_table = html.select(\"table\")\ntable = pd.read_html(str(html_table))\nprint('íŒŒì‹±ëœ í…Œì´ë¸”ì˜ ê°œìˆ˜ :', len(table))\n\níŒŒì‹±ëœ í…Œì´ë¸”ì˜ ê°œìˆ˜ : 2\n\n\n\ntable[0]\n\n\n\n\n\n  \n    \n      \n      ë‚ ì§œ\n      ì²´ê²°ê°€\n      ì „ì¼ë¹„\n      ë“±ë½ë¥ \n      ê±°ë˜ëŸ‰(ì²œì£¼)\n      ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      6\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      7\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      10\n      2023.06.30\n      2564.28\n      14.26\n      +0.56%\n      510934.0\n      8209121.0\n    \n    \n      11\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      12\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ntable[1]\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n      11\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n      ë‹¤ìŒ\n      ë§¨ë’¤\n    \n  \n\n\n\n\n\ntable[0].dropna()\n\n\n\n\n\n  \n    \n      \n      ë‚ ì§œ\n      ì²´ê²°ê°€\n      ì „ì¼ë¹„\n      ë“±ë½ë¥ \n      ê±°ë˜ëŸ‰(ì²œì£¼)\n      ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)\n    \n  \n  \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      10\n      2023.06.30\n      2564.28\n      14.26\n      +0.56%\n      510934.0\n      8209121.0\n    \n  \n\n\n\n\n\ndf = pd.DataFrame()\nsise_url = 'https://finance.naver.com/sise/sise_index_day.naver?code=KOSPI'  \nfor page in range(1, 500):\n    page_url = '{}&page={}'.format(sise_url, page)\n    print(page_url)\n\n    # ìœ„ì—ì„œ í–ˆë˜ ì¼ë ¨ì˜ ê³¼ì •ë“¤ì„ ê° urlì— ëŒ€í•´ì„œ (99í˜ì´ì§€ì— ëŒ€í•´ì„œ ë°˜ë³µ)\n    response = requests.get(page_url, headers=headers)\n    html = bs(response.text, 'html.parser')\n    html_table = html.select(\"table\")\n    table = pd.read_html(str(html_table))\n\n    # í˜„ì¬ ì–»ì€ ë°ì´í„°í”„ë ˆì„ì„ ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì— ëˆ„ì .\n    df = df.append(table[0].dropna())\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=1\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=2\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=3\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=4\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=5\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=6\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=7\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=8\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=9\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=10\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=11\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=12\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=13\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=14\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=15\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=16\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=17\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=18\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=19\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=20\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=21\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=22\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=23\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=24\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=25\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=26\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=27\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=28\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=29\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=30\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=31\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=32\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=33\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=34\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=35\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=36\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=37\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=38\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=39\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=40\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=41\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=42\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=43\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=44\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=45\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=46\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=47\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=48\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=49\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=50\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=51\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=52\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=53\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=54\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=55\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=56\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=57\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=58\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=59\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=60\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=61\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=62\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=63\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=64\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=65\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=66\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=67\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=68\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=69\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=70\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=71\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=72\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=73\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=74\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=75\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=76\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=77\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=78\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=79\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=80\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=81\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=82\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=83\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=84\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=85\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=86\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=87\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=88\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=89\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=90\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=91\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=92\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=93\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=94\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=95\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=96\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=97\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=98\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=99\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=100\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=101\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=102\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=103\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=104\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=105\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=106\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=107\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=108\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=109\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=110\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=111\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=112\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=113\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=114\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=115\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=116\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=117\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=118\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=119\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=120\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=121\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=122\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=123\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=124\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=125\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=126\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=127\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=128\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=129\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=130\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=131\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=132\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=133\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=134\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=135\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=136\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=137\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=138\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=139\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=140\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=141\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=142\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=143\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=144\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=145\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=146\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=147\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=148\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=149\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=150\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=151\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=152\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=153\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=154\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=155\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=156\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=157\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=158\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=159\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=160\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=161\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=162\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=163\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=164\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=165\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=166\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=167\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=168\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=169\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=170\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=171\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=172\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=173\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=174\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=175\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=176\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=177\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=178\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=179\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=180\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=181\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=182\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=183\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=184\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=185\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=186\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=187\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=188\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=189\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=190\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=191\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=192\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=193\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=194\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=195\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=196\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=197\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=198\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=199\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=200\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=201\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=202\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=203\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=204\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=205\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=206\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=207\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=208\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=209\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=210\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=211\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=212\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=213\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=214\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=215\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=216\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=217\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=218\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=219\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=220\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=221\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=222\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=223\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=224\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=225\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=226\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=227\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=228\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=229\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=230\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=231\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=232\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=233\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=234\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=235\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=236\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=237\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=238\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=239\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=240\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=241\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=242\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=243\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=244\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=245\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=246\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=247\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=248\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=249\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=250\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=251\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=252\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=253\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=254\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=255\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=256\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=257\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=258\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=259\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=260\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=261\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=262\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=263\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=264\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=265\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=266\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=267\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=268\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=269\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=270\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=271\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=272\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=273\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=274\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=275\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=276\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=277\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=278\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=279\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=280\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=281\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=282\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=283\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=284\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=285\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=286\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=287\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=288\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=289\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=290\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=291\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=292\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=293\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=294\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=295\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=296\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=297\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=298\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=299\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=300\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=301\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=302\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=303\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=304\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=305\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=306\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=307\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=308\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=309\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=310\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=311\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=312\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=313\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=314\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=315\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=316\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=317\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=318\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=319\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=320\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=321\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=322\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=323\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=324\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=325\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=326\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=327\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=328\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=329\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=330\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=331\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=332\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=333\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=334\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=335\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=336\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=337\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=338\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=339\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=340\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=341\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=342\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=343\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=344\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=345\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=346\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=347\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=348\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=349\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=350\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=351\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=352\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=353\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=354\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=355\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=356\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=357\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=358\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=359\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=360\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=361\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=362\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=363\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=364\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=365\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=366\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=367\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=368\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=369\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=370\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=371\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=372\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=373\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=374\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=375\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=376\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=377\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=378\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=379\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=380\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=381\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=382\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=383\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=384\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=385\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=386\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=387\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=388\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=389\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=390\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=391\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=392\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=393\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=394\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=395\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=396\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=397\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=398\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=399\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=400\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=401\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=402\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=403\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=404\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=405\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=406\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=407\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=408\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=409\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=410\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=411\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=412\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=413\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=414\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=415\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=416\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=417\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=418\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=419\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=420\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=421\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=422\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=423\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=424\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=425\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=426\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=427\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=428\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=429\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=430\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=431\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=432\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=433\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=434\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=435\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=436\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=437\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=438\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=439\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=440\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=441\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=442\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=443\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=444\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=445\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=446\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=447\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=448\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=449\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=450\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=451\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=452\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=453\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=454\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=455\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=456\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=457\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=458\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=459\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=460\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=461\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=462\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=463\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=464\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=465\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=466\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=467\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=468\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=469\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=470\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=471\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=472\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=473\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=474\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=475\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=476\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=477\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=478\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=479\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=480\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=481\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=482\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=483\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=484\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=485\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=486\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=487\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=488\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=489\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=490\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=491\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=492\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=493\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=494\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=495\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=496\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=497\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=498\nhttps://finance.naver.com/sise/sise_index_day.naver?code=KOSPI&page=499\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n<ipython-input-40-3bcb01c44ed2>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[0].dropna())\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      ë‚ ì§œ\n      ì²´ê²°ê°€\n      ì „ì¼ë¹„\n      ë“±ë½ë¥ \n      ê±°ë˜ëŸ‰(ì²œì£¼)\n      ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)\n    \n  \n  \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2\n      2011.05.24\n      2061.76\n      6.05\n      +0.29%\n      261949.0\n      6012138.0\n    \n    \n      3\n      2011.05.23\n      2055.71\n      55.79\n      -2.64%\n      289835.0\n      6239214.0\n    \n    \n      8\n      2011.05.20\n      2111.50\n      15.99\n      +0.76%\n      280007.0\n      6096860.0\n    \n    \n      9\n      2011.05.19\n      2095.51\n      40.27\n      -1.89%\n      278726.0\n      7779617.0\n    \n    \n      10\n      2011.05.18\n      2135.78\n      33.37\n      +1.59%\n      255798.0\n      7102533.0\n    \n  \n\n2994 rows Ã— 6 columns\n\n\n\n\ndf = df.dropna()\n# df = df.iloc[0:30] \ndf = df.sort_values(by='ë‚ ì§œ')\ndf\n\n\n\n\n\n  \n    \n      \n      ë‚ ì§œ\n      ì²´ê²°ê°€\n      ì „ì¼ë¹„\n      ë“±ë½ë¥ \n      ê±°ë˜ëŸ‰(ì²œì£¼)\n      ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)\n    \n  \n  \n    \n      10\n      2011.05.18\n      2135.78\n      33.37\n      +1.59%\n      255798.0\n      7102533.0\n    \n    \n      9\n      2011.05.19\n      2095.51\n      40.27\n      -1.89%\n      278726.0\n      7779617.0\n    \n    \n      8\n      2011.05.20\n      2111.50\n      15.99\n      +0.76%\n      280007.0\n      6096860.0\n    \n    \n      3\n      2011.05.23\n      2055.71\n      55.79\n      -2.64%\n      289835.0\n      6239214.0\n    \n    \n      2\n      2011.05.24\n      2061.76\n      6.05\n      +0.29%\n      261949.0\n      6012138.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9\n      2023.07.03\n      2602.47\n      38.19\n      +1.49%\n      618006.0\n      8973590.0\n    \n    \n      8\n      2023.07.04\n      2593.31\n      9.16\n      -0.35%\n      674411.0\n      9160796.0\n    \n    \n      3\n      2023.07.05\n      2579.00\n      14.31\n      -0.55%\n      601089.0\n      10257664.0\n    \n    \n      2\n      2023.07.06\n      2556.29\n      22.71\n      -0.88%\n      531900.0\n      10291029.0\n    \n    \n      1\n      2023.07.07\n      2526.71\n      29.58\n      -1.16%\n      613265.0\n      10367353.0\n    \n  \n\n2994 rows Ã— 6 columns\n\n\n\n\nplt.figure(figsize=(15, 5)) \nplt.title('Celltrion (close)')\nplt.xticks(rotation=45) \nplt.plot(df['ë‚ ì§œ'], df['ì²´ê²°ê°€'], 'co-')\nplt.grid(color='gray', linestyle='--')\nplt.show()\n\n\n\n\n\ndf.to_csv('korea_kospi.csv')\n\n\n\nUS(NASDAQ)\n\nurl = 'https://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=1'\n\n\nheaders = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}\nresponse = requests.get(url, headers=headers)\n\n\nresponse.text\n\n'<script language=javascript>\\nvar nsc=\"finance.world\";\\nfunction select_chart(pst)\\n{\\n\\tfor(var i=0 ; i<4 ; i++)\\n\\t{\\n\\t\\tif (i == pst)\\n\\t\\t\\tdocument.getElementById(\\'chart_\\'+pst).className = \\'on\\';\\n\\t\\telse\\n\\t\\t\\tdocument.getElementById(\\'chart_\\'+i).className = \"\";\\n\\t}\\n}\\n</script>\\n\\n<!--  global include -->\\n\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t\\n<html lang=\\'ko\\'>\\n<head>\\n\\n\\n\\t\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t<title>ë‚˜ìŠ¤ë‹¥ ì¢…í•© : ë„¤ì´ë²„ ì¦ê¶Œ</title>\\n\\t\\t\\t\\n\\t\\t\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\\n\\t\\n\\n\\n<meta http-equiv=\"Content-Script-Type\" content=\"text/javascript\">\\n<meta http-equiv=\"Content-Style-Type\" content=\"text/css\">\\n<meta name=\"apple-mobile-web-app-title\" content=\"ë„¤ì´ë²„ ì¦ê¶Œ\" />\\n\\n\\n\\n\\n\\n\\t\\n    \\n        <meta property=\"og:url\" content=\"http://finance.naver.com/world/sise.naver?symbol=NAS@IXIC\"/>\\n        \\n\\t\\t\\t\\n\\t\\t    \\n\\t\\t    \\t<meta property=\"og:title\" content=\"ë‚˜ìŠ¤ë‹¥ ì¢…í•© : ë„¤ì´ë²„ ì¦ê¶Œ\"/>\\n\\t\\t     \\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t   <meta property=\"og:description\" content=\"ê´€ì‹¬ì¢…ëª©ì˜ ì‹¤ì‹œê°„ ì£¼ê°€ë¥¼ ê°€ì¥ ë¹ ë¥´ê²Œ í™•ì¸í•˜ëŠ” ê³³\"/>\\n\\t\\t    \\n\\t\\t    \\n\\t\\t\\n\\t\\t \\n\\t\\t\\t\\n\\t\\t    \\n\\t\\t        <meta property=\"og:image\" content=\"https://ssl.pstatic.net/imgfinance/chart/mobile/world/day/NAS@IXIC_end_up.png\"/>\\n\\t\\t    \\n\\t\\t\\n    \\n\\n<meta property=\"og:type\" content=\"article\"/>\\n<meta property=\"og:article:thumbnailUrl\" content=\"\"/>\\n<meta property=\"og:article:author\" content=\"ë„¤ì´ë²„ ì¦ê¶Œ\"/>\\n<meta property=\"og:article:author:url\" content=\"http://FINANCE.NAVER.COM\"/>\\n\\n\\n\\n\\n\\n\\n<link rel=\\'stylesheet\\' type=\\'text/css\\' href=\\'https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/finance_header.css\\'>\\n\\n\\t\\n\\t\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/finance.css\">\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/css/newstock3.css\">\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindo.min.ns.1.5.3.euckr.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/release/common.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/jindoComponent/jindo.Component.1.0.3.js\"></script>\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/nhn.autocomplete.stock.js\"></script>\\n\\t\\n\\t\\n\\t\\n\\n<script>\\n\\tvar ieVersion = (function () {\\n        var version = -1;\\n        if (\\n          navigator.appName == \\'Microsoft Internet Explorer\\' &&\\n          navigator.userAgent.toLowerCase().indexOf(\\'msie\\') != -1 &&\\n          new RegExp(\\'MSIE ([0-9]{1,}[\\\\./0-9]{0,})\\').exec(navigator.userAgent) != null\\n        ) {\\n          version = parseInt(RegExp.$1);\\n        }\\n        return version;\\n      })();\\n</script>\\n\\t\\n\\t<!-- smart channel ê´‘ê³  -->\\n\\t<script async src=\"https://ssl.pstatic.net/tveta/libs/glad/prod/gfp-core.js\">\\n\\t\\t</script>\\n\\t<script type=\"text/javascript\">\\n\\t\\t(function(){\\n\\t\\t\\tif (ieVersion === -1 || ieVersion > 10) {\\n\\t\\t\\t\\twindow.gladsdk = window.gladsdk || { cmd: [] };\\n\\n\\t\\t\\t\\tgladsdk.cmd.push(function() {\\n\\t\\t\\t\\t\\t\\tgladsdk.defineAdSlot({\\n\\t\\t\\t\\t\\t\\t\\tadUnitId: \"p_nf_stock\",\\n\\t\\t\\t\\t\\t\\t\\tadSlotElementId: \"_SmartChannelTopBanner\",\\n\\t\\t\\t\\t\\t\\t\\tuct: \"KR\",\\n\\t\\t\\t\\t\\t\\t\\tcustomParam: {\\n\\t\\t\\t\\t\\t\\t\\t\\tcalp: \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\"abroad\"\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t});\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_LOADED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_LOADED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_CLICKED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_CLICKED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.AD_IMPRESSED, function(ad) {\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.AD_IMPRESSED);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\tgladsdk.addEventListener(gladsdk.event.ERROR, function(ad, error) {\\n\\t\\t\\t\\t\\t\\t\\t//TODO: ì˜¤ë¥˜ ë¡œê¹…ì²˜ë¦¬\\n\\t\\t\\t\\t\\t\\t\\t//console.log(gladsdk.event.ERROR);\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t});\\n\\t\\t\\t}\\n\\t\\t})();\\n\\t</script>\\n\\t\\n\\n\\t<link rel=\"shortcut icon\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon.ico\" type=\"image/x-icon\">\\n\\t\\n\\t<script type=\"text/javascript\">\\n    (function(){\\n\\t\\tdocument.write(\\n\\t\\t\\t\\t[\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-96x96.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" sizes=\"180x180\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-180x180.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"apple-touch-icon-precomposed\" sizes=\"192x192\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-192x192.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-16x16.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-32x32.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"96x96\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-96x96.png\"/>\\',\\n\\t\\t\\t\\t\\t\\'<link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://ssl.pstatic.net/imgstock/favi/favicon-192x192.png\"/>\\'\\n\\t\\t\\t\\t]\\n\\t\\t\\t.join(\\'\\\\n\\')\\n\\t\\t);\\n    })();\\n    </script>\\n</head>\\n\\n\\n\\n\\n<body onload=\\'getGNB();\\'>\\n\\n\\n\\n<script type=\"text/javascript\">\\n\\n\\tvar nclk_evt = 3;\\n\\tnclk_do();\\n</script>\\n\\n\\n<script type=\"text/javascript\">\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nvar nsc=\"finance.world\";\\n\\n\\n\\n\\n\\nvar ccsrv=\"cc.naver.com\";\\n\\n\\n\\t\\n\\t\\n\\tvar gnb_service=\\'finance\\';\\n\\t\\n\\n\\nvar gnb_logout=document.URL; //GNBì—ì„œ ë¡œê·¸ì•„ì›ƒ í›„ redirect ë  URL\\nvar gnb_searchbox=\\'off\\'; //ë¯¸ë‹ˆ ê²€ìƒ‰ì°½ì„ on í• ì§€ off í• ì§€. defaultëŠ” off\\nvar gnb_shortnick=\\'off\\'; //ë‹‰ë„¤ì„ ë§ì¤„ì„(10ì)ì„ oní• ì§€ off í• ì§€. defaultëŠ” off.\\n\\n\\nvar gnb_naverme_layer_open_callback = function(){\\n\\t   var naverLayerSize = gnbNaverMeLayer.getLayerSize();\\n\\t\\t\\n\\t\\tvar me_layers = document.getElementById(\"me_layers\");\\n\\t\\tme_layers.width=naverLayerSize.width;\\n\\t\\tme_layers.height=naverLayerSize.height;};\\n\\nvar gnb_naverme_layer_close_callback = function(){\\n\\t\\t\\n\\t\\t\\tvar me_layers = document.getElementById(\"me_layers\");\\n\\t\\t\\tme_layers.width=\"0\";\\n\\t\\t\\tme_layers.height=\"0\";};\\n</script>\\n\\n\\n<div id=\"u_skip\">\\n\\t<a href=\"#menu\" tabindex=\"1\"><span>ë©”ì¸ ë©”ë‰´ë¡œ ë°”ë¡œê°€ê¸°</span></a>\\n\\n\\t\\n\\t\\n\\t\\t<a href=\"#start\" tabindex=\"2\"><span>ë³¸ë¬¸ìœ¼ë¡œ ë°”ë¡œê°€ê¸°</span></a>\\n\\t\\n\\n</div>\\n\\n\\n<div id=\"header\">\\n\\t<div class=\"snb_area\">\\n\\t\\t<div class=\"snb_inner\">\\n\\t\\t\\t<div id=\"gnb_area\">\\n\\t\\t\\t\\t<div id=\"gnb\">\\n\\t\\t\\t\\t\\t<script charset=\"EUC-KR\" type=\"text/javascript\">\\n\\t\\t\\t\\t\\tvar gnb_service = \"gnbtest\";\\n                    var gnb_template = location.protocol == \"http:\" ? \"gnb_quirks_euckr\" : \"gnb_utf8\" ;\\n\\t\\t\\t\\t\\tvar gnb_dark = false;\\n\\t\\t\\t\\t\\tvar gnb_brightness = 1;\\n\\t\\t\\t\\t\\tvar gnb_logout=encodeURIComponent(location.href);\\n\\t\\t\\t\\t\\tvar gnb_one_naver = 1;\\n\\t\\t\\t\\t\\t</script>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<script type=\"text/javascript\" charset=\"utf-8\" src=\"https://ssl.pstatic.net/static.gn/templates/gnb_utf8.nhn?20230707\">\\n                    \\t\\t</script>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\n\\t\\t\\t<div class=\"sta\">\\n\\t\\t\\t\\t<h1 class=\"logo\"> <a href=\"https://www.naver.com/\" class=\"logo_naver\" onClick=\"clickcr(this, \\'STA.naver\\', \\'\\', \\'\\', event);\"><span class=\"blind\">ë„¤ì´ë²„</span></a>\\n\\t\\t\\t\\t<a href=\"/\" class=\"logo_service\" onClick=\"clickcr(this, \\'STA.finance\\', \\'\\', \\'\\', event);\"><span class=\"blind\">ì¦ê¶Œ</span></a> </h1>\\n\\t\\t\\t\\t<form name=\"search\" action=\"/search/search.naver\"  method=\"get\"\\n\\t\\t\\t\\t\\tonsubmit=\"return delayed_submit(this)\" style=\"margin:0; padding:0;\">\\n\\t\\t\\t\\t<fieldset>\\n\\t\\t\\t\\t\\t<legend>ê²€ìƒ‰</legend>\\n\\t\\t\\t\\t\\t<div class=\"snb_search_box\">\\n\\t\\t\\t\\t\\t\\t<div class=\"snb_search_box_sub\">\\n\\t\\t\\t\\t\\t\\t\\t<input id=\"stock_items\" type=\"text\" title=\"ê²€ìƒ‰\" name=\"query\" value=\"ì¢…ëª©ëª…&middot;ì§€ìˆ˜ëª… ì…ë ¥\" accesskey=\"s\" class=\"snb_search_text snb_default\" autocomplete=\"off\">\\n\\t\\t\\t\\t\\t\\t\\t<a id=\"nautocomplete\" href=\"#\" onclick=\"return false\" class=\"btn_arrow\"><span class=\"blind\">ìë™ì™„ì„± í¼ì¹˜ê¸°</span></a>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t<div class=\"auto_area\">\\n\\t\\t\\t\\t\\t\\t\\t<h2 class=\"blind\">ìë™ì™„ì„±</h2>\\n\\t\\t\\t\\t\\t\\t\\t<div id=\"autoFrame\" style=\"display: none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmp\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<ul class=\"_resultBox\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'AUT.list\\', \\'\\', \\'\\', event); return false;\" class=\"_au_real_list\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"num _au_real_list\">@code@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"_au_real_list\">@txt@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"type _au_real_list\">@market@</span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_full\">@full_txt@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_code\">@in_code@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_name\">@in_name@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_link\">@in_link@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div style=\"display:none\" class=\"_au_market\">@in_market@</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\" onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\" >ê¸°ëŠ¥ë„ê¸°</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t<!-- í˜„ì¬ ìë™ì™„ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ê³„ì‹­ë‹ˆë‹¤ -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmpIng\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"msg\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tí˜„ì¬ ìë™ì™„ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ê³„ì‹­ë‹ˆë‹¤.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\" onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\">ê¸°ëŠ¥ë„ê¸°</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t<!--// í˜„ì¬ ìë™ì™„ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ê³„ì‹­ë‹ˆë‹¤ -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<!-- ìë™ì™„ì„± ê¸°ëŠ¥ì´ í™œì„±í™” -->\\n\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap\" id=\"atcmpStart\" style=\"display:none;\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"wrap_in\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"words\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"msg\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tìë™ì™„ì„± ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<p class=\"func\">\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span><a href=\"#\" class=\"fire_event funoff\"  onclick=\"clickcr(this, \\'AUT.x\\', \\'\\', \\'\\', event); smartSearch.unuse(); return false;\">ê¸°ëŠ¥ë„ê¸°</a></span>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\t<button type=\"submit\" class=\"snb_search_btn\" onclick=\"clickcr(this, \\'STA.search\\', \\'\\', \\'\\', event);\" alt=\"ê²€ìƒ‰\"><span class=\"blind\">ê²€ìƒ‰</span></button>\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" target=\"_blank\" class=\"snb_search_btn-total\" onclick=\"itegrationSearch();clickcr(this, \\'STA.nx\\', \\'\\', \\'\\', event);return false;\">í†µí•©ê²€ìƒ‰</a>\\n\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t</fieldset>\\n\\t\\t\\t\\t</form>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\t<div class=\"lnb_area \">\\n\\t\\t<div class=\"lnb_inner\">\\n\\t\\t\\t<div id=\"menu\">\\n\\t\\t\\t\\t<ul class=\"menu\">\\n\\t\\t\\t\\t\\t<li class=\"m1 first \"><a href=\"/\" onClick=\"clickcr(this, \\'LNB.home\\', \\'\\', \\'\\', event);\"><span class=\"tx\">ì¦ê¶Œ í™ˆ</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m2 \"><a href=\"/sise/\" onClick=\"clickcr(this, \\'LNB.sise\\', \\'\\', \\'\\', event);\"><span class=\"tx\">êµ­ë‚´ì¦ì‹œ</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m3 on\"><a href=\"/world/\" onClick=\"clickcr(this, \\'LNB.world\\', \\'\\', \\'\\', event);\"><span class=\"tx\">í•´ì™¸ì¦ì‹œ</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m4 \"><a href=\"/marketindex/\" onClick=\"clickcr(this, \\'LNB.market\\', \\'\\', \\'\\', event);\"><span class=\"tx\">ì‹œì¥ì§€í‘œ</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m6 \"><a href=\"/research/\" onClick=\"clickcr(this, \\'LNB.research\\', \\'\\', \\'\\', event);\"><span class=\"tx\">ë¦¬ì„œì¹˜</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m7 \"><a href=\"/news/\"><span class=\"tx\">ë‰´ìŠ¤</span></a></li>\\n\\t\\t\\t\\t\\t<li class=\"m8 \"><a href=\"/mystock/\" onClick=\"clickcr(this, \\'LNB.mystock\\', \\'\\', \\'\\', event);\"><span class=\"tx\">MY</span></a></li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\t\\n\\t\\n\\t\\n\\t\\n\\t<script type=\"text/JavaScript\">\\n\\t\\tfunction overSubmenu(e) {\\n\\t\\t\\tvar curElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\t\\tcurElement.addClass(\"on\");\\n\\t\\t}\\n\\n\\t\\tfunction outSubmenu(e) {\\n\\t\\t\\tvar curElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\t\\tcurElement.removeClass(\"on\");\\n\\t\\t}\\n\\n\\t\\twindow.onload=function(){\\n\\t\\t\\t// í•´ì™¸ì¦ì‹œí™ˆ, í•´ì™¸ì¦ì‹œë‰´ìŠ¤ëŠ” mouseover ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ë©´ ì•ˆëœë‹¤.\\n\\t\\t\\tvar liMenuElement = jindo.$A(jindo.$$(\\'ul.lnb2 li\\')).slice(2, 6);\\n\\t\\t\\tvar liMenuElementValue = liMenuElement.$value();\\n\\t\\t\\tjindo.$Fn(function(e){overSubmenu(e);}).attach(liMenuElementValue,\\'mouseover\\');\\n\\t\\t\\tjindo.$Fn(function(e){outSubmenu(e);}).attach(liMenuElementValue,\\'mouseout\\');\\n\\t\\t\\tgetGNB();\\n\\t\\t}\\n\\t</script>\\n\\t\\n\\n\\t\\n\\t<script type=\"text/JavaScript\">\\n\\t\\t/* lcs ì§‘ê³„ */\\n        ;(function(){\\n            var eventType = \"onpageshow\" in window ? \"pageshow\" : \"load\";\\n            jindo.$Fn(function(){\\n                lcs_do();\\n            }).attach(window, eventType);\\n        })();\\n\\n\\t\\t/* ê²€ìƒ‰ ìë™ì™„ì„± [ ì¸ì1 : ê²€ìƒ‰inputì˜ ID, ì¸ì2 : iframe íƒœê·¸ ID ]   */\\n\\t\\t// AutoComplete ìƒì„±\\n\\t\\tvar acDomain = \"ac.finance.naver.com\";\\n        if (location.hostname.indexOf(\"staging-\") > -1) {\\n            acDomain = \"staging-\" + acDomain;\\n        } else if (location.hostname.indexOf(\"dev-\") > -1 || location.hostname.indexOf(\"localhost\") > -1 || location.hostname.indexOf(\"local-\") > -1) {\\n\\t\\t\\tacDomain = \"dev-\" + acDomain;\\n\\t\\t}\\n\\n        var acUrl = \"https://\" + acDomain + \"/ac\";\\n\\n\\t\\tsmartSearch = new nhn.Autocomplete(\\n\\t\\t\\t// InputManager ìƒì„±\\n\\t\\t\\tnew nhn.AcInputManager(jindo.$(\"stock_items\")),\\n\\t\\t\\t// DataManager ìƒì„±\\n\\t\\t\\tnew nhn.AcDataManager(acUrl, \"jsonp\", \"get\", {\\n                    st: \"111\",\\n                    r_lt : \"111\",\\n                    q_enc : \"euc-kr\",\\n                    r_enc : \"euc-kr\",\\n                    frm: \"stock\"}),\\n\\t\\t\\t// ViewManager ìƒì„±\\n\\t\\t\\tnew nhn.AcStockViewManager(jindo.$(\"autoFrame\"), jindo.$(\"nautocomplete\"), {\\n                                        strMax: 200,\\n                                        listMax: [7, 2, 2],\\n                                        aRedirectUrl : [\\n                            \\t\\t\\t\"https://finance.naver.com\",\\n                            \\t\\t\\t\"https://finance.naver.com\",\\n                            \\t\\t\\t\"https://finance.naver.com\"]}),\\n\\t\\t\\t// Autocomplete Option\\n            {formId:\"search\", cookieDomain:location.hostname, cookieName:\"NaverCommonStock\"});\\n\\n\\t\\t\\tsmartSearch.attach({\\n\\t            onFocus: function () {\\n\\t                var weInput = jindo.$Element(\\'stock_items\\');\\n\\t                if (weInput && weInput.hasClass(\"snb_default\")) {\\n\\t                        weInput.text(\"\");\\n\\t                        weInput.removeClass(\\'snb_default\\');\\n\\t                }\\n\\t            }\\n\\t        });\\n\\n\\t\\t/* í†µí•©ê²€ìƒ‰  start ----->  */\\n\\t\\t//document.domain = \\'naver.com\\';\\n\\t\\tvar sSearchHintText = \\'ì¢…ëª©ëª…Â·ì§€ìˆ˜ëª…Â·í™˜ìœ¨ëª…Â·ì›ìì¬ëª… ì…ë ¥\\';\\n\\t\\tfunction itegrationSearch() {\\n\\t\\t\\tvar query = jindo.$(\\'stock_items\\').value;\\n\\n\\t\\t\\tif ( query == \\'\\'  || encodeURIComponent(query) == encodeURIComponent(sSearchHintText))\\n\\t\\t\\t{\\n\\t\\t\\t\\talert ( \\'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\\' );\\n\\t\\t\\t\\treturn;\\n\\t\\t\\t}\\n\\n            var url = location.protocol + \"//search.naver.com/search.naver?sm=sta_hty.finance&where=nexearch&ie=UTF8&query=\" + encodeURIComponent(query);\\n            window.open(url, \"_blank\");\\n\\n\\t\\t\\treturn false;\\n\\t\\t}\\n\\n\\t\\tfunction delayed_submit(object) {\\n\\t\\t\\tif (navigator.userAgent.indexOf(\\'MSIE\\') == -1) {\\n\\t\\t\\t\\twindow.setTimeout(function() {stock_search(object)}, 300);\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tstock_search(object);\\n\\t\\t\\t}\\n\\t\\t\\treturn false;\\n\\t\\t}\\n\\n\\t\\tfunction stock_search (object)\\n\\t\\t{\\n\\t\\t\\tquery = object.query.value.replace(/^\\\\s*/,\\'\\').replace(/\\\\s*$/,\\'\\');\\t// trim\\n\\t\\t\\tobject.query.value=query;\\n\\n\\t\\t\\tif ( query == \\'\\' || query == sSearchHintText.replace(/^\\\\s*/,\\'\\').replace(/\\\\s*$/,\\'\\'))\\n\\t\\t\\t{\\n\\t\\t\\t\\talert ( \\'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\\' );\\n\\t\\t\\t\\treturn;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tobject.submit();\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t/* <---------- í†µí•©ê²€ìƒ‰  end */\\n\\n\\t\\tfunction popup()\\n\\t\\t{\\n\\t\\t\\twin = window.open(\\'/template/group_limit_pop.jsp\\',\\'finan_popup\\',\\'width=569 height=278 scrollbars=no status=no\\');\\n\\t\\t\\twin.focus();\\n\\t\\t}\\n\\t</script>\\n\\n\\t<iframe id=\"me_layers\" name=\"test\" title=\"ë„¤ì´ë²„ë¯¸ ì˜ì—­\" width=\"0\" height=\"0\" scrolling=\"no\" frameborder=\"0\" style=\"display:block;top: 22px; right: 209px; position: absolute; z-index: 15;\"></iframe>\\n</div>\\n<div id=\"wrap\"  >\\n\\t\\n\\t\\t<div class=\"banner_smart\">\\n\\t\\t\\t<div id=\"_SmartChannelTopBanner\">\\n\\t\\t\\t\\t<script type=\"text/javascript\">\\n\\t\\t\\t\\tif (ieVersion === -1 || ieVersion > 10) {\\n\\t\\t\\t\\t\\tgladsdk.cmd.push(function() {\\n\\t\\t\\t\\t\\t\\tgladsdk.displayAd(\"_SmartChannelTopBanner\");\\n\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t</script>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\n\\n<!-- //  global include -->\\n\\t<!-- [D] ì´ ë¼ì¸ë¶€í„° Footer ì „ê¹Œì§€ëŠ” ì „ë¶€ ìƒˆë¡œ ë§ˆí¬ì—…ëœ ì˜ì—­ì…ë‹ˆë‹¤. ê¸°ì¡´ ë ˆì´ì•„ì›ƒì„ ê±·ì–´ë‚´ ì£¼ì„¸ìš”.\\n\\t\\tclass=\"ì„¹ì…˜ê³ ìœ ë„¤ì´ë°\" ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\\n\\t\\t(í•´ì™¸ì¦ì‹œ ì„¹ì…˜ > end í˜ì´ì§€ : section_world section_world_end)\\n\\t\\të‹¤ìŒ ë§ˆí¬ì—…ë‹´ë‹¹ìë‹˜ : ê¸°ì¡´ finance.css ì—ì„œ #container ë¥¼ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì—, ì‚¬ì´ë“œì´í™íŠ¸ë¥¼ ê³ ë ¤í•´ì„œ id=\"container\" ë¥¼ ì œì™¸í–ˆìŠµë‹ˆë‹¤ -->\\n\\t<div class=\"section_world section_world_end\">\\n\\t\\t<!-- ìƒë‹¨ ì œëª©ì˜ì—­ -->\\n\\n\\t\\t<div class=\"group_h\">\\n\\t\\t\\t<div class=\"h_area\">\\n\\t\\t\\t\\t<h2>ë‚˜ìŠ¤ë‹¥ ì¢…í•©</h2>\\n\\t\\t\\t\\t<em class=\"quot\">NAS@IXIC</em>\\n\\t\\t\\t\\t<span class=\"state\">ë¯¸êµ­</span>\\n\\t\\t\\t\\t<span class=\"date\"><em>2023.07.07 10:42</em> \\n\\t\\t\\t\\tí˜„ì§€ì‹œê°„ ê¸°ì¤€\\n\\t\\t\\t\\t<span>|</span>15ë¶„ ì§€ì—°ì œê³µ </span>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\t<!-- //ìƒë‹¨ ì œëª©ì˜ì—­ -->\\n\\t\\t<div id=\"content\">\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\t<!-- í˜„ì¬ ì‹œì„¸ -->\\n\\t\\t\\t<!-- [D] í€ë“œ end ì™€ ë™ì¼í•œ êµ¬ì¡°ì…ë‹ˆë‹¤ -->\\n\\t\\t\\t<div class=\"rate_info\">\\n\\t\\t\\t\\t<div class=\"today\">\\n\\t\\t\\t\\t\\t<p class=\"no_today\">\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no8\">8</span><span class=\"no1\">1</span><span class=\"jum\">.</span><span class=\"no6\">6</span><span class=\"no1\">1</span>\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t<p class=\"no_exday\">\\n\\t\\t\\t\\t\\t\\t<span class=\"txt_comparison\">ì „ì¼ëŒ€ë¹„</span>\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\"\">\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"ico up\"></span>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no2\">2</span><span class=\"jum\">.</span><span class=\"no5\">5</span><span class=\"no7\">7</span>\\n\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"parenthesis1\">(</span><span class=\"ico plus\">+</span>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"no0\">0</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no2\">2</span><span class=\"per\">%</span>\\n\\t\\t\\t\\t\\t\\t\\t<span class=\"parenthesis2\">)</span>\\n\\n\\t\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<table summary=\"ì£¼ìš” ì‹œì„¸(ì „ì¼ì¢…ê°€, ì‹œê³ ì €ê°€, ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ)ì„ ì œê³µí•©ë‹ˆë‹¤.\" class=\"no_info\">\\n\\t\\t\\t\\t<caption>ì£¼ìš” ì‹œì„¸</caption>\\n\\t\\t\\t\\t<colgroup><col width=\"150\"><col><col width=\"154\"></colgroup>\\n\\t\\t\\t\\t<tbody>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail7\">ì „ì¼</span>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no7\">7</span><span class=\"no9\">9</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no4\">4</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail8\">ê³ ê°€</span>\\n\\t\\t\\t\\t\\t<em class=\"no_up\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no7\">7</span><span class=\"no3\">3</span><span class=\"no0\">0</span><span class=\"jum\">.</span><span class=\"no7\">7</span><span class=\"no2\">2</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail9\">52ì£¼ ìµœê³ </span>\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no8\">8</span><span class=\"no6\">6</span><span class=\"no4\">4</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no6\">6</span>\\n\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail10\">ì‹œê°€</span>\\n\\t\\t\\t\\t\\t<em class=\"no_down\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no6\">6</span><span class=\"no8\">8</span><span class=\"jum\">.</span><span class=\"no0\">0</span><span class=\"no7\">7</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<span class=\"detail detail11\">ì €ê°€</span>\\n\\t\\t\\t\\t\\t<em class=\"no_down\">\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no3\">3</span><span class=\"shim\">,</span><span class=\"no6\">6</span><span class=\"no5\">5</span><span class=\"no7\">7</span><span class=\"jum\">.</span><span class=\"no7\">7</span><span class=\"no2\">2</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t<td>\\n\\t\\t\\t\\t\\t<span class=\"detail detail12\">52ì£¼ ìµœì €</span>\\n\\t\\t\\t\\t\\t<em>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<span class=\"no1\">1</span><span class=\"no0\">0</span><span class=\"shim\">,</span><span class=\"no0\">0</span><span class=\"no8\">8</span><span class=\"no8\">8</span><span class=\"jum\">.</span><span class=\"no8\">8</span><span class=\"no3\">3</span>\\n\\t\\t\\t\\t\\t</em>\\n\\t\\t\\t\\t</td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</tbody>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<!-- ë¯¸ë‹ˆ ì¼ì°¨íŠ¸ -->\\n\\t\\t\\t\\t<div class=\"aside_section\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<!-- [D] 130x53 -->\\n\\t\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgfinance/chart/mobile/world/mini/NAS@IXIC.png?sidcode=1365666030675\" class=\"img_graph\" title=\"ë¯¸ë‹ˆ ì¼ì°¨íŠ¸\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<!-- //ë¯¸ë‹ˆ ì¼ì°¨íŠ¸ -->\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- ì°¨íŠ¸ ì»¨íŠ¸ë¡¤ ì˜ì—­ -->\\n\\t\\t\\t<div class=\"chart_control_area\">\\n\\t\\t\\t\\t<dl class=\"line\">\\n\\n\\t\\t\\t\\t<dt>ì„ ì°¨íŠ¸</dt>\\n\\t\\t\\t\\t<dd>\\n\\t\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li class=\"month3\"><a href=\"#\" class=\"on\" onclick=\"showChart(\\'month3\\');\">3ê°œì›”</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year\"><a href=\"#\" onclick=\"showChart(\\'year\\');\">1ë…„</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year3\"><a href=\"#\" onclick=\"showChart(\\'year3\\');\">3ë…„</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year5\"><a href=\"#\" onclick=\"showChart(\\'year5\\');\">5ë…„</a></li>\\n\\t\\t\\t\\t\\t<li class=\"year10\"><a href=\"#\" onclick=\"showChart(\\'year10\\');\">10ë…„</a></li>\\n\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</dd>\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t\\t<dl class=\"bar\">\\n\\t\\t\\t\\t<dt>ë´‰ì°¨íŠ¸</dt>\\n\\t\\t\\t\\t<dd>\\n\\t\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li class=\"day\"><a href=\"#\" onclick=\"showBarChart(\\'day\\');\">ì¼ë´‰</a></li>\\n\\t\\t\\t\\t\\t<li class=\"week\"><a href=\"#\" onclick=\"showBarChart(\\'week\\');\">ì£¼ë´‰</a></li>\\n\\t\\t\\t\\t\\t<li class=\"month\"><a href=\"#\" onclick=\"showBarChart(\\'month\\');\">ì›”ë´‰</a></li>\\n\\t\\t\\t\\t\\t</ul>\\n\\n\\t\\t\\t\\t</dd>\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //ì°¨íŠ¸ ì»¨íŠ¸ë¡¤ ì˜ì—­ -->\\n\\t\\t\\t<!-- ì°¨íŠ¸ -->\\n\\t\\t\\t<div class=\"flash_area\">\\n\\t\\t\\t\\t<img src=\"https://ssl.pstatic.net/imgfinance/chart/world/month3/NAS@IXIC.png?1688741844631\" width=\"700\" alt=\"ì°¨íŠ¸\" onerror=\"this.src=\\'https://ssl.pstatic.net/imgstock/chart3/world2008/error_700x243.gif\\'\" />\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //ì°¨íŠ¸ -->\\n\\n\\t\\t\\t<!-- //í˜„ì¬ ì‹œì„¸ -->\\n\\t\\t\\t<!-- ì¼ë³„,ì‹œê°„ë³„ì‹œì„¸ -->\\n\\t\\t\\t<div class=\"section_quot\">\\n\\t\\t\\t\\t<h3 class=\"h_sise_day\">ì¼ë³„ì‹œì„¸</h3>\\n\\t\\t\\t\\t<!-- [D] ì¼ë³„ì‹œì„¸ : ë§ˆì§€ë§‰ tr ì— .last ì¶”ê°€ -->\\n\\t\\t\\t\\t<table sumary=\"ì¼ë³„ì‹œì„¸ ë¦¬ìŠ¤íŠ¸\" cellpadding=\"0\" cellspacing=\"0\" class=\"tb_status2 tb_status2_t2\" id=\"dayTable\">\\n\\t\\t\\t\\t<caption>ì¼ë³„ì‹œì„¸</caption>\\n\\n\\t\\t\\t\\t<col width=\"87\"><col width=\"124\"><col width=\"118\"><col width=\"124\"><col width=\"124\"><col width=\"124\">\\n\\t\\t\\t\\t<thead>\\n\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td\"><span class=\"blind\">ì¼ì</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td2\"><span class=\"blind\">ì¢…ê°€</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td3\"><span class=\"blind\">ì „ì¼ëŒ€ë¹„</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td4\"><span class=\"blind\">ì‹œê°€</span></th>\\n\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td5\"><span class=\"blind\">ê³ ê°€</span></th>\\n\\t\\t\\t\\t<th scope=\"col\" class=\"tb_td6\"><span class=\"blind\">ì €ê°€</span></th>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t</thead>\\n\\t\\t\\t\\t<tbody>\\n\\t\\t\\t\\t<!-- ì¢…ê°€ë°ì´í„°ê°€ ì•ˆë“¤ì–´ì™”ì„ì‹œ ì²˜ë¦¬ -->\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<tr class=\"point_up\">\\n\\t\\n\\t\\t\\t\\t\\t<td class=\"tb_td\">2023.07.07</td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,681.61</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">2.57</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,668.07</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,730.72</span></td>\\n\\t\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,657.72</span></td>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.06</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,679.04</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">112.61</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,653.17</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,689.52</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,567.26</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.05</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,791.65</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">25.12</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,772.10</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,844.50</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,764.25</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.07.03</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,816.77</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">28.85</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,798.70</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,839.09</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,773.41</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.30</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,787.92</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">196.59</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,719.98</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,816.68</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,716.16</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.29</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,591.33</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">0.42</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,592.36</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,618.53</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,540.26</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.28</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,591.75</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">36.08</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,506.02</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,654.14</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,495.73</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_up \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.27</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,555.67</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">219.89</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,389.25</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,578.80</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,366.97</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn \">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.26</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,335.78</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">156.74</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,468.75</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,573.57</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,334.42</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<tr class=\"point_dn last\">\\n\\n\\t\\t\\t\\t<td class=\"tb_td\">2023.06.23</td>\\n\\t\\t\\t\\t<td class=\"tb_td2\"><span>13,492.52</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td3\"><span class=\"point_status\">138.09</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td4\"><span>13,484.10</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td5\"><span>13,572.19</span></td>\\n\\t\\t\\t\\t<td class=\"tb_td6\"><span>13,442.65</span></td>\\n\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t</tbody>\\n\\t\\t\\t\\t</table>\\n\\t\\t\\t\\t<div class=\"paging\" id=\"dayPaging\">\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink1\" class=\"on\" onClick=\"moveDayPaging(1, false, event); return false\">1</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink2\"  onClick=\"moveDayPaging(2, false, event); return false\">2</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink3\"  onClick=\"moveDayPaging(3, false, event); return false\">3</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink4\"  onClick=\"moveDayPaging(4, false, event); return false\">4</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink5\"  onClick=\"moveDayPaging(5, false, event); return false\">5</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink6\"  onClick=\"moveDayPaging(6, false, event); return false\">6</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink7\"  onClick=\"moveDayPaging(7, false, event); return false\">7</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink8\"  onClick=\"moveDayPaging(8, false, event); return false\">8</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink9\"  onClick=\"moveDayPaging(9, false, event); return false\">9</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" id=\"dayLink10\"  onClick=\"moveDayPaging(10, false, event); return false\">10</a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t <a href=\"#\" class=\"next\" onClick=\"moveDayPaging(11, true, event); return false\">ë‹¤ìŒ <img src=\"https://ssl.pstatic.net/static/nfinance/bu_pgarR.gif\" width=\"3\" height=\"5\" alt=\"ë‹¤ìŒ\"></a>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t\\t<!-- //ì¼ë³„,ì‹œê°„ë³„ì‹œì„¸ -->\\n\\t\\t</div>\\n\\t\\t<!-- [D] ë¯¸ë‹ˆ ì¼ì°¨íŠ¸ê°€ ìˆì„ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ style ì¶”ê°€ -->\\n\\t\\t<div id=\"world_end\" class=\"aside\" style=\"padding-top:99px\">\\n\\t\\t\\t<div class=\"aside_world_end\">\\n\\t\\t\\t\\t<h3 class=\"h_info_relative\"><span>ê´€ë ¨ì •ë³´</span></h3>\\n\\t\\t\\t\\t<dl class=\"info_aside\">\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<!-- ì¢…ëª©ì˜ ê²½ìš°ì—ë§Œ í¸ì…ì§€ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤. -->\\n\\t\\t\\t\\t\\n\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t<dt class=\"dt5\"><span class=\"blind\">ê±°ë˜ì†Œ</span></dt>\\n\\t\\t\\t\\t<dd><span>NASDAQ Stock Market</span></dd>\\n\\t\\t\\t\\t<dt class=\"dt7\"><span class=\"blind\">ê¸°ì¤€í†µí™”</span></dt>\\n\\t\\t\\t\\t<dd><span>USD</span></dd>\\n\\t\\t\\t\\t<dt class=\"dt6\"><span class=\"blind\">ê±°ë˜ì‹œê°„(í•œêµ­ì‹œê°„ ê¸°ì¤€)</span></dt>\\n\\t\\t\\t\\t<dd><span>23:30~06:00<br>ì„œë¨¸íƒ€ì„ 22:30~05:00</span></dd>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t \\n\\t\\t\\t\\t<dt class=\"dt8\"><span class=\"blind\">ì§€ìˆ˜ ì„¤ëª…</span></dt>\\n\\t\\t\\t\\t<dd class=\"dd3\">í•˜ì´í…Œí¬Â·ì¤‘ì†Œê¸°ì—…ì˜ ì£¼ì‹ì„ ì¥ì™¸ì—ì„œ ê±°ë˜í•˜ëŠ” ë‚˜ìŠ¤ë‹¥ ì‹œì¥ì˜ ì¢…í•©ì§€ìˆ˜<br><a href=\"http://terms.naver.com/entry.nhn?docId=1192561&cid=200000000&categoryId=200000418\" target=\"blank\">\\n\\t\\t\\t\\të„¤ì´ë²„ ì§€ì‹ë°±ê³¼\\n\\t\\t\\t\\t</a></dd>\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t</dl>\\n\\t\\t\\t</div>\\n\\t\\t\\t\\n\\t\\t\\t<script>\\nfunction fnShowOn(onId){\\n\\tdocument.getElementById(onId).style.display=\"block\";\\n}\\nfunction fnShowOff(offId){\\n\\tdocument.getElementById(offId).style.display=\"none\";\\n}\\n</script>\\n\\n\\t\\n\\t\\n\\n\\n\\t\\n\\n\\t\\n\\t<!-- Type3 [í•´ì™¸ì¦ì‹œ ì¢…ëª©í˜ì´ì§€] -->\\n\\t\\t<!-- ìµœê·¼ì¡°íšŒì¢…ëª© -->\\n\\t\\t<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/util.js\"></script>\\n<script type=\"text/javascript\" src=\"https://ssl.pstatic.net/imgstock/static.pc/20230704202526/js/myStock.js\"></script>\\n\\n\\t\\n\\t\\n\\t\\t\\n\\t\\n\\n\\n<div class=\"section_aside\">\\n\\t<div class=\"tab_search search3\">\\n\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.1\\', \\'\\', \\'\\', event); return false;\"><span>ìµœê·¼ì¡°íšŒ</span></a>\\n\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.3\\', \\'\\', \\'\\', event); return false;\"><span>MY STOCK</span></a>\\n\\t</div>\\n\\t<table class=\"tbl_search\" summary=\"ìµœê·¼ì¡°íšŒ ë¦¬ìŠ¤íŠ¸\">\\n\\t\\t<caption>ìµœê·¼ì¡°íšŒ</caption>\\n\\t\\t<colgroup>\\n\\t\\t\\t<col width=\"65\">\\n\\t\\t\\t<col width=\"55\">\\n\\t\\t\\t<col width=\"80\">\\n\\t\\t</colgroup>\\n\\t\\t<thead>\\n\\t\\t<tr>\\n\\t\\t\\t<th>ì—…ì²´ëª…</th>\\n\\t\\t\\t<th>ê±°ë˜ëŸ‰</th>\\n\\t\\t\\t<th>ì „ì¼ë¹„</th>\\n\\t\\t</tr>\\n\\t\\t</thead>\\n\\t\\t<tbody>\\n\\t\\t</tbody>\\n\\t</table>\\n\\t<div class=\"more_info\">\\n\\t\\t<span>\\n\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.5\\', \\'\\', \\'\\', event); return false;\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_prev2.gif\" width=\"17\" height=\"15\" alt=\"ì´ì „\"></a>\\n\\t\\t\\t<a href=\"#\" onclick=\"clickcr(this, \\'rch.6\\', \\'\\', \\'\\', event); return false;\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_next2.gif\" width=\"17\" height=\"15\" alt=\"ë‹¤ìŒ\"></a>\\n\\t\\t</span>\\n\\t\\t<a href=\"#\" onclick=\"javascript:openMyitemNew(\\'https://finance.naver.com\\'); clickcr(this, \\'rch.7\\', \\'\\', \\'\\', event);\" class=\"btn_more _mystock_more_info\"><img src=\"https://ssl.pstatic.net/static/nfinance/btn_more5.gif\" width=\"33\" height=\"10\" alt=\"ë”ë³´ê¸°\"></a>\\n\\t</div>\\n</div>\\n\\n<script type=\"text/javascript\" language=\"javascript\">\\n\\tfunction initMyStock() {\\n\\t\\tgetStockRightMenuData(\\'000000\\', \\'recent\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\');\\n\\n\\t\\tvar tabSearchArea = jindo.$$.getSingle(\\'.tab_search\\');\\n\\t\\tvar moreInfoArea = jindo.$Element(jindo.$$.getSingle(\\'.tbl_search\\')).next().$value();\\n\\n\\t\\tjindo.$Fn(function(e) {toggleTabSearch(e); getStockRightMenuData(\\'000000\\', \\'recent\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$.getSingle(\\'a\\' ,tabSearchArea), \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {toggleTabSearch(e); getStockRightMenuData(\\'000000\\', \\'mystock\\', 1, \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$(\\'a\\' ,tabSearchArea)[1], \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {updatePageForPaging (currentType, \\'up\\', \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$.getSingle(\\'a\\', moreInfoArea), \\'click\\');\\n\\t\\tjindo.$Fn(function(e) {updatePageForPaging (currentType, \\'down\\', \\'https://finance.naver.com\\', \\'https://ssl.pstatic.net/static/nfinance\\'); }).attach(jindo.$$(\\'a\\', moreInfoArea)[1], \\'click\\');\\n\\t}\\n\\n\\tfunction toggleTabSearch(e){\\n\\t\\tvar currentElement = jindo.$Element(jindo.$Event(e).currentElement);\\n\\t\\tvar parentElement = currentElement.parent();\\n\\t\\tvar id = currentElement.className();\\n\\t\\tvar order = parentElement.indexOf(currentElement) + 3;\\n\\t\\tparentElement.className(\"tab_search search\"+ order);\\n\\n\\t\\t// í˜ì´ì§•ì„ ìœ„í•´ì„œ orderê°’ì— ë”°ë¼ ìµœê·¼ì¡°íšŒì¸ì§€ mystockì¸ì§€ typeì„ ì €ì¥\\n\\t\\tif (order == 1) {\\n\\t\\t\\tcurrentType = \"recent\";\\n\\t\\t} else {\\n\\t\\t\\tcurrentType = \"mystock\";\\n\\t\\t}\\n\\t}\\n\\n\\tjindo.$Fn(initMyStock).attach(document, \"domready\");\\n\\n\\tfunction openMyitemNew(stockHost) {\\n\\t\\tvar selectedElement = jindo.$Element(jindo.$$.getSingle(\".tab_search\"));\\n\\t\\tif (selectedElement != null) {\\n\\t\\t\\tif (selectedElement.hasClass(\"search1\")) {\\n\\t\\t\\t\\tdocument.location.href = stockHost + \\'/mystock/recentSearchItemList.naver\\';\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tdocument.location.href = stockHost + \\'/mystock/itemList.naver\\';\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n\\t//initMyStock();\\n</script>\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\t\\n\\n\\n\\t\\t</div>\\n\\t</div>\\n<script language=\"javascript\" type=\"text/JavaScript\" src=\"/js/worldIndex.js\"></script>\\n<script language=\"javascript\" type=\"text/JavaScript\">\\nvar sSymbol = \"NAS@IXIC\";\\nvar sFdtc = \"0\";\\nvar nMaxTimePage = 0;\\nvar nMaxDayPage = 542;\\nvar nMaxIncludePage = 0;\\nvar sIncludeItemMenuId = \"\";\\n\\nvar nCurTimePage = 1;\\nvar nCurDayPage = 1;\\nvar nCurIncludePage = 1;\\nvar sCurIncludeDirection = \"up\";\\nvar sCurIncludeSort = \"knam\";\\nvar sDayHtmlFormat = \"<td class=\\\\\"tb_td\\\\\">%s</td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td2\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td3\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td4\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td5\\\\\"><span>%s</span></td>\"\\n\\t\\t+ \"<td class=\\\\\"tb_td6\\\\\"><span>%s</span></td>\";\\nvar sDefaultDayHtml = null;\\nvar sDefaultDayPointClass = null;\\n\\nfunction initWorld() {\\n\\t\\n}\\n\\nfunction initsDefaultDayHtml() {\\n\\tvar nDiff = 2.57;\\n\\tvar sDiff = formatNumberForFinance(\"2.57\", false);\\n\\tvar sXymd = \"20230707\".substr(0, 4) + \".\" + \"20230707\".substr(4, 2) + \".\" + \"20230707\".substr(6, 2);\\n\\tvar sClos = formatNumberForFinance(\"13681.61\", false);\\n\\tvar sOpen = formatNumberForFinance(\"13668.07\", false);\\n\\tvar sHigh = formatNumberForFinance(\"13730.72\", false);\\n\\tvar sLow = formatNumberForFinance(\"13657.72\", false);\\n\\t\\n\\tsDefaultDayPointClass = \"\";\\n\\t\\n\\tif (nDiff > 0) {\\n\\t\\tsDefaultDayPointClass = \"point_up\";\\n\\t} else if (nDiff < 0) {\\n\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\tsDefaultDayPointClass = \"point_dn\";\\n\\t}\\n\\t\\n\\tsDefaultDayHtml = jindo.$S(sDayHtmlFormat).format(sXymd, sClos, sDiff, sOpen, sHigh, sLow);\\n}\\n\\njindo.$Fn(initWorld).attach(document, \"domready\");\\n\\n// ì¼ë³„ì‹œì„¸ í˜ì´ì§• ì´ë™\\nfunction moveDayPaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\tif (sDefaultDayHtml == null) {\\n\\t\\tinitsDefaultDayHtml();\\n\\t}\\n\\n\\t// í˜„ì¬í˜ì´ì§€ì™€ ë‹¤ë¥¸ ë§í¬ë¥¼ ëˆŒë €ì„ ê²½ìš°ì—ë§Œ Ajaxë¡œ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¨ë‹¤.\\n\\tif (nCurDayPage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\tvar url = \"/world/worldDayListJson.naver?symbol=\" + sSymbol + \"&fdtc=\" + sFdtc + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"dayTable\");\\n\\t\\t\\t\\t\\n\\t\\t\\t// tr ì „ë¶€ ì‚­ì œ\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sXymd = v.xymd.substr(0, 4) + \".\" + v.xymd.substr(4, 2) + \".\" + v.xymd.substr(6, 2);\\n\\t\\t\\t\\tvar sClos = formatNumberForFinance(v.clos, false);\\n\\t\\t\\t\\tvar sOpen = formatNumberForFinance(v.open, false);\\n\\t\\t\\t\\tvar sHigh = formatNumberForFinance(v.high, false);\\n\\t\\t\\t\\tvar sLow = formatNumberForFinance(v.low, false);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sDayHtmlFormat).format(sXymd, sClos, sDiff, sOpen, sHigh, sLow);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\n\\t\\t\\tif (nPage == 1 && jindo.$A(json).length() < 10) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tjindo.$Element(elTr).html(sDefaultDayHtml);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sDefaultDayPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sDefaultDayPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// ìƒˆë¡œ í˜ì´ì§•ì„ ì œì‘\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"dayPaging\", \"dayLink\", moveDayPaging, nPage, nMaxDayPage);\\n\\t\\tnCurDayPage = nPage;\\n\\t} else {\\n\\t\\tjindo.$Element(\"dayLink\" + nCurDayPage).removeClass(\"on\");\\n\\t\\tjindo.$Element(\"dayLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurDayPage = nPage;\\n\\t}\\n}\\n\\n// ì‹œê°„ë³„ ì‹œì„¸ í˜ì´ì§• ì´ë™\\nfunction moveTimePaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\t// í˜„ì¬í˜ì´ì§€ì™€ ë‹¤ë¥¸ ë§í¬ë¥¼ ëˆŒë €ì„ ê²½ìš°ì—ë§Œ Ajaxë¡œ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¨ë‹¤.\\n\\tif (nCurTimePage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\tvar url = \"/world/worldTimeListJson.naver?symbol=\" + sSymbol + \"&fdtc=\" + sFdtc + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"timeTable\");\\n\\t\\t\\tvar sHtmlFormat = \"<td class=\\\\\"tb_td11\\\\\">%s</td><td class=\\\\\"tb_td12\\\\\"><span>%s</span></td><td class=\\\\\"tb_td13\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td14\\\\\"><span class=\\\\\"point_status\\\\\">%s%</span></td><td class=\\\\\"tb_td15\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\n\\t\\t\\t// tr ì „ë¶€ ì‚­ì œ\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sXhms = v.xhms.substr(0, 2) + \":\" + v.xhms.substr(2, 2);\\n\\t\\t\\t\\tvar sLast = formatNumberForFinance(v.last, false);\\n\\t\\t\\t\\tvar sRate = formatNumberForFinance(v.rate, true);\\n\\t\\t\\t\\tvar sGvol = formatNumberForFinance(v.gvol, false);\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tsGvol = sGvol.substr(0, sGvol.length - 3);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sHtmlFormat).format(sXhms, sLast, sDiff, sRate, sGvol);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// ìƒˆë¡œ í˜ì´ì§•ì„ ì œì‘\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"timePaging\", \"timeLink\", moveTimePaging, nPage, nMaxTimePage);\\n\\t\\tnCurTimePage = nPage;\\n\\t} else {\\n\\t\\tjindo.$Element(\"timeLink\" + nCurTimePage).removeClass(\"on\");\\n\\t\\tjindo.$Element(\"timeLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurTimePage = nPage;\\n\\t}\\n}\\n\\t\\nfunction sortInclude(sOrdering, sDirection, sBtnId, e) {\\n\\tsCurIncludeDirection = sDirection;\\n\\tsCurIncludeSort = sOrdering;\\n\\tvar elSelectedBtn = jindo.$(sBtnId);\\n\\t\\n\\tjindo.$A(jindo.$$(\"table th button\")).forEach(function (v, i) {\\n\\t\\tvar welCurBtn = jindo.$Element(v);\\n\\t\\t\\n\\t\\tif (welCurBtn.attr(\"id\").indexOf(sBtnId) != -1) {\\n\\t\\t\\twelCurBtn.removeClass(\"asc\");\\n\\t\\t\\twelCurBtn.removeClass(\"desc\");\\n\\t\\t} else {\\n\\t\\t\\twelCurBtn.removeClass(\"asc\");\\n\\t\\t\\twelCurBtn.removeClass(\"desc\");\\n\\t\\t}\\n\\t});\\n\\t\\n\\tvar sToggledDirection;\\n\\tif (sDirection.indexOf(\"up\") != -1) {\\n\\t\\tjindo.$Element(elSelectedBtn).addClass(\"asc\");\\n\\t\\tsToggledDirection = \"down\";\\n\\t} else {\\n\\t\\tjindo.$Element(elSelectedBtn).addClass(\"desc\");\\n\\t\\tsToggledDirection = \"up\";\\n\\t}\\n\\t\\n\\tjindo.$Fn.freeElement(elSelectedBtn);\\n\\tjindo.$Fn(jindo.$Fn(sortInclude, this).bind(sOrdering, sToggledDirection, sBtnId)).attach(elSelectedBtn, \"click\");\\n\\t\\n\\tif (nCurIncludePage < 11) {\\n\\t\\tif (nCurIncludePage == 1) {\\n\\t\\t\\tnCurIncludePage = 2;\\n\\t\\t}\\n\\t\\tmoveIncludePaging(1, false, e);\\n\\t} else {\\n\\t\\tmoveIncludePaging(1, true, e);\\n\\t}\\n\\t\\n}\\n\\n// í¸ì…ì§€ìˆ˜ í˜ì´ì§• ì´ë™\\nfunction moveIncludePaging(nPage, bRenewPaging, e) {\\n\\tjindo.$Event(e).stop();\\n\\t\\n\\t// í˜„ì¬í˜ì´ì§€ì™€ ë‹¤ë¥¸ ë§í¬ë¥¼ ëˆŒë €ì„ ê²½ìš°ì—ë§Œ Ajaxë¡œ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¨ë‹¤.\\n\\tif (nCurIncludePage == nPage) {\\n\\t\\treturn ;\\n\\t}\\n\\n\\tvar url = \"/world/worldIncludeListJson.naver?includeItemMenuId=\" + sIncludeItemMenuId + \"&direction=\" + sCurIncludeDirection + \"&ordering=\" + sCurIncludeSort + \"&page=\" + nPage;\\n\\t//var url = \"/world/worldIncludeListJson.naver?includeItemMenuId=USA_ITEM_1&direction=up&ordering=knam&page=2\";\\n\\tjindo.$Ajax(url, {\\n\\t\\tonload : function(res) {\\n\\t\\t\\tvar json = res.json();\\n\\t\\t\\tvar elTable = jindo.$(\"includeTable\");\\n\\t\\t\\tvar sHtmlFormat = \"<td class=\\\\\"tb_td\\\\\"><a href=\\\\\"/world/sise.naver?symbol=%s\\\\\">%s</a></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td2\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td3\\\\\"><span class=\\\\\"point_status\\\\\">%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td4\\\\\"><span class=\\\\\"point_status\\\\\">%s%</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td5\\\\\"><span>%s</span></td>\"\\n\\t\\t\\t\\t+ \"<td class=\\\\\"tb_td6\\\\\"><span>%s</span></td>\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t// tr ì „ë¶€ ì‚­ì œ\\n\\t\\t\\tjindo.$A(jindo.$$(\"tr\", elTable)).forEach(function (v, i) {\\n\\t\\t\\t\\tif (i > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTable).remove(v);\\n\\t\\t\\t\\t}\\n\\t\\t\\t});\\n\\t\\t\\t\\t\\n\\t\\t\\tjindo.$A(json).reverse().forEach(function(v, i) {\\n\\t\\t\\t\\tvar elTr = jindo.$$.getSingle(\"tbody\", elTable).insertRow(0);\\n\\t\\t\\t\\tvar sSymb = v.symb;\\n\\t\\t\\t\\tvar sKnam = v.knam;\\n\\t\\t\\t\\tvar nDiff = v.diff + 0;\\n\\t\\t\\t\\tvar sDiff = formatNumberForFinance(v.diff, false);\\n\\t\\t\\t\\tvar sRate = formatNumberForFinance(v.rate, true);\\n\\t\\t\\t\\tvar sLast = formatNumberForFinance(v.last, false);\\n\\t\\t\\t\\tvar sGvol = formatNumberForFinance(v.gvol, false);\\n\\t\\t\\t\\tvar sTotAmt = formatNumberForFinance(v.totAmt, false);\\n\\t\\t\\t\\tvar sPointClass = \"\";\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tsGvol = sGvol.substr(0, sGvol.length - 3);\\n\\t\\t\\t\\tsTotAmt = sTotAmt.substr(0, sTotAmt.length - 3);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (nDiff > 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_up\";\\n\\t\\t\\t\\t} else if (nDiff < 0) {\\n\\t\\t\\t\\t\\tsPointClass = \"point_dn\";\\n\\t\\t\\t\\t\\tsDiff = sDiff.replace(\"-\", \"\");\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tvar html = jindo.$S(sHtmlFormat).format(sSymb, sKnam, sLast, sDiff, sRate, sGvol, sTotAmt);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tjindo.$Element(elTr).html(html);\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tif (sPointClass.length > 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(sPointClass);\\n\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\tif (i == 0) {\\n\\t\\t\\t\\t\\tjindo.$Element(elTr).addClass(\"last\");\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t}).request();\\n\\t\\n\\t// ìƒˆë¡œ í˜ì´ì§•ì„ ì œì‘\\n\\tif (bRenewPaging) {\\n\\t\\tmakePaging(\"includePaging\", \"includeLink\", moveIncludePaging, nPage, nMaxIncludePage);\\n\\t\\tnCurIncludePage = nPage;\\n\\t} else {\\n\\t\\tvar welCurLink = jindo.$Element(\"includeLink\" + nCurIncludePage);\\n\\t\\tif (welCurLink != null) {\\n\\t\\t\\twelCurLink.removeClass(\"on\");\\n\\t\\t}\\n\\t\\tjindo.$Element(\"includeLink\" + nPage).addClass(\"on\");\\n\\t\\t\\n\\t\\tnCurIncludePage = nPage;\\n\\t}\\n}\\n\\t\\n// í˜ì´ì§•ì„ ìƒˆë¡œ ìƒì„±í•´ì£¼ëŠ” ê³µí†µí•¨ìˆ˜\\nfunction makePaging(pagingId, linkId, func, nPage, nMax) {\\n\\tvar welPaging = jindo.$Element(pagingId);\\n\\tvar sPrevFormat = \"<img src=\\\\\"https://ssl.pstatic.net/static/nfinance/bu_pgarL.gif\\\\\" width=\\\\\"3\\\\\" height=\\\\\"5\\\\\" alt=\\\\\"ì´ì „\\\\\"> ì´ì „\";\\n\\tvar sNextFormat = \"ë‹¤ìŒ <img src=\\\\\"https://ssl.pstatic.net/static/nfinance/bu_pgarR.gif\\\\\" width=\\\\\"3\\\\\" height=\\\\\"5\\\\\" alt=\\\\\"ë‹¤ìŒ\\\\\">\";\\n\\n\\t// ì‚­ì œ í›„ ì‚½ì…\\n\\twelPaging.html(\"\");\\n\\t\\n\\t// ì´ì „\\n\\tif (nPage > 10) {\\n\\t\\tvar welPrev = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelPrev.addClass(\"prev\");\\n\\t\\twelPrev.attr(\"href\", \"#\");\\n\\t\\tvar nPrevPage;\\n\\t\\tif (nPage % 10 == 0) {\\n\\t\\t\\tnPrevPage = nPage - 10;\\n\\t\\t} else {\\n\\t\\t\\tnPrevPage = nPage - 1;\\n\\t\\t}\\n\\n\\t\\tjindo.$Fn(jindo.$Fn(func).bind(nPrevPage, true)).attach(welPrev, \"click\");\\n\\t\\twelPrev.html(jindo.$S(sPrevFormat).format());\\n\\t\\t\\n\\t\\twelPaging.append(welPrev);\\n\\t}\\n\\t\\n\\t// í˜ì´ì§€\\n\\tvar nStart;\\n\\tvar nEnd;\\n\\t\\n\\tif (nPage % 10 == 0) {\\n\\t\\tnStart = nPage - 9;\\n\\t} else {\\n\\t\\tnStart = nPage; \\n\\t}\\n\\t\\n\\tif (nMax - nStart > 9) {\\n\\t\\tnEnd = nStart + 9;\\n\\t} else {\\n\\t\\tnEnd = nMax;\\n\\t}\\n\\t\\n\\tfor (var i = nStart; i <= nEnd; i++) {\\n\\t\\tvar welPage = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelPage.text(i + \"\");\\n\\t\\twelPage.attr(\"href\", \"#\");\\n\\t\\twelPage.attr(\"id\", linkId + i);\\n\\t\\twelPage.attr(\"tojson\", \"\");\\n\\t\\tjindo.$Fn(jindo.$Fn(func, this).bind(i, false), this).attach(welPage, \"click\");\\n\\t\\t\\n\\t\\tif (i == nPage) {\\n\\t\\t\\twelPage.addClass(\"on\");\\n\\t\\t}\\n\\t\\t\\n\\t\\twelPaging.append(welPage);\\n\\t}\\n\\t\\n\\t// ë‹¤ìŒ\\n\\tvar bMakeNext = false;\\n\\tif (nPage % 10 == 1) {\\n\\t\\tbMakeNext = nMax >= nPage + 10;\\n\\t} else if (nPage % 10 == 0){\\n\\t\\tbMakeNext = nMax - nPage > 0;\\n\\t}\\n\\t\\n\\tif (bMakeNext) {\\n\\t\\tvar welNext = jindo.$Element(jindo.$(\"<a></a>\"));\\n\\t\\t\\n\\t\\twelNext.addClass(\"next\");\\n\\t\\twelNext.attr(\"href\", \"#\");\\n\\t\\tvar nNextPage;\\n\\t\\tif (nPage % 10 == 0) {\\n\\t\\t\\tnNextPage = nPage + 1;\\n\\t\\t} else {\\n\\t\\t\\tnNextPage = nPage + 10;\\n\\t\\t}\\n\\n\\t\\tjindo.$Fn(jindo.$Fn(func).bind(nNextPage, true)).attach(welNext, \"click\");\\n\\t\\twelNext.html(jindo.$S(sNextFormat).format());\\n\\n\\t\\twelPaging.append(welNext);\\t\\n\\t}\\n}\\n\\n// ì¼ë³„ì‹œì„¸ ë…¸ì¶œ\\nfunction showDayQuoteList() {\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_day a\")).addClass(\"on\");\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_time a\")).removeClass(\"on\");\\n\\tjindo.$Element(\"dayTable\").show();\\n\\tjindo.$Element(\"timeTable\").hide();\\n\\tjindo.$Element(\"dayPaging\").show();\\n\\tjindo.$Element(\"timePaging\").hide();\\n}\\n\\n// ì‹œê°„ë³„ì‹œì„¸ ë…¸ì¶œ\\nfunction showTimeQuoteList() {\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_day a\")).removeClass(\"on\");\\n\\tjindo.$Element(jindo.$$.getSingle(\"li.btn_time a\")).addClass(\"on\");\\n\\tjindo.$Element(\"dayTable\").hide();\\n\\tjindo.$Element(\"timeTable\").show();\\n\\tjindo.$Element(\"dayPaging\").hide();\\n\\tjindo.$Element(\"timePaging\").show();\\n}\\n\\n// ì„  ì°¨íŠ¸ ë…¸ì¶œ\\nfunction showChart(target) {\\n\\tvar directory = \"\";\\n\\t\\n\\tif (target == \"day\") {\\n\\t\\tdirectory = \"daily\";\\n\\t} else if (target == \"week\") {\\n\\t\\tdirectory = \"weekly\";\\n\\t} else if (target.indexOf(\"month\") == 0 || target.indexOf(\"year\") == 0) {\\n\\t\\tdirectory = target;\\n\\t}\\n\\t\\n\\tjindo.$A(jindo.$$(\"dl.line dd ul li\")).forEach(function(v) {\\n\\t\\tif (jindo.$Element(v).className() == target) {\\n\\t\\t\\tjindo.$Element(v).child()[0].addClass(\"on\");\\n\\t\\t\\tvar welChart = jindo.$Element(jindo.$$.getSingle(\"div.flash_area img\"));\\n\\t\\t\\twelChart.attr(\"src\", \"https://ssl.pstatic.net/imgfinance/chart/world/\" + directory + \"/NAS@IXIC.png?1688741844631\");\\n\\t\\t} else {\\n\\t\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t\\t}\\n\\t});\\n\\n\\tjindo.$A(jindo.$$(\"dl.bar dd ul li\")).forEach(function(v) {\\n\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t});\\n\\t\\n}\\n\\n// ë´‰ ì°¨íŠ¸ ë…¸ì¶œ\\nfunction showBarChart(target) {\\n\\tjindo.$A(jindo.$$(\"dl.bar dd ul li\")).forEach(function(v) {\\n\\t\\tif (jindo.$Element(v).className() == target) {\\n\\t\\t\\tjindo.$Element(v).child()[0].addClass(\"on\");\\n\\t\\t\\tvar welChart = jindo.$Element(jindo.$$.getSingle(\"div.flash_area img\"));\\n\\t\\t\\twelChart.attr(\"src\", \"https://ssl.pstatic.net/imgfinance/chart/world/candle/\" + target + \"/NAS@IXIC.png?1688741844631\");\\n\\t\\t} else {\\n\\t\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t\\t}\\n\\t});\\n\\n\\tjindo.$A(jindo.$$(\"dl.line dd ul li\")).forEach(function(v) {\\n\\t\\tjindo.$Element(v).child()[0].removeClass(\"on\");\\n\\t});\\n}\\n</script>\\n\\t<!-- Footer -->\\n\\t<div id=\"footer\">\\n\\t<ul>\\n\\t\\t<li class=\"first\">\\n\\t\\t\\t<a href=\"https://new-m.pay.naver.com/member/terms-policy/naver-financial-service\" onClick=\"clickcr(this, \\'fot.service\\', \\'\\', \\'\\', event);\" target=\"_blank\">ì´ìš©ì•½ê´€</a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"https://new-m.pay.naver.com/member/terms-policy/privacy\" onClick=\"clickcr(this, \\'fot.privacy\\', \\'\\', \\'\\', event);\" target=\"_blank\"><strong>ê°œì¸ì •ë³´ì²˜ë¦¬ë°©ì¹¨</strong></a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"/rules.naver\" onClick=\"clickcr(this, \\'fot.policy\\', \\'\\', \\'\\', event);\" target=\"_blank\">ê²Œì‹œíŒ ìš´ì˜ì›ì¹™</a>\\n\\t\\t</li>\\n\\t\\t<li>\\n\\t\\t\\t<a href=\"https://help.naver.com/service/5617/category/bookmark?lang=ko\" onClick=\"clickcr(this, \\'fot.help\\', \\'\\', \\'\\', event);\" target=\"_blank\">ì¦ê¶Œ ê³ ê°ì„¼í„°</a>\\n\\t\\t</li>\\n\\t</ul>\\n\\t<p class=\"desc\">\\n\\t\\të„¤ì´ë²„íŒŒì´ë‚¸ì…œ(ì£¼)ì´ ì œê³µí•˜ëŠ” ê¸ˆìœµ ì •ë³´ëŠ” <a href=\"javascript:;\" onclick=\"togglePanelFooter(\\'footerPanel0\\');\" class=\"desc_help\">ì½˜í…ì¸  ì œê³µì—…ì²´</a>ë¡œë¶€í„° ë°›ëŠ” íˆ¬ì ì°¸ê³ ì‚¬í•­ì´ë©°, ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê±°ë‚˜ ì§€ì—°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\\n\\t\\të„¤ì´ë²„íŒŒì´ë‚¸ì…œ(ì£¼)ê³¼ ì½˜í…ì¸  ì œê³µì—…ì²´ëŠ” ì œê³µëœ ì •ë³´ì— ì˜í•œ íˆ¬ì ê²°ê³¼ì— ë²•ì ì¸ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ê²Œì‹œëœ ì •ë³´ëŠ” ë¬´ë‹¨ìœ¼ë¡œ ë°°í¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\n\\t</p>\\n\\t<div id=\"footerPanel0\" class=\"provider_layer\" style=\"display:none\" tabindex=\"0\" onblur=\"hidePannel(\\'footerPanel0\\')\">\\n\\t\\t<strong class=\"provider_layer__tit\">ë„¤ì´ë²„íŒŒì´ë‚¸ì…œì— ì½˜í…ì¸  ì œê³µ</strong>\\n\\t\\t<div class=\"provider_layer__txt\">\\n\\t\\t\\t<strong>ì—í”„ì•¤ê°€ì´ë“œ</strong> ê¸°ì—… ë° ì¬ë¬´ì •ë³´<br>\\n\\t\\t\\t<strong>KGì œë¡œì¸</strong> í•´ì™¸ ì‹œì„¸, ì‹œì¥ì§€í‘œ ì •ë³´<br>\\n\\t\\t\\t<strong>í•œêµ­ì˜ˆíƒê²°ì œì›</strong> ì£¼ì£¼ì´íšŒì¼, ì „ìíˆ¬í‘œ ì •ë³´<br>\\n\\t\\t\\t<strong>ì¸í¬ìŠ¤íƒ</strong> êµ­ë‚´ í…Œë§ˆ ì •ë³´\\n\\t\\t</div>\\n\\t\\t<div class=\"provider_layer__info\">\\n\\t\\t\\t<strong class=\"provider_layer__tit\">ë„¤ì´ë²„ì— ì½˜í…ì¸  ì œê³µ</strong>\\n\\t\\t\\t<div class=\"provider_layer__txt\">\\n\\t\\t\\t\\t<strong>ì½”ìŠ¤ì½¤</strong> êµ­ë‚´ ì‹œì„¸ ì •ë³´\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\t<button type=\"button\" class=\"button_close\" onclick=\"hidePannel(\\'footerPanel0\\')\">\\n\\t\\t\\t<img src=\"https://ssl.pstatic.net/static/nfinance/2022/footer_close.png\" width=\"20\" height=\"20\" alt=\"ë‹«ê¸°\">\\n\\t\\t</button>\\n\\t</div>\\n\\t<address>\\n\\t\\t<a href=\"http://www.navercorp.com/\" target=\"_blank\" class=\"logo\" onClick=\"clickcr(this, \\'fot.nhn\\', \\'\\', \\'\\', event);\"><img src=\"https://ssl.pstatic.net/static/nfinance/img/logo_financial.png\" width=\"160\" height=\"12\" alt=\"NAVER FINANCIAL\"></a>\\n\\t</address>\\n\\t\\n\\t\\n\\t\\n</div>\\n\\n<script type=\"text/javascript\">\\nfunction isVisible(obj) {\\n    if (obj == document) return true\\n \\n    if (!obj) return false\\n    if (!obj.parentNode) return false\\n    if (obj.style) {\\n        if (obj.style.display == \\'none\\') return false\\n        if (obj.style.visibility == \\'hidden\\') return false\\n    }\\n \\n    if (window.getComputedStyle) {\\n        var style = window.getComputedStyle(obj, \"\")\\n        if (style.display == \\'none\\') return false\\n        if (style.visibility == \\'hidden\\') return false\\n    }\\n \\n    var style = obj.currentStyle\\n    if (style) {\\n        if (style[\\'display\\'] == \\'none\\') return false\\n        if (style[\\'visibility\\'] == \\'hidden\\') return false\\n    }\\n \\n    return isVisible(obj.parentNode)\\n}\\n\\nfunction isChildOf(myobj, containerObj) {\\n\\twhile(myobj != undefined) {\\n\\t\\tif (myobj == document.body) {\\n\\t\\t\\tbreak;\\n\\t\\t} \\n\\t\\tif (myobj == containerObj) {\\n\\t\\t\\treturn true;\\n\\t\\t}\\n\\t\\tmyobj = myobj.parentElement;\\n\\t}\\n\\treturn false;\\t\\n}\\n\\nfunction gnbLayerClose(e){\\n\\tvar target = e.target ? e.target : e.srcElement;\\n\\tif (isVisible(document.getElementById(\\'gnb_service_lyr\\')) || isVisible(document.getElementById(\\'gnb_notice_lyr\\')) ||isVisible(document.getElementById(\\'gnb_my_lyr\\')) ) {\\n\\t\\tif (!isChildOf(target, document.getElementById(\\'gnb\\'))) {\\n\\t\\t\\tgnbAllLayerClose();\\n\\t\\t}\\n\\t}\\t\\n}\\n\\nfunction showPannel(layerId){\\n\\tvar layer = jindo.$(layerId);\\n\\tlayer.style.display=\\'block\\';\\n\\n\\tif (layerId == \"summary_lyr\") {\\n\\t\\tvar layerHeight = jindo.$Element(layer).height();\\n\\t\\tjindo.$Element(\"summary_ifr\").height(layerHeight);\\n\\t}\\n}\\n\\nfunction hidePannel(layerId){\\n\\tvar layer = jindo.$(layerId);\\n\\tlayer.style.display=\\'none\\';\\n}\\n\\nfunction togglePanelFooter(layerId) {\\n\\tvar elTargetLayer = jindo.$Element(jindo.$$.getSingle(\"#\" + layerId));\\n\\n\\tif (elTargetLayer != null) {\\n\\t\\tif (elTargetLayer.visible()) {\\n\\t\\t\\thidePannel(layerId);\\n\\t\\t} else {\\n\\t\\t\\tshowPannel(layerId);\\n\\t\\t}\\n\\t}\\n}\\n\\nvar isIE = (navigator.userAgent.toLowerCase().indexOf(\"msie\")!=-1 && window.document.all) ? true:false;\\nif (isIE) {\\n\\tdocument.attachEvent(\\'onmousedown\\', gnbLayerClose);\\n} else {\\n\\twindow.addEventListener(\\'mousedown\\', gnbLayerClose);\\n}\\n</script>\\n\\n\\n\\n</div>  \\n</body>\\n</html>\\n'\n\n\n\nhtml = bs(response.text, 'html.parser')\nhtml_table = html.select(\"table\")\ntable = pd.read_html(str(html_table))\nprint('íŒŒì‹±ëœ í…Œì´ë¸”ì˜ ê°œìˆ˜ :', len(table))\n\níŒŒì‹±ëœ í…Œì´ë¸”ì˜ ê°œìˆ˜ : 3\n\n\n\ntable[0]\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      ì „ì¼ 13,679.04\n      ê³ ê°€ 13,730.72\n      52ì£¼ ìµœê³  13,864.06\n    \n    \n      1\n      ì‹œê°€ 13,668.07\n      ì €ê°€ 13,657.72\n      52ì£¼ ìµœì € 10,088.83\n    \n  \n\n\n\n\n\ntable[1]\n\n\n\n\n\n  \n    \n      \n      ì¼ì\n      ì¢…ê°€\n      ì „ì¼ëŒ€ë¹„\n      ì‹œê°€\n      ê³ ê°€\n      ì €ê°€\n    \n  \n  \n    \n      0\n      2023.07.07\n      13681.61\n      2.57\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      1\n      2023.07.06\n      13679.04\n      112.61\n      13653.17\n      13689.52\n      13567.26\n    \n    \n      2\n      2023.07.05\n      13791.65\n      25.12\n      13772.10\n      13844.50\n      13764.25\n    \n    \n      3\n      2023.07.03\n      13816.77\n      28.85\n      13798.70\n      13839.09\n      13773.41\n    \n    \n      4\n      2023.06.30\n      13787.92\n      196.59\n      13719.98\n      13816.68\n      13716.16\n    \n    \n      5\n      2023.06.29\n      13591.33\n      0.42\n      13592.36\n      13618.53\n      13540.26\n    \n    \n      6\n      2023.06.28\n      13591.75\n      36.08\n      13506.02\n      13654.14\n      13495.73\n    \n    \n      7\n      2023.06.27\n      13555.67\n      219.89\n      13389.25\n      13578.80\n      13366.97\n    \n    \n      8\n      2023.06.26\n      13335.78\n      156.74\n      13468.75\n      13573.57\n      13334.42\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n  \n\n\n\n\n\ntable[2]\n\n\n\n\n\n  \n    \n      \n      ì—…ì²´ëª…\n      ê±°ë˜ëŸ‰\n      ì „ì¼ë¹„\n    \n  \n  \n  \n\n\n\n\n\ntable[1].dropna()\n\n\n\n\n\n  \n    \n      \n      ì¼ì\n      ì¢…ê°€\n      ì „ì¼ëŒ€ë¹„\n      ì‹œê°€\n      ê³ ê°€\n      ì €ê°€\n    \n  \n  \n    \n      0\n      2023.07.07\n      13681.61\n      2.57\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      1\n      2023.07.06\n      13679.04\n      112.61\n      13653.17\n      13689.52\n      13567.26\n    \n    \n      2\n      2023.07.05\n      13791.65\n      25.12\n      13772.10\n      13844.50\n      13764.25\n    \n    \n      3\n      2023.07.03\n      13816.77\n      28.85\n      13798.70\n      13839.09\n      13773.41\n    \n    \n      4\n      2023.06.30\n      13787.92\n      196.59\n      13719.98\n      13816.68\n      13716.16\n    \n    \n      5\n      2023.06.29\n      13591.33\n      0.42\n      13592.36\n      13618.53\n      13540.26\n    \n    \n      6\n      2023.06.28\n      13591.75\n      36.08\n      13506.02\n      13654.14\n      13495.73\n    \n    \n      7\n      2023.06.27\n      13555.67\n      219.89\n      13389.25\n      13578.80\n      13366.97\n    \n    \n      8\n      2023.06.26\n      13335.78\n      156.74\n      13468.75\n      13573.57\n      13334.42\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n  \n\n\n\n\n\ndf = pd.DataFrame()\nsise_url = 'https://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#'  \nfor page in range(1, 500):\n    page_url = '{}&page={}'.format(sise_url, page)\n    print(page_url)\n\n    # ìœ„ì—ì„œ í–ˆë˜ ì¼ë ¨ì˜ ê³¼ì •ë“¤ì„ ê° urlì— ëŒ€í•´ì„œ (99í˜ì´ì§€ì— ëŒ€í•´ì„œ ë°˜ë³µ)\n    response = requests.get(page_url, headers=headers)\n    html = bs(response.text, 'html.parser')\n    html_table = html.select(\"table\")\n    table = pd.read_html(str(html_table))\n\n    # í˜„ì¬ ì–»ì€ ë°ì´í„°í”„ë ˆì„ì„ ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì— ëˆ„ì .\n    df = df.append(table[1].dropna())\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=1\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=2\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=3\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=4\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=5\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=6\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=7\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=8\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=9\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=10\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=11\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=12\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=13\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=14\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=15\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=16\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=17\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=18\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=19\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=20\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=21\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=22\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=23\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=24\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=25\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=26\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=27\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=28\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=29\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=30\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=31\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=32\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=33\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=34\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=35\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=36\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=37\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=38\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=39\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=40\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=41\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=42\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=43\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=44\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=45\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=46\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=47\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=48\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=49\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=50\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=51\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=52\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=53\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=54\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=55\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=56\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=57\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=58\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=59\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=60\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=61\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=62\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=63\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=64\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=65\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=66\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=67\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=68\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=69\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=70\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=71\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=72\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=73\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=74\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=75\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=76\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=77\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=78\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=79\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=80\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=81\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=82\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=83\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=84\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=85\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=86\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=87\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=88\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=89\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=90\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=91\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=92\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=93\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=94\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=95\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=96\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=97\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=98\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=99\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=100\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=101\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=102\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=103\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=104\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=105\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=106\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=107\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=108\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=109\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=110\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=111\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=112\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=113\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=114\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=115\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=116\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=117\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=118\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=119\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=120\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=121\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=122\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=123\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=124\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=125\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=126\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=127\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=128\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=129\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=130\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=131\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=132\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=133\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=134\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=135\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=136\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=137\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=138\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=139\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=140\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=141\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=142\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=143\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=144\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=145\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=146\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=147\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=148\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=149\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=150\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=151\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=152\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=153\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=154\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=155\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=156\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=157\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=158\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=159\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=160\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=161\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=162\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=163\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=164\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=165\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=166\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=167\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=168\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=169\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=170\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=171\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=172\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=173\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=174\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=175\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=176\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=177\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=178\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=179\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=180\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=181\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=182\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=183\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=184\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=185\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=186\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=187\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=188\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=189\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=190\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=191\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=192\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=193\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=194\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=195\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=196\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=197\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=198\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=199\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=200\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=201\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=202\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=203\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=204\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=205\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=206\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=207\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=208\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=209\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=210\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=211\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=212\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=213\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=214\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=215\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=216\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=217\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=218\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=219\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=220\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=221\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=222\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=223\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=224\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=225\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=226\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=227\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=228\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=229\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=230\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=231\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=232\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=233\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=234\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=235\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=236\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=237\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=238\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=239\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=240\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=241\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=242\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=243\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=244\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=245\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=246\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=247\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=248\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=249\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=250\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=251\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=252\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=253\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=254\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=255\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=256\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=257\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=258\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=259\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=260\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=261\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=262\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=263\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=264\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=265\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=266\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=267\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=268\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=269\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=270\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=271\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=272\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=273\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=274\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=275\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=276\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=277\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=278\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=279\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=280\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=281\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=282\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=283\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=284\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=285\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=286\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=287\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=288\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=289\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=290\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=291\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=292\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=293\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=294\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=295\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=296\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=297\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=298\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=299\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=300\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=301\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=302\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=303\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=304\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=305\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=306\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=307\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=308\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=309\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=310\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=311\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=312\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=313\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=314\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=315\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=316\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=317\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=318\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=319\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=320\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=321\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=322\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=323\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=324\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=325\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=326\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=327\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=328\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=329\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=330\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=331\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=332\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=333\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=334\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=335\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=336\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=337\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=338\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=339\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=340\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=341\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=342\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=343\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=344\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=345\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=346\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=347\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=348\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=349\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=350\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=351\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=352\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=353\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=354\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=355\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=356\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=357\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=358\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=359\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=360\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=361\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=362\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=363\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=364\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=365\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=366\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=367\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=368\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=369\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=370\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=371\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=372\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=373\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=374\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=375\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=376\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=377\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=378\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=379\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=380\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=381\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=382\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=383\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=384\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=385\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=386\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=387\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=388\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=389\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=390\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=391\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=392\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=393\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=394\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=395\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=396\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=397\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=398\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=399\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=400\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=401\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=402\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=403\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=404\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=405\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=406\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=407\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=408\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=409\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=410\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=411\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=412\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=413\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=414\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=415\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=416\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=417\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=418\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=419\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=420\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=421\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=422\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=423\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=424\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=425\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=426\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=427\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=428\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=429\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=430\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=431\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=432\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=433\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=434\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=435\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=436\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=437\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=438\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=439\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=440\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=441\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=442\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=443\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=444\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=445\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=446\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=447\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=448\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=449\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=450\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=451\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=452\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=453\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=454\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=455\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=456\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=457\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=458\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=459\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=460\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=461\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=462\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=463\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=464\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=465\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=466\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=467\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=468\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=469\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=470\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=471\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=472\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=473\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=474\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=475\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=476\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=477\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=478\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=479\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=480\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=481\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=482\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=483\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=484\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=485\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=486\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=487\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=488\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=489\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=490\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=491\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=492\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=493\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=494\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=495\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=496\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=497\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=498\nhttps://finance.naver.com/world/sise.naver?symbol=NAS@IXIC#&page=499\n\n\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n<ipython-input-61-77dee5e93da6>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(table[1].dropna())\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      ì¼ì\n      ì¢…ê°€\n      ì „ì¼ëŒ€ë¹„\n      ì‹œê°€\n      ê³ ê°€\n      ì €ê°€\n    \n  \n  \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.1\n      13572.19\n      13442.65\n    \n  \n\n100 rows Ã— 6 columns\n\n\n\n\ndf = df.dropna()\n# df = df.iloc[0:30] \ndf = df.sort_values(by='ì¼ì')\ndf\n\n\n\n\n\n  \n    \n      \n      ì¼ì\n      ì¢…ê°€\n      ì „ì¼ëŒ€ë¹„\n      ì‹œê°€\n      ê³ ê°€\n      ì €ê°€\n    \n  \n  \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      9\n      2023.06.23\n      13492.52\n      138.09\n      13484.10\n      13572.19\n      13442.65\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      0\n      2023.07.07\n      13683.99\n      4.95\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13687.15\n      8.11\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13683.99\n      4.95\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13687.06\n      8.02\n      13668.07\n      13730.72\n      13657.72\n    \n    \n      0\n      2023.07.07\n      13684.51\n      5.47\n      13668.07\n      13730.72\n      13657.72\n    \n  \n\n4990 rows Ã— 6 columns\n\n\n\n\nplt.figure(figsize=(15, 5)) \nplt.title('Celltrion (close)')\nplt.xticks(rotation=45) \nplt.plot(df['ì¼ì'], df['ì¢…ê°€'], 'co-')\nplt.grid(color='gray', linestyle='--')\nplt.show()"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html",
    "title": "PyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)",
    "section": "",
    "text": "import torch_geometric\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport torch"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#ì •ë³´",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#ì •ë³´",
    "title": "PyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)",
    "section": "ì •ë³´",
    "text": "ì •ë³´\n- ê¸°ë³¸ì •ë³´: ENZYMES dataset\n\n(ChatGPT) ENZYMESëŠ” ê·¸ë˜í”„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ 600ê°œì˜ ê·¸ë˜í”„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, 6ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ê° ê·¸ë˜í”„ëŠ” íš¨ì†Œ(enzyme) ë¶„ìì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê·¸ë˜í”„ì˜ ë…¸ë“œëŠ” ì›ì(atom)ë¥¼ ë‚˜íƒ€ë‚´ê³ , ì—£ì§€(edge)ëŠ” ì›ì ê°„ì˜ ì—°ê²°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ENZYMES ë°ì´í„°ì…‹ì€ í™”í•™ ë° ìƒë¬¼ ì •ë³´í•™ ë¶„ì•¼ì—ì„œ ê·¸ë˜í”„ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì€ ì£¼ì–´ì§„ ê·¸ë˜í”„ë¥¼ íŠ¹ì • í´ë˜ìŠ¤ ë ˆì´ë¸”ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ENZYMES ë°ì´í„°ì…‹ì˜ ê·¸ë˜í”„ëŠ” íŠ¹ì • íš¨ì†Œ ì¢…ë¥˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê·¸ë˜í”„ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì€ ì£¼ì–´ì§„ íš¨ì†Œ ê·¸ë˜í”„ê°€ ì–´ë–¤ ì¢…ë¥˜ì˜ íš¨ì†Œì¸ì§€ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyGë¥¼ ì‚¬ìš©í•˜ì—¬ ENZYMES ë°ì´í„°ì…‹ì„ ì´ˆê¸°í™”í•˜ë©´ í•´ë‹¹ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•„ìš”í•œ ì „ì²˜ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´ ENZYMES ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ndataset # ë°ì´í„°ì…‹ ì´ë¦„\n\nENZYMES(600)\n\n\n\nlen(dataset) # ì´ ë°ì´í„°ì…‹ì—ëŠ” 600ê°œì˜ ê·¸ë˜í”„ê°€ ìˆìŒ\n\n600\n\n\n\ndataset.num_classes # 6ê°œì˜ í´ë˜ìŠ¤\n\n6\n\n\n\ndataset.num_node_features # ê° ë…¸ë“œì—ëŠ” 3ê°œì˜ í”¼ì²˜ê°€ ìˆìŒ\n\n3\n\n\n- 600ê°œì˜ ê·¸ë˜í”„ì¤‘ ì²«ë²ˆì§¸ ê·¸ë˜í”„ì— ì ‘ê·¼\n\ndataset[0]\n\nData(edge_index=[2, 168], x=[37, 3], y=[1])\n\n\n\nx=[37, 3]: \\(|{\\cal V}|=37\\), \\(f \\in \\mathbb{R}^3\\)\nedge_index=[2, 168]: \\(|{\\cal E}|=168\\)"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-ë¶„ë¦¬",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-ë¶„ë¦¬",
    "title": "PyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)",
    "section": "Train/Test ë¶„ë¦¬",
    "text": "Train/Test ë¶„ë¦¬\n- 600ê°œì˜ ê·¸ë˜í”„ì¤‘ 540ë¥¼ trainìœ¼ë¡œ, 60ê°œë¥¼ testë¡œ\n\ntrain_dataset = dataset[:540]\ntest_dataset = dataset[540:]"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#ì •ë³´-1",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#ì •ë³´-1",
    "title": "PyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)",
    "section": "ì •ë³´",
    "text": "ì •ë³´\n\nChatGPT: CoraëŠ” ê·¸ë˜í”„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ë¡œ, PyGì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ê¸°ê³„ í•™ìŠµ ë° ì •ë³´ ê²€ìƒ‰ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í•™ìˆ  ë…¼ë¬¸ë“¤ì˜ ì¸ìš© ë„¤íŠ¸ì›Œí¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Cora ë°ì´í„°ì…‹ì€ ì»´í“¨í„° ê³¼í•™ ë¶„ì•¼ì˜ ë…¼ë¬¸ì„ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤. ê° ë…¼ë¬¸ì€ ê·¸ë˜í”„ì˜ ë…¸ë“œë¡œ í‘œí˜„ë˜ë©°, ë…¸ë“œëŠ” ë…¼ë¬¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë…¸ë“œ ê°„ì˜ ì—£ì§€ëŠ” ë…¼ë¬¸ë“¤ ì‚¬ì´ì˜ ì¸ìš© ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë”°ë¼ì„œ Cora ë°ì´í„°ì…‹ì€ ë…¼ë¬¸ì˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •ë³´ì™€ ì¸ìš© ê´€ê³„ì— ëŒ€í•œ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Cora ë°ì´í„°ì…‹ì€ 7ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë˜ë©°, ê° ë…¼ë¬¸ì€ íŠ¹ì„± ë²¡í„°(feature vector)ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ íŠ¹ì„± ë²¡í„°ì—ëŠ” ë…¼ë¬¸ì˜ ë‹¨ì–´ ë“± ë‹¤ì–‘í•œ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyGë¥¼ ì‚¬ìš©í•˜ì—¬ Cora ë°ì´í„°ì…‹ì„ ì´ˆê¸°í™”í•˜ë©´ í•´ë‹¹ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œ Cora ë°ì´í„°ì…‹ì˜ ë…¼ë¬¸ì„ ë¶„ë¥˜í•˜ê±°ë‚˜ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n- ê¸°ë³¸ì •ë³´\n\nlen(dataset) # í•˜ë‚˜ì˜ ê·¸ë˜í”„ê°€ ìˆìŒ\n\n1\n\n\n\ndataset.num_classes # 7ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆìŒ\n\n7\n\n\n\ndataset.num_node_features # ê° ë…¸ë“œëŠ” 1433ê°œì˜ íŠ¹ì§•ì´ ìˆìŒ. (ë…¼ë¬¸ì— í¬í•¨ëœ ë‹¨ì–´ë“± ë‹¤ì–‘í•œ íŠ¹ì„±ì´ ë‹´ê²¨ìˆì„ ìˆ˜ ìˆìŒ) \n\n1433\n\n\n- ê·¸ë˜í”„ì— ì ‘ê·¼\n\ndataset[0] # ê¸°ë³¸ì •ë³´\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n\n\n\nx=[2708, 1433]: 2708ê°œì˜ ë…¼ë¬¸ì´ ìˆê³ , ê° ë…¼ë¬¸ì€ 1433ê°œì˜ íŠ¹ì§•ë²¡í„°ë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒ.\nedge_index=[2, 10556]: ë…¼ë¬¸ê°„ì˜ ì¸ìš©ì€ ì•½ 10556.\ny=[2708]:\n\n\ndataset[0].x.shape # 2708ê°œì˜ ë…¼ë¬¸ì´ ìˆê³  1433ê°œì˜ íŠ¹ì§•ë²¡í„°ë¥¼ ê°€ì§\n\ntorch.Size([2708, 1433])\n\n\n\ndataset[0].y.unique() # ë…¼ë¬¸ì´ 7ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ë˜ëŠ”ë“¯\n\ntensor([0, 1, 2, 3, 4, 5, 6])"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-ì´ë¯¸-ë¶„ë¦¬ë˜ì–´-ìˆìŒ",
    "href": "posts/RESEARCHES/2023-07-22-ls2.out.html#traintest-ì´ë¯¸-ë¶„ë¦¬ë˜ì–´-ìˆìŒ",
    "title": "PyG lesson2: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ (train/testë¶„ë¦¬)",
    "section": "Train/Test (ì´ë¯¸ ë¶„ë¦¬ë˜ì–´ ìˆìŒ)",
    "text": "Train/Test (ì´ë¯¸ ë¶„ë¦¬ë˜ì–´ ìˆìŒ)\n\ndataset[0].train_mask \n# dataset[0].train_mask ëŠ” True, Falseë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ” ê¸¸ì´ê°€ 2708(=ë…¸ë“œìˆ˜=ë…¼ë¬¸ìˆ˜)ì¸ ë²¡í„°\n# ì—¬ê¸°ì—ì„œ Trueì¸ ë…¸ë“œë§Œ í›ˆë ¨í•¨\n\ntensor([ True,  True,  True,  ..., False, False, False])\n\n\n\ndataset[0].train_mask.sum() # 140ê°œì˜ ë…¸ë“œë§Œ í›ˆë ¨í•¨? \n\ntensor(140)\n\n\n\ndataset[0].val_mask.sum() # valì€ 500ê°œì˜ ë…¸ë“œ?\n\ntensor(500)\n\n\n\ndataset[0].test_mask.sum() # test setì€ 1000?\n\ntensor(1000)\n\n\n\ndataset.edge_index\n\ntensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
  },
  {
    "objectID": "posts/RESEARCHES/2023-07-20-LLM.html",
    "href": "posts/RESEARCHES/2023-07-20-LLM.html",
    "title": "LLM",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport torch\nfrom transformers import GPT2Tokenizer, TFGPT2LMHeadModel\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nimport copy\n\n\nimport os\nimport re\nimport string\nimport json\nimport numpy as np\nfrom sklearn import metrics\nfrom bs4 import BeautifulSoup\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option(\"display.max_columns\", None)\n\n\n\nData\nref: kaggle\n\ndf2 = pd.read_csv('./dataset/twitter_MBTI.csv').iloc[:,1:]\n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      text\n      label\n    \n  \n  \n    \n      0\n      @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n      intj\n    \n    \n      1\n      @Hispanthicckk Being you makes you look cute||...\n      intj\n    \n    \n      2\n      @Alshymi Les balles sont rÃ©elles et sont tirÃ©e...\n      intj\n    \n    \n      3\n      I'm like entp but idiotic|||Hey boy, do you wa...\n      intj\n    \n    \n      4\n      @kaeshurr1 Give it to @ZargarShanif ... He has...\n      intj\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      7806\n      @sobsjjun God,,pls take care ğŸ˜•|||@sobsjjun Hir...\n      intp\n    \n    \n      7807\n      @Ignis_02 wow last time i got intp https://t.c...\n      intp\n    \n    \n      7808\n      @akupilled A 100%|||@akupilled That SOMEONE wi...\n      entp\n    \n    \n      7809\n      If youâ€™re #INTJ this one is for you | What is ...\n      infj\n    \n    \n      7810\n      @harry__lambert @gucci hey can you dm me a pic...\n      istp\n    \n  \n\n7811 rows Ã— 2 columns\n\n\n\n\ndf_t = pd.read_csv('./dataset/mbti_1.csv')\n\n\ndf_t\n\n\n\n\n\n  \n    \n      \n      type\n      posts\n    \n  \n  \n    \n      0\n      INFJ\n      'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n    \n    \n      1\n      ENTP\n      'I'm finding the lack of me in these posts ver...\n    \n    \n      2\n      INTP\n      'Good one  _____   https://www.youtube.com/wat...\n    \n    \n      3\n      INTJ\n      'Dear INTP,   I enjoyed our conversation the o...\n    \n    \n      4\n      ENTJ\n      'You're fired.|||That's another silly misconce...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      8670\n      ISFP\n      'https://www.youtube.com/watch?v=t8edHB_h908||...\n    \n    \n      8671\n      ENFP\n      'So...if this thread already exists someplace ...\n    \n    \n      8672\n      INTP\n      'So many questions when i do these things.  I ...\n    \n    \n      8673\n      INFP\n      'I am very conflicted right now when it comes ...\n    \n    \n      8674\n      INFP\n      'It has been too long since I have been on per...\n    \n  \n\n8675 rows Ã— 2 columns\n\n\n\n\ndf_t.iloc[1,:]\n\ntype                                                  ENTP\nposts    'I'm finding the lack of me in these posts ver...\nName: 1, dtype: object\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df2['label'],color='grey', align='left', rwidth=0.8,bins=16)\n\n(array([ 781.,  811.,  279.,  577., 1057., 1282.,  518.,  729.,  259.,\n         364.,   81.,  105.,  327.,  367.,  100.,  174.]),\n array([ 0.    ,  0.9375,  1.875 ,  2.8125,  3.75  ,  4.6875,  5.625 ,\n         6.5625,  7.5   ,  8.4375,  9.375 , 10.3125, 11.25  , 12.1875,\n        13.125 , 14.0625, 15.    ]),\n <BarContainer object of 16 artists>)\n\n\n\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df_t['type'],color='grey', align='left', rwidth=0.8,bins=16)\n\n(array([1470.,  685., 1304., 1091.,  231.,  190., 1832.,  675.,  271.,\n         337.,  166.,  205.,   89.,   48.,   39.,   42.]),\n array([ 0.    ,  0.9375,  1.875 ,  2.8125,  3.75  ,  4.6875,  5.625 ,\n         6.5625,  7.5   ,  8.4375,  9.375 , 10.3125, 11.25  , 12.1875,\n        13.125 , 14.0625, 15.    ]),\n <BarContainer object of 16 artists>)\n\n\n\n\n\n\ndf2['word_count'] = df2['text'].apply(lambda x: len(x.split()))\n\n\ndf_t['word_count'] = df_t['posts'].apply(lambda x: len(x.split()))\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df2['word_count'],color='lightblue', align='left', rwidth=0.8,bins=100)\n\n(array([109.,  94.,  89.,  99.,  99., 102., 153., 106., 124., 149., 151.,\n        162., 140., 161., 155., 221., 229., 218., 210., 202., 220., 209.,\n        192., 240., 207., 188., 184., 186., 182., 187., 185., 160., 174.,\n        155., 133., 116., 121., 123., 130., 118.,  99.,  90.,  91.,  84.,\n         88.,  68.,  64.,  57.,  70.,  58.,  42.,  44.,  53.,  43.,  47.,\n         42.,  30.,  37.,  42.,  15.,  21.,  27.,  26.,  14.,  18.,   9.,\n         13.,  19.,  14.,  20.,   7.,  12.,   3.,  11.,   4.,   3.,   4.,\n          4.,   1.,   4.,   5.,   3.,   3.,   5.,   2.,   4.,   2.,   0.,\n          1.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   1.,\n          1.]),\n array([ 201.  ,  242.43,  283.86,  325.29,  366.72,  408.15,  449.58,\n         491.01,  532.44,  573.87,  615.3 ,  656.73,  698.16,  739.59,\n         781.02,  822.45,  863.88,  905.31,  946.74,  988.17, 1029.6 ,\n        1071.03, 1112.46, 1153.89, 1195.32, 1236.75, 1278.18, 1319.61,\n        1361.04, 1402.47, 1443.9 , 1485.33, 1526.76, 1568.19, 1609.62,\n        1651.05, 1692.48, 1733.91, 1775.34, 1816.77, 1858.2 , 1899.63,\n        1941.06, 1982.49, 2023.92, 2065.35, 2106.78, 2148.21, 2189.64,\n        2231.07, 2272.5 , 2313.93, 2355.36, 2396.79, 2438.22, 2479.65,\n        2521.08, 2562.51, 2603.94, 2645.37, 2686.8 , 2728.23, 2769.66,\n        2811.09, 2852.52, 2893.95, 2935.38, 2976.81, 3018.24, 3059.67,\n        3101.1 , 3142.53, 3183.96, 3225.39, 3266.82, 3308.25, 3349.68,\n        3391.11, 3432.54, 3473.97, 3515.4 , 3556.83, 3598.26, 3639.69,\n        3681.12, 3722.55, 3763.98, 3805.41, 3846.84, 3888.27, 3929.7 ,\n        3971.13, 4012.56, 4053.99, 4095.42, 4136.85, 4178.28, 4219.71,\n        4261.14, 4302.57, 4344.  ]),\n <BarContainer object of 100 artists>)\n\n\n\n\n\n\nplt.figure(figsize=(25, 8))\nplt.hist(df_t['word_count'],color='lightblue', align='left', rwidth=0.8,bins=100)\n\n(array([  2.,   1.,   4.,   2.,   1.,   1.,   3.,   3.,   2.,   9.,   4.,\n          7.,   4.,   8.,   9.,   9.,  10.,  13.,   8.,  17.,  13.,  17.,\n         18.,  22.,  28.,  16.,  22.,  24.,  31.,  30.,  36.,  35.,  31.,\n         26.,  42.,  38.,  51.,  43.,  43.,  53.,  70.,  53.,  70.,  89.,\n         66.,  88.,  85.,  67., 104., 100., 111., 116.,  96., 139., 108.,\n        135., 138., 128., 167., 145., 156., 187., 185., 161., 211., 207.,\n        211., 249., 224., 203., 243., 235., 220., 206., 260., 239., 212.,\n        210., 206., 227., 211., 180., 157., 179., 155., 153., 107., 126.,\n         84.,  66.,  52.,  37.,  39.,  33.,  12.,   8.,   5.,   4.,   3.,\n          1.]),\n array([   4.  ,   22.77,   41.54,   60.31,   79.08,   97.85,  116.62,\n         135.39,  154.16,  172.93,  191.7 ,  210.47,  229.24,  248.01,\n         266.78,  285.55,  304.32,  323.09,  341.86,  360.63,  379.4 ,\n         398.17,  416.94,  435.71,  454.48,  473.25,  492.02,  510.79,\n         529.56,  548.33,  567.1 ,  585.87,  604.64,  623.41,  642.18,\n         660.95,  679.72,  698.49,  717.26,  736.03,  754.8 ,  773.57,\n         792.34,  811.11,  829.88,  848.65,  867.42,  886.19,  904.96,\n         923.73,  942.5 ,  961.27,  980.04,  998.81, 1017.58, 1036.35,\n        1055.12, 1073.89, 1092.66, 1111.43, 1130.2 , 1148.97, 1167.74,\n        1186.51, 1205.28, 1224.05, 1242.82, 1261.59, 1280.36, 1299.13,\n        1317.9 , 1336.67, 1355.44, 1374.21, 1392.98, 1411.75, 1430.52,\n        1449.29, 1468.06, 1486.83, 1505.6 , 1524.37, 1543.14, 1561.91,\n        1580.68, 1599.45, 1618.22, 1636.99, 1655.76, 1674.53, 1693.3 ,\n        1712.07, 1730.84, 1749.61, 1768.38, 1787.15, 1805.92, 1824.69,\n        1843.46, 1862.23, 1881.  ]),\n <BarContainer object of 100 artists>)\n\n\n\n\n\nhttps://wikidocs.net/152922\nhttps://dacon.io/codeshare/5619\nhttps://www.kaggle.com/code/debarshichanda/bert-multi-label-text-classification\nhttps://www.kaggle.com/datasets/datasnaek/mbti-type?select=mbti_1.csv\n\none = pd.get_dummies(df2['label'], prefix='label')\n\n\none_t = pd.get_dummies(df_t['type'], prefix='type')\n\n\ndf3 = pd.concat([df2,one],axis=1)\n\n\ndf_t1 = pd.concat([df_t,one_t],axis=1)\n\n\ndf3.head()\n\n\n\n\n\n  \n    \n      \n      text\n      label\n      word_count\n      label_enfj\n      label_enfp\n      label_entj\n      label_entp\n      label_esfj\n      label_esfp\n      label_estj\n      label_estp\n      label_infj\n      label_infp\n      label_intj\n      label_intp\n      label_isfj\n      label_isfp\n      label_istj\n      label_istp\n    \n  \n  \n    \n      0\n      @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n      intj\n      2351\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      @Hispanthicckk Being you makes you look cute||...\n      intj\n      943\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      @Alshymi Les balles sont rÃ©elles et sont tirÃ©e...\n      intj\n      1646\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      I'm like entp but idiotic|||Hey boy, do you wa...\n      intj\n      923\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      @kaeshurr1 Give it to @ZargarShanif ... He has...\n      intj\n      1024\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndf_t1.head()\n\n\n\n\n\n  \n    \n      \n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      INFJ\n      'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      ENTP\n      'I'm finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      INTP\n      'Good one  _____   https://www.youtube.com/wat...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      INTJ\n      'Dear INTP,   I enjoyed our conversation the o...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      ENTJ\n      'You're fired.|||That's another silly misconce...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndef clean_text(text):\n    text = re.sub(r'\\:(.*?)\\:','',text)\n    text = str(text).lower()    #Making Text Lowercase\n    text = re.sub('\\[.*?\\]', '', text)\n    #The next 2 lines remove html text\n    text = BeautifulSoup(text, 'lxml').get_text()\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n    text = re.sub(r\"[^a-zA-Z?.!,Â¿']+\", \" \", text)\n    return text\n\ndef clean_contractions(text, mapping):\n    '''Clean contraction using contraction mapping'''    \n    specials = [\"â€™\", \"â€˜\", \"Â´\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    for word in mapping.keys():\n        if \"\"+word+\"\" in text:\n            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n    #Remove Punctuations\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    text = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", text)\n    text = re.sub(r'[\" \"]+', \" \", text)\n    return text\n\ndef clean_special_chars(text, punct, mapping):\n    '''Cleans special characters present(if any)'''   \n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    \n    for p in punct:\n        text = text.replace(p, f' {p} ')\n    \n    specials = {'\\u200b': ' ', 'â€¦': ' ... ', '\\ufeff': '', 'à¤•à¤°à¤¨à¤¾': '', 'à¤¹à¥ˆ': ''}  \n    for s in specials:\n        text = text.replace(s, specials[s])\n    \n    return text\n\ndef correct_spelling(x, dic):\n    '''Corrects common spelling errors'''   \n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x\n\ndef remove_space(text):\n    '''Removes awkward spaces'''   \n    #Removes awkward spaces \n    text = text.strip()\n    text = text.split()\n    return \" \".join(text)\n\ndef text_preprocessing_pipeline(text):\n    '''Cleaning and parsing the text.'''\n    text = clean_text(text)\n    text = clean_contractions(text, contraction_mapping)\n    text = clean_special_chars(text, punct, punct_mapping)\n    text = correct_spelling(text, mispell_dict)\n    text = remove_space(text)\n    return text\n\n\ndf_t2 = df_t1.copy().reset_index()\n\n\ncontraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n\npunct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', 'â€¢',  '~', '@', 'Â£', \n 'Â·', '_', '{', '}', 'Â©', '^', 'Â®', '`',  '<', 'â†’', 'Â°', 'â‚¬', 'â„¢', 'â€º',  'â™¥', 'â†', 'Ã—', 'Â§', 'â€³', 'â€²', 'Ã‚', 'â–ˆ', 'Â½', 'Ã ', 'â€¦', \n 'â€œ', 'â˜…', 'â€', 'â€“', 'â—', 'Ã¢', 'â–º', 'âˆ’', 'Â¢', 'Â²', 'Â¬', 'â–‘', 'Â¶', 'â†‘', 'Â±', 'Â¿', 'â–¾', 'â•', 'Â¦', 'â•‘', 'â€•', 'Â¥', 'â–“', 'â€”', 'â€¹', 'â”€', \n 'â–’', 'ï¼š', 'Â¼', 'âŠ•', 'â–¼', 'â–ª', 'â€ ', 'â– ', 'â€™', 'â–€', 'Â¨', 'â–„', 'â™«', 'â˜†', 'Ã©', 'Â¯', 'â™¦', 'Â¤', 'â–²', 'Ã¨', 'Â¸', 'Â¾', 'Ãƒ', 'â‹…', 'â€˜', 'âˆ', \n 'âˆ™', 'ï¼‰', 'â†“', 'ã€', 'â”‚', 'ï¼ˆ', 'Â»', 'ï¼Œ', 'â™ª', 'â•©', 'â•š', 'Â³', 'ãƒ»', 'â•¦', 'â•£', 'â•”', 'â•—', 'â–¬', 'â¤', 'Ã¯', 'Ã˜', 'Â¹', 'â‰¤', 'â€¡', 'âˆš', ]\n\npunct_mapping = {\"â€˜\": \"'\", \"â‚¹\": \"e\", \"Â´\": \"'\", \"Â°\": \"\", \"â‚¬\": \"e\", \"â„¢\": \"tm\", \"âˆš\": \" sqrt \", \"Ã—\": \"x\", \"Â²\": \"2\", \"â€”\": \"-\", \"â€“\": \"-\", \"â€™\": \"'\", \"_\": \"-\",\n                 \"`\": \"'\", 'â€œ': '\"', 'â€': '\"', 'â€œ': '\"', \"Â£\": \"e\", 'âˆ': 'infinity', 'Î¸': 'theta', 'Ã·': '/', 'Î±': 'alpha', 'â€¢': '.', 'Ã ': 'a', 'âˆ’': '-', \n                 'Î²': 'beta', 'âˆ…': '', 'Â³': '3', 'Ï€': 'pi', '!':' '}\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n                'demonetisation': 'demonetization'}\n\n\ndf_t2['posts'] = df_t2['posts'].apply(text_preprocessing_pipeline)\n\n\ndf_t2.head()\n\n\n\n\n\n  \n    \n      \n      index\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      INFJ\n      http mediatumblrcom jpg enfp and intj moments ...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENTP\n      i am finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INTP\n      good one https dozens of different plant speci...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      INTJ\n      dear intp i enjoyed our conversation the other...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      you are fired that is another silly misconcept...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\nlen(df_t2) * 0.6\n\n5205.0\n\n\n\nlen(df_t2) - len(df_t2) * 0.2\n\n6940.0\n\n\n\ndf_t_train = df_t2[:5205].reset_index().iloc[:,1:].rename(columns={'index':'ids'})\ndf_t_valid = df_t2[5205:6240].reset_index().iloc[:,2:].reset_index().rename(columns={'index':'ids'})\ndf_t_test = df_t2[6240:].reset_index().iloc[:,2:].reset_index().rename(columns={'index':'ids'})\n\n\ndf_t_train.head()\n\n\n\n\n\n  \n    \n      \n      ids\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      INFJ\n      http mediatumblrcom jpg enfp and intj moments ...\n      556\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENTP\n      i am finding the lack of me in these posts ver...\n      1170\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INTP\n      good one https dozens of different plant speci...\n      836\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      INTJ\n      dear intp i enjoyed our conversation the other...\n      1064\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      you are fired that is another silly misconcept...\n      967\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndf_t_valid.head()\n\n\n\n\n\n  \n    \n      \n      ids\n      type\n      posts\n      word_count\n      type_ENFJ\n      type_ENFP\n      type_ENTJ\n      type_ENTP\n      type_ESFJ\n      type_ESFP\n      type_ESTJ\n      type_ESTP\n      type_INFJ\n      type_INFP\n      type_INTJ\n      type_INTP\n      type_ISFJ\n      type_ISFP\n      type_ISTJ\n      type_ISTP\n    \n  \n  \n    \n      0\n      0\n      ENFP\n      people attempt to label anything as a disorder...\n      1067\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      1\n      ENFP\n      well this would be consistent with my forums n...\n      1342\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      2\n      INFP\n      why i feel like this todays world is full of c...\n      952\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      3\n      ENFP\n      hi leaves long time no see my advice would be ...\n      1204\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      4\n      ENTJ\n      velcome my husband is intj we get along very w...\n      838\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\nprint(df_t_train.shape)\nprint(df_t_valid.shape)\nprint(df_t_test.shape)\n\n(5205, 20)\n(1035, 20)\n(2435, 20)\n\n\n\nMAX_LEN = 1000\nTRAIN_BATCH_SIZE = 64\nVALID_BATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 0.01\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\n\n\ntarget_cols = [col for col in df_t_train.columns if col not in ['ids','posts','type','word_count']]\n\n\n# target_cols = [text.replace('type_', '') for text in target_cols]\n\n\nclass BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.posts\n        self.tokenizer = tokenizer\n        self.targets = df[target_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }\n\n\ntrain_dataset = BERTDataset(df_t_train, tokenizer, MAX_LEN)\ntest_dataset = BERTDataset(df_t_test, tokenizer, MAX_LEN)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, \n                          num_workers=4, shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, \n                          num_workers=4, shuffle=False, pin_memory=True)\n\n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.roberta = AutoModel.from_pretrained('roberta-base')\n#         self.l2 = torch.nn.Dropout(0.3)\n        self.fc = torch.nn.Linear(768,16)\n    \n    def forward(self, index, mask, token_type_ids):\n        _, features = self.roberta(index, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n#         output_2 = self.l2(output_1)\n        output = self.fc(features)\n        return output\n\nmodel = BERTClass()\nmodel.to(device);\n\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\ndef loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\n\noptimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE, weight_decay=1e-6)\n\n\ndef train(epoch):\n    model.train()\n    for _,data in enumerate(train_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        if _%500 == 0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nfor epoch in range(EPOCHS):\n    train(epoch)\n\nIndexError: index out of range in self\n\n\n\ndef validation():\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(valid_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets\n\n\noutputs, targets = validation()\n\n\nnp.array(outputs)[:10]\n\n\nnp.array(outputs) >= 0.1\n\n\ndef one_hot_to_integer(one_hot_data):\n    return np.argmax(one_hot_data) + 1\n\n\nret = [one_hot_to_integer(sample) for sample in targets]\n\n\nret[:10]\n\n\ntst = [0.05589867, 0.01052203, 0.13754041, 0.0588008 , 0.01005199,\n        0.0295825 , 0.00209739, 0.02436998, 0.07758361, 0.10916023,\n        0.07828864, 0.23720771, 0.00276894, 0.02201499, 0.08916565,\n        0.01853185]\n\n\nsum(tst)\n\n\nnp.argmax([0.05589867, 0.01052203, 0.13754041, 0.0588008 , 0.01005199,\n        0.0295825 , 0.00209739, 0.02436998, 0.07758361, 0.10916023,\n        0.07828864, 0.23720771, 0.00276894, 0.02201499, 0.08916565,\n        0.01853185])\n\n\nnp.array(outputs).shape\n\n\nplt.hist(np.argmax(outputs,axis=1))\n\n\n\noutputs1 = np.array(outputs) >= 0.5\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score (Micro) = {f1_score_micro}\")\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, there ;)\nì°¸ê³ \n\nsudo reeboot ë¡œ ì¬ë¶€íŒ… í›„\njupyter notebook & ì…ë ¥ í›„\nenter ë¡œ ë‚˜ê°€ì„œ\nexit í•˜ê¸°\nì¬ë¶€íŒ…ì‹œ drop box open ~ (~/.dropbox-dist/dropboxd)\n\n\nnvidia-smi ë¡œ GPU ìƒíƒœ í™•ì¸ ! ì•ˆ ì¼œì ¸ ìˆë‹¤ë©´? (sudo ./NVIDIA-Linux-x86_64-495.46.run(tabëˆ„ë¥´ë©´ ë‚˜ì˜´))\n\nterminal check\n\ntop\nnvidia-smi\nps aux | grep jupyter-lab\ní•„ìš”ì—†ëŠ” ê±° â€™kill 0000â€™ë¡œ í”„ë¡œì„¸ìŠ¤ ë„ê¸°"
  }
]
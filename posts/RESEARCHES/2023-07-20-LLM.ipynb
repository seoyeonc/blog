{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3d8d9e77-c4ef-45aa-8433-18a18f7fe7b9",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"LLM\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-07-20\"\n",
    "categories:\n",
    "  - LLM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe86a26-05e1-4e94-8bde-56aaa5a7f046",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2d3b7e8-9dc1-4224-82e0-523a22b58508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620e328-8c91-422f-a812-5ea5169a144a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343acbed-9fef-47b4-9a46-9d99ff75fabf",
   "metadata": {},
   "source": [
    "ref: [kaggle](https://www.kaggle.com/datasets/mazlumi/mbti-personality-type-twitter-dataset/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb71bafc-4b35-406c-9026-f0e38adeb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv('./dataset/twitter_MBTI.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8199021-6acd-401c-ae36-b6baf78719a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alshymi Les balles sont rÃ©elles et sont tirÃ©e...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>@sobsjjun God,,pls take care ðŸ˜•|||@sobsjjun Hir...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>@Ignis_02 wow last time i got intp https://t.c...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>@akupilled A 100%|||@akupilled That SOMEONE wi...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>If youâ€™re #INTJ this one is for you | What is ...</td>\n",
       "      <td>infj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>@harry__lambert @gucci hey can you dm me a pic...</td>\n",
       "      <td>istp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7811 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj\n",
       "1     @Hispanthicckk Being you makes you look cute||...  intj\n",
       "2     @Alshymi Les balles sont rÃ©elles et sont tirÃ©e...  intj\n",
       "3     I'm like entp but idiotic|||Hey boy, do you wa...  intj\n",
       "4     @kaeshurr1 Give it to @ZargarShanif ... He has...  intj\n",
       "...                                                 ...   ...\n",
       "7806  @sobsjjun God,,pls take care ðŸ˜•|||@sobsjjun Hir...  intp\n",
       "7807  @Ignis_02 wow last time i got intp https://t.c...  intp\n",
       "7808  @akupilled A 100%|||@akupilled That SOMEONE wi...  entp\n",
       "7809  If youâ€™re #INTJ this one is for you | What is ...  infj\n",
       "7810  @harry__lambert @gucci hey can you dm me a pic...  istp\n",
       "\n",
       "[7811 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c63251d-cb52-4c53-8d0d-61cb81ba9c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8b632-e406-4764-af48-75206e4619f1",
   "metadata": {},
   "source": [
    "https://wikidocs.net/152922"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172f9d6-42b9-445f-b7a1-1f0772ecbcc5",
   "metadata": {},
   "source": [
    "https://dacon.io/codeshare/5619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a12ae0d-00de-48dd-8b9e-1a992d6fd7af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2561\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2561\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2619\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2621\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m     )\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2626\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2627\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2628\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(df2.iloc[:,0],return_tensors=\"tf\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5324a2-6ef7-4125-a291-188a975f20ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "raw",
   "id": "11a64360-0e10-4615-a9a7-c5a24259fa02",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Simulation Tables\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-05-17\"\n",
    "categories:\n",
    "  - ITSTGCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d226b-96cb-4015-88f1-b1176a4bc84f",
   "metadata": {
    "tags": []
   },
   "source": [
    "> Simulation Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcfea5-acb6-4176-a141-2b3e018837bf",
   "metadata": {},
   "source": [
    "ref: [keras ex](https://keras.io/examples/timeseries/timeseries_traffic_forecasting/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d9f47b5-9000-4701-86d3-fe443a3d4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6bcf9-81f6-4237-9534-f0c3ed00acf4",
   "metadata": {},
   "source": [
    "url = \"https://github.com/VeritasYin/STGCN_IJCAI-18/tree/master/dataset/PeMSD7_Full.zip\"\n",
    "data_dir = keras.utils.get_file(origin=url, extract=True, archive_format=\"zip\")\n",
    "data_dir = data_dir.rstrip(\".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "217a65ce-e3e5-43a0-a579-ba99c457b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances = pd.read_csv('./data/PeMSD7_W_228.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a5aff01-6981-46d4-bce0-a14abdea6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_array = pd.read_csv('./data/PeMSD7_V_228.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e07dcba5-08db-45fd-9faf-b60306653f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route_distances shape=(227, 228)\n",
      "speeds_array shape=(12671, 228)\n"
     ]
    }
   ],
   "source": [
    "print(f\"route_distances shape={route_distances.shape}\")\n",
    "print(f\"speeds_array shape={speeds_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f58dc-a493-4a27-84e2-529446ddb89c",
   "metadata": {},
   "source": [
    "공식 문서(아래)와 다름\n",
    "\n",
    "- route_distances shape=(228, 228)\n",
    "- speeds_array shape=(12672, 228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03fb45b2-50af-41db-a77b-b6f181837611",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_routes = [\n",
    "    0,\n",
    "    1,\n",
    "    4,\n",
    "    7,\n",
    "    8,\n",
    "    11,\n",
    "    15,\n",
    "    108,\n",
    "    109,\n",
    "    114,\n",
    "    115,\n",
    "    118,\n",
    "    120,\n",
    "    123,\n",
    "    124,\n",
    "    126,\n",
    "    127,\n",
    "    129,\n",
    "    130,\n",
    "    132,\n",
    "    133,\n",
    "    136,\n",
    "    139,\n",
    "    144,\n",
    "    147,\n",
    "    216,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05bad0be-0863-4c5c-8cc0-751437bb3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances = route_distances.iloc[np.array(sample_routes), np.array(sample_routes)] #route_distances[np.ix_(sample_routes, sample_routes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27735e6-d28b-4f74-bcb6-72e41105a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_array = speeds_array[:,sample_routes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a3257-28dd-46d8-b07d-addacafebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"route_distances shape={route_distances.shape}\")\n",
    "print(f\"speeds_array shape={speeds_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8ea8d-f315-41fc-87cc-0be8d1c073e0",
   "metadata": {},
   "source": [
    "공식문서(아래)\n",
    "\n",
    "- route_distances shape=(26, 26)\n",
    "- speeds_array shape=(12672, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b84c6-ac19-4121-9e2f-6811ce5bdd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "427240fd-bf96-46c8-84ac-01447e816657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dd4d0b3-3db6-42fa-b3b8-eae1d239a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_sequence_length = 12\n",
    "forecast_horizon = 3\n",
    "multi_horizon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31a4e9-7de8-4aec-bced-2e57e9eeb166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821462cd-566f-4e1c-b4d9-341b81a149cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf1ee3c-3849-4199-b08c-a952c8d9d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(\n",
    "    data_array: np.ndarray,\n",
    "    input_sequence_length: int,\n",
    "    forecast_horizon: int,\n",
    "    batch_size: int = 128,\n",
    "    shuffle=True,\n",
    "    multi_horizon=True,\n",
    "):\n",
    "    \"\"\"Creates tensorflow dataset from numpy array.\n",
    "\n",
    "    This function creates a dataset where each element is a tuple `(inputs, targets)`.\n",
    "    `inputs` is a Tensor\n",
    "    of shape `(batch_size, input_sequence_length, num_routes, 1)` containing\n",
    "    the `input_sequence_length` past values of the timeseries for each node.\n",
    "    `targets` is a Tensor of shape `(batch_size, forecast_horizon, num_routes)`\n",
    "    containing the `forecast_horizon`\n",
    "    future values of the timeseries for each node.\n",
    "\n",
    "    Args:\n",
    "        data_array: np.ndarray with shape `(num_time_steps, num_routes)`\n",
    "        input_sequence_length: Length of the input sequence (in number of timesteps).\n",
    "        forecast_horizon: If `multi_horizon=True`, the target will be the values of the timeseries for 1 to\n",
    "            `forecast_horizon` timesteps ahead. If `multi_horizon=False`, the target will be the value of the\n",
    "            timeseries `forecast_horizon` steps ahead (only one value).\n",
    "        batch_size: Number of timeseries samples in each batch.\n",
    "        shuffle: Whether to shuffle output samples, or instead draw them in chronological order.\n",
    "        multi_horizon: See `forecast_horizon`.\n",
    "\n",
    "    Returns:\n",
    "        A tf.data.Dataset instance.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = timeseries_dataset_from_array(\n",
    "        np.expand_dims(data_array[:-forecast_horizon], axis=-1),\n",
    "        None,\n",
    "        sequence_length=input_sequence_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    target_offset = (\n",
    "        input_sequence_length\n",
    "        if multi_horizon\n",
    "        else input_sequence_length + forecast_horizon - 1\n",
    "    )\n",
    "    target_seq_length = forecast_horizon if multi_horizon else 1\n",
    "    targets = timeseries_dataset_from_array(\n",
    "        data_array[target_offset:],\n",
    "        None,\n",
    "        sequence_length=target_seq_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((inputs, targets))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "    return dataset.prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b577078-995e-47de-a8c2-9eea167390b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     create_tf_dataset(data_array, input_sequence_length, forecast_horizon, batch_size)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_array \u001b[38;5;129;01min\u001b[39;00m [train_dataset, test_dataset]\n\u001b[1;32m      4\u001b[0m )\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mcreate_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_array \u001b[38;5;129;01min\u001b[39;00m [train_dataset, test_dataset]\n\u001b[1;32m      4\u001b[0m )\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mcreate_tf_dataset\u001b[0;34m(data_array, input_sequence_length, forecast_horizon, batch_size, shuffle, multi_horizon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tf_dataset\u001b[39m(\n\u001b[1;32m      2\u001b[0m     data_array: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m      3\u001b[0m     input_sequence_length: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     multi_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m ):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates tensorflow dataset from numpy array.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    This function creates a dataset where each element is a tuple `(inputs, targets)`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m        A tf.data.Dataset instance.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtimeseries_dataset_from_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     target_offset \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     42\u001b[0m         input_sequence_length\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multi_horizon\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m input_sequence_length \u001b[38;5;241m+\u001b[39m forecast_horizon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     target_seq_length \u001b[38;5;241m=\u001b[39m forecast_horizon \u001b[38;5;28;01mif\u001b[39;00m multi_horizon \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/utils/timeseries_dataset.py:188\u001b[0m, in \u001b[0;36mtimeseries_dataset_from_array\u001b[0;34m(data, targets, sequence_length, sequence_stride, sampling_rate, batch_size, shuffle, seed, start_index, end_index)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sampling_rate` must be higher than 0. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sampling_rate` must be lower than the length of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata. Received: sampling_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, for data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sequence_stride \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sequence_stride` must be higher than 0. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_stride=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_stride\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 1"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = (\n",
    "    create_tf_dataset(data_array, input_sequence_length, forecast_horizon, batch_size)\n",
    "    for data_array in [train_dataset, test_dataset]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4df385-6c8f-48a6-a2b4-b609fdec138e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m create_tf_dataset(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtest_array\u001b[49m,\n\u001b[1;32m      3\u001b[0m     input_sequence_length,\n\u001b[1;32m      4\u001b[0m     forecast_horizon,\n\u001b[1;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mtest_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      6\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     multi_horizon\u001b[38;5;241m=\u001b[39mmulti_horizon,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_array' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = create_tf_dataset(\n",
    "    test_array,\n",
    "    input_sequence_length,\n",
    "    forecast_horizon,\n",
    "    batch_size=test_array.shape[0],\n",
    "    shuffle=False,\n",
    "    multi_horizon=multi_horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766baeb-edac-478a-8a30-3599ff753942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab920b5a-bb54-4712-967d-24aaa9a88375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

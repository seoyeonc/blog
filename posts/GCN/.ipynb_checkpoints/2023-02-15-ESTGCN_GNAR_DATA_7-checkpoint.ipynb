{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6c8f0bf9-e110-4e30-8596-b2dd384e79e0",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"GNAR lag 1 Randomly Missing comparison Table by Number of Filter and gnar forecast updating\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-02-15\"\n",
    "categories:\n",
    "  - ST-GCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf50ae2-58ec-4c6e-9cc8-393c473767eb",
   "metadata": {},
   "source": [
    "> GNAR fiveNet,fivenodes lag 1 (Missing rate 80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463f6e7-0b6c-490d-b7ee-4022ce4345a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f90af573-4bc0-4c9e-ad94-e9739160055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "# scipy \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import rpy2.robjects.numpy2ri as rpyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbbe91df-66c9-46da-abf9-379f37061d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f9f9-20fb-489c-9a8d-0f47cf681b1e",
   "metadata": {},
   "source": [
    "# my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "227faf0a-4609-4fb1-bb57-f72308e2b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'rb') as outfile:\n",
    "        data_dict = pickle.load(outfile)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a159f970-32cf-4719-b3b7-d16eeb939f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict,fname):\n",
    "    with open(fname,'wb') as outfile:\n",
    "        pickle.dump(data_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46b2f8de-d7db-4a8a-8b56-68987ea54c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f,*args,t=None,h=2.5,**kwargs):\n",
    "    T,N = f.shape\n",
    "    if t == None: t = range(T)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots(N,1)\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "        ax[n].set_title('node='+str(n))\n",
    "    fig.set_figheight(N*h)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfd30cd2-1daf-474d-b132-7b41af02e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_add(fig,f,*args,t=None,**kwargs):\n",
    "    T = f.shape[0]\n",
    "    N = f.shape[1] \n",
    "    if t == None: t = range(T)   \n",
    "    ax = fig.get_axes()\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5422d968-a917-483b-8e82-4ab2bf569bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Psi(T):\n",
    "    W = np.zeros((T,T))\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            if i==j :\n",
    "                W[i,j] = 0\n",
    "            elif np.abs(i-j) <= 1 : \n",
    "                W[i,j] = 1\n",
    "    d = np.array(W.sum(axis=1))\n",
    "    D = np.diag(d)\n",
    "    L = np.array(np.diag(1/np.sqrt(d)) @ (D-W) @ np.diag(1/np.sqrt(d)))\n",
    "    lamb, Psi = np.linalg.eigh(L)\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fdbd67c-4d90-4d7f-9a4f-2f73dac5485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7da0eb4f-5518-4e35-b392-9762da230d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(f):\n",
    "    f = np.array(f)\n",
    "    if len(f.shape)==1: f = f.reshape(-1,1)\n",
    "    T,N = f.shape\n",
    "    Psi = make_Psi(T)\n",
    "    fbar = Psi.T @ f # apply dft \n",
    "    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n",
    "    fhat = Psi @ fbar_threshed # inverse dft \n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3036d47a-8211-4f46-9cd3-c316e01e5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_freq_domain(signal, missing_index):\n",
    "    signal = np.array(signal)\n",
    "    T,N = signal.shape \n",
    "    signal_trimed = trim(signal)\n",
    "    for i in range(N):\n",
    "        signal[missing_index[i],i] = signal_trimed[missing_index[i],i]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c101-5cff-4aec-9f7b-fe41c9c16b47",
   "metadata": {},
   "source": [
    "# data 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4e297-0e68-4b57-adc2-2abafc28cc03",
   "metadata": {},
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bcaefae-0b23-4dbd-b35b-30a36b84095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('./data/fivenodes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50d881f0-65fc-49c4-acab-1c7b4d371a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_tensor = torch.tensor(data['edges'])\n",
    "fiveVTS = np.array(data['f'])\n",
    "nonzero_indices = edges_tensor.nonzero()\n",
    "fiveNet_edge = np.array(nonzero_indices).T\n",
    "T = 200\n",
    "N = 5 # number of Nodes\n",
    "E = fiveNet_edge\n",
    "V = np.array([1,2,3,4,5])\n",
    "t = np.arange(0,T)\n",
    "node_features = 1\n",
    "edge_index = torch.tensor(E)\n",
    "edge_attr = torch.tensor(np.array([1,1,1,1,1,1,1,1,1,1]),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed58fa-3cd6-428b-a6d0-52e3460d9e1f",
   "metadata": {},
   "source": [
    "`-` train / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cef13f89-df0c-467f-b856-7145f554e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveVTS_train = fiveVTS[:int(len(fiveVTS)*0.8)]\n",
    "fiveVTS_test = fiveVTS[int(len(fiveVTS)*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ecff-ebeb-4d3f-97de-297aa69aa487",
   "metadata": {},
   "source": [
    "# Random Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a9c2d697-7649-4ed0-a0c7-e4b66c4fd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Missing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.N = N\n",
    "        self.number = []\n",
    "    def miss(self,percent=0.5):\n",
    "        self.missing = self.df.copy()\n",
    "        self.percent = percent\n",
    "        for i in range(self.N):\n",
    "            #self.seed = np.random.choice(1000,1,replace=False)\n",
    "            #np.random.seed(self.seed)\n",
    "            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n",
    "            self.missing[self.number[i],i] = float('nan')\n",
    "    def first_mean(self):\n",
    "        self.train_mean = self.missing.copy()\n",
    "        for i in range(self.N):\n",
    "            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n",
    "    def second_linear(self):\n",
    "        self.train_linear = pd.DataFrame(self.missing)\n",
    "        self.train_linear.interpolate(method='linear', inplace=True)\n",
    "        self.train_linear = self.train_linear.fillna(0)\n",
    "        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d928975-ebe6-4361-8cd1-480bca90b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n",
    "\n",
    "filter_num = [4,8,16,24,32,64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5832fea-151e-43ca-8ef9-8d12b18a2655",
   "metadata": {},
   "source": [
    "# Class code by Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90619301-0663-4e78-8d2e-926f0efc8482",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e4cefbf-1ffb-481f-9084-42d90689956f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_Missing:\n",
    "    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "\n",
    "        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            for epoch in range(50):\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):\n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_stgcn = (((self.real_y-yhat).squeeze())**2).mean()\n",
    "            test_mse_total_stgcn = (((self.yy-yyhat).squeeze())**2).mean() \n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74841d2a-f372-4543-8f78-a22b5ba83d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "532d3cd3-ba47-4747-9933-98dfd5d44bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESTGCN_Missing:\n",
    "    def __init__(self,Dataset,df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.XX = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[:-1,:,:]).float()\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "\n",
    "        self.real_y = torch.tensor(fiveVTS_train).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "            y = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            signal = interpolated_signal.copy()\n",
    "            for epoch in range(50):\n",
    "                signal = update_from_freq_domain(signal,missing_index)\n",
    "                X = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-1),:,:]\n",
    "                y = torch.tensor(signal).reshape(int(T*0.8),N,1).float()[1:,:,:]\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):        \n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                signal = torch.concat([X.squeeze(),yt_hat.detach().squeeze().reshape(1,-1)])               \n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_estgcn = (((self.real_y-yhat).squeeze())**2).mean()\n",
    "            test_mse_total_estgcn = (((self.yy-yyhat).squeeze())**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4d8f2-8812-45b8-bd10-0f8b1ee66f3d",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbe1e6e5-6513-4fce-9934-92cb0de798d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'stgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingrate = 0.3 # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0da146bc-81ad-4092-9631-d626c969ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stgcn= pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b506a74-1c2d-475a-96f2-68f8d33e5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Number_of_filters in filter_num:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    stgcn.iter()\n",
    "    df_add = stgcn.df.copy()\n",
    "    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87310b2f-ce1a-44ee-bafd-d98d09f4dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_stgcn, './data/GNAR_stgcn_randomly_by_filter_30.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c0982-fee0-41e6-b40a-f1c20b92afa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9194b09-297b-4835-8d8d-0501c19a5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'estgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingrate = 0.3 # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eac26e-4312-43f4-b70b-f327e5158576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estgcn = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ccb52d-b2c7-4089-8af2-6bb9a9993f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Number_of_filters in filter_num:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    estgcn.iter()\n",
    "    df_add = estgcn.df.copy()\n",
    "    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc4e12-6576-44ed-852c-c2a01abfa56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_estgcn, './data/GNAR_estgcn_randomly_by_filter_30.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f82ec17-73ec-41d6-9668-a41af127089e",
   "metadata": {},
   "source": [
    "# GNAR Forecast by 1 and Continuous updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9df66-e800-4ca7-95ac-49c408436804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa59d5d-2f8d-4914-984f-a6446864ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(GNAR)\n",
    "library(igraph)\n",
    "library(zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e12ef4-b43c-4aee-a290-667e064332ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fiveNet_m <- as.matrix(fiveNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f39ce4-4c9c-4b7f-be03-498bad1b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o fiveNet_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d099607-3183-459a-82bd-8a7f0f14e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNAR = importr('GNAR') # import GNAR \n",
    "igraph = importr('igraph') # import igraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e9759-6897-44fe-94d0-2010359048ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = robjects.r.matrix(FloatVector([0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0]), nrow = 5, ncol = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb0a47-eada-462f-a653-05bdc4068f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNAR_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "    def iter(self):\n",
    "        self.yy = torch.tensor(fiveVTS_test.reshape(int(T*0.2),N,1)[1:,:,:]).float()\n",
    "        for i in range(self.iterable):\n",
    "            _zero = Missing(fiveVTS_train)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(interpolated_signal).reshape(int(T*0.8),N,1).float()[:int(T*0.8-2),:,:]\n",
    "            for j in range(40):\n",
    "\n",
    "                answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = int(len(fiveVTS)*0.8)+j, ncol = 5),net = GNAR.matrixtoGNAR(m), alphaOrder = 2, betaOrder = FloatVector([1, 1]))             \n",
    "                predict = GNAR.predict_GNARfit(answer,n_ahead=1)\n",
    "\n",
    "                X = torch.concat([X.squeeze(),torch.tensor(predict[0:5]).reshape(-1,5)])\n",
    "\n",
    "            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,5))**2).mean()\n",
    "            test_mse_total_gnar = ((self.yy.squeeze() - X[-39:,:])**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f84973-6fda-4dca-b18d-4b1158b2886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = [i/10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43a00c-8bd6-47df-b8a6-205d81f7ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'fivenodes'\n",
    "Method = 'gnar_one' # 'stgcn','estgcn','gnar' \n",
    "Missingrate = 0.3 # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 1 # 1,2,3,4 ... \n",
    "Number_of_filters = None # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a791bf9-6eaf-4bc5-97a8-d82ffc6ae07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnar = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00411a0-56e8-4eed-b4d2-5ece3b12a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    gnar = GNAR_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    gnar.iter()\n",
    "    df_add = gnar.df.copy()\n",
    "    df_gnar = pd.concat([df_gnar,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28821128-fb00-4027-aeae-97b379561738",
   "metadata": {},
   "source": [
    "save_data(df_gnar, './data/GANR_gnar_one_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca0dfc-952b-4d98-814d-1d1bc7159750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

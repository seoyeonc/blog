{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b8a18c36-7705-4cf3-a9a5-358a4a93c041",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Original CAM\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-09-15\"\n",
    "categories:\n",
    "  - CAM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd2c1b-3d3f-4114-ad2d-75cdb068f397",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d86f6-a5c9-4aef-90bb-a5514b9b4b47",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83b071-7964-4407-ab86-95162852c56e",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b518da-7b1f-47c3-b5af-c578ca1a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3a7f48-cd9c-4643-9f84-640bcb38422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a884697-3fc8-4552-bc54-a74366aab5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    if f[0].isupper():\n",
    "        return 'cat' \n",
    "    else: \n",
    "        return 'dog' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae804670-3607-4ed9-a512-4440eeb8ed30",
   "metadata": {},
   "source": [
    "# path 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9ae225-aae3-49f9-8d7b-a161227e8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('original_pet') \n",
    "files=get_image_files(path)\n",
    "dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec23b02-ca72-4b3e-aeb1-251cc5fc6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_r=Path('random_pet_one')   #랜덤박스넣은사진\n",
    "files_r=get_image_files(path_r)\n",
    "dls_r=ImageDataLoaders.from_name_func(path_r,files_r,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da02560-3697-4868-9dbd-7e7ec9ff1c15",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5abe3-5edb-47ef-b211-398c9995962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
      "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='38' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      41.30% [38/92 10:14&lt;14:33 0.4327]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr=cnn_learner(dls_r,resnet34,metrics=error_rate)\n",
    "lrnr.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae1745-d459-429d-bb39-2a7e6ac03e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=lrnr.model[0]\n",
    "net2=lrnr.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6540410-81ee-4cec-8e8b-f9ae20fc43c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f23173-c028-4ab8-addf-07a95b837359",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a741d34-9479-4d46-b2f5-23870b3cecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2=Learner(dls,net,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ecc92-c5a7-4540-b4c4-c5ff67598f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2.fine_tune(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12443a7-e2e6-43de-af50-25d5a73d0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(lrnr2)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6394e-d599-48d1-9ac3-079fb6f36603",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c87b6-131c-4547-bbc4-60e816184d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n",
    "        camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n",
    "        a,b = net(x).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b)) \n",
    "        if catprob>dogprob: \n",
    "            test=camimg[0]-torch.min(camimg[0])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)\n",
    "            (x1*0.35).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            test=camimg[1]-torch.min(camimg[1])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)\n",
    "            (x1*0.35).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b8296-43f3-4a3f-a772-e118408268c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "        camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n",
    "        a,b = net(x).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n",
    "        if catprob>dogprob: \n",
    "            test=camimg[0]-torch.min(camimg[0])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            test=camimg[1]-torch.min(camimg[1])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2967090-abe1-4977-9af2-7cf8bd18acfd",
   "metadata": {},
   "source": [
    "# CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989d64c-dda6-49b9-b422-cfcbf963e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60b810-8d8d-48c8-be41-9e49ae621c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05854f6d-e3dd-4e11-92ce-bf9446f11497",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"Input image\")\n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"CAT PART\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"DOG PART\")\n",
    "#\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09fe75-3d45-4bc3-90e2-688d6e5103ea",
   "metadata": {},
   "source": [
    "- 판단 근거가 강할 수록 파란색 -> 보라색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639aca4-d887-42a5-8955-b1bc9b8f4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0f49a-9c09-4ccb-83d0-1ae75a166d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1aa933-ee4e-464e-b514-8ba6670bdaaf",
   "metadata": {},
   "source": [
    "# DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf98d37-76ca-4cba-b0a4-eab59843bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744182a-a953-4126-ad94-6cedcbc6c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03939575-a472-4949-82c3-14f32733b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"Input image\")\n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"CAT PART\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"DOG PART\")\n",
    "#\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed813d69-1505-49c5-aecf-28a205a99c06",
   "metadata": {},
   "source": [
    "- 판단 근거가 강할 수록 파란색 -> 보라색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e46c7-4faf-4119-bac1-6d33ffec0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdc393-bcd7-49e0-aa82-3ef79004ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fd85e-28d1-4726-aa4d-f5d05c727acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29905bbc-0360-4e88-9426-d28742105a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

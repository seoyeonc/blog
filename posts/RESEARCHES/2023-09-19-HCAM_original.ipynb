{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b8a18c36-7705-4cf3-a9a5-358a4a93c041",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"**[CAM]**HCAM original\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-09-19\"\n",
    "categories:\n",
    "  - CAM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd2c1b-3d3f-4114-ad2d-75cdb068f397",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d86f6-a5c9-4aef-90bb-a5514b9b4b47",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93354ffd-fda9-44e9-ad1f-f60d060a80db",
   "metadata": {},
   "source": [
    "CNN으로 이미지 분류를 할 때 마지막 단의 출력값이 클수록 softmax를 거친 뒤 1에 가까워 진다면, 입력 이미지의 label에 해당하는 채널의 마지막 conv layer의 출력이 크게 하는 클래스에 크게 반응했다는 것이 됌..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83b071-7964-4407-ab86-95162852c56e",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b518da-7b1f-47c3-b5af-c578ca1a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3a7f48-cd9c-4643-9f84-640bcb38422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a884697-3fc8-4552-bc54-a74366aab5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    if f[0].isupper():\n",
    "        return 'cat' \n",
    "    else: \n",
    "        return 'dog' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da02560-3697-4868-9dbd-7e7ec9ff1c15",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15145b1d-6a03-4135-a43f-9ea5e84a743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('original_pet')   #랜덤박스넣은사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b771802-8427-4348-ae25-b21d7e36aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3513d4af-ceed-49e9-be0c-906febfb54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5abe3-5edb-47ef-b211-398c9995962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
      "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.183123</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>40:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='15' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.30% [15/92 07:49&lt;40:11 0.0305]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr=cnn_learner(dls,resnet34,metrics=error_rate)\n",
    "lrnr.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae1745-d459-429d-bb39-2a7e6ac03e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=lrnr.model[0]\n",
    "net2=lrnr.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6540410-81ee-4cec-8e8b-f9ae20fc43c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f23173-c028-4ab8-addf-07a95b837359",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ea828-adcc-42ac-afb8-397550452892",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2=Learner(dls,net,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091da62-09e0-4f8b-96d5-770306f3a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbc071-ead2-4e57-802a-b9f79b082476",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(lrnr2)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a5e55-1a0c-4e43-bc53-8edad36d6e3e",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0734212-51ba-4b93-8f8e-af669915b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=lrnr.model[0]\n",
    "net2=lrnr.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de349bfe-1fdf-4785-9af0-b95e0810837a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d31b1a-c13c-4bff-96f2-2dfe7d36aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc818baa-d8d0-47fb-8810-e198fe5c544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2=Learner(dls,net,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916b3e3-fe99-4c83-97c8-38f50401591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa42999-221e-442c-ba64-5a26eb699941",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(lrnr2)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374fc2b-0fab-4e0c-9a8a-4bec8d958e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_acc_s = [] #고양이를 고양이라고 잘 맞춤\n",
    "dog_acc_s = [] #강아지를 고양이라고 맞춤\n",
    "cat_acc_f = [] #강아지를 강아지라고 잘 맞춤\n",
    "dog_acc_f = [] #고양이를 강아지라고 맞춤\n",
    "\n",
    "for i in range(len(path_res1.ls())) :\n",
    "    x, = first(dls_r1.test_dl([PILImage.create(get_image_files(path_res1)[i])]))\n",
    "    camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "    a,b = net_r(x).tolist()[0]\n",
    "    catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b)) \n",
    "    if catprob>dogprob: \n",
    "        if label_func(str(list(path_res1.ls())[i]).split('/')[-1]) == 'cat' :\n",
    "            cat_acc_s.append(catprob.round(5))\n",
    "        else : \n",
    "            cat_acc_f.append(catprob.round(5))\n",
    "    else:\n",
    "        if label_func(str(list(path_res1.ls())[i]).split('/')[-1]) == 'dog' :\n",
    "            dog_acc_s.append(dogprob.round(5))\n",
    "        else : \n",
    "            dog_acc_f.append(dogprob.round(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a5ffc-f1b4-4d3f-bbc0-327b5495bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cat_acc_s))\n",
    "print(len(cat_acc_f))\n",
    "print(len(dog_acc_s))\n",
    "print(len(dog_acc_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d7680-07d1-48aa-a410-eb9342dadfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(cat_acc_s)/len(cat_acc_s) * 100)\n",
    "print(sum(cat_acc_f)/len(cat_acc_f) * 100)\n",
    "\n",
    "print(sum(dog_acc_s)/len(dog_acc_s) * 100)\n",
    "print(sum(dog_acc_f)/len(dog_acc_f) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7b88a-7762-4255-b2eb-f49e404186eb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48038029-eb37-4ee6-9d9b-e69a3d200c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 서연 수정 code\n",
    "# fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# # \n",
    "# dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "# ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\n",
    "# #\n",
    "# dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "# ax2.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\n",
    "# fig.set_figwidth(8)            \n",
    "# fig.set_figheight(8)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b922e5-6404-49a3-ab5f-bdd624655af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(5,5) \n",
    "# k=0 \n",
    "# for i in range(5):\n",
    "#     for j in range(5): \n",
    "#         x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "#         camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "#         a,b = net_r(x).tolist()[0]\n",
    "#         catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b)) \n",
    "#         if catprob>dogprob: \n",
    "#             dls_r.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n",
    "#             ax[i][j].imshow(camimg[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n",
    "#             ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "#         else: \n",
    "#             dls_r.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n",
    "#             ax[i][j].imshow(camimg[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n",
    "#             ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "#         k=k+1 \n",
    "# fig.set_figwidth(16)            \n",
    "# fig.set_figheight(16)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5bfbc-78f3-43ae-99a9-e1cf93d218a6",
   "metadata": {},
   "source": [
    "## thresholding point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b6210-3209-408e-89a2-fbb75c1ceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "        camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "        a,b = net_r(x).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n",
    "        ebayesthresh = importr('EbayesThresh').ebayesthresh\n",
    "        power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n",
    "        ybar_threshed = np.where(power_threshed>2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n",
    "        power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n",
    "        ybar_threshed2 = np.where(power_threshed>2000,torch.tensor(camimg[1].detach().reshape(-1)),0)\n",
    "        ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n",
    "        ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))\n",
    "        if catprob>dogprob: \n",
    "            # test=camimg[0]-torch.min(camimg[0])\n",
    "            A1=torch.exp(-0.1*ybar_threshed)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            # test=camimg[1]-torch.min(camimg[1])\n",
    "            A1=torch.exp(-0.1*ybar_threshed2)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5aa93d-e0a9-46f1-84b8-e2dc9405622f",
   "metadata": {},
   "source": [
    "## ebayes X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc165e3-8f34-4732-a13e-10f9bdbe3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(5,5) \n",
    "# k=0 \n",
    "# for i in range(5):\n",
    "#     for j in range(5): \n",
    "#         x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "#         camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "#         a,b = net_r(x).tolist()[0]\n",
    "#         catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n",
    "#         if catprob>dogprob: \n",
    "#             test=camimg[0]-torch.min(camimg[0])\n",
    "#             A1=torch.exp(-0.1*test)\n",
    "#             X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "#             Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "#             x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "#             (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "#             ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "#         else: \n",
    "#             test=camimg[1]-torch.min(camimg[1])\n",
    "#             A1=torch.exp(-0.1*test)\n",
    "#             X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "#             Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "#             x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "#             (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "#             ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "#         k=k+1 \n",
    "# fig.set_figwidth(16)            \n",
    "# fig.set_figheight(16)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd9a20-421a-4070-99aa-7e2958593209",
   "metadata": {},
   "source": [
    "# Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b9363-9355-4d05-bbaf-e2f965db5aa1",
   "metadata": {},
   "source": [
    "# CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf3d7e-9bd7-4d54-ab27-ed0157b886d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43264338-9c31-490c-892d-39ce90ccc47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beb0b7-3f93-4f9e-8474-a53c61de7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh\n",
    "\n",
    "power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n",
    "ybar_threshed = np.where(power_threshed>2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n",
    "ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n",
    "\n",
    "power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n",
    "ybar_threshed2 = np.where(power_threshed2>1600,torch.tensor(camimg[1].detach().reshape(-1)),0)\n",
    "ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826f756-b070-47b3-be0f-15cdb2c01106",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"Input image\")\n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"CAT PART\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"DOG PART\")\n",
    "#\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce9886-3d95-4dff-b896-62c5e7c5ae5c",
   "metadata": {},
   "source": [
    "- 판단 근거가 강할 수록 파란색 -> 보라색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb019d-6009-453a-9377-694caa396fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net_r(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506807b-fff6-4a12-9ff0-8f87079e2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2cbb2-a4af-4b43-842b-eea6a7c8042d",
   "metadata": {},
   "source": [
    "## mode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0a24f-c60b-41e2-b5bf-5b40f06a785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=camimg_o[0]-torch.min(camimg_o[0])\n",
    "T = camimg[0]\n",
    "A1=torch.exp(-0.05*(ybar_threshed))\n",
    "T1 = torch.exp(-0.05*T)\n",
    "A2 = 1 - A1\n",
    "T2 = 1 - T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d807d-6d5a-42c8-b6b2-1d7b73f3d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE1 WEIGHTT\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE1 RES WEIGHT\")\n",
    "#\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4bc3d-5c14-49cc-abca-8ee5d617d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode 1 res\n",
    "X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "\n",
    "# mode 1\n",
    "X12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98c15f-00d2-43eb-9b64-91ca14c4d34d",
   "metadata": {},
   "source": [
    "`-` 1st CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb59c70-5649-46d0-8bbe-9f7c093ce5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4fa6e4-8069-4fe8-99e4-d0af4c1f3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aff8b1-1f81-41d3-ad6f-97160c405cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1.to('cpu')\n",
    "net_2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569826fe-4bc4-4270-a2f8-741fd9140217",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg1 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011adc5-be84-464d-a053-62fdf4b4c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,b1 = net_r(x1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abd697-fab9-41b4-af2c-e2869c1884e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29baf61e-9f5a-4281-a4fe-d846cba364e4",
   "metadata": {},
   "source": [
    "`-` mode1 res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f7c16-a11f-4442-be17-383b9d91f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "(x1*0.25).squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "(x1*0.25).squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626ea07-794b-425f-b0d9-08c013ad58b3",
   "metadata": {},
   "source": [
    "`-` 첫번째 CAM 결과와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e9d2c-5065-49df-8133-dcd1a8a26c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127dde7-8e7a-4c70-9147-f483e73766cd",
   "metadata": {},
   "source": [
    "`-` 2nd CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e5188-0ce7-43d9-9630-fdd41187f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=camimg1[0]-torch.min(camimg1[0])\n",
    "A3 = torch.exp(-0.03*(test1))\n",
    "A4 = 1 - A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fc601-31e7-47c9-bc16-5374964dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE2 RES WEIGHT\")\n",
    "#\n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE2 WEIGHT\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f677e-fe60-4d0a-aef1-b4561868d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\n",
    "\n",
    "Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "x2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n",
    "\n",
    "X22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\n",
    "\n",
    "Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "x22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652aa45-7abb-48de-81d2-55593be176c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*4).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99824d88-eb94-4529-8f2b-6fd03122b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x2.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0107eaa-a5af-409b-bf32-2c42653bc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1.to('cpu')\n",
    "net_2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922f864-c57c-476e-a2c3-01e8cfbd8f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg2 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a579ac-b969-402d-a36b-22344ec19086",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2,b2 = net_r(x2).tolist()[0]\n",
    "np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f657d7-bf05-4653-85ea-92b18a9074db",
   "metadata": {},
   "source": [
    "`-` mode2 res 에 CAM 결과 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85fc14a-c8d6-4b10-b206-8b3142a126e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981041f-adc8-4df2-9b77-052d8fc22196",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"3RD CAM\")\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74f1a9-0ba2-4e03-b2b4-3c66376f6e17",
   "metadata": {},
   "source": [
    "## mode 3 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec52fb1-3a2f-4470-9e62-1307bd2b381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=camimg2[0]-torch.min(camimg2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6719f9-63da-4e97-851b-7fc78afcf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5 = torch.exp(-0.05*(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59d4fa-5a96-4208-9162-2654871704dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6 = 1 - A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882536f-2a09-4b10-92ea-f874f6c3d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcceb69-bb00-474e-abce-1ff37dab315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode 3 res\n",
    "X3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x3=x2*Y3-torch.min(x2*Y3)\n",
    "# mode 3\n",
    "X32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x32=x2*Y32-torch.min(x2*Y32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e5af5-2476-4e18-be13-706124483872",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*4).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x32*8).squeeze().show(ax=ax1)  #MODE3\n",
    "(x3).squeeze().show(ax=ax2)  #MODE3_res\n",
    "ax1.set_title(\"MODE3\")\n",
    "ax2.set_title(\"MODE3 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59221b-1da2-4ec3-b80d-f93c47e97c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "ax1.set_title(\"MODE1\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600907a0-fa43-4b55-9e1b-f6a603ccfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\n",
    "ax1.set_title(\"MODE1+MODE2\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734b7de-a302-4bc6-8e9f-b738a8eb9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\n",
    "ax1.set_title(\"MODE3+MODE2+MODE3\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47fec8-a000-4739-82ff-3a159483e259",
   "metadata": {},
   "source": [
    "# DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6322241-a03d-4345-8cd8-c05c1e2e6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700e546-0262-4247-8239-8237ad3f85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d4f02-df60-41a6-b18b-e98dcc39b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh\n",
    "\n",
    "power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n",
    "ybar_threshed = np.where(power_threshed>2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n",
    "ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n",
    "\n",
    "power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n",
    "ybar_threshed2 = np.where(power_threshed2>1500,torch.tensor(camimg[1].detach().reshape(-1)),0)\n",
    "ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbfc53b-0837-421c-9a46-80f173367bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"Input image\")\n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"CAT PART\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"DOG PART\")\n",
    "#\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29df601-3db3-4c5e-a517-4ae4e25682b2",
   "metadata": {},
   "source": [
    "- 판단 근거가 강할 수록 파란색 -> 보라색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbf5d5-7d6f-4917-a22a-cce8dd5abfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net_r(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61520df6-98f3-47e5-baa0-138251f8ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79639ca1-8753-4ef2-a5e4-5e44f481a90a",
   "metadata": {},
   "source": [
    "## mode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4cd22-d0e9-46da-8f85-3a707097ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=camimg_o[0]-torch.min(camimg_o[0])\n",
    "T = camimg[1]\n",
    "A1=torch.exp(-0.05*(ybar_threshed2))\n",
    "T1 = torch.exp(-0.05*T)\n",
    "A2 = 1 - A1\n",
    "T2 = 1 - T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a0da6-ee9d-4f60-9820-82901f836289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE1 WEIGHTT\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE1 RES WEIGHT\")\n",
    "#\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873ea9f-5bf5-4859-9228-b327b38122b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode 1 res\n",
    "X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "\n",
    "# mode 1\n",
    "X12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1d242-bde8-40d7-88da-950d8de1c37e",
   "metadata": {},
   "source": [
    "`-` 1st CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa05e8d-79a1-41e7-9b32-09e202c81987",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af8d9c-07bb-4e85-bdcc-aa560fec5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2e944-83f9-485b-b648-d2c728dd36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1.to('cpu')\n",
    "net_2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e956146-794c-413a-a0ac-571168ddcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg1 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05ab56-c3ac-45b4-8281-d232026e01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,b1 = net_r(x1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985e9db-16a2-4078-9654-f6c49ae09843",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb09942-8a7c-424a-91ff-759a835d55d5",
   "metadata": {},
   "source": [
    "`-` mode1 res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751d9c0-248e-4452-8556-01fcde7eed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "(x1*0.25).squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "(x1*0.25).squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713d272-ee1d-4f22-a18f-10d4bfa638c7",
   "metadata": {},
   "source": [
    "`-` 첫번째 CAM 결과와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200e830-794d-4e86-a844-137dc4f4f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a3e7c-8272-45ae-8c7b-0aaf343f45a9",
   "metadata": {},
   "source": [
    "`-` 2nd CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dedbe-646c-4c6d-ba7b-9ba1aa162f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=camimg1[1]-torch.min(camimg1[1])\n",
    "A3 = torch.exp(-0.05*(test1))\n",
    "A4 = 1 - A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe28d5-15d5-480f-b842-8cd0c608ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE2 RES WEIGHT\")\n",
    "#\n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE2 WEIGHT\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2fc4f-ce33-4401-9ac9-1db20d2eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res \n",
    "X2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n",
    "#\n",
    "X22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5578d-9fbb-4e4d-874f-91e623d03b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*3).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c5c75-465e-4edc-a750-c87b6ddfb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x2.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7b241-75dc-4a29-9615-990ae773bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1.to('cpu')\n",
    "net_2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e35a4-e928-4a86-a9cd-f1ac8c136cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg2 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bb0d6-eaea-4b2b-a190-87e5ff9ec29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2,b2 = net_r(x2).tolist()[0]\n",
    "np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d30419-1ff1-4b48-94ec-fb451a8eeaaf",
   "metadata": {},
   "source": [
    "`-` mode2 res 에 CAM 결과 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3d68e-f6b4-47b1-87e5-0633be6806dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d14a6-0c0b-4058-a28e-8574876d0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"3RD CAM\")\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d20ef3-e6b5-405e-a1ff-2139e9779cb4",
   "metadata": {},
   "source": [
    "## mode 3 만들기 더이상 분리되지 않는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05950869-09f4-48b5-95bf-7c772c88a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=camimg2[1]-torch.min(camimg2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeee34-89ff-492f-8dd2-a9d4d9d47ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5 = torch.exp(-0.05*(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab5da3-a2b2-4be0-aa99-5aa1bf679ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6 = 1 - A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c282c8-a5c6-49f5-9059-e0b10e9464f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e07af-da3d-48ff-9517-79cd851c0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode 3 res\n",
    "X3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x3=x2*Y3-torch.min(x2*Y3)\n",
    "# mode 3\n",
    "X32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x32=x2*Y32-torch.min(x2*Y32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bc27e-5e21-42b1-8d36-7ffc6c7800a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*4).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x32*8).squeeze().show(ax=ax1)  #MODE3\n",
    "(x3).squeeze().show(ax=ax2)  #MODE3_res\n",
    "ax1.set_title(\"MODE3\")\n",
    "ax2.set_title(\"MODE3 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c0cda-ba4a-4bb1-a805-71b8ea55a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "ax1.set_title(\"MODE1\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b26644-1251-4096-a931-93be5a005904",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\n",
    "ax1.set_title(\"MODE1+MODE2\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19340ba-8094-455b-9cf4-d1421b4201db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\n",
    "ax1.set_title(\"MODE3+MODE2+MODE3\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fd85e-28d1-4726-aa4d-f5d05c727acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29905bbc-0360-4e88-9426-d28742105a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

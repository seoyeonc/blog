{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b8a18c36-7705-4cf3-a9a5-358a4a93c041",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"CAM\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-07-26\"\n",
    "categories:\n",
    "  - CAM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd2c1b-3d3f-4114-ad2d-75cdb068f397",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d86f6-a5c9-4aef-90bb-a5514b9b4b47",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83b071-7964-4407-ab86-95162852c56e",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b518da-7b1f-47c3-b5af-c578ca1a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ca5b6-ac1a-49e4-9dc7-a42d1523a25d",
   "metadata": {},
   "source": [
    "#### (1) 랜덤박스가 들어간 개 고양이 그림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1ba35b-bdbb-4487-94f3-91e34393b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19050cc0-c59b-4d4a-8e7b-b2a3d56c2d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70016aa0-0066-47a4-8c7a-5d5234ce7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a884697-3fc8-4552-bc54-a74366aab5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    if f[0].isupper():\n",
    "        return 'cat' \n",
    "    else: \n",
    "        return 'dog' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfeb0c53-11b1-4f08-b15b-9725da0016eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a85a5-f520-49cf-8bfb-4ee63da4e60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.171485</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>37:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='48' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      52.17% [48/92 24:48&lt;22:44 0.0628]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr=cnn_learner(dls,resnet34,metrics=error_rate)\n",
    "lrnr.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "473e4380-c443-49d7-9a58-2b5eb6bcffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=lrnr.model[0]\n",
    "net2=lrnr.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9a1eefa-a1f3-4e6d-b5d7-dcbd76c8c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b20514d-0c94-483f-b092-4f8d3fc66bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d7ccfbf-df3d-4e2b-9522-35ee3698e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2=Learner(dls,net,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d5ee0-8db0-4f20-9476-4861177b2fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/92 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793c8d7-7235-402b-aa72-11d3e4ea61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(lrnr2)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf71f6-39f8-4fdd-aac6-a0d123cb857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae17c54-589e-4aa9-979b-50a79496dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d31d2-309e-4bc2-bb46-20ec20ad77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(list(path.ls())[103]).split('/')[-1].split('.')[-1]==\"jpg\" :\n",
    "    print(\"jpg\")\n",
    "#name=str(list(path.ls())[i]).split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88fb2a-02a5-4515-8535-e3d90a62162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dcd23-ec0c-4eeb-8210-f27f74bd3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7393) :\n",
    "    img = PILImage.create(get_image_files(path)[i])\n",
    "    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n",
    "    name = str(list(path.ls())[i]).split('/')[-1]\n",
    "    fname = name.split('.')[-1]\n",
    "    if fname!=\"jpg\" : \n",
    "        print(name)\n",
    "    else : pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662b860-d973-4973-8c1f-198a72aea8c1",
   "metadata": {},
   "source": [
    "`.mat` 파일 같은 이상한 거 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b8730-5756-4b4e-8229-711946aa10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"random_pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caed24-f705-4270-b5d0-fb8cd7f138a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(path.ls())) :\n",
    "    img = PILImage.create(get_image_files(path)[i])\n",
    "    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n",
    "    (w, h) = (img.shape[0], img.shape[1])\n",
    "    a = random.uniform(0, w*0.7)\n",
    "    b = random.uniform(0, h*0.9)\n",
    "    shape = [(a, b), (a+100, b+50)]\n",
    "    font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.08))\n",
    "    name = str(list(path.ls())[i]).split('/')[-1]\n",
    "    fname = name.split('.')[-1]\n",
    "    if name[0].isupper() == True :\n",
    "        img1 = ImageDraw.Draw(img)  \n",
    "        img1.rectangle(shape, fill =\"white\", outline =\"black\")\n",
    "        ImageDraw.Draw(img).text((a, b), 'CAT', (0,0,0), font=font)\n",
    "        img.save(\"random_pet/\"+name)\n",
    "    else: \n",
    "        img1 = ImageDraw.Draw(img)  \n",
    "        img1.rectangle(shape, fill =\"black\", outline =\"black\")\n",
    "        ImageDraw.Draw(img).text((a, b), 'DOG', (255,255,255), font=font)\n",
    "        img.save(\"random_pet/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15145b1d-6a03-4135-a43f-9ea5e84a743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_r=Path('random_pet')   #랜덤박스넣은사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b771802-8427-4348-ae25-b21d7e36aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_image_files(path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513d4af-ceed-49e9-be0c-906febfb54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_r=ImageDataLoaders.from_name_func(path_r,files,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5abe3-5edb-47ef-b211-398c9995962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_r1=cnn_learner(dls_r,resnet34,metrics=error_rate)\n",
    "lrnr_r1.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae1745-d459-429d-bb39-2a7e6ac03e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1=lrnr_r1.model[0]\n",
    "net_2=lrnr_r1.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6540410-81ee-4cec-8e8b-f9ae20fc43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f23173-c028-4ab8-addf-07a95b837359",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_r=torch.nn.Sequential(net_1,net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ea828-adcc-42ac-afb8-397550452892",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_r2=Learner(dls_r,net_r,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091da62-09e0-4f8b-96d5-770306f3a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_r2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbc071-ead2-4e57-802a-b9f79b082476",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(lrnr_r2)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35682c7-798f-45f3-bdd0-8b5d8c567c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[7389])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ed34e-dd14-4e9e-972f-92ca4a0073f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02f5cb1-f848-4904-a214-d68d2b52bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23e74f-e347-472f-9ee1-375a2943d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81b8f4-abbb-4d3d-aba1-fcb71e9ac2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.3,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n",
    "#\n",
    "dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.3,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b922e5-6404-49a3-ab5f-bdd624655af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "        camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "        a,b = net_r(x).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b)) \n",
    "        if catprob>dogprob: \n",
    "            dls_r.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].imshow(camimg[0].to(\"cpu\").detach(),alpha=0.3,extent=(0,512,512,0),interpolation='bilinear',cmap='magma')\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            dls_r.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].imshow(camimg[1].to(\"cpu\").detach(),alpha=0.3,extent=(0,512,512,0),interpolation='bilinear',cmap='magma')\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720ba18-e83d-400b-8370-88a8c9950501",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n",
    "        camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "        a,b = net_r(x).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n",
    "        if catprob>dogprob: \n",
    "            test=camimg[0]-torch.min(camimg[0])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.35).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            test=camimg[1]-torch.min(camimg[1])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.35).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc23cad-8af5-4ea7-9565-394601153de8",
   "metadata": {},
   "source": [
    "- `.mat`파일 있나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af0110-f56d-4280-8ece-3d73891dd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(path_r.ls())) :\n",
    "    img = PILImage.create(get_image_files(path_r)[i])\n",
    "    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n",
    "    name = str(list(path.ls())[i]).split('/')[-1]\n",
    "    fname = name.split('.')[-1]\n",
    "    if fname!=\"jpg\" : \n",
    "        print(name)\n",
    "    else : pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27953ec-32eb-4378-9a6f-7d70e899ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[1])]))\n",
    "camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n",
    "a,b = net_r(x).tolist()[0]\n",
    "catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n",
    "if catprob>dogprob: \n",
    "    test=camimg[0]-torch.min(camimg[0])\n",
    "    A1=torch.exp(-0.07*test)\n",
    "    X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "    Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "    x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "    (x1*0.35).squeeze().show()\n",
    "else: \n",
    "        test=camimg[1]-torch.min(camimg[1])\n",
    "        A1=torch.exp(-0.07*test)\n",
    "        X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "        Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "        x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "        (x1*0.35).squeeze().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb5145-f0ce-4c16-81fd-113884479e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #저장 참고\n",
    "# np_arr = np.array(tensor, dtype=np.uint8)\n",
    "# img = PIL.Image.fromarray(np_arr)\n",
    "# img.save('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b89b4-1868-4b40-ad1e-9f806ad5ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = str(list(path.ls())[1]).split('/')[-1]\n",
    "# res1=(x1*0.35).squeeze()\n",
    "# res1.show()\n",
    "# save_image(res1, \"pet3_mode1_res/\"+name)\n",
    "#res1.save(\"pet3_mode1_res/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cafc6-11e5-4eac-96b1-b93114afd2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

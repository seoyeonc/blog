<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2023-07-03">

<title>Seoyeon’s Blog for study - Other Outlier Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for study</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/blog/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Other Outlier Detection</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Other Outlier Detection</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">GODE</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GCN/index.html" class="sidebar-item-text sidebar-link">GCN</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-29-STGCN-tutorial.html" class="sidebar-item-text sidebar-link"><strong>[IT-STGCN]</strong> STGCN 튜토리얼</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html" class="sidebar-item-text sidebar-link">1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-20-Algorithm_traintest.html" class="sidebar-item-text sidebar-link">1st ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html" class="sidebar-item-text sidebar-link">2nd ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-18-Algorithm_traintest_2.html" class="sidebar-item-text sidebar-link">2nd ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html" class="sidebar-item-text sidebar-link">Adding the RecurrentGCN models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-guebin.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-21-Class.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1 80% Missing repeat</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-20-data load, data save as pickle.html" class="sidebar-item-text sidebar-link">data load, data save as pickle</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-20-EbayesThresh toy ex.html" class="sidebar-item-text sidebar-link">EbayesThresh Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-11-Algorithm_EX_1.html" class="sidebar-item-text sidebar-link">GCN Algorithm Example 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Boxplot_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-05-GNAR.html" class="sidebar-item-text sidebar-link">GNAR data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-05-31-Other Method.html" class="sidebar-item-text sidebar-link">ITSTGCN add Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-06-article_refer.html" class="sidebar-item-text sidebar-link">ITSTGCN Article Refernece</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-17-ITSTGCN-Tutorial.html" class="sidebar-item-text sidebar-link">ITSTGCN-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-06-METRLADatasetLoader.html" class="sidebar-item-text sidebar-link">METRLADatasetLoader-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-25-note_matrix.html" class="sidebar-item-text sidebar-link">Note_weight amatrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-29-pedalme_GSO_st.html" class="sidebar-item-text sidebar-link">Padalme GSO_st</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-CPUvsGPU.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal CPU vs GPU</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-PyGGeometricTemporalEx.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal Examples</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-21-ST-GCN_Dataset.html" class="sidebar-item-text sidebar-link">PyTorch ST-GCN Dataset</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">Questions of PyTorch Geometric Temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-18-Self Consistency toy ex.html" class="sidebar-item-text sidebar-link">Self Consistency Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation_boxplot.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-28-gcn_simulation.html" class="sidebar-item-text sidebar-link">Simulation of geometric-temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-simulation_table.html" class="sidebar-item-text sidebar-link">Simulation Tables</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-04-Sparse_matrix.html" class="sidebar-item-text sidebar-link">Sparse matrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html" class="sidebar-item-text sidebar-link">SY 1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-07-torchgcn.html" class="sidebar-item-text sidebar-link">TORCH_GEOMETRIC.NN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_figure.html" class="sidebar-item-text sidebar-link">Toy Example Figure(Intro)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_notes.html" class="sidebar-item-text sidebar-link">Toy Example Note</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GODE/index.html" class="sidebar-item-text sidebar-link">GODE</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-11-19-class_code_for_paper.html" class="sidebar-item-text sidebar-link">Class code for Comparison Study</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-22-comparison_earthquake.html" class="sidebar-item-text sidebar-link">Comparison Results on Real Data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-27-DFT_study.html" class="sidebar-item-text sidebar-link">Discrete Fourier Transform</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-10-02-Earthquake_real.html" class="sidebar-item-text sidebar-link">Earthquake</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-01-graph_code_guebin.html" class="sidebar-item-text sidebar-link">Graph code</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-27-Linear_graph_code_for_paper.html" class="sidebar-item-text sidebar-link">Linear Graph code for Paper</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-07-03-other_outlier_detection.html" class="sidebar-item-text sidebar-link active">Other Outlier Detection</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-09-02-paper_simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/Untitled.html" class="sidebar-item-text sidebar-link">Untitled</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a>
  <ul class="collapse">
  <li><a href="#class-code" id="toc-class-code" class="nav-link" data-scroll-target="#class-code">Class Code</a></li>
  <li><a href="#linear-ebayesthresh" id="toc-linear-ebayesthresh" class="nav-link" data-scroll-target="#linear-ebayesthresh">Linear EbayesThresh</a></li>
  <li><a href="#linear" id="toc-linear" class="nav-link" data-scroll-target="#linear">Linear</a>
  <ul class="collapse">
  <li><a href="#gode" id="toc-gode" class="nav-link" data-scroll-target="#gode">GODE</a></li>
  <li><a href="#lofbreunig2000lofstar" id="toc-lofbreunig2000lofstar" class="nav-link" data-scroll-target="#lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(Breunig et al. 2000)</span><span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">KNN</a></li>
  <li><a href="#cblof오류" id="toc-cblof오류" class="nav-link" data-scroll-target="#cblof오류">CBLOF(오류)</a></li>
  <li><a href="#ocsvm" id="toc-ocsvm" class="nav-link" data-scroll-target="#ocsvm">OCSVM</a></li>
  <li><a href="#mcdstar" id="toc-mcdstar" class="nav-link" data-scroll-target="#mcdstar">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar" id="toc-feature-baggingstar" class="nav-link" data-scroll-target="#feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar" id="toc-abodstar" class="nav-link" data-scroll-target="#abodstar">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar" id="toc-iforeststar" class="nav-link" data-scroll-target="#iforeststar">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar" id="toc-hbosstar" class="nav-link" data-scroll-target="#hbosstar">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar" id="toc-sosstar" class="nav-link" data-scroll-target="#sosstar">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaal" id="toc-so_gaal" class="nav-link" data-scroll-target="#so_gaal">SO_GAAL</a></li>
  <li><a href="#mo_gaalstar" id="toc-mo_gaalstar" class="nav-link" data-scroll-target="#mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar" id="toc-lscpstar" class="nav-link" data-scroll-target="#lscpstar">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#linear-result" id="toc-linear-result" class="nav-link" data-scroll-target="#linear-result">Linear Result</a></li>
  <li><a href="#orbit-ebayesthresh" id="toc-orbit-ebayesthresh" class="nav-link" data-scroll-target="#orbit-ebayesthresh">Orbit EbayesThresh</a></li>
  <li><a href="#orbit" id="toc-orbit" class="nav-link" data-scroll-target="#orbit">Orbit</a>
  <ul class="collapse">
  <li><a href="#gode-1" id="toc-gode-1" class="nav-link" data-scroll-target="#gode-1">GODE</a></li>
  <li><a href="#lofstar" id="toc-lofstar" class="nav-link" data-scroll-target="#lofstar">LOF<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn-1" id="toc-knn-1" class="nav-link" data-scroll-target="#knn-1">KNN</a></li>
  <li><a href="#cblof" id="toc-cblof" class="nav-link" data-scroll-target="#cblof">CBLOF</a></li>
  <li><a href="#ocsvm-1" id="toc-ocsvm-1" class="nav-link" data-scroll-target="#ocsvm-1">OCSVM</a></li>
  <li><a href="#mcdstar-1" id="toc-mcdstar-1" class="nav-link" data-scroll-target="#mcdstar-1">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar-1" id="toc-feature-baggingstar-1" class="nav-link" data-scroll-target="#feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar-1" id="toc-abodstar-1" class="nav-link" data-scroll-target="#abodstar-1">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar-1" id="toc-iforeststar-1" class="nav-link" data-scroll-target="#iforeststar-1">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar-1" id="toc-hbosstar-1" class="nav-link" data-scroll-target="#hbosstar-1">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar-1" id="toc-sosstar-1" class="nav-link" data-scroll-target="#sosstar-1">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaalstar" id="toc-so_gaalstar" class="nav-link" data-scroll-target="#so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#mo_gaalstar-1" id="toc-mo_gaalstar-1" class="nav-link" data-scroll-target="#mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar-1" id="toc-lscpstar-1" class="nav-link" data-scroll-target="#lscpstar-1">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#orbit-result" id="toc-orbit-result" class="nav-link" data-scroll-target="#orbit-result">Orbit Result</a></li>
  <li><a href="#bunny" id="toc-bunny" class="nav-link" data-scroll-target="#bunny">Bunny</a>
  <ul class="collapse">
  <li><a href="#bunny-저장용" id="toc-bunny-저장용" class="nav-link" data-scroll-target="#bunny-저장용">bunny 저장용</a></li>
  <li><a href="#gode-2" id="toc-gode-2" class="nav-link" data-scroll-target="#gode-2">GODE</a></li>
  <li><a href="#lof" id="toc-lof" class="nav-link" data-scroll-target="#lof">LOF</a></li>
  <li><a href="#knn-2" id="toc-knn-2" class="nav-link" data-scroll-target="#knn-2">KNN</a></li>
  <li><a href="#cblof-1" id="toc-cblof-1" class="nav-link" data-scroll-target="#cblof-1">CBLOF</a></li>
  <li><a href="#ocsvm-2" id="toc-ocsvm-2" class="nav-link" data-scroll-target="#ocsvm-2">OCSVM</a></li>
  <li><a href="#mcd" id="toc-mcd" class="nav-link" data-scroll-target="#mcd">MCD</a></li>
  <li><a href="#feature-bagging" id="toc-feature-bagging" class="nav-link" data-scroll-target="#feature-bagging">Feature Bagging</a></li>
  <li><a href="#abod" id="toc-abod" class="nav-link" data-scroll-target="#abod">ABOD</a></li>
  <li><a href="#iforest" id="toc-iforest" class="nav-link" data-scroll-target="#iforest">IForest</a></li>
  <li><a href="#hbos" id="toc-hbos" class="nav-link" data-scroll-target="#hbos">HBOS</a></li>
  <li><a href="#sos" id="toc-sos" class="nav-link" data-scroll-target="#sos">SOS</a></li>
  <li><a href="#so_gaal-1" id="toc-so_gaal-1" class="nav-link" data-scroll-target="#so_gaal-1">SO_GAAL</a></li>
  <li><a href="#mo_gaal" id="toc-mo_gaal" class="nav-link" data-scroll-target="#mo_gaal">MO_GAAL</a></li>
  <li><a href="#lscp" id="toc-lscp" class="nav-link" data-scroll-target="#lscp">LSCP</a></li>
  </ul></li>
  <li><a href="#bunny-result" id="toc-bunny-result" class="nav-link" data-scroll-target="#bunny-result">Bunny Result</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>knn, cblof, ocsvm 을 제외한 이상치 탐지 기법들에 데이터 집합에서 이상치 비율을 지정할 수 있는 옵션이 존재하였음.</p>
<p>default값은 10%인데, ABOD 방법에서는 5로 지정해주었고, 다른 방법들은 default인 10%가 들어갔다.</p>
<p>일단 우리 방법이랑 비교해서 좋은지 보기</p>
</div>
</div>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(5,7)\)</span> and <span class="math inline">\(U(-7,-5)\)</span>.</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.930</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;"><strong>0.988</strong></td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.889</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.883</td>
<td style="text-align: center;">0.938</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.896</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.997</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.926</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;"><strong>0.999</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.984</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.885</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.936</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.943</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.970</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.997</strong></td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.998</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.886</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.892</td>
<td style="text-align: center;">0.937</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.918</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.958</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.866</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.903</td>
<td style="text-align: center;">0.928</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.979</td>
<td style="text-align: center;">0.927</td>
<td style="text-align: center;">0.952</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.378</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.514</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.876</td>
<td style="text-align: center;">0.959</td>
<td style="text-align: center;">0.908</td>
<td style="text-align: center;">0.933</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.999</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(3,7)\)</span> and <span class="math inline">\(U(-7,-3)\)</span>.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Stanford Bunny 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.995</strong></td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.997</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.869</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.932</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.937</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.938</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.915</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.794</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.788</td>
<td style="text-align: center;">0.879</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.967</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Stanford Bunny 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.988</strong></td>
<td style="text-align: center;"><strong>0.995</strong></td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.913</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.990</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.884</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.958</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.989</td>
</tr>
</tbody>
</table>
<section id="import" class="level1">
<h1>Import</h1>
<div class="cell" data-execution_count="397">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDOneClassSVM</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> Nystroem</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2.robjects <span class="im">as</span> ro </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.vectors <span class="im">import</span> FloatVector </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.packages <span class="im">import</span> importr</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_kddcup99, fetch_covtype, fetch_openml</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tqdm</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score, accuracy_score</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.covariance <span class="im">import</span> EmpiricalCovariance, MinCovDet</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> alibi_detect.od <span class="im">import</span> IForest</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># from pyod.models.iforest import IForest</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.abod <span class="im">import</span> ABOD</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.cblof <span class="im">import</span> CBLOF</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PyNomaly <span class="im">import</span> loop</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lscp <span class="im">import</span> LSCP</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.hbos <span class="im">import</span> HBOS</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.so_gaal <span class="im">import</span> SO_GAAL</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mcd <span class="im">import</span> MCD</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mo_gaal <span class="im">import</span> MO_GAAL</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lof <span class="im">import</span> LOF</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.ocsvm <span class="im">import</span> OCSVM</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.feature_bagging <span class="im">import</span> FeatureBagging</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.sos <span class="im">import</span> SOS</span></code></pre></div>
</div>
<div class="cell" data-execution_count="398">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<section id="class-code" class="level2">
<h2 class="anchored" data-anchor-id="class-code">Class Code</h2>
<div class="cell" data-execution_count="666">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>tab_linear <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>tab_orbit <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>tab_bunny <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="254">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conf_matrx:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,original,compare,tab):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original <span class="op">=</span> original</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compare <span class="op">=</span> compare</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> tab</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> conf(<span class="va">self</span>,name):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conf_matrix <span class="op">=</span> confusion_matrix(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        ax.matshow(<span class="va">self</span>.conf_matrix, cmap<span class="op">=</span>plt.cm.Oranges, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>                ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span><span class="va">self</span>.conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Confusion Matrix'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.acc <span class="op">=</span> accuracy_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pre <span class="op">=</span> precision_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rec <span class="op">=</span> recall_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f1 <span class="op">=</span> f1_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.acc)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Precision: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.pre)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Recall: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.rec)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'F1 Score: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.f1)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> <span class="va">self</span>.tab.append(pd.DataFrame({<span class="st">"Accuracy"</span>:[<span class="va">self</span>.acc],<span class="st">"Precision"</span>:[<span class="va">self</span>.pre],<span class="st">"Recall"</span>:[<span class="va">self</span>.rec],<span class="st">"F1"</span>:[<span class="va">self</span>.f1]},index <span class="op">=</span> [name]))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="255">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.y1 = df.y1.to_numpy()</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> w</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)      </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.y <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.ybar,<span class="dv">0</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.yhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.ybar_threshed</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(yHat <span class="op">=</span> <span class="va">self</span>.yhat)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.y<span class="op">-</span> <span class="va">self</span>.df.yHat)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="256">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Orbit:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_distance(<span class="va">self</span>):</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> np.zeros([<span class="va">self</span>.n,<span class="va">self</span>.n])</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        locations <span class="op">=</span> np.stack([<span class="va">self</span>.x, <span class="va">self</span>.y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm.tqdm(<span class="bu">range</span>(<span class="va">self</span>.n)):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i,<span class="va">self</span>.n):</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.D[i,j]<span class="op">=</span>np.linalg.norm(locations[i]<span class="op">-</span>locations[j])</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> <span class="va">self</span>.D <span class="op">+</span> <span class="va">self</span>.D.T</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_weightmatrix(<span class="va">self</span>,theta<span class="op">=</span><span class="dv">1</span>,beta<span class="op">=</span><span class="fl">0.5</span>,kappa<span class="op">=</span><span class="dv">4000</span>):</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta <span class="op">=</span> theta</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.where(<span class="va">self</span>.D <span class="op">&lt;</span> kappa,<span class="va">self</span>.D,<span class="dv">0</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.exp(<span class="op">-</span>(dist<span class="op">/</span><span class="va">self</span>.theta)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.f <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f<span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="257">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BUNNY:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z <span class="op">=</span> df.z.to_numpy()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.noise <span class="op">=</span> df.noise.to_numpy()</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fnoise <span class="op">=</span> <span class="va">self</span>.f <span class="op">+</span> <span class="va">self</span>.noise</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> _W</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">6</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.fnoise <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fnoise <span class="op">=</span> <span class="va">self</span>.fnoise)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f <span class="op">+</span> <span class="va">self</span>.df.noise <span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
</section>
<section id="linear-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="linear-ebayesthresh">Linear EbayesThresh</h2>
<div class="cell" data-execution_count="258">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>signal_1 <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1 <span class="op">=</span> which(signal_1<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>x_1<span class="op">=</span>signal_1<span class="op">+</span>epsilon</span></code></pre></div>
</div>
<div class="cell" data-execution_count="276">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x_1</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier_1</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="277">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="278">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index_1 <span class="op">=</span> index_of_trueoutlier_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="279">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value_1 <span class="op">=</span> x_1[index_of_trueoutlier_1]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="280">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> signal_1.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="281">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_1))</span></code></pre></div>
</div>
</section>
<section id="linear" class="level2">
<h2 class="anchored" data-anchor-id="linear">Linear</h2>
<div class="cell" data-tags="[]" data-execution_count="403">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>_x_1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1000</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>_y1_1 <span class="op">=</span> <span class="dv">5</span><span class="op">*</span>_x_1</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>_y_1 <span class="op">=</span> _y1_1 <span class="op">+</span> x_1 <span class="co"># x is epsilon</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="404">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>_df<span class="op">=</span>pd.DataFrame({<span class="st">'x'</span>:_x_1, <span class="st">'y'</span>:_y_1})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="405">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<section id="gode" class="level3">
<h3 class="anchored" data-anchor-id="gode">GODE</h3>
<div class="cell" data-execution_count="406">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span>np.zeros((<span class="dv">1000</span>,<span class="dv">1000</span>))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="407">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">==</span>j :</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> np.<span class="bu">abs</span>(i<span class="op">-</span>j) <span class="op">&lt;=</span> <span class="dv">1</span> : </span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="408">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>_Linear <span class="op">=</span> Linear(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="409">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>_Linear.fit(sd<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="507">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Linear.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="508">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">10.7</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="509">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="510">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="510">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="511">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="511">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="513">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.994
Precision: 0.997
Recall: 0.997
F1 Score: 0.997</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="514">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="514">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.994</td>
      <td>0.996842</td>
      <td>0.996842</td>
      <td>0.996842</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lofbreunig2000lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(<a href="#ref-breunig2000lof" role="doc-biblioref">Breunig et al. 2000</a>)</span><span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="301">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<p>Lof 논문 원문에 따라 LOF를 계산하고, min-max 범위를 넘으면 이상치</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figs/lof.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure: LOF’s outliers detection method</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="302">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="303">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.926
Precision: 0.961
Recall: 0.961
F1 Score: 0.961</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="306">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>tab_linear.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  tab_linear.append(_conf.tab)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="306">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.926</td>
      <td>0.961053</td>
      <td>0.961053</td>
      <td>0.961053</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="knn" class="level3">
<h3 class="anchored" data-anchor-id="knn">KNN</h3>
<div class="cell" data-execution_count="307">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="308">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p>k번째 이상은 outlier로 본다.</p>
<p><strong>이상치 비율 정하지 않음</strong></p>
<p>Three kNN detectors are supported:</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the outlier score</li>
</ul>
<div class="cell" data-execution_count="309">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="310">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="311">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="969">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="cblof오류" class="level3">
<h3 class="anchored" data-anchor-id="cblof오류">CBLOF(오류)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="971">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="972">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="973">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="975">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>four <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="ocsvm" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm">OCSVM</h3>
<p>default=10%</p>
<div class="cell" data-execution_count="313">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="314">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="314">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="315">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="316">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="317">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-52-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.991
Recall: 0.940
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="318">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="318">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.991121</td>
      <td>0.94</td>
      <td>0.964884</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mcdstar" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="320">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="321">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="322">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="323">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="324">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-58-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="325">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="325">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="feature-baggingstar" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<p>default값은 10%로 설정되어 있었고, 5%로 지정한 결과, 평가지표값이 전반적으로 1%이상 낮아졌다.</p>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="326">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="327">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="328">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="329">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="330">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-64-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.984
Precision: 0.992
Recall: 0.992
F1 Score: 0.992</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="331">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="331">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.984</td>
      <td>0.991579</td>
      <td>0.991579</td>
      <td>0.991579</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="abodstar" class="level3">
<h3 class="anchored" data-anchor-id="abodstar">ABOD<span class="math inline">\(\star\)</span></h3>
<p>default 값이 5%이며, 이미 지정된 채려 시뮬레이션 돌림</p>
<div class="cell" data-execution_count="332">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p><strong>contamination</strong> : float in (0., 0.5), optional (default=0.1)</p>
<ul>
<li>The amount of contamination of the data set, i.e.</li>
<li>the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.</li>
</ul>
<div class="cell" data-execution_count="333">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="334">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="335">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="336">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-70-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="337">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="337">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="iforeststar" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar">IForest<span class="math inline">\(\star\)</span></h3>
<p>n_estimators Number of base estimators in the ensemble.</p>
<ul>
<li>n이 총 1000개니까 5%인 50 지정해줄 수 있음</li>
</ul>
<div class="cell" data-execution_count="338">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="339">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="340">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>]],</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="341">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="342">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="343">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="344">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="345">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-79-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.885
Precision: 0.999
Recall: 0.880
F1 Score: 0.936</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="346">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="346">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.885</td>
      <td>0.998805</td>
      <td>0.88</td>
      <td>0.935646</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="hbosstar" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar">HBOS<span class="math inline">\(\star\)</span></h3>
<p>default값은 이상치값을 10%로 지정하였으며, 5%로 지정한 결과 값 다 작아짐</p>
<div class="cell" data-execution_count="384">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="385">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="386">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="387">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="388">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-85-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.960
Precision: 0.978
Recall: 0.980
F1 Score: 0.979</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="389">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="389">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.96</td>
      <td>0.977941</td>
      <td>0.98</td>
      <td>0.97897</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sosstar" class="level3">
<h3 class="anchored" data-anchor-id="sosstar">SOS<span class="math inline">\(\star\)</span></h3>
<p>default 는 10%</p>
<div class="cell" data-execution_count="355">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="356">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="357">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="358">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="359">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-91-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="360">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="360">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.916</td>
      <td>0.955789</td>
      <td>0.955789</td>
      <td>0.955789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="so_gaal" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal">SO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="361">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 862us/step - loss: 1.0640

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 827us/step - loss: 1.0818
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 853us/step - loss: 1.0984

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 846us/step - loss: 1.1023
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 851us/step - loss: 1.1116

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 830us/step - loss: 1.1127
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 815us/step - loss: 1.1359

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 812us/step - loss: 1.1429
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 808us/step - loss: 1.1177

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 785us/step - loss: 1.1457
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 805us/step - loss: 1.1468

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 802us/step - loss: 1.1501
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.1816

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 797us/step - loss: 1.1725
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 796us/step - loss: 1.1822

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 798us/step - loss: 1.1752
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 868us/step - loss: 1.1898

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 805us/step - loss: 1.2337
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 819us/step - loss: 1.2280

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.2237
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 816us/step - loss: 1.2403

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.2572
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.2652

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 809us/step - loss: 1.2678
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.2597

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 801us/step - loss: 1.2931
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 804us/step - loss: 1.2927

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 815us/step - loss: 1.3224
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 808us/step - loss: 1.3126

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 812us/step - loss: 1.3397
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.3516

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 798us/step - loss: 1.3297
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 800us/step - loss: 1.3493

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 826us/step - loss: 1.3447
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 803us/step - loss: 1.3573

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 799us/step - loss: 1.3643
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 809us/step - loss: 1.3702

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 800us/step - loss: 1.4059
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 802us/step - loss: 1.4023

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 875us/step - loss: 1.3997
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 796us/step - loss: 1.4110

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 796us/step - loss: 1.4132
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 791us/step - loss: 1.4308

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 804us/step - loss: 1.4205
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.4429

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 785us/step - loss: 1.4500
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 813us/step - loss: 1.4560

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4629
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.4531

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4627
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 868us/step - loss: 1.4971

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 871us/step - loss: 1.5024
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 801us/step - loss: 1.4855

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 877us/step - loss: 1.5128
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 872us/step - loss: 1.5061

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 872us/step - loss: 1.5104
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 871us/step - loss: 1.5186

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 890us/step - loss: 1.5191
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 690us/step - loss: 1.5765

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 802us/step - loss: 1.5212
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5610

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5390
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 822us/step - loss: 1.5472

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.5762
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5946

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 988us/step - loss: 1.6020
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6007

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5847
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5918

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 795us/step - loss: 1.6119
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6314

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6356
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 959us/step - loss: 1.6195

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6137
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 848us/step - loss: 1.6543

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6529
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 790us/step - loss: 1.6446

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6672
32/32 [==============================] - 0s 572us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="362">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="363">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="364">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="365">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-97-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.936
Precision: 0.966
Recall: 0.966
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="366">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="366">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.936</td>
      <td>0.966316</td>
      <td>0.966316</td>
      <td>0.966316</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mo_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="367">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 578us/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 588us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 830us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 560us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 947us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 568us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 601us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 635us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 617us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 616us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 620us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 696us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 620us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 696us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 696us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 598us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 844us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 627us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 869us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 615us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 826us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 614us/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 872us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 622us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 614us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 702us/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 616us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 623us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 631us/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 629us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 831us/step - loss: 0.2442
16/16 [==============================] - 0s 830us/step - loss: 0.7355
16/16 [==============================] - 0s 827us/step - loss: 1.0992
16/16 [==============================] - 0s 896us/step - loss: 1.3980
16/16 [==============================] - 0s 876us/step - loss: 1.5344
16/16 [==============================] - 0s 844us/step - loss: 1.6077
16/16 [==============================] - 0s 849us/step - loss: 1.6388
16/16 [==============================] - 0s 808us/step - loss: 1.6578
16/16 [==============================] - 0s 829us/step - loss: 1.6642
16/16 [==============================] - 0s 805us/step - loss: 1.6662
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 622us/step
16/16 [==============================] - 0s 817us/step - loss: 0.2554
16/16 [==============================] - 0s 831us/step - loss: 0.7341
16/16 [==============================] - 0s 812us/step - loss: 1.0999
16/16 [==============================] - 0s 849us/step - loss: 1.3911
16/16 [==============================] - 0s 828us/step - loss: 1.5222
16/16 [==============================] - 0s 819us/step - loss: 1.5852
16/16 [==============================] - 0s 800us/step - loss: 1.6118
16/16 [==============================] - 0s 808us/step - loss: 1.6276
16/16 [==============================] - 0s 799us/step - loss: 1.6324
16/16 [==============================] - 0s 825us/step - loss: 1.6339

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 843us/step - loss: 0.2366
16/16 [==============================] - 0s 797us/step - loss: 0.7465
16/16 [==============================] - 0s 819us/step - loss: 1.1457
16/16 [==============================] - 0s 786us/step - loss: 1.4587
16/16 [==============================] - 0s 824us/step - loss: 1.5968
16/16 [==============================] - 0s 841us/step - loss: 1.6577
16/16 [==============================] - 0s 827us/step - loss: 1.6835
16/16 [==============================] - 0s 808us/step - loss: 1.6982
16/16 [==============================] - 0s 807us/step - loss: 1.7024
16/16 [==============================] - 0s 835us/step - loss: 1.7036
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2361
16/16 [==============================] - 0s 793us/step - loss: 0.7428
16/16 [==============================] - 0s 794us/step - loss: 1.1534
16/16 [==============================] - 0s 814us/step - loss: 1.4658
16/16 [==============================] - 0s 800us/step - loss: 1.5961
16/16 [==============================] - 0s 807us/step - loss: 1.6504
16/16 [==============================] - 0s 820us/step - loss: 1.6722
16/16 [==============================] - 0s 793us/step - loss: 1.6837
16/16 [==============================] - 0s 795us/step - loss: 1.6869
16/16 [==============================] - 0s 798us/step - loss: 1.6878

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2431
16/16 [==============================] - 0s 805us/step - loss: 0.7496
16/16 [==============================] - 0s 800us/step - loss: 1.1677
16/16 [==============================] - 0s 789us/step - loss: 1.4776
16/16 [==============================] - 0s 793us/step - loss: 1.6030
16/16 [==============================] - 0s 797us/step - loss: 1.6522
16/16 [==============================] - 0s 803us/step - loss: 1.6718
16/16 [==============================] - 0s 819us/step - loss: 1.6812
16/16 [==============================] - 0s 804us/step - loss: 1.6837
16/16 [==============================] - 0s 804us/step - loss: 1.6843
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 813us/step - loss: 0.2415
16/16 [==============================] - 0s 799us/step - loss: 0.7505
16/16 [==============================] - 0s 876us/step - loss: 1.1814
16/16 [==============================] - 0s 808us/step - loss: 1.4910
16/16 [==============================] - 0s 803us/step - loss: 1.6103
16/16 [==============================] - 0s 797us/step - loss: 1.6554
16/16 [==============================] - 0s 813us/step - loss: 1.6721
16/16 [==============================] - 0s 808us/step - loss: 1.6797
16/16 [==============================] - 0s 883us/step - loss: 1.6816
16/16 [==============================] - 0s 904us/step - loss: 1.6819

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 800us/step - loss: 0.2375
16/16 [==============================] - 0s 785us/step - loss: 0.7587
16/16 [==============================] - 0s 786us/step - loss: 1.2044
16/16 [==============================] - 0s 795us/step - loss: 1.5185
16/16 [==============================] - 0s 795us/step - loss: 1.6332
16/16 [==============================] - 0s 809us/step - loss: 1.6752
16/16 [==============================] - 0s 876us/step - loss: 1.6902
16/16 [==============================] - 0s 784us/step - loss: 1.6965
16/16 [==============================] - 0s 787us/step - loss: 1.6980
16/16 [==============================] - 0s 783us/step - loss: 1.6981
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2494
16/16 [==============================] - 0s 781us/step - loss: 0.7594
16/16 [==============================] - 0s 781us/step - loss: 1.1934
16/16 [==============================] - 0s 802us/step - loss: 1.5007
16/16 [==============================] - 0s 776us/step - loss: 1.6008
16/16 [==============================] - 0s 783us/step - loss: 1.6370
16/16 [==============================] - 0s 775us/step - loss: 1.6496
16/16 [==============================] - 0s 871us/step - loss: 1.6543
16/16 [==============================] - 0s 855us/step - loss: 1.6554
16/16 [==============================] - 0s 793us/step - loss: 1.6554

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2409
16/16 [==============================] - 0s 780us/step - loss: 0.7635
16/16 [==============================] - 0s 794us/step - loss: 1.2141
16/16 [==============================] - 0s 780us/step - loss: 1.5226
16/16 [==============================] - 0s 777us/step - loss: 1.6196
16/16 [==============================] - 0s 773us/step - loss: 1.6527
16/16 [==============================] - 0s 795us/step - loss: 1.6639
16/16 [==============================] - 0s 779us/step - loss: 1.6678
16/16 [==============================] - 0s 774us/step - loss: 1.6685
16/16 [==============================] - 0s 794us/step - loss: 1.6684
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 787us/step - loss: 0.2487
16/16 [==============================] - 0s 778us/step - loss: 0.7632
16/16 [==============================] - 0s 781us/step - loss: 1.2111
16/16 [==============================] - 0s 790us/step - loss: 1.5075
16/16 [==============================] - 0s 770us/step - loss: 1.5966
16/16 [==============================] - 0s 779us/step - loss: 1.6256
16/16 [==============================] - 0s 799us/step - loss: 1.6345
16/16 [==============================] - 0s 783us/step - loss: 1.6375
16/16 [==============================] - 0s 772us/step - loss: 1.6379
16/16 [==============================] - 0s 778us/step - loss: 1.6377

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 806us/step - loss: 0.2401
16/16 [==============================] - 0s 792us/step - loss: 0.7722
16/16 [==============================] - 0s 801us/step - loss: 1.2335
16/16 [==============================] - 0s 796us/step - loss: 1.5382
16/16 [==============================] - 0s 797us/step - loss: 1.6241
16/16 [==============================] - 0s 826us/step - loss: 1.6522
16/16 [==============================] - 0s 861us/step - loss: 1.6602
16/16 [==============================] - 0s 862us/step - loss: 1.6627
16/16 [==============================] - 0s 866us/step - loss: 1.6629
16/16 [==============================] - 0s 885us/step - loss: 1.6627
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 668us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2333
16/16 [==============================] - 0s 782us/step - loss: 0.7913
16/16 [==============================] - 0s 794us/step - loss: 1.2768
16/16 [==============================] - 0s 782us/step - loss: 1.5948
16/16 [==============================] - 0s 778us/step - loss: 1.6772
16/16 [==============================] - 0s 777us/step - loss: 1.7041
16/16 [==============================] - 0s 778us/step - loss: 1.7113
16/16 [==============================] - 0s 867us/step - loss: 1.7133
16/16 [==============================] - 0s 863us/step - loss: 1.7134
16/16 [==============================] - 0s 883us/step - loss: 1.7131

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 803us/step - loss: 0.2502
16/16 [==============================] - 0s 776us/step - loss: 0.7807
16/16 [==============================] - 0s 788us/step - loss: 1.2273
16/16 [==============================] - 0s 788us/step - loss: 1.5163
16/16 [==============================] - 0s 783us/step - loss: 1.5878
16/16 [==============================] - 0s 764us/step - loss: 1.6098
16/16 [==============================] - 0s 803us/step - loss: 1.6156
16/16 [==============================] - 0s 782us/step - loss: 1.6169
16/16 [==============================] - 0s 773us/step - loss: 1.6168
16/16 [==============================] - 0s 790us/step - loss: 1.6165
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 873us/step - loss: 0.2442
16/16 [==============================] - 0s 783us/step - loss: 0.7980
16/16 [==============================] - 0s 790us/step - loss: 1.2739
16/16 [==============================] - 0s 859us/step - loss: 1.5676
16/16 [==============================] - 0s 870us/step - loss: 1.6381
16/16 [==============================] - 0s 857us/step - loss: 1.6591
16/16 [==============================] - 0s 778us/step - loss: 1.6644
16/16 [==============================] - 0s 783us/step - loss: 1.6654
16/16 [==============================] - 0s 783us/step - loss: 1.6653
16/16 [==============================] - 0s 880us/step - loss: 1.6649

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 796us/step - loss: 0.2358
16/16 [==============================] - 0s 810us/step - loss: 0.7929
16/16 [==============================] - 0s 795us/step - loss: 1.2759
16/16 [==============================] - 0s 791us/step - loss: 1.5708
16/16 [==============================] - 0s 887us/step - loss: 1.6388
16/16 [==============================] - 0s 860us/step - loss: 1.6583
16/16 [==============================] - 0s 800us/step - loss: 1.6629
16/16 [==============================] - 0s 804us/step - loss: 1.6637
16/16 [==============================] - 0s 793us/step - loss: 1.6635
16/16 [==============================] - 0s 797us/step - loss: 1.6631
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 866us/step - loss: 0.2461
16/16 [==============================] - 0s 870us/step - loss: 0.8010
16/16 [==============================] - 0s 879us/step - loss: 1.2778
16/16 [==============================] - 0s 786us/step - loss: 1.5659
16/16 [==============================] - 0s 785us/step - loss: 1.6292
16/16 [==============================] - 0s 778us/step - loss: 1.6467
16/16 [==============================] - 0s 773us/step - loss: 1.6507
16/16 [==============================] - 0s 783us/step - loss: 1.6512
16/16 [==============================] - 0s 781us/step - loss: 1.6509
16/16 [==============================] - 0s 881us/step - loss: 1.6505

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 816us/step - loss: 0.2467
16/16 [==============================] - 0s 871us/step - loss: 0.8035
16/16 [==============================] - 0s 808us/step - loss: 1.2758
16/16 [==============================] - 0s 788us/step - loss: 1.5587
16/16 [==============================] - 0s 793us/step - loss: 1.6187
16/16 [==============================] - 0s 821us/step - loss: 1.6348
16/16 [==============================] - 0s 804us/step - loss: 1.6383
16/16 [==============================] - 0s 799us/step - loss: 1.6386
16/16 [==============================] - 0s 811us/step - loss: 1.6383
16/16 [==============================] - 0s 849us/step - loss: 1.6378
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 801us/step - loss: 0.2443
16/16 [==============================] - 0s 797us/step - loss: 0.8144
16/16 [==============================] - 0s 784us/step - loss: 1.2987
16/16 [==============================] - 0s 807us/step - loss: 1.5808
16/16 [==============================] - 0s 793us/step - loss: 1.6388
16/16 [==============================] - 0s 781us/step - loss: 1.6542
16/16 [==============================] - 0s 803us/step - loss: 1.6573
16/16 [==============================] - 0s 814us/step - loss: 1.6575
16/16 [==============================] - 0s 785us/step - loss: 1.6570
16/16 [==============================] - 0s 805us/step - loss: 1.6566

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 626us/step
16/16 [==============================] - 0s 780us/step - loss: 0.2401
16/16 [==============================] - 0s 786us/step - loss: 0.8137
16/16 [==============================] - 0s 767us/step - loss: 1.3065
16/16 [==============================] - 0s 777us/step - loss: 1.5921
16/16 [==============================] - 0s 777us/step - loss: 1.6496
16/16 [==============================] - 0s 772us/step - loss: 1.6646
16/16 [==============================] - 0s 774us/step - loss: 1.6676
16/16 [==============================] - 0s 774us/step - loss: 1.6676
16/16 [==============================] - 0s 771us/step - loss: 1.6672
16/16 [==============================] - 0s 1ms/step - loss: 1.6668
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 852us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2448
16/16 [==============================] - 0s 1ms/step - loss: 0.8181
16/16 [==============================] - 0s 1ms/step - loss: 1.3169
16/16 [==============================] - 0s 1ms/step - loss: 1.6009
16/16 [==============================] - 0s 1ms/step - loss: 1.6568
16/16 [==============================] - 0s 1ms/step - loss: 1.6712
16/16 [==============================] - 0s 1ms/step - loss: 1.6738
16/16 [==============================] - 0s 1ms/step - loss: 1.6738
16/16 [==============================] - 0s 1ms/step - loss: 1.6733
16/16 [==============================] - 0s 1ms/step - loss: 1.6729

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 799us/step - loss: 0.2406
16/16 [==============================] - 0s 806us/step - loss: 0.8169
16/16 [==============================] - 0s 790us/step - loss: 1.3234
16/16 [==============================] - 0s 784us/step - loss: 1.6093
16/16 [==============================] - 0s 791us/step - loss: 1.6646
16/16 [==============================] - 0s 1ms/step - loss: 1.6786
16/16 [==============================] - 0s 1ms/step - loss: 1.6810
16/16 [==============================] - 0s 785us/step - loss: 1.6809
16/16 [==============================] - 0s 796us/step - loss: 1.6804
16/16 [==============================] - 0s 1ms/step - loss: 1.6799
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 856us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2314
16/16 [==============================] - 0s 798us/step - loss: 0.8227
16/16 [==============================] - 0s 771us/step - loss: 1.3532
16/16 [==============================] - 0s 771us/step - loss: 1.6509
16/16 [==============================] - 0s 1ms/step - loss: 1.7075
16/16 [==============================] - 0s 1ms/step - loss: 1.7219
16/16 [==============================] - 0s 1ms/step - loss: 1.7243
16/16 [==============================] - 0s 779us/step - loss: 1.7241
16/16 [==============================] - 0s 780us/step - loss: 1.7236
16/16 [==============================] - 0s 1ms/step - loss: 1.7232

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2430
16/16 [==============================] - 0s 782us/step - loss: 0.8187
16/16 [==============================] - 0s 772us/step - loss: 1.3371
16/16 [==============================] - 0s 800us/step - loss: 1.6239
16/16 [==============================] - 0s 776us/step - loss: 1.6777
16/16 [==============================] - 0s 773us/step - loss: 1.6911
16/16 [==============================] - 0s 779us/step - loss: 1.6933
16/16 [==============================] - 0s 812us/step - loss: 1.6930
16/16 [==============================] - 0s 782us/step - loss: 1.6925
16/16 [==============================] - 0s 780us/step - loss: 1.6920
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 829us/step - loss: 0.2215
16/16 [==============================] - 0s 781us/step - loss: 0.8192
16/16 [==============================] - 0s 816us/step - loss: 1.3681
16/16 [==============================] - 0s 778us/step - loss: 1.6695
16/16 [==============================] - 0s 806us/step - loss: 1.7252
16/16 [==============================] - 0s 772us/step - loss: 1.7389
16/16 [==============================] - 0s 774us/step - loss: 1.7410
16/16 [==============================] - 0s 1ms/step - loss: 1.7407
16/16 [==============================] - 0s 1ms/step - loss: 1.7401
16/16 [==============================] - 0s 802us/step - loss: 1.7396

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2442
16/16 [==============================] - 0s 778us/step - loss: 0.8062
16/16 [==============================] - 0s 781us/step - loss: 1.3207
16/16 [==============================] - 0s 775us/step - loss: 1.6016
16/16 [==============================] - 0s 788us/step - loss: 1.6528
16/16 [==============================] - 0s 790us/step - loss: 1.6652
16/16 [==============================] - 0s 1ms/step - loss: 1.6669
16/16 [==============================] - 0s 1ms/step - loss: 1.6666
16/16 [==============================] - 0s 1ms/step - loss: 1.6660
16/16 [==============================] - 0s 796us/step - loss: 1.6655
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 870us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2375
16/16 [==============================] - 0s 795us/step - loss: 0.8257
16/16 [==============================] - 0s 780us/step - loss: 1.3547
16/16 [==============================] - 0s 1ms/step - loss: 1.6472
16/16 [==============================] - 0s 1ms/step - loss: 1.6999
16/16 [==============================] - 0s 1ms/step - loss: 1.7126
16/16 [==============================] - 0s 776us/step - loss: 1.7144
16/16 [==============================] - 0s 804us/step - loss: 1.7139
16/16 [==============================] - 0s 803us/step - loss: 1.7134
16/16 [==============================] - 0s 807us/step - loss: 1.7129

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 850us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2315
16/16 [==============================] - 0s 774us/step - loss: 0.8231
16/16 [==============================] - 0s 812us/step - loss: 1.3534
16/16 [==============================] - 0s 777us/step - loss: 1.6488
16/16 [==============================] - 0s 772us/step - loss: 1.7017
16/16 [==============================] - 0s 1ms/step - loss: 1.7143
16/16 [==============================] - 0s 808us/step - loss: 1.7160
16/16 [==============================] - 0s 1ms/step - loss: 1.7156
16/16 [==============================] - 0s 1ms/step - loss: 1.7150
16/16 [==============================] - 0s 1ms/step - loss: 1.7145
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 791us/step - loss: 0.2183
16/16 [==============================] - 0s 1ms/step - loss: 0.8358
16/16 [==============================] - 0s 816us/step - loss: 1.3978
16/16 [==============================] - 0s 785us/step - loss: 1.7101
16/16 [==============================] - 0s 770us/step - loss: 1.7654
16/16 [==============================] - 0s 766us/step - loss: 1.7786
16/16 [==============================] - 0s 798us/step - loss: 1.7803
16/16 [==============================] - 0s 773us/step - loss: 1.7798
16/16 [==============================] - 0s 777us/step - loss: 1.7792
16/16 [==============================] - 0s 788us/step - loss: 1.7787

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 799us/step - loss: 0.2312
16/16 [==============================] - 0s 791us/step - loss: 0.8347
16/16 [==============================] - 0s 789us/step - loss: 1.3870
16/16 [==============================] - 0s 1ms/step - loss: 1.6952
16/16 [==============================] - 0s 1ms/step - loss: 1.7499
16/16 [==============================] - 0s 777us/step - loss: 1.7629
16/16 [==============================] - 0s 1ms/step - loss: 1.7646
16/16 [==============================] - 0s 1ms/step - loss: 1.7642
16/16 [==============================] - 0s 772us/step - loss: 1.7636
16/16 [==============================] - 0s 1ms/step - loss: 1.7631
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 832us/step
16/16 [==============================] - 0s 792us/step - loss: 0.2219
16/16 [==============================] - 0s 809us/step - loss: 0.8349
16/16 [==============================] - 0s 774us/step - loss: 1.4016
16/16 [==============================] - 0s 776us/step - loss: 1.7174
16/16 [==============================] - 0s 781us/step - loss: 1.7730
16/16 [==============================] - 0s 777us/step - loss: 1.7861
16/16 [==============================] - 0s 806us/step - loss: 1.7878
16/16 [==============================] - 0s 785us/step - loss: 1.7873
16/16 [==============================] - 0s 849us/step - loss: 1.7867
16/16 [==============================] - 0s 797us/step - loss: 1.7862

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 778us/step - loss: 0.2198
16/16 [==============================] - 0s 797us/step - loss: 0.8154
16/16 [==============================] - 0s 775us/step - loss: 1.3622
16/16 [==============================] - 0s 787us/step - loss: 1.6691
16/16 [==============================] - 0s 791us/step - loss: 1.7227
16/16 [==============================] - 0s 768us/step - loss: 1.7352
16/16 [==============================] - 0s 818us/step - loss: 1.7367
16/16 [==============================] - 0s 794us/step - loss: 1.7362
16/16 [==============================] - 0s 805us/step - loss: 1.7356
16/16 [==============================] - 0s 778us/step - loss: 1.7351
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2221
16/16 [==============================] - 0s 812us/step - loss: 0.8290
16/16 [==============================] - 0s 775us/step - loss: 1.3930
16/16 [==============================] - 0s 766us/step - loss: 1.6988
16/16 [==============================] - 0s 843us/step - loss: 1.7532
16/16 [==============================] - 0s 815us/step - loss: 1.7658
16/16 [==============================] - 0s 808us/step - loss: 1.7673
16/16 [==============================] - 0s 776us/step - loss: 1.7667
16/16 [==============================] - 0s 809us/step - loss: 1.7661
16/16 [==============================] - 0s 805us/step - loss: 1.7656

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 786us/step - loss: 0.2237
16/16 [==============================] - 0s 813us/step - loss: 0.8281
16/16 [==============================] - 0s 788us/step - loss: 1.4075
16/16 [==============================] - 0s 781us/step - loss: 1.7080
16/16 [==============================] - 0s 790us/step - loss: 1.7636
16/16 [==============================] - 0s 785us/step - loss: 1.7765
16/16 [==============================] - 0s 824us/step - loss: 1.7781
16/16 [==============================] - 0s 779us/step - loss: 1.7776
16/16 [==============================] - 0s 832us/step - loss: 1.7770
16/16 [==============================] - 0s 846us/step - loss: 1.7765
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 815us/step - loss: 0.2216
16/16 [==============================] - 0s 778us/step - loss: 0.8257
16/16 [==============================] - 0s 767us/step - loss: 1.4080
16/16 [==============================] - 0s 779us/step - loss: 1.7093
16/16 [==============================] - 0s 779us/step - loss: 1.7644
16/16 [==============================] - 0s 1ms/step - loss: 1.7769
16/16 [==============================] - 0s 1ms/step - loss: 1.7784
16/16 [==============================] - 0s 1ms/step - loss: 1.7778
16/16 [==============================] - 0s 1ms/step - loss: 1.7772
16/16 [==============================] - 0s 1ms/step - loss: 1.7767

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2256
16/16 [==============================] - 0s 827us/step - loss: 0.8196
16/16 [==============================] - 0s 816us/step - loss: 1.3982
16/16 [==============================] - 0s 798us/step - loss: 1.6984
16/16 [==============================] - 0s 784us/step - loss: 1.7537
16/16 [==============================] - 0s 821us/step - loss: 1.7663
16/16 [==============================] - 0s 1ms/step - loss: 1.7678
16/16 [==============================] - 0s 1ms/step - loss: 1.7672
16/16 [==============================] - 0s 1ms/step - loss: 1.7666
16/16 [==============================] - 0s 1ms/step - loss: 1.7661
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 849us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2225
16/16 [==============================] - 0s 811us/step - loss: 0.8187
16/16 [==============================] - 0s 808us/step - loss: 1.4016
16/16 [==============================] - 0s 778us/step - loss: 1.7034
16/16 [==============================] - 0s 1ms/step - loss: 1.7582
16/16 [==============================] - 0s 734us/step - loss: 1.7706
16/16 [==============================] - 0s 1ms/step - loss: 1.7720
16/16 [==============================] - 0s 792us/step - loss: 1.7713
16/16 [==============================] - 0s 786us/step - loss: 1.7707
16/16 [==============================] - 0s 775us/step - loss: 1.7702

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2222
16/16 [==============================] - 0s 763us/step - loss: 0.8215
16/16 [==============================] - 0s 769us/step - loss: 1.4169
16/16 [==============================] - 0s 758us/step - loss: 1.7273
16/16 [==============================] - 0s 1ms/step - loss: 1.7844
16/16 [==============================] - 0s 772us/step - loss: 1.7973
16/16 [==============================] - 0s 760us/step - loss: 1.7988
16/16 [==============================] - 0s 764us/step - loss: 1.7983
16/16 [==============================] - 0s 1ms/step - loss: 1.7976
16/16 [==============================] - 0s 798us/step - loss: 1.7971
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 844us/step
16/16 [==============================] - 0s 783us/step - loss: 0.2152
16/16 [==============================] - 0s 784us/step - loss: 0.8201
16/16 [==============================] - 0s 1ms/step - loss: 1.4240
16/16 [==============================] - 0s 1ms/step - loss: 1.7393
16/16 [==============================] - 0s 1ms/step - loss: 1.7968
16/16 [==============================] - 0s 1ms/step - loss: 1.8097
16/16 [==============================] - 0s 775us/step - loss: 1.8111
16/16 [==============================] - 0s 787us/step - loss: 1.8105
16/16 [==============================] - 0s 803us/step - loss: 1.8099
16/16 [==============================] - 0s 809us/step - loss: 1.8093

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 842us/step - loss: 0.2151
16/16 [==============================] - 0s 802us/step - loss: 0.8166
16/16 [==============================] - 0s 813us/step - loss: 1.4138
16/16 [==============================] - 0s 793us/step - loss: 1.7288
16/16 [==============================] - 0s 823us/step - loss: 1.7865
16/16 [==============================] - 0s 814us/step - loss: 1.7994
16/16 [==============================] - 0s 804us/step - loss: 1.8008
16/16 [==============================] - 0s 783us/step - loss: 1.8002
16/16 [==============================] - 0s 801us/step - loss: 1.7996
16/16 [==============================] - 0s 808us/step - loss: 1.7991
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 818us/step
16/16 [==============================] - 0s 805us/step - loss: 0.2050
16/16 [==============================] - 0s 795us/step - loss: 0.8289
16/16 [==============================] - 0s 791us/step - loss: 1.4504
16/16 [==============================] - 0s 790us/step - loss: 1.7804
16/16 [==============================] - 0s 775us/step - loss: 1.8405
16/16 [==============================] - 0s 778us/step - loss: 1.8539
16/16 [==============================] - 0s 806us/step - loss: 1.8554
16/16 [==============================] - 0s 1ms/step - loss: 1.8548
16/16 [==============================] - 0s 1ms/step - loss: 1.8541
16/16 [==============================] - 0s 1ms/step - loss: 1.8536

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2105
16/16 [==============================] - 0s 793us/step - loss: 0.8226
16/16 [==============================] - 0s 1ms/step - loss: 1.4313
16/16 [==============================] - 0s 806us/step - loss: 1.7525
16/16 [==============================] - 0s 818us/step - loss: 1.8117
16/16 [==============================] - 0s 789us/step - loss: 1.8248
16/16 [==============================] - 0s 818us/step - loss: 1.8263
16/16 [==============================] - 0s 792us/step - loss: 1.8257
16/16 [==============================] - 0s 809us/step - loss: 1.8250
16/16 [==============================] - 0s 836us/step - loss: 1.8245
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 795us/step - loss: 0.2015
16/16 [==============================] - 0s 806us/step - loss: 0.8330
16/16 [==============================] - 0s 789us/step - loss: 1.4669
16/16 [==============================] - 0s 769us/step - loss: 1.8040
16/16 [==============================] - 0s 811us/step - loss: 1.8662
16/16 [==============================] - 0s 819us/step - loss: 1.8801
16/16 [==============================] - 0s 819us/step - loss: 1.8817
16/16 [==============================] - 0s 804us/step - loss: 1.8811
16/16 [==============================] - 0s 767us/step - loss: 1.8804
16/16 [==============================] - 0s 773us/step - loss: 1.8799

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2090
16/16 [==============================] - 0s 2ms/step - loss: 0.8199
16/16 [==============================] - 0s 2ms/step - loss: 1.4259
16/16 [==============================] - 0s 1ms/step - loss: 1.7494
16/16 [==============================] - 0s 752us/step - loss: 1.8087
16/16 [==============================] - 0s 775us/step - loss: 1.8217
16/16 [==============================] - 0s 790us/step - loss: 1.8231
16/16 [==============================] - 0s 772us/step - loss: 1.8224
16/16 [==============================] - 0s 2ms/step - loss: 1.8217
16/16 [==============================] - 0s 2ms/step - loss: 1.8212
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 936us/step
16/16 [==============================] - 0s 819us/step - loss: 0.2074
16/16 [==============================] - 0s 2ms/step - loss: 0.8283
16/16 [==============================] - 0s 2ms/step - loss: 1.4517
16/16 [==============================] - 0s 2ms/step - loss: 1.7854
16/16 [==============================] - 0s 770us/step - loss: 1.8463
16/16 [==============================] - 0s 2ms/step - loss: 1.8597
16/16 [==============================] - 0s 2ms/step - loss: 1.8611
16/16 [==============================] - 0s 2ms/step - loss: 1.8605
16/16 [==============================] - 0s 797us/step - loss: 1.8598
16/16 [==============================] - 0s 813us/step - loss: 1.8593

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2030
16/16 [==============================] - 0s 2ms/step - loss: 0.8287
16/16 [==============================] - 0s 2ms/step - loss: 1.4616
16/16 [==============================] - 0s 947us/step - loss: 1.8025
16/16 [==============================] - 0s 766us/step - loss: 1.8622
16/16 [==============================] - 0s 981us/step - loss: 1.8755
16/16 [==============================] - 0s 2ms/step - loss: 1.8769
16/16 [==============================] - 0s 1ms/step - loss: 1.8762
16/16 [==============================] - 0s 2ms/step - loss: 1.8755
16/16 [==============================] - 0s 833us/step - loss: 1.8750
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2062
16/16 [==============================] - 0s 2ms/step - loss: 0.8221
16/16 [==============================] - 0s 2ms/step - loss: 1.4472
16/16 [==============================] - 0s 2ms/step - loss: 1.7832
16/16 [==============================] - 0s 2ms/step - loss: 1.8412
16/16 [==============================] - 0s 2ms/step - loss: 1.8542
16/16 [==============================] - 0s 798us/step - loss: 1.8555
16/16 [==============================] - 0s 2ms/step - loss: 1.8548
16/16 [==============================] - 0s 827us/step - loss: 1.8541
16/16 [==============================] - 0s 1ms/step - loss: 1.8536

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 805us/step - loss: 0.2065
16/16 [==============================] - 0s 798us/step - loss: 0.8351
16/16 [==============================] - 0s 1ms/step - loss: 1.4656
16/16 [==============================] - 0s 2ms/step - loss: 1.8095
16/16 [==============================] - 0s 2ms/step - loss: 1.8689
16/16 [==============================] - 0s 2ms/step - loss: 1.8821
16/16 [==============================] - 0s 2ms/step - loss: 1.8835
16/16 [==============================] - 0s 2ms/step - loss: 1.8828
16/16 [==============================] - 0s 798us/step - loss: 1.8821
16/16 [==============================] - 0s 815us/step - loss: 1.8816
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1969
16/16 [==============================] - 0s 799us/step - loss: 0.8283
16/16 [==============================] - 0s 2ms/step - loss: 1.4682
16/16 [==============================] - 0s 2ms/step - loss: 1.8167
16/16 [==============================] - 0s 806us/step - loss: 1.8761
16/16 [==============================] - 0s 846us/step - loss: 1.8893
16/16 [==============================] - 0s 1ms/step - loss: 1.8905
16/16 [==============================] - 0s 802us/step - loss: 1.8898
16/16 [==============================] - 0s 1ms/step - loss: 1.8891
16/16 [==============================] - 0s 805us/step - loss: 1.8885

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 715us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2048
16/16 [==============================] - 0s 794us/step - loss: 0.8273
16/16 [==============================] - 0s 1ms/step - loss: 1.4605
16/16 [==============================] - 0s 893us/step - loss: 1.8055
16/16 [==============================] - 0s 2ms/step - loss: 1.8641
16/16 [==============================] - 0s 2ms/step - loss: 1.8770
16/16 [==============================] - 0s 808us/step - loss: 1.8782
16/16 [==============================] - 0s 1ms/step - loss: 1.8774
16/16 [==============================] - 0s 752us/step - loss: 1.8767
16/16 [==============================] - 0s 2ms/step - loss: 1.8762
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1993
16/16 [==============================] - 0s 2ms/step - loss: 0.8345
16/16 [==============================] - 0s 1ms/step - loss: 1.4813
16/16 [==============================] - 0s 801us/step - loss: 1.8351
16/16 [==============================] - 0s 762us/step - loss: 1.8942
16/16 [==============================] - 0s 801us/step - loss: 1.9073
16/16 [==============================] - 0s 2ms/step - loss: 1.9085
16/16 [==============================] - 0s 2ms/step - loss: 1.9077
16/16 [==============================] - 0s 2ms/step - loss: 1.9070
16/16 [==============================] - 0s 2ms/step - loss: 1.9065

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2034
16/16 [==============================] - 0s 2ms/step - loss: 0.8315
16/16 [==============================] - 0s 2ms/step - loss: 1.4620
16/16 [==============================] - 0s 799us/step - loss: 1.8092
16/16 [==============================] - 0s 1ms/step - loss: 1.8668
16/16 [==============================] - 0s 889us/step - loss: 1.8794
16/16 [==============================] - 0s 2ms/step - loss: 1.8805
16/16 [==============================] - 0s 867us/step - loss: 1.8796
16/16 [==============================] - 0s 939us/step - loss: 1.8789
16/16 [==============================] - 0s 843us/step - loss: 1.8784
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 570us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2014
16/16 [==============================] - 0s 819us/step - loss: 0.8300
16/16 [==============================] - 0s 788us/step - loss: 1.4568
16/16 [==============================] - 0s 828us/step - loss: 1.8020
16/16 [==============================] - 0s 2ms/step - loss: 1.8579
16/16 [==============================] - 0s 2ms/step - loss: 1.8700
16/16 [==============================] - 0s 2ms/step - loss: 1.8709
16/16 [==============================] - 0s 780us/step - loss: 1.8700
16/16 [==============================] - 0s 788us/step - loss: 1.8693
16/16 [==============================] - 0s 826us/step - loss: 1.8688

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 829us/step - loss: 0.2047
16/16 [==============================] - 0s 791us/step - loss: 0.8333
16/16 [==============================] - 0s 1ms/step - loss: 1.4539
16/16 [==============================] - 0s 827us/step - loss: 1.7984
16/16 [==============================] - 0s 837us/step - loss: 1.8540
16/16 [==============================] - 0s 826us/step - loss: 1.8659
16/16 [==============================] - 0s 2ms/step - loss: 1.8668
16/16 [==============================] - 0s 1ms/step - loss: 1.8659
16/16 [==============================] - 0s 1ms/step - loss: 1.8652
16/16 [==============================] - 0s 2ms/step - loss: 1.8646
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 779us/step - loss: 0.2034
16/16 [==============================] - 0s 853us/step - loss: 0.8267
16/16 [==============================] - 0s 2ms/step - loss: 1.4422
16/16 [==============================] - 0s 1ms/step - loss: 1.7828
16/16 [==============================] - 0s 868us/step - loss: 1.8365
16/16 [==============================] - 0s 1ms/step - loss: 1.8479
16/16 [==============================] - 0s 802us/step - loss: 1.8486
16/16 [==============================] - 0s 2ms/step - loss: 1.8477
16/16 [==============================] - 0s 1ms/step - loss: 1.8469
16/16 [==============================] - 0s 796us/step - loss: 1.8464

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 659us/step
16/16 [==============================] - 0s 857us/step - loss: 0.1954
16/16 [==============================] - 0s 850us/step - loss: 0.8554
16/16 [==============================] - 0s 763us/step - loss: 1.5063
16/16 [==============================] - 0s 847us/step - loss: 1.8737
16/16 [==============================] - 0s 774us/step - loss: 1.9321
16/16 [==============================] - 0s 773us/step - loss: 1.9449
16/16 [==============================] - 0s 786us/step - loss: 1.9459
16/16 [==============================] - 0s 769us/step - loss: 1.9451
16/16 [==============================] - 0s 775us/step - loss: 1.9444
16/16 [==============================] - 0s 781us/step - loss: 1.9439
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2032
16/16 [==============================] - 0s 770us/step - loss: 0.8365
16/16 [==============================] - 0s 851us/step - loss: 1.4474
16/16 [==============================] - 0s 779us/step - loss: 1.7883
16/16 [==============================] - 0s 761us/step - loss: 1.8403
16/16 [==============================] - 0s 771us/step - loss: 1.8511
16/16 [==============================] - 0s 766us/step - loss: 1.8516
16/16 [==============================] - 0s 766us/step - loss: 1.8506
16/16 [==============================] - 0s 762us/step - loss: 1.8498
16/16 [==============================] - 0s 775us/step - loss: 1.8493

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 762us/step - loss: 0.1946
16/16 [==============================] - 0s 781us/step - loss: 0.8535
16/16 [==============================] - 0s 813us/step - loss: 1.4905
16/16 [==============================] - 0s 795us/step - loss: 1.8507
16/16 [==============================] - 0s 818us/step - loss: 1.9058
16/16 [==============================] - 0s 1ms/step - loss: 1.9174
16/16 [==============================] - 0s 1ms/step - loss: 1.9180
16/16 [==============================] - 0s 787us/step - loss: 1.9171
16/16 [==============================] - 0s 785us/step - loss: 1.9163
16/16 [==============================] - 0s 789us/step - loss: 1.9158
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1920
16/16 [==============================] - 0s 1ms/step - loss: 0.8667
16/16 [==============================] - 0s 1ms/step - loss: 1.5162
16/16 [==============================] - 0s 1ms/step - loss: 1.8831
16/16 [==============================] - 0s 1ms/step - loss: 1.9383
16/16 [==============================] - 0s 1ms/step - loss: 1.9498
16/16 [==============================] - 0s 882us/step - loss: 1.9504
16/16 [==============================] - 0s 867us/step - loss: 1.9494
16/16 [==============================] - 0s 860us/step - loss: 1.9486
16/16 [==============================] - 0s 886us/step - loss: 1.9481

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1961
16/16 [==============================] - 0s 875us/step - loss: 0.8599
16/16 [==============================] - 0s 784us/step - loss: 1.4982
16/16 [==============================] - 0s 870us/step - loss: 1.8590
16/16 [==============================] - 0s 875us/step - loss: 1.9127
16/16 [==============================] - 0s 877us/step - loss: 1.9239
16/16 [==============================] - 0s 780us/step - loss: 1.9244
16/16 [==============================] - 0s 870us/step - loss: 1.9234
16/16 [==============================] - 0s 900us/step - loss: 1.9226
16/16 [==============================] - 0s 885us/step - loss: 1.9221
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1906
16/16 [==============================] - 0s 833us/step - loss: 0.8721
16/16 [==============================] - 0s 785us/step - loss: 1.5320
16/16 [==============================] - 0s 1ms/step - loss: 1.9031
16/16 [==============================] - 0s 1ms/step - loss: 1.9574
16/16 [==============================] - 0s 1ms/step - loss: 1.9686
16/16 [==============================] - 0s 1ms/step - loss: 1.9690
16/16 [==============================] - 0s 794us/step - loss: 1.9679
16/16 [==============================] - 0s 784us/step - loss: 1.9671
16/16 [==============================] - 0s 787us/step - loss: 1.9666

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1942
16/16 [==============================] - 0s 784us/step - loss: 0.8684
16/16 [==============================] - 0s 781us/step - loss: 1.5212
16/16 [==============================] - 0s 795us/step - loss: 1.8875
16/16 [==============================] - 0s 786us/step - loss: 1.9405
16/16 [==============================] - 0s 781us/step - loss: 1.9512
16/16 [==============================] - 0s 781us/step - loss: 1.9515
16/16 [==============================] - 0s 793us/step - loss: 1.9504
16/16 [==============================] - 0s 784us/step - loss: 1.9496
16/16 [==============================] - 0s 782us/step - loss: 1.9491
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1894
16/16 [==============================] - 0s 792us/step - loss: 0.8742
16/16 [==============================] - 0s 790us/step - loss: 1.5435
16/16 [==============================] - 0s 788us/step - loss: 1.9175
16/16 [==============================] - 0s 783us/step - loss: 1.9711
16/16 [==============================] - 0s 786us/step - loss: 1.9818
16/16 [==============================] - 0s 787us/step - loss: 1.9820
16/16 [==============================] - 0s 792us/step - loss: 1.9810
16/16 [==============================] - 0s 791us/step - loss: 1.9802
16/16 [==============================] - 0s 799us/step - loss: 1.9796

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1939
16/16 [==============================] - 0s 787us/step - loss: 0.8649
16/16 [==============================] - 0s 779us/step - loss: 1.5200
16/16 [==============================] - 0s 785us/step - loss: 1.8842
16/16 [==============================] - 0s 1ms/step - loss: 1.9357
16/16 [==============================] - 0s 1ms/step - loss: 1.9457
16/16 [==============================] - 0s 1ms/step - loss: 1.9458
16/16 [==============================] - 0s 1ms/step - loss: 1.9446
16/16 [==============================] - 0s 1ms/step - loss: 1.9438
16/16 [==============================] - 0s 1ms/step - loss: 1.9433
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 633us/step
16/16 [==============================] - 0s 846us/step - loss: 0.2051
16/16 [==============================] - 0s 793us/step - loss: 0.8592
16/16 [==============================] - 0s 840us/step - loss: 1.4964
16/16 [==============================] - 0s 794us/step - loss: 1.8473
16/16 [==============================] - 0s 812us/step - loss: 1.8961
16/16 [==============================] - 0s 792us/step - loss: 1.9052
16/16 [==============================] - 0s 815us/step - loss: 1.9052
16/16 [==============================] - 0s 812us/step - loss: 1.9040
16/16 [==============================] - 0s 830us/step - loss: 1.9033
16/16 [==============================] - 0s 807us/step - loss: 1.9027

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 794us/step - loss: 0.1899
16/16 [==============================] - 0s 809us/step - loss: 0.8706
16/16 [==============================] - 0s 808us/step - loss: 1.5429
16/16 [==============================] - 0s 823us/step - loss: 1.9137
16/16 [==============================] - 0s 816us/step - loss: 1.9652
16/16 [==============================] - 0s 787us/step - loss: 1.9749
16/16 [==============================] - 0s 784us/step - loss: 1.9749
16/16 [==============================] - 0s 817us/step - loss: 1.9737
16/16 [==============================] - 0s 779us/step - loss: 1.9729
16/16 [==============================] - 0s 818us/step - loss: 1.9724
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 620us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1924
16/16 [==============================] - 0s 802us/step - loss: 0.8632
16/16 [==============================] - 0s 819us/step - loss: 1.5266
16/16 [==============================] - 0s 1ms/step - loss: 1.8876
16/16 [==============================] - 0s 808us/step - loss: 1.9365
16/16 [==============================] - 0s 831us/step - loss: 1.9453
16/16 [==============================] - 0s 989us/step - loss: 1.9451
16/16 [==============================] - 0s 1ms/step - loss: 1.9439
16/16 [==============================] - 0s 1ms/step - loss: 1.9430
16/16 [==============================] - 0s 1ms/step - loss: 1.9425

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 805us/step - loss: 0.1927
16/16 [==============================] - 0s 887us/step - loss: 0.8685
16/16 [==============================] - 0s 811us/step - loss: 1.5446
16/16 [==============================] - 0s 805us/step - loss: 1.9131
16/16 [==============================] - 0s 819us/step - loss: 1.9631
16/16 [==============================] - 0s 811us/step - loss: 1.9722
16/16 [==============================] - 0s 811us/step - loss: 1.9721
16/16 [==============================] - 0s 827us/step - loss: 1.9708
16/16 [==============================] - 0s 821us/step - loss: 1.9700
16/16 [==============================] - 0s 798us/step - loss: 1.9695
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 804us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1900
16/16 [==============================] - 0s 794us/step - loss: 0.8666
16/16 [==============================] - 0s 829us/step - loss: 1.5422
16/16 [==============================] - 0s 799us/step - loss: 1.9066
16/16 [==============================] - 0s 789us/step - loss: 1.9549
16/16 [==============================] - 0s 821us/step - loss: 1.9633
16/16 [==============================] - 0s 797us/step - loss: 1.9630
16/16 [==============================] - 0s 806us/step - loss: 1.9617
16/16 [==============================] - 0s 1ms/step - loss: 1.9609
16/16 [==============================] - 0s 796us/step - loss: 1.9603

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 793us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1893
16/16 [==============================] - 0s 798us/step - loss: 0.8677
16/16 [==============================] - 0s 812us/step - loss: 1.5436
16/16 [==============================] - 0s 810us/step - loss: 1.9078
16/16 [==============================] - 0s 791us/step - loss: 1.9554
16/16 [==============================] - 0s 791us/step - loss: 1.9636
16/16 [==============================] - 0s 794us/step - loss: 1.9632
16/16 [==============================] - 0s 787us/step - loss: 1.9618
16/16 [==============================] - 0s 788us/step - loss: 1.9610
16/16 [==============================] - 0s 797us/step - loss: 1.9604
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1920
16/16 [==============================] - 0s 866us/step - loss: 0.8652
16/16 [==============================] - 0s 861us/step - loss: 1.5393
16/16 [==============================] - 0s 897us/step - loss: 1.8998
16/16 [==============================] - 0s 861us/step - loss: 1.9463
16/16 [==============================] - 0s 885us/step - loss: 1.9543
16/16 [==============================] - 0s 871us/step - loss: 1.9538
16/16 [==============================] - 0s 850us/step - loss: 1.9525
16/16 [==============================] - 0s 794us/step - loss: 1.9517
16/16 [==============================] - 0s 786us/step - loss: 1.9511

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1924
16/16 [==============================] - 0s 797us/step - loss: 0.8578
16/16 [==============================] - 0s 784us/step - loss: 1.5246
16/16 [==============================] - 0s 852us/step - loss: 1.8795
16/16 [==============================] - 0s 822us/step - loss: 1.9246
16/16 [==============================] - 0s 1ms/step - loss: 1.9321
16/16 [==============================] - 0s 1ms/step - loss: 1.9315
16/16 [==============================] - 0s 1ms/step - loss: 1.9302
16/16 [==============================] - 0s 849us/step - loss: 1.9293
16/16 [==============================] - 0s 797us/step - loss: 1.9288
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1912
16/16 [==============================] - 0s 793us/step - loss: 0.8643
16/16 [==============================] - 0s 786us/step - loss: 1.5409
16/16 [==============================] - 0s 839us/step - loss: 1.8974
16/16 [==============================] - 0s 825us/step - loss: 1.9422
16/16 [==============================] - 0s 783us/step - loss: 1.9491
16/16 [==============================] - 0s 785us/step - loss: 1.9485
16/16 [==============================] - 0s 1ms/step - loss: 1.9471
16/16 [==============================] - 0s 1ms/step - loss: 1.9462
16/16 [==============================] - 0s 1ms/step - loss: 1.9457

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1941
16/16 [==============================] - 0s 790us/step - loss: 0.8572
16/16 [==============================] - 0s 817us/step - loss: 1.5258
16/16 [==============================] - 0s 790us/step - loss: 1.8769
16/16 [==============================] - 0s 809us/step - loss: 1.9209
16/16 [==============================] - 0s 801us/step - loss: 1.9274
16/16 [==============================] - 0s 768us/step - loss: 1.9267
16/16 [==============================] - 0s 806us/step - loss: 1.9253
16/16 [==============================] - 0s 793us/step - loss: 1.9245
16/16 [==============================] - 0s 1ms/step - loss: 1.9239
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1994
16/16 [==============================] - 0s 790us/step - loss: 0.8588
16/16 [==============================] - 0s 783us/step - loss: 1.5245
16/16 [==============================] - 0s 789us/step - loss: 1.8703
16/16 [==============================] - 0s 783us/step - loss: 1.9128
16/16 [==============================] - 0s 803us/step - loss: 1.9189
16/16 [==============================] - 0s 804us/step - loss: 1.9181
16/16 [==============================] - 0s 792us/step - loss: 1.9167
16/16 [==============================] - 0s 808us/step - loss: 1.9159
16/16 [==============================] - 0s 1ms/step - loss: 1.9153

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1935
16/16 [==============================] - 0s 1ms/step - loss: 0.8608
16/16 [==============================] - 0s 1ms/step - loss: 1.5410
16/16 [==============================] - 0s 1ms/step - loss: 1.8951
16/16 [==============================] - 0s 1ms/step - loss: 1.9378
16/16 [==============================] - 0s 1ms/step - loss: 1.9441
16/16 [==============================] - 0s 1ms/step - loss: 1.9434
16/16 [==============================] - 0s 1ms/step - loss: 1.9420
16/16 [==============================] - 0s 1ms/step - loss: 1.9411
16/16 [==============================] - 0s 1ms/step - loss: 1.9406
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1915
16/16 [==============================] - 0s 1ms/step - loss: 0.8815
16/16 [==============================] - 0s 1ms/step - loss: 1.5885
16/16 [==============================] - 0s 1ms/step - loss: 1.9539
16/16 [==============================] - 0s 1ms/step - loss: 1.9968
16/16 [==============================] - 0s 1ms/step - loss: 2.0031
16/16 [==============================] - 0s 1ms/step - loss: 2.0023
16/16 [==============================] - 0s 1ms/step - loss: 2.0008
16/16 [==============================] - 0s 1ms/step - loss: 2.0000
16/16 [==============================] - 0s 855us/step - loss: 1.9994

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1896
16/16 [==============================] - 0s 794us/step - loss: 0.8657
16/16 [==============================] - 0s 822us/step - loss: 1.5564
16/16 [==============================] - 0s 1ms/step - loss: 1.9111
16/16 [==============================] - 0s 1ms/step - loss: 1.9520
16/16 [==============================] - 0s 862us/step - loss: 1.9577
16/16 [==============================] - 0s 866us/step - loss: 1.9567
16/16 [==============================] - 0s 876us/step - loss: 1.9552
16/16 [==============================] - 0s 871us/step - loss: 1.9543
16/16 [==============================] - 0s 806us/step - loss: 1.9538
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 652us/step
16/16 [==============================] - 0s 831us/step - loss: 0.1877
16/16 [==============================] - 0s 805us/step - loss: 0.8748
16/16 [==============================] - 0s 827us/step - loss: 1.5801
16/16 [==============================] - 0s 990us/step - loss: 1.9404
16/16 [==============================] - 0s 1ms/step - loss: 1.9818
16/16 [==============================] - 0s 825us/step - loss: 1.9875
16/16 [==============================] - 0s 1ms/step - loss: 1.9865
16/16 [==============================] - 0s 1ms/step - loss: 1.9850
16/16 [==============================] - 0s 1ms/step - loss: 1.9841
16/16 [==============================] - 0s 1ms/step - loss: 1.9836

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1924
16/16 [==============================] - 0s 1ms/step - loss: 0.8726
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
16/16 [==============================] - 0s 1ms/step - loss: 1.9322
16/16 [==============================] - 0s 833us/step - loss: 1.9733
16/16 [==============================] - 0s 820us/step - loss: 1.9790
16/16 [==============================] - 0s 768us/step - loss: 1.9780
16/16 [==============================] - 0s 836us/step - loss: 1.9766
16/16 [==============================] - 0s 1ms/step - loss: 1.9757
16/16 [==============================] - 0s 1ms/step - loss: 1.9752
32/32 [==============================] - 0s 595us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="368">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="369">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="370">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="371">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-103-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.943
Precision: 0.966
Recall: 0.975
F1 Score: 0.970</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="372">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="372">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.943</td>
      <td>0.965589</td>
      <td>0.974737</td>
      <td>0.970141</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lscpstar" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar">LSCP<span class="math inline">\(\star\)</span></h3>
<p>default=10%</p>
<div class="cell" data-execution_count="373">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="374">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="375">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="376">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="377">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-109-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.992
Precision: 0.996
Recall: 0.996
F1 Score: 0.996</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="378">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="378">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.992</td>
      <td>0.995789</td>
      <td>0.995789</td>
      <td>0.995789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="linear-result" class="level2">
<h2 class="anchored" data-anchor-id="linear-result">Linear Result</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen_linear,<span class="dv">3</span>)</span></code></pre></div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.926</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.961</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.999</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.984</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.992</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.885</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.936</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.943</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.970</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.996</td>
</tr>
</tbody>
</table>
</section>
<section id="orbit-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="orbit-ebayesthresh">Orbit EbayesThresh</h2>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="575">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb147-5"><a href="#cb147-5" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb147-6"><a href="#cb147-6" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier <span class="op">=</span> which(signal<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb147-7"><a href="#cb147-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier</span>
<span id="cb147-8"><a href="#cb147-8" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>signal<span class="op">+</span>epsilon</span>
<span id="cb147-9"><a href="#cb147-9" aria-hidden="true" tabindex="-1"></a>plot(<span class="dv">1</span>:<span class="dv">1000</span>,x)</span>
<span id="cb147-10"><a href="#cb147-10" aria-hidden="true" tabindex="-1"></a>points(index_of_trueoutlier,x[index_of_trueoutlier],col<span class="op">=</span><span class="dv">2</span>,cex<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb147-11"><a href="#cb147-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-12"><a href="#cb147-12" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(x,type='l')</span></span>
<span id="cb147-13"><a href="#cb147-13" aria-hidden="true" tabindex="-1"></a><span class="co">#mu &lt;- EbayesThresh::ebayesthresh(x,sdev=2)</span></span>
<span id="cb147-14"><a href="#cb147-14" aria-hidden="true" tabindex="-1"></a><span class="co">#lines(mu,col=2,lty=2,lwd=2)</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-113-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="576">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal</span></code></pre></div>
</div>
<div class="cell" data-execution_count="577">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="578">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>xhat <span class="op">=</span> np.array(ebayesthresh(FloatVector(x)))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="579">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(x)</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(xhat)</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="580">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index <span class="op">=</span> index_of_trueoutlier</span></code></pre></div>
</div>
<div class="cell" data-execution_count="655">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value <span class="op">=</span> x[index_of_trueoutlier]</span></code></pre></div>
</div>
<p>package와 비교를 위해 outlier는 -1, inlier는 1로 표시</p>
<div class="cell" data-execution_count="582">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> signal.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="583">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one))</span></code></pre></div>
</div>
</section>
<section id="orbit" class="level2">
<h2 class="anchored" data-anchor-id="orbit">Orbit</h2>
<div class="cell" data-execution_count="584">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">777</span>)</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>pi<span class="op">=</span>np.pi</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>ang<span class="op">=</span>np.linspace(<span class="op">-</span>pi,pi<span class="op">-</span><span class="dv">2</span><span class="op">*</span>pi<span class="op">/</span>n,n)</span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>r<span class="op">=</span><span class="dv">5</span><span class="op">+</span>np.cos(np.linspace(<span class="dv">0</span>,<span class="dv">12</span><span class="op">*</span>pi,n))</span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a>vx<span class="op">=</span>r<span class="op">*</span>np.cos(ang)</span>
<span id="cb156-7"><a href="#cb156-7" aria-hidden="true" tabindex="-1"></a>vy<span class="op">=</span>r<span class="op">*</span>np.sin(ang)</span>
<span id="cb156-8"><a href="#cb156-8" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span><span class="dv">10</span><span class="op">*</span>np.sin(np.linspace(<span class="dv">0</span>,<span class="dv">6</span><span class="op">*</span>pi,n))</span>
<span id="cb156-9"><a href="#cb156-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f1 <span class="op">+</span> x</span></code></pre></div>
</div>
<div class="cell" data-execution_count="585">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span> : vx, <span class="st">'y'</span> : vy, <span class="st">'f'</span> : f})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="586">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="590">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save_data(_df,'Orbit.pkl')</span></span></code></pre></div>
</div>
<section id="gode-1" class="level3">
<h3 class="anchored" data-anchor-id="gode-1">GODE</h3>
<div class="cell" data-execution_count="526">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>_Orbit <span class="op">=</span> Orbit(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="527">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_distance()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1000/1000 [00:02&lt;00:00, 384.08it/s]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="528">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_weightmatrix(theta<span class="op">=</span>(_Orbit.D[_Orbit.D<span class="op">&gt;</span><span class="dv">0</span>].mean()),kappa<span class="op">=</span><span class="dv">2500</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="529">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>_Orbit.fit(sd<span class="op">=</span><span class="dv">15</span>,ref<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="558">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Orbit.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="559">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">13</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="560">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="560">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="561">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="561">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="562">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="563">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-135-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="565">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="565">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofstar">LOF<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-139-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.976
Recall: 0.976
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="169">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.954</td>
      <td>0.975789</td>
      <td>0.975789</td>
      <td>0.975789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="knn-1" class="level3">
<h3 class="anchored" data-anchor-id="knn-1">KNN</h3>
<div class="cell" data-tags="[]" data-execution_count="134">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="cblof" class="level3">
<h3 class="anchored" data-anchor-id="cblof">CBLOF</h3>
<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>four <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="ocsvm-1" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-1">OCSVM</h3>
<div class="cell" data-execution_count="170">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="171">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-157-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.908
Precision: 0.977
Recall: 0.925
F1 Score: 0.950</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="176">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.908</td>
      <td>0.976667</td>
      <td>0.925263</td>
      <td>0.95027</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mcdstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar-1">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="177">
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb202-2"><a href="#cb202-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb202-3"><a href="#cb202-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-163-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.916</td>
      <td>0.955789</td>
      <td>0.955789</td>
      <td>0.955789</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="feature-baggingstar-1" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="184">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="185">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-169-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.969
Recall: 0.969
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="189">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.942</td>
      <td>0.969474</td>
      <td>0.969474</td>
      <td>0.969474</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="abodstar-1" class="level3">
<h3 class="anchored" data-anchor-id="abodstar-1">ABOD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="190">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-175-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="195">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="iforeststar-1" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar-1">IForest<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]],</span>
<span id="cb228-3"><a href="#cb228-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb228-4"><a href="#cb228-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="201">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="202">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="203">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-184-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.443
Precision: 0.992
Recall: 0.417
F1 Score: 0.587</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="204">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="204">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.443</td>
      <td>0.992481</td>
      <td>0.416842</td>
      <td>0.587102</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="hbosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar-1">HBOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="205">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb237-3"><a href="#cb237-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="206">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="207">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="208">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="209">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-190-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.960
Recall: 0.973
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="210">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="210">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.935</td>
      <td>0.959502</td>
      <td>0.972632</td>
      <td>0.966022</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="sosstar-1">SOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="211">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb245-2"><a href="#cb245-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb245-3"><a href="#cb245-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="212">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="213">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="214">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="215">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-196-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.974
Recall: 0.974
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="216">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="216">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.95</td>
      <td>0.973684</td>
      <td>0.973684</td>
      <td>0.973684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="so_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="217">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb253-2"><a href="#cb253-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb253-3"><a href="#cb253-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.2463

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.2638
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.2803

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.3116
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3359

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3306
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3703

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3762
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.3821

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4154
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.4274

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4426
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4476

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4723
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4929

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4871
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5141

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 932us/step - loss: 1.5047
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5151

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5108
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.5223

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5451
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5592

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5583
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.5766

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5713
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5877

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6025
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6303

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6321
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6358

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6567
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6791

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6957
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7147

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7083
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.7201

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7494
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7608

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7744
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7782

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8041
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.8156

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8259
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8290

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8340
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8584

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8740
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9041

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 898us/step - loss: 1.8801
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9261

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9211
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9269

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.9367
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9587

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 971us/step - loss: 1.9549
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9729

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9807
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 926us/step - loss: 2.0082

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0105
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 792us/step - loss: 2.0273

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 797us/step - loss: 2.0485
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 784us/step - loss: 2.0468

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 781us/step - loss: 2.0672
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 787us/step - loss: 2.0739

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 806us/step - loss: 2.0657
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 806us/step - loss: 2.0858

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 798us/step - loss: 2.0947
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1176

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 811us/step - loss: 2.1461
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 673us/step - loss: 2.1360

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 787us/step - loss: 2.1514
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1614

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 808us/step - loss: 2.1548
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 791us/step - loss: 2.1811

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 802us/step - loss: 2.1819
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 782us/step - loss: 2.2201

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 775us/step - loss: 2.2222
32/32 [==============================] - 0s 599us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="218">
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="219">
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="220">
<div class="sourceCode cell-code" id="cb258"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="221">
<div class="sourceCode cell-code" id="cb259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-202-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="222">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="222">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.95</td>
      <td>0.95</td>
      <td>1.0</td>
      <td>0.974359</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mo_gaalstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="223">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb263-2"><a href="#cb263-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb263-3"><a href="#cb263-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 612us/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 864us/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 646us/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 608us/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 609us/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 600us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 819us/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 615us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 617us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 650us/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 622us/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 851us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 602us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 861us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 605us/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 644us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 639us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 636us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 878us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 872us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 646us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 639us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 664us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 631us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 655us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 599us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 744us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 641us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 646us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 647us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 637us/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 641us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 873us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 586us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 573us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 829us/step - loss: 0.5766
16/16 [==============================] - 0s 1ms/step - loss: 1.0464
16/16 [==============================] - 0s 858us/step - loss: 1.0938
16/16 [==============================] - 0s 857us/step - loss: 1.1020
16/16 [==============================] - 0s 861us/step - loss: 1.1044
16/16 [==============================] - 0s 842us/step - loss: 1.1049
16/16 [==============================] - 0s 1ms/step - loss: 1.1050
16/16 [==============================] - 0s 862us/step - loss: 1.1050
16/16 [==============================] - 0s 851us/step - loss: 1.1050
16/16 [==============================] - 0s 871us/step - loss: 1.1050
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5693
16/16 [==============================] - 0s 1ms/step - loss: 1.0560
16/16 [==============================] - 0s 975us/step - loss: 1.1040
16/16 [==============================] - 0s 2ms/step - loss: 1.1121
16/16 [==============================] - 0s 2ms/step - loss: 1.1143
16/16 [==============================] - 0s 2ms/step - loss: 1.1148
16/16 [==============================] - 0s 1ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149
16/16 [==============================] - 0s 2ms/step - loss: 1.1149

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5640
16/16 [==============================] - 0s 1ms/step - loss: 1.0682
16/16 [==============================] - 0s 2ms/step - loss: 1.1167
16/16 [==============================] - 0s 2ms/step - loss: 1.1247
16/16 [==============================] - 0s 1ms/step - loss: 1.1269
16/16 [==============================] - 0s 874us/step - loss: 1.1274
16/16 [==============================] - 0s 865us/step - loss: 1.1274
16/16 [==============================] - 0s 1ms/step - loss: 1.1275
16/16 [==============================] - 0s 1ms/step - loss: 1.1275
16/16 [==============================] - 0s 2ms/step - loss: 1.1275
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 947us/step - loss: 0.5556
16/16 [==============================] - 0s 859us/step - loss: 1.0762
16/16 [==============================] - 0s 830us/step - loss: 1.1295
16/16 [==============================] - 0s 1ms/step - loss: 1.1374
16/16 [==============================] - 0s 863us/step - loss: 1.1397
16/16 [==============================] - 0s 1ms/step - loss: 1.1402
16/16 [==============================] - 0s 831us/step - loss: 1.1403
16/16 [==============================] - 0s 2ms/step - loss: 1.1403
16/16 [==============================] - 0s 2ms/step - loss: 1.1403
16/16 [==============================] - 0s 821us/step - loss: 1.1403

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5506
16/16 [==============================] - 0s 2ms/step - loss: 1.0873
16/16 [==============================] - 0s 2ms/step - loss: 1.1408
16/16 [==============================] - 0s 2ms/step - loss: 1.1487
16/16 [==============================] - 0s 1ms/step - loss: 1.1510
16/16 [==============================] - 0s 1ms/step - loss: 1.1515
16/16 [==============================] - 0s 1ms/step - loss: 1.1516
16/16 [==============================] - 0s 854us/step - loss: 1.1516
16/16 [==============================] - 0s 2ms/step - loss: 1.1516
16/16 [==============================] - 0s 889us/step - loss: 1.1516
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5415
16/16 [==============================] - 0s 2ms/step - loss: 1.1038
16/16 [==============================] - 0s 861us/step - loss: 1.1591
16/16 [==============================] - 0s 922us/step - loss: 1.1674
16/16 [==============================] - 0s 864us/step - loss: 1.1696
16/16 [==============================] - 0s 2ms/step - loss: 1.1701
16/16 [==============================] - 0s 2ms/step - loss: 1.1701
16/16 [==============================] - 0s 854us/step - loss: 1.1701
16/16 [==============================] - 0s 1ms/step - loss: 1.1701
16/16 [==============================] - 0s 1ms/step - loss: 1.1701

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5350
16/16 [==============================] - 0s 2ms/step - loss: 1.1180
16/16 [==============================] - 0s 2ms/step - loss: 1.1748
16/16 [==============================] - 0s 825us/step - loss: 1.1831
16/16 [==============================] - 0s 856us/step - loss: 1.1853
16/16 [==============================] - 0s 2ms/step - loss: 1.1858
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 833us/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 906us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5264
16/16 [==============================] - 0s 808us/step - loss: 1.1314
16/16 [==============================] - 0s 937us/step - loss: 1.1900
16/16 [==============================] - 0s 824us/step - loss: 1.1986
16/16 [==============================] - 0s 833us/step - loss: 1.2009
16/16 [==============================] - 0s 1ms/step - loss: 1.2014
16/16 [==============================] - 0s 811us/step - loss: 1.2014
16/16 [==============================] - 0s 2ms/step - loss: 1.2015
16/16 [==============================] - 0s 2ms/step - loss: 1.2015
16/16 [==============================] - 0s 2ms/step - loss: 1.2015

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 567us/step
16/16 [==============================] - 0s 841us/step - loss: 0.5216
16/16 [==============================] - 0s 1ms/step - loss: 1.1457
16/16 [==============================] - 0s 1ms/step - loss: 1.2047
16/16 [==============================] - 0s 679us/step - loss: 1.2133
16/16 [==============================] - 0s 666us/step - loss: 1.2156
16/16 [==============================] - 0s 833us/step - loss: 1.2161
16/16 [==============================] - 0s 802us/step - loss: 1.2162
16/16 [==============================] - 0s 786us/step - loss: 1.2162
16/16 [==============================] - 0s 797us/step - loss: 1.2162
16/16 [==============================] - 0s 788us/step - loss: 1.2162
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 865us/step - loss: 0.5150
16/16 [==============================] - 0s 870us/step - loss: 1.1494
16/16 [==============================] - 0s 774us/step - loss: 1.2095
16/16 [==============================] - 0s 775us/step - loss: 1.2182
16/16 [==============================] - 0s 824us/step - loss: 1.2205
16/16 [==============================] - 0s 788us/step - loss: 1.2210
16/16 [==============================] - 0s 773us/step - loss: 1.2211
16/16 [==============================] - 0s 774us/step - loss: 1.2211
16/16 [==============================] - 0s 776us/step - loss: 1.2211
16/16 [==============================] - 0s 861us/step - loss: 1.2211

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 785us/step - loss: 0.5109
16/16 [==============================] - 0s 812us/step - loss: 1.1619
16/16 [==============================] - 0s 1ms/step - loss: 1.2235
16/16 [==============================] - 0s 871us/step - loss: 1.2321
16/16 [==============================] - 0s 773us/step - loss: 1.2344
16/16 [==============================] - 0s 799us/step - loss: 1.2349
16/16 [==============================] - 0s 768us/step - loss: 1.2350
16/16 [==============================] - 0s 770us/step - loss: 1.2350
16/16 [==============================] - 0s 771us/step - loss: 1.2350
16/16 [==============================] - 0s 780us/step - loss: 1.2350
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 793us/step - loss: 0.5029
16/16 [==============================] - 0s 785us/step - loss: 1.1787
16/16 [==============================] - 0s 788us/step - loss: 1.2438
16/16 [==============================] - 0s 791us/step - loss: 1.2527
16/16 [==============================] - 0s 800us/step - loss: 1.2551
16/16 [==============================] - 0s 793us/step - loss: 1.2556
16/16 [==============================] - 0s 783us/step - loss: 1.2557
16/16 [==============================] - 0s 807us/step - loss: 1.2557
16/16 [==============================] - 0s 828us/step - loss: 1.2557
16/16 [==============================] - 0s 798us/step - loss: 1.2557

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 801us/step - loss: 0.5025
16/16 [==============================] - 0s 785us/step - loss: 1.1809
16/16 [==============================] - 0s 793us/step - loss: 1.2452
16/16 [==============================] - 0s 812us/step - loss: 1.2538
16/16 [==============================] - 0s 807us/step - loss: 1.2560
16/16 [==============================] - 0s 828us/step - loss: 1.2566
16/16 [==============================] - 0s 785us/step - loss: 1.2566
16/16 [==============================] - 0s 789us/step - loss: 1.2566
16/16 [==============================] - 0s 800us/step - loss: 1.2566
16/16 [==============================] - 0s 788us/step - loss: 1.2566
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 797us/step - loss: 0.4954
16/16 [==============================] - 0s 1ms/step - loss: 1.1997
16/16 [==============================] - 0s 1ms/step - loss: 1.2662
16/16 [==============================] - 0s 1ms/step - loss: 1.2750
16/16 [==============================] - 0s 1ms/step - loss: 1.2773
16/16 [==============================] - 0s 1ms/step - loss: 1.2778
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779
16/16 [==============================] - 0s 1ms/step - loss: 1.2779

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 826us/step
16/16 [==============================] - 0s 799us/step - loss: 0.4926
16/16 [==============================] - 0s 774us/step - loss: 1.2188
16/16 [==============================] - 0s 812us/step - loss: 1.2854
16/16 [==============================] - 0s 798us/step - loss: 1.2941
16/16 [==============================] - 0s 816us/step - loss: 1.2964
16/16 [==============================] - 0s 822us/step - loss: 1.2969
16/16 [==============================] - 0s 797us/step - loss: 1.2969
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
16/16 [==============================] - 0s 1ms/step - loss: 1.2970
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 830us/step - loss: 0.4909
16/16 [==============================] - 0s 788us/step - loss: 1.2161
16/16 [==============================] - 0s 817us/step - loss: 1.2819
16/16 [==============================] - 0s 844us/step - loss: 1.2906
16/16 [==============================] - 0s 808us/step - loss: 1.2927
16/16 [==============================] - 0s 791us/step - loss: 1.2932
16/16 [==============================] - 0s 988us/step - loss: 1.2932
16/16 [==============================] - 0s 787us/step - loss: 1.2933
16/16 [==============================] - 0s 797us/step - loss: 1.2933
16/16 [==============================] - 0s 1ms/step - loss: 1.2933

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 802us/step - loss: 0.4908
16/16 [==============================] - 0s 803us/step - loss: 1.2300
16/16 [==============================] - 0s 801us/step - loss: 1.2947
16/16 [==============================] - 0s 783us/step - loss: 1.3035
16/16 [==============================] - 0s 1ms/step - loss: 1.3056
16/16 [==============================] - 0s 822us/step - loss: 1.3061
16/16 [==============================] - 0s 803us/step - loss: 1.3061
16/16 [==============================] - 0s 780us/step - loss: 1.3062
16/16 [==============================] - 0s 806us/step - loss: 1.3062
16/16 [==============================] - 0s 788us/step - loss: 1.3062
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4860
16/16 [==============================] - 0s 1ms/step - loss: 1.2481
16/16 [==============================] - 0s 1ms/step - loss: 1.3139
16/16 [==============================] - 0s 1ms/step - loss: 1.3229
16/16 [==============================] - 0s 833us/step - loss: 1.3251
16/16 [==============================] - 0s 1ms/step - loss: 1.3256
16/16 [==============================] - 0s 1ms/step - loss: 1.3256
16/16 [==============================] - 0s 1ms/step - loss: 1.3257
16/16 [==============================] - 0s 790us/step - loss: 1.3257
16/16 [==============================] - 0s 1ms/step - loss: 1.3257

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 852us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4867
16/16 [==============================] - 0s 1ms/step - loss: 1.2636
16/16 [==============================] - 0s 780us/step - loss: 1.3284
16/16 [==============================] - 0s 1ms/step - loss: 1.3373
16/16 [==============================] - 0s 1ms/step - loss: 1.3394
16/16 [==============================] - 0s 1ms/step - loss: 1.3399
16/16 [==============================] - 0s 1ms/step - loss: 1.3399
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
16/16 [==============================] - 0s 1ms/step - loss: 1.3400
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 784us/step - loss: 0.4869
16/16 [==============================] - 0s 782us/step - loss: 1.2596
16/16 [==============================] - 0s 791us/step - loss: 1.3232
16/16 [==============================] - 0s 772us/step - loss: 1.3319
16/16 [==============================] - 0s 793us/step - loss: 1.3339
16/16 [==============================] - 0s 795us/step - loss: 1.3344
16/16 [==============================] - 0s 774us/step - loss: 1.3344
16/16 [==============================] - 0s 772us/step - loss: 1.3345
16/16 [==============================] - 0s 783us/step - loss: 1.3345
16/16 [==============================] - 0s 1ms/step - loss: 1.3345

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 788us/step - loss: 0.4871
16/16 [==============================] - 0s 788us/step - loss: 1.2850
16/16 [==============================] - 0s 785us/step - loss: 1.3492
16/16 [==============================] - 0s 776us/step - loss: 1.3579
16/16 [==============================] - 0s 1ms/step - loss: 1.3599
16/16 [==============================] - 0s 1ms/step - loss: 1.3604
16/16 [==============================] - 0s 1ms/step - loss: 1.3605
16/16 [==============================] - 0s 1ms/step - loss: 1.3605
16/16 [==============================] - 0s 780us/step - loss: 1.3605
16/16 [==============================] - 0s 776us/step - loss: 1.3605
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 847us/step
16/16 [==============================] - 0s 778us/step - loss: 0.4859
16/16 [==============================] - 0s 776us/step - loss: 1.2906
16/16 [==============================] - 0s 772us/step - loss: 1.3553
16/16 [==============================] - 0s 775us/step - loss: 1.3638
16/16 [==============================] - 0s 793us/step - loss: 1.3658
16/16 [==============================] - 0s 1ms/step - loss: 1.3663
16/16 [==============================] - 0s 820us/step - loss: 1.3664
16/16 [==============================] - 0s 811us/step - loss: 1.3664
16/16 [==============================] - 0s 782us/step - loss: 1.3664
16/16 [==============================] - 0s 1ms/step - loss: 1.3664

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 785us/step - loss: 0.4911
16/16 [==============================] - 0s 1ms/step - loss: 1.2887
16/16 [==============================] - 0s 1ms/step - loss: 1.3521
16/16 [==============================] - 0s 791us/step - loss: 1.3601
16/16 [==============================] - 0s 1ms/step - loss: 1.3620
16/16 [==============================] - 0s 815us/step - loss: 1.3625
16/16 [==============================] - 0s 804us/step - loss: 1.3625
16/16 [==============================] - 0s 777us/step - loss: 1.3625
16/16 [==============================] - 0s 767us/step - loss: 1.3625
16/16 [==============================] - 0s 780us/step - loss: 1.3625
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 781us/step - loss: 0.4892
16/16 [==============================] - 0s 770us/step - loss: 1.3080
16/16 [==============================] - 0s 781us/step - loss: 1.3727
16/16 [==============================] - 0s 773us/step - loss: 1.3807
16/16 [==============================] - 0s 773us/step - loss: 1.3826
16/16 [==============================] - 0s 1ms/step - loss: 1.3831
16/16 [==============================] - 0s 1ms/step - loss: 1.3832
16/16 [==============================] - 0s 1ms/step - loss: 1.3832
16/16 [==============================] - 0s 766us/step - loss: 1.3832
16/16 [==============================] - 0s 1ms/step - loss: 1.3832

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 855us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4938
16/16 [==============================] - 0s 798us/step - loss: 1.3114
16/16 [==============================] - 0s 785us/step - loss: 1.3752
16/16 [==============================] - 0s 790us/step - loss: 1.3827
16/16 [==============================] - 0s 783us/step - loss: 1.3846
16/16 [==============================] - 0s 810us/step - loss: 1.3851
16/16 [==============================] - 0s 788us/step - loss: 1.3852
16/16 [==============================] - 0s 834us/step - loss: 1.3852
16/16 [==============================] - 0s 768us/step - loss: 1.3852
16/16 [==============================] - 0s 775us/step - loss: 1.3852
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 780us/step - loss: 0.4942
16/16 [==============================] - 0s 778us/step - loss: 1.3220
16/16 [==============================] - 0s 789us/step - loss: 1.3861
16/16 [==============================] - 0s 785us/step - loss: 1.3935
16/16 [==============================] - 0s 775us/step - loss: 1.3954
16/16 [==============================] - 0s 814us/step - loss: 1.3958
16/16 [==============================] - 0s 777us/step - loss: 1.3959
16/16 [==============================] - 0s 767us/step - loss: 1.3959
16/16 [==============================] - 0s 785us/step - loss: 1.3959
16/16 [==============================] - 0s 772us/step - loss: 1.3959

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 805us/step - loss: 0.4983
16/16 [==============================] - 0s 786us/step - loss: 1.3372
16/16 [==============================] - 0s 774us/step - loss: 1.4013
16/16 [==============================] - 0s 802us/step - loss: 1.4084
16/16 [==============================] - 0s 775us/step - loss: 1.4103
16/16 [==============================] - 0s 804us/step - loss: 1.4108
16/16 [==============================] - 0s 781us/step - loss: 1.4108
16/16 [==============================] - 0s 781us/step - loss: 1.4108
16/16 [==============================] - 0s 782us/step - loss: 1.4108
16/16 [==============================] - 0s 789us/step - loss: 1.4108
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 786us/step - loss: 0.5005
16/16 [==============================] - 0s 778us/step - loss: 1.3357
16/16 [==============================] - 0s 777us/step - loss: 1.3989
16/16 [==============================] - 0s 773us/step - loss: 1.4057
16/16 [==============================] - 0s 771us/step - loss: 1.4076
16/16 [==============================] - 0s 798us/step - loss: 1.4080
16/16 [==============================] - 0s 870us/step - loss: 1.4081
16/16 [==============================] - 0s 799us/step - loss: 1.4081
16/16 [==============================] - 0s 788us/step - loss: 1.4081
16/16 [==============================] - 0s 798us/step - loss: 1.4081

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 786us/step - loss: 0.5063
16/16 [==============================] - 0s 780us/step - loss: 1.3477
16/16 [==============================] - 0s 785us/step - loss: 1.4105
16/16 [==============================] - 0s 808us/step - loss: 1.4171
16/16 [==============================] - 0s 775us/step - loss: 1.4189
16/16 [==============================] - 0s 813us/step - loss: 1.4193
16/16 [==============================] - 0s 784us/step - loss: 1.4194
16/16 [==============================] - 0s 791us/step - loss: 1.4194
16/16 [==============================] - 0s 823us/step - loss: 1.4195
16/16 [==============================] - 0s 827us/step - loss: 1.4195
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 646us/step
16/16 [==============================] - 0s 884us/step - loss: 0.5084
16/16 [==============================] - 0s 826us/step - loss: 1.3507
16/16 [==============================] - 0s 857us/step - loss: 1.4129
16/16 [==============================] - 0s 806us/step - loss: 1.4193
16/16 [==============================] - 0s 899us/step - loss: 1.4210
16/16 [==============================] - 0s 890us/step - loss: 1.4214
16/16 [==============================] - 0s 897us/step - loss: 1.4215
16/16 [==============================] - 0s 911us/step - loss: 1.4215
16/16 [==============================] - 0s 882us/step - loss: 1.4215
16/16 [==============================] - 0s 886us/step - loss: 1.4215

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 831us/step - loss: 0.5137
16/16 [==============================] - 0s 847us/step - loss: 1.3616
16/16 [==============================] - 0s 806us/step - loss: 1.4231
16/16 [==============================] - 0s 777us/step - loss: 1.4294
16/16 [==============================] - 0s 894us/step - loss: 1.4309
16/16 [==============================] - 0s 807us/step - loss: 1.4314
16/16 [==============================] - 0s 895us/step - loss: 1.4314
16/16 [==============================] - 0s 854us/step - loss: 1.4315
16/16 [==============================] - 0s 817us/step - loss: 1.4315
16/16 [==============================] - 0s 824us/step - loss: 1.4315
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 816us/step
16/16 [==============================] - 0s 825us/step - loss: 0.5156
16/16 [==============================] - 0s 1ms/step - loss: 1.3670
16/16 [==============================] - 0s 884us/step - loss: 1.4273
16/16 [==============================] - 0s 786us/step - loss: 1.4336
16/16 [==============================] - 0s 1ms/step - loss: 1.4351
16/16 [==============================] - 0s 812us/step - loss: 1.4355
16/16 [==============================] - 0s 874us/step - loss: 1.4356
16/16 [==============================] - 0s 797us/step - loss: 1.4356
16/16 [==============================] - 0s 799us/step - loss: 1.4356
16/16 [==============================] - 0s 815us/step - loss: 1.4356

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 719us/step
16/16 [==============================] - 0s 876us/step - loss: 0.5224
16/16 [==============================] - 0s 797us/step - loss: 1.3726
16/16 [==============================] - 0s 884us/step - loss: 1.4310
16/16 [==============================] - 0s 817us/step - loss: 1.4370
16/16 [==============================] - 0s 817us/step - loss: 1.4385
16/16 [==============================] - 0s 808us/step - loss: 1.4389
16/16 [==============================] - 0s 788us/step - loss: 1.4390
16/16 [==============================] - 0s 810us/step - loss: 1.4390
16/16 [==============================] - 0s 833us/step - loss: 1.4390
16/16 [==============================] - 0s 781us/step - loss: 1.4390
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 730us/step
16/16 [==============================] - 0s 876us/step - loss: 0.5231
16/16 [==============================] - 0s 865us/step - loss: 1.3945
16/16 [==============================] - 0s 863us/step - loss: 1.4537
16/16 [==============================] - 0s 866us/step - loss: 1.4598
16/16 [==============================] - 0s 892us/step - loss: 1.4613
16/16 [==============================] - 0s 878us/step - loss: 1.4617
16/16 [==============================] - 0s 859us/step - loss: 1.4618
16/16 [==============================] - 0s 856us/step - loss: 1.4618
16/16 [==============================] - 0s 858us/step - loss: 1.4618
16/16 [==============================] - 0s 860us/step - loss: 1.4618

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 797us/step - loss: 0.5304
16/16 [==============================] - 0s 808us/step - loss: 1.3896
16/16 [==============================] - 0s 785us/step - loss: 1.4472
16/16 [==============================] - 0s 788us/step - loss: 1.4530
16/16 [==============================] - 0s 826us/step - loss: 1.4543
16/16 [==============================] - 0s 812us/step - loss: 1.4547
16/16 [==============================] - 0s 786us/step - loss: 1.4547
16/16 [==============================] - 0s 784us/step - loss: 1.4547
16/16 [==============================] - 0s 794us/step - loss: 1.4547
16/16 [==============================] - 0s 790us/step - loss: 1.4547
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 838us/step - loss: 0.5317
16/16 [==============================] - 0s 795us/step - loss: 1.4114
16/16 [==============================] - 0s 826us/step - loss: 1.4698
16/16 [==============================] - 0s 797us/step - loss: 1.4756
16/16 [==============================] - 0s 798us/step - loss: 1.4770
16/16 [==============================] - 0s 814us/step - loss: 1.4774
16/16 [==============================] - 0s 828us/step - loss: 1.4775
16/16 [==============================] - 0s 841us/step - loss: 1.4775
16/16 [==============================] - 0s 833us/step - loss: 1.4775
16/16 [==============================] - 0s 788us/step - loss: 1.4775

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 693us/step
16/16 [==============================] - 0s 873us/step - loss: 0.5384
16/16 [==============================] - 0s 859us/step - loss: 1.4133
16/16 [==============================] - 0s 865us/step - loss: 1.4700
16/16 [==============================] - 0s 869us/step - loss: 1.4756
16/16 [==============================] - 0s 865us/step - loss: 1.4769
16/16 [==============================] - 0s 883us/step - loss: 1.4773
16/16 [==============================] - 0s 798us/step - loss: 1.4774
16/16 [==============================] - 0s 823us/step - loss: 1.4774
16/16 [==============================] - 0s 799us/step - loss: 1.4774
16/16 [==============================] - 0s 791us/step - loss: 1.4774
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 841us/step - loss: 0.5404
16/16 [==============================] - 0s 812us/step - loss: 1.4280
16/16 [==============================] - 0s 839us/step - loss: 1.4849
16/16 [==============================] - 0s 846us/step - loss: 1.4905
16/16 [==============================] - 0s 804us/step - loss: 1.4919
16/16 [==============================] - 0s 793us/step - loss: 1.4923
16/16 [==============================] - 0s 794us/step - loss: 1.4924
16/16 [==============================] - 0s 788us/step - loss: 1.4924
16/16 [==============================] - 0s 798us/step - loss: 1.4924
16/16 [==============================] - 0s 799us/step - loss: 1.4924

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 674us/step
16/16 [==============================] - 0s 806us/step - loss: 0.5472
16/16 [==============================] - 0s 791us/step - loss: 1.4360
16/16 [==============================] - 0s 792us/step - loss: 1.4914
16/16 [==============================] - 0s 788us/step - loss: 1.4970
16/16 [==============================] - 0s 787us/step - loss: 1.4983
16/16 [==============================] - 0s 782us/step - loss: 1.4987
16/16 [==============================] - 0s 783us/step - loss: 1.4988
16/16 [==============================] - 0s 806us/step - loss: 1.4988
16/16 [==============================] - 0s 789us/step - loss: 1.4988
16/16 [==============================] - 0s 806us/step - loss: 1.4988
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 806us/step - loss: 0.5490
16/16 [==============================] - 0s 800us/step - loss: 1.4384
16/16 [==============================] - 0s 808us/step - loss: 1.4933
16/16 [==============================] - 0s 802us/step - loss: 1.4988
16/16 [==============================] - 0s 804us/step - loss: 1.5001
16/16 [==============================] - 0s 840us/step - loss: 1.5005
16/16 [==============================] - 0s 792us/step - loss: 1.5006
16/16 [==============================] - 0s 798us/step - loss: 1.5006
16/16 [==============================] - 0s 824us/step - loss: 1.5006
16/16 [==============================] - 0s 801us/step - loss: 1.5006

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 803us/step - loss: 0.5552
16/16 [==============================] - 0s 798us/step - loss: 1.4452
16/16 [==============================] - 0s 812us/step - loss: 1.4995
16/16 [==============================] - 0s 803us/step - loss: 1.5049
16/16 [==============================] - 0s 834us/step - loss: 1.5061
16/16 [==============================] - 0s 797us/step - loss: 1.5065
16/16 [==============================] - 0s 804us/step - loss: 1.5066
16/16 [==============================] - 0s 797us/step - loss: 1.5066
16/16 [==============================] - 0s 801us/step - loss: 1.5066
16/16 [==============================] - 0s 782us/step - loss: 1.5066
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 811us/step - loss: 0.5568
16/16 [==============================] - 0s 791us/step - loss: 1.4605
16/16 [==============================] - 0s 874us/step - loss: 1.5154
16/16 [==============================] - 0s 796us/step - loss: 1.5208
16/16 [==============================] - 0s 789us/step - loss: 1.5220
16/16 [==============================] - 0s 787us/step - loss: 1.5224
16/16 [==============================] - 0s 783us/step - loss: 1.5225
16/16 [==============================] - 0s 793us/step - loss: 1.5225
16/16 [==============================] - 0s 808us/step - loss: 1.5225
16/16 [==============================] - 0s 821us/step - loss: 1.5225

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 793us/step - loss: 0.5636
16/16 [==============================] - 0s 788us/step - loss: 1.4727
16/16 [==============================] - 0s 785us/step - loss: 1.5280
16/16 [==============================] - 0s 866us/step - loss: 1.5334
16/16 [==============================] - 0s 859us/step - loss: 1.5346
16/16 [==============================] - 0s 882us/step - loss: 1.5350
16/16 [==============================] - 0s 856us/step - loss: 1.5350
16/16 [==============================] - 0s 886us/step - loss: 1.5351
16/16 [==============================] - 0s 857us/step - loss: 1.5351
16/16 [==============================] - 0s 860us/step - loss: 1.5351
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 692us/step
16/16 [==============================] - 0s 851us/step - loss: 0.5649
16/16 [==============================] - 0s 812us/step - loss: 1.4776
16/16 [==============================] - 0s 678us/step - loss: 1.5327
16/16 [==============================] - 0s 1ms/step - loss: 1.5382
16/16 [==============================] - 0s 791us/step - loss: 1.5393
16/16 [==============================] - 0s 780us/step - loss: 1.5397
16/16 [==============================] - 0s 763us/step - loss: 1.5398
16/16 [==============================] - 0s 675us/step - loss: 1.5398
16/16 [==============================] - 0s 741us/step - loss: 1.5398
16/16 [==============================] - 0s 1ms/step - loss: 1.5398

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 676us/step
16/16 [==============================] - 0s 880us/step - loss: 0.5713
16/16 [==============================] - 0s 788us/step - loss: 1.4905
16/16 [==============================] - 0s 804us/step - loss: 1.5460
16/16 [==============================] - 0s 785us/step - loss: 1.5514
16/16 [==============================] - 0s 803us/step - loss: 1.5526
16/16 [==============================] - 0s 788us/step - loss: 1.5530
16/16 [==============================] - 0s 780us/step - loss: 1.5530
16/16 [==============================] - 0s 804us/step - loss: 1.5531
16/16 [==============================] - 0s 781us/step - loss: 1.5531
16/16 [==============================] - 0s 780us/step - loss: 1.5531
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 770us/step
16/16 [==============================] - 0s 849us/step - loss: 0.5726
16/16 [==============================] - 0s 794us/step - loss: 1.4976
16/16 [==============================] - 0s 797us/step - loss: 1.5531
16/16 [==============================] - 0s 801us/step - loss: 1.5585
16/16 [==============================] - 0s 798us/step - loss: 1.5597
16/16 [==============================] - 0s 787us/step - loss: 1.5601
16/16 [==============================] - 0s 806us/step - loss: 1.5602
16/16 [==============================] - 0s 798us/step - loss: 1.5602
16/16 [==============================] - 0s 822us/step - loss: 1.5602
16/16 [==============================] - 0s 797us/step - loss: 1.5602

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 800us/step - loss: 0.5787
16/16 [==============================] - 0s 782us/step - loss: 1.5036
16/16 [==============================] - 0s 794us/step - loss: 1.5586
16/16 [==============================] - 0s 783us/step - loss: 1.5639
16/16 [==============================] - 0s 790us/step - loss: 1.5650
16/16 [==============================] - 0s 780us/step - loss: 1.5654
16/16 [==============================] - 0s 802us/step - loss: 1.5655
16/16 [==============================] - 0s 876us/step - loss: 1.5655
16/16 [==============================] - 0s 866us/step - loss: 1.5655
16/16 [==============================] - 0s 798us/step - loss: 1.5655
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 700us/step
16/16 [==============================] - 0s 873us/step - loss: 0.5799
16/16 [==============================] - 0s 868us/step - loss: 1.5106
16/16 [==============================] - 0s 798us/step - loss: 1.5655
16/16 [==============================] - 0s 810us/step - loss: 1.5708
16/16 [==============================] - 0s 792us/step - loss: 1.5719
16/16 [==============================] - 0s 783us/step - loss: 1.5723
16/16 [==============================] - 0s 791us/step - loss: 1.5724
16/16 [==============================] - 0s 784us/step - loss: 1.5724
16/16 [==============================] - 0s 789us/step - loss: 1.5724
16/16 [==============================] - 0s 790us/step - loss: 1.5724

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 799us/step - loss: 0.5865
16/16 [==============================] - 0s 793us/step - loss: 1.5229
16/16 [==============================] - 0s 798us/step - loss: 1.5778
16/16 [==============================] - 0s 800us/step - loss: 1.5830
16/16 [==============================] - 0s 793us/step - loss: 1.5841
16/16 [==============================] - 0s 778us/step - loss: 1.5846
16/16 [==============================] - 0s 775us/step - loss: 1.5847
16/16 [==============================] - 0s 784us/step - loss: 1.5847
16/16 [==============================] - 0s 768us/step - loss: 1.5847
16/16 [==============================] - 0s 783us/step - loss: 1.5847
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 597us/step
16/16 [==============================] - 0s 862us/step - loss: 0.5874
16/16 [==============================] - 0s 777us/step - loss: 1.5260
16/16 [==============================] - 0s 805us/step - loss: 1.5806
16/16 [==============================] - 0s 791us/step - loss: 1.5858
16/16 [==============================] - 0s 796us/step - loss: 1.5869
16/16 [==============================] - 0s 771us/step - loss: 1.5874
16/16 [==============================] - 0s 774us/step - loss: 1.5874
16/16 [==============================] - 0s 783us/step - loss: 1.5875
16/16 [==============================] - 0s 800us/step - loss: 1.5875
16/16 [==============================] - 0s 800us/step - loss: 1.5875

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 802us/step - loss: 0.5942
16/16 [==============================] - 0s 812us/step - loss: 1.5376
16/16 [==============================] - 0s 788us/step - loss: 1.5921
16/16 [==============================] - 0s 788us/step - loss: 1.5972
16/16 [==============================] - 0s 792us/step - loss: 1.5983
16/16 [==============================] - 0s 783us/step - loss: 1.5987
16/16 [==============================] - 0s 780us/step - loss: 1.5988
16/16 [==============================] - 0s 808us/step - loss: 1.5988
16/16 [==============================] - 0s 781us/step - loss: 1.5988
16/16 [==============================] - 0s 778us/step - loss: 1.5988
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 820us/step - loss: 0.5951
16/16 [==============================] - 0s 863us/step - loss: 1.5463
16/16 [==============================] - 0s 794us/step - loss: 1.6008
16/16 [==============================] - 0s 802us/step - loss: 1.6059
16/16 [==============================] - 0s 877us/step - loss: 1.6070
16/16 [==============================] - 0s 873us/step - loss: 1.6075
16/16 [==============================] - 0s 869us/step - loss: 1.6076
16/16 [==============================] - 0s 881us/step - loss: 1.6076
16/16 [==============================] - 0s 874us/step - loss: 1.6076
16/16 [==============================] - 0s 803us/step - loss: 1.6076

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 873us/step - loss: 0.6017
16/16 [==============================] - 0s 876us/step - loss: 1.5594
16/16 [==============================] - 0s 859us/step - loss: 1.6138
16/16 [==============================] - 0s 791us/step - loss: 1.6189
16/16 [==============================] - 0s 799us/step - loss: 1.6199
16/16 [==============================] - 0s 783us/step - loss: 1.6204
16/16 [==============================] - 0s 803us/step - loss: 1.6204
16/16 [==============================] - 0s 794us/step - loss: 1.6204
16/16 [==============================] - 0s 790us/step - loss: 1.6204
16/16 [==============================] - 0s 769us/step - loss: 1.6204
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 655us/step
16/16 [==============================] - 0s 899us/step - loss: 0.6031
16/16 [==============================] - 0s 10ms/step - loss: 1.5670
16/16 [==============================] - 0s 5ms/step - loss: 1.6213
16/16 [==============================] - 0s 2ms/step - loss: 1.6263
16/16 [==============================] - 0s 3ms/step - loss: 1.6274
16/16 [==============================] - 0s 2ms/step - loss: 1.6279
16/16 [==============================] - 0s 2ms/step - loss: 1.6280
16/16 [==============================] - 0s 5ms/step - loss: 1.6280
16/16 [==============================] - 0s 2ms/step - loss: 1.6280
16/16 [==============================] - 0s 1ms/step - loss: 1.6280

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.6099
16/16 [==============================] - 0s 6ms/step - loss: 1.5795
16/16 [==============================] - 0s 3ms/step - loss: 1.6337
16/16 [==============================] - 0s 3ms/step - loss: 1.6386
16/16 [==============================] - 0s 1ms/step - loss: 1.6397
16/16 [==============================] - 0s 2ms/step - loss: 1.6401
16/16 [==============================] - 0s 5ms/step - loss: 1.6402
16/16 [==============================] - 0s 6ms/step - loss: 1.6402
16/16 [==============================] - 0s 5ms/step - loss: 1.6402
16/16 [==============================] - 0s 3ms/step - loss: 1.6402
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6110
16/16 [==============================] - 0s 2ms/step - loss: 1.5866
16/16 [==============================] - 0s 3ms/step - loss: 1.6408
16/16 [==============================] - 0s 2ms/step - loss: 1.6457
16/16 [==============================] - 0s 2ms/step - loss: 1.6468
16/16 [==============================] - 0s 4ms/step - loss: 1.6472
16/16 [==============================] - 0s 4ms/step - loss: 1.6472
16/16 [==============================] - 0s 5ms/step - loss: 1.6473
16/16 [==============================] - 0s 2ms/step - loss: 1.6473
16/16 [==============================] - 0s 5ms/step - loss: 1.6473

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6166
16/16 [==============================] - 0s 2ms/step - loss: 1.5886
16/16 [==============================] - 0s 2ms/step - loss: 1.6420
16/16 [==============================] - 0s 3ms/step - loss: 1.6468
16/16 [==============================] - 0s 2ms/step - loss: 1.6479
16/16 [==============================] - 0s 2ms/step - loss: 1.6484
16/16 [==============================] - 0s 1ms/step - loss: 1.6485
16/16 [==============================] - 0s 2ms/step - loss: 1.6485
16/16 [==============================] - 0s 5ms/step - loss: 1.6485
16/16 [==============================] - 0s 2ms/step - loss: 1.6485
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.6181
16/16 [==============================] - 0s 2ms/step - loss: 1.5963
16/16 [==============================] - 0s 4ms/step - loss: 1.6496
16/16 [==============================] - 0s 3ms/step - loss: 1.6544
16/16 [==============================] - 0s 2ms/step - loss: 1.6555
16/16 [==============================] - 0s 1ms/step - loss: 1.6559
16/16 [==============================] - 0s 2ms/step - loss: 1.6560
16/16 [==============================] - 0s 2ms/step - loss: 1.6560
16/16 [==============================] - 0s 1ms/step - loss: 1.6560
16/16 [==============================] - 0s 1ms/step - loss: 1.6560

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6242
16/16 [==============================] - 0s 2ms/step - loss: 1.5993
16/16 [==============================] - 0s 4ms/step - loss: 1.6519
16/16 [==============================] - 0s 2ms/step - loss: 1.6566
16/16 [==============================] - 0s 1ms/step - loss: 1.6577
16/16 [==============================] - 0s 2ms/step - loss: 1.6581
16/16 [==============================] - 0s 4ms/step - loss: 1.6582
16/16 [==============================] - 0s 2ms/step - loss: 1.6582
16/16 [==============================] - 0s 1ms/step - loss: 1.6582
16/16 [==============================] - 0s 4ms/step - loss: 1.6582
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6275
16/16 [==============================] - 0s 2ms/step - loss: 1.6267
16/16 [==============================] - 0s 3ms/step - loss: 1.6803
16/16 [==============================] - 0s 4ms/step - loss: 1.6852
16/16 [==============================] - 0s 2ms/step - loss: 1.6863
16/16 [==============================] - 0s 2ms/step - loss: 1.6867
16/16 [==============================] - 0s 2ms/step - loss: 1.6868
16/16 [==============================] - 0s 4ms/step - loss: 1.6868
16/16 [==============================] - 0s 2ms/step - loss: 1.6868
16/16 [==============================] - 0s 3ms/step - loss: 1.6868

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 4ms/step
16/16 [==============================] - 0s 6ms/step - loss: 0.6335
16/16 [==============================] - 0s 3ms/step - loss: 1.6307
16/16 [==============================] - 0s 2ms/step - loss: 1.6837
16/16 [==============================] - 0s 2ms/step - loss: 1.6884
16/16 [==============================] - 0s 3ms/step - loss: 1.6894
16/16 [==============================] - 0s 2ms/step - loss: 1.6898
16/16 [==============================] - 0s 2ms/step - loss: 1.6899
16/16 [==============================] - 0s 4ms/step - loss: 1.6899
16/16 [==============================] - 0s 3ms/step - loss: 1.6899
16/16 [==============================] - 0s 5ms/step - loss: 1.6899
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6328
16/16 [==============================] - 0s 2ms/step - loss: 1.6231
16/16 [==============================] - 0s 4ms/step - loss: 1.6753
16/16 [==============================] - 0s 1ms/step - loss: 1.6798
16/16 [==============================] - 0s 2ms/step - loss: 1.6808
16/16 [==============================] - 0s 4ms/step - loss: 1.6812
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813
16/16 [==============================] - 0s 2ms/step - loss: 1.6813

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 6ms/step - loss: 0.6413
16/16 [==============================] - 0s 2ms/step - loss: 1.6429
16/16 [==============================] - 0s 1ms/step - loss: 1.6952
16/16 [==============================] - 0s 2ms/step - loss: 1.6998
16/16 [==============================] - 0s 2ms/step - loss: 1.7008
16/16 [==============================] - 0s 4ms/step - loss: 1.7012
16/16 [==============================] - 0s 3ms/step - loss: 1.7013
16/16 [==============================] - 0s 3ms/step - loss: 1.7013
16/16 [==============================] - 0s 5ms/step - loss: 1.7013
16/16 [==============================] - 0s 7ms/step - loss: 1.7013
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 902us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6435
16/16 [==============================] - 0s 1ms/step - loss: 1.6565
16/16 [==============================] - 0s 1ms/step - loss: 1.7091
16/16 [==============================] - 0s 1ms/step - loss: 1.7136
16/16 [==============================] - 0s 1ms/step - loss: 1.7147
16/16 [==============================] - 0s 2ms/step - loss: 1.7151
16/16 [==============================] - 0s 944us/step - loss: 1.7152
16/16 [==============================] - 0s 1ms/step - loss: 1.7153
16/16 [==============================] - 0s 1ms/step - loss: 1.7153
16/16 [==============================] - 0s 1ms/step - loss: 1.7153

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 760us/step
16/16 [==============================] - 0s 965us/step - loss: 0.6498
16/16 [==============================] - 0s 1ms/step - loss: 1.6572
16/16 [==============================] - 0s 973us/step - loss: 1.7090
16/16 [==============================] - 0s 816us/step - loss: 1.7135
16/16 [==============================] - 0s 964us/step - loss: 1.7145
16/16 [==============================] - 0s 964us/step - loss: 1.7150
16/16 [==============================] - 0s 1ms/step - loss: 1.7151
16/16 [==============================] - 0s 863us/step - loss: 1.7151
16/16 [==============================] - 0s 840us/step - loss: 1.7151
16/16 [==============================] - 0s 819us/step - loss: 1.7151
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6535
16/16 [==============================] - 0s 1ms/step - loss: 1.6806
16/16 [==============================] - 0s 3ms/step - loss: 1.7330
16/16 [==============================] - 0s 1ms/step - loss: 1.7376
16/16 [==============================] - 0s 1ms/step - loss: 1.7386
16/16 [==============================] - 0s 1ms/step - loss: 1.7390
16/16 [==============================] - 0s 3ms/step - loss: 1.7391
16/16 [==============================] - 0s 2ms/step - loss: 1.7391
16/16 [==============================] - 0s 4ms/step - loss: 1.7391
16/16 [==============================] - 0s 1ms/step - loss: 1.7391

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6593
16/16 [==============================] - 0s 2ms/step - loss: 1.6769
16/16 [==============================] - 0s 6ms/step - loss: 1.7284
16/16 [==============================] - 0s 4ms/step - loss: 1.7328
16/16 [==============================] - 0s 4ms/step - loss: 1.7338
16/16 [==============================] - 0s 4ms/step - loss: 1.7342
16/16 [==============================] - 0s 2ms/step - loss: 1.7343
16/16 [==============================] - 0s 4ms/step - loss: 1.7343
16/16 [==============================] - 0s 2ms/step - loss: 1.7344
16/16 [==============================] - 0s 3ms/step - loss: 1.7344
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6622
16/16 [==============================] - 0s 3ms/step - loss: 1.6888
16/16 [==============================] - 0s 2ms/step - loss: 1.7403
16/16 [==============================] - 0s 2ms/step - loss: 1.7447
16/16 [==============================] - 0s 2ms/step - loss: 1.7457
16/16 [==============================] - 0s 1ms/step - loss: 1.7462
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463
16/16 [==============================] - 0s 2ms/step - loss: 1.7463

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6714
16/16 [==============================] - 0s 3ms/step - loss: 1.7059
16/16 [==============================] - 0s 3ms/step - loss: 1.7574
16/16 [==============================] - 0s 5ms/step - loss: 1.7618
16/16 [==============================] - 0s 3ms/step - loss: 1.7628
16/16 [==============================] - 0s 2ms/step - loss: 1.7632
16/16 [==============================] - 0s 2ms/step - loss: 1.7633
16/16 [==============================] - 0s 2ms/step - loss: 1.7633
16/16 [==============================] - 0s 3ms/step - loss: 1.7634
16/16 [==============================] - 0s 2ms/step - loss: 1.7634
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6699
16/16 [==============================] - 0s 2ms/step - loss: 1.6914
16/16 [==============================] - 0s 3ms/step - loss: 1.7418
16/16 [==============================] - 0s 2ms/step - loss: 1.7460
16/16 [==============================] - 0s 3ms/step - loss: 1.7469
16/16 [==============================] - 0s 2ms/step - loss: 1.7473
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 1ms/step - loss: 1.7474

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6793
16/16 [==============================] - 0s 2ms/step - loss: 1.7090
16/16 [==============================] - 0s 3ms/step - loss: 1.7595
16/16 [==============================] - 0s 3ms/step - loss: 1.7637
16/16 [==============================] - 0s 2ms/step - loss: 1.7646
16/16 [==============================] - 0s 2ms/step - loss: 1.7651
16/16 [==============================] - 0s 3ms/step - loss: 1.7652
16/16 [==============================] - 0s 2ms/step - loss: 1.7652
16/16 [==============================] - 0s 2ms/step - loss: 1.7652
16/16 [==============================] - 0s 3ms/step - loss: 1.7652
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6800
16/16 [==============================] - 0s 2ms/step - loss: 1.7117
16/16 [==============================] - 0s 2ms/step - loss: 1.7619
16/16 [==============================] - 0s 2ms/step - loss: 1.7660
16/16 [==============================] - 0s 6ms/step - loss: 1.7669
16/16 [==============================] - 0s 3ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7674
16/16 [==============================] - 0s 2ms/step - loss: 1.7674

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6897
16/16 [==============================] - 0s 3ms/step - loss: 1.7319
16/16 [==============================] - 0s 2ms/step - loss: 1.7822
16/16 [==============================] - 0s 2ms/step - loss: 1.7863
16/16 [==============================] - 0s 3ms/step - loss: 1.7872
16/16 [==============================] - 0s 2ms/step - loss: 1.7877
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
16/16 [==============================] - 0s 3ms/step - loss: 1.7878
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.6918
16/16 [==============================] - 0s 2ms/step - loss: 1.7417
16/16 [==============================] - 0s 2ms/step - loss: 1.7920
16/16 [==============================] - 0s 2ms/step - loss: 1.7960
16/16 [==============================] - 0s 2ms/step - loss: 1.7970
16/16 [==============================] - 0s 2ms/step - loss: 1.7974
16/16 [==============================] - 0s 2ms/step - loss: 1.7975
16/16 [==============================] - 0s 2ms/step - loss: 1.7975
16/16 [==============================] - 0s 3ms/step - loss: 1.7975
16/16 [==============================] - 0s 3ms/step - loss: 1.7975

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6990
16/16 [==============================] - 0s 2ms/step - loss: 1.7482
16/16 [==============================] - 0s 2ms/step - loss: 1.7981
16/16 [==============================] - 0s 3ms/step - loss: 1.8021
16/16 [==============================] - 0s 5ms/step - loss: 1.8030
16/16 [==============================] - 0s 3ms/step - loss: 1.8035
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
16/16 [==============================] - 0s 2ms/step - loss: 1.8036
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.7001
16/16 [==============================] - 0s 2ms/step - loss: 1.7518
16/16 [==============================] - 0s 2ms/step - loss: 1.8013
16/16 [==============================] - 0s 3ms/step - loss: 1.8052
16/16 [==============================] - 0s 2ms/step - loss: 1.8062
16/16 [==============================] - 0s 2ms/step - loss: 1.8066
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 3ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8067

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.7091
16/16 [==============================] - 0s 2ms/step - loss: 1.7639
16/16 [==============================] - 0s 2ms/step - loss: 1.8133
16/16 [==============================] - 0s 4ms/step - loss: 1.8171
16/16 [==============================] - 0s 2ms/step - loss: 1.8180
16/16 [==============================] - 0s 2ms/step - loss: 1.8184
16/16 [==============================] - 0s 2ms/step - loss: 1.8185
16/16 [==============================] - 0s 2ms/step - loss: 1.8185
16/16 [==============================] - 0s 3ms/step - loss: 1.8185
16/16 [==============================] - 0s 4ms/step - loss: 1.8185
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.7096
16/16 [==============================] - 0s 2ms/step - loss: 1.7645
16/16 [==============================] - 0s 2ms/step - loss: 1.8135
16/16 [==============================] - 0s 2ms/step - loss: 1.8172
16/16 [==============================] - 0s 2ms/step - loss: 1.8182
16/16 [==============================] - 0s 5ms/step - loss: 1.8186
16/16 [==============================] - 0s 2ms/step - loss: 1.8187
16/16 [==============================] - 0s 2ms/step - loss: 1.8187
16/16 [==============================] - 0s 3ms/step - loss: 1.8187
16/16 [==============================] - 0s 3ms/step - loss: 1.8187

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.7180
16/16 [==============================] - 0s 5ms/step - loss: 1.7741
16/16 [==============================] - 0s 3ms/step - loss: 1.8228
16/16 [==============================] - 0s 2ms/step - loss: 1.8265
16/16 [==============================] - 0s 2ms/step - loss: 1.8275
16/16 [==============================] - 0s 3ms/step - loss: 1.8280
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
16/16 [==============================] - 0s 2ms/step - loss: 1.8281
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="224">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="225">
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="226">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb269"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-208-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="228">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.95</td>
      <td>0.95</td>
      <td>1.0</td>
      <td>0.974359</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lscpstar-1" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar-1">LSCP<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb273"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb273-2"><a href="#cb273-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb273-3"><a href="#cb273-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb273-4"><a href="#cb273-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="231">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb277"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-214-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="234">
<div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="234">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="orbit-result" class="level2">
<h2 class="anchored" data-anchor-id="orbit-result">Orbit Result</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen_orbit,<span class="dv">4</span>)</span></code></pre></div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
</section>
<section id="bunny" class="level2">
<h2 class="anchored" data-anchor-id="bunny">Bunny</h2>
<hr>
<section id="bunny-저장용" class="level3">
<h3 class="anchored" data-anchor-id="bunny-저장용">bunny 저장용</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_data(data_dict,fname):</span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname,<span class="st">'wb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb284-3"><a href="#cb284-3" aria-hidden="true" tabindex="-1"></a>        pickle.dump(data_dict,outfile)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb285"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> graphs.Bunny()</span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> G.N</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> filters.Heat(G, tau<span class="op">=</span><span class="dv">75</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">2503</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb289"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb289-1"><a href="#cb289-1" aria-hidden="true" tabindex="-1"></a>normal <span class="op">=</span> np.random.randn(n)</span>
<span id="cb289-2"><a href="#cb289-2" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> np.concatenate([np.random.uniform(low<span class="op">=</span><span class="dv">3</span>,high<span class="op">=</span><span class="dv">7</span>,size<span class="op">=</span><span class="dv">60</span>), np.random.uniform(low<span class="op">=-</span><span class="dv">7</span>,high<span class="op">=-</span><span class="dv">3</span>,size<span class="op">=</span><span class="dv">60</span>),np.zeros(n<span class="op">-</span><span class="dv">120</span>)])<span class="op">;</span> np.random.shuffle(unif)</span>
<span id="cb289-3"><a href="#cb289-3" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> normal <span class="op">+</span> unif</span>
<span id="cb289-4"><a href="#cb289-4" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier2 <span class="op">=</span> np.where(unif<span class="op">!=</span><span class="dv">0</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.zeros(n)</span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">1000</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3234</span></span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> g.<span class="bu">filter</span>(f, method<span class="op">=</span><span class="st">'chebyshev'</span>) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-07-04 17:37:32,017:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb292"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>G.coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(2503, 3)</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> G.W.toarray()</span>
<span id="cb294-2"><a href="#cb294-2" aria-hidden="true" tabindex="-1"></a>_x <span class="op">=</span> G.coords[:,<span class="dv">0</span>]</span>
<span id="cb294-3"><a href="#cb294-3" aria-hidden="true" tabindex="-1"></a>_y <span class="op">=</span> G.coords[:,<span class="dv">1</span>]</span>
<span id="cb294-4"><a href="#cb294-4" aria-hidden="true" tabindex="-1"></a>_z <span class="op">=</span> <span class="op">-</span>G.coords[:,<span class="dv">2</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb296"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb298"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> {<span class="st">'W'</span>:_W,<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z, <span class="st">'fnoise'</span>:f<span class="op">+</span>noise,<span class="st">'f'</span> : f, <span class="st">'noise'</span>: noise,<span class="st">'unif'</span>:unif,<span class="st">'index_of_trueoutlier2'</span>:index_of_trueoutlier2}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a>save_data(_df,<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a>_df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'W': array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]),
 'x': array([ 0.26815193, -0.58456893, -0.02730755, ...,  0.15397547,
        -0.45056488, -0.29405249]),
 'y': array([ 0.39314334,  0.63468595,  0.33280949, ...,  0.80205526,
         0.6207154 , -0.40187451]),
 'z': array([-0.13834514, -0.22438843,  0.08658215, ...,  0.33698514,
         0.58353051, -0.08647485]),
 'fnoise': array([-1.63569131,  0.49423926, -1.04026277, ..., -1.0694093 ,
        -0.24395499,  0.41729667]),
 'f': array([-1.54422488, -0.03596483, -0.93972715, ..., -0.01924028,
        -0.02470869, -0.26266752]),
 'noise': array([-0.09146643,  0.53020409, -0.10053563, ..., -1.05016902,
        -0.2192463 ,  0.67996419]),
 'unif': array([0., 0., 0., ..., 0., 0., 0.]),
 'index_of_trueoutlier2': (array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
          240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
          397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
          569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
          858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
         1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
         1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
         1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
         1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
         2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
         2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)}</code></pre>
</div>
</div>
<hr>
<div class="cell" data-execution_count="883">
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname):</span>
<span id="cb302-2"><a href="#cb302-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname, <span class="st">'rb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb302-3"><a href="#cb302-3" aria-hidden="true" tabindex="-1"></a>        data_dict <span class="op">=</span> pickle.load(outfile)</span>
<span id="cb302-4"><a href="#cb302-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_dict</span></code></pre></div>
</div>
<div class="cell" data-execution_count="884">
<div class="sourceCode cell-code" id="cb303"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a>_df1 <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="885">
<div class="sourceCode cell-code" id="cb304"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: _df1[<span class="st">'x'</span>],<span class="st">'y'</span>:_df1[<span class="st">'y'</span>],<span class="st">'z'</span>:_df1[<span class="st">'z'</span>],<span class="st">'fnoise'</span>:_df1[<span class="st">'fnoise'</span>],<span class="st">'f'</span>:_df1[<span class="st">'f'</span>],<span class="st">'noise'</span>:_df1[<span class="st">'noise'</span>]})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="889">
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> _df1[<span class="st">'unif'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="888">
<div class="sourceCode cell-code" id="cb306"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb306-1"><a href="#cb306-1" aria-hidden="true" tabindex="-1"></a>_df1[<span class="st">'index_of_trueoutlier2'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="888">
<pre><code>(array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
         240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
         397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
         569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
         858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
        1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
        1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
        1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
        1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
        2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
        2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="643">
<div class="sourceCode cell-code" id="cb308"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="co"># _df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="890">
<div class="sourceCode cell-code" id="cb309"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> unif.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="891">
<div class="sourceCode cell-code" id="cb310"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">!=</span><span class="dv">0</span>  <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_2))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="892">
<div class="sourceCode cell-code" id="cb311"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)[:,:<span class="dv">4</span>]</span></code></pre></div>
</div>
</section>
<section id="gode-2" class="level3">
<h3 class="anchored" data-anchor-id="gode-2">GODE</h3>
<div class="cell" data-execution_count="893">
<div class="sourceCode cell-code" id="cb312"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> _df1[<span class="st">'W'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="894">
<div class="sourceCode cell-code" id="cb313"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a>_BUNNY <span class="op">=</span> BUNNY(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="895">
<div class="sourceCode cell-code" id="cb314"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>_BUNNY.fit(sd<span class="op">=</span><span class="dv">20</span>,ref<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="896">
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(_BUNNY.f)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="896">
<pre><code>2503</code></pre>
</div>
</div>
<div class="cell" data-execution_count="897">
<div class="sourceCode cell-code" id="cb317"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2503</span><span class="op">*</span><span class="fl">0.05</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="897">
<pre><code>125.15</code></pre>
</div>
</div>
<div class="cell" data-execution_count="941">
<div class="sourceCode cell-code" id="cb319"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_BUNNY.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="942">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="co"># outlier_simul_one = list(map(lambda x: -1 if x &gt; 8.7 else 1,outlier_simul_one))</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="943">
<div class="sourceCode cell-code" id="cb321"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">8.05</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="944">
<div class="sourceCode cell-code" id="cb322"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="944">
<pre><code>2378</code></pre>
</div>
</div>
<div class="cell" data-execution_count="945">
<div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="945">
<pre><code>125</code></pre>
</div>
</div>
<div class="cell" data-execution_count="946">
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="947">
<div class="sourceCode cell-code" id="cb327"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-253-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.995
Recall: 0.993
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="948">
<div class="sourceCode cell-code" id="cb330"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="948">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.988414</td>
      <td>0.994954</td>
      <td>0.992866</td>
      <td>0.993909</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lof" class="level3">
<h3 class="anchored" data-anchor-id="lof">LOF</h3>
<div class="cell" data-execution_count="949">
<div class="sourceCode cell-code" id="cb331"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb331-1"><a href="#cb331-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="950">
<div class="sourceCode cell-code" id="cb332"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="951">
<div class="sourceCode cell-code" id="cb333"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-257-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.913
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="952">
<div class="sourceCode cell-code" id="cb336"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="952">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.913304</td>
      <td>0.955425</td>
      <td>0.95342</td>
      <td>0.954421</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="knn-2" class="level3">
<h3 class="anchored" data-anchor-id="knn-2">KNN</h3>
<div class="cell" data-tags="[]" data-execution_count="231">
<div class="sourceCode cell-code" id="cb337"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb337-2"><a href="#cb337-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb337-3"><a href="#cb337-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb338"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="234">
<div class="sourceCode cell-code" id="cb340"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="235">
<div class="sourceCode cell-code" id="cb341"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb341-1"><a href="#cb341-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-263-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.940
Precision: 0.996
Recall: 0.941
F1 Score: 0.968</code></pre>
</div>
</div>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb343"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="cblof-1" class="level3">
<h3 class="anchored" data-anchor-id="cblof-1">CBLOF</h3>
<div class="cell" data-execution_count="237">
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb344-3"><a href="#cb344-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="238">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="239">
<div class="sourceCode cell-code" id="cb346"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="240">
<div class="sourceCode cell-code" id="cb347"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="241">
<div class="sourceCode cell-code" id="cb348"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-269-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.978
Precision: 0.989
Recall: 0.987
F1 Score: 0.988</code></pre>
</div>
</div>
<div class="cell" data-execution_count="242">
<div class="sourceCode cell-code" id="cb350"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a>four <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="ocsvm-2" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-2">OCSVM</h3>
<div class="cell" data-execution_count="243">
<div class="sourceCode cell-code" id="cb351"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="244">
<div class="sourceCode cell-code" id="cb352"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>OneClassSVM(gamma=0.1, nu=0.1)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="245">
<div class="sourceCode cell-code" id="cb354"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="246">
<div class="sourceCode cell-code" id="cb355"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="247">
<div class="sourceCode cell-code" id="cb356"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb356-1"><a href="#cb356-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-275-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.932
Precision: 0.991
Recall: 0.937
F1 Score: 0.963</code></pre>
</div>
</div>
<div class="cell" data-execution_count="248">
<div class="sourceCode cell-code" id="cb358"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb358-1"><a href="#cb358-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> four.append(_conf.tab)</span></code></pre></div>
</div>
</section>
<section id="mcd" class="level3">
<h3 class="anchored" data-anchor-id="mcd">MCD</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="953">
<div class="sourceCode cell-code" id="cb359"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb359-1"><a href="#cb359-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb359-2"><a href="#cb359-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb359-3"><a href="#cb359-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="954">
<div class="sourceCode cell-code" id="cb360"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="955">
<div class="sourceCode cell-code" id="cb361"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb361-1"><a href="#cb361-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="956">
<div class="sourceCode cell-code" id="cb362"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="957">
<div class="sourceCode cell-code" id="cb363"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-281-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.982
Precision: 0.992
Recall: 0.989
F1 Score: 0.990</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="959">
<div class="sourceCode cell-code" id="cb366"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="959">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.981622</td>
      <td>0.991586</td>
      <td>0.989089</td>
      <td>0.990336</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="feature-bagging" class="level3">
<h3 class="anchored" data-anchor-id="feature-bagging">Feature Bagging</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="960">
<div class="sourceCode cell-code" id="cb367"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb367-1"><a href="#cb367-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb367-2"><a href="#cb367-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb367-3"><a href="#cb367-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="961">
<div class="sourceCode cell-code" id="cb368"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="962">
<div class="sourceCode cell-code" id="cb369"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb369-1"><a href="#cb369-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="963">
<div class="sourceCode cell-code" id="cb370"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="964">
<div class="sourceCode cell-code" id="cb371"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb371-1"><a href="#cb371-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-287-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.977
Recall: 0.975
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="966">
<div class="sourceCode cell-code" id="cb374"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="966">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.954455</td>
      <td>0.977282</td>
      <td>0.974822</td>
      <td>0.97605</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="abod" class="level3">
<h3 class="anchored" data-anchor-id="abod">ABOD</h3>
<div class="cell" data-execution_count="967">
<div class="sourceCode cell-code" id="cb375"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb375-1"><a href="#cb375-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb375-2"><a href="#cb375-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb375-3"><a href="#cb375-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="968">
<div class="sourceCode cell-code" id="cb376"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb376-1"><a href="#cb376-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="969">
<div class="sourceCode cell-code" id="cb377"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="970">
<div class="sourceCode cell-code" id="cb378"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb378-1"><a href="#cb378-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="973">
<div class="sourceCode cell-code" id="cb380"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb380-1"><a href="#cb380-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="973">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.979225</td>
      <td>0.990324</td>
      <td>0.98783</td>
      <td>0.989076</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>normal fix 안 해줘서 좀 다른듯</p>
</section>
<section id="iforest" class="level3">
<h3 class="anchored" data-anchor-id="iforest">IForest</h3>
<div class="cell" data-execution_count="974">
<div class="sourceCode cell-code" id="cb381"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb381-2"><a href="#cb381-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb381-3"><a href="#cb381-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">125</span></span>
<span id="cb381-4"><a href="#cb381-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="975">
<div class="sourceCode cell-code" id="cb382"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="976">
<div class="sourceCode cell-code" id="cb383"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb383-2"><a href="#cb383-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]],</span>
<span id="cb383-3"><a href="#cb383-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb383-4"><a href="#cb383-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="977">
<div class="sourceCode cell-code" id="cb384"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb384-1"><a href="#cb384-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="978">
<div class="sourceCode cell-code" id="cb385"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="979">
<div class="sourceCode cell-code" id="cb386"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb386-1"><a href="#cb386-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="980">
<div class="sourceCode cell-code" id="cb387"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb387-1"><a href="#cb387-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="981">
<div class="sourceCode cell-code" id="cb388"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-302-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.802
Precision: 0.996
Recall: 0.795
F1 Score: 0.884</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="982">
<div class="sourceCode cell-code" id="cb391"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="982">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.801838</td>
      <td>0.996318</td>
      <td>0.794796</td>
      <td>0.88422</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="hbos" class="level3">
<h3 class="anchored" data-anchor-id="hbos">HBOS</h3>
<div class="cell" data-execution_count="983">
<div class="sourceCode cell-code" id="cb392"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb392-2"><a href="#cb392-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb392-3"><a href="#cb392-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="984">
<div class="sourceCode cell-code" id="cb393"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="985">
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="986">
<div class="sourceCode cell-code" id="cb395"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="987">
<div class="sourceCode cell-code" id="cb396"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb396-1"><a href="#cb396-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-308-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.919
Precision: 0.958
Recall: 0.956
F1 Score: 0.957</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="989">
<div class="sourceCode cell-code" id="cb399"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb399-1"><a href="#cb399-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="989">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.918897</td>
      <td>0.958368</td>
      <td>0.956358</td>
      <td>0.957362</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sos" class="level3">
<h3 class="anchored" data-anchor-id="sos">SOS</h3>
<div class="cell" data-execution_count="990">
<div class="sourceCode cell-code" id="cb400"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb400-2"><a href="#cb400-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb400-3"><a href="#cb400-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="991">
<div class="sourceCode cell-code" id="cb401"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb401-1"><a href="#cb401-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="992">
<div class="sourceCode cell-code" id="cb402"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb402-1"><a href="#cb402-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="993">
<div class="sourceCode cell-code" id="cb403"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb403-1"><a href="#cb403-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="994">
<div class="sourceCode cell-code" id="cb404"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb404-1"><a href="#cb404-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-314-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.912
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="995">
<div class="sourceCode cell-code" id="cb407"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb407-1"><a href="#cb407-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="995">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.912105</td>
      <td>0.954985</td>
      <td>0.952581</td>
      <td>0.953782</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="so_gaal-1" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal-1">SO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="996">
<div class="sourceCode cell-code" id="cb408"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb408-1"><a href="#cb408-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb408-2"><a href="#cb408-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb408-3"><a href="#cb408-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:

Testing for epoch 1 index 3:

Testing for epoch 1 index 4:

Testing for epoch 1 index 5:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:

Testing for epoch 2 index 3:

Testing for epoch 2 index 4:

Testing for epoch 2 index 5:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:

Testing for epoch 3 index 3:

Testing for epoch 3 index 4:

Testing for epoch 3 index 5:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:

Testing for epoch 4 index 3:

Testing for epoch 4 index 4:

Testing for epoch 4 index 5:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:

Testing for epoch 5 index 3:

Testing for epoch 5 index 4:

Testing for epoch 5 index 5:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:

Testing for epoch 6 index 3:

Testing for epoch 6 index 4:

Testing for epoch 6 index 5:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:

Testing for epoch 7 index 3:

Testing for epoch 7 index 4:

Testing for epoch 7 index 5:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:

Testing for epoch 8 index 3:

Testing for epoch 8 index 4:

Testing for epoch 8 index 5:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:

Testing for epoch 9 index 3:

Testing for epoch 9 index 4:

Testing for epoch 9 index 5:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:

Testing for epoch 10 index 3:

Testing for epoch 10 index 4:

Testing for epoch 10 index 5:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:

Testing for epoch 11 index 3:

Testing for epoch 11 index 4:

Testing for epoch 11 index 5:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:

Testing for epoch 12 index 3:

Testing for epoch 12 index 4:

Testing for epoch 12 index 5:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:

Testing for epoch 13 index 3:

Testing for epoch 13 index 4:

Testing for epoch 13 index 5:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:

Testing for epoch 14 index 3:

Testing for epoch 14 index 4:

Testing for epoch 14 index 5:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:

Testing for epoch 15 index 3:

Testing for epoch 15 index 4:

Testing for epoch 15 index 5:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:

Testing for epoch 16 index 3:

Testing for epoch 16 index 4:

Testing for epoch 16 index 5:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:

Testing for epoch 17 index 3:

Testing for epoch 17 index 4:

Testing for epoch 17 index 5:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:

Testing for epoch 18 index 3:

Testing for epoch 18 index 4:

Testing for epoch 18 index 5:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:

Testing for epoch 19 index 3:

Testing for epoch 19 index 4:

Testing for epoch 19 index 5:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:

Testing for epoch 20 index 3:

Testing for epoch 20 index 4:

Testing for epoch 20 index 5:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:

Testing for epoch 21 index 3:

Testing for epoch 21 index 4:

Testing for epoch 21 index 5:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 884us/step - loss: 1.8581

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 851us/step - loss: 1.8268

Testing for epoch 22 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 1.8105

Testing for epoch 22 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 1.8629

Testing for epoch 22 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 1.8437
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 817us/step - loss: 1.8746

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8769

Testing for epoch 23 index 3:
16/16 [==============================] - 0s 820us/step - loss: 1.9082

Testing for epoch 23 index 4:
16/16 [==============================] - 0s 829us/step - loss: 1.9774

Testing for epoch 23 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 1.8979
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9382

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 816us/step - loss: 2.0013

Testing for epoch 24 index 3:
16/16 [==============================] - 0s 780us/step - loss: 1.9474

Testing for epoch 24 index 4:
16/16 [==============================] - 0s 776us/step - loss: 1.9568

Testing for epoch 24 index 5:
16/16 [==============================] - 0s 781us/step - loss: 1.9321
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 786us/step - loss: 2.0072

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 796us/step - loss: 1.9963

Testing for epoch 25 index 3:
16/16 [==============================] - 0s 791us/step - loss: 1.9636

Testing for epoch 25 index 4:
16/16 [==============================] - 0s 798us/step - loss: 1.9991

Testing for epoch 25 index 5:
16/16 [==============================] - 0s 800us/step - loss: 1.9622
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 805us/step - loss: 2.0317

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 788us/step - loss: 2.0292

Testing for epoch 26 index 3:
16/16 [==============================] - 0s 780us/step - loss: 2.0108

Testing for epoch 26 index 4:
16/16 [==============================] - 0s 811us/step - loss: 2.0986

Testing for epoch 26 index 5:
16/16 [==============================] - 0s 804us/step - loss: 2.0268
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 807us/step - loss: 2.0039

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 810us/step - loss: 1.9839

Testing for epoch 27 index 3:
16/16 [==============================] - 0s 780us/step - loss: 2.0369

Testing for epoch 27 index 4:
16/16 [==============================] - 0s 769us/step - loss: 2.0882

Testing for epoch 27 index 5:
16/16 [==============================] - 0s 776us/step - loss: 2.1175
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 783us/step - loss: 2.0468

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 775us/step - loss: 2.1566

Testing for epoch 28 index 3:
16/16 [==============================] - 0s 790us/step - loss: 2.1313

Testing for epoch 28 index 4:
16/16 [==============================] - 0s 774us/step - loss: 2.0696

Testing for epoch 28 index 5:
16/16 [==============================] - 0s 783us/step - loss: 2.1105
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 859us/step - loss: 2.1233

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 858us/step - loss: 2.1898

Testing for epoch 29 index 3:
16/16 [==============================] - 0s 787us/step - loss: 2.1491

Testing for epoch 29 index 4:
16/16 [==============================] - 0s 778us/step - loss: 2.0588

Testing for epoch 29 index 5:
16/16 [==============================] - 0s 782us/step - loss: 2.1768
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 785us/step - loss: 2.1179

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 789us/step - loss: 2.0555

Testing for epoch 30 index 3:
16/16 [==============================] - 0s 806us/step - loss: 2.1895

Testing for epoch 30 index 4:
16/16 [==============================] - 0s 784us/step - loss: 2.1507

Testing for epoch 30 index 5:
16/16 [==============================] - 0s 778us/step - loss: 2.1609
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 870us/step - loss: 2.1508

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 855us/step - loss: 2.1723

Testing for epoch 31 index 3:
16/16 [==============================] - 0s 772us/step - loss: 2.1727

Testing for epoch 31 index 4:
16/16 [==============================] - 0s 858us/step - loss: 2.1854

Testing for epoch 31 index 5:
16/16 [==============================] - 0s 868us/step - loss: 2.1387
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 792us/step - loss: 2.1947

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 781us/step - loss: 2.1907

Testing for epoch 32 index 3:
16/16 [==============================] - 0s 808us/step - loss: 2.2182

Testing for epoch 32 index 4:
16/16 [==============================] - 0s 868us/step - loss: 2.1766

Testing for epoch 32 index 5:
16/16 [==============================] - 0s 866us/step - loss: 2.2530
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 862us/step - loss: 2.1474

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 859us/step - loss: 2.2063

Testing for epoch 33 index 3:
16/16 [==============================] - 0s 794us/step - loss: 2.1418

Testing for epoch 33 index 4:
16/16 [==============================] - 0s 802us/step - loss: 2.1733

Testing for epoch 33 index 5:
16/16 [==============================] - 0s 865us/step - loss: 2.1798
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 784us/step - loss: 2.1840

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 864us/step - loss: 2.2017

Testing for epoch 34 index 3:
16/16 [==============================] - 0s 874us/step - loss: 2.1487

Testing for epoch 34 index 4:
16/16 [==============================] - 0s 865us/step - loss: 2.1722

Testing for epoch 34 index 5:
16/16 [==============================] - 0s 862us/step - loss: 2.2064
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 784us/step - loss: 2.2386

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 784us/step - loss: 2.2565

Testing for epoch 35 index 3:
16/16 [==============================] - 0s 782us/step - loss: 2.2598

Testing for epoch 35 index 4:
16/16 [==============================] - 0s 778us/step - loss: 2.2462

Testing for epoch 35 index 5:
16/16 [==============================] - 0s 775us/step - loss: 2.2122
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 798us/step - loss: 2.2970

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 783us/step - loss: 2.1968

Testing for epoch 36 index 3:
16/16 [==============================] - 0s 783us/step - loss: 2.1858

Testing for epoch 36 index 4:
16/16 [==============================] - 0s 779us/step - loss: 2.2718

Testing for epoch 36 index 5:
16/16 [==============================] - 0s 788us/step - loss: 2.2524
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 786us/step - loss: 2.3237

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 804us/step - loss: 2.2730

Testing for epoch 37 index 3:
16/16 [==============================] - 0s 802us/step - loss: 2.2791

Testing for epoch 37 index 4:
16/16 [==============================] - 0s 797us/step - loss: 2.2170

Testing for epoch 37 index 5:
16/16 [==============================] - 0s 791us/step - loss: 2.2519
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 794us/step - loss: 2.2645

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 802us/step - loss: 2.2773

Testing for epoch 38 index 3:
16/16 [==============================] - 0s 789us/step - loss: 2.2241

Testing for epoch 38 index 4:
16/16 [==============================] - 0s 788us/step - loss: 2.2027

Testing for epoch 38 index 5:
16/16 [==============================] - 0s 782us/step - loss: 2.2587
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 793us/step - loss: 2.3062

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 810us/step - loss: 2.2876

Testing for epoch 39 index 3:
16/16 [==============================] - 0s 796us/step - loss: 2.3002

Testing for epoch 39 index 4:
16/16 [==============================] - 0s 792us/step - loss: 2.2957

Testing for epoch 39 index 5:
16/16 [==============================] - 0s 783us/step - loss: 2.3436
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 795us/step - loss: 2.3124

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 793us/step - loss: 2.3122

Testing for epoch 40 index 3:
16/16 [==============================] - 0s 785us/step - loss: 2.3793

Testing for epoch 40 index 4:
16/16 [==============================] - 0s 775us/step - loss: 2.3909

Testing for epoch 40 index 5:
16/16 [==============================] - 0s 779us/step - loss: 2.3545
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 780us/step - loss: 2.3163

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 862us/step - loss: 2.2775

Testing for epoch 41 index 3:
16/16 [==============================] - 0s 783us/step - loss: 2.3917

Testing for epoch 41 index 4:
16/16 [==============================] - 0s 866us/step - loss: 2.3026

Testing for epoch 41 index 5:
16/16 [==============================] - 0s 868us/step - loss: 2.3877
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 803us/step - loss: 2.3786

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 856us/step - loss: 2.3494

Testing for epoch 42 index 3:
16/16 [==============================] - 0s 863us/step - loss: 2.3941

Testing for epoch 42 index 4:
16/16 [==============================] - 0s 864us/step - loss: 2.4017

Testing for epoch 42 index 5:
16/16 [==============================] - 0s 789us/step - loss: 2.4000
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 778us/step - loss: 2.3983

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 781us/step - loss: 2.4288

Testing for epoch 43 index 3:
16/16 [==============================] - 0s 859us/step - loss: 2.4264

Testing for epoch 43 index 4:
16/16 [==============================] - 0s 856us/step - loss: 2.3392

Testing for epoch 43 index 5:
16/16 [==============================] - 0s 777us/step - loss: 2.3499
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 858us/step - loss: 2.3771

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 801us/step - loss: 2.4369

Testing for epoch 44 index 3:
16/16 [==============================] - 0s 800us/step - loss: 2.4018

Testing for epoch 44 index 4:
16/16 [==============================] - 0s 876us/step - loss: 2.3719

Testing for epoch 44 index 5:
16/16 [==============================] - 0s 788us/step - loss: 2.4317
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 789us/step - loss: 2.3697

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 782us/step - loss: 2.4209

Testing for epoch 45 index 3:
16/16 [==============================] - 0s 801us/step - loss: 2.4024

Testing for epoch 45 index 4:
16/16 [==============================] - 0s 893us/step - loss: 2.3772

Testing for epoch 45 index 5:
16/16 [==============================] - 0s 659us/step - loss: 2.4637
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 765us/step - loss: 2.3838

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 773us/step - loss: 2.4202

Testing for epoch 46 index 3:
16/16 [==============================] - 0s 815us/step - loss: 2.4058

Testing for epoch 46 index 4:
16/16 [==============================] - 0s 865us/step - loss: 2.4420

Testing for epoch 46 index 5:
16/16 [==============================] - 0s 861us/step - loss: 2.3690
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 867us/step - loss: 2.4586

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 867us/step - loss: 2.3855

Testing for epoch 47 index 3:
16/16 [==============================] - 0s 825us/step - loss: 2.4066

Testing for epoch 47 index 4:
16/16 [==============================] - 0s 790us/step - loss: 2.3900

Testing for epoch 47 index 5:
16/16 [==============================] - 0s 788us/step - loss: 2.3786
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 782us/step - loss: 2.4204

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 806us/step - loss: 2.4810

Testing for epoch 48 index 3:
16/16 [==============================] - 0s 857us/step - loss: 2.4269

Testing for epoch 48 index 4:
16/16 [==============================] - 0s 806us/step - loss: 2.4338

Testing for epoch 48 index 5:
16/16 [==============================] - 0s 799us/step - loss: 2.4088
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 785us/step - loss: 2.4287

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 804us/step - loss: 2.4810

Testing for epoch 49 index 3:
16/16 [==============================] - 0s 785us/step - loss: 2.4933

Testing for epoch 49 index 4:
16/16 [==============================] - 0s 777us/step - loss: 2.4442

Testing for epoch 49 index 5:
16/16 [==============================] - 0s 782us/step - loss: 2.4288
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 782us/step - loss: 2.4540

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 811us/step - loss: 2.4526

Testing for epoch 50 index 3:
16/16 [==============================] - 0s 795us/step - loss: 2.4647

Testing for epoch 50 index 4:
16/16 [==============================] - 0s 794us/step - loss: 2.4452

Testing for epoch 50 index 5:
16/16 [==============================] - 0s 897us/step - loss: 2.4421
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 811us/step - loss: 2.4730

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 887us/step - loss: 2.4679

Testing for epoch 51 index 3:
16/16 [==============================] - 0s 795us/step - loss: 2.5049

Testing for epoch 51 index 4:
16/16 [==============================] - 0s 791us/step - loss: 2.4165

Testing for epoch 51 index 5:
16/16 [==============================] - 0s 785us/step - loss: 2.4767
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 788us/step - loss: 2.4997

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 794us/step - loss: 2.4975

Testing for epoch 52 index 3:
16/16 [==============================] - 0s 794us/step - loss: 2.4337

Testing for epoch 52 index 4:
16/16 [==============================] - 0s 790us/step - loss: 2.5195

Testing for epoch 52 index 5:
16/16 [==============================] - 0s 800us/step - loss: 2.5090
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 790us/step - loss: 2.5437

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 856us/step - loss: 2.4638

Testing for epoch 53 index 3:
16/16 [==============================] - 0s 818us/step - loss: 2.5519

Testing for epoch 53 index 4:
16/16 [==============================] - 0s 814us/step - loss: 2.5230

Testing for epoch 53 index 5:
16/16 [==============================] - 0s 798us/step - loss: 2.5974
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 805us/step - loss: 2.4882

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 805us/step - loss: 2.5543

Testing for epoch 54 index 3:
16/16 [==============================] - 0s 818us/step - loss: 2.5479

Testing for epoch 54 index 4:
16/16 [==============================] - 0s 802us/step - loss: 2.4534

Testing for epoch 54 index 5:
16/16 [==============================] - 0s 807us/step - loss: 2.5373
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 859us/step - loss: 2.4623

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 786us/step - loss: 2.5190

Testing for epoch 55 index 3:
16/16 [==============================] - 0s 822us/step - loss: 2.5732

Testing for epoch 55 index 4:
16/16 [==============================] - 0s 809us/step - loss: 2.5078

Testing for epoch 55 index 5:
16/16 [==============================] - 0s 973us/step - loss: 2.4994
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 795us/step - loss: 2.5726

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 893us/step - loss: 2.5790

Testing for epoch 56 index 3:
16/16 [==============================] - 0s 885us/step - loss: 2.6221

Testing for epoch 56 index 4:
16/16 [==============================] - 0s 813us/step - loss: 2.5213

Testing for epoch 56 index 5:
16/16 [==============================] - 0s 879us/step - loss: 2.5010
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 820us/step - loss: 2.5513

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 803us/step - loss: 2.4536

Testing for epoch 57 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.4946

Testing for epoch 57 index 4:
16/16 [==============================] - 0s 799us/step - loss: 2.6023

Testing for epoch 57 index 5:
16/16 [==============================] - 0s 808us/step - loss: 2.5290
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 807us/step - loss: 2.5448

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.5045

Testing for epoch 58 index 3:
16/16 [==============================] - 0s 819us/step - loss: 2.5511

Testing for epoch 58 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5779

Testing for epoch 58 index 5:
16/16 [==============================] - 0s 832us/step - loss: 2.5539
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 835us/step - loss: 2.5352

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 824us/step - loss: 2.5329

Testing for epoch 59 index 3:
16/16 [==============================] - 0s 876us/step - loss: 2.5908

Testing for epoch 59 index 4:
16/16 [==============================] - 0s 796us/step - loss: 2.5827

Testing for epoch 59 index 5:
16/16 [==============================] - 0s 801us/step - loss: 2.5933
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 806us/step - loss: 2.6601

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 797us/step - loss: 2.6500

Testing for epoch 60 index 3:
16/16 [==============================] - 0s 797us/step - loss: 2.5971

Testing for epoch 60 index 4:
16/16 [==============================] - 0s 799us/step - loss: 2.5911

Testing for epoch 60 index 5:
16/16 [==============================] - 0s 883us/step - loss: 2.5570
79/79 [==============================] - 0s 813us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="997">
<div class="sourceCode cell-code" id="cb411"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="998">
<div class="sourceCode cell-code" id="cb412"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb412-1"><a href="#cb412-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="999">
<div class="sourceCode cell-code" id="cb413"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb413-1"><a href="#cb413-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1000">
<div class="sourceCode cell-code" id="cb414"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb414-1"><a href="#cb414-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-320-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1001">
<div class="sourceCode cell-code" id="cb417"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb417-1"><a href="#cb417-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1001">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.952058</td>
      <td>0.952058</td>
      <td>1.0</td>
      <td>0.97544</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="mo_gaal" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaal">MO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1002">
<div class="sourceCode cell-code" id="cb418"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb418-2"><a href="#cb418-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb418-3"><a href="#cb418-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
79/79 [==============================] - 0s 607us/step

Testing for epoch 1 index 2:
79/79 [==============================] - 0s 602us/step

Testing for epoch 1 index 3:
79/79 [==============================] - 0s 579us/step

Testing for epoch 1 index 4:
79/79 [==============================] - 0s 586us/step

Testing for epoch 1 index 5:
79/79 [==============================] - 0s 611us/step
Epoch 2 of 60

Testing for epoch 2 index 1:
79/79 [==============================] - 0s 627us/step

Testing for epoch 2 index 2:
79/79 [==============================] - 0s 600us/step

Testing for epoch 2 index 3:
79/79 [==============================] - 0s 591us/step

Testing for epoch 2 index 4:
79/79 [==============================] - 0s 756us/step

Testing for epoch 2 index 5:
79/79 [==============================] - 0s 832us/step
Epoch 3 of 60

Testing for epoch 3 index 1:
79/79 [==============================] - 0s 579us/step

Testing for epoch 3 index 2:
79/79 [==============================] - 0s 580us/step

Testing for epoch 3 index 3:
79/79 [==============================] - 0s 825us/step

Testing for epoch 3 index 4:
79/79 [==============================] - 0s 591us/step

Testing for epoch 3 index 5:
79/79 [==============================] - 0s 589us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
79/79 [==============================] - 0s 594us/step

Testing for epoch 4 index 2:
79/79 [==============================] - 0s 576us/step

Testing for epoch 4 index 3:
79/79 [==============================] - 0s 588us/step

Testing for epoch 4 index 4:
79/79 [==============================] - 0s 592us/step

Testing for epoch 4 index 5:
79/79 [==============================] - 0s 612us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
79/79 [==============================] - 0s 596us/step

Testing for epoch 5 index 2:
79/79 [==============================] - 0s 590us/step

Testing for epoch 5 index 3:
79/79 [==============================] - 0s 585us/step

Testing for epoch 5 index 4:
79/79 [==============================] - 0s 580us/step

Testing for epoch 5 index 5:
79/79 [==============================] - 0s 579us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
79/79 [==============================] - 0s 602us/step

Testing for epoch 6 index 2:
79/79 [==============================] - 0s 589us/step

Testing for epoch 6 index 3:
79/79 [==============================] - 0s 592us/step

Testing for epoch 6 index 4:
79/79 [==============================] - 0s 725us/step

Testing for epoch 6 index 5:
79/79 [==============================] - 0s 599us/step
Epoch 7 of 60

Testing for epoch 7 index 1:
79/79 [==============================] - 0s 581us/step

Testing for epoch 7 index 2:
79/79 [==============================] - 0s 587us/step

Testing for epoch 7 index 3:
79/79 [==============================] - 0s 831us/step

Testing for epoch 7 index 4:
79/79 [==============================] - 0s 595us/step

Testing for epoch 7 index 5:
79/79 [==============================] - 0s 668us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
79/79 [==============================] - 0s 599us/step

Testing for epoch 8 index 2:
79/79 [==============================] - 0s 608us/step

Testing for epoch 8 index 3:
79/79 [==============================] - 0s 603us/step

Testing for epoch 8 index 4:
79/79 [==============================] - 0s 586us/step

Testing for epoch 8 index 5:
79/79 [==============================] - 0s 606us/step
Epoch 9 of 60

Testing for epoch 9 index 1:
79/79 [==============================] - 0s 617us/step

Testing for epoch 9 index 2:
79/79 [==============================] - 0s 606us/step

Testing for epoch 9 index 3:
79/79 [==============================] - 0s 611us/step

Testing for epoch 9 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 9 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 10 of 60

Testing for epoch 10 index 1:
79/79 [==============================] - 0s 845us/step

Testing for epoch 10 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 11 of 60

Testing for epoch 11 index 1:
79/79 [==============================] - 0s 548us/step

Testing for epoch 11 index 2:
79/79 [==============================] - 0s 951us/step

Testing for epoch 11 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 4:
79/79 [==============================] - 0s 887us/step

Testing for epoch 11 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 12 of 60

Testing for epoch 12 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 3:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 12 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 13 of 60

Testing for epoch 13 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 13 index 2:
79/79 [==============================] - 0s 4ms/step

Testing for epoch 13 index 3:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 13 index 4:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 13 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 14 of 60

Testing for epoch 14 index 1:
79/79 [==============================] - 0s 801us/step

Testing for epoch 14 index 2:
79/79 [==============================] - 0s 813us/step

Testing for epoch 14 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 14 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 14 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 15 of 60

Testing for epoch 15 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 15 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 15 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 15 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 16 of 60

Testing for epoch 16 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 16 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 17 of 60

Testing for epoch 17 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 17 index 2:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 17 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 17 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 17 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 18 of 60

Testing for epoch 18 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 19 of 60

Testing for epoch 19 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 20 of 60

Testing for epoch 20 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 20 index 2:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 20 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 20 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 20 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 21 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1933
16/16 [==============================] - 0s 3ms/step - loss: 1.3341
16/16 [==============================] - 0s 2ms/step - loss: 1.5591
16/16 [==============================] - 0s 2ms/step - loss: 1.6358
16/16 [==============================] - 0s 4ms/step - loss: 1.6683
16/16 [==============================] - 0s 2ms/step - loss: 1.6828
16/16 [==============================] - 0s 3ms/step - loss: 1.6807
16/16 [==============================] - 0s 2ms/step - loss: 1.6763
16/16 [==============================] - 0s 2ms/step - loss: 1.6722
16/16 [==============================] - 0s 2ms/step - loss: 1.6712

Testing for epoch 21 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.3434
16/16 [==============================] - 0s 3ms/step - loss: 1.5719
16/16 [==============================] - 0s 2ms/step - loss: 1.6501
16/16 [==============================] - 0s 2ms/step - loss: 1.6844
16/16 [==============================] - 0s 2ms/step - loss: 1.7006
16/16 [==============================] - 0s 3ms/step - loss: 1.6990
16/16 [==============================] - 0s 2ms/step - loss: 1.6947
16/16 [==============================] - 0s 3ms/step - loss: 1.6905
16/16 [==============================] - 0s 2ms/step - loss: 1.6894

Testing for epoch 21 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1818
16/16 [==============================] - 0s 2ms/step - loss: 1.3634
16/16 [==============================] - 0s 2ms/step - loss: 1.5974
16/16 [==============================] - 0s 2ms/step - loss: 1.6766
16/16 [==============================] - 0s 2ms/step - loss: 1.7110
16/16 [==============================] - 0s 3ms/step - loss: 1.7256
16/16 [==============================] - 0s 2ms/step - loss: 1.7227
16/16 [==============================] - 0s 2ms/step - loss: 1.7178
16/16 [==============================] - 0s 2ms/step - loss: 1.7134
16/16 [==============================] - 0s 2ms/step - loss: 1.7124

Testing for epoch 21 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1826
16/16 [==============================] - 0s 2ms/step - loss: 1.3497
16/16 [==============================] - 0s 3ms/step - loss: 1.5859
16/16 [==============================] - 0s 2ms/step - loss: 1.6665
16/16 [==============================] - 0s 3ms/step - loss: 1.7009
16/16 [==============================] - 0s 3ms/step - loss: 1.7171
16/16 [==============================] - 0s 5ms/step - loss: 1.7145
16/16 [==============================] - 0s 2ms/step - loss: 1.7096
16/16 [==============================] - 0s 2ms/step - loss: 1.7053
16/16 [==============================] - 0s 3ms/step - loss: 1.7043
Epoch 22 of 60

Testing for epoch 22 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1790
16/16 [==============================] - 0s 2ms/step - loss: 1.3860
16/16 [==============================] - 0s 3ms/step - loss: 1.6307
16/16 [==============================] - 0s 3ms/step - loss: 1.7131
16/16 [==============================] - 0s 2ms/step - loss: 1.7474
16/16 [==============================] - 0s 2ms/step - loss: 1.7627
16/16 [==============================] - 0s 2ms/step - loss: 1.7590
16/16 [==============================] - 0s 2ms/step - loss: 1.7538
16/16 [==============================] - 0s 2ms/step - loss: 1.7493
16/16 [==============================] - 0s 2ms/step - loss: 1.7481

Testing for epoch 22 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1797
16/16 [==============================] - 0s 2ms/step - loss: 1.3880
16/16 [==============================] - 0s 2ms/step - loss: 1.6376
16/16 [==============================] - 0s 3ms/step - loss: 1.7229
16/16 [==============================] - 0s 2ms/step - loss: 1.7587
16/16 [==============================] - 0s 2ms/step - loss: 1.7752
16/16 [==============================] - 0s 3ms/step - loss: 1.7713
16/16 [==============================] - 0s 2ms/step - loss: 1.7658
16/16 [==============================] - 0s 2ms/step - loss: 1.7612
16/16 [==============================] - 0s 2ms/step - loss: 1.7601

Testing for epoch 22 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1766
16/16 [==============================] - 0s 3ms/step - loss: 1.3857
16/16 [==============================] - 0s 2ms/step - loss: 1.6338
16/16 [==============================] - 0s 2ms/step - loss: 1.7171
16/16 [==============================] - 0s 2ms/step - loss: 1.7519
16/16 [==============================] - 0s 2ms/step - loss: 1.7660
16/16 [==============================] - 0s 3ms/step - loss: 1.7621
16/16 [==============================] - 0s 2ms/step - loss: 1.7562
16/16 [==============================] - 0s 3ms/step - loss: 1.7516
16/16 [==============================] - 0s 4ms/step - loss: 1.7504

Testing for epoch 22 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1761
16/16 [==============================] - 0s 2ms/step - loss: 1.3624
16/16 [==============================] - 0s 3ms/step - loss: 1.6046
16/16 [==============================] - 0s 2ms/step - loss: 1.6858
16/16 [==============================] - 0s 2ms/step - loss: 1.7200
16/16 [==============================] - 0s 2ms/step - loss: 1.7329
16/16 [==============================] - 0s 2ms/step - loss: 1.7283
16/16 [==============================] - 0s 3ms/step - loss: 1.7224
16/16 [==============================] - 0s 3ms/step - loss: 1.7179
16/16 [==============================] - 0s 2ms/step - loss: 1.7168

Testing for epoch 22 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1749
16/16 [==============================] - 0s 2ms/step - loss: 1.3904
16/16 [==============================] - 0s 2ms/step - loss: 1.6450
16/16 [==============================] - 0s 2ms/step - loss: 1.7296
16/16 [==============================] - 0s 2ms/step - loss: 1.7647
16/16 [==============================] - 0s 2ms/step - loss: 1.7782
16/16 [==============================] - 0s 3ms/step - loss: 1.7735
16/16 [==============================] - 0s 1ms/step - loss: 1.7673
16/16 [==============================] - 0s 2ms/step - loss: 1.7626
16/16 [==============================] - 0s 2ms/step - loss: 1.7614
Epoch 23 of 60

Testing for epoch 23 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1717
16/16 [==============================] - 0s 1ms/step - loss: 1.4195
16/16 [==============================] - 0s 2ms/step - loss: 1.6803
16/16 [==============================] - 0s 2ms/step - loss: 1.7678
16/16 [==============================] - 0s 2ms/step - loss: 1.8049
16/16 [==============================] - 0s 2ms/step - loss: 1.8176
16/16 [==============================] - 0s 2ms/step - loss: 1.8127
16/16 [==============================] - 0s 2ms/step - loss: 1.8065
16/16 [==============================] - 0s 2ms/step - loss: 1.8018
16/16 [==============================] - 0s 1ms/step - loss: 1.8007

Testing for epoch 23 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1703
16/16 [==============================] - 0s 3ms/step - loss: 1.3781
16/16 [==============================] - 0s 2ms/step - loss: 1.6307
16/16 [==============================] - 0s 2ms/step - loss: 1.7149
16/16 [==============================] - 0s 2ms/step - loss: 1.7492
16/16 [==============================] - 0s 4ms/step - loss: 1.7597
16/16 [==============================] - 0s 2ms/step - loss: 1.7541
16/16 [==============================] - 0s 3ms/step - loss: 1.7477
16/16 [==============================] - 0s 2ms/step - loss: 1.7429
16/16 [==============================] - 0s 3ms/step - loss: 1.7418

Testing for epoch 23 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1692
16/16 [==============================] - 0s 2ms/step - loss: 1.3997
16/16 [==============================] - 0s 2ms/step - loss: 1.6614
16/16 [==============================] - 0s 2ms/step - loss: 1.7488
16/16 [==============================] - 0s 2ms/step - loss: 1.7829
16/16 [==============================] - 0s 3ms/step - loss: 1.7923
16/16 [==============================] - 0s 2ms/step - loss: 1.7860
16/16 [==============================] - 0s 2ms/step - loss: 1.7791
16/16 [==============================] - 0s 2ms/step - loss: 1.7741
16/16 [==============================] - 0s 4ms/step - loss: 1.7729

Testing for epoch 23 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1614
16/16 [==============================] - 0s 2ms/step - loss: 1.4243
16/16 [==============================] - 0s 2ms/step - loss: 1.6874
16/16 [==============================] - 0s 3ms/step - loss: 1.7730
16/16 [==============================] - 0s 2ms/step - loss: 1.8044
16/16 [==============================] - 0s 2ms/step - loss: 1.8106
16/16 [==============================] - 0s 2ms/step - loss: 1.8023
16/16 [==============================] - 0s 2ms/step - loss: 1.7947
16/16 [==============================] - 0s 2ms/step - loss: 1.7895
16/16 [==============================] - 0s 2ms/step - loss: 1.7883

Testing for epoch 23 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1639
16/16 [==============================] - 0s 2ms/step - loss: 1.4096
16/16 [==============================] - 0s 2ms/step - loss: 1.6728
16/16 [==============================] - 0s 2ms/step - loss: 1.7611
16/16 [==============================] - 0s 2ms/step - loss: 1.7945
16/16 [==============================] - 0s 2ms/step - loss: 1.8032
16/16 [==============================] - 0s 2ms/step - loss: 1.7960
16/16 [==============================] - 0s 2ms/step - loss: 1.7889
16/16 [==============================] - 0s 3ms/step - loss: 1.7839
16/16 [==============================] - 0s 2ms/step - loss: 1.7828
Epoch 24 of 60

Testing for epoch 24 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1652
16/16 [==============================] - 0s 3ms/step - loss: 1.4203
16/16 [==============================] - 0s 2ms/step - loss: 1.6889
16/16 [==============================] - 0s 2ms/step - loss: 1.7794
16/16 [==============================] - 0s 2ms/step - loss: 1.8128
16/16 [==============================] - 0s 2ms/step - loss: 1.8200
16/16 [==============================] - 0s 2ms/step - loss: 1.8117
16/16 [==============================] - 0s 3ms/step - loss: 1.8043
16/16 [==============================] - 0s 4ms/step - loss: 1.7992
16/16 [==============================] - 0s 2ms/step - loss: 1.7979

Testing for epoch 24 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1629
16/16 [==============================] - 0s 2ms/step - loss: 1.4565
16/16 [==============================] - 0s 1ms/step - loss: 1.7324
16/16 [==============================] - 0s 3ms/step - loss: 1.8232
16/16 [==============================] - 0s 2ms/step - loss: 1.8567
16/16 [==============================] - 0s 2ms/step - loss: 1.8623
16/16 [==============================] - 0s 2ms/step - loss: 1.8525
16/16 [==============================] - 0s 2ms/step - loss: 1.8445
16/16 [==============================] - 0s 2ms/step - loss: 1.8391
16/16 [==============================] - 0s 2ms/step - loss: 1.8378

Testing for epoch 24 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1588
16/16 [==============================] - 0s 2ms/step - loss: 1.4328
16/16 [==============================] - 0s 2ms/step - loss: 1.7034
16/16 [==============================] - 0s 2ms/step - loss: 1.7931
16/16 [==============================] - 0s 2ms/step - loss: 1.8254
16/16 [==============================] - 0s 3ms/step - loss: 1.8305
16/16 [==============================] - 0s 3ms/step - loss: 1.8213
16/16 [==============================] - 0s 3ms/step - loss: 1.8135
16/16 [==============================] - 0s 2ms/step - loss: 1.8082
16/16 [==============================] - 0s 2ms/step - loss: 1.8070

Testing for epoch 24 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1598
16/16 [==============================] - 0s 3ms/step - loss: 1.4625
16/16 [==============================] - 0s 4ms/step - loss: 1.7385
16/16 [==============================] - 0s 2ms/step - loss: 1.8330
16/16 [==============================] - 0s 2ms/step - loss: 1.8680
16/16 [==============================] - 0s 3ms/step - loss: 1.8748
16/16 [==============================] - 0s 4ms/step - loss: 1.8655
16/16 [==============================] - 0s 2ms/step - loss: 1.8573
16/16 [==============================] - 0s 2ms/step - loss: 1.8520
16/16 [==============================] - 0s 2ms/step - loss: 1.8508

Testing for epoch 24 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1582
16/16 [==============================] - 0s 3ms/step - loss: 1.4227
16/16 [==============================] - 0s 2ms/step - loss: 1.6980
16/16 [==============================] - 0s 4ms/step - loss: 1.7907
16/16 [==============================] - 0s 2ms/step - loss: 1.8247
16/16 [==============================] - 0s 2ms/step - loss: 1.8321
16/16 [==============================] - 0s 2ms/step - loss: 1.8246
16/16 [==============================] - 0s 3ms/step - loss: 1.8169
16/16 [==============================] - 0s 2ms/step - loss: 1.8117
16/16 [==============================] - 0s 3ms/step - loss: 1.8105
Epoch 25 of 60

Testing for epoch 25 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1566
16/16 [==============================] - 0s 2ms/step - loss: 1.4854
16/16 [==============================] - 0s 3ms/step - loss: 1.7707
16/16 [==============================] - 0s 3ms/step - loss: 1.8668
16/16 [==============================] - 0s 3ms/step - loss: 1.9001
16/16 [==============================] - 0s 2ms/step - loss: 1.9027
16/16 [==============================] - 0s 2ms/step - loss: 1.8906
16/16 [==============================] - 0s 2ms/step - loss: 1.8810
16/16 [==============================] - 0s 2ms/step - loss: 1.8751
16/16 [==============================] - 0s 2ms/step - loss: 1.8737

Testing for epoch 25 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1562
16/16 [==============================] - 0s 2ms/step - loss: 1.4476
16/16 [==============================] - 0s 2ms/step - loss: 1.7269
16/16 [==============================] - 0s 2ms/step - loss: 1.8207
16/16 [==============================] - 0s 2ms/step - loss: 1.8530
16/16 [==============================] - 0s 3ms/step - loss: 1.8573
16/16 [==============================] - 0s 2ms/step - loss: 1.8472
16/16 [==============================] - 0s 2ms/step - loss: 1.8387
16/16 [==============================] - 0s 2ms/step - loss: 1.8334
16/16 [==============================] - 0s 2ms/step - loss: 1.8323

Testing for epoch 25 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1538
16/16 [==============================] - 0s 3ms/step - loss: 1.4666
16/16 [==============================] - 0s 2ms/step - loss: 1.7485
16/16 [==============================] - 0s 2ms/step - loss: 1.8424
16/16 [==============================] - 0s 2ms/step - loss: 1.8732
16/16 [==============================] - 0s 2ms/step - loss: 1.8750
16/16 [==============================] - 0s 3ms/step - loss: 1.8633
16/16 [==============================] - 0s 3ms/step - loss: 1.8543
16/16 [==============================] - 0s 2ms/step - loss: 1.8487
16/16 [==============================] - 0s 2ms/step - loss: 1.8474

Testing for epoch 25 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1567
16/16 [==============================] - 0s 2ms/step - loss: 1.4159
16/16 [==============================] - 0s 3ms/step - loss: 1.6860
16/16 [==============================] - 0s 2ms/step - loss: 1.7732
16/16 [==============================] - 0s 2ms/step - loss: 1.8016
16/16 [==============================] - 0s 2ms/step - loss: 1.8046
16/16 [==============================] - 0s 1ms/step - loss: 1.7946
16/16 [==============================] - 0s 3ms/step - loss: 1.7868
16/16 [==============================] - 0s 2ms/step - loss: 1.7818
16/16 [==============================] - 0s 2ms/step - loss: 1.7807

Testing for epoch 25 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1513
16/16 [==============================] - 0s 2ms/step - loss: 1.4927
16/16 [==============================] - 0s 3ms/step - loss: 1.7875
16/16 [==============================] - 0s 2ms/step - loss: 1.8838
16/16 [==============================] - 0s 2ms/step - loss: 1.9161
16/16 [==============================] - 0s 2ms/step - loss: 1.9203
16/16 [==============================] - 0s 2ms/step - loss: 1.9086
16/16 [==============================] - 0s 2ms/step - loss: 1.8996
16/16 [==============================] - 0s 2ms/step - loss: 1.8940
16/16 [==============================] - 0s 2ms/step - loss: 1.8927
Epoch 26 of 60

Testing for epoch 26 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1514
16/16 [==============================] - 0s 2ms/step - loss: 1.4652
16/16 [==============================] - 0s 2ms/step - loss: 1.7546
16/16 [==============================] - 0s 2ms/step - loss: 1.8485
16/16 [==============================] - 0s 2ms/step - loss: 1.8802
16/16 [==============================] - 0s 4ms/step - loss: 1.8830
16/16 [==============================] - 0s 4ms/step - loss: 1.8708
16/16 [==============================] - 0s 3ms/step - loss: 1.8616
16/16 [==============================] - 0s 2ms/step - loss: 1.8560
16/16 [==============================] - 0s 2ms/step - loss: 1.8546

Testing for epoch 26 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1486
16/16 [==============================] - 0s 2ms/step - loss: 1.5028
16/16 [==============================] - 0s 2ms/step - loss: 1.7964
16/16 [==============================] - 0s 2ms/step - loss: 1.8873
16/16 [==============================] - 0s 2ms/step - loss: 1.9176
16/16 [==============================] - 0s 2ms/step - loss: 1.9142
16/16 [==============================] - 0s 3ms/step - loss: 1.8984
16/16 [==============================] - 0s 2ms/step - loss: 1.8882
16/16 [==============================] - 0s 2ms/step - loss: 1.8821
16/16 [==============================] - 0s 2ms/step - loss: 1.8808

Testing for epoch 26 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1504
16/16 [==============================] - 0s 2ms/step - loss: 1.4629
16/16 [==============================] - 0s 1ms/step - loss: 1.7446
16/16 [==============================] - 0s 2ms/step - loss: 1.8318
16/16 [==============================] - 0s 2ms/step - loss: 1.8615
16/16 [==============================] - 0s 2ms/step - loss: 1.8578
16/16 [==============================] - 0s 2ms/step - loss: 1.8424
16/16 [==============================] - 0s 1ms/step - loss: 1.8326
16/16 [==============================] - 0s 2ms/step - loss: 1.8269
16/16 [==============================] - 0s 2ms/step - loss: 1.8256

Testing for epoch 26 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1495
16/16 [==============================] - 0s 2ms/step - loss: 1.5175
16/16 [==============================] - 0s 2ms/step - loss: 1.8163
16/16 [==============================] - 0s 2ms/step - loss: 1.9093
16/16 [==============================] - 0s 2ms/step - loss: 1.9438
16/16 [==============================] - 0s 2ms/step - loss: 1.9432
16/16 [==============================] - 0s 2ms/step - loss: 1.9280
16/16 [==============================] - 0s 2ms/step - loss: 1.9181
16/16 [==============================] - 0s 1ms/step - loss: 1.9121
16/16 [==============================] - 0s 1ms/step - loss: 1.9108

Testing for epoch 26 index 5:
79/79 [==============================] - 0s 538us/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1513
16/16 [==============================] - 0s 1ms/step - loss: 1.4852
16/16 [==============================] - 0s 692us/step - loss: 1.7743
16/16 [==============================] - 0s 812us/step - loss: 1.8640
16/16 [==============================] - 0s 2ms/step - loss: 1.8964
16/16 [==============================] - 0s 1ms/step - loss: 1.8941
16/16 [==============================] - 0s 778us/step - loss: 1.8783
16/16 [==============================] - 0s 4ms/step - loss: 1.8685
16/16 [==============================] - 0s 1ms/step - loss: 1.8628
16/16 [==============================] - 0s 746us/step - loss: 1.8615
Epoch 27 of 60

Testing for epoch 27 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1446
16/16 [==============================] - 0s 3ms/step - loss: 1.5541
16/16 [==============================] - 0s 5ms/step - loss: 1.8599
16/16 [==============================] - 0s 5ms/step - loss: 1.9514
16/16 [==============================] - 0s 3ms/step - loss: 1.9830
16/16 [==============================] - 0s 992us/step - loss: 1.9766
16/16 [==============================] - 0s 745us/step - loss: 1.9560
16/16 [==============================] - 0s 788us/step - loss: 1.9446
16/16 [==============================] - 0s 2ms/step - loss: 1.9381
16/16 [==============================] - 0s 825us/step - loss: 1.9366

Testing for epoch 27 index 2:
79/79 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1476
16/16 [==============================] - 0s 903us/step - loss: 1.5111
16/16 [==============================] - 0s 2ms/step - loss: 1.8062
16/16 [==============================] - 0s 2ms/step - loss: 1.8968
16/16 [==============================] - 0s 2ms/step - loss: 1.9303
16/16 [==============================] - 0s 802us/step - loss: 1.9283
16/16 [==============================] - 0s 2ms/step - loss: 1.9130
16/16 [==============================] - 0s 917us/step - loss: 1.9034
16/16 [==============================] - 0s 2ms/step - loss: 1.8976
16/16 [==============================] - 0s 2ms/step - loss: 1.8964

Testing for epoch 27 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1475
16/16 [==============================] - 0s 839us/step - loss: 1.5722
16/16 [==============================] - 0s 1ms/step - loss: 1.8865
16/16 [==============================] - 0s 2ms/step - loss: 1.9827
16/16 [==============================] - 0s 2ms/step - loss: 2.0182
16/16 [==============================] - 0s 878us/step - loss: 2.0125
16/16 [==============================] - 0s 833us/step - loss: 1.9940
16/16 [==============================] - 0s 2ms/step - loss: 1.9832
16/16 [==============================] - 0s 965us/step - loss: 1.9769
16/16 [==============================] - 0s 845us/step - loss: 1.9755

Testing for epoch 27 index 4:
79/79 [==============================] - 0s 4ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.1415
16/16 [==============================] - 0s 5ms/step - loss: 1.5335
16/16 [==============================] - 0s 4ms/step - loss: 1.8353
16/16 [==============================] - 0s 1ms/step - loss: 1.9257
16/16 [==============================] - 0s 980us/step - loss: 1.9580
16/16 [==============================] - 0s 890us/step - loss: 1.9520
16/16 [==============================] - 0s 2ms/step - loss: 1.9336
16/16 [==============================] - 0s 7ms/step - loss: 1.9229
16/16 [==============================] - 0s 5ms/step - loss: 1.9167
16/16 [==============================] - 0s 4ms/step - loss: 1.9153

Testing for epoch 27 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 985us/step - loss: 0.1453
16/16 [==============================] - 0s 891us/step - loss: 1.4944
16/16 [==============================] - 0s 2ms/step - loss: 1.7821
16/16 [==============================] - 0s 802us/step - loss: 1.8687
16/16 [==============================] - 0s 2ms/step - loss: 1.8964
16/16 [==============================] - 0s 2ms/step - loss: 1.8865
16/16 [==============================] - 0s 2ms/step - loss: 1.8666
16/16 [==============================] - 0s 1ms/step - loss: 1.8560
16/16 [==============================] - 0s 1ms/step - loss: 1.8500
16/16 [==============================] - 0s 1ms/step - loss: 1.8487
Epoch 28 of 60

Testing for epoch 28 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1420
16/16 [==============================] - 0s 2ms/step - loss: 1.5332
16/16 [==============================] - 0s 2ms/step - loss: 1.8363
16/16 [==============================] - 0s 2ms/step - loss: 1.9309
16/16 [==============================] - 0s 1ms/step - loss: 1.9619
16/16 [==============================] - 0s 2ms/step - loss: 1.9542
16/16 [==============================] - 0s 2ms/step - loss: 1.9350
16/16 [==============================] - 0s 2ms/step - loss: 1.9240
16/16 [==============================] - 0s 1ms/step - loss: 1.9177
16/16 [==============================] - 0s 2ms/step - loss: 1.9163

Testing for epoch 28 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1444
16/16 [==============================] - 0s 2ms/step - loss: 1.5196
16/16 [==============================] - 0s 2ms/step - loss: 1.8152
16/16 [==============================] - 0s 1ms/step - loss: 1.9060
16/16 [==============================] - 0s 2ms/step - loss: 1.9341
16/16 [==============================] - 0s 2ms/step - loss: 1.9241
16/16 [==============================] - 0s 1ms/step - loss: 1.9028
16/16 [==============================] - 0s 2ms/step - loss: 1.8915
16/16 [==============================] - 0s 3ms/step - loss: 1.8853
16/16 [==============================] - 0s 2ms/step - loss: 1.8839

Testing for epoch 28 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1412
16/16 [==============================] - 0s 2ms/step - loss: 1.5458
16/16 [==============================] - 0s 3ms/step - loss: 1.8524
16/16 [==============================] - 0s 2ms/step - loss: 1.9500
16/16 [==============================] - 0s 3ms/step - loss: 1.9813
16/16 [==============================] - 0s 3ms/step - loss: 1.9739
16/16 [==============================] - 0s 3ms/step - loss: 1.9541
16/16 [==============================] - 0s 2ms/step - loss: 1.9429
16/16 [==============================] - 0s 2ms/step - loss: 1.9365
16/16 [==============================] - 0s 3ms/step - loss: 1.9351

Testing for epoch 28 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1420
16/16 [==============================] - 0s 3ms/step - loss: 1.5560
16/16 [==============================] - 0s 1ms/step - loss: 1.8608
16/16 [==============================] - 0s 3ms/step - loss: 1.9587
16/16 [==============================] - 0s 3ms/step - loss: 1.9893
16/16 [==============================] - 0s 2ms/step - loss: 1.9808
16/16 [==============================] - 0s 2ms/step - loss: 1.9603
16/16 [==============================] - 0s 1ms/step - loss: 1.9490
16/16 [==============================] - 0s 1ms/step - loss: 1.9427
16/16 [==============================] - 0s 3ms/step - loss: 1.9414

Testing for epoch 28 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1386
16/16 [==============================] - 0s 2ms/step - loss: 1.5381
16/16 [==============================] - 0s 2ms/step - loss: 1.8388
16/16 [==============================] - 0s 3ms/step - loss: 1.9343
16/16 [==============================] - 0s 2ms/step - loss: 1.9632
16/16 [==============================] - 0s 3ms/step - loss: 1.9532
16/16 [==============================] - 0s 4ms/step - loss: 1.9322
16/16 [==============================] - 0s 2ms/step - loss: 1.9211
16/16 [==============================] - 0s 2ms/step - loss: 1.9149
16/16 [==============================] - 0s 2ms/step - loss: 1.9136
Epoch 29 of 60

Testing for epoch 29 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1397
16/16 [==============================] - 0s 2ms/step - loss: 1.5312
16/16 [==============================] - 0s 2ms/step - loss: 1.8309
16/16 [==============================] - 0s 2ms/step - loss: 1.9245
16/16 [==============================] - 0s 1ms/step - loss: 1.9524
16/16 [==============================] - 0s 2ms/step - loss: 1.9416
16/16 [==============================] - 0s 3ms/step - loss: 1.9206
16/16 [==============================] - 0s 2ms/step - loss: 1.9094
16/16 [==============================] - 0s 3ms/step - loss: 1.9032
16/16 [==============================] - 0s 2ms/step - loss: 1.9018

Testing for epoch 29 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1389
16/16 [==============================] - 0s 2ms/step - loss: 1.5254
16/16 [==============================] - 0s 3ms/step - loss: 1.8184
16/16 [==============================] - 0s 2ms/step - loss: 1.9075
16/16 [==============================] - 0s 4ms/step - loss: 1.9329
16/16 [==============================] - 0s 3ms/step - loss: 1.9186
16/16 [==============================] - 0s 3ms/step - loss: 1.8955
16/16 [==============================] - 0s 3ms/step - loss: 1.8842
16/16 [==============================] - 0s 1ms/step - loss: 1.8781
16/16 [==============================] - 0s 2ms/step - loss: 1.8769

Testing for epoch 29 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1340
16/16 [==============================] - 0s 2ms/step - loss: 1.5991
16/16 [==============================] - 0s 3ms/step - loss: 1.9160
16/16 [==============================] - 0s 1ms/step - loss: 2.0105
16/16 [==============================] - 0s 4ms/step - loss: 2.0378
16/16 [==============================] - 0s 2ms/step - loss: 2.0232
16/16 [==============================] - 0s 3ms/step - loss: 1.9972
16/16 [==============================] - 0s 3ms/step - loss: 1.9842
16/16 [==============================] - 0s 1ms/step - loss: 1.9772
16/16 [==============================] - 0s 2ms/step - loss: 1.9757

Testing for epoch 29 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1357
16/16 [==============================] - 0s 2ms/step - loss: 1.5796
16/16 [==============================] - 0s 1ms/step - loss: 1.8964
16/16 [==============================] - 0s 3ms/step - loss: 1.9901
16/16 [==============================] - 0s 3ms/step - loss: 2.0197
16/16 [==============================] - 0s 2ms/step - loss: 2.0090
16/16 [==============================] - 0s 2ms/step - loss: 1.9863
16/16 [==============================] - 0s 2ms/step - loss: 1.9746
16/16 [==============================] - 0s 3ms/step - loss: 1.9683
16/16 [==============================] - 0s 2ms/step - loss: 1.9670

Testing for epoch 29 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1359
16/16 [==============================] - 0s 2ms/step - loss: 1.5885
16/16 [==============================] - 0s 3ms/step - loss: 1.9104
16/16 [==============================] - 0s 2ms/step - loss: 2.0041
16/16 [==============================] - 0s 2ms/step - loss: 2.0359
16/16 [==============================] - 0s 2ms/step - loss: 2.0251
16/16 [==============================] - 0s 1ms/step - loss: 2.0024
16/16 [==============================] - 0s 3ms/step - loss: 1.9907
16/16 [==============================] - 0s 3ms/step - loss: 1.9843
16/16 [==============================] - 0s 2ms/step - loss: 1.9829
Epoch 30 of 60

Testing for epoch 30 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1322
16/16 [==============================] - 0s 2ms/step - loss: 1.6097
16/16 [==============================] - 0s 2ms/step - loss: 1.9287
16/16 [==============================] - 0s 3ms/step - loss: 2.0162
16/16 [==============================] - 0s 2ms/step - loss: 2.0431
16/16 [==============================] - 0s 1ms/step - loss: 2.0261
16/16 [==============================] - 0s 3ms/step - loss: 1.9982
16/16 [==============================] - 0s 1ms/step - loss: 1.9849
16/16 [==============================] - 0s 4ms/step - loss: 1.9780
16/16 [==============================] - 0s 3ms/step - loss: 1.9765

Testing for epoch 30 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1323
16/16 [==============================] - 0s 2ms/step - loss: 1.6524
16/16 [==============================] - 0s 2ms/step - loss: 1.9891
16/16 [==============================] - 0s 4ms/step - loss: 2.0821
16/16 [==============================] - 0s 3ms/step - loss: 2.1134
16/16 [==============================] - 0s 1ms/step - loss: 2.0982
16/16 [==============================] - 0s 4ms/step - loss: 2.0702
16/16 [==============================] - 0s 2ms/step - loss: 2.0568
16/16 [==============================] - 0s 2ms/step - loss: 2.0499
16/16 [==============================] - 0s 4ms/step - loss: 2.0484

Testing for epoch 30 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1366
16/16 [==============================] - 0s 2ms/step - loss: 1.5719
16/16 [==============================] - 0s 2ms/step - loss: 1.8858
16/16 [==============================] - 0s 2ms/step - loss: 1.9692
16/16 [==============================] - 0s 3ms/step - loss: 1.9997
16/16 [==============================] - 0s 1ms/step - loss: 1.9874
16/16 [==============================] - 0s 2ms/step - loss: 1.9634
16/16 [==============================] - 0s 2ms/step - loss: 1.9515
16/16 [==============================] - 0s 1ms/step - loss: 1.9451
16/16 [==============================] - 0s 2ms/step - loss: 1.9438

Testing for epoch 30 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1359
16/16 [==============================] - 0s 2ms/step - loss: 1.6132
16/16 [==============================] - 0s 2ms/step - loss: 1.9377
16/16 [==============================] - 0s 3ms/step - loss: 2.0224
16/16 [==============================] - 0s 2ms/step - loss: 2.0541
16/16 [==============================] - 0s 4ms/step - loss: 2.0392
16/16 [==============================] - 0s 2ms/step - loss: 2.0135
16/16 [==============================] - 0s 1ms/step - loss: 2.0010
16/16 [==============================] - 0s 2ms/step - loss: 1.9941
16/16 [==============================] - 0s 2ms/step - loss: 1.9927

Testing for epoch 30 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1313
16/16 [==============================] - 0s 1ms/step - loss: 1.6612
16/16 [==============================] - 0s 2ms/step - loss: 1.9969
16/16 [==============================] - 0s 2ms/step - loss: 2.0810
16/16 [==============================] - 0s 4ms/step - loss: 2.1112
16/16 [==============================] - 0s 2ms/step - loss: 2.0926
16/16 [==============================] - 0s 1ms/step - loss: 2.0627
16/16 [==============================] - 0s 2ms/step - loss: 2.0487
16/16 [==============================] - 0s 4ms/step - loss: 2.0415
16/16 [==============================] - 0s 3ms/step - loss: 2.0401
Epoch 31 of 60

Testing for epoch 31 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1294
16/16 [==============================] - 0s 2ms/step - loss: 1.6127
16/16 [==============================] - 0s 1ms/step - loss: 1.9414
16/16 [==============================] - 0s 2ms/step - loss: 2.0220
16/16 [==============================] - 0s 1ms/step - loss: 2.0502
16/16 [==============================] - 0s 2ms/step - loss: 2.0309
16/16 [==============================] - 0s 1ms/step - loss: 2.0029
16/16 [==============================] - 0s 3ms/step - loss: 1.9898
16/16 [==============================] - 0s 1ms/step - loss: 1.9829
16/16 [==============================] - 0s 2ms/step - loss: 1.9815

Testing for epoch 31 index 2:
79/79 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1301
16/16 [==============================] - 0s 2ms/step - loss: 1.6529
16/16 [==============================] - 0s 1ms/step - loss: 1.9912
16/16 [==============================] - 0s 3ms/step - loss: 2.0713
16/16 [==============================] - 0s 1ms/step - loss: 2.0974
16/16 [==============================] - 0s 3ms/step - loss: 2.0753
16/16 [==============================] - 0s 3ms/step - loss: 2.0448
16/16 [==============================] - 0s 2ms/step - loss: 2.0307
16/16 [==============================] - 0s 2ms/step - loss: 2.0234
16/16 [==============================] - 0s 1ms/step - loss: 2.0219

Testing for epoch 31 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1281
16/16 [==============================] - 0s 4ms/step - loss: 1.6509
16/16 [==============================] - 0s 3ms/step - loss: 1.9920
16/16 [==============================] - 0s 1ms/step - loss: 2.0752
16/16 [==============================] - 0s 2ms/step - loss: 2.1047
16/16 [==============================] - 0s 1ms/step - loss: 2.0851
16/16 [==============================] - 0s 2ms/step - loss: 2.0553
16/16 [==============================] - 0s 1ms/step - loss: 2.0412
16/16 [==============================] - 0s 2ms/step - loss: 2.0339
16/16 [==============================] - 0s 2ms/step - loss: 2.0323

Testing for epoch 31 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1286
16/16 [==============================] - 0s 3ms/step - loss: 1.6262
16/16 [==============================] - 0s 3ms/step - loss: 1.9585
16/16 [==============================] - 0s 2ms/step - loss: 2.0358
16/16 [==============================] - 0s 5ms/step - loss: 2.0611
16/16 [==============================] - 0s 3ms/step - loss: 2.0403
16/16 [==============================] - 0s 2ms/step - loss: 2.0121
16/16 [==============================] - 0s 2ms/step - loss: 1.9990
16/16 [==============================] - 0s 1ms/step - loss: 1.9924
16/16 [==============================] - 0s 2ms/step - loss: 1.9911

Testing for epoch 31 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1308
16/16 [==============================] - 0s 2ms/step - loss: 1.5804
16/16 [==============================] - 0s 3ms/step - loss: 1.9013
16/16 [==============================] - 0s 5ms/step - loss: 1.9765
16/16 [==============================] - 0s 3ms/step - loss: 2.0018
16/16 [==============================] - 0s 3ms/step - loss: 1.9825
16/16 [==============================] - 0s 3ms/step - loss: 1.9541
16/16 [==============================] - 0s 4ms/step - loss: 1.9412
16/16 [==============================] - 0s 3ms/step - loss: 1.9346
16/16 [==============================] - 0s 3ms/step - loss: 1.9333
Epoch 32 of 60

Testing for epoch 32 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1304
16/16 [==============================] - 0s 2ms/step - loss: 1.6039
16/16 [==============================] - 0s 2ms/step - loss: 1.9289
16/16 [==============================] - 0s 5ms/step - loss: 2.0049
16/16 [==============================] - 0s 3ms/step - loss: 2.0289
16/16 [==============================] - 0s 2ms/step - loss: 2.0085
16/16 [==============================] - 0s 1ms/step - loss: 1.9780
16/16 [==============================] - 0s 3ms/step - loss: 1.9645
16/16 [==============================] - 0s 4ms/step - loss: 1.9577
16/16 [==============================] - 0s 3ms/step - loss: 1.9562

Testing for epoch 32 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1308
16/16 [==============================] - 0s 2ms/step - loss: 1.6057
16/16 [==============================] - 0s 4ms/step - loss: 1.9294
16/16 [==============================] - 0s 2ms/step - loss: 2.0058
16/16 [==============================] - 0s 3ms/step - loss: 2.0312
16/16 [==============================] - 0s 1ms/step - loss: 2.0111
16/16 [==============================] - 0s 2ms/step - loss: 1.9812
16/16 [==============================] - 0s 3ms/step - loss: 1.9676
16/16 [==============================] - 0s 2ms/step - loss: 1.9607
16/16 [==============================] - 0s 4ms/step - loss: 1.9593

Testing for epoch 32 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1270
16/16 [==============================] - 0s 2ms/step - loss: 1.6557
16/16 [==============================] - 0s 3ms/step - loss: 1.9883
16/16 [==============================] - 0s 4ms/step - loss: 2.0666
16/16 [==============================] - 0s 2ms/step - loss: 2.0939
16/16 [==============================] - 0s 3ms/step - loss: 2.0729
16/16 [==============================] - 0s 2ms/step - loss: 2.0417
16/16 [==============================] - 0s 2ms/step - loss: 2.0278
16/16 [==============================] - 0s 2ms/step - loss: 2.0208
16/16 [==============================] - 0s 2ms/step - loss: 2.0194

Testing for epoch 32 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1297
16/16 [==============================] - 0s 2ms/step - loss: 1.6287
16/16 [==============================] - 0s 2ms/step - loss: 1.9639
16/16 [==============================] - 0s 1ms/step - loss: 2.0434
16/16 [==============================] - 0s 2ms/step - loss: 2.0697
16/16 [==============================] - 0s 1ms/step - loss: 2.0478
16/16 [==============================] - 0s 2ms/step - loss: 2.0168
16/16 [==============================] - 0s 2ms/step - loss: 2.0029
16/16 [==============================] - 0s 2ms/step - loss: 1.9960
16/16 [==============================] - 0s 4ms/step - loss: 1.9946

Testing for epoch 32 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1284
16/16 [==============================] - 0s 5ms/step - loss: 1.6422
16/16 [==============================] - 0s 2ms/step - loss: 1.9750
16/16 [==============================] - 0s 2ms/step - loss: 2.0515
16/16 [==============================] - 0s 1ms/step - loss: 2.0770
16/16 [==============================] - 0s 2ms/step - loss: 2.0537
16/16 [==============================] - 0s 5ms/step - loss: 2.0217
16/16 [==============================] - 0s 2ms/step - loss: 2.0076
16/16 [==============================] - 0s 1ms/step - loss: 2.0006
16/16 [==============================] - 0s 3ms/step - loss: 1.9992
Epoch 33 of 60

Testing for epoch 33 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1290
16/16 [==============================] - 0s 2ms/step - loss: 1.6671
16/16 [==============================] - 0s 2ms/step - loss: 2.0069
16/16 [==============================] - 0s 3ms/step - loss: 2.0852
16/16 [==============================] - 0s 4ms/step - loss: 2.1102
16/16 [==============================] - 0s 2ms/step - loss: 2.0861
16/16 [==============================] - 0s 2ms/step - loss: 2.0514
16/16 [==============================] - 0s 1ms/step - loss: 2.0362
16/16 [==============================] - 0s 3ms/step - loss: 2.0288
16/16 [==============================] - 0s 4ms/step - loss: 2.0274

Testing for epoch 33 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1231
16/16 [==============================] - 0s 1ms/step - loss: 1.6641
16/16 [==============================] - 0s 2ms/step - loss: 1.9991
16/16 [==============================] - 0s 2ms/step - loss: 2.0762
16/16 [==============================] - 0s 2ms/step - loss: 2.0993
16/16 [==============================] - 0s 5ms/step - loss: 2.0744
16/16 [==============================] - 0s 2ms/step - loss: 2.0399
16/16 [==============================] - 0s 2ms/step - loss: 2.0250
16/16 [==============================] - 0s 2ms/step - loss: 2.0177
16/16 [==============================] - 0s 5ms/step - loss: 2.0162

Testing for epoch 33 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1242
16/16 [==============================] - 0s 1ms/step - loss: 1.6962
16/16 [==============================] - 0s 2ms/step - loss: 2.0373
16/16 [==============================] - 0s 5ms/step - loss: 2.1154
16/16 [==============================] - 0s 2ms/step - loss: 2.1379
16/16 [==============================] - 0s 3ms/step - loss: 2.1114
16/16 [==============================] - 0s 1ms/step - loss: 2.0752
16/16 [==============================] - 0s 2ms/step - loss: 2.0597
16/16 [==============================] - 0s 1ms/step - loss: 2.0520
16/16 [==============================] - 0s 2ms/step - loss: 2.0504

Testing for epoch 33 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1238
16/16 [==============================] - 0s 2ms/step - loss: 1.7007
16/16 [==============================] - 0s 990us/step - loss: 2.0434
16/16 [==============================] - 0s 3ms/step - loss: 2.1200
16/16 [==============================] - 0s 3ms/step - loss: 2.1398
16/16 [==============================] - 0s 2ms/step - loss: 2.1118
16/16 [==============================] - 0s 1ms/step - loss: 2.0744
16/16 [==============================] - 0s 2ms/step - loss: 2.0586
16/16 [==============================] - 0s 2ms/step - loss: 2.0510
16/16 [==============================] - 0s 2ms/step - loss: 2.0495

Testing for epoch 33 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1219
16/16 [==============================] - 0s 4ms/step - loss: 1.6472
16/16 [==============================] - 0s 2ms/step - loss: 1.9775
16/16 [==============================] - 0s 2ms/step - loss: 2.0515
16/16 [==============================] - 0s 1ms/step - loss: 2.0726
16/16 [==============================] - 0s 2ms/step - loss: 2.0488
16/16 [==============================] - 0s 1ms/step - loss: 2.0161
16/16 [==============================] - 0s 2ms/step - loss: 2.0019
16/16 [==============================] - 0s 1ms/step - loss: 1.9951
16/16 [==============================] - 0s 3ms/step - loss: 1.9937
Epoch 34 of 60

Testing for epoch 34 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1203
16/16 [==============================] - 0s 2ms/step - loss: 1.6294
16/16 [==============================] - 0s 5ms/step - loss: 1.9523
16/16 [==============================] - 0s 3ms/step - loss: 2.0237
16/16 [==============================] - 0s 2ms/step - loss: 2.0446
16/16 [==============================] - 0s 1ms/step - loss: 2.0211
16/16 [==============================] - 0s 2ms/step - loss: 1.9883
16/16 [==============================] - 0s 2ms/step - loss: 1.9743
16/16 [==============================] - 0s 2ms/step - loss: 1.9675
16/16 [==============================] - 0s 2ms/step - loss: 1.9662

Testing for epoch 34 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.1275
16/16 [==============================] - 0s 2ms/step - loss: 1.6269
16/16 [==============================] - 0s 3ms/step - loss: 1.9469
16/16 [==============================] - 0s 5ms/step - loss: 2.0152
16/16 [==============================] - 0s 2ms/step - loss: 2.0335
16/16 [==============================] - 0s 2ms/step - loss: 2.0079
16/16 [==============================] - 0s 2ms/step - loss: 1.9738
16/16 [==============================] - 0s 2ms/step - loss: 1.9595
16/16 [==============================] - 0s 5ms/step - loss: 1.9525
16/16 [==============================] - 0s 2ms/step - loss: 1.9511

Testing for epoch 34 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 730us/step - loss: 0.1189
16/16 [==============================] - 0s 864us/step - loss: 1.7223
16/16 [==============================] - 0s 825us/step - loss: 2.0704
16/16 [==============================] - 0s 924us/step - loss: 2.1444
16/16 [==============================] - 0s 1ms/step - loss: 2.1615
16/16 [==============================] - 0s 964us/step - loss: 2.1318
16/16 [==============================] - 0s 874us/step - loss: 2.0925
16/16 [==============================] - 0s 2ms/step - loss: 2.0761
16/16 [==============================] - 0s 2ms/step - loss: 2.0682
16/16 [==============================] - 0s 2ms/step - loss: 2.0666

Testing for epoch 34 index 4:
79/79 [==============================] - 0s 916us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1241
16/16 [==============================] - 0s 716us/step - loss: 1.6562
16/16 [==============================] - 0s 2ms/step - loss: 1.9886
16/16 [==============================] - 0s 723us/step - loss: 2.0595
16/16 [==============================] - 0s 892us/step - loss: 2.0769
16/16 [==============================] - 0s 2ms/step - loss: 2.0506
16/16 [==============================] - 0s 820us/step - loss: 2.0150
16/16 [==============================] - 0s 794us/step - loss: 2.0003
16/16 [==============================] - 0s 801us/step - loss: 1.9932
16/16 [==============================] - 0s 667us/step - loss: 1.9918

Testing for epoch 34 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 816us/step - loss: 0.1206
16/16 [==============================] - 0s 848us/step - loss: 1.6710
16/16 [==============================] - 0s 823us/step - loss: 2.0076
16/16 [==============================] - 0s 818us/step - loss: 2.0774
16/16 [==============================] - 0s 823us/step - loss: 2.0942
16/16 [==============================] - 0s 787us/step - loss: 2.0662
16/16 [==============================] - 0s 1ms/step - loss: 2.0296
16/16 [==============================] - 0s 834us/step - loss: 2.0145
16/16 [==============================] - 0s 2ms/step - loss: 2.0073
16/16 [==============================] - 0s 971us/step - loss: 2.0059
Epoch 35 of 60

Testing for epoch 35 index 1:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1222
16/16 [==============================] - 0s 791us/step - loss: 1.6736
16/16 [==============================] - 0s 780us/step - loss: 2.0161
16/16 [==============================] - 0s 834us/step - loss: 2.0865
16/16 [==============================] - 0s 780us/step - loss: 2.1034
16/16 [==============================] - 0s 805us/step - loss: 2.0761
16/16 [==============================] - 0s 782us/step - loss: 2.0399
16/16 [==============================] - 0s 781us/step - loss: 2.0249
16/16 [==============================] - 0s 868us/step - loss: 2.0178
16/16 [==============================] - 0s 1ms/step - loss: 2.0164

Testing for epoch 35 index 2:
79/79 [==============================] - 0s 785us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1240
16/16 [==============================] - 0s 789us/step - loss: 1.6424
16/16 [==============================] - 0s 775us/step - loss: 1.9733
16/16 [==============================] - 0s 779us/step - loss: 2.0378
16/16 [==============================] - 0s 792us/step - loss: 2.0535
16/16 [==============================] - 0s 795us/step - loss: 2.0264
16/16 [==============================] - 0s 797us/step - loss: 1.9912
16/16 [==============================] - 0s 1ms/step - loss: 1.9770
16/16 [==============================] - 0s 1ms/step - loss: 1.9702
16/16 [==============================] - 0s 773us/step - loss: 1.9689

Testing for epoch 35 index 3:
79/79 [==============================] - 0s 594us/step
16/16 [==============================] - 0s 868us/step - loss: 0.1195
16/16 [==============================] - 0s 796us/step - loss: 1.7210
16/16 [==============================] - 0s 1ms/step - loss: 2.0745
16/16 [==============================] - 0s 841us/step - loss: 2.1411
16/16 [==============================] - 0s 829us/step - loss: 2.1550
16/16 [==============================] - 0s 819us/step - loss: 2.1230
16/16 [==============================] - 0s 810us/step - loss: 2.0831
16/16 [==============================] - 0s 774us/step - loss: 2.0667
16/16 [==============================] - 0s 790us/step - loss: 2.0590
16/16 [==============================] - 0s 784us/step - loss: 2.0575

Testing for epoch 35 index 4:
79/79 [==============================] - 0s 687us/step
16/16 [==============================] - 0s 832us/step - loss: 0.1199
16/16 [==============================] - 0s 804us/step - loss: 1.6854
16/16 [==============================] - 0s 823us/step - loss: 2.0344
16/16 [==============================] - 0s 788us/step - loss: 2.1017
16/16 [==============================] - 0s 794us/step - loss: 2.1175
16/16 [==============================] - 0s 784us/step - loss: 2.0892
16/16 [==============================] - 0s 789us/step - loss: 2.0529
16/16 [==============================] - 0s 784us/step - loss: 2.0378
16/16 [==============================] - 0s 816us/step - loss: 2.0307
16/16 [==============================] - 0s 825us/step - loss: 2.0293

Testing for epoch 35 index 5:
79/79 [==============================] - 0s 689us/step
16/16 [==============================] - 0s 895us/step - loss: 0.1220
16/16 [==============================] - 0s 893us/step - loss: 1.7423
16/16 [==============================] - 0s 901us/step - loss: 2.1090
16/16 [==============================] - 0s 808us/step - loss: 2.1781
16/16 [==============================] - 0s 881us/step - loss: 2.1922
16/16 [==============================] - 0s 862us/step - loss: 2.1604
16/16 [==============================] - 0s 877us/step - loss: 2.1200
16/16 [==============================] - 0s 871us/step - loss: 2.1033
16/16 [==============================] - 0s 822us/step - loss: 2.0954
16/16 [==============================] - 0s 873us/step - loss: 2.0939
Epoch 36 of 60

Testing for epoch 36 index 1:
79/79 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1162
16/16 [==============================] - 0s 1ms/step - loss: 1.7248
16/16 [==============================] - 0s 786us/step - loss: 2.0856
16/16 [==============================] - 0s 799us/step - loss: 2.1535
16/16 [==============================] - 0s 785us/step - loss: 2.1675
16/16 [==============================] - 0s 799us/step - loss: 2.1374
16/16 [==============================] - 0s 811us/step - loss: 2.0985
16/16 [==============================] - 0s 787us/step - loss: 2.0821
16/16 [==============================] - 0s 800us/step - loss: 2.0743
16/16 [==============================] - 0s 793us/step - loss: 2.0728

Testing for epoch 36 index 2:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1175
16/16 [==============================] - 0s 799us/step - loss: 1.7178
16/16 [==============================] - 0s 782us/step - loss: 2.0756
16/16 [==============================] - 0s 862us/step - loss: 2.1438
16/16 [==============================] - 0s 938us/step - loss: 2.1563
16/16 [==============================] - 0s 881us/step - loss: 2.1234
16/16 [==============================] - 0s 806us/step - loss: 2.0830
16/16 [==============================] - 0s 797us/step - loss: 2.0663
16/16 [==============================] - 0s 797us/step - loss: 2.0586
16/16 [==============================] - 0s 825us/step - loss: 2.0571

Testing for epoch 36 index 3:
79/79 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1194
16/16 [==============================] - 0s 846us/step - loss: 1.7307
16/16 [==============================] - 0s 811us/step - loss: 2.0893
16/16 [==============================] - 0s 796us/step - loss: 2.1578
16/16 [==============================] - 0s 823us/step - loss: 2.1703
16/16 [==============================] - 0s 791us/step - loss: 2.1378
16/16 [==============================] - 0s 800us/step - loss: 2.0980
16/16 [==============================] - 0s 806us/step - loss: 2.0815
16/16 [==============================] - 0s 837us/step - loss: 2.0738
16/16 [==============================] - 0s 865us/step - loss: 2.0723

Testing for epoch 36 index 4:
79/79 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 826us/step - loss: 0.1160
16/16 [==============================] - 0s 850us/step - loss: 1.7513
16/16 [==============================] - 0s 819us/step - loss: 2.1164
16/16 [==============================] - 0s 845us/step - loss: 2.1846
16/16 [==============================] - 0s 804us/step - loss: 2.1957
16/16 [==============================] - 0s 831us/step - loss: 2.1603
16/16 [==============================] - 0s 814us/step - loss: 2.1182
16/16 [==============================] - 0s 801us/step - loss: 2.1009
16/16 [==============================] - 0s 843us/step - loss: 2.0928
16/16 [==============================] - 0s 789us/step - loss: 2.0912

Testing for epoch 36 index 5:
79/79 [==============================] - 0s 618us/step
16/16 [==============================] - 0s 832us/step - loss: 0.1140
16/16 [==============================] - 0s 796us/step - loss: 1.7489
16/16 [==============================] - 0s 850us/step - loss: 2.1106
16/16 [==============================] - 0s 839us/step - loss: 2.1741
16/16 [==============================] - 0s 1ms/step - loss: 2.1808
16/16 [==============================] - 0s 843us/step - loss: 2.1423
16/16 [==============================] - 0s 820us/step - loss: 2.0993
16/16 [==============================] - 0s 841us/step - loss: 2.0821
16/16 [==============================] - 0s 1ms/step - loss: 2.0741
16/16 [==============================] - 0s 1ms/step - loss: 2.0725
Epoch 37 of 60

Testing for epoch 37 index 1:
79/79 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1171
16/16 [==============================] - 0s 801us/step - loss: 1.7179
16/16 [==============================] - 0s 789us/step - loss: 2.0789
16/16 [==============================] - 0s 785us/step - loss: 2.1479
16/16 [==============================] - 0s 785us/step - loss: 2.1616
16/16 [==============================] - 0s 793us/step - loss: 2.1303
16/16 [==============================] - 0s 817us/step - loss: 2.0917
16/16 [==============================] - 0s 808us/step - loss: 2.0757
16/16 [==============================] - 0s 782us/step - loss: 2.0682
16/16 [==============================] - 0s 819us/step - loss: 2.0667

Testing for epoch 37 index 2:
79/79 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1152
16/16 [==============================] - 0s 802us/step - loss: 1.7662
16/16 [==============================] - 0s 777us/step - loss: 2.1333
16/16 [==============================] - 0s 794us/step - loss: 2.2005
16/16 [==============================] - 0s 790us/step - loss: 2.2101
16/16 [==============================] - 0s 794us/step - loss: 2.1746
16/16 [==============================] - 0s 781us/step - loss: 2.1333
16/16 [==============================] - 0s 785us/step - loss: 2.1165
16/16 [==============================] - 0s 817us/step - loss: 2.1088
16/16 [==============================] - 0s 825us/step - loss: 2.1073

Testing for epoch 37 index 3:
79/79 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1121
16/16 [==============================] - 0s 1ms/step - loss: 1.8196
16/16 [==============================] - 0s 782us/step - loss: 2.2011
16/16 [==============================] - 0s 1ms/step - loss: 2.2731
16/16 [==============================] - 0s 1ms/step - loss: 2.2834
16/16 [==============================] - 0s 1ms/step - loss: 2.2449
16/16 [==============================] - 0s 1ms/step - loss: 2.2013
16/16 [==============================] - 0s 778us/step - loss: 2.1835
16/16 [==============================] - 0s 799us/step - loss: 2.1751
16/16 [==============================] - 0s 827us/step - loss: 2.1734

Testing for epoch 37 index 4:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1157
16/16 [==============================] - 0s 844us/step - loss: 1.7313
16/16 [==============================] - 0s 806us/step - loss: 2.0871
16/16 [==============================] - 0s 805us/step - loss: 2.1535
16/16 [==============================] - 0s 822us/step - loss: 2.1619
16/16 [==============================] - 0s 812us/step - loss: 2.1268
16/16 [==============================] - 0s 814us/step - loss: 2.0847
16/16 [==============================] - 0s 793us/step - loss: 2.0678
16/16 [==============================] - 0s 835us/step - loss: 2.0601
16/16 [==============================] - 0s 790us/step - loss: 2.0586

Testing for epoch 37 index 5:
79/79 [==============================] - 0s 668us/step
16/16 [==============================] - 0s 789us/step - loss: 0.1167
16/16 [==============================] - 0s 801us/step - loss: 1.7508
16/16 [==============================] - 0s 808us/step - loss: 2.1167
16/16 [==============================] - 0s 783us/step - loss: 2.1851
16/16 [==============================] - 0s 779us/step - loss: 2.1928
16/16 [==============================] - 0s 795us/step - loss: 2.1561
16/16 [==============================] - 0s 802us/step - loss: 2.1142
16/16 [==============================] - 0s 1ms/step - loss: 2.0974
16/16 [==============================] - 0s 1ms/step - loss: 2.0896
16/16 [==============================] - 0s 1ms/step - loss: 2.0881
Epoch 38 of 60

Testing for epoch 38 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1109
16/16 [==============================] - 0s 819us/step - loss: 1.7595
16/16 [==============================] - 0s 1ms/step - loss: 2.1283
16/16 [==============================] - 0s 776us/step - loss: 2.1993
16/16 [==============================] - 0s 1ms/step - loss: 2.2081
16/16 [==============================] - 0s 1ms/step - loss: 2.1730
16/16 [==============================] - 0s 816us/step - loss: 2.1321
16/16 [==============================] - 0s 782us/step - loss: 2.1153
16/16 [==============================] - 0s 1ms/step - loss: 2.1076
16/16 [==============================] - 0s 1ms/step - loss: 2.1061

Testing for epoch 38 index 2:
79/79 [==============================] - 0s 832us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1127
16/16 [==============================] - 0s 1ms/step - loss: 1.7701
16/16 [==============================] - 0s 1ms/step - loss: 2.1418
16/16 [==============================] - 0s 1ms/step - loss: 2.2119
16/16 [==============================] - 0s 1ms/step - loss: 2.2207
16/16 [==============================] - 0s 819us/step - loss: 2.1862
16/16 [==============================] - 0s 810us/step - loss: 2.1437
16/16 [==============================] - 0s 1ms/step - loss: 2.1267
16/16 [==============================] - 0s 1ms/step - loss: 2.1191
16/16 [==============================] - 0s 1ms/step - loss: 2.1176

Testing for epoch 38 index 3:
79/79 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1122
16/16 [==============================] - 0s 827us/step - loss: 1.8247
16/16 [==============================] - 0s 796us/step - loss: 2.1973
16/16 [==============================] - 0s 802us/step - loss: 2.2641
16/16 [==============================] - 0s 798us/step - loss: 2.2681
16/16 [==============================] - 0s 797us/step - loss: 2.2248
16/16 [==============================] - 0s 823us/step - loss: 2.1768
16/16 [==============================] - 0s 788us/step - loss: 2.1579
16/16 [==============================] - 0s 792us/step - loss: 2.1495
16/16 [==============================] - 0s 818us/step - loss: 2.1479

Testing for epoch 38 index 4:
79/79 [==============================] - 0s 678us/step
16/16 [==============================] - 0s 827us/step - loss: 0.1146
16/16 [==============================] - 0s 847us/step - loss: 1.7631
16/16 [==============================] - 0s 809us/step - loss: 2.1241
16/16 [==============================] - 0s 793us/step - loss: 2.1922
16/16 [==============================] - 0s 796us/step - loss: 2.1991
16/16 [==============================] - 0s 1ms/step - loss: 2.1634
16/16 [==============================] - 0s 1ms/step - loss: 2.1214
16/16 [==============================] - 0s 1ms/step - loss: 2.1048
16/16 [==============================] - 0s 1ms/step - loss: 2.0973
16/16 [==============================] - 0s 1ms/step - loss: 2.0959

Testing for epoch 38 index 5:
79/79 [==============================] - 0s 799us/step
16/16 [==============================] - 0s 899us/step - loss: 0.1116
16/16 [==============================] - 0s 897us/step - loss: 1.7540
16/16 [==============================] - 0s 901us/step - loss: 2.1101
16/16 [==============================] - 0s 902us/step - loss: 2.1768
16/16 [==============================] - 0s 897us/step - loss: 2.1830
16/16 [==============================] - 0s 876us/step - loss: 2.1442
16/16 [==============================] - 0s 1ms/step - loss: 2.0999
16/16 [==============================] - 0s 1ms/step - loss: 2.0824
16/16 [==============================] - 0s 1ms/step - loss: 2.0745
16/16 [==============================] - 0s 860us/step - loss: 2.0729
Epoch 39 of 60

Testing for epoch 39 index 1:
79/79 [==============================] - 0s 699us/step
16/16 [==============================] - 0s 930us/step - loss: 0.1090
16/16 [==============================] - 0s 907us/step - loss: 1.7778
16/16 [==============================] - 0s 930us/step - loss: 2.1277
16/16 [==============================] - 0s 905us/step - loss: 2.1890
16/16 [==============================] - 0s 911us/step - loss: 2.1898
16/16 [==============================] - 0s 928us/step - loss: 2.1447
16/16 [==============================] - 0s 896us/step - loss: 2.0964
16/16 [==============================] - 0s 894us/step - loss: 2.0778
16/16 [==============================] - 0s 896us/step - loss: 2.0695
16/16 [==============================] - 0s 877us/step - loss: 2.0679

Testing for epoch 39 index 2:
79/79 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 857us/step - loss: 0.1075
16/16 [==============================] - 0s 879us/step - loss: 1.8452
16/16 [==============================] - 0s 845us/step - loss: 2.2109
16/16 [==============================] - 0s 825us/step - loss: 2.2799
16/16 [==============================] - 0s 1ms/step - loss: 2.2856
16/16 [==============================] - 0s 1ms/step - loss: 2.2448
16/16 [==============================] - 0s 1ms/step - loss: 2.1990
16/16 [==============================] - 0s 1ms/step - loss: 2.1807
16/16 [==============================] - 0s 893us/step - loss: 2.1724
16/16 [==============================] - 0s 814us/step - loss: 2.1707

Testing for epoch 39 index 3:
79/79 [==============================] - 0s 800us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1145
16/16 [==============================] - 0s 1ms/step - loss: 1.7575
16/16 [==============================] - 0s 1ms/step - loss: 2.0971
16/16 [==============================] - 0s 1ms/step - loss: 2.1605
16/16 [==============================] - 0s 885us/step - loss: 2.1647
16/16 [==============================] - 0s 1ms/step - loss: 2.1274
16/16 [==============================] - 0s 1ms/step - loss: 2.0856
16/16 [==============================] - 0s 911us/step - loss: 2.0692
16/16 [==============================] - 0s 898us/step - loss: 2.0619
16/16 [==============================] - 0s 949us/step - loss: 2.0605

Testing for epoch 39 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 832us/step - loss: 0.1122
16/16 [==============================] - 0s 832us/step - loss: 1.8212
16/16 [==============================] - 0s 844us/step - loss: 2.1717
16/16 [==============================] - 0s 820us/step - loss: 2.2333
16/16 [==============================] - 0s 849us/step - loss: 2.2347
16/16 [==============================] - 0s 816us/step - loss: 2.1920
16/16 [==============================] - 0s 802us/step - loss: 2.1447
16/16 [==============================] - 0s 779us/step - loss: 2.1265
16/16 [==============================] - 0s 812us/step - loss: 2.1183
16/16 [==============================] - 0s 810us/step - loss: 2.1167

Testing for epoch 39 index 5:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 781us/step - loss: 0.1091
16/16 [==============================] - 0s 1ms/step - loss: 1.8458
16/16 [==============================] - 0s 782us/step - loss: 2.2025
16/16 [==============================] - 0s 829us/step - loss: 2.2659
16/16 [==============================] - 0s 932us/step - loss: 2.2668
16/16 [==============================] - 0s 848us/step - loss: 2.2216
16/16 [==============================] - 0s 796us/step - loss: 2.1730
16/16 [==============================] - 0s 780us/step - loss: 2.1544
16/16 [==============================] - 0s 809us/step - loss: 2.1462
16/16 [==============================] - 0s 1ms/step - loss: 2.1446
Epoch 40 of 60

Testing for epoch 40 index 1:
79/79 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1066
16/16 [==============================] - 0s 810us/step - loss: 1.8574
16/16 [==============================] - 0s 779us/step - loss: 2.2169
16/16 [==============================] - 0s 874us/step - loss: 2.2805
16/16 [==============================] - 0s 853us/step - loss: 2.2825
16/16 [==============================] - 0s 1ms/step - loss: 2.2379
16/16 [==============================] - 0s 897us/step - loss: 2.1889
16/16 [==============================] - 0s 858us/step - loss: 2.1701
16/16 [==============================] - 0s 882us/step - loss: 2.1618
16/16 [==============================] - 0s 862us/step - loss: 2.1602

Testing for epoch 40 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1070
16/16 [==============================] - 0s 2ms/step - loss: 1.8320
16/16 [==============================] - 0s 1ms/step - loss: 2.1920
16/16 [==============================] - 0s 5ms/step - loss: 2.2574
16/16 [==============================] - 0s 7ms/step - loss: 2.2615
16/16 [==============================] - 0s 5ms/step - loss: 2.2199
16/16 [==============================] - 0s 2ms/step - loss: 2.1736
16/16 [==============================] - 0s 2ms/step - loss: 2.1552
16/16 [==============================] - 0s 1ms/step - loss: 2.1471
16/16 [==============================] - 0s 1ms/step - loss: 2.1455

Testing for epoch 40 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1088
16/16 [==============================] - 0s 1ms/step - loss: 1.8057
16/16 [==============================] - 0s 3ms/step - loss: 2.1619
16/16 [==============================] - 0s 3ms/step - loss: 2.2233
16/16 [==============================] - 0s 3ms/step - loss: 2.2255
16/16 [==============================] - 0s 2ms/step - loss: 2.1841
16/16 [==============================] - 0s 3ms/step - loss: 2.1390
16/16 [==============================] - 0s 2ms/step - loss: 2.1218
16/16 [==============================] - 0s 1ms/step - loss: 2.1142
16/16 [==============================] - 0s 2ms/step - loss: 2.1128

Testing for epoch 40 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1092
16/16 [==============================] - 0s 5ms/step - loss: 1.7906
16/16 [==============================] - 0s 2ms/step - loss: 2.1394
16/16 [==============================] - 0s 7ms/step - loss: 2.1967
16/16 [==============================] - 0s 6ms/step - loss: 2.1977
16/16 [==============================] - 0s 3ms/step - loss: 2.1566
16/16 [==============================] - 0s 2ms/step - loss: 2.1100
16/16 [==============================] - 0s 4ms/step - loss: 2.0923
16/16 [==============================] - 0s 2ms/step - loss: 2.0846
16/16 [==============================] - 0s 7ms/step - loss: 2.0832

Testing for epoch 40 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1079
16/16 [==============================] - 0s 4ms/step - loss: 1.8167
16/16 [==============================] - 0s 1ms/step - loss: 2.1744
16/16 [==============================] - 0s 1ms/step - loss: 2.2326
16/16 [==============================] - 0s 5ms/step - loss: 2.2331
16/16 [==============================] - 0s 5ms/step - loss: 2.1902
16/16 [==============================] - 0s 2ms/step - loss: 2.1440
16/16 [==============================] - 0s 3ms/step - loss: 2.1264
16/16 [==============================] - 0s 2ms/step - loss: 2.1188
16/16 [==============================] - 0s 4ms/step - loss: 2.1174
Epoch 41 of 60

Testing for epoch 41 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 9ms/step - loss: 0.1043
16/16 [==============================] - 0s 1ms/step - loss: 1.8739
16/16 [==============================] - 0s 3ms/step - loss: 2.2448
16/16 [==============================] - 0s 7ms/step - loss: 2.3052
16/16 [==============================] - 0s 4ms/step - loss: 2.3051
16/16 [==============================] - 0s 2ms/step - loss: 2.2600
16/16 [==============================] - 0s 2ms/step - loss: 2.2093
16/16 [==============================] - 0s 2ms/step - loss: 2.1900
16/16 [==============================] - 0s 2ms/step - loss: 2.1816
16/16 [==============================] - 0s 2ms/step - loss: 2.1800

Testing for epoch 41 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1113
16/16 [==============================] - 0s 2ms/step - loss: 1.8695
16/16 [==============================] - 0s 4ms/step - loss: 2.2364
16/16 [==============================] - 0s 2ms/step - loss: 2.2950
16/16 [==============================] - 0s 3ms/step - loss: 2.2926
16/16 [==============================] - 0s 1ms/step - loss: 2.2449
16/16 [==============================] - 0s 3ms/step - loss: 2.1935
16/16 [==============================] - 0s 5ms/step - loss: 2.1740
16/16 [==============================] - 0s 3ms/step - loss: 2.1657
16/16 [==============================] - 0s 5ms/step - loss: 2.1641

Testing for epoch 41 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1082
16/16 [==============================] - 0s 2ms/step - loss: 1.7951
16/16 [==============================] - 0s 2ms/step - loss: 2.1454
16/16 [==============================] - 0s 2ms/step - loss: 2.2035
16/16 [==============================] - 0s 2ms/step - loss: 2.2039
16/16 [==============================] - 0s 1ms/step - loss: 2.1643
16/16 [==============================] - 0s 2ms/step - loss: 2.1198
16/16 [==============================] - 0s 6ms/step - loss: 2.1025
16/16 [==============================] - 0s 3ms/step - loss: 2.0948
16/16 [==============================] - 0s 2ms/step - loss: 2.0933

Testing for epoch 41 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1060
16/16 [==============================] - 0s 5ms/step - loss: 1.8358
16/16 [==============================] - 0s 3ms/step - loss: 2.1926
16/16 [==============================] - 0s 1ms/step - loss: 2.2530
16/16 [==============================] - 0s 2ms/step - loss: 2.2543
16/16 [==============================] - 0s 4ms/step - loss: 2.2128
16/16 [==============================] - 0s 7ms/step - loss: 2.1656
16/16 [==============================] - 0s 3ms/step - loss: 2.1477
16/16 [==============================] - 0s 5ms/step - loss: 2.1398
16/16 [==============================] - 0s 5ms/step - loss: 2.1383

Testing for epoch 41 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1057
16/16 [==============================] - 0s 1ms/step - loss: 1.8683
16/16 [==============================] - 0s 3ms/step - loss: 2.2282
16/16 [==============================] - 0s 3ms/step - loss: 2.2842
16/16 [==============================] - 0s 2ms/step - loss: 2.2801
16/16 [==============================] - 0s 3ms/step - loss: 2.2306
16/16 [==============================] - 0s 2ms/step - loss: 2.1778
16/16 [==============================] - 0s 1ms/step - loss: 2.1580
16/16 [==============================] - 0s 2ms/step - loss: 2.1493
16/16 [==============================] - 0s 4ms/step - loss: 2.1476
Epoch 42 of 60

Testing for epoch 42 index 1:
79/79 [==============================] - 0s 955us/step
16/16 [==============================] - 0s 823us/step - loss: 0.1064
16/16 [==============================] - 0s 823us/step - loss: 1.8454
16/16 [==============================] - 0s 846us/step - loss: 2.2010
16/16 [==============================] - 0s 839us/step - loss: 2.2554
16/16 [==============================] - 0s 867us/step - loss: 2.2502
16/16 [==============================] - 0s 859us/step - loss: 2.2011
16/16 [==============================] - 0s 856us/step - loss: 2.1487
16/16 [==============================] - 0s 832us/step - loss: 2.1291
16/16 [==============================] - 0s 830us/step - loss: 2.1207
16/16 [==============================] - 0s 833us/step - loss: 2.1190

Testing for epoch 42 index 2:
79/79 [==============================] - 0s 726us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1050
16/16 [==============================] - 0s 832us/step - loss: 1.9043
16/16 [==============================] - 0s 829us/step - loss: 2.2777
16/16 [==============================] - 0s 836us/step - loss: 2.3367
16/16 [==============================] - 0s 854us/step - loss: 2.3319
16/16 [==============================] - 0s 836us/step - loss: 2.2817
16/16 [==============================] - 0s 829us/step - loss: 2.2269
16/16 [==============================] - 0s 818us/step - loss: 2.2062
16/16 [==============================] - 0s 824us/step - loss: 2.1972
16/16 [==============================] - 0s 813us/step - loss: 2.1954

Testing for epoch 42 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1069
16/16 [==============================] - 0s 2ms/step - loss: 1.8916
16/16 [==============================] - 0s 2ms/step - loss: 2.2629
16/16 [==============================] - 0s 3ms/step - loss: 2.3229
16/16 [==============================] - 0s 2ms/step - loss: 2.3214
16/16 [==============================] - 0s 2ms/step - loss: 2.2760
16/16 [==============================] - 0s 2ms/step - loss: 2.2246
16/16 [==============================] - 0s 2ms/step - loss: 2.2051
16/16 [==============================] - 0s 2ms/step - loss: 2.1966
16/16 [==============================] - 0s 4ms/step - loss: 2.1950

Testing for epoch 42 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1038
16/16 [==============================] - 0s 2ms/step - loss: 1.8663
16/16 [==============================] - 0s 2ms/step - loss: 2.2235
16/16 [==============================] - 0s 3ms/step - loss: 2.2756
16/16 [==============================] - 0s 2ms/step - loss: 2.2693
16/16 [==============================] - 0s 2ms/step - loss: 2.2205
16/16 [==============================] - 0s 1ms/step - loss: 2.1677
16/16 [==============================] - 0s 2ms/step - loss: 2.1482
16/16 [==============================] - 0s 3ms/step - loss: 2.1398
16/16 [==============================] - 0s 2ms/step - loss: 2.1383

Testing for epoch 42 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.1041
16/16 [==============================] - 0s 3ms/step - loss: 1.8920
16/16 [==============================] - 0s 4ms/step - loss: 2.2540
16/16 [==============================] - 0s 3ms/step - loss: 2.3050
16/16 [==============================] - 0s 3ms/step - loss: 2.2963
16/16 [==============================] - 0s 3ms/step - loss: 2.2433
16/16 [==============================] - 0s 1ms/step - loss: 2.1876
16/16 [==============================] - 0s 2ms/step - loss: 2.1675
16/16 [==============================] - 0s 2ms/step - loss: 2.1588
16/16 [==============================] - 0s 2ms/step - loss: 2.1571
Epoch 43 of 60

Testing for epoch 43 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1053
16/16 [==============================] - 0s 2ms/step - loss: 1.8360
16/16 [==============================] - 0s 2ms/step - loss: 2.1927
16/16 [==============================] - 0s 1ms/step - loss: 2.2445
16/16 [==============================] - 0s 1ms/step - loss: 2.2380
16/16 [==============================] - 0s 2ms/step - loss: 2.1903
16/16 [==============================] - 0s 3ms/step - loss: 2.1397
16/16 [==============================] - 0s 3ms/step - loss: 2.1212
16/16 [==============================] - 0s 5ms/step - loss: 2.1133
16/16 [==============================] - 0s 2ms/step - loss: 2.1118

Testing for epoch 43 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1029
16/16 [==============================] - 0s 3ms/step - loss: 1.9029
16/16 [==============================] - 0s 2ms/step - loss: 2.2801
16/16 [==============================] - 0s 2ms/step - loss: 2.3378
16/16 [==============================] - 0s 2ms/step - loss: 2.3321
16/16 [==============================] - 0s 2ms/step - loss: 2.2817
16/16 [==============================] - 0s 1ms/step - loss: 2.2272
16/16 [==============================] - 0s 2ms/step - loss: 2.2073
16/16 [==============================] - 0s 2ms/step - loss: 2.1987
16/16 [==============================] - 0s 2ms/step - loss: 2.1970

Testing for epoch 43 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1021
16/16 [==============================] - 0s 3ms/step - loss: 1.8966
16/16 [==============================] - 0s 2ms/step - loss: 2.2667
16/16 [==============================] - 0s 2ms/step - loss: 2.3197
16/16 [==============================] - 0s 3ms/step - loss: 2.3105
16/16 [==============================] - 0s 2ms/step - loss: 2.2570
16/16 [==============================] - 0s 4ms/step - loss: 2.2010
16/16 [==============================] - 0s 2ms/step - loss: 2.1807
16/16 [==============================] - 0s 3ms/step - loss: 2.1719
16/16 [==============================] - 0s 2ms/step - loss: 2.1702

Testing for epoch 43 index 4:
79/79 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1002
16/16 [==============================] - 0s 2ms/step - loss: 1.8870
16/16 [==============================] - 0s 3ms/step - loss: 2.2541
16/16 [==============================] - 0s 2ms/step - loss: 2.3053
16/16 [==============================] - 0s 2ms/step - loss: 2.2973
16/16 [==============================] - 0s 1ms/step - loss: 2.2457
16/16 [==============================] - 0s 1ms/step - loss: 2.1912
16/16 [==============================] - 0s 3ms/step - loss: 2.1714
16/16 [==============================] - 0s 2ms/step - loss: 2.1629
16/16 [==============================] - 0s 2ms/step - loss: 2.1613

Testing for epoch 43 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1055
16/16 [==============================] - 0s 2ms/step - loss: 1.7964
16/16 [==============================] - 0s 2ms/step - loss: 2.1514
16/16 [==============================] - 0s 2ms/step - loss: 2.2038
16/16 [==============================] - 0s 3ms/step - loss: 2.1992
16/16 [==============================] - 0s 2ms/step - loss: 2.1546
16/16 [==============================] - 0s 2ms/step - loss: 2.1068
16/16 [==============================] - 0s 2ms/step - loss: 2.0890
16/16 [==============================] - 0s 2ms/step - loss: 2.0813
16/16 [==============================] - 0s 4ms/step - loss: 2.0798
Epoch 44 of 60

Testing for epoch 44 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0993
16/16 [==============================] - 0s 2ms/step - loss: 1.9243
16/16 [==============================] - 0s 2ms/step - loss: 2.3076
16/16 [==============================] - 0s 2ms/step - loss: 2.3605
16/16 [==============================] - 0s 2ms/step - loss: 2.3511
16/16 [==============================] - 0s 2ms/step - loss: 2.2970
16/16 [==============================] - 0s 2ms/step - loss: 2.2412
16/16 [==============================] - 0s 2ms/step - loss: 2.2210
16/16 [==============================] - 0s 2ms/step - loss: 2.2123
16/16 [==============================] - 0s 2ms/step - loss: 2.2107

Testing for epoch 44 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1029
16/16 [==============================] - 0s 2ms/step - loss: 1.9018
16/16 [==============================] - 0s 3ms/step - loss: 2.2785
16/16 [==============================] - 0s 3ms/step - loss: 2.3319
16/16 [==============================] - 0s 2ms/step - loss: 2.3247
16/16 [==============================] - 0s 2ms/step - loss: 2.2731
16/16 [==============================] - 0s 2ms/step - loss: 2.2185
16/16 [==============================] - 0s 2ms/step - loss: 2.1982
16/16 [==============================] - 0s 2ms/step - loss: 2.1893
16/16 [==============================] - 0s 2ms/step - loss: 2.1875

Testing for epoch 44 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1031
16/16 [==============================] - 0s 2ms/step - loss: 1.8852
16/16 [==============================] - 0s 2ms/step - loss: 2.2469
16/16 [==============================] - 0s 1ms/step - loss: 2.2936
16/16 [==============================] - 0s 1ms/step - loss: 2.2832
16/16 [==============================] - 0s 2ms/step - loss: 2.2297
16/16 [==============================] - 0s 3ms/step - loss: 2.1747
16/16 [==============================] - 0s 2ms/step - loss: 2.1547
16/16 [==============================] - 0s 2ms/step - loss: 2.1460
16/16 [==============================] - 0s 2ms/step - loss: 2.1443

Testing for epoch 44 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1022
16/16 [==============================] - 0s 2ms/step - loss: 1.8336
16/16 [==============================] - 0s 2ms/step - loss: 2.1891
16/16 [==============================] - 0s 2ms/step - loss: 2.2400
16/16 [==============================] - 0s 2ms/step - loss: 2.2349
16/16 [==============================] - 0s 2ms/step - loss: 2.1888
16/16 [==============================] - 0s 1ms/step - loss: 2.1397
16/16 [==============================] - 0s 2ms/step - loss: 2.1214
16/16 [==============================] - 0s 1ms/step - loss: 2.1135
16/16 [==============================] - 0s 2ms/step - loss: 2.1120

Testing for epoch 44 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1018
16/16 [==============================] - 0s 2ms/step - loss: 1.8813
16/16 [==============================] - 0s 2ms/step - loss: 2.2425
16/16 [==============================] - 0s 2ms/step - loss: 2.2887
16/16 [==============================] - 0s 2ms/step - loss: 2.2773
16/16 [==============================] - 0s 4ms/step - loss: 2.2237
16/16 [==============================] - 0s 3ms/step - loss: 2.1704
16/16 [==============================] - 0s 2ms/step - loss: 2.1507
16/16 [==============================] - 0s 3ms/step - loss: 2.1422
16/16 [==============================] - 0s 2ms/step - loss: 2.1406
Epoch 45 of 60

Testing for epoch 45 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1009
16/16 [==============================] - 0s 1ms/step - loss: 1.9181
16/16 [==============================] - 0s 2ms/step - loss: 2.2904
16/16 [==============================] - 0s 1ms/step - loss: 2.3389
16/16 [==============================] - 0s 2ms/step - loss: 2.3291
16/16 [==============================] - 0s 2ms/step - loss: 2.2755
16/16 [==============================] - 0s 2ms/step - loss: 2.2214
16/16 [==============================] - 0s 2ms/step - loss: 2.2016
16/16 [==============================] - 0s 1ms/step - loss: 2.1931
16/16 [==============================] - 0s 3ms/step - loss: 2.1915

Testing for epoch 45 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1004
16/16 [==============================] - 0s 2ms/step - loss: 1.8338
16/16 [==============================] - 0s 3ms/step - loss: 2.1909
16/16 [==============================] - 0s 2ms/step - loss: 2.2387
16/16 [==============================] - 0s 2ms/step - loss: 2.2301
16/16 [==============================] - 0s 5ms/step - loss: 2.1798
16/16 [==============================] - 0s 3ms/step - loss: 2.1289
16/16 [==============================] - 0s 2ms/step - loss: 2.1104
16/16 [==============================] - 0s 2ms/step - loss: 2.1027
16/16 [==============================] - 0s 2ms/step - loss: 2.1013

Testing for epoch 45 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1010
16/16 [==============================] - 0s 2ms/step - loss: 1.8990
16/16 [==============================] - 0s 2ms/step - loss: 2.2661
16/16 [==============================] - 0s 2ms/step - loss: 2.3140
16/16 [==============================] - 0s 2ms/step - loss: 2.3043
16/16 [==============================] - 0s 4ms/step - loss: 2.2506
16/16 [==============================] - 0s 1ms/step - loss: 2.1956
16/16 [==============================] - 0s 999us/step - loss: 2.1755
16/16 [==============================] - 0s 1ms/step - loss: 2.1670
16/16 [==============================] - 0s 1ms/step - loss: 2.1654

Testing for epoch 45 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 999us/step - loss: 0.0983
16/16 [==============================] - 0s 2ms/step - loss: 1.9696
16/16 [==============================] - 0s 1ms/step - loss: 2.3530
16/16 [==============================] - 0s 1ms/step - loss: 2.4018
16/16 [==============================] - 0s 2ms/step - loss: 2.3902
16/16 [==============================] - 0s 4ms/step - loss: 2.3347
16/16 [==============================] - 0s 3ms/step - loss: 2.2789
16/16 [==============================] - 0s 2ms/step - loss: 2.2587
16/16 [==============================] - 0s 2ms/step - loss: 2.2502
16/16 [==============================] - 0s 2ms/step - loss: 2.2486

Testing for epoch 45 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1002
16/16 [==============================] - 0s 1ms/step - loss: 1.8591
16/16 [==============================] - 0s 1ms/step - loss: 2.2248
16/16 [==============================] - 0s 2ms/step - loss: 2.2754
16/16 [==============================] - 0s 5ms/step - loss: 2.2690
16/16 [==============================] - 0s 3ms/step - loss: 2.2211
16/16 [==============================] - 0s 2ms/step - loss: 2.1718
16/16 [==============================] - 0s 3ms/step - loss: 2.1532
16/16 [==============================] - 0s 2ms/step - loss: 2.1451
16/16 [==============================] - 0s 2ms/step - loss: 2.1435
Epoch 46 of 60

Testing for epoch 46 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0985
16/16 [==============================] - 0s 2ms/step - loss: 1.9587
16/16 [==============================] - 0s 2ms/step - loss: 2.3423
16/16 [==============================] - 0s 2ms/step - loss: 2.3921
16/16 [==============================] - 0s 2ms/step - loss: 2.3813
16/16 [==============================] - 0s 2ms/step - loss: 2.3263
16/16 [==============================] - 0s 2ms/step - loss: 2.2709
16/16 [==============================] - 0s 2ms/step - loss: 2.2502
16/16 [==============================] - 0s 2ms/step - loss: 2.2414
16/16 [==============================] - 0s 1ms/step - loss: 2.2397

Testing for epoch 46 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0992
16/16 [==============================] - 0s 2ms/step - loss: 1.9068
16/16 [==============================] - 0s 2ms/step - loss: 2.2699
16/16 [==============================] - 0s 2ms/step - loss: 2.3141
16/16 [==============================] - 0s 2ms/step - loss: 2.3022
16/16 [==============================] - 0s 2ms/step - loss: 2.2467
16/16 [==============================] - 0s 2ms/step - loss: 2.1911
16/16 [==============================] - 0s 3ms/step - loss: 2.1712
16/16 [==============================] - 0s 2ms/step - loss: 2.1629
16/16 [==============================] - 0s 2ms/step - loss: 2.1614

Testing for epoch 46 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1001
16/16 [==============================] - 0s 2ms/step - loss: 1.9393
16/16 [==============================] - 0s 2ms/step - loss: 2.3122
16/16 [==============================] - 0s 2ms/step - loss: 2.3589
16/16 [==============================] - 0s 2ms/step - loss: 2.3481
16/16 [==============================] - 0s 2ms/step - loss: 2.2943
16/16 [==============================] - 0s 3ms/step - loss: 2.2397
16/16 [==============================] - 0s 2ms/step - loss: 2.2194
16/16 [==============================] - 0s 4ms/step - loss: 2.2106
16/16 [==============================] - 0s 5ms/step - loss: 2.2089

Testing for epoch 46 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0961
16/16 [==============================] - 0s 2ms/step - loss: 1.9574
16/16 [==============================] - 0s 3ms/step - loss: 2.3292
16/16 [==============================] - 0s 1ms/step - loss: 2.3711
16/16 [==============================] - 0s 3ms/step - loss: 2.3554
16/16 [==============================] - 0s 3ms/step - loss: 2.2951
16/16 [==============================] - 0s 2ms/step - loss: 2.2366
16/16 [==============================] - 0s 2ms/step - loss: 2.2155
16/16 [==============================] - 0s 2ms/step - loss: 2.2066
16/16 [==============================] - 0s 2ms/step - loss: 2.2050

Testing for epoch 46 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0988
16/16 [==============================] - 0s 2ms/step - loss: 1.9651
16/16 [==============================] - 0s 2ms/step - loss: 2.3462
16/16 [==============================] - 0s 2ms/step - loss: 2.3924
16/16 [==============================] - 0s 2ms/step - loss: 2.3789
16/16 [==============================] - 0s 2ms/step - loss: 2.3194
16/16 [==============================] - 0s 2ms/step - loss: 2.2610
16/16 [==============================] - 0s 3ms/step - loss: 2.2398
16/16 [==============================] - 0s 2ms/step - loss: 2.2308
16/16 [==============================] - 0s 3ms/step - loss: 2.2291
Epoch 47 of 60

Testing for epoch 47 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0950
16/16 [==============================] - 0s 2ms/step - loss: 1.9756
16/16 [==============================] - 0s 4ms/step - loss: 2.3563
16/16 [==============================] - 0s 2ms/step - loss: 2.4010
16/16 [==============================] - 0s 3ms/step - loss: 2.3877
16/16 [==============================] - 0s 2ms/step - loss: 2.3300
16/16 [==============================] - 0s 2ms/step - loss: 2.2720
16/16 [==============================] - 0s 2ms/step - loss: 2.2506
16/16 [==============================] - 0s 3ms/step - loss: 2.2415
16/16 [==============================] - 0s 3ms/step - loss: 2.2397

Testing for epoch 47 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0979
16/16 [==============================] - 0s 3ms/step - loss: 1.9808
16/16 [==============================] - 0s 2ms/step - loss: 2.3619
16/16 [==============================] - 0s 2ms/step - loss: 2.4050
16/16 [==============================] - 0s 2ms/step - loss: 2.3910
16/16 [==============================] - 0s 2ms/step - loss: 2.3322
16/16 [==============================] - 0s 2ms/step - loss: 2.2735
16/16 [==============================] - 0s 2ms/step - loss: 2.2522
16/16 [==============================] - 0s 4ms/step - loss: 2.2433
16/16 [==============================] - 0s 2ms/step - loss: 2.2417

Testing for epoch 47 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0988
16/16 [==============================] - 0s 2ms/step - loss: 1.9357
16/16 [==============================] - 0s 2ms/step - loss: 2.3099
16/16 [==============================] - 0s 2ms/step - loss: 2.3568
16/16 [==============================] - 0s 2ms/step - loss: 2.3453
16/16 [==============================] - 0s 4ms/step - loss: 2.2904
16/16 [==============================] - 0s 3ms/step - loss: 2.2345
16/16 [==============================] - 0s 2ms/step - loss: 2.2140
16/16 [==============================] - 0s 3ms/step - loss: 2.2053
16/16 [==============================] - 0s 2ms/step - loss: 2.2037

Testing for epoch 47 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0938
16/16 [==============================] - 0s 4ms/step - loss: 1.9931
16/16 [==============================] - 0s 2ms/step - loss: 2.3662
16/16 [==============================] - 0s 3ms/step - loss: 2.4063
16/16 [==============================] - 0s 2ms/step - loss: 2.3901
16/16 [==============================] - 0s 3ms/step - loss: 2.3299
16/16 [==============================] - 0s 3ms/step - loss: 2.2703
16/16 [==============================] - 0s 2ms/step - loss: 2.2486
16/16 [==============================] - 0s 3ms/step - loss: 2.2396
16/16 [==============================] - 0s 2ms/step - loss: 2.2379

Testing for epoch 47 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0992
16/16 [==============================] - 0s 2ms/step - loss: 1.9485
16/16 [==============================] - 0s 2ms/step - loss: 2.3270
16/16 [==============================] - 0s 4ms/step - loss: 2.3710
16/16 [==============================] - 0s 2ms/step - loss: 2.3569
16/16 [==============================] - 0s 2ms/step - loss: 2.2979
16/16 [==============================] - 0s 3ms/step - loss: 2.2407
16/16 [==============================] - 0s 2ms/step - loss: 2.2200
16/16 [==============================] - 0s 3ms/step - loss: 2.2113
16/16 [==============================] - 0s 2ms/step - loss: 2.2098
Epoch 48 of 60

Testing for epoch 48 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0939
16/16 [==============================] - 0s 2ms/step - loss: 2.0025
16/16 [==============================] - 0s 2ms/step - loss: 2.3825
16/16 [==============================] - 0s 2ms/step - loss: 2.4248
16/16 [==============================] - 0s 3ms/step - loss: 2.4099
16/16 [==============================] - 0s 2ms/step - loss: 2.3499
16/16 [==============================] - 0s 2ms/step - loss: 2.2911
16/16 [==============================] - 0s 2ms/step - loss: 2.2699
16/16 [==============================] - 0s 3ms/step - loss: 2.2610
16/16 [==============================] - 0s 2ms/step - loss: 2.2593

Testing for epoch 48 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0942
16/16 [==============================] - 0s 2ms/step - loss: 2.0243
16/16 [==============================] - 0s 2ms/step - loss: 2.4154
16/16 [==============================] - 0s 2ms/step - loss: 2.4577
16/16 [==============================] - 0s 2ms/step - loss: 2.4397
16/16 [==============================] - 0s 3ms/step - loss: 2.3764
16/16 [==============================] - 0s 2ms/step - loss: 2.3147
16/16 [==============================] - 0s 2ms/step - loss: 2.2926
16/16 [==============================] - 0s 3ms/step - loss: 2.2835
16/16 [==============================] - 0s 2ms/step - loss: 2.2818

Testing for epoch 48 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0926
16/16 [==============================] - 0s 2ms/step - loss: 2.0129
16/16 [==============================] - 0s 2ms/step - loss: 2.4026
16/16 [==============================] - 0s 3ms/step - loss: 2.4448
16/16 [==============================] - 0s 2ms/step - loss: 2.4273
16/16 [==============================] - 0s 2ms/step - loss: 2.3640
16/16 [==============================] - 0s 2ms/step - loss: 2.3025
16/16 [==============================] - 0s 2ms/step - loss: 2.2802
16/16 [==============================] - 0s 3ms/step - loss: 2.2709
16/16 [==============================] - 0s 2ms/step - loss: 2.2690

Testing for epoch 48 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0961
16/16 [==============================] - 0s 2ms/step - loss: 2.0192
16/16 [==============================] - 0s 2ms/step - loss: 2.4039
16/16 [==============================] - 0s 2ms/step - loss: 2.4414
16/16 [==============================] - 0s 3ms/step - loss: 2.4219
16/16 [==============================] - 0s 3ms/step - loss: 2.3577
16/16 [==============================] - 0s 2ms/step - loss: 2.2948
16/16 [==============================] - 0s 2ms/step - loss: 2.2720
16/16 [==============================] - 0s 5ms/step - loss: 2.2624
16/16 [==============================] - 0s 2ms/step - loss: 2.2606

Testing for epoch 48 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0973
16/16 [==============================] - 0s 2ms/step - loss: 2.0340
16/16 [==============================] - 0s 2ms/step - loss: 2.4261
16/16 [==============================] - 0s 3ms/step - loss: 2.4671
16/16 [==============================] - 0s 3ms/step - loss: 2.4484
16/16 [==============================] - 0s 2ms/step - loss: 2.3850
16/16 [==============================] - 0s 2ms/step - loss: 2.3236
16/16 [==============================] - 0s 2ms/step - loss: 2.3015
16/16 [==============================] - 0s 4ms/step - loss: 2.2923
16/16 [==============================] - 0s 2ms/step - loss: 2.2906
Epoch 49 of 60

Testing for epoch 49 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0942
16/16 [==============================] - 0s 2ms/step - loss: 1.9984
16/16 [==============================] - 0s 2ms/step - loss: 2.3882
16/16 [==============================] - 0s 2ms/step - loss: 2.4299
16/16 [==============================] - 0s 2ms/step - loss: 2.4138
16/16 [==============================] - 0s 2ms/step - loss: 2.3538
16/16 [==============================] - 0s 2ms/step - loss: 2.2943
16/16 [==============================] - 0s 2ms/step - loss: 2.2728
16/16 [==============================] - 0s 2ms/step - loss: 2.2639
16/16 [==============================] - 0s 2ms/step - loss: 2.2622

Testing for epoch 49 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0941
16/16 [==============================] - 0s 2ms/step - loss: 1.9608
16/16 [==============================] - 0s 2ms/step - loss: 2.3309
16/16 [==============================] - 0s 2ms/step - loss: 2.3672
16/16 [==============================] - 0s 2ms/step - loss: 2.3494
16/16 [==============================] - 0s 1ms/step - loss: 2.2910
16/16 [==============================] - 0s 2ms/step - loss: 2.2344
16/16 [==============================] - 0s 2ms/step - loss: 2.2142
16/16 [==============================] - 0s 4ms/step - loss: 2.2058
16/16 [==============================] - 0s 4ms/step - loss: 2.2042

Testing for epoch 49 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0956
16/16 [==============================] - 0s 2ms/step - loss: 1.9786
16/16 [==============================] - 0s 3ms/step - loss: 2.3595
16/16 [==============================] - 0s 3ms/step - loss: 2.3978
16/16 [==============================] - 0s 2ms/step - loss: 2.3803
16/16 [==============================] - 0s 4ms/step - loss: 2.3199
16/16 [==============================] - 0s 2ms/step - loss: 2.2618
16/16 [==============================] - 0s 3ms/step - loss: 2.2405
16/16 [==============================] - 0s 3ms/step - loss: 2.2316
16/16 [==============================] - 0s 3ms/step - loss: 2.2298

Testing for epoch 49 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0940
16/16 [==============================] - 0s 2ms/step - loss: 1.9577
16/16 [==============================] - 0s 2ms/step - loss: 2.3256
16/16 [==============================] - 0s 3ms/step - loss: 2.3595
16/16 [==============================] - 0s 2ms/step - loss: 2.3391
16/16 [==============================] - 0s 2ms/step - loss: 2.2756
16/16 [==============================] - 0s 2ms/step - loss: 2.2159
16/16 [==============================] - 0s 2ms/step - loss: 2.1946
16/16 [==============================] - 0s 2ms/step - loss: 2.1857
16/16 [==============================] - 0s 2ms/step - loss: 2.1840

Testing for epoch 49 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0950
16/16 [==============================] - 0s 4ms/step - loss: 2.0165
16/16 [==============================] - 0s 3ms/step - loss: 2.4044
16/16 [==============================] - 0s 2ms/step - loss: 2.4434
16/16 [==============================] - 0s 2ms/step - loss: 2.4255
16/16 [==============================] - 0s 2ms/step - loss: 2.3646
16/16 [==============================] - 0s 3ms/step - loss: 2.3054
16/16 [==============================] - 0s 2ms/step - loss: 2.2840
16/16 [==============================] - 0s 4ms/step - loss: 2.2751
16/16 [==============================] - 0s 2ms/step - loss: 2.2734
Epoch 50 of 60

Testing for epoch 50 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0939
16/16 [==============================] - 0s 3ms/step - loss: 2.0316
16/16 [==============================] - 0s 2ms/step - loss: 2.4252
16/16 [==============================] - 0s 2ms/step - loss: 2.4670
16/16 [==============================] - 0s 2ms/step - loss: 2.4486
16/16 [==============================] - 0s 3ms/step - loss: 2.3856
16/16 [==============================] - 0s 2ms/step - loss: 2.3238
16/16 [==============================] - 0s 2ms/step - loss: 2.3017
16/16 [==============================] - 0s 1ms/step - loss: 2.2923
16/16 [==============================] - 0s 2ms/step - loss: 2.2905

Testing for epoch 50 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0945
16/16 [==============================] - 0s 2ms/step - loss: 2.0411
16/16 [==============================] - 0s 2ms/step - loss: 2.4303
16/16 [==============================] - 0s 2ms/step - loss: 2.4670
16/16 [==============================] - 0s 3ms/step - loss: 2.4431
16/16 [==============================] - 0s 2ms/step - loss: 2.3757
16/16 [==============================] - 0s 3ms/step - loss: 2.3104
16/16 [==============================] - 0s 2ms/step - loss: 2.2871
16/16 [==============================] - 0s 2ms/step - loss: 2.2775
16/16 [==============================] - 0s 2ms/step - loss: 2.2756

Testing for epoch 50 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0915
16/16 [==============================] - 0s 2ms/step - loss: 2.0305
16/16 [==============================] - 0s 4ms/step - loss: 2.4191
16/16 [==============================] - 0s 3ms/step - loss: 2.4574
16/16 [==============================] - 0s 2ms/step - loss: 2.4353
16/16 [==============================] - 0s 2ms/step - loss: 2.3695
16/16 [==============================] - 0s 2ms/step - loss: 2.3069
16/16 [==============================] - 0s 2ms/step - loss: 2.2844
16/16 [==============================] - 0s 2ms/step - loss: 2.2751
16/16 [==============================] - 0s 2ms/step - loss: 2.2734

Testing for epoch 50 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0948
16/16 [==============================] - 0s 2ms/step - loss: 2.0094
16/16 [==============================] - 0s 3ms/step - loss: 2.3988
16/16 [==============================] - 0s 2ms/step - loss: 2.4394
16/16 [==============================] - 0s 2ms/step - loss: 2.4206
16/16 [==============================] - 0s 2ms/step - loss: 2.3598
16/16 [==============================] - 0s 2ms/step - loss: 2.3009
16/16 [==============================] - 0s 2ms/step - loss: 2.2799
16/16 [==============================] - 0s 2ms/step - loss: 2.2713
16/16 [==============================] - 0s 3ms/step - loss: 2.2697

Testing for epoch 50 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0948
16/16 [==============================] - 0s 2ms/step - loss: 1.9350
16/16 [==============================] - 0s 3ms/step - loss: 2.3002
16/16 [==============================] - 0s 2ms/step - loss: 2.3353
16/16 [==============================] - 0s 2ms/step - loss: 2.3162
16/16 [==============================] - 0s 2ms/step - loss: 2.2605
16/16 [==============================] - 0s 3ms/step - loss: 2.2075
16/16 [==============================] - 0s 2ms/step - loss: 2.1885
16/16 [==============================] - 0s 2ms/step - loss: 2.1805
16/16 [==============================] - 0s 2ms/step - loss: 2.1790
Epoch 51 of 60

Testing for epoch 51 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0943
16/16 [==============================] - 0s 3ms/step - loss: 2.0148
16/16 [==============================] - 0s 2ms/step - loss: 2.3989
16/16 [==============================] - 0s 2ms/step - loss: 2.4336
16/16 [==============================] - 0s 2ms/step - loss: 2.4111
16/16 [==============================] - 0s 3ms/step - loss: 2.3485
16/16 [==============================] - 0s 2ms/step - loss: 2.2887
16/16 [==============================] - 0s 2ms/step - loss: 2.2673
16/16 [==============================] - 0s 2ms/step - loss: 2.2586
16/16 [==============================] - 0s 2ms/step - loss: 2.2570

Testing for epoch 51 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0891
16/16 [==============================] - 0s 3ms/step - loss: 1.9820
16/16 [==============================] - 0s 2ms/step - loss: 2.3552
16/16 [==============================] - 0s 3ms/step - loss: 2.3865
16/16 [==============================] - 0s 995us/step - loss: 2.3612
16/16 [==============================] - 0s 2ms/step - loss: 2.2946
16/16 [==============================] - 0s 3ms/step - loss: 2.2336
16/16 [==============================] - 0s 2ms/step - loss: 2.2116
16/16 [==============================] - 0s 2ms/step - loss: 2.2026
16/16 [==============================] - 0s 2ms/step - loss: 2.2008

Testing for epoch 51 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0906
16/16 [==============================] - 0s 2ms/step - loss: 2.0591
16/16 [==============================] - 0s 2ms/step - loss: 2.4496
16/16 [==============================] - 0s 2ms/step - loss: 2.4830
16/16 [==============================] - 0s 2ms/step - loss: 2.4580
16/16 [==============================] - 0s 2ms/step - loss: 2.3893
16/16 [==============================] - 0s 2ms/step - loss: 2.3244
16/16 [==============================] - 0s 3ms/step - loss: 2.3015
16/16 [==============================] - 0s 2ms/step - loss: 2.2921
16/16 [==============================] - 0s 2ms/step - loss: 2.2903

Testing for epoch 51 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0930
16/16 [==============================] - 0s 2ms/step - loss: 2.0165
16/16 [==============================] - 0s 3ms/step - loss: 2.3985
16/16 [==============================] - 0s 3ms/step - loss: 2.4314
16/16 [==============================] - 0s 2ms/step - loss: 2.4067
16/16 [==============================] - 0s 2ms/step - loss: 2.3406
16/16 [==============================] - 0s 2ms/step - loss: 2.2785
16/16 [==============================] - 0s 2ms/step - loss: 2.2561
16/16 [==============================] - 0s 2ms/step - loss: 2.2468
16/16 [==============================] - 0s 2ms/step - loss: 2.2449

Testing for epoch 51 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0919
16/16 [==============================] - 0s 2ms/step - loss: 2.0436
16/16 [==============================] - 0s 2ms/step - loss: 2.4294
16/16 [==============================] - 0s 3ms/step - loss: 2.4592
16/16 [==============================] - 0s 2ms/step - loss: 2.4329
16/16 [==============================] - 0s 2ms/step - loss: 2.3668
16/16 [==============================] - 0s 2ms/step - loss: 2.3043
16/16 [==============================] - 0s 2ms/step - loss: 2.2821
16/16 [==============================] - 0s 2ms/step - loss: 2.2730
16/16 [==============================] - 0s 2ms/step - loss: 2.2713
Epoch 52 of 60

Testing for epoch 52 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0883
16/16 [==============================] - 0s 2ms/step - loss: 2.0146
16/16 [==============================] - 0s 2ms/step - loss: 2.3887
16/16 [==============================] - 0s 2ms/step - loss: 2.4170
16/16 [==============================] - 0s 3ms/step - loss: 2.3903
16/16 [==============================] - 0s 2ms/step - loss: 2.3223
16/16 [==============================] - 0s 2ms/step - loss: 2.2596
16/16 [==============================] - 0s 2ms/step - loss: 2.2375
16/16 [==============================] - 0s 2ms/step - loss: 2.2285
16/16 [==============================] - 0s 2ms/step - loss: 2.2268

Testing for epoch 52 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0894
16/16 [==============================] - 0s 2ms/step - loss: 2.0583
16/16 [==============================] - 0s 2ms/step - loss: 2.4503
16/16 [==============================] - 0s 2ms/step - loss: 2.4842
16/16 [==============================] - 0s 2ms/step - loss: 2.4607
16/16 [==============================] - 0s 2ms/step - loss: 2.3956
16/16 [==============================] - 0s 2ms/step - loss: 2.3347
16/16 [==============================] - 0s 2ms/step - loss: 2.3125
16/16 [==============================] - 0s 2ms/step - loss: 2.3032
16/16 [==============================] - 0s 3ms/step - loss: 2.3014

Testing for epoch 52 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0926
16/16 [==============================] - 0s 2ms/step - loss: 2.0713
16/16 [==============================] - 0s 2ms/step - loss: 2.4635
16/16 [==============================] - 0s 2ms/step - loss: 2.4962
16/16 [==============================] - 0s 3ms/step - loss: 2.4703
16/16 [==============================] - 0s 2ms/step - loss: 2.4005
16/16 [==============================] - 0s 2ms/step - loss: 2.3354
16/16 [==============================] - 0s 2ms/step - loss: 2.3126
16/16 [==============================] - 0s 3ms/step - loss: 2.3034
16/16 [==============================] - 0s 2ms/step - loss: 2.3017

Testing for epoch 52 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0877
16/16 [==============================] - 0s 3ms/step - loss: 2.0447
16/16 [==============================] - 0s 2ms/step - loss: 2.4348
16/16 [==============================] - 0s 2ms/step - loss: 2.4672
16/16 [==============================] - 0s 2ms/step - loss: 2.4432
16/16 [==============================] - 0s 2ms/step - loss: 2.3776
16/16 [==============================] - 0s 2ms/step - loss: 2.3149
16/16 [==============================] - 0s 2ms/step - loss: 2.2923
16/16 [==============================] - 0s 2ms/step - loss: 2.2829
16/16 [==============================] - 0s 2ms/step - loss: 2.2812

Testing for epoch 52 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0925
16/16 [==============================] - 0s 1ms/step - loss: 2.0490
16/16 [==============================] - 0s 1ms/step - loss: 2.4412
16/16 [==============================] - 0s 734us/step - loss: 2.4733
16/16 [==============================] - 0s 2ms/step - loss: 2.4480
16/16 [==============================] - 0s 2ms/step - loss: 2.3792
16/16 [==============================] - 0s 943us/step - loss: 2.3161
16/16 [==============================] - 0s 862us/step - loss: 2.2938
16/16 [==============================] - 0s 817us/step - loss: 2.2848
16/16 [==============================] - 0s 2ms/step - loss: 2.2831
Epoch 53 of 60

Testing for epoch 53 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0866
16/16 [==============================] - 0s 1ms/step - loss: 2.0849
16/16 [==============================] - 0s 725us/step - loss: 2.4819
16/16 [==============================] - 0s 881us/step - loss: 2.5101
16/16 [==============================] - 0s 2ms/step - loss: 2.4814
16/16 [==============================] - 0s 2ms/step - loss: 2.4079
16/16 [==============================] - 0s 693us/step - loss: 2.3426
16/16 [==============================] - 0s 795us/step - loss: 2.3199
16/16 [==============================] - 0s 5ms/step - loss: 2.3106
16/16 [==============================] - 0s 2ms/step - loss: 2.3088

Testing for epoch 53 index 2:
79/79 [==============================] - 0s 753us/step
16/16 [==============================] - 0s 847us/step - loss: 0.0894
16/16 [==============================] - 0s 878us/step - loss: 2.0244
16/16 [==============================] - 0s 811us/step - loss: 2.4226
16/16 [==============================] - 0s 789us/step - loss: 2.4576
16/16 [==============================] - 0s 1ms/step - loss: 2.4359
16/16 [==============================] - 0s 2ms/step - loss: 2.3727
16/16 [==============================] - 0s 4ms/step - loss: 2.3120
16/16 [==============================] - 0s 4ms/step - loss: 2.2901
16/16 [==============================] - 0s 3ms/step - loss: 2.2810
16/16 [==============================] - 0s 2ms/step - loss: 2.2792

Testing for epoch 53 index 3:
79/79 [==============================] - 0s 527us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0919
16/16 [==============================] - 0s 838us/step - loss: 2.0539
16/16 [==============================] - 0s 812us/step - loss: 2.4374
16/16 [==============================] - 0s 5ms/step - loss: 2.4630
16/16 [==============================] - 0s 5ms/step - loss: 2.4341
16/16 [==============================] - 0s 4ms/step - loss: 2.3644
16/16 [==============================] - 0s 4ms/step - loss: 2.3013
16/16 [==============================] - 0s 4ms/step - loss: 2.2790
16/16 [==============================] - 0s 1ms/step - loss: 2.2699
16/16 [==============================] - 0s 792us/step - loss: 2.2681

Testing for epoch 53 index 4:
79/79 [==============================] - 0s 546us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0883
16/16 [==============================] - 0s 2ms/step - loss: 2.1081
16/16 [==============================] - 0s 1ms/step - loss: 2.5085
16/16 [==============================] - 0s 824us/step - loss: 2.5367
16/16 [==============================] - 0s 2ms/step - loss: 2.5091
16/16 [==============================] - 0s 833us/step - loss: 2.4358
16/16 [==============================] - 0s 2ms/step - loss: 2.3696
16/16 [==============================] - 0s 2ms/step - loss: 2.3459
16/16 [==============================] - 0s 1ms/step - loss: 2.3362
16/16 [==============================] - 0s 2ms/step - loss: 2.3343

Testing for epoch 53 index 5:
79/79 [==============================] - 0s 798us/step
16/16 [==============================] - 0s 813us/step - loss: 0.0876
16/16 [==============================] - 0s 876us/step - loss: 2.0422
16/16 [==============================] - 0s 785us/step - loss: 2.4186
16/16 [==============================] - 0s 1ms/step - loss: 2.4428
16/16 [==============================] - 0s 839us/step - loss: 2.4149
16/16 [==============================] - 0s 1ms/step - loss: 2.3452
16/16 [==============================] - 0s 874us/step - loss: 2.2818
16/16 [==============================] - 0s 821us/step - loss: 2.2595
16/16 [==============================] - 0s 4ms/step - loss: 2.2503
16/16 [==============================] - 0s 8ms/step - loss: 2.2485
Epoch 54 of 60

Testing for epoch 54 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0888
16/16 [==============================] - 0s 4ms/step - loss: 2.0366
16/16 [==============================] - 0s 1ms/step - loss: 2.4164
16/16 [==============================] - 0s 949us/step - loss: 2.4435
16/16 [==============================] - 0s 5ms/step - loss: 2.4179
16/16 [==============================] - 0s 5ms/step - loss: 2.3513
16/16 [==============================] - 0s 7ms/step - loss: 2.2913
16/16 [==============================] - 0s 5ms/step - loss: 2.2702
16/16 [==============================] - 0s 8ms/step - loss: 2.2615
16/16 [==============================] - 0s 8ms/step - loss: 2.2598

Testing for epoch 54 index 2:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0892
16/16 [==============================] - 0s 837us/step - loss: 2.0350
16/16 [==============================] - 0s 1ms/step - loss: 2.4158
16/16 [==============================] - 0s 843us/step - loss: 2.4420
16/16 [==============================] - 0s 877us/step - loss: 2.4149
16/16 [==============================] - 0s 2ms/step - loss: 2.3478
16/16 [==============================] - 0s 917us/step - loss: 2.2856
16/16 [==============================] - 0s 2ms/step - loss: 2.2639
16/16 [==============================] - 0s 1ms/step - loss: 2.2554
16/16 [==============================] - 0s 1ms/step - loss: 2.2538

Testing for epoch 54 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0910
16/16 [==============================] - 0s 2ms/step - loss: 2.0584
16/16 [==============================] - 0s 2ms/step - loss: 2.4485
16/16 [==============================] - 0s 2ms/step - loss: 2.4785
16/16 [==============================] - 0s 1ms/step - loss: 2.4525
16/16 [==============================] - 0s 2ms/step - loss: 2.3842
16/16 [==============================] - 0s 1ms/step - loss: 2.3213
16/16 [==============================] - 0s 2ms/step - loss: 2.2991
16/16 [==============================] - 0s 2ms/step - loss: 2.2901
16/16 [==============================] - 0s 2ms/step - loss: 2.2883

Testing for epoch 54 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0884
16/16 [==============================] - 0s 2ms/step - loss: 2.0856
16/16 [==============================] - 0s 2ms/step - loss: 2.4778
16/16 [==============================] - 0s 2ms/step - loss: 2.5052
16/16 [==============================] - 0s 1ms/step - loss: 2.4778
16/16 [==============================] - 0s 2ms/step - loss: 2.4060
16/16 [==============================] - 0s 2ms/step - loss: 2.3409
16/16 [==============================] - 0s 3ms/step - loss: 2.3178
16/16 [==============================] - 0s 1ms/step - loss: 2.3084
16/16 [==============================] - 0s 2ms/step - loss: 2.3065

Testing for epoch 54 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0858
16/16 [==============================] - 0s 3ms/step - loss: 2.0647
16/16 [==============================] - 0s 3ms/step - loss: 2.4518
16/16 [==============================] - 0s 2ms/step - loss: 2.4769
16/16 [==============================] - 0s 2ms/step - loss: 2.4471
16/16 [==============================] - 0s 2ms/step - loss: 2.3741
16/16 [==============================] - 0s 2ms/step - loss: 2.3085
16/16 [==============================] - 0s 2ms/step - loss: 2.2854
16/16 [==============================] - 0s 3ms/step - loss: 2.2760
16/16 [==============================] - 0s 2ms/step - loss: 2.2742
Epoch 55 of 60

Testing for epoch 55 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0890
16/16 [==============================] - 0s 2ms/step - loss: 2.0756
16/16 [==============================] - 0s 2ms/step - loss: 2.4647
16/16 [==============================] - 0s 1ms/step - loss: 2.4909
16/16 [==============================] - 0s 2ms/step - loss: 2.4635
16/16 [==============================] - 0s 1ms/step - loss: 2.3939
16/16 [==============================] - 0s 1ms/step - loss: 2.3302
16/16 [==============================] - 0s 2ms/step - loss: 2.3079
16/16 [==============================] - 0s 3ms/step - loss: 2.2990
16/16 [==============================] - 0s 1ms/step - loss: 2.2974

Testing for epoch 55 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0878
16/16 [==============================] - 0s 3ms/step - loss: 2.0431
16/16 [==============================] - 0s 2ms/step - loss: 2.4252
16/16 [==============================] - 0s 2ms/step - loss: 2.4498
16/16 [==============================] - 0s 2ms/step - loss: 2.4230
16/16 [==============================] - 0s 3ms/step - loss: 2.3545
16/16 [==============================] - 0s 2ms/step - loss: 2.2923
16/16 [==============================] - 0s 2ms/step - loss: 2.2707
16/16 [==============================] - 0s 2ms/step - loss: 2.2620
16/16 [==============================] - 0s 1ms/step - loss: 2.2604

Testing for epoch 55 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0868
16/16 [==============================] - 0s 1ms/step - loss: 2.0898
16/16 [==============================] - 0s 1ms/step - loss: 2.4731
16/16 [==============================] - 0s 3ms/step - loss: 2.4900
16/16 [==============================] - 0s 2ms/step - loss: 2.4568
16/16 [==============================] - 0s 3ms/step - loss: 2.3812
16/16 [==============================] - 0s 3ms/step - loss: 2.3136
16/16 [==============================] - 0s 3ms/step - loss: 2.2901
16/16 [==============================] - 0s 2ms/step - loss: 2.2805
16/16 [==============================] - 0s 1ms/step - loss: 2.2787

Testing for epoch 55 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0857
16/16 [==============================] - 0s 3ms/step - loss: 2.0635
16/16 [==============================] - 0s 3ms/step - loss: 2.4504
16/16 [==============================] - 0s 3ms/step - loss: 2.4728
16/16 [==============================] - 0s 2ms/step - loss: 2.4434
16/16 [==============================] - 0s 2ms/step - loss: 2.3710
16/16 [==============================] - 0s 2ms/step - loss: 2.3065
16/16 [==============================] - 0s 1ms/step - loss: 2.2839
16/16 [==============================] - 0s 3ms/step - loss: 2.2747
16/16 [==============================] - 0s 3ms/step - loss: 2.2729

Testing for epoch 55 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0859
16/16 [==============================] - 0s 4ms/step - loss: 2.0823
16/16 [==============================] - 0s 3ms/step - loss: 2.4687
16/16 [==============================] - 0s 2ms/step - loss: 2.4899
16/16 [==============================] - 0s 1ms/step - loss: 2.4595
16/16 [==============================] - 0s 2ms/step - loss: 2.3872
16/16 [==============================] - 0s 2ms/step - loss: 2.3223
16/16 [==============================] - 0s 2ms/step - loss: 2.2996
16/16 [==============================] - 0s 2ms/step - loss: 2.2905
16/16 [==============================] - 0s 3ms/step - loss: 2.2888
Epoch 56 of 60

Testing for epoch 56 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0855
16/16 [==============================] - 0s 4ms/step - loss: 2.1142
16/16 [==============================] - 0s 3ms/step - loss: 2.5178
16/16 [==============================] - 0s 2ms/step - loss: 2.5438
16/16 [==============================] - 0s 3ms/step - loss: 2.5148
16/16 [==============================] - 0s 2ms/step - loss: 2.4413
16/16 [==============================] - 0s 2ms/step - loss: 2.3754
16/16 [==============================] - 0s 4ms/step - loss: 2.3522
16/16 [==============================] - 0s 3ms/step - loss: 2.3428
16/16 [==============================] - 0s 2ms/step - loss: 2.3410

Testing for epoch 56 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0850
16/16 [==============================] - 0s 2ms/step - loss: 2.0906
16/16 [==============================] - 0s 3ms/step - loss: 2.4752
16/16 [==============================] - 0s 1ms/step - loss: 2.4913
16/16 [==============================] - 0s 4ms/step - loss: 2.4597
16/16 [==============================] - 0s 2ms/step - loss: 2.3841
16/16 [==============================] - 0s 1ms/step - loss: 2.3176
16/16 [==============================] - 0s 2ms/step - loss: 2.2948
16/16 [==============================] - 0s 3ms/step - loss: 2.2856
16/16 [==============================] - 0s 3ms/step - loss: 2.2839

Testing for epoch 56 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0842
16/16 [==============================] - 0s 1ms/step - loss: 2.1612
16/16 [==============================] - 0s 3ms/step - loss: 2.5638
16/16 [==============================] - 0s 2ms/step - loss: 2.5835
16/16 [==============================] - 0s 3ms/step - loss: 2.5528
16/16 [==============================] - 0s 3ms/step - loss: 2.4765
16/16 [==============================] - 0s 2ms/step - loss: 2.4080
16/16 [==============================] - 0s 3ms/step - loss: 2.3840
16/16 [==============================] - 0s 2ms/step - loss: 2.3743
16/16 [==============================] - 0s 3ms/step - loss: 2.3725

Testing for epoch 56 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0836
16/16 [==============================] - 0s 2ms/step - loss: 2.0942
16/16 [==============================] - 0s 2ms/step - loss: 2.4783
16/16 [==============================] - 0s 2ms/step - loss: 2.4977
16/16 [==============================] - 0s 2ms/step - loss: 2.4668
16/16 [==============================] - 0s 2ms/step - loss: 2.3934
16/16 [==============================] - 0s 1ms/step - loss: 2.3289
16/16 [==============================] - 0s 2ms/step - loss: 2.3063
16/16 [==============================] - 0s 4ms/step - loss: 2.2972
16/16 [==============================] - 0s 3ms/step - loss: 2.2954

Testing for epoch 56 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0830
16/16 [==============================] - 0s 2ms/step - loss: 2.1505
16/16 [==============================] - 0s 2ms/step - loss: 2.5526
16/16 [==============================] - 0s 3ms/step - loss: 2.5713
16/16 [==============================] - 0s 2ms/step - loss: 2.5386
16/16 [==============================] - 0s 2ms/step - loss: 2.4593
16/16 [==============================] - 0s 3ms/step - loss: 2.3887
16/16 [==============================] - 0s 1ms/step - loss: 2.3643
16/16 [==============================] - 0s 2ms/step - loss: 2.3545
16/16 [==============================] - 0s 2ms/step - loss: 2.3527
Epoch 57 of 60

Testing for epoch 57 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0833
16/16 [==============================] - 0s 2ms/step - loss: 2.1562
16/16 [==============================] - 0s 2ms/step - loss: 2.5582
16/16 [==============================] - 0s 2ms/step - loss: 2.5754
16/16 [==============================] - 0s 3ms/step - loss: 2.5415
16/16 [==============================] - 0s 3ms/step - loss: 2.4629
16/16 [==============================] - 0s 986us/step - loss: 2.3941
16/16 [==============================] - 0s 2ms/step - loss: 2.3703
16/16 [==============================] - 0s 2ms/step - loss: 2.3606
16/16 [==============================] - 0s 3ms/step - loss: 2.3588

Testing for epoch 57 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.0868
16/16 [==============================] - 0s 3ms/step - loss: 2.1272
16/16 [==============================] - 0s 995us/step - loss: 2.5227
16/16 [==============================] - 0s 3ms/step - loss: 2.5441
16/16 [==============================] - 0s 3ms/step - loss: 2.5139
16/16 [==============================] - 0s 1ms/step - loss: 2.4385
16/16 [==============================] - 0s 3ms/step - loss: 2.3718
16/16 [==============================] - 0s 4ms/step - loss: 2.3488
16/16 [==============================] - 0s 3ms/step - loss: 2.3396
16/16 [==============================] - 0s 1ms/step - loss: 2.3380

Testing for epoch 57 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0894
16/16 [==============================] - 0s 1ms/step - loss: 2.0938
16/16 [==============================] - 0s 3ms/step - loss: 2.4832
16/16 [==============================] - 0s 1ms/step - loss: 2.5010
16/16 [==============================] - 0s 2ms/step - loss: 2.4690
16/16 [==============================] - 0s 4ms/step - loss: 2.3947
16/16 [==============================] - 0s 2ms/step - loss: 2.3295
16/16 [==============================] - 0s 4ms/step - loss: 2.3069
16/16 [==============================] - 0s 3ms/step - loss: 2.2978
16/16 [==============================] - 0s 3ms/step - loss: 2.2961

Testing for epoch 57 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0857
16/16 [==============================] - 0s 3ms/step - loss: 2.1356
16/16 [==============================] - 0s 1ms/step - loss: 2.5298
16/16 [==============================] - 0s 3ms/step - loss: 2.5462
16/16 [==============================] - 0s 2ms/step - loss: 2.5133
16/16 [==============================] - 0s 2ms/step - loss: 2.4372
16/16 [==============================] - 0s 2ms/step - loss: 2.3700
16/16 [==============================] - 0s 1ms/step - loss: 2.3467
16/16 [==============================] - 0s 2ms/step - loss: 2.3373
16/16 [==============================] - 0s 1ms/step - loss: 2.3355

Testing for epoch 57 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0879
16/16 [==============================] - 0s 1ms/step - loss: 2.1030
16/16 [==============================] - 0s 3ms/step - loss: 2.4915
16/16 [==============================] - 0s 2ms/step - loss: 2.5079
16/16 [==============================] - 0s 2ms/step - loss: 2.4754
16/16 [==============================] - 0s 3ms/step - loss: 2.3989
16/16 [==============================] - 0s 3ms/step - loss: 2.3323
16/16 [==============================] - 0s 2ms/step - loss: 2.3096
16/16 [==============================] - 0s 2ms/step - loss: 2.3006
16/16 [==============================] - 0s 2ms/step - loss: 2.2990
Epoch 58 of 60

Testing for epoch 58 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.0862
16/16 [==============================] - 0s 3ms/step - loss: 2.0546
16/16 [==============================] - 0s 5ms/step - loss: 2.4322
16/16 [==============================] - 0s 2ms/step - loss: 2.4499
16/16 [==============================] - 0s 1ms/step - loss: 2.4210
16/16 [==============================] - 0s 2ms/step - loss: 2.3513
16/16 [==============================] - 0s 3ms/step - loss: 2.2901
16/16 [==============================] - 0s 2ms/step - loss: 2.2685
16/16 [==============================] - 0s 2ms/step - loss: 2.2599
16/16 [==============================] - 0s 3ms/step - loss: 2.2584

Testing for epoch 58 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0849
16/16 [==============================] - 0s 4ms/step - loss: 2.1171
16/16 [==============================] - 0s 3ms/step - loss: 2.5045
16/16 [==============================] - 0s 5ms/step - loss: 2.5214
16/16 [==============================] - 0s 2ms/step - loss: 2.4900
16/16 [==============================] - 0s 4ms/step - loss: 2.4147
16/16 [==============================] - 0s 3ms/step - loss: 2.3485
16/16 [==============================] - 0s 5ms/step - loss: 2.3256
16/16 [==============================] - 0s 3ms/step - loss: 2.3166
16/16 [==============================] - 0s 1ms/step - loss: 2.3149

Testing for epoch 58 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.0828
16/16 [==============================] - 0s 4ms/step - loss: 2.1149
16/16 [==============================] - 0s 1ms/step - loss: 2.5037
16/16 [==============================] - 0s 2ms/step - loss: 2.5191
16/16 [==============================] - 0s 1ms/step - loss: 2.4869
16/16 [==============================] - 0s 2ms/step - loss: 2.4123
16/16 [==============================] - 0s 4ms/step - loss: 2.3460
16/16 [==============================] - 0s 3ms/step - loss: 2.3230
16/16 [==============================] - 0s 4ms/step - loss: 2.3139
16/16 [==============================] - 0s 2ms/step - loss: 2.3123

Testing for epoch 58 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0828
16/16 [==============================] - 0s 1ms/step - loss: 2.2028
16/16 [==============================] - 0s 2ms/step - loss: 2.6156
16/16 [==============================] - 0s 2ms/step - loss: 2.6338
16/16 [==============================] - 0s 1ms/step - loss: 2.6000
16/16 [==============================] - 0s 2ms/step - loss: 2.5199
16/16 [==============================] - 0s 4ms/step - loss: 2.4485
16/16 [==============================] - 0s 3ms/step - loss: 2.4235
16/16 [==============================] - 0s 1ms/step - loss: 2.4133
16/16 [==============================] - 0s 2ms/step - loss: 2.4113

Testing for epoch 58 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0845
16/16 [==============================] - 0s 3ms/step - loss: 2.1760
16/16 [==============================] - 0s 2ms/step - loss: 2.5826
16/16 [==============================] - 0s 2ms/step - loss: 2.5986
16/16 [==============================] - 0s 2ms/step - loss: 2.5625
16/16 [==============================] - 0s 1ms/step - loss: 2.4802
16/16 [==============================] - 0s 3ms/step - loss: 2.4086
16/16 [==============================] - 0s 1ms/step - loss: 2.3839
16/16 [==============================] - 0s 2ms/step - loss: 2.3739
16/16 [==============================] - 0s 3ms/step - loss: 2.3720
Epoch 59 of 60

Testing for epoch 59 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0839
16/16 [==============================] - 0s 1ms/step - loss: 2.1692
16/16 [==============================] - 0s 3ms/step - loss: 2.5681
16/16 [==============================] - 0s 1ms/step - loss: 2.5792
16/16 [==============================] - 0s 3ms/step - loss: 2.5405
16/16 [==============================] - 0s 3ms/step - loss: 2.4566
16/16 [==============================] - 0s 1ms/step - loss: 2.3842
16/16 [==============================] - 0s 2ms/step - loss: 2.3596
16/16 [==============================] - 0s 1ms/step - loss: 2.3499
16/16 [==============================] - 0s 2ms/step - loss: 2.3481

Testing for epoch 59 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0838
16/16 [==============================] - 0s 1ms/step - loss: 2.1059
16/16 [==============================] - 0s 2ms/step - loss: 2.4935
16/16 [==============================] - 0s 4ms/step - loss: 2.5120
16/16 [==============================] - 0s 5ms/step - loss: 2.4809
16/16 [==============================] - 0s 2ms/step - loss: 2.4076
16/16 [==============================] - 0s 5ms/step - loss: 2.3424
16/16 [==============================] - 0s 2ms/step - loss: 2.3194
16/16 [==============================] - 0s 1ms/step - loss: 2.3102
16/16 [==============================] - 0s 2ms/step - loss: 2.3085

Testing for epoch 59 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0858
16/16 [==============================] - 0s 3ms/step - loss: 2.0837
16/16 [==============================] - 0s 4ms/step - loss: 2.4550
16/16 [==============================] - 0s 2ms/step - loss: 2.4649
16/16 [==============================] - 0s 5ms/step - loss: 2.4289
16/16 [==============================] - 0s 3ms/step - loss: 2.3528
16/16 [==============================] - 0s 5ms/step - loss: 2.2873
16/16 [==============================] - 0s 3ms/step - loss: 2.2649
16/16 [==============================] - 0s 1ms/step - loss: 2.2560
16/16 [==============================] - 0s 2ms/step - loss: 2.2542

Testing for epoch 59 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0819
16/16 [==============================] - 0s 2ms/step - loss: 2.2194
16/16 [==============================] - 0s 1ms/step - loss: 2.6237
16/16 [==============================] - 0s 2ms/step - loss: 2.6334
16/16 [==============================] - 0s 2ms/step - loss: 2.5913
16/16 [==============================] - 0s 3ms/step - loss: 2.5024
16/16 [==============================] - 0s 3ms/step - loss: 2.4262
16/16 [==============================] - 0s 2ms/step - loss: 2.4000
16/16 [==============================] - 0s 3ms/step - loss: 2.3896
16/16 [==============================] - 0s 2ms/step - loss: 2.3876

Testing for epoch 59 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.0835
16/16 [==============================] - 0s 3ms/step - loss: 2.1086
16/16 [==============================] - 0s 3ms/step - loss: 2.4909
16/16 [==============================] - 0s 977us/step - loss: 2.5044
16/16 [==============================] - 0s 2ms/step - loss: 2.4715
16/16 [==============================] - 0s 3ms/step - loss: 2.3969
16/16 [==============================] - 0s 2ms/step - loss: 2.3307
16/16 [==============================] - 0s 1ms/step - loss: 2.3079
16/16 [==============================] - 0s 2ms/step - loss: 2.2989
16/16 [==============================] - 0s 2ms/step - loss: 2.2972
Epoch 60 of 60

Testing for epoch 60 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0798
16/16 [==============================] - 0s 2ms/step - loss: 2.1316
16/16 [==============================] - 0s 5ms/step - loss: 2.5245
16/16 [==============================] - 0s 3ms/step - loss: 2.5380
16/16 [==============================] - 0s 3ms/step - loss: 2.5019
16/16 [==============================] - 0s 1ms/step - loss: 2.4226
16/16 [==============================] - 0s 3ms/step - loss: 2.3552
16/16 [==============================] - 0s 1ms/step - loss: 2.3318
16/16 [==============================] - 0s 2ms/step - loss: 2.3224
16/16 [==============================] - 0s 2ms/step - loss: 2.3206

Testing for epoch 60 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0840
16/16 [==============================] - 0s 2ms/step - loss: 2.1644
16/16 [==============================] - 0s 3ms/step - loss: 2.5553
16/16 [==============================] - 0s 3ms/step - loss: 2.5647
16/16 [==============================] - 0s 3ms/step - loss: 2.5265
16/16 [==============================] - 0s 1ms/step - loss: 2.4439
16/16 [==============================] - 0s 2ms/step - loss: 2.3748
16/16 [==============================] - 0s 2ms/step - loss: 2.3508
16/16 [==============================] - 0s 1ms/step - loss: 2.3410
16/16 [==============================] - 0s 3ms/step - loss: 2.3390

Testing for epoch 60 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.0825
16/16 [==============================] - 0s 5ms/step - loss: 2.1426
16/16 [==============================] - 0s 2ms/step - loss: 2.5299
16/16 [==============================] - 0s 3ms/step - loss: 2.5412
16/16 [==============================] - 0s 3ms/step - loss: 2.5028
16/16 [==============================] - 0s 2ms/step - loss: 2.4226
16/16 [==============================] - 0s 3ms/step - loss: 2.3530
16/16 [==============================] - 0s 3ms/step - loss: 2.3291
16/16 [==============================] - 0s 3ms/step - loss: 2.3194
16/16 [==============================] - 0s 1ms/step - loss: 2.3175

Testing for epoch 60 index 4:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0813
16/16 [==============================] - 0s 4ms/step - loss: 2.1837
16/16 [==============================] - 0s 3ms/step - loss: 2.5842
16/16 [==============================] - 0s 4ms/step - loss: 2.5960
16/16 [==============================] - 0s 2ms/step - loss: 2.5577
16/16 [==============================] - 0s 3ms/step - loss: 2.4753
16/16 [==============================] - 0s 1ms/step - loss: 2.4040
16/16 [==============================] - 0s 3ms/step - loss: 2.3793
16/16 [==============================] - 0s 2ms/step - loss: 2.3695
16/16 [==============================] - 0s 1ms/step - loss: 2.3677

Testing for epoch 60 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.0809
16/16 [==============================] - 0s 2ms/step - loss: 2.2111
16/16 [==============================] - 0s 3ms/step - loss: 2.6163
16/16 [==============================] - 0s 5ms/step - loss: 2.6288
16/16 [==============================] - 0s 2ms/step - loss: 2.5911
16/16 [==============================] - 0s 2ms/step - loss: 2.5081
16/16 [==============================] - 0s 1ms/step - loss: 2.4362
16/16 [==============================] - 0s 2ms/step - loss: 2.4117
16/16 [==============================] - 0s 3ms/step - loss: 2.4020
16/16 [==============================] - 0s 5ms/step - loss: 2.4002
79/79 [==============================] - 0s 812us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1003">
<div class="sourceCode cell-code" id="cb421"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb421-1"><a href="#cb421-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1004">
<div class="sourceCode cell-code" id="cb422"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb422-1"><a href="#cb422-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1005">
<div class="sourceCode cell-code" id="cb423"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb423-1"><a href="#cb423-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1006">
<div class="sourceCode cell-code" id="cb424"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb424-1"><a href="#cb424-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-326-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1007">
<div class="sourceCode cell-code" id="cb427"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb427-1"><a href="#cb427-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1007">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.952058</td>
      <td>0.952058</td>
      <td>1.0</td>
      <td>0.97544</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="lscp" class="level3">
<h3 class="anchored" data-anchor-id="lscp">LSCP</h3>
<div class="cell" data-execution_count="1008">
<div class="sourceCode cell-code" id="cb428"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb428-1"><a href="#cb428-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb428-2"><a href="#cb428-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb428-3"><a href="#cb428-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb428-4"><a href="#cb428-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1009">
<div class="sourceCode cell-code" id="cb430"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb430-1"><a href="#cb430-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1010">
<div class="sourceCode cell-code" id="cb431"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb431-1"><a href="#cb431-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1011">
<div class="sourceCode cell-code" id="cb432"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb432-1"><a href="#cb432-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1012">
<div class="sourceCode cell-code" id="cb433"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb433-1"><a href="#cb433-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-332-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.980
Precision: 0.991
Recall: 0.988
F1 Score: 0.989</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1013">
<div class="sourceCode cell-code" id="cb436"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb436-1"><a href="#cb436-1" aria-hidden="true" tabindex="-1"></a>_conf.tab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1013">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.980024</td>
      <td>0.990745</td>
      <td>0.98825</td>
      <td>0.989496</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="bunny-result" class="level2">
<h2 class="anchored" data-anchor-id="bunny-result">Bunny Result</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb437"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb437-1"><a href="#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen_bunny,<span class="dv">4</span>)</span></code></pre></div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Bunny 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.913</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.990</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.884</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.958</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.989</td>
</tr>
</tbody>
</table>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-breunig2000lof" class="csl-entry" role="doc-biblioentry">
Breunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. <span>“LOF: Identifying Density-Based Local Outliers.”</span> In <em>Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</em>, 93–104.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
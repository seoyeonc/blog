{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8e90f49b-a002-4301-9656-147f3e4b8c46",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"WikiMath lag 4 Randomly Missing comparison Table\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-02-15\"\n",
    "categories:\n",
    "  - ST-GCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf50ae2-58ec-4c6e-9cc8-393c473767eb",
   "metadata": {},
   "source": [
    "> ST-GCN Dataset WikiMathsDatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71cd28-6c66-4bfa-80fb-f62d33fb2e7e",
   "metadata": {},
   "source": [
    "# WikiMathsDatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b62160-c197-4dcd-b5d8-83835c7218a5",
   "metadata": {},
   "source": [
    "A dataset of vital mathematics articles from Wikipedia. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are Wikipedia pages and edges are links between them. The graph is directed and weighted. Weights represent the number of links found at the source Wikipedia page linking to the target Wikipedia page. The target is the daily user visits to the Wikipedia pages between March 16th 2019 and March 15th 2021 which results in 731 periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97438b-ec71-40e9-bf5c-f3c5d42bf4a7",
   "metadata": {},
   "source": [
    "데이터정리 \n",
    "\n",
    "- T = 722\n",
    "- V = 위키피디아 페이지\n",
    "- N = 1068 # number of nodes \n",
    "- E = 27079 # edges \n",
    "- $f(v,t)$의 차원? (1,) # 해당페이지를 유저가 방문한 횟수 \n",
    "- 시간에 따라서 N이 변하는지? False\n",
    "- 시간에 따라서 E가 변하는지? False\n",
    "- X: (1068,8) (N,8), $f(v,t_0),f(v,t_1),f(v,t_2),f(v,t_3),f(v,t_4),f(v,t_5),f(v,t_6),f(v,t_7)$\n",
    "- y: (1068,) (N,), $f(v,t_8)$\n",
    "- 예제코드적용가능여부: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5979406-5567-4820-90d3-4d85f5943c60",
   "metadata": {},
   "source": [
    "`-` Nodes : `1068`\n",
    "\n",
    "- vertices are Wikipedia pages\n",
    "\n",
    "`-`Edges : `27079`\n",
    "\n",
    "- edges are links between them\n",
    "\n",
    "`-` Time : `722`\n",
    "\n",
    "- Wikipedia pages between March 16th 2019 and March 15th 2021\n",
    "- per weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463f6e7-0b6c-490d-b7ee-4022ce4345a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90af573-4bc0-4c9e-ad94-e9739160055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "# scipy \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import copy\n",
    "\n",
    "import rpy2.robjects.numpy2ri as rpyn\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe91df-66c9-46da-abf9-379f37061d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f9f9-20fb-489c-9a8d-0f47cf681b1e",
   "metadata": {},
   "source": [
    "# my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227faf0a-4609-4fb1-bb57-f72308e2b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'rb') as outfile:\n",
    "        data_dict = pickle.load(outfile)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159f970-32cf-4719-b3b7-d16eeb939f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict,fname):\n",
    "    with open(fname,'wb') as outfile:\n",
    "        pickle.dump(data_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2f8de-d7db-4a8a-8b56-68987ea54c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f,*args,t=None,h=2.5,**kwargs):\n",
    "    T,N = f.shape\n",
    "    if t == None: t = range(T)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots(N,1)\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "        ax[n].set_title('node='+str(n))\n",
    "    fig.set_figheight(N*h)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd30cd2-1daf-474d-b132-7b41af02e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_add(fig,f,*args,t=None,**kwargs):\n",
    "    T = f.shape[0]\n",
    "    N = f.shape[1] \n",
    "    if t == None: t = range(T)   \n",
    "    ax = fig.get_axes()\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422d968-a917-483b-8e82-4ab2bf569bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Psi(T):\n",
    "    W = np.zeros((T,T))\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            if i==j :\n",
    "                W[i,j] = 0\n",
    "            elif np.abs(i-j) <= 1 : \n",
    "                W[i,j] = 1\n",
    "    d = np.array(W.sum(axis=1))\n",
    "    D = np.diag(d)\n",
    "    L = np.array(np.diag(1/np.sqrt(d)) @ (D-W) @ np.diag(1/np.sqrt(d)))\n",
    "    lamb, Psi = np.linalg.eigh(L)\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbd67c-4d90-4d7f-9a4f-2f73dac5485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0eb4f-5518-4e35-b392-9762da230d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(f):\n",
    "    f = np.array(f)\n",
    "    if len(f.shape)==1: f = f.reshape(-1,1)\n",
    "    T,N = f.shape\n",
    "    Psi = make_Psi(T)\n",
    "    fbar = Psi.T @ f # apply dft \n",
    "    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n",
    "    fhat = Psi @ fbar_threshed # inverse dft \n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036d47a-8211-4f46-9cd3-c316e01e5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_freq_domain(signal, missing_index):\n",
    "    signal = np.array(signal)\n",
    "    T,N = signal.shape \n",
    "    signal_trimed = trim(signal)\n",
    "    for i in range(N):\n",
    "        signal[missing_index[i],i] = signal_trimed[missing_index[i],i]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7494a4-48fb-4615-8278-92c167349a86",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5df260d-2d15-4aad-aa43-6a007338235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c0532a-4145-444b-b21c-cd2527ac9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WikiMathsDatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a769d9e-6673-45a9-af2d-d2f468eb4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.get_dataset(lags=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fa5d05-33c4-4a1e-a35e-165a199bb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7bfb4-afc6-4dbe-8214-74c3ab5b54e8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6636dc51-0b08-46c3-a085-e393a97aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    data_train.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5966c5-a39b-4b70-9028-a61dfd1de3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1068, 4]),\n",
       " torch.Size([1068]),\n",
       " torch.Size([2, 27079]),\n",
       " torch.Size([27079]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a07c500-5603-47c3-bdbf-2263bce42ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f10135-8c29-4ebf-81d0-be0757442889",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = time\n",
    "N = len(data_train[0][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa85896-7946-4953-8ee3-b26fd94acd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data_train[0][1].edge_index\n",
    "edge_attr = data_train[0][1].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b676bbb5-3b7f-4124-bc07-b76bbb3ef55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(time):\n",
    "    x_train.append(data_train[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133c53ec-f888-4692-8ec2-1190210ea234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([580, 1068, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_train = data_tensor.reshape(time,1068,-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0e2332-9332-457c-838f-913c746c357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(time):\n",
    "    y_train.append(data_train[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77b6591-a226-48e1-ad80-c80c450a0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([580, 1068])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_train = data_tensor.reshape(time,1068)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a982424-a5d6-4f00-b9f9-99148e4e71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([580, 1068, 4]), torch.Size([580, 1068]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d821f1b-bddd-4df4-91f1-f80f0d34492d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85c19483-c755-45dd-9a3f-1998c4088d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    data_test.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "620a37fb-0ac2-4550-8c66-5e788cdfa0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1068, 4]),\n",
       " torch.Size([1068]),\n",
       " torch.Size([2, 27079]),\n",
       " torch.Size([27079]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c43585-3bf3-43ad-a84b-26edcc809058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80140e76-d286-4fc9-b94a-d93de15e70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_test = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cedea55-bc18-45ac-b61a-676002cf8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(time):\n",
    "    x_test.append(data_test[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b775a13-ed2c-44ef-9d53-b53a475be2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145, 1068, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_test = data_tensor.reshape(time,1068,-1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a6a387a-f862-423c-b29f-e636c8ef507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for i in range(time):\n",
    "    y_test.append(data_test[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d2c5d2c-1b76-4022-b699-39cd13649f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145, 1068])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_test = data_tensor.reshape(time,1068)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf275097-975f-4812-a385-290f49d83136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([145, 1068, 4]), torch.Size([145, 1068]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c101-5cff-4aec-9f7b-fe41c9c16b47",
   "metadata": {},
   "source": [
    "# data 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4e297-0e68-4b57-adc2-2abafc28cc03",
   "metadata": {},
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a16a8e01-944a-4b32-aba4-519372d25976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 580, 1068)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_test,T_train,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c27e81db-e176-44d4-aef7-b978e6e8fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 1056, 1063, 1065],\n",
       "        [   1,    2,    3,  ..., 1059, 1064, 1066]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = edge_index;E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8bbe9e3-5bb9-4fce-b8d0-4501388c620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "307602a2-61d2-40cd-b331-f498a8539e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 2.,  ..., 1., 1., 2.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed58fa-3cd6-428b-a6d0-52e3460d9e1f",
   "metadata": {},
   "source": [
    "`-` train / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829a2c68-3ed8-4c46-909e-fae75875f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f = torch.concat([x_train[:-1,:,0], x_train[-1,:,:].T])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ecff-ebeb-4d3f-97de-297aa69aa487",
   "metadata": {},
   "source": [
    "# Random Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c2d697-7649-4ed0-a0c7-e4b66c4fd45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Missing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.N = N\n",
    "        self.number = []\n",
    "    def miss(self,percent=0.5):\n",
    "        self.missing = copy.deepcopy(self.df)\n",
    "        self.percent = percent\n",
    "        for i in range(self.N):\n",
    "            #self.seed = np.random.choice(1000,1,replace=False)\n",
    "            #np.random.seed(self.seed)\n",
    "            self.number.append(np.random.choice(int(len(self.df))-10,int(len(self.df)*self.percent),replace=False))\n",
    "            self.missing[self.number[i],i] = float('nan')\n",
    "    def first_mean(self):\n",
    "        self.train_mean = np.array(copy.deepcopy(self.missing))\n",
    "        for i in range(self.N):\n",
    "            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n",
    "    def second_linear(self):\n",
    "        self.train_linear = pd.DataFrame(self.missing.tolist())\n",
    "        self.train_linear.interpolate(method='linear', inplace=True)\n",
    "        self.train_linear = self.train_linear.fillna(0)\n",
    "        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0b4a0ee-df6b-410e-b95a-dbe6752b777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n",
    "\n",
    "rate = [i/10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9d407-a7b9-4d9c-90cf-390558a2a54d",
   "metadata": {},
   "source": [
    "# Class code by Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a576f-5751-460a-a374-8bf2f81d3e1c",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b18f97f-1fff-4d70-8d46-39416d954b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[j:(T_train+j),:] for j in range(self.lag)],axis = -1)).float()\n",
    "            y = torch.tensor(interpolated_signal[self.lag:,:]).float()\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            for epoch in range(50):\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):\n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_stgcn = (((self.real_y-yhat.squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_stgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "    \n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08d9a7-1069-4489-9ba2-fcc79361f45c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64c6ba31-a25e-405c-a410-4292d11a6da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESTGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            signal = interpolated_signal.copy()\n",
    "            for epoch in range(50):\n",
    "                signal = update_from_freq_domain(signal,missing_index)\n",
    "                X = torch.tensor(np.stack([signal[i:(T_train+epoch+i),:] for i in range(self.lag)],axis = -1)).reshape(-1,N,self.lag).float()\n",
    "                y = torch.tensor(signal).reshape(-1,N,1).float()[self.lag:,:,:]\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):        \n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_estgcn = (((self.real_y-yhat[:T_train,:].squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_estgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a30f7a-7435-4a8a-8685-a672b75e5764",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2768a07-6c2e-4232-8019-e94bd7dc2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63fcce33-58b6-4554-a297-aa4e6d3de83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: igraph\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: wordcloud\n",
      "\n",
      "R[write to console]: Loading required package: RColorBrewer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(GNAR)\n",
    "library(igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14d0be46-6771-456f-8631-63b040a834b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNAR = importr('GNAR') # import GNAR \n",
    "igraph = importr('igraph') # import igraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75b50b1f-e8bf-49d2-a2c5-a790edb0cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.zeros((N,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "037ccd50-0c8e-4594-9a84-caef6a766b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(edge_index[0])):\n",
    "    w[edge_index[0][k],edge_index[1][k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc149481-7248-4d81-8346-29365afc9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = robjects.r.matrix(FloatVector(w), nrow = N, ncol = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec363634-a385-4630-bd95-6c5dc578d4ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNAR_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.yy = torch.tensor(y_test).float()\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[i:(T_train-self.lag+i),:] for i in range(self.lag)],axis = -1)).float()\n",
    "\n",
    "            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = T_train, ncol = N),net = GNAR.matrixtoGNAR(m), alphaOrder = 4, betaOrder = FloatVector([1, 1, 1, 1]))             \n",
    "            predict = GNAR.predict_GNARfit(answer,n_ahead=T_test)\n",
    "\n",
    "\n",
    "            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,N))**2).mean()\n",
    "            test_mse_total_gnar = ((self.yy - pd.DataFrame(predict).values.reshape(-1,N))**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423800d-629b-4e4a-8452-3285f5caecd8",
   "metadata": {},
   "source": [
    "## STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8e2d68b-4e7d-4b53-9250-94b3188a13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'WikiMaths'\n",
    "Method = 'stgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6328e579-7161-40d3-8fb4-102c60db59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stgcn= pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe554f0-a332-4c67-b962-433d755489fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    stgcn.iter()\n",
    "    df_add = stgcn.df.copy()\n",
    "    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a4cd8-8420-4e85-a3ba-2ea115046627",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_stgcn, './data/Wiki_stgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b0839-0ce0-4e9c-9117-55edbfb8b56e",
   "metadata": {},
   "source": [
    "## Enhencement of STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cde8e-4610-475d-bbb6-657161d373b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'WikiMaths'\n",
    "Method = 'estgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733fa44-711f-48a9-9971-af915965b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estgcn = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b6cb2-ae36-4a27-82d7-26f70f30cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    estgcn.iter()\n",
    "    df_add = estgcn.df.copy()\n",
    "    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58467a0e-94fa-4e69-b96b-faff96839840",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_estgcn, './data/Wiki_estgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f435b52-7a28-4f9c-8876-92532e600406",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc596277-a478-452d-8562-a63da5917aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'WikiMaths'\n",
    "Method = 'gnar' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e1322-d0e0-4583-a204-9051ab42b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnar = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b91f98-b152-466b-86ed-a807f306b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    gnar = GNAR_Missing(Dataset, df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    gnar.iter()\n",
    "    df_add = gnar.df.copy()\n",
    "    df_gnar = pd.concat([df_gnar,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d81f39-8c51-473f-b9c1-431372106038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_gnar, './data/Wiki_gnar_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a130b81-8606-4e2d-ba03-d7f2b9a3ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

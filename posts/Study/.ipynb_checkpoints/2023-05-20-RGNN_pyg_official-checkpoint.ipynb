{
 "cells": [
  {
   "cell_type": "raw",
   "id": "66e10ec9-b4f5-4d9f-a1da-28692f967e03",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Recurrent Graph Neural Network\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-05-20\"\n",
    "categories:\n",
    "  - RGNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062b351-cd14-4229-8cb6-8c74e780703d",
   "metadata": {},
   "source": [
    "> RGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1fc2d-001d-4743-b1df-cbb3b4ca016f",
   "metadata": {},
   "source": [
    "ref : [official](https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html#official-examples), [vlog](https://medium.com/watcha/gnn-%EC%86%8C%EA%B0%9C-%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EB%85%BC%EB%AC%B8%EA%B9%8C%EC%A7%80-96567b783479), [IEEE](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4700287)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933a125-6fb4-427c-938f-335aaac6531d",
   "metadata": {},
   "source": [
    "my own summary 메세지 전달 방식으로 메세지를 전달하고 업데이트하는 과정을 통해 수렴 조건을 만족할때까지 x의 상태를 업데이트하는 학습과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619896dc-59e6-40fa-9b8c-edc34c7045a2",
   "metadata": {},
   "source": [
    "# Recurrent Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4de36d-6bda-484e-8c38-03b819b887aa",
   "metadata": {},
   "source": [
    "*Based on* [Banach Fixed Point Thm.](https://en.wikipedia.org/wiki/Banach_fixed-point_theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a9986-f509-4215-ab8f-304fc38b08d2",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "완비 거리 공간 $(x,d)$\n",
    "\n",
    "축약 사상 $T : X \\to X$ 축약 상수^[일정 값까지만 거리로 봄](Lipschitz continuity) $k \\in [0,1)$\n",
    "\n",
    "즉, $d(T(x),T(y) \\le k d(x,y)$\n",
    "\n",
    "1. $T$는 유일한 고정점 $\\bar{x} \\in X$를 갖는다.\n",
    "\n",
    "2. 임의의 $x \\in X$에 대해 $lim_{n \\to \\infty} T^n (x) = \\bar{x}$\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133f7e0-de9e-471e-a1fa-69f7ffbaa005",
   "metadata": {},
   "source": [
    "$$x_{v}^{t+1} = f_w(l_v , l_{co(v)}, x^t_{ne(v)}, l_{ne(v)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9264810-e656-4786-b2e2-c0d9913571c9",
   "metadata": {},
   "source": [
    "- $l_v$ 는 node 의 feature\n",
    "- $l_{co(v)}$ 는 line between nodes의 feature\n",
    "- $x^t_{ne(v)}$ 는 node와 연결된 node들의 상태\n",
    "- $l_{ne(v)})$ 는 node와 연결된 line들의 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc567b-3e0f-4beb-ad04-d14b1d64a559",
   "metadata": {},
   "source": [
    "$$o^t_v = g_w(x^t_v, l_v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc0f1a-0cb3-4b56-9b9a-1e1f48d365be",
   "metadata": {},
   "source": [
    "# Tutorial 9: Recurrent GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a7b07-f6ec-40fe-aad9-41915338cde1",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial we will implement an approximation of the Graph Neural Network Model (without enforcing contraction map) and analyze the GatedGraph Convolution of Pytorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd1124-502f-4bfb-a88c-67f0d6085534",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0363984b-2531-4531-a68a-f380d766af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch.nn import Parameter as Param\n",
    "from torch import Tensor \n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dfb0f6-44cd-4ece-8dec-340e11b6fccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f64b9c6d470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271d8571-4d1b-45a2-9171-278ea2e2c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026e6daf-17a3-41dc-b8e9-ba9685427279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "transform = T.Compose([\n",
    "    T.RandomNodeSplit('train_rest', num_val=500, num_test=500),\n",
    "    T.TargetIndegree(),\n",
    "])\n",
    "path = osp.join('data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a300f96a-8c44-4385-a643-561ac7e34cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a908f7-0845-4576-8962-9b3dbf710ade",
   "metadata": {},
   "source": [
    "$$x_{v}^{t+1} = f_w(l_v , l_{co(v)}, x^t_{ne(v)}, l_{ne(v)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5020588-a078-4679-a907-77b0a2ebffdc",
   "metadata": {},
   "source": [
    "$$o^t_v = g_w(x^t_v, l_v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78501617-b77f-4507-b0f1-03c5625adaa5",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8b04e-fc21-4f89-ba2a-60d63adce07a",
   "metadata": {},
   "source": [
    "The MLP class is used to instantiate the transition and output functions as simple feed forard networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8634959-26d3-419d-8611-6446b3fa4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dims, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential()\n",
    "        dims = [input_dim] + hid_dims + [out_dim]\n",
    "        for i in range(len(dims)-1):\n",
    "            self.mlp.add_module('lay_{}'.format(i),nn.Linear(in_features=dims[i], out_features=dims[i+1]))\n",
    "            if i+2 < len(dims):\n",
    "                self.mlp.add_module('act_{}'.format(i), nn.Tanh())\n",
    "    def reset_parameters(self):\n",
    "        for i, l in enumerate(self.mlp):\n",
    "            if type(l) == nn.Linear:\n",
    "                nn.init.xavier_normal_(l.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4de4ef-3fe2-40b8-9fa8-d12888a4a4d1",
   "metadata": {},
   "source": [
    "## Graph Neural Network MessagePassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e63cf9-3446-4761-a219-5f8285f9bb48",
   "metadata": {},
   "source": [
    "The GNNM calss puts together the state propagations and the readout of the nodes' states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133cdfe2-eca1-4548-a2e4-ffb1abd8bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNM(MessagePassing):\n",
    "    def __init__(self, n_nodes, out_channels, features_dim, hid_dims, num_layers = 50, eps=1e-3, aggr = 'add',\n",
    "                 bias = True, **kwargs):\n",
    "        super(GNNM, self).__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.node_states = Param(torch.zeros((n_nodes, features_dim)), requires_grad=False)\n",
    "        self.out_channels = out_channels\n",
    "        self.eps = eps\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.transition = MLP(features_dim, hid_dims, features_dim)\n",
    "        self.readout = MLP(features_dim, hid_dims, out_channels)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        print(self.transition)\n",
    "        print(self.readout)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.transition.reset_parameters()\n",
    "        self.readout.reset_parameters()\n",
    "        \n",
    "    def forward(self): \n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_attr\n",
    "        node_states = self.node_states\n",
    "        for i in range(self.num_layers):\n",
    "            m = self.propagate(edge_index, x=node_states, edge_weight=edge_weight,\n",
    "                               size=None)\n",
    "            new_states = self.transition(m)\n",
    "            with torch.no_grad():\n",
    "                distance = torch.norm(new_states - node_states, dim=1)\n",
    "                convergence = distance < self.eps\n",
    "            node_states = new_states\n",
    "            if convergence.all():\n",
    "                break\n",
    "            \n",
    "        out = self.readout(node_states)\n",
    "        \n",
    "        return F.log_softmax(out, dim=-1)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x) :\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, num_layers={})'.format(self.__class__.__name__,\n",
    "                                              self.out_channels,\n",
    "                                              self.num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08af19c5-146f-4dc4-8b7a-3f146e5b6dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (lay_0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (act_0): Tanh()\n",
      "    (lay_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_1): Tanh()\n",
      "    (lay_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_2): Tanh()\n",
      "    (lay_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_3): Tanh()\n",
      "    (lay_4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_4): Tanh()\n",
      "    (lay_5): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      ")\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (lay_0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (act_0): Tanh()\n",
      "    (lay_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_1): Tanh()\n",
      "    (lay_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_2): Tanh()\n",
      "    (lay_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_3): Tanh()\n",
      "    (lay_4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (act_4): Tanh()\n",
      "    (lay_5): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GNNM(data.num_nodes, dataset.num_classes, 32, [64,64,64,64,64], eps=0.01).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830398e7-3eba-4c37-995b-1d5c699c02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset)\n",
    "train_loader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47066619-e352-402e-80aa-b1773944881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.12857, Val Acc: 0.14200, Test Acc: 0.13700\n",
      "Epoch: 002, Train Acc: 0.13571, Val Acc: 0.15800, Test Acc: 0.14200\n",
      "Epoch: 003, Train Acc: 0.08571, Val Acc: 0.09000, Test Acc: 0.06600\n",
      "Epoch: 004, Train Acc: 0.14286, Val Acc: 0.20800, Test Acc: 0.20800\n",
      "Epoch: 005, Train Acc: 0.15714, Val Acc: 0.27400, Test Acc: 0.28600\n",
      "Epoch: 006, Train Acc: 0.11429, Val Acc: 0.24000, Test Acc: 0.24000\n",
      "Epoch: 007, Train Acc: 0.15000, Val Acc: 0.17800, Test Acc: 0.18000\n",
      "Epoch: 008, Train Acc: 0.17143, Val Acc: 0.12400, Test Acc: 0.11800\n",
      "Epoch: 009, Train Acc: 0.17143, Val Acc: 0.07600, Test Acc: 0.07900\n",
      "Epoch: 010, Train Acc: 0.14286, Val Acc: 0.05800, Test Acc: 0.06700\n",
      "Epoch: 011, Train Acc: 0.15714, Val Acc: 0.10200, Test Acc: 0.09900\n",
      "Epoch: 012, Train Acc: 0.18571, Val Acc: 0.12000, Test Acc: 0.11300\n",
      "Epoch: 013, Train Acc: 0.17857, Val Acc: 0.11600, Test Acc: 0.11400\n",
      "Epoch: 014, Train Acc: 0.18571, Val Acc: 0.12800, Test Acc: 0.11900\n",
      "Epoch: 015, Train Acc: 0.22143, Val Acc: 0.10800, Test Acc: 0.11800\n",
      "Epoch: 016, Train Acc: 0.18571, Val Acc: 0.11400, Test Acc: 0.13700\n",
      "Epoch: 017, Train Acc: 0.20000, Val Acc: 0.13600, Test Acc: 0.12000\n",
      "Epoch: 018, Train Acc: 0.19286, Val Acc: 0.13200, Test Acc: 0.11700\n",
      "Epoch: 019, Train Acc: 0.20714, Val Acc: 0.13200, Test Acc: 0.12400\n",
      "Epoch: 020, Train Acc: 0.22143, Val Acc: 0.14200, Test Acc: 0.13600\n",
      "Epoch: 021, Train Acc: 0.21429, Val Acc: 0.15000, Test Acc: 0.14200\n",
      "Epoch: 022, Train Acc: 0.21429, Val Acc: 0.12800, Test Acc: 0.11600\n",
      "Epoch: 023, Train Acc: 0.20000, Val Acc: 0.13000, Test Acc: 0.11600\n",
      "Epoch: 024, Train Acc: 0.21429, Val Acc: 0.12800, Test Acc: 0.11500\n",
      "Epoch: 025, Train Acc: 0.21429, Val Acc: 0.12600, Test Acc: 0.11500\n",
      "Epoch: 026, Train Acc: 0.21429, Val Acc: 0.12800, Test Acc: 0.11700\n",
      "Epoch: 027, Train Acc: 0.20000, Val Acc: 0.14800, Test Acc: 0.13600\n",
      "Epoch: 028, Train Acc: 0.22857, Val Acc: 0.14800, Test Acc: 0.13700\n",
      "Epoch: 029, Train Acc: 0.20714, Val Acc: 0.13600, Test Acc: 0.13000\n",
      "Epoch: 030, Train Acc: 0.20714, Val Acc: 0.14200, Test Acc: 0.13100\n",
      "Epoch: 031, Train Acc: 0.21429, Val Acc: 0.15600, Test Acc: 0.14400\n",
      "Epoch: 032, Train Acc: 0.22143, Val Acc: 0.14800, Test Acc: 0.14500\n",
      "Epoch: 033, Train Acc: 0.21429, Val Acc: 0.13400, Test Acc: 0.13000\n",
      "Epoch: 034, Train Acc: 0.22857, Val Acc: 0.13000, Test Acc: 0.12300\n",
      "Epoch: 035, Train Acc: 0.22143, Val Acc: 0.13200, Test Acc: 0.12100\n",
      "Epoch: 036, Train Acc: 0.20000, Val Acc: 0.13200, Test Acc: 0.12400\n",
      "Epoch: 037, Train Acc: 0.21429, Val Acc: 0.12400, Test Acc: 0.12800\n",
      "Epoch: 038, Train Acc: 0.23571, Val Acc: 0.14800, Test Acc: 0.13700\n",
      "Epoch: 039, Train Acc: 0.22143, Val Acc: 0.14400, Test Acc: 0.14500\n",
      "Epoch: 040, Train Acc: 0.23571, Val Acc: 0.14800, Test Acc: 0.15300\n",
      "Epoch: 041, Train Acc: 0.23571, Val Acc: 0.15600, Test Acc: 0.14800\n",
      "Epoch: 042, Train Acc: 0.23571, Val Acc: 0.16600, Test Acc: 0.15300\n",
      "Epoch: 043, Train Acc: 0.23571, Val Acc: 0.16000, Test Acc: 0.15500\n",
      "Epoch: 044, Train Acc: 0.22143, Val Acc: 0.15600, Test Acc: 0.14600\n",
      "Epoch: 045, Train Acc: 0.24286, Val Acc: 0.15400, Test Acc: 0.15600\n",
      "Epoch: 046, Train Acc: 0.22857, Val Acc: 0.14800, Test Acc: 0.14100\n",
      "Epoch: 047, Train Acc: 0.24286, Val Acc: 0.15800, Test Acc: 0.14100\n",
      "Epoch: 048, Train Acc: 0.22857, Val Acc: 0.16000, Test Acc: 0.14300\n",
      "Epoch: 049, Train Acc: 0.24286, Val Acc: 0.15800, Test Acc: 0.14300\n",
      "Epoch: 050, Train Acc: 0.23571, Val Acc: 0.17000, Test Acc: 0.15100\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_fn(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    train()\n",
    "    accs = test()\n",
    "    train_acc = accs[0]\n",
    "    val_acc = accs[1]\n",
    "    test_acc = accs[2]\n",
    "    print('Epoch: {:03d}, Train Acc: {:.5f}, '\n",
    "          'Val Acc: {:.5f}, Test Acc: {:.5f}'.format(epoch, train_acc,\n",
    "                                                       val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db96b6f-8eb3-4439-b2b7-cbf1c87a9005",
   "metadata": {},
   "source": [
    "## Gated Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb3c6e5-b7c4-462a-b555-6d134c5f8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedGraphConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self, out_channels, num_layers, aggr = 'add',\n",
    "                 bias = True, **kwargs):\n",
    "        super(GatedGraphConv, self).__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.weight = Param(Tensor(num_layers, out_channels, out_channels))\n",
    "        self.rnn = torch.nn.GRUCell(out_channels, out_channels, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        uniform(self.out_channels, self.weight)\n",
    "        self.rnn.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\"\"\"\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_attr\n",
    "        if x.size(-1) > self.out_channels:\n",
    "            raise ValueError('The number of input channels is not allowed to '\n",
    "                             'be larger than the number of output channels')\n",
    "\n",
    "        if x.size(-1) < self.out_channels:\n",
    "            zero = x.new_zeros(x.size(0), self.out_channels - x.size(-1))\n",
    "            x = torch.cat([x, zero], dim=1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            m = torch.matmul(x, self.weight[i])\n",
    "            m = self.propagate(edge_index, x=m, edge_weight=edge_weight,\n",
    "                               size=None)\n",
    "            x = self.rnn(m, x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, num_layers={})'.format(self.__class__.__name__,\n",
    "                                              self.out_channels,\n",
    "                                              self.num_layers)\n",
    "\n",
    "class GGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GGNN, self).__init__()\n",
    "        \n",
    "        self.conv = GatedGraphConv(1433, 3)\n",
    "        self.mlp = MLP(1433, [32,32,32], dataset.num_classes)\n",
    "        \n",
    "    def forward(self):\n",
    "        x = self.conv(data)\n",
    "        x = self.mlp(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97b4236-94b6-4d2c-ac45-6498ddfdda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = GGNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21fbb86a-bea1-4ede-9eff-394ec698c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset)\n",
    "train_loader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6c1440-8cd9-497a-b4e0-98a39e73bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.15000, Val Acc: 0.16400, Test Acc: 0.16700\n",
      "Epoch: 002, Train Acc: 0.14286, Val Acc: 0.12200, Test Acc: 0.13000\n",
      "Epoch: 003, Train Acc: 0.32857, Val Acc: 0.22600, Test Acc: 0.23500\n",
      "Epoch: 004, Train Acc: 0.37143, Val Acc: 0.27600, Test Acc: 0.27800\n",
      "Epoch: 005, Train Acc: 0.41429, Val Acc: 0.29200, Test Acc: 0.31600\n",
      "Epoch: 006, Train Acc: 0.50000, Val Acc: 0.33600, Test Acc: 0.36400\n",
      "Epoch: 007, Train Acc: 0.52857, Val Acc: 0.33200, Test Acc: 0.34000\n",
      "Epoch: 008, Train Acc: 0.54286, Val Acc: 0.34000, Test Acc: 0.35400\n",
      "Epoch: 009, Train Acc: 0.55714, Val Acc: 0.34800, Test Acc: 0.36000\n",
      "Epoch: 010, Train Acc: 0.56429, Val Acc: 0.37200, Test Acc: 0.37300\n",
      "Epoch: 011, Train Acc: 0.61429, Val Acc: 0.42800, Test Acc: 0.41300\n",
      "Epoch: 012, Train Acc: 0.64286, Val Acc: 0.45000, Test Acc: 0.44700\n",
      "Epoch: 013, Train Acc: 0.79286, Val Acc: 0.56000, Test Acc: 0.56200\n",
      "Epoch: 014, Train Acc: 0.82857, Val Acc: 0.58600, Test Acc: 0.58300\n",
      "Epoch: 015, Train Acc: 0.77857, Val Acc: 0.57200, Test Acc: 0.56700\n",
      "Epoch: 016, Train Acc: 0.80000, Val Acc: 0.58200, Test Acc: 0.58700\n",
      "Epoch: 017, Train Acc: 0.85714, Val Acc: 0.62000, Test Acc: 0.61000\n",
      "Epoch: 018, Train Acc: 0.87857, Val Acc: 0.61800, Test Acc: 0.61800\n",
      "Epoch: 019, Train Acc: 0.90000, Val Acc: 0.62200, Test Acc: 0.63300\n",
      "Epoch: 020, Train Acc: 0.92143, Val Acc: 0.65800, Test Acc: 0.66000\n",
      "Epoch: 021, Train Acc: 0.94286, Val Acc: 0.66400, Test Acc: 0.66900\n",
      "Epoch: 022, Train Acc: 0.95000, Val Acc: 0.68200, Test Acc: 0.68100\n",
      "Epoch: 023, Train Acc: 0.96429, Val Acc: 0.69200, Test Acc: 0.69400\n",
      "Epoch: 024, Train Acc: 0.97143, Val Acc: 0.70000, Test Acc: 0.70500\n",
      "Epoch: 025, Train Acc: 0.97143, Val Acc: 0.69400, Test Acc: 0.70700\n",
      "Epoch: 026, Train Acc: 0.97143, Val Acc: 0.69600, Test Acc: 0.70300\n",
      "Epoch: 027, Train Acc: 0.97143, Val Acc: 0.69000, Test Acc: 0.70000\n",
      "Epoch: 028, Train Acc: 0.97857, Val Acc: 0.69000, Test Acc: 0.69600\n",
      "Epoch: 029, Train Acc: 0.97857, Val Acc: 0.68200, Test Acc: 0.69500\n",
      "Epoch: 030, Train Acc: 0.97857, Val Acc: 0.68200, Test Acc: 0.69300\n",
      "Epoch: 031, Train Acc: 0.97857, Val Acc: 0.68000, Test Acc: 0.69300\n",
      "Epoch: 032, Train Acc: 0.97857, Val Acc: 0.68400, Test Acc: 0.70300\n",
      "Epoch: 033, Train Acc: 0.98571, Val Acc: 0.68400, Test Acc: 0.70400\n",
      "Epoch: 034, Train Acc: 0.98571, Val Acc: 0.68200, Test Acc: 0.70100\n",
      "Epoch: 035, Train Acc: 0.98571, Val Acc: 0.67200, Test Acc: 0.70600\n",
      "Epoch: 036, Train Acc: 0.98571, Val Acc: 0.67000, Test Acc: 0.70300\n",
      "Epoch: 037, Train Acc: 0.98571, Val Acc: 0.67200, Test Acc: 0.70400\n",
      "Epoch: 038, Train Acc: 0.98571, Val Acc: 0.67600, Test Acc: 0.70700\n",
      "Epoch: 039, Train Acc: 0.98571, Val Acc: 0.67600, Test Acc: 0.70600\n",
      "Epoch: 040, Train Acc: 0.98571, Val Acc: 0.67800, Test Acc: 0.70900\n",
      "Epoch: 041, Train Acc: 0.98571, Val Acc: 0.68200, Test Acc: 0.71400\n",
      "Epoch: 042, Train Acc: 0.98571, Val Acc: 0.68400, Test Acc: 0.71500\n",
      "Epoch: 043, Train Acc: 0.98571, Val Acc: 0.68200, Test Acc: 0.71700\n",
      "Epoch: 044, Train Acc: 0.98571, Val Acc: 0.68000, Test Acc: 0.71500\n",
      "Epoch: 045, Train Acc: 0.98571, Val Acc: 0.68000, Test Acc: 0.71500\n",
      "Epoch: 046, Train Acc: 0.98571, Val Acc: 0.68200, Test Acc: 0.71600\n",
      "Epoch: 047, Train Acc: 0.98571, Val Acc: 0.68000, Test Acc: 0.71600\n",
      "Epoch: 048, Train Acc: 0.98571, Val Acc: 0.67800, Test Acc: 0.72000\n",
      "Epoch: 049, Train Acc: 0.98571, Val Acc: 0.67800, Test Acc: 0.72100\n",
      "Epoch: 050, Train Acc: 0.99286, Val Acc: 0.68600, Test Acc: 0.72400\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_fn(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    train()\n",
    "    accs = test()\n",
    "    train_acc = accs[0]\n",
    "    val_acc = accs[1]\n",
    "    test_acc = accs[2]\n",
    "    print('Epoch: {:03d}, Train Acc: {:.5f}, '\n",
    "          'Val Acc: {:.5f}, Test Acc: {:.5f}'.format(epoch, train_acc,\n",
    "                                                       val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e8cec-25d1-43d5-952e-fe1f7fe8bec6",
   "metadata": {},
   "source": [
    "## Additoinal review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1a1d0a5-1e3d-42b2-ae5c-2d975e0edccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mMessagePassing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maggr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAggregation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maggr_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnode_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecomposed_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Base class for creating message passing layers of the form\n",
       "\n",
       ".. math::\n",
       "    \\mathbf{x}_i^{\\prime} = \\gamma_{\\mathbf{\\Theta}} \\left( \\mathbf{x}_i,\n",
       "    \\bigoplus_{j \\in \\mathcal{N}(i)} \\, \\phi_{\\mathbf{\\Theta}}\n",
       "    \\left(\\mathbf{x}_i, \\mathbf{x}_j,\\mathbf{e}_{j,i}\\right) \\right),\n",
       "\n",
       "where :math:`\\bigoplus` denotes a differentiable, permutation invariant\n",
       "function, *e.g.*, sum, mean, min, max or mul, and\n",
       ":math:`\\gamma_{\\mathbf{\\Theta}}` and :math:`\\phi_{\\mathbf{\\Theta}}` denote\n",
       "differentiable functions such as MLPs.\n",
       "See `here <https://pytorch-geometric.readthedocs.io/en/latest/tutorial/\n",
       "create_gnn.html>`__ for the accompanying tutorial.\n",
       "\n",
       "Args:\n",
       "    aggr (str or [str] or Aggregation, optional): The aggregation scheme\n",
       "        to use, *e.g.*, :obj:`\"add\"`, :obj:`\"sum\"` :obj:`\"mean\"`,\n",
       "        :obj:`\"min\"`, :obj:`\"max\"` or :obj:`\"mul\"`.\n",
       "        In addition, can be any\n",
       "        :class:`~torch_geometric.nn.aggr.Aggregation` module (or any string\n",
       "        that automatically resolves to it).\n",
       "        If given as a list, will make use of multiple aggregations in which\n",
       "        different outputs will get concatenated in the last dimension.\n",
       "        If set to :obj:`None`, the :class:`MessagePassing` instantiation is\n",
       "        expected to implement its own aggregation logic via\n",
       "        :meth:`aggregate`. (default: :obj:`\"add\"`)\n",
       "    aggr_kwargs (Dict[str, Any], optional): Arguments passed to the\n",
       "        respective aggregation function in case it gets automatically\n",
       "        resolved. (default: :obj:`None`)\n",
       "    flow (str, optional): The flow direction of message passing\n",
       "        (:obj:`\"source_to_target\"` or :obj:`\"target_to_source\"`).\n",
       "        (default: :obj:`\"source_to_target\"`)\n",
       "    node_dim (int, optional): The axis along which to propagate.\n",
       "        (default: :obj:`-2`)\n",
       "    decomposed_layers (int, optional): The number of feature decomposition\n",
       "        layers, as introduced in the `\"Optimizing Memory Efficiency of\n",
       "        Graph Neural Networks on Edge Computing Platforms\"\n",
       "        <https://arxiv.org/abs/2104.03058>`_ paper.\n",
       "        Feature decomposition reduces the peak memory usage by slicing\n",
       "        the feature dimensions into separated feature decomposition layers\n",
       "        during GNN aggregation.\n",
       "        This method can accelerate GNN execution on CPU-based platforms\n",
       "        (*e.g.*, 2-3x speedup on the\n",
       "        :class:`~torch_geometric.datasets.Reddit` dataset) for common GNN\n",
       "        models such as :class:`~torch_geometric.nn.models.GCN`,\n",
       "        :class:`~torch_geometric.nn.models.GraphSAGE`,\n",
       "        :class:`~torch_geometric.nn.models.GIN`, etc.\n",
       "        However, this method is not applicable to all GNN operators\n",
       "        available, in particular for operators in which message computation\n",
       "        can not easily be decomposed, *e.g.* in attention-based GNNs.\n",
       "        The selection of the optimal value of :obj:`decomposed_layers`\n",
       "        depends both on the specific graph dataset and available hardware\n",
       "        resources.\n",
       "        A value of :obj:`2` is suitable in most cases.\n",
       "        Although the peak memory usage is directly associated with the\n",
       "        granularity of feature decomposition, the same is not necessarily\n",
       "        true for execution speedups. (default: :obj:`1`)\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     SimpleConv, GCNConv, ChebConv, SAGEConv, GraphConv, GravNetConv, GatedGraphConv, ResGatedGraphConv, GATConv, GATv2Conv, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MessagePassing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871c970-7b22-408a-96bc-fb6a9e810c5d",
   "metadata": {},
   "source": [
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c12d187-5ddf-4f3d-8eb8-f10c3cf2b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 두 개의 행렬 생성\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "# matmul을 사용하여 두 행렬의 곱셈 수행\n",
    "C = np.matmul(A, B)\n",
    "\n",
    "# 결과 출력\n",
    "print(C)\n",
    "# [[1*5+2*7  2*5+4*7\n",
    "#   3*5+4*7  3*6+4*8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6fb12-4945-4407-b07c-eb6f46940381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbafb9-3919-489b-979b-72c40da933f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2adc05e-62b8-4444-ae02-1d3ee2569aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b071cf-2d92-4124-93d2-c278c4c4a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a902bab-14f5-4f79-bc1b-472c4bf00781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9059d92-62f9-4043-8c13-641e1ec5cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fc789-1bdd-4145-8e9d-ce424b04a8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a61aee-98ba-4567-95f2-2cb3d59765a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337f3bc-f3af-4a2e-b967-6547606909bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce9d73-4aa5-4703-b2c2-c7330a85a29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8df6a-b817-47a3-894c-fccf8c4fcfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b2e04-8dcc-4caf-a435-0bc76bfea14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c31119-89ba-4a2d-9bd8-2503558b248d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d0bd3-f5f3-42c6-9e9d-73f0cf147108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d858620-2afb-4ddb-b7b1-602cf337ba33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d62a4a-8a1b-4041-a959-d7adf9d97042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a1884-f400-4431-9bbb-16deab3e7e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd4f88-a66c-4d24-86de-1eb36c7119c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabd323-f7f3-47a3-911a-894a9382e044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da54aef-e5de-49ee-a222-d7b237e6b961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fb82b-3200-437c-bfb4-d6faee38c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204b681-d15e-4506-87af-52a3f897b188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

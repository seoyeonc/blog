<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2023-07-03">

<title>Seoyeon’s Blog for study - Other Outlier Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for study</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/blog/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Other Outlier Detection</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Other Outlier Detection</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">GODE</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">FRAUD</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/FRAUD/2023-07-10-fraud_data.html" class="sidebar-item-text sidebar-link">Fraud data</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GCN/index.html" class="sidebar-item-text sidebar-link">GCN</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-29-STGCN-tutorial.html" class="sidebar-item-text sidebar-link"><strong>[IT-STGCN]</strong> STGCN 튜토리얼</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin.html" class="sidebar-item-text sidebar-link">1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-20-Algorithm_traintest.html" class="sidebar-item-text sidebar-link">1st ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-20-ESTGCN_GNAR_edit_guebin2.html" class="sidebar-item-text sidebar-link">2nd ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-18-Algorithm_traintest_2.html" class="sidebar-item-text sidebar-link">2nd ST-GCN Example dividing train and test</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-27-AddingtheRecurrentGCNmodels.html" class="sidebar-item-text sidebar-link">Adding the RecurrentGCN models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-guebin.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-21-Class.html" class="sidebar-item-text sidebar-link">Class of Method</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_GNAR_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_3.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 1 80% Missing repeat</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-06-ESTGCN_GNAR_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(GNAR) lag 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-02-07-ESTGCN_WIKI_DATA_2.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-26-ESTGCN_WIKI_DATA.html" class="sidebar-item-text sidebar-link">Class of Method(WikiMath) lag 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-20-data load, data save as pickle.html" class="sidebar-item-text sidebar-link">data load, data save as pickle</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-05-ITSTGCN_data_management.html" class="sidebar-item-text sidebar-link">Data management for ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-13-DCRNN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DCRNN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-28-DYGRENCODER_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">DYGRENCODER_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-20-EbayesThresh toy ex.html" class="sidebar-item-text sidebar-link">EbayesThresh Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-01-EvolveGCNH_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNH_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-25-EvolveGCNO_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">EvolveGCNO_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-06-GCLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GCLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-11-Algorithm_EX_1.html" class="sidebar-item-text sidebar-link">GCN Algorithm Example 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU and GNAR_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-25-GCONVGRU_snd_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Boxplot_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-xx_GCONVGRU_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvGRU_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-30-GConvLSTM_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">GConvLSTM_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-01-05-GNAR.html" class="sidebar-item-text sidebar-link">GNAR data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-05-31-Other Method.html" class="sidebar-item-text sidebar-link">ITSTGCN add Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-06-article_refer.html" class="sidebar-item-text sidebar-link">ITSTGCN Article Refernece</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-17-ITSTGCN-Tutorial.html" class="sidebar-item-text sidebar-link">ITSTGCN-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-19-LRGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">LRGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-06-METRLADatasetLoader.html" class="sidebar-item-text sidebar-link">METRLADatasetLoader-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-25-note_matrix.html" class="sidebar-item-text sidebar-link">Note_weight amatrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-29-pedalme_GSO_st.html" class="sidebar-item-text sidebar-link">Padalme GSO_st</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-CPUvsGPU.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal CPU vs GPU</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-11-PyGGeometricTemporalEx.html" class="sidebar-item-text sidebar-link">PyG Geometric Temporal Examples</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-21-ST-GCN_Dataset.html" class="sidebar-item-text sidebar-link">PyTorch ST-GCN Dataset</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">Questions of PyTorch Geometric Temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-18-Self Consistency toy ex.html" class="sidebar-item-text sidebar-link">Self Consistency Toy ex</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-22-SimulationPlanner-Tutorial_test_test.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2099-03-18-SimulationPlanner-Tutorial.html" class="sidebar-item-text sidebar-link">SimualtionPlanner-Tutorial</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation_boxplot.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-05-Simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-28-gcn_simulation.html" class="sidebar-item-text sidebar-link">Simulation of geometric-temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-simulation_table.html" class="sidebar-item-text sidebar-link">Simulation Tables</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-05-17-itstgcntry)fail_version__Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-04-Sparse_matrix.html" class="sidebar-item-text sidebar-link">Sparse matrix</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-03-03-ESTGCN_GNAR_edit_guebin2_seoyeon.html" class="sidebar-item-text sidebar-link">SY 1st ITSTGCN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_simulation_table_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation Tables_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-06-20-TGCN_Simulation_boxplot_reshape.html" class="sidebar-item-text sidebar-link">TGCN_Simulation_reshape</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2022-12-07-torchgcn.html" class="sidebar-item-text sidebar-link">TORCH_GEOMETRIC.NN</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-04-toy_example_figure.html" class="sidebar-item-text sidebar-link">Toy Example Figure(Intro)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-04-27-toy_example_notes.html" class="sidebar-item-text sidebar-link">Toy Example Note</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GCN/2023-07-08-toy_example_using_gnar.html" class="sidebar-item-text sidebar-link">Toy example using GNAR</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/GODE/index.html" class="sidebar-item-text sidebar-link">GODE</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-11-19-class_code_for_paper.html" class="sidebar-item-text sidebar-link">Class code for Comparison Study</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-22-comparison_earthquake.html" class="sidebar-item-text sidebar-link">Comparison Results on Real Data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-27-DFT_study.html" class="sidebar-item-text sidebar-link">Discrete Fourier Transform</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-10-02-Earthquake_real.html" class="sidebar-item-text sidebar-link">Earthquake</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-12-01-graph_code_guebin.html" class="sidebar-item-text sidebar-link">Graph code</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-06-27-Linear_graph_code_for_paper.html" class="sidebar-item-text sidebar-link">Linear Graph code for Paper</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2023-07-03-other_outlier_detection.html" class="sidebar-item-text sidebar-link active">Other Outlier Detection</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/2022-09-02-paper_simulation.html" class="sidebar-item-text sidebar-link">Simulation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/GODE/Untitled.html" class="sidebar-item-text sidebar-link">Untitled</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/STOCK/index.html" class="sidebar-item-text sidebar-link">STOCK</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/STOCK/2023-07-07-Stock_Crawling.html" class="sidebar-item-text sidebar-link">Stock Crawling</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/STOCK/2023-07-08-stock_on_graph.html" class="sidebar-item-text sidebar-link">Stock on Graph</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a>
  <ul class="collapse">
  <li><a href="#class-code" id="toc-class-code" class="nav-link" data-scroll-target="#class-code">Class Code</a></li>
  <li><a href="#linear-ebayesthresh" id="toc-linear-ebayesthresh" class="nav-link" data-scroll-target="#linear-ebayesthresh">Linear EbayesThresh</a></li>
  <li><a href="#linear" id="toc-linear" class="nav-link" data-scroll-target="#linear">Linear</a>
  <ul class="collapse">
  <li><a href="#gode" id="toc-gode" class="nav-link" data-scroll-target="#gode">GODE</a></li>
  <li><a href="#lofbreunig2000lofstar" id="toc-lofbreunig2000lofstar" class="nav-link" data-scroll-target="#lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(Breunig et al. 2000)</span><span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">KNN</a></li>
  <li><a href="#cblof오류" id="toc-cblof오류" class="nav-link" data-scroll-target="#cblof오류">CBLOF(오류)</a></li>
  <li><a href="#ocsvm" id="toc-ocsvm" class="nav-link" data-scroll-target="#ocsvm">OCSVM</a></li>
  <li><a href="#mcdstar" id="toc-mcdstar" class="nav-link" data-scroll-target="#mcdstar">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar" id="toc-feature-baggingstar" class="nav-link" data-scroll-target="#feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar" id="toc-abodstar" class="nav-link" data-scroll-target="#abodstar">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar" id="toc-iforeststar" class="nav-link" data-scroll-target="#iforeststar">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar" id="toc-hbosstar" class="nav-link" data-scroll-target="#hbosstar">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar" id="toc-sosstar" class="nav-link" data-scroll-target="#sosstar">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaal" id="toc-so_gaal" class="nav-link" data-scroll-target="#so_gaal">SO_GAAL</a></li>
  <li><a href="#mo_gaalstar" id="toc-mo_gaalstar" class="nav-link" data-scroll-target="#mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar" id="toc-lscpstar" class="nav-link" data-scroll-target="#lscpstar">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#linear-result" id="toc-linear-result" class="nav-link" data-scroll-target="#linear-result">Linear Result</a></li>
  <li><a href="#orbit-ebayesthresh" id="toc-orbit-ebayesthresh" class="nav-link" data-scroll-target="#orbit-ebayesthresh">Orbit EbayesThresh</a></li>
  <li><a href="#orbit" id="toc-orbit" class="nav-link" data-scroll-target="#orbit">Orbit</a>
  <ul class="collapse">
  <li><a href="#gode-1" id="toc-gode-1" class="nav-link" data-scroll-target="#gode-1">GODE</a></li>
  <li><a href="#lofstar" id="toc-lofstar" class="nav-link" data-scroll-target="#lofstar">LOF<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#knn-1" id="toc-knn-1" class="nav-link" data-scroll-target="#knn-1">KNN</a></li>
  <li><a href="#cblof" id="toc-cblof" class="nav-link" data-scroll-target="#cblof">CBLOF</a></li>
  <li><a href="#ocsvm-1" id="toc-ocsvm-1" class="nav-link" data-scroll-target="#ocsvm-1">OCSVM</a></li>
  <li><a href="#mcdstar-1" id="toc-mcdstar-1" class="nav-link" data-scroll-target="#mcdstar-1">MCD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#feature-baggingstar-1" id="toc-feature-baggingstar-1" class="nav-link" data-scroll-target="#feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#abodstar-1" id="toc-abodstar-1" class="nav-link" data-scroll-target="#abodstar-1">ABOD<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#iforeststar-1" id="toc-iforeststar-1" class="nav-link" data-scroll-target="#iforeststar-1">IForest<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#hbosstar-1" id="toc-hbosstar-1" class="nav-link" data-scroll-target="#hbosstar-1">HBOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#sosstar-1" id="toc-sosstar-1" class="nav-link" data-scroll-target="#sosstar-1">SOS<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#so_gaalstar" id="toc-so_gaalstar" class="nav-link" data-scroll-target="#so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#mo_gaalstar-1" id="toc-mo_gaalstar-1" class="nav-link" data-scroll-target="#mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></a></li>
  <li><a href="#lscpstar-1" id="toc-lscpstar-1" class="nav-link" data-scroll-target="#lscpstar-1">LSCP<span class="math inline">\(\star\)</span></a></li>
  </ul></li>
  <li><a href="#orbit-result" id="toc-orbit-result" class="nav-link" data-scroll-target="#orbit-result">Orbit Result</a></li>
  <li><a href="#bunny" id="toc-bunny" class="nav-link" data-scroll-target="#bunny">Bunny</a>
  <ul class="collapse">
  <li><a href="#bunny-저장용" id="toc-bunny-저장용" class="nav-link" data-scroll-target="#bunny-저장용">bunny 저장용</a></li>
  <li><a href="#gode-2" id="toc-gode-2" class="nav-link" data-scroll-target="#gode-2">GODE</a></li>
  <li><a href="#lof" id="toc-lof" class="nav-link" data-scroll-target="#lof">LOF</a></li>
  <li><a href="#knn-2" id="toc-knn-2" class="nav-link" data-scroll-target="#knn-2">KNN</a></li>
  <li><a href="#cblof-1" id="toc-cblof-1" class="nav-link" data-scroll-target="#cblof-1">CBLOF</a></li>
  <li><a href="#ocsvm-2" id="toc-ocsvm-2" class="nav-link" data-scroll-target="#ocsvm-2">OCSVM</a></li>
  <li><a href="#mcd" id="toc-mcd" class="nav-link" data-scroll-target="#mcd">MCD</a></li>
  <li><a href="#feature-bagging" id="toc-feature-bagging" class="nav-link" data-scroll-target="#feature-bagging">Feature Bagging</a></li>
  <li><a href="#abod" id="toc-abod" class="nav-link" data-scroll-target="#abod">ABOD</a></li>
  <li><a href="#iforest" id="toc-iforest" class="nav-link" data-scroll-target="#iforest">IForest</a></li>
  <li><a href="#hbos" id="toc-hbos" class="nav-link" data-scroll-target="#hbos">HBOS</a></li>
  <li><a href="#sos" id="toc-sos" class="nav-link" data-scroll-target="#sos">SOS</a></li>
  <li><a href="#so_gaal-1" id="toc-so_gaal-1" class="nav-link" data-scroll-target="#so_gaal-1">SO_GAAL</a></li>
  <li><a href="#mo_gaal" id="toc-mo_gaal" class="nav-link" data-scroll-target="#mo_gaal">MO_GAAL</a></li>
  <li><a href="#lscp" id="toc-lscp" class="nav-link" data-scroll-target="#lscp">LSCP</a></li>
  </ul></li>
  <li><a href="#bunny-result" id="toc-bunny-result" class="nav-link" data-scroll-target="#bunny-result">Bunny Result</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>knn, cblof, ocsvm 을 제외한 이상치 탐지 기법들에 데이터 집합에서 이상치 비율을 지정할 수 있는 옵션이 존재하였음.</p>
<p>default값은 10%인데, ABOD 방법에서는 5로 지정해주었고, 다른 방법들은 default인 10%가 들어갔다.</p>
<p>일단 우리 방법이랑 비교해서 좋은지 보기</p>
</div>
</div>
<p>iter</p>
<ul>
<li>LOF, CBLOF, OCSVM, MCD</li>
</ul>
<p>iter x - kNN, Feature Bagging, ABOD, Isolation, HBOS, SOS, SO-GAAL, MO-GAAL, LSCP</p>
<ul>
<li>Simple Linear</li>
</ul>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(5,7)\)</span> and <span class="math inline">\(U(-7,-5)\)</span>.</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Simple Linear 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.998</strong></td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.930</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
<td style="text-align: center;">0.985</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;"><strong>0.988</strong></td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;"><strong>0.994</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.889</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.883</td>
<td style="text-align: center;">0.938</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.979</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.896</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.947</td>
<td style="text-align: center;">0.973</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="1628">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1628">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.999</td>
      <td>0.999</td>
      <td>0.999</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.926</td>
      <td>0.961</td>
      <td>0.961</td>
      <td>0.961</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.950</td>
      <td>1.000</td>
      <td>0.947</td>
      <td>0.973</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.991</td>
      <td>0.940</td>
      <td>0.965</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.998</td>
      <td>0.999</td>
      <td>0.999</td>
      <td>0.999</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.986</td>
      <td>0.993</td>
      <td>0.993</td>
      <td>0.993</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.868</td>
      <td>0.999</td>
      <td>0.862</td>
      <td>0.925</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.960</td>
      <td>0.978</td>
      <td>0.980</td>
      <td>0.979</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.916</td>
      <td>0.956</td>
      <td>0.956</td>
      <td>0.956</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.936</td>
      <td>0.966</td>
      <td>0.966</td>
      <td>0.966</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.940</td>
      <td>0.965</td>
      <td>0.972</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<ul>
<li>Orbit</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.997</strong></td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;"><strong>0.998</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.886</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.892</td>
<td style="text-align: center;">0.937</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.918</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.958</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.866</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.903</td>
<td style="text-align: center;">0.928</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.979</td>
<td style="text-align: center;">0.927</td>
<td style="text-align: center;">0.952</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.378</td>
<td style="text-align: center;">0.997</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.514</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.936</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.876</td>
<td style="text-align: center;">0.959</td>
<td style="text-align: center;">0.908</td>
<td style="text-align: center;">0.933</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.948</td>
<td style="text-align: center;"><strong>0.999</strong></td>
<td style="text-align: center;">0.946</td>
<td style="text-align: center;">0.972</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="1739">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1739">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.999</td>
      <td>0.999</td>
      <td>0.999</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.954</td>
      <td>0.976</td>
      <td>0.976</td>
      <td>0.976</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.948</td>
      <td>0.999</td>
      <td>0.946</td>
      <td>0.972</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.908</td>
      <td>0.977</td>
      <td>0.925</td>
      <td>0.950</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.916</td>
      <td>0.956</td>
      <td>0.956</td>
      <td>0.956</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.942</td>
      <td>0.969</td>
      <td>0.969</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.443</td>
      <td>0.992</td>
      <td>0.417</td>
      <td>0.587</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.935</td>
      <td>0.960</td>
      <td>0.973</td>
      <td>0.966</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.950</td>
      <td>0.974</td>
      <td>0.974</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.950</td>
      <td>0.950</td>
      <td>1.000</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.950</td>
      <td>0.950</td>
      <td>1.000</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<ul>
<li>Stanford Bunny</li>
</ul>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(3,7)\)</span> and <span class="math inline">\(U(-7,-3)\)</span>.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Stanford Bunny 논문</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;"><strong>0.995</strong></td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.999</td>
<td style="text-align: center;"><strong>0.997</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.869</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="odd">
<td style="text-align: center;">kNN (Ramaswamy et al., 2000)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.968</td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF (He et al., 2003)</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;">0.932</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.937</td>
<td style="text-align: center;">0.963</td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.938</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.915</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.928</td>
<td style="text-align: center;">0.965</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.794</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.788</td>
<td style="text-align: center;">0.879</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;"><strong>1.000</strong></td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;"><strong>0.996</strong></td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.967</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="1852">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1852">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.988</td>
      <td>0.995</td>
      <td>0.993</td>
      <td>0.994</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.913</td>
      <td>0.955</td>
      <td>0.953</td>
      <td>0.954</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.942</td>
      <td>0.997</td>
      <td>0.942</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.992</td>
      <td>0.939</td>
      <td>0.965</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.982</td>
      <td>0.992</td>
      <td>0.989</td>
      <td>0.990</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.954</td>
      <td>0.977</td>
      <td>0.974</td>
      <td>0.976</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.979</td>
      <td>0.990</td>
      <td>0.988</td>
      <td>0.989</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.827</td>
      <td>0.995</td>
      <td>0.822</td>
      <td>0.900</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.919</td>
      <td>0.958</td>
      <td>0.956</td>
      <td>0.957</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.912</td>
      <td>0.955</td>
      <td>0.953</td>
      <td>0.954</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.952</td>
      <td>0.952</td>
      <td>1.000</td>
      <td>0.975</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.952</td>
      <td>0.952</td>
      <td>1.000</td>
      <td>0.975</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.978</td>
      <td>0.990</td>
      <td>0.987</td>
      <td>0.989</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="import" class="level1 page-columns page-full">
<h1>Import</h1>
<div class="cell" data-execution_count="397">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDOneClassSVM</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> Nystroem</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2.robjects <span class="im">as</span> ro </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.vectors <span class="im">import</span> FloatVector </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rpy2.robjects.packages <span class="im">import</span> importr</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_kddcup99, fetch_covtype, fetch_openml</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tqdm</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score, accuracy_score</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.covariance <span class="im">import</span> EmpiricalCovariance, MinCovDet</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> alibi_detect.od <span class="im">import</span> IForest</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># from pyod.models.iforest import IForest</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.abod <span class="im">import</span> ABOD</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.cblof <span class="im">import</span> CBLOF</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PyNomaly <span class="im">import</span> loop</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lscp <span class="im">import</span> LSCP</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.hbos <span class="im">import</span> HBOS</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.so_gaal <span class="im">import</span> SO_GAAL</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mcd <span class="im">import</span> MCD</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.mo_gaal <span class="im">import</span> MO_GAAL</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.lof <span class="im">import</span> LOF</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.ocsvm <span class="im">import</span> OCSVM</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.feature_bagging <span class="im">import</span> FeatureBagging</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.sos <span class="im">import</span> SOS</span></code></pre></div>
</div>
<section id="class-code" class="level2">
<h2 class="anchored" data-anchor-id="class-code">Class Code</h2>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tab_linear <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>tab_orbit <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>tab_bunny <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Accuracy"</span>,<span class="st">"Precision"</span>,<span class="st">"Recall"</span>,<span class="st">"F1"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Conf_matrx:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,original,compare,tab):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original <span class="op">=</span> original</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compare <span class="op">=</span> compare</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> tab</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> conf(<span class="va">self</span>,name):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conf_matrix <span class="op">=</span> confusion_matrix(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        ax.matshow(<span class="va">self</span>.conf_matrix, cmap<span class="op">=</span>plt.cm.Oranges, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span><span class="va">self</span>.conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Confusion Matrix'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.acc <span class="op">=</span> accuracy_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pre <span class="op">=</span> precision_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rec <span class="op">=</span> recall_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f1 <span class="op">=</span> f1_score(<span class="va">self</span>.original, <span class="va">self</span>.compare)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.acc)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Precision: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.pre)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Recall: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.rec)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'F1 Score: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> <span class="va">self</span>.f1)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab <span class="op">=</span> <span class="va">self</span>.tab.append(pd.DataFrame({<span class="st">"Accuracy"</span>:[<span class="va">self</span>.acc],<span class="st">"Precision"</span>:[<span class="va">self</span>.pre],<span class="st">"Recall"</span>:[<span class="va">self</span>.rec],<span class="st">"F1"</span>:[<span class="va">self</span>.f1]},index <span class="op">=</span> [name]))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="255">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.y1 = df.y1.to_numpy()</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> w</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)      </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.y <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.ybar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ybar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.ybar,<span class="dv">0</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.yhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.ybar_threshed</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(yHat <span class="op">=</span> <span class="va">self</span>.yhat)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.y<span class="op">-</span> <span class="va">self</span>.df.yHat)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="256">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Orbit:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_distance(<span class="va">self</span>):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> np.zeros([<span class="va">self</span>.n,<span class="va">self</span>.n])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        locations <span class="op">=</span> np.stack([<span class="va">self</span>.x, <span class="va">self</span>.y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm.tqdm(<span class="bu">range</span>(<span class="va">self</span>.n)):</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i,<span class="va">self</span>.n):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.D[i,j]<span class="op">=</span>np.linalg.norm(locations[i]<span class="op">-</span>locations[j])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> <span class="va">self</span>.D <span class="op">+</span> <span class="va">self</span>.D.T</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_weightmatrix(<span class="va">self</span>,theta<span class="op">=</span><span class="dv">1</span>,beta<span class="op">=</span><span class="fl">0.5</span>,kappa<span class="op">=</span><span class="dv">4000</span>):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta <span class="op">=</span> theta</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.where(<span class="va">self</span>.D <span class="op">&lt;</span> kappa,<span class="va">self</span>.D,<span class="dv">0</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.exp(<span class="op">-</span>(dist<span class="op">/</span><span class="va">self</span>.theta)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">20</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.f <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f<span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="257">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BUNNY:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,df):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.f <span class="op">=</span> df.f.to_numpy()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z <span class="op">=</span> df.z.to_numpy()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> df.x.to_numpy()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> df.y.to_numpy()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.noise <span class="op">=</span> df.noise.to_numpy()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fnoise <span class="op">=</span> <span class="va">self</span>.f <span class="op">+</span> <span class="va">self</span>.noise</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> _W</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.f)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta<span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eigen(<span class="va">self</span>):</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        d<span class="op">=</span> <span class="va">self</span>.W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        D<span class="op">=</span> np.diag(d)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span><span class="va">self</span>.W) <span class="op">@</span> np.diag(<span class="dv">1</span><span class="op">/</span>np.sqrt(d))</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lamb, <span class="va">self</span>.Psi <span class="op">=</span> np.linalg.eigh(<span class="va">self</span>.L)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Lamb <span class="op">=</span> np.diag(<span class="va">self</span>.lamb)       </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>,sd<span class="op">=</span><span class="dv">5</span>,ref<span class="op">=</span><span class="dv">6</span>): <span class="co"># fit with ebayesthresh</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._eigen()</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar <span class="op">=</span> <span class="va">self</span>.Psi.T <span class="op">@</span> <span class="va">self</span>.fnoise <span class="co"># fbar := graph fourier transform of f</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power <span class="op">=</span> <span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.power_threshed<span class="op">=</span>np.array(ebayesthresh(FloatVector(<span class="va">self</span>.fbar<span class="op">**</span><span class="dv">2</span>),sd<span class="op">=</span>sd))</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fbar_threshed <span class="op">=</span> np.where(<span class="va">self</span>.power_threshed<span class="op">&gt;</span><span class="dv">0</span>,<span class="va">self</span>.fbar,<span class="dv">0</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fhat <span class="op">=</span> <span class="va">self</span>.Psi<span class="op">@</span>self.fbar_threshed</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fnoise <span class="op">=</span> <span class="va">self</span>.fnoise)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(fHat <span class="op">=</span> <span class="va">self</span>.fhat)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> <span class="va">self</span>.df.assign(Residual <span class="op">=</span> <span class="va">self</span>.df.f <span class="op">+</span> <span class="va">self</span>.df.noise <span class="op">-</span> <span class="va">self</span>.df.fHat)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottom <span class="op">=</span> np.zeros_like(<span class="va">self</span>.f)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.width<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth<span class="op">=</span><span class="fl">0.05</span></span></code></pre></div>
</div>
</section>
<section id="linear-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="linear-ebayesthresh">Linear EbayesThresh</h2>
<div class="cell" data-execution_count="1882">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1883">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># signal_1 = sample(c(runif(25,-2,-1.5), runif(25,1.5,2), rep(0,950)))</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>signal_1 <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1 <span class="op">=</span> which(signal_1<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier_1</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>x_1<span class="op">=</span>signal_1<span class="op">+</span>epsilon</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1884">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x_1</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier_1</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1885">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1886">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index_1 <span class="op">=</span> index_of_trueoutlier_1</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1887">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value_1 <span class="op">=</span> x_1[index_of_trueoutlier_1]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1888">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> signal_1.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1889">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_1))</span></code></pre></div>
</div>
</section>
<section id="linear" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="linear">Linear</h2>
<div class="cell" data-tags="[]" data-execution_count="1890">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>_x_1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1000</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>_y1_1 <span class="op">=</span> <span class="dv">5</span><span class="op">*</span>_x_1</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>_y_1 <span class="op">=</span> _y1_1 <span class="op">+</span> x_1 <span class="co"># x is epsilon</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1891">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>_df<span class="op">=</span>pd.DataFrame({<span class="st">'x'</span>:_x_1, <span class="st">'y'</span>:_y_1})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1892">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1897">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># _df.to_csv('simple_linear_df.csv')</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1898">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one_1).to_csv('simple_linear_outlier.csv')</span></span></code></pre></div>
</div>
<section id="gode" class="level3">
<h3 class="anchored" data-anchor-id="gode">GODE</h3>
<div class="cell" data-execution_count="1490">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span>np.zeros((<span class="dv">1000</span>,<span class="dv">1000</span>))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1491">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">==</span>j :</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> np.<span class="bu">abs</span>(i<span class="op">-</span>j) <span class="op">&lt;=</span> <span class="dv">1</span> : </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>            w[i,j] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1492">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>_Linear <span class="op">=</span> Linear(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1499">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>_Linear.fit(sd<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1543">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Linear.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1544">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">9.8</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1545">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_simul_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1546">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1546">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1547">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1547">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1548">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1549">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lofbreunig2000lofstar" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="lofbreunig2000lofstar">LOF<span class="citation" data-cites="breunig2000lof">(<a href="#ref-breunig2000lof" role="doc-biblioref">Breunig et al. 2000</a>)</span><span class="math inline">\(\star\)</span></h3>
<div class="no-row-height column-margin column-container"><div id="ref-breunig2000lof" class="csl-entry" role="doc-biblioentry">
Breunig, Markus M, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. <span>“LOF: Identifying Density-Based Local Outliers.”</span> In <em>Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</em>, 93–104.
</div></div><div class="cell" data-execution_count="1550">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<p>Lof 논문 원문에 따라 LOF를 계산하고, min-max 범위를 넘으면 이상치</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="Figs/lof.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Figure: LOF’s outliers detection method</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="1551">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,clf.fit_predict(X),tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1552">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.926
Precision: 0.961
Recall: 0.961
F1 Score: 0.961</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1553">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn" class="level3">
<h3 class="anchored" data-anchor-id="knn">KNN</h3>
<div class="cell" data-execution_count="1554">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyod.models.knn <span class="im">import</span> KNN</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="1555">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p>k번째 이상은 outlier로 본다.</p>
<p><strong>이상치 비율 정하지 않음</strong></p>
<p>Three kNN detectors are supported:</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the outlier score</li>
</ul>
<div class="cell" data-execution_count="1556">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1557">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1558">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_KNN_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1559">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-44-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 1.000
Recall: 0.947
F1 Score: 0.973</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1560">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof오류" class="level3">
<h3 class="anchored" data-anchor-id="cblof오류">CBLOF(오류)</h3>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span>  pd.read_csv(<span class="st">'simple_linear_df.csv'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_1 <span class="op">=</span> pd.read_csv(<span class="st">'simple_linear_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_CBLOF_one,tab_linear)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-51-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.972
Precision: 0.985
Recall: 0.985
F1 Score: 0.985</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
</div>
<ul>
<li>Accuracy: 0.972</li>
<li>Precision: 0.985</li>
<li>Recall: 0.985</li>
<li>F1 Score: 0.985</li>
</ul>
</section>
<section id="ocsvm" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm">OCSVM</h3>
<p>default=10%</p>
<div class="cell" data-execution_count="1562">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1563">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1563">
<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="1564">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1565">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_OSVM_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1566">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-57-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.991
Recall: 0.940
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1567">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcdstar" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1568">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1569">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1570">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1571">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MCD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1572">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-63-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1573">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-baggingstar" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<p>default값은 10%로 설정되어 있었고, 5%로 지정한 결과, 평가지표값이 전반적으로 1%이상 낮아졌다.</p>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1574">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1575">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1576">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1577">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_FeatureBagging_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1578">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-69-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.986
Precision: 0.993
Recall: 0.993
F1 Score: 0.993</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1579">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abodstar" class="level3">
<h3 class="anchored" data-anchor-id="abodstar">ABOD<span class="math inline">\(\star\)</span></h3>
<p>default 값이 5%이며, 이미 지정된 채려 시뮬레이션 돌림</p>
<div class="cell" data-execution_count="1580">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<p><strong>contamination</strong> : float in (0., 0.5), optional (default=0.1)</p>
<ul>
<li>The amount of contamination of the data set, i.e.</li>
<li>the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.</li>
</ul>
<div class="cell" data-execution_count="1581">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1582">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1583">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_ABOD_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1584">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-75-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1585">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="iforeststar" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar">IForest<span class="math inline">\(\star\)</span></h3>
<p>n_estimators Number of base estimators in the ensemble.</p>
<ul>
<li>n이 총 1000개니까 5%인 50 지정해줄 수 있음</li>
</ul>
<div class="cell" data-execution_count="1586">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1587">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1588">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>]],</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1589">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1590">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1591">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1592">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_alibi_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1593">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-84-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.868
Precision: 0.999
Recall: 0.862
F1 Score: 0.925</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1594">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbosstar" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar">HBOS<span class="math inline">\(\star\)</span></h3>
<p>default값은 이상치값을 10%로 지정하였으며, 5%로 지정한 결과 값 다 작아짐</p>
<div class="cell" data-execution_count="1595">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1596">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1597">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1598">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_HBOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1599">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-90-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.960
Precision: 0.978
Recall: 0.980
F1 Score: 0.979</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1600">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sosstar" class="level3">
<h3 class="anchored" data-anchor-id="sosstar">SOS<span class="math inline">\(\star\)</span></h3>
<p>default 는 10%</p>
<div class="cell" data-execution_count="1601">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1602">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1603">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1604">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SOS_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1605">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-96-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1606">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaal" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal">SO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1607">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3130

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.3524
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3562

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3857
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3845

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3516
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3861

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4008
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3870

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4348
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.3913

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4431
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4510

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4427
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.4704

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4752
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4794

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4972
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4998

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.5168
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5228

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.5560
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5677

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.4929
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5675

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5508
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5679

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5563
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5806

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.5637
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5749

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.6370
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6088

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6408
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6699

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5958
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5661

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.6471
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.6815

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6419
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6967

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7016
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6348

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 5ms/step - loss: 1.6519
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6470

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6582
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6890

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7197
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7613

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7085
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6933

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7013
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7330

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7275
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7635

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7682
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.8321

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7557
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.7231

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7787
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.7553

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7782
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.7678

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8069
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.7798

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8038
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 5ms/step - loss: 1.8120

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7591
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.8204

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8033
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8414

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.7215
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8414

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8143
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.8406

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.8562
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8167

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8597
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1608">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1609">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1610">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_SO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1611">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-102-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.936
Precision: 0.966
Recall: 0.966
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1612">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1613">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 658us/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 865us/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 597us/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 623us/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 633us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 597us/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 605us/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 810us/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 613us/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 610us/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 624us/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 597us/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 833us/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 615us/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 600us/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 614us/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 635us/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 619us/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 610us/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 610us/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 613us/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 616us/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 627us/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 621us/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 614us/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 846us/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 623us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 915us/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 836us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 829us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 860us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 832us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 870us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3802
16/16 [==============================] - 0s 992us/step - loss: 0.7194
16/16 [==============================] - 0s 1ms/step - loss: 0.9382
16/16 [==============================] - 0s 2ms/step - loss: 1.1679
16/16 [==============================] - 0s 1ms/step - loss: 1.2953
16/16 [==============================] - 0s 982us/step - loss: 1.3707
16/16 [==============================] - 0s 1ms/step - loss: 1.4090
16/16 [==============================] - 0s 1ms/step - loss: 1.4370
16/16 [==============================] - 0s 1ms/step - loss: 1.4481
16/16 [==============================] - 0s 1ms/step - loss: 1.4524
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3784
16/16 [==============================] - 0s 3ms/step - loss: 0.7280
16/16 [==============================] - 0s 1ms/step - loss: 0.9713
16/16 [==============================] - 0s 2ms/step - loss: 1.2091
16/16 [==============================] - 0s 1ms/step - loss: 1.3341
16/16 [==============================] - 0s 2ms/step - loss: 1.4019
16/16 [==============================] - 0s 2ms/step - loss: 1.4333
16/16 [==============================] - 0s 1ms/step - loss: 1.4551
16/16 [==============================] - 0s 1ms/step - loss: 1.4629
16/16 [==============================] - 0s 1ms/step - loss: 1.4656

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 913us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3866
16/16 [==============================] - 0s 1ms/step - loss: 0.7327
16/16 [==============================] - 0s 2ms/step - loss: 0.9839
16/16 [==============================] - 0s 5ms/step - loss: 1.2335
16/16 [==============================] - 0s 1ms/step - loss: 1.3481
16/16 [==============================] - 0s 3ms/step - loss: 1.4093
16/16 [==============================] - 0s 1ms/step - loss: 1.4348
16/16 [==============================] - 0s 2ms/step - loss: 1.4506
16/16 [==============================] - 0s 1ms/step - loss: 1.4559
16/16 [==============================] - 0s 2ms/step - loss: 1.4576
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.3956
16/16 [==============================] - 0s 1ms/step - loss: 0.7406
16/16 [==============================] - 0s 1ms/step - loss: 0.9936
16/16 [==============================] - 0s 2ms/step - loss: 1.2356
16/16 [==============================] - 0s 2ms/step - loss: 1.3418
16/16 [==============================] - 0s 1ms/step - loss: 1.3928
16/16 [==============================] - 0s 2ms/step - loss: 1.4131
16/16 [==============================] - 0s 1ms/step - loss: 1.4239
16/16 [==============================] - 0s 1ms/step - loss: 1.4275
16/16 [==============================] - 0s 1ms/step - loss: 1.4283

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 5ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3925
16/16 [==============================] - 0s 1ms/step - loss: 0.7523
16/16 [==============================] - 0s 1ms/step - loss: 1.0367
16/16 [==============================] - 0s 1ms/step - loss: 1.2950
16/16 [==============================] - 0s 2ms/step - loss: 1.3968
16/16 [==============================] - 0s 2ms/step - loss: 1.4439
16/16 [==============================] - 0s 2ms/step - loss: 1.4623
16/16 [==============================] - 0s 1ms/step - loss: 1.4710
16/16 [==============================] - 0s 2ms/step - loss: 1.4735
16/16 [==============================] - 0s 2ms/step - loss: 1.4740
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4051
16/16 [==============================] - 0s 2ms/step - loss: 0.7528
16/16 [==============================] - 0s 2ms/step - loss: 1.0473
16/16 [==============================] - 0s 1ms/step - loss: 1.2922
16/16 [==============================] - 0s 1ms/step - loss: 1.3798
16/16 [==============================] - 0s 2ms/step - loss: 1.4177
16/16 [==============================] - 0s 2ms/step - loss: 1.4316
16/16 [==============================] - 0s 2ms/step - loss: 1.4376
16/16 [==============================] - 0s 1ms/step - loss: 1.4391
16/16 [==============================] - 0s 2ms/step - loss: 1.4393

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 897us/step
16/16 [==============================] - 0s 3ms/step - loss: 0.4123
16/16 [==============================] - 0s 2ms/step - loss: 0.7576
16/16 [==============================] - 0s 2ms/step - loss: 1.0566
16/16 [==============================] - 0s 2ms/step - loss: 1.2987
16/16 [==============================] - 0s 2ms/step - loss: 1.3765
16/16 [==============================] - 0s 4ms/step - loss: 1.4095
16/16 [==============================] - 0s 2ms/step - loss: 1.4206
16/16 [==============================] - 0s 2ms/step - loss: 1.4250
16/16 [==============================] - 0s 2ms/step - loss: 1.4259
16/16 [==============================] - 0s 1ms/step - loss: 1.4259
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4149
16/16 [==============================] - 0s 2ms/step - loss: 0.7675
16/16 [==============================] - 0s 1ms/step - loss: 1.0765
16/16 [==============================] - 0s 2ms/step - loss: 1.3167
16/16 [==============================] - 0s 1ms/step - loss: 1.3880
16/16 [==============================] - 0s 1ms/step - loss: 1.4164
16/16 [==============================] - 0s 2ms/step - loss: 1.4257
16/16 [==============================] - 0s 1ms/step - loss: 1.4288
16/16 [==============================] - 0s 1ms/step - loss: 1.4294
16/16 [==============================] - 0s 1ms/step - loss: 1.4293

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 899us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4172
16/16 [==============================] - 0s 1ms/step - loss: 0.7677
16/16 [==============================] - 0s 1ms/step - loss: 1.0818
16/16 [==============================] - 0s 1ms/step - loss: 1.3143
16/16 [==============================] - 0s 1ms/step - loss: 1.3797
16/16 [==============================] - 0s 1ms/step - loss: 1.4048
16/16 [==============================] - 0s 1ms/step - loss: 1.4123
16/16 [==============================] - 0s 1ms/step - loss: 1.4147
16/16 [==============================] - 0s 2ms/step - loss: 1.4150
16/16 [==============================] - 0s 2ms/step - loss: 1.4148
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 754us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4148
16/16 [==============================] - 0s 2ms/step - loss: 0.7766
16/16 [==============================] - 0s 4ms/step - loss: 1.1064
16/16 [==============================] - 0s 2ms/step - loss: 1.3376
16/16 [==============================] - 0s 1ms/step - loss: 1.4002
16/16 [==============================] - 0s 1ms/step - loss: 1.4228
16/16 [==============================] - 0s 1ms/step - loss: 1.4290
16/16 [==============================] - 0s 1ms/step - loss: 1.4308
16/16 [==============================] - 0s 1ms/step - loss: 1.4309
16/16 [==============================] - 0s 1ms/step - loss: 1.4307

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 842us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4190
16/16 [==============================] - 0s 1ms/step - loss: 0.7761
16/16 [==============================] - 0s 2ms/step - loss: 1.1055
16/16 [==============================] - 0s 1ms/step - loss: 1.3282
16/16 [==============================] - 0s 2ms/step - loss: 1.3846
16/16 [==============================] - 0s 1ms/step - loss: 1.4044
16/16 [==============================] - 0s 2ms/step - loss: 1.4095
16/16 [==============================] - 0s 1ms/step - loss: 1.4108
16/16 [==============================] - 0s 2ms/step - loss: 1.4108
16/16 [==============================] - 0s 2ms/step - loss: 1.4105
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4225
16/16 [==============================] - 0s 1ms/step - loss: 0.7746
16/16 [==============================] - 0s 1ms/step - loss: 1.1026
16/16 [==============================] - 0s 1ms/step - loss: 1.3159
16/16 [==============================] - 0s 1ms/step - loss: 1.3665
16/16 [==============================] - 0s 2ms/step - loss: 1.3838
16/16 [==============================] - 0s 972us/step - loss: 1.3880
16/16 [==============================] - 0s 1ms/step - loss: 1.3888
16/16 [==============================] - 0s 1ms/step - loss: 1.3887
16/16 [==============================] - 0s 2ms/step - loss: 1.3884

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4196
16/16 [==============================] - 0s 1ms/step - loss: 0.7825
16/16 [==============================] - 0s 2ms/step - loss: 1.1245
16/16 [==============================] - 0s 1ms/step - loss: 1.3411
16/16 [==============================] - 0s 2ms/step - loss: 1.3905
16/16 [==============================] - 0s 1ms/step - loss: 1.4071
16/16 [==============================] - 0s 2ms/step - loss: 1.4109
16/16 [==============================] - 0s 2ms/step - loss: 1.4116
16/16 [==============================] - 0s 1ms/step - loss: 1.4115
16/16 [==============================] - 0s 3ms/step - loss: 1.4112
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4124
16/16 [==============================] - 0s 2ms/step - loss: 0.7896
16/16 [==============================] - 0s 2ms/step - loss: 1.1481
16/16 [==============================] - 0s 2ms/step - loss: 1.3684
16/16 [==============================] - 0s 2ms/step - loss: 1.4180
16/16 [==============================] - 0s 2ms/step - loss: 1.4340
16/16 [==============================] - 0s 2ms/step - loss: 1.4374
16/16 [==============================] - 0s 1ms/step - loss: 1.4380
16/16 [==============================] - 0s 1ms/step - loss: 1.4378
16/16 [==============================] - 0s 1ms/step - loss: 1.4375

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4173
16/16 [==============================] - 0s 2ms/step - loss: 0.7865
16/16 [==============================] - 0s 2ms/step - loss: 1.1353
16/16 [==============================] - 0s 1ms/step - loss: 1.3465
16/16 [==============================] - 0s 1ms/step - loss: 1.3927
16/16 [==============================] - 0s 1ms/step - loss: 1.4072
16/16 [==============================] - 0s 2ms/step - loss: 1.4101
16/16 [==============================] - 0s 1ms/step - loss: 1.4105
16/16 [==============================] - 0s 1ms/step - loss: 1.4102
16/16 [==============================] - 0s 1ms/step - loss: 1.4099
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4145
16/16 [==============================] - 0s 1ms/step - loss: 0.7933
16/16 [==============================] - 0s 1ms/step - loss: 1.1517
16/16 [==============================] - 0s 1ms/step - loss: 1.3656
16/16 [==============================] - 0s 5ms/step - loss: 1.4111
16/16 [==============================] - 0s 4ms/step - loss: 1.4251
16/16 [==============================] - 0s 4ms/step - loss: 1.4278
16/16 [==============================] - 0s 2ms/step - loss: 1.4281
16/16 [==============================] - 0s 2ms/step - loss: 1.4278
16/16 [==============================] - 0s 2ms/step - loss: 1.4275

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4111
16/16 [==============================] - 0s 1ms/step - loss: 0.7909
16/16 [==============================] - 0s 1ms/step - loss: 1.1516
16/16 [==============================] - 0s 2ms/step - loss: 1.3647
16/16 [==============================] - 0s 1ms/step - loss: 1.4090
16/16 [==============================] - 0s 1ms/step - loss: 1.4224
16/16 [==============================] - 0s 2ms/step - loss: 1.4249
16/16 [==============================] - 0s 2ms/step - loss: 1.4250
16/16 [==============================] - 0s 2ms/step - loss: 1.4247
16/16 [==============================] - 0s 2ms/step - loss: 1.4244
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 869us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4107
16/16 [==============================] - 0s 1ms/step - loss: 0.7938
16/16 [==============================] - 0s 1ms/step - loss: 1.1611
16/16 [==============================] - 0s 2ms/step - loss: 1.3750
16/16 [==============================] - 0s 994us/step - loss: 1.4188
16/16 [==============================] - 0s 903us/step - loss: 1.4319
16/16 [==============================] - 0s 916us/step - loss: 1.4343
16/16 [==============================] - 0s 997us/step - loss: 1.4344
16/16 [==============================] - 0s 4ms/step - loss: 1.4341
16/16 [==============================] - 0s 1ms/step - loss: 1.4338

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4054
16/16 [==============================] - 0s 4ms/step - loss: 0.7927
16/16 [==============================] - 0s 3ms/step - loss: 1.1646
16/16 [==============================] - 0s 2ms/step - loss: 1.3805
16/16 [==============================] - 0s 4ms/step - loss: 1.4241
16/16 [==============================] - 0s 2ms/step - loss: 1.4369
16/16 [==============================] - 0s 2ms/step - loss: 1.4391
16/16 [==============================] - 0s 1ms/step - loss: 1.4391
16/16 [==============================] - 0s 1ms/step - loss: 1.4388
16/16 [==============================] - 0s 1ms/step - loss: 1.4384
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3962
16/16 [==============================] - 0s 2ms/step - loss: 0.7984
16/16 [==============================] - 0s 1ms/step - loss: 1.1888
16/16 [==============================] - 0s 5ms/step - loss: 1.4144
16/16 [==============================] - 0s 3ms/step - loss: 1.4594
16/16 [==============================] - 0s 2ms/step - loss: 1.4726
16/16 [==============================] - 0s 4ms/step - loss: 1.4748
16/16 [==============================] - 0s 2ms/step - loss: 1.4749
16/16 [==============================] - 0s 1ms/step - loss: 1.4745
16/16 [==============================] - 0s 1ms/step - loss: 1.4742

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 898us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3984
16/16 [==============================] - 0s 1ms/step - loss: 0.7936
16/16 [==============================] - 0s 1ms/step - loss: 1.1789
16/16 [==============================] - 0s 3ms/step - loss: 1.4023
16/16 [==============================] - 0s 2ms/step - loss: 1.4465
16/16 [==============================] - 0s 1ms/step - loss: 1.4593
16/16 [==============================] - 0s 954us/step - loss: 1.4615
16/16 [==============================] - 0s 1ms/step - loss: 1.4616
16/16 [==============================] - 0s 998us/step - loss: 1.4612
16/16 [==============================] - 0s 2ms/step - loss: 1.4608
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3891
16/16 [==============================] - 0s 1ms/step - loss: 0.7938
16/16 [==============================] - 0s 1ms/step - loss: 1.1911
16/16 [==============================] - 0s 1ms/step - loss: 1.4219
16/16 [==============================] - 0s 3ms/step - loss: 1.4666
16/16 [==============================] - 0s 2ms/step - loss: 1.4796
16/16 [==============================] - 0s 2ms/step - loss: 1.4818
16/16 [==============================] - 0s 1ms/step - loss: 1.4818
16/16 [==============================] - 0s 1ms/step - loss: 1.4815
16/16 [==============================] - 0s 1ms/step - loss: 1.4811

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 913us/step
16/16 [==============================] - 0s 3ms/step - loss: 0.3883
16/16 [==============================] - 0s 3ms/step - loss: 0.7919
16/16 [==============================] - 0s 2ms/step - loss: 1.1930
16/16 [==============================] - 0s 1ms/step - loss: 1.4285
16/16 [==============================] - 0s 2ms/step - loss: 1.4721
16/16 [==============================] - 0s 1ms/step - loss: 1.4852
16/16 [==============================] - 0s 2ms/step - loss: 1.4875
16/16 [==============================] - 0s 1ms/step - loss: 1.4875
16/16 [==============================] - 0s 1ms/step - loss: 1.4871
16/16 [==============================] - 0s 3ms/step - loss: 1.4867
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3772
16/16 [==============================] - 0s 1ms/step - loss: 0.7929
16/16 [==============================] - 0s 2ms/step - loss: 1.2122
16/16 [==============================] - 0s 1ms/step - loss: 1.4584
16/16 [==============================] - 0s 3ms/step - loss: 1.5041
16/16 [==============================] - 0s 3ms/step - loss: 1.5178
16/16 [==============================] - 0s 1ms/step - loss: 1.5201
16/16 [==============================] - 0s 1ms/step - loss: 1.5202
16/16 [==============================] - 0s 1ms/step - loss: 1.5198
16/16 [==============================] - 0s 973us/step - loss: 1.5194

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3685
16/16 [==============================] - 0s 2ms/step - loss: 0.7940
16/16 [==============================] - 0s 1ms/step - loss: 1.2262
16/16 [==============================] - 0s 2ms/step - loss: 1.4829
16/16 [==============================] - 0s 2ms/step - loss: 1.5311
16/16 [==============================] - 0s 1ms/step - loss: 1.5455
16/16 [==============================] - 0s 2ms/step - loss: 1.5481
16/16 [==============================] - 0s 4ms/step - loss: 1.5482
16/16 [==============================] - 0s 2ms/step - loss: 1.5478
16/16 [==============================] - 0s 3ms/step - loss: 1.5474
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.3693
16/16 [==============================] - 0s 1ms/step - loss: 0.7909
16/16 [==============================] - 0s 1ms/step - loss: 1.2196
16/16 [==============================] - 0s 1ms/step - loss: 1.4752
16/16 [==============================] - 0s 2ms/step - loss: 1.5233
16/16 [==============================] - 0s 2ms/step - loss: 1.5375
16/16 [==============================] - 0s 1ms/step - loss: 1.5400
16/16 [==============================] - 0s 1ms/step - loss: 1.5400
16/16 [==============================] - 0s 2ms/step - loss: 1.5396
16/16 [==============================] - 0s 3ms/step - loss: 1.5392

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3592
16/16 [==============================] - 0s 1ms/step - loss: 0.7936
16/16 [==============================] - 0s 2ms/step - loss: 1.2413
16/16 [==============================] - 0s 2ms/step - loss: 1.5117
16/16 [==============================] - 0s 2ms/step - loss: 1.5633
16/16 [==============================] - 0s 2ms/step - loss: 1.5786
16/16 [==============================] - 0s 4ms/step - loss: 1.5814
16/16 [==============================] - 0s 2ms/step - loss: 1.5816
16/16 [==============================] - 0s 2ms/step - loss: 1.5812
16/16 [==============================] - 0s 1ms/step - loss: 1.5808
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 923us/step - loss: 0.3582
16/16 [==============================] - 0s 1ms/step - loss: 0.7895
16/16 [==============================] - 0s 1ms/step - loss: 1.2360
16/16 [==============================] - 0s 1ms/step - loss: 1.5072
16/16 [==============================] - 0s 952us/step - loss: 1.5584
16/16 [==============================] - 0s 2ms/step - loss: 1.5735
16/16 [==============================] - 0s 2ms/step - loss: 1.5763
16/16 [==============================] - 0s 1ms/step - loss: 1.5764
16/16 [==============================] - 0s 2ms/step - loss: 1.5760
16/16 [==============================] - 0s 1ms/step - loss: 1.5756

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.3488
16/16 [==============================] - 0s 2ms/step - loss: 0.7942
16/16 [==============================] - 0s 1ms/step - loss: 1.2601
16/16 [==============================] - 0s 1ms/step - loss: 1.5469
16/16 [==============================] - 0s 1ms/step - loss: 1.6015
16/16 [==============================] - 0s 1ms/step - loss: 1.6177
16/16 [==============================] - 0s 1ms/step - loss: 1.6207
16/16 [==============================] - 0s 2ms/step - loss: 1.6210
16/16 [==============================] - 0s 2ms/step - loss: 1.6206
16/16 [==============================] - 0s 1ms/step - loss: 1.6202
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 829us/step
16/16 [==============================] - 0s 980us/step - loss: 0.3512
16/16 [==============================] - 0s 943us/step - loss: 0.7854
16/16 [==============================] - 0s 842us/step - loss: 1.2413
16/16 [==============================] - 0s 816us/step - loss: 1.5228
16/16 [==============================] - 0s 1ms/step - loss: 1.5761
16/16 [==============================] - 0s 829us/step - loss: 1.5918
16/16 [==============================] - 0s 819us/step - loss: 1.5947
16/16 [==============================] - 0s 801us/step - loss: 1.5949
16/16 [==============================] - 0s 852us/step - loss: 1.5945
16/16 [==============================] - 0s 874us/step - loss: 1.5940

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 637us/step
16/16 [==============================] - 0s 798us/step - loss: 0.3437
16/16 [==============================] - 0s 798us/step - loss: 0.7857
16/16 [==============================] - 0s 793us/step - loss: 1.2551
16/16 [==============================] - 0s 784us/step - loss: 1.5475
16/16 [==============================] - 0s 778us/step - loss: 1.6036
16/16 [==============================] - 0s 789us/step - loss: 1.6201
16/16 [==============================] - 0s 800us/step - loss: 1.6232
16/16 [==============================] - 0s 786us/step - loss: 1.6234
16/16 [==============================] - 0s 804us/step - loss: 1.6230
16/16 [==============================] - 0s 771us/step - loss: 1.6226
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 837us/step
16/16 [==============================] - 0s 906us/step - loss: 0.3392
16/16 [==============================] - 0s 772us/step - loss: 0.7786
16/16 [==============================] - 0s 1ms/step - loss: 1.2518
16/16 [==============================] - 0s 1ms/step - loss: 1.5415
16/16 [==============================] - 0s 1ms/step - loss: 1.5975
16/16 [==============================] - 0s 1ms/step - loss: 1.6140
16/16 [==============================] - 0s 836us/step - loss: 1.6171
16/16 [==============================] - 0s 781us/step - loss: 1.6173
16/16 [==============================] - 0s 805us/step - loss: 1.6169
16/16 [==============================] - 0s 802us/step - loss: 1.6165

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 831us/step - loss: 0.3362
16/16 [==============================] - 0s 795us/step - loss: 0.7794
16/16 [==============================] - 0s 806us/step - loss: 1.2570
16/16 [==============================] - 0s 780us/step - loss: 1.5521
16/16 [==============================] - 0s 821us/step - loss: 1.6094
16/16 [==============================] - 0s 778us/step - loss: 1.6265
16/16 [==============================] - 0s 835us/step - loss: 1.6298
16/16 [==============================] - 0s 774us/step - loss: 1.6300
16/16 [==============================] - 0s 773us/step - loss: 1.6296
16/16 [==============================] - 0s 782us/step - loss: 1.6291
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 821us/step - loss: 0.3350
16/16 [==============================] - 0s 780us/step - loss: 0.7829
16/16 [==============================] - 0s 807us/step - loss: 1.2628
16/16 [==============================] - 0s 798us/step - loss: 1.5617
16/16 [==============================] - 0s 790us/step - loss: 1.6196
16/16 [==============================] - 0s 810us/step - loss: 1.6369
16/16 [==============================] - 0s 814us/step - loss: 1.6402
16/16 [==============================] - 0s 784us/step - loss: 1.6404
16/16 [==============================] - 0s 812us/step - loss: 1.6400
16/16 [==============================] - 0s 808us/step - loss: 1.6395

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 854us/step - loss: 0.3207
16/16 [==============================] - 0s 771us/step - loss: 0.7883
16/16 [==============================] - 0s 791us/step - loss: 1.2870
16/16 [==============================] - 0s 762us/step - loss: 1.6028
16/16 [==============================] - 0s 770us/step - loss: 1.6645
16/16 [==============================] - 0s 770us/step - loss: 1.6830
16/16 [==============================] - 0s 792us/step - loss: 1.6866
16/16 [==============================] - 0s 788us/step - loss: 1.6869
16/16 [==============================] - 0s 827us/step - loss: 1.6865
16/16 [==============================] - 0s 758us/step - loss: 1.6861
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 807us/step - loss: 0.3234
16/16 [==============================] - 0s 771us/step - loss: 0.7890
16/16 [==============================] - 0s 777us/step - loss: 1.2822
16/16 [==============================] - 0s 780us/step - loss: 1.5961
16/16 [==============================] - 0s 807us/step - loss: 1.6572
16/16 [==============================] - 0s 795us/step - loss: 1.6753
16/16 [==============================] - 0s 803us/step - loss: 1.6788
16/16 [==============================] - 0s 1ms/step - loss: 1.6791
16/16 [==============================] - 0s 682us/step - loss: 1.6786
16/16 [==============================] - 0s 750us/step - loss: 1.6782

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 660us/step - loss: 0.3169
16/16 [==============================] - 0s 1ms/step - loss: 0.7846
16/16 [==============================] - 0s 664us/step - loss: 1.2831
16/16 [==============================] - 0s 655us/step - loss: 1.6025
16/16 [==============================] - 0s 771us/step - loss: 1.6649
16/16 [==============================] - 0s 675us/step - loss: 1.6836
16/16 [==============================] - 0s 677us/step - loss: 1.6870
16/16 [==============================] - 0s 815us/step - loss: 1.6873
16/16 [==============================] - 0s 791us/step - loss: 1.6868
16/16 [==============================] - 0s 785us/step - loss: 1.6863
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 798us/step - loss: 0.3223
16/16 [==============================] - 0s 769us/step - loss: 0.7759
16/16 [==============================] - 0s 774us/step - loss: 1.2607
16/16 [==============================] - 0s 769us/step - loss: 1.5701
16/16 [==============================] - 0s 806us/step - loss: 1.6300
16/16 [==============================] - 0s 781us/step - loss: 1.6478
16/16 [==============================] - 0s 791us/step - loss: 1.6509
16/16 [==============================] - 0s 779us/step - loss: 1.6511
16/16 [==============================] - 0s 1ms/step - loss: 1.6506
16/16 [==============================] - 0s 779us/step - loss: 1.6501

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 779us/step - loss: 0.3189
16/16 [==============================] - 0s 824us/step - loss: 0.7810
16/16 [==============================] - 0s 808us/step - loss: 1.2802
16/16 [==============================] - 0s 809us/step - loss: 1.6001
16/16 [==============================] - 0s 777us/step - loss: 1.6622
16/16 [==============================] - 0s 785us/step - loss: 1.6807
16/16 [==============================] - 0s 780us/step - loss: 1.6840
16/16 [==============================] - 0s 805us/step - loss: 1.6842
16/16 [==============================] - 0s 783us/step - loss: 1.6838
16/16 [==============================] - 0s 818us/step - loss: 1.6833
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 606us/step
16/16 [==============================] - 0s 797us/step - loss: 0.3072
16/16 [==============================] - 0s 828us/step - loss: 0.7912
16/16 [==============================] - 0s 783us/step - loss: 1.3176
16/16 [==============================] - 0s 819us/step - loss: 1.6547
16/16 [==============================] - 0s 783us/step - loss: 1.7199
16/16 [==============================] - 0s 810us/step - loss: 1.7392
16/16 [==============================] - 0s 818us/step - loss: 1.7426
16/16 [==============================] - 0s 773us/step - loss: 1.7428
16/16 [==============================] - 0s 769us/step - loss: 1.7424
16/16 [==============================] - 0s 772us/step - loss: 1.7419

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 783us/step - loss: 0.3088
16/16 [==============================] - 0s 818us/step - loss: 0.7812
16/16 [==============================] - 0s 804us/step - loss: 1.2987
16/16 [==============================] - 0s 774us/step - loss: 1.6308
16/16 [==============================] - 0s 770us/step - loss: 1.6949
16/16 [==============================] - 0s 772us/step - loss: 1.7138
16/16 [==============================] - 0s 803us/step - loss: 1.7172
16/16 [==============================] - 0s 773us/step - loss: 1.7174
16/16 [==============================] - 0s 789us/step - loss: 1.7170
16/16 [==============================] - 0s 771us/step - loss: 1.7165
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 788us/step - loss: 0.3021
16/16 [==============================] - 0s 792us/step - loss: 0.7873
16/16 [==============================] - 0s 673us/step - loss: 1.3203
16/16 [==============================] - 0s 786us/step - loss: 1.6612
16/16 [==============================] - 0s 2ms/step - loss: 1.7264
16/16 [==============================] - 0s 2ms/step - loss: 1.7454
16/16 [==============================] - 0s 2ms/step - loss: 1.7487
16/16 [==============================] - 0s 767us/step - loss: 1.7489
16/16 [==============================] - 0s 2ms/step - loss: 1.7484
16/16 [==============================] - 0s 844us/step - loss: 1.7479

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2994
16/16 [==============================] - 0s 655us/step - loss: 0.7933
16/16 [==============================] - 0s 1ms/step - loss: 1.3330
16/16 [==============================] - 0s 818us/step - loss: 1.6811
16/16 [==============================] - 0s 1ms/step - loss: 1.7477
16/16 [==============================] - 0s 806us/step - loss: 1.7671
16/16 [==============================] - 0s 825us/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.7707
16/16 [==============================] - 0s 1ms/step - loss: 1.7702
16/16 [==============================] - 0s 2ms/step - loss: 1.7697
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.3054
16/16 [==============================] - 0s 2ms/step - loss: 0.7894
16/16 [==============================] - 0s 2ms/step - loss: 1.3140
16/16 [==============================] - 0s 799us/step - loss: 1.6513
16/16 [==============================] - 0s 1ms/step - loss: 1.7147
16/16 [==============================] - 0s 894us/step - loss: 1.7329
16/16 [==============================] - 0s 2ms/step - loss: 1.7359
16/16 [==============================] - 0s 896us/step - loss: 1.7360
16/16 [==============================] - 0s 1ms/step - loss: 1.7355
16/16 [==============================] - 0s 2ms/step - loss: 1.7350

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 551us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2985
16/16 [==============================] - 0s 2ms/step - loss: 0.7894
16/16 [==============================] - 0s 2ms/step - loss: 1.3189
16/16 [==============================] - 0s 2ms/step - loss: 1.6614
16/16 [==============================] - 0s 803us/step - loss: 1.7256
16/16 [==============================] - 0s 2ms/step - loss: 1.7439
16/16 [==============================] - 0s 2ms/step - loss: 1.7470
16/16 [==============================] - 0s 2ms/step - loss: 1.7471
16/16 [==============================] - 0s 2ms/step - loss: 1.7465
16/16 [==============================] - 0s 2ms/step - loss: 1.7460
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2929
16/16 [==============================] - 0s 773us/step - loss: 0.7969
16/16 [==============================] - 0s 1ms/step - loss: 1.3407
16/16 [==============================] - 0s 2ms/step - loss: 1.6916
16/16 [==============================] - 0s 2ms/step - loss: 1.7567
16/16 [==============================] - 0s 819us/step - loss: 1.7749
16/16 [==============================] - 0s 2ms/step - loss: 1.7779
16/16 [==============================] - 0s 2ms/step - loss: 1.7780
16/16 [==============================] - 0s 2ms/step - loss: 1.7775
16/16 [==============================] - 0s 2ms/step - loss: 1.7769

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 796us/step - loss: 0.2909
16/16 [==============================] - 0s 772us/step - loss: 0.7933
16/16 [==============================] - 0s 823us/step - loss: 1.3388
16/16 [==============================] - 0s 2ms/step - loss: 1.6890
16/16 [==============================] - 0s 951us/step - loss: 1.7538
16/16 [==============================] - 0s 831us/step - loss: 1.7717
16/16 [==============================] - 0s 1ms/step - loss: 1.7746
16/16 [==============================] - 0s 2ms/step - loss: 1.7747
16/16 [==============================] - 0s 796us/step - loss: 1.7741
16/16 [==============================] - 0s 2ms/step - loss: 1.7736
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 791us/step - loss: 0.2946
16/16 [==============================] - 0s 786us/step - loss: 0.7951
16/16 [==============================] - 0s 823us/step - loss: 1.3410
16/16 [==============================] - 0s 1ms/step - loss: 1.6875
16/16 [==============================] - 0s 1ms/step - loss: 1.7506
16/16 [==============================] - 0s 812us/step - loss: 1.7678
16/16 [==============================] - 0s 1ms/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.7705
16/16 [==============================] - 0s 1ms/step - loss: 1.7700
16/16 [==============================] - 0s 2ms/step - loss: 1.7694

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2911
16/16 [==============================] - 0s 789us/step - loss: 0.7943
16/16 [==============================] - 0s 817us/step - loss: 1.3485
16/16 [==============================] - 0s 2ms/step - loss: 1.6968
16/16 [==============================] - 0s 934us/step - loss: 1.7600
16/16 [==============================] - 0s 2ms/step - loss: 1.7771
16/16 [==============================] - 0s 816us/step - loss: 1.7797
16/16 [==============================] - 0s 807us/step - loss: 1.7796
16/16 [==============================] - 0s 820us/step - loss: 1.7791
16/16 [==============================] - 0s 932us/step - loss: 1.7785
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 804us/step - loss: 0.2932
16/16 [==============================] - 0s 2ms/step - loss: 0.7938
16/16 [==============================] - 0s 2ms/step - loss: 1.3487
16/16 [==============================] - 0s 942us/step - loss: 1.6919
16/16 [==============================] - 0s 984us/step - loss: 1.7534
16/16 [==============================] - 0s 828us/step - loss: 1.7699
16/16 [==============================] - 0s 2ms/step - loss: 1.7723
16/16 [==============================] - 0s 839us/step - loss: 1.7722
16/16 [==============================] - 0s 801us/step - loss: 1.7717
16/16 [==============================] - 0s 796us/step - loss: 1.7711

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 805us/step - loss: 0.2842
16/16 [==============================] - 0s 2ms/step - loss: 0.8012
16/16 [==============================] - 0s 2ms/step - loss: 1.3785
16/16 [==============================] - 0s 809us/step - loss: 1.7329
16/16 [==============================] - 0s 853us/step - loss: 1.7961
16/16 [==============================] - 0s 2ms/step - loss: 1.8129
16/16 [==============================] - 0s 812us/step - loss: 1.8153
16/16 [==============================] - 0s 1ms/step - loss: 1.8152
16/16 [==============================] - 0s 760us/step - loss: 1.8146
16/16 [==============================] - 0s 794us/step - loss: 1.8141
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 831us/step - loss: 0.2767
16/16 [==============================] - 0s 805us/step - loss: 0.8072
16/16 [==============================] - 0s 1ms/step - loss: 1.4037
16/16 [==============================] - 0s 869us/step - loss: 1.7654
16/16 [==============================] - 0s 843us/step - loss: 1.8289
16/16 [==============================] - 0s 814us/step - loss: 1.8455
16/16 [==============================] - 0s 837us/step - loss: 1.8479
16/16 [==============================] - 0s 827us/step - loss: 1.8477
16/16 [==============================] - 0s 2ms/step - loss: 1.8471
16/16 [==============================] - 0s 2ms/step - loss: 1.8466

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 582us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2830
16/16 [==============================] - 0s 2ms/step - loss: 0.8001
16/16 [==============================] - 0s 2ms/step - loss: 1.3796
16/16 [==============================] - 0s 799us/step - loss: 1.7297
16/16 [==============================] - 0s 822us/step - loss: 1.7904
16/16 [==============================] - 0s 2ms/step - loss: 1.8061
16/16 [==============================] - 0s 830us/step - loss: 1.8082
16/16 [==============================] - 0s 2ms/step - loss: 1.8080
16/16 [==============================] - 0s 805us/step - loss: 1.8074
16/16 [==============================] - 0s 842us/step - loss: 1.8069
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 671us/step
16/16 [==============================] - 0s 763us/step - loss: 0.2810
16/16 [==============================] - 0s 786us/step - loss: 0.8040
16/16 [==============================] - 0s 770us/step - loss: 1.3884
16/16 [==============================] - 0s 764us/step - loss: 1.7378
16/16 [==============================] - 0s 757us/step - loss: 1.7973
16/16 [==============================] - 0s 769us/step - loss: 1.8124
16/16 [==============================] - 0s 773us/step - loss: 1.8144
16/16 [==============================] - 0s 1ms/step - loss: 1.8141
16/16 [==============================] - 0s 1ms/step - loss: 1.8134
16/16 [==============================] - 0s 1ms/step - loss: 1.8129

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2789
16/16 [==============================] - 0s 783us/step - loss: 0.8059
16/16 [==============================] - 0s 779us/step - loss: 1.3913
16/16 [==============================] - 0s 762us/step - loss: 1.7401
16/16 [==============================] - 0s 762us/step - loss: 1.7989
16/16 [==============================] - 0s 846us/step - loss: 1.8136
16/16 [==============================] - 0s 857us/step - loss: 1.8155
16/16 [==============================] - 0s 839us/step - loss: 1.8151
16/16 [==============================] - 0s 860us/step - loss: 1.8145
16/16 [==============================] - 0s 877us/step - loss: 1.8139
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2754
16/16 [==============================] - 0s 800us/step - loss: 0.8119
16/16 [==============================] - 0s 791us/step - loss: 1.4077
16/16 [==============================] - 0s 786us/step - loss: 1.7589
16/16 [==============================] - 0s 1ms/step - loss: 1.8171
16/16 [==============================] - 0s 801us/step - loss: 1.8315
16/16 [==============================] - 0s 886us/step - loss: 1.8332
16/16 [==============================] - 0s 1ms/step - loss: 1.8328
16/16 [==============================] - 0s 875us/step - loss: 1.8322
16/16 [==============================] - 0s 861us/step - loss: 1.8316

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 789us/step - loss: 0.2707
16/16 [==============================] - 0s 784us/step - loss: 0.8127
16/16 [==============================] - 0s 817us/step - loss: 1.4127
16/16 [==============================] - 0s 815us/step - loss: 1.7644
16/16 [==============================] - 0s 792us/step - loss: 1.8221
16/16 [==============================] - 0s 817us/step - loss: 1.8361
16/16 [==============================] - 0s 800us/step - loss: 1.8377
16/16 [==============================] - 0s 800us/step - loss: 1.8373
16/16 [==============================] - 0s 812us/step - loss: 1.8366
16/16 [==============================] - 0s 856us/step - loss: 1.8360
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 809us/step - loss: 0.2747
16/16 [==============================] - 0s 783us/step - loss: 0.8236
16/16 [==============================] - 0s 793us/step - loss: 1.4341
16/16 [==============================] - 0s 1ms/step - loss: 1.7868
16/16 [==============================] - 0s 904us/step - loss: 1.8438
16/16 [==============================] - 0s 877us/step - loss: 1.8574
16/16 [==============================] - 0s 811us/step - loss: 1.8589
16/16 [==============================] - 0s 807us/step - loss: 1.8584
16/16 [==============================] - 0s 791us/step - loss: 1.8578
16/16 [==============================] - 0s 820us/step - loss: 1.8572

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2854
16/16 [==============================] - 0s 818us/step - loss: 0.8126
16/16 [==============================] - 0s 790us/step - loss: 1.3992
16/16 [==============================] - 0s 837us/step - loss: 1.7342
16/16 [==============================] - 0s 789us/step - loss: 1.7876
16/16 [==============================] - 0s 781us/step - loss: 1.8000
16/16 [==============================] - 0s 785us/step - loss: 1.8013
16/16 [==============================] - 0s 779us/step - loss: 1.8007
16/16 [==============================] - 0s 781us/step - loss: 1.8000
16/16 [==============================] - 0s 806us/step - loss: 1.7995
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 788us/step - loss: 0.2657
16/16 [==============================] - 0s 813us/step - loss: 0.8298
16/16 [==============================] - 0s 787us/step - loss: 1.4637
16/16 [==============================] - 0s 791us/step - loss: 1.8214
16/16 [==============================] - 0s 790us/step - loss: 1.8778
16/16 [==============================] - 0s 780us/step - loss: 1.8907
16/16 [==============================] - 0s 803us/step - loss: 1.8920
16/16 [==============================] - 0s 817us/step - loss: 1.8915
16/16 [==============================] - 0s 779us/step - loss: 1.8908
16/16 [==============================] - 0s 777us/step - loss: 1.8902

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 594us/step
16/16 [==============================] - 0s 818us/step - loss: 0.2715
16/16 [==============================] - 0s 1ms/step - loss: 0.8213
16/16 [==============================] - 0s 1ms/step - loss: 1.4421
16/16 [==============================] - 0s 1ms/step - loss: 1.7886
16/16 [==============================] - 0s 1ms/step - loss: 1.8427
16/16 [==============================] - 0s 787us/step - loss: 1.8549
16/16 [==============================] - 0s 1ms/step - loss: 1.8561
16/16 [==============================] - 0s 1ms/step - loss: 1.8555
16/16 [==============================] - 0s 1ms/step - loss: 1.8549
16/16 [==============================] - 0s 796us/step - loss: 1.8543
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 821us/step - loss: 0.2673
16/16 [==============================] - 0s 799us/step - loss: 0.8241
16/16 [==============================] - 0s 780us/step - loss: 1.4541
16/16 [==============================] - 0s 796us/step - loss: 1.8011
16/16 [==============================] - 0s 811us/step - loss: 1.8543
16/16 [==============================] - 0s 779us/step - loss: 1.8660
16/16 [==============================] - 0s 791us/step - loss: 1.8671
16/16 [==============================] - 0s 771us/step - loss: 1.8665
16/16 [==============================] - 0s 823us/step - loss: 1.8658
16/16 [==============================] - 0s 774us/step - loss: 1.8652

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 801us/step - loss: 0.2792
16/16 [==============================] - 0s 780us/step - loss: 0.8209
16/16 [==============================] - 0s 825us/step - loss: 1.4352
16/16 [==============================] - 0s 812us/step - loss: 1.7676
16/16 [==============================] - 0s 821us/step - loss: 1.8181
16/16 [==============================] - 0s 814us/step - loss: 1.8289
16/16 [==============================] - 0s 1ms/step - loss: 1.8298
16/16 [==============================] - 0s 1ms/step - loss: 1.8291
16/16 [==============================] - 0s 802us/step - loss: 1.8284
16/16 [==============================] - 0s 797us/step - loss: 1.8278
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 859us/step - loss: 0.2657
16/16 [==============================] - 0s 817us/step - loss: 0.8274
16/16 [==============================] - 0s 799us/step - loss: 1.4711
16/16 [==============================] - 0s 898us/step - loss: 1.8159
16/16 [==============================] - 0s 791us/step - loss: 1.8675
16/16 [==============================] - 0s 821us/step - loss: 1.8786
16/16 [==============================] - 0s 802us/step - loss: 1.8795
16/16 [==============================] - 0s 823us/step - loss: 1.8789
16/16 [==============================] - 0s 779us/step - loss: 1.8782
16/16 [==============================] - 0s 797us/step - loss: 1.8776

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 612us/step
16/16 [==============================] - 0s 792us/step - loss: 0.2711
16/16 [==============================] - 0s 779us/step - loss: 0.8247
16/16 [==============================] - 0s 798us/step - loss: 1.4613
16/16 [==============================] - 0s 772us/step - loss: 1.7968
16/16 [==============================] - 0s 780us/step - loss: 1.8466
16/16 [==============================] - 0s 797us/step - loss: 1.8571
16/16 [==============================] - 0s 811us/step - loss: 1.8579
16/16 [==============================] - 0s 801us/step - loss: 1.8572
16/16 [==============================] - 0s 776us/step - loss: 1.8565
16/16 [==============================] - 0s 774us/step - loss: 1.8559
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2669
16/16 [==============================] - 0s 830us/step - loss: 0.8337
16/16 [==============================] - 0s 782us/step - loss: 1.4889
16/16 [==============================] - 0s 901us/step - loss: 1.8301
16/16 [==============================] - 0s 812us/step - loss: 1.8797
16/16 [==============================] - 0s 816us/step - loss: 1.8901
16/16 [==============================] - 0s 775us/step - loss: 1.8908
16/16 [==============================] - 0s 778us/step - loss: 1.8901
16/16 [==============================] - 0s 797us/step - loss: 1.8894
16/16 [==============================] - 0s 784us/step - loss: 1.8888

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 811us/step - loss: 0.2687
16/16 [==============================] - 0s 800us/step - loss: 0.8254
16/16 [==============================] - 0s 794us/step - loss: 1.4729
16/16 [==============================] - 0s 777us/step - loss: 1.8040
16/16 [==============================] - 0s 775us/step - loss: 1.8518
16/16 [==============================] - 0s 790us/step - loss: 1.8616
16/16 [==============================] - 0s 806us/step - loss: 1.8622
16/16 [==============================] - 0s 781us/step - loss: 1.8615
16/16 [==============================] - 0s 804us/step - loss: 1.8608
16/16 [==============================] - 0s 782us/step - loss: 1.8602
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2630
16/16 [==============================] - 0s 1ms/step - loss: 0.8345
16/16 [==============================] - 0s 1ms/step - loss: 1.5023
16/16 [==============================] - 0s 1ms/step - loss: 1.8396
16/16 [==============================] - 0s 1ms/step - loss: 1.8872
16/16 [==============================] - 0s 769us/step - loss: 1.8970
16/16 [==============================] - 0s 822us/step - loss: 1.8976
16/16 [==============================] - 0s 778us/step - loss: 1.8968
16/16 [==============================] - 0s 778us/step - loss: 1.8961
16/16 [==============================] - 0s 804us/step - loss: 1.8955

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 787us/step - loss: 0.2649
16/16 [==============================] - 0s 825us/step - loss: 0.8307
16/16 [==============================] - 0s 785us/step - loss: 1.4969
16/16 [==============================] - 0s 799us/step - loss: 1.8271
16/16 [==============================] - 0s 800us/step - loss: 1.8735
16/16 [==============================] - 0s 1ms/step - loss: 1.8829
16/16 [==============================] - 0s 1ms/step - loss: 1.8834
16/16 [==============================] - 0s 1ms/step - loss: 1.8826
16/16 [==============================] - 0s 1ms/step - loss: 1.8818
16/16 [==============================] - 0s 1ms/step - loss: 1.8813
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 845us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2646
16/16 [==============================] - 0s 1ms/step - loss: 0.8302
16/16 [==============================] - 0s 1ms/step - loss: 1.4973
16/16 [==============================] - 0s 780us/step - loss: 1.8229
16/16 [==============================] - 0s 773us/step - loss: 1.8679
16/16 [==============================] - 0s 794us/step - loss: 1.8768
16/16 [==============================] - 0s 1ms/step - loss: 1.8772
16/16 [==============================] - 0s 1ms/step - loss: 1.8763
16/16 [==============================] - 0s 804us/step - loss: 1.8756
16/16 [==============================] - 0s 806us/step - loss: 1.8750

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 844us/step - loss: 0.2654
16/16 [==============================] - 0s 777us/step - loss: 0.8271
16/16 [==============================] - 0s 797us/step - loss: 1.4953
16/16 [==============================] - 0s 781us/step - loss: 1.8151
16/16 [==============================] - 0s 797us/step - loss: 1.8594
16/16 [==============================] - 0s 774us/step - loss: 1.8680
16/16 [==============================] - 0s 811us/step - loss: 1.8683
16/16 [==============================] - 0s 808us/step - loss: 1.8674
16/16 [==============================] - 0s 782us/step - loss: 1.8667
16/16 [==============================] - 0s 785us/step - loss: 1.8661
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 626us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2603
16/16 [==============================] - 0s 797us/step - loss: 0.8334
16/16 [==============================] - 0s 781us/step - loss: 1.5190
16/16 [==============================] - 0s 775us/step - loss: 1.8422
16/16 [==============================] - 0s 772us/step - loss: 1.8866
16/16 [==============================] - 0s 819us/step - loss: 1.8950
16/16 [==============================] - 0s 814us/step - loss: 1.8952
16/16 [==============================] - 0s 790us/step - loss: 1.8943
16/16 [==============================] - 0s 798us/step - loss: 1.8935
16/16 [==============================] - 0s 802us/step - loss: 1.8930

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 635us/step
16/16 [==============================] - 0s 785us/step - loss: 0.2586
16/16 [==============================] - 0s 775us/step - loss: 0.8385
16/16 [==============================] - 0s 784us/step - loss: 1.5405
16/16 [==============================] - 0s 786us/step - loss: 1.8654
16/16 [==============================] - 0s 784us/step - loss: 1.9105
16/16 [==============================] - 0s 787us/step - loss: 1.9188
16/16 [==============================] - 0s 787us/step - loss: 1.9191
16/16 [==============================] - 0s 825us/step - loss: 1.9182
16/16 [==============================] - 0s 796us/step - loss: 1.9175
16/16 [==============================] - 0s 790us/step - loss: 1.9169
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 896us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2664
16/16 [==============================] - 0s 887us/step - loss: 0.8317
16/16 [==============================] - 0s 789us/step - loss: 1.5162
16/16 [==============================] - 0s 1ms/step - loss: 1.8275
16/16 [==============================] - 0s 807us/step - loss: 1.8701
16/16 [==============================] - 0s 780us/step - loss: 1.8777
16/16 [==============================] - 0s 782us/step - loss: 1.8779
16/16 [==============================] - 0s 782us/step - loss: 1.8769
16/16 [==============================] - 0s 778us/step - loss: 1.8762
16/16 [==============================] - 0s 801us/step - loss: 1.8756

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 793us/step - loss: 0.2565
16/16 [==============================] - 0s 790us/step - loss: 0.8364
16/16 [==============================] - 0s 832us/step - loss: 1.5469
16/16 [==============================] - 0s 782us/step - loss: 1.8653
16/16 [==============================] - 0s 796us/step - loss: 1.9092
16/16 [==============================] - 0s 783us/step - loss: 1.9169
16/16 [==============================] - 0s 790us/step - loss: 1.9171
16/16 [==============================] - 0s 785us/step - loss: 1.9162
16/16 [==============================] - 0s 799us/step - loss: 1.9154
16/16 [==============================] - 0s 822us/step - loss: 1.9149
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 843us/step - loss: 0.2551
16/16 [==============================] - 0s 823us/step - loss: 0.8408
16/16 [==============================] - 0s 1ms/step - loss: 1.5610
16/16 [==============================] - 0s 804us/step - loss: 1.8795
16/16 [==============================] - 0s 1ms/step - loss: 1.9230
16/16 [==============================] - 0s 832us/step - loss: 1.9304
16/16 [==============================] - 0s 1ms/step - loss: 1.9306
16/16 [==============================] - 0s 1ms/step - loss: 1.9296
16/16 [==============================] - 0s 875us/step - loss: 1.9289
16/16 [==============================] - 0s 825us/step - loss: 1.9283

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 794us/step
16/16 [==============================] - 0s 827us/step - loss: 0.2557
16/16 [==============================] - 0s 812us/step - loss: 0.8404
16/16 [==============================] - 0s 1ms/step - loss: 1.5661
16/16 [==============================] - 0s 1ms/step - loss: 1.8818
16/16 [==============================] - 0s 1ms/step - loss: 1.9253
16/16 [==============================] - 0s 1ms/step - loss: 1.9326
16/16 [==============================] - 0s 820us/step - loss: 1.9327
16/16 [==============================] - 0s 1ms/step - loss: 1.9318
16/16 [==============================] - 0s 1ms/step - loss: 1.9311
16/16 [==============================] - 0s 1ms/step - loss: 1.9305
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2626
16/16 [==============================] - 0s 1ms/step - loss: 0.8359
16/16 [==============================] - 0s 1ms/step - loss: 1.5479
16/16 [==============================] - 0s 1ms/step - loss: 1.8518
16/16 [==============================] - 0s 1ms/step - loss: 1.8930
16/16 [==============================] - 0s 1ms/step - loss: 1.8996
16/16 [==============================] - 0s 853us/step - loss: 1.8996
16/16 [==============================] - 0s 825us/step - loss: 1.8986
16/16 [==============================] - 0s 819us/step - loss: 1.8979
16/16 [==============================] - 0s 857us/step - loss: 1.8973

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 645us/step
16/16 [==============================] - 0s 813us/step - loss: 0.2643
16/16 [==============================] - 0s 836us/step - loss: 0.8245
16/16 [==============================] - 0s 851us/step - loss: 1.5218
16/16 [==============================] - 0s 854us/step - loss: 1.8173
16/16 [==============================] - 0s 807us/step - loss: 1.8571
16/16 [==============================] - 0s 829us/step - loss: 1.8634
16/16 [==============================] - 0s 803us/step - loss: 1.8633
16/16 [==============================] - 0s 814us/step - loss: 1.8623
16/16 [==============================] - 0s 811us/step - loss: 1.8615
16/16 [==============================] - 0s 828us/step - loss: 1.8609
32/32 [==============================] - 0s 634us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1614">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1615">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1616">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_MO_GAAL_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1617">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-108-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.940
Precision: 0.965
Recall: 0.972
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1618">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>therteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  therteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscpstar" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar">LSCP<span class="math inline">\(\star\)</span></h3>
<p>default=10%</p>
<div class="cell" data-execution_count="1619">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>]])</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1620">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1621">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1622">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_1,outlier_LSCP_one,tab_linear)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1623">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-114-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1624">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> therteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = therteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="linear-result" class="level2">
<h2 class="anchored" data-anchor-id="linear-result">Linear Result</h2>
<p><span class="math inline">\(U^\star\)</span>, which is a mixture of uniform distributions <span class="math inline">\(U(5,7)\)</span> and <span class="math inline">\(U(-7,-5)\)</span>.</p>
<div class="cell" data-execution_count="1625">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>fourteen</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1625">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.926</td>
      <td>0.961053</td>
      <td>0.961053</td>
      <td>0.961053</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.950</td>
      <td>1.000000</td>
      <td>0.947368</td>
      <td>0.972973</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.991121</td>
      <td>0.940000</td>
      <td>0.964884</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.998</td>
      <td>0.998947</td>
      <td>0.998947</td>
      <td>0.998947</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.986</td>
      <td>0.992632</td>
      <td>0.992632</td>
      <td>0.992632</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.868</td>
      <td>0.998780</td>
      <td>0.862105</td>
      <td>0.925424</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.960</td>
      <td>0.977941</td>
      <td>0.980000</td>
      <td>0.978970</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.916</td>
      <td>0.955789</td>
      <td>0.955789</td>
      <td>0.955789</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.936</td>
      <td>0.966316</td>
      <td>0.966316</td>
      <td>0.966316</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.940</td>
      <td>0.965481</td>
      <td>0.971579</td>
      <td>0.968520</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.993684</td>
      <td>0.993684</td>
      <td>0.993684</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="orbit-ebayesthresh" class="level2">
<h2 class="anchored" data-anchor-id="orbit-ebayesthresh">Orbit EbayesThresh</h2>
<div class="cell" data-execution_count="1899">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext rpy2.ipython</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rpy2.ipython extension is already loaded. To reload it, use:
  %reload_ext rpy2.ipython</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1900">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>R</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>library(EbayesThresh)</span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>.seed(<span class="dv">1</span>)</span>
<span id="cb169-4"><a href="#cb169-4" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> rnorm(<span class="dv">1000</span>)</span>
<span id="cb169-5"><a href="#cb169-5" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> sample(c(runif(<span class="dv">25</span>,<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">5</span>), runif(<span class="dv">25</span>,<span class="dv">5</span>,<span class="dv">7</span>), rep(<span class="dv">0</span>,<span class="dv">950</span>)))</span>
<span id="cb169-6"><a href="#cb169-6" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier <span class="op">=</span> which(signal<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb169-7"><a href="#cb169-7" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier</span>
<span id="cb169-8"><a href="#cb169-8" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>signal<span class="op">+</span>epsilon</span>
<span id="cb169-9"><a href="#cb169-9" aria-hidden="true" tabindex="-1"></a>plot(<span class="dv">1</span>:<span class="dv">1000</span>,x)</span>
<span id="cb169-10"><a href="#cb169-10" aria-hidden="true" tabindex="-1"></a>points(index_of_trueoutlier,x[index_of_trueoutlier],col<span class="op">=</span><span class="dv">2</span>,cex<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb169-11"><a href="#cb169-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-12"><a href="#cb169-12" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(x,type='l')</span></span>
<span id="cb169-13"><a href="#cb169-13" aria-hidden="true" tabindex="-1"></a><span class="co">#mu &lt;- EbayesThresh::ebayesthresh(x,sdev=2)</span></span>
<span id="cb169-14"><a href="#cb169-14" aria-hidden="true" tabindex="-1"></a><span class="co">#lines(mu,col=2,lty=2,lwd=2)</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-118-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="1901">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o x</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o index_of_trueoutlier</span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o signal</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1902">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="op">=</span> importr(<span class="st">'EbayesThresh'</span>).ebayesthresh</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1903">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>xhat <span class="op">=</span> np.array(ebayesthresh(FloatVector(x)))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1904">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(x)</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(xhat)</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1905">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>outlier_true_index <span class="op">=</span> index_of_trueoutlier</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1906">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>outlier_true_value <span class="op">=</span> x[index_of_trueoutlier]</span></code></pre></div>
</div>
<p>package와 비교를 위해 outlier는 -1, inlier는 1로 표시</p>
<div class="cell" data-execution_count="1907">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> signal.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1908">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x<span class="op">!=</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1909">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one).to_csv('orbit_outlier.csv')</span></span></code></pre></div>
</div>
</section>
<section id="orbit" class="level2">
<h2 class="anchored" data-anchor-id="orbit">Orbit</h2>
<div class="cell" data-execution_count="1877">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">777</span>)</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>pi<span class="op">=</span>np.pi</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>ang<span class="op">=</span>np.linspace(<span class="op">-</span>pi,pi<span class="op">-</span><span class="dv">2</span><span class="op">*</span>pi<span class="op">/</span>n,n)</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a>r<span class="op">=</span><span class="dv">5</span><span class="op">+</span>np.cos(np.linspace(<span class="dv">0</span>,<span class="dv">12</span><span class="op">*</span>pi,n))</span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>vx<span class="op">=</span>r<span class="op">*</span>np.cos(ang)</span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a>vy<span class="op">=</span>r<span class="op">*</span>np.sin(ang)</span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span><span class="dv">10</span><span class="op">*</span>np.sin(np.linspace(<span class="dv">0</span>,<span class="dv">6</span><span class="op">*</span>pi,n))</span>
<span id="cb179-9"><a href="#cb179-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f1 <span class="op">+</span> x</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1878">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span> : vx, <span class="st">'y'</span> : vy, <span class="st">'f'</span> : f})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1879">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1642">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save_data(_df,'Orbit.pkl')</span></span></code></pre></div>
</div>
<section id="gode-1" class="level3">
<h3 class="anchored" data-anchor-id="gode-1">GODE</h3>
<div class="cell" data-execution_count="1643">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>_Orbit <span class="op">=</span> Orbit(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1644">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_distance()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1000/1000 [00:02&lt;00:00, 340.03it/s]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1645">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>_Orbit.get_weightmatrix(theta<span class="op">=</span>(_Orbit.D[_Orbit.D<span class="op">&gt;</span><span class="dv">0</span>].mean()),kappa<span class="op">=</span><span class="dv">2500</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="1646">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>_Orbit.fit(sd<span class="op">=</span><span class="dv">15</span>,ref<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1647">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_Orbit.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1648">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">13</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1649">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1649">
<pre><code>950</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1650">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1650">
<pre><code>50</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1651">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_simul_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1652">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-141-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.998
Precision: 0.999
Recall: 0.999
F1 Score: 0.999</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1653">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lofstar" class="level3">
<h3 class="anchored" data-anchor-id="lofstar">LOF<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1654">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1655">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,clf.fit_predict(X),tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1656">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-145-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.976
Recall: 0.976
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1658">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn-1" class="level3">
<h3 class="anchored" data-anchor-id="knn-1">KNN</h3>
<div class="cell" data-tags="[]" data-execution_count="1659">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1660">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1661">
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1662">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_KNN_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1663">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-151-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.948
Precision: 0.999
Recall: 0.946
F1 Score: 0.972</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1664">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof" class="level3">
<h3 class="anchored" data-anchor-id="cblof">CBLOF</h3>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> load_data(<span class="st">'Orbit.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one <span class="op">=</span> pd.read_csv(<span class="st">'orbit_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb220-3"><a href="#cb220-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span>
<span id="cb220-4"><a href="#cb220-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-5"><a href="#cb220-5" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span>
<span id="cb220-6"><a href="#cb220-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-7"><a href="#cb220-7" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span>
<span id="cb220-8"><a href="#cb220-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-9"><a href="#cb220-9" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_CBLOF_one,tab_orbit)</span>
<span id="cb220-10"><a href="#cb220-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-11"><a href="#cb220-11" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span>
<span id="cb220-12"><a href="#cb220-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-13"><a href="#cb220-13" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-157-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<ul>
<li>Accuracy: 0.916</li>
<li>Precision: 0.956</li>
<li>Recall: 0.956</li>
<li>F1 Score: 0.956</li>
</ul>
</section>
<section id="ocsvm-1" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-1">OCSVM</h3>
<div class="cell" data-execution_count="1668">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1669">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1669">
<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked=""><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.05, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="1670">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1671">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_OSVM_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1672">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-162-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.908
Precision: 0.977
Recall: 0.925
F1 Score: 0.950</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1674">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcdstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mcdstar-1">MCD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1675">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb233-3"><a href="#cb233-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1676">
<div class="sourceCode cell-code" id="cb234"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1677">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1678">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MCD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1679">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-168-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.916
Precision: 0.956
Recall: 0.956
F1 Score: 0.956</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1682">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-baggingstar-1" class="level3">
<h3 class="anchored" data-anchor-id="feature-baggingstar-1">Feature Bagging<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1683">
<div class="sourceCode cell-code" id="cb242"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb242-2"><a href="#cb242-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb242-3"><a href="#cb242-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1684">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1685">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1686">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_FeatureBagging_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1687">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-174-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.969
Recall: 0.969
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1688">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abodstar-1" class="level3">
<h3 class="anchored" data-anchor-id="abodstar-1">ABOD<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1689">
<div class="sourceCode cell-code" id="cb251"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb251-2"><a href="#cb251-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb251-3"><a href="#cb251-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1690">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1691">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1692">
<div class="sourceCode cell-code" id="cb254"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_ABOD_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1693">
<div class="sourceCode cell-code" id="cb255"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-180-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1695">
<div class="sourceCode cell-code" id="cb258"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="iforeststar-1" class="level3">
<h3 class="anchored" data-anchor-id="iforeststar-1">IForest<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1696">
<div class="sourceCode cell-code" id="cb260"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb260-2"><a href="#cb260-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb260-3"><a href="#cb260-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span></span>
<span id="cb260-4"><a href="#cb260-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1697">
<div class="sourceCode cell-code" id="cb261"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1698">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb262-2"><a href="#cb262-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]],</span>
<span id="cb262-3"><a href="#cb262-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb262-4"><a href="#cb262-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1699">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1700">
<div class="sourceCode cell-code" id="cb264"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1701">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1702">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_alibi_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1703">
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-189-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.443
Precision: 0.992
Recall: 0.417
F1 Score: 0.587</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1704">
<div class="sourceCode cell-code" id="cb270"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="hbosstar-1">HBOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1705">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb272-2"><a href="#cb272-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb272-3"><a href="#cb272-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1706">
<div class="sourceCode cell-code" id="cb273"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1707">
<div class="sourceCode cell-code" id="cb274"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1708">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_HBOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1709">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-195-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.960
Recall: 0.973
F1 Score: 0.966</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1711">
<div class="sourceCode cell-code" id="cb279"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sosstar-1" class="level3">
<h3 class="anchored" data-anchor-id="sosstar-1">SOS<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1712">
<div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb281-2"><a href="#cb281-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb281-3"><a href="#cb281-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1713">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1714">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1715">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SOS_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1716">
<div class="sourceCode cell-code" id="cb285"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-201-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.974
Recall: 0.974
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1718">
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaalstar" class="level3">
<h3 class="anchored" data-anchor-id="so_gaalstar">SO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1719">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 969us/step - loss: 1.3463

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.3506
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3586

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3721
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.3866

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.3800
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4006

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.4023
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4122

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.4314
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4473

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.4588
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.4734

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.4913
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5128

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5221
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5512

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5569
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.5717

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.5833
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.5991

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6237
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.6486

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6528
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.6775

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.6728
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.6961

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7114
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7382

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.7361
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7442

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7632
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7813

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.7997
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8135

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8074
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8185

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 1.8404
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 4ms/step - loss: 1.8432

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8590
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8644

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.8872
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9012

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 4ms/step - loss: 1.9049
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9139

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9184
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 1.9365

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9581
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.9824

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 1.9639
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0122

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0024
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0080

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.0230
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0424

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0419
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0648

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.0705
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0983

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1023
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1145

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.1403
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1403

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1572
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1621

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.1594
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1776

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1913
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.2041

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2355
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2292

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2431
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2475

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2408
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2696

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2748
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3000

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.3168
32/32 [==============================] - 0s 2ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1720">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1721">
<div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1722">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_SO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1723">
<div class="sourceCode cell-code" id="cb296"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-207-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1724">
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaalstar-1" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaalstar-1">MO_GAAL<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1725">
<div class="sourceCode cell-code" id="cb301"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb301-1"><a href="#cb301-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb301-2"><a href="#cb301-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb301-3"><a href="#cb301-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 4 of 60

Testing for epoch 4 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 4 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 5 of 60

Testing for epoch 5 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 5 index 2:
32/32 [==============================] - 0s 3ms/step
Epoch 6 of 60

Testing for epoch 6 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 6 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 7 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 8 of 60

Testing for epoch 8 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 8 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 9 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 10 of 60

Testing for epoch 10 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 10 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 11 of 60

Testing for epoch 11 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 11 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 12 of 60

Testing for epoch 12 index 1:
32/32 [==============================] - 0s 3ms/step

Testing for epoch 12 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 13 of 60

Testing for epoch 13 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 13 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 14 of 60

Testing for epoch 14 index 1:
32/32 [==============================] - 0s 2ms/step

Testing for epoch 14 index 2:
32/32 [==============================] - 0s 1ms/step
Epoch 15 of 60

Testing for epoch 15 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 15 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 16 of 60

Testing for epoch 16 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 16 index 2:
32/32 [==============================] - 0s 992us/step
Epoch 17 of 60

Testing for epoch 17 index 1:
32/32 [==============================] - 0s 1ms/step

Testing for epoch 17 index 2:
32/32 [==============================] - 0s 782us/step
Epoch 18 of 60

Testing for epoch 18 index 1:
32/32 [==============================] - 0s 680us/step

Testing for epoch 18 index 2:
32/32 [==============================] - 0s 801us/step
Epoch 19 of 60

Testing for epoch 19 index 1:
32/32 [==============================] - 0s 642us/step

Testing for epoch 19 index 2:
32/32 [==============================] - 0s 617us/step
Epoch 20 of 60

Testing for epoch 20 index 1:
32/32 [==============================] - 0s 801us/step

Testing for epoch 20 index 2:
32/32 [==============================] - 0s 2ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
32/32 [==============================] - 0s 894us/step

Testing for epoch 21 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4662
16/16 [==============================] - 0s 1ms/step - loss: 1.1250
16/16 [==============================] - 0s 1ms/step - loss: 1.1652
16/16 [==============================] - 0s 1ms/step - loss: 1.1668
16/16 [==============================] - 0s 997us/step - loss: 1.1673
16/16 [==============================] - 0s 965us/step - loss: 1.1677
16/16 [==============================] - 0s 1ms/step - loss: 1.1681
16/16 [==============================] - 0s 1ms/step - loss: 1.1688
16/16 [==============================] - 0s 971us/step - loss: 1.1690
16/16 [==============================] - 0s 2ms/step - loss: 1.1690
Epoch 22 of 60

Testing for epoch 22 index 1:
32/32 [==============================] - 0s 858us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4861
16/16 [==============================] - 0s 2ms/step - loss: 1.1078
16/16 [==============================] - 0s 1ms/step - loss: 1.1395
16/16 [==============================] - 0s 1ms/step - loss: 1.1408
16/16 [==============================] - 0s 1ms/step - loss: 1.1412
16/16 [==============================] - 0s 1ms/step - loss: 1.1417
16/16 [==============================] - 0s 2ms/step - loss: 1.1423
16/16 [==============================] - 0s 2ms/step - loss: 1.1430
16/16 [==============================] - 0s 1ms/step - loss: 1.1433
16/16 [==============================] - 0s 1ms/step - loss: 1.1433

Testing for epoch 22 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4978
16/16 [==============================] - 0s 2ms/step - loss: 1.1226
16/16 [==============================] - 0s 1ms/step - loss: 1.1496
16/16 [==============================] - 0s 2ms/step - loss: 1.1507
16/16 [==============================] - 0s 1ms/step - loss: 1.1512
16/16 [==============================] - 0s 4ms/step - loss: 1.1516
16/16 [==============================] - 0s 3ms/step - loss: 1.1520
16/16 [==============================] - 0s 2ms/step - loss: 1.1527
16/16 [==============================] - 0s 2ms/step - loss: 1.1529
16/16 [==============================] - 0s 1ms/step - loss: 1.1529
Epoch 23 of 60

Testing for epoch 23 index 1:
32/32 [==============================] - 0s 900us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5048
16/16 [==============================] - 0s 1ms/step - loss: 1.1336
16/16 [==============================] - 0s 2ms/step - loss: 1.1607
16/16 [==============================] - 0s 1ms/step - loss: 1.1618
16/16 [==============================] - 0s 2ms/step - loss: 1.1622
16/16 [==============================] - 0s 4ms/step - loss: 1.1625
16/16 [==============================] - 0s 2ms/step - loss: 1.1630
16/16 [==============================] - 0s 1ms/step - loss: 1.1636
16/16 [==============================] - 0s 1ms/step - loss: 1.1638
16/16 [==============================] - 0s 2ms/step - loss: 1.1638

Testing for epoch 23 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5183
16/16 [==============================] - 0s 2ms/step - loss: 1.1345
16/16 [==============================] - 0s 2ms/step - loss: 1.1583
16/16 [==============================] - 0s 2ms/step - loss: 1.1593
16/16 [==============================] - 0s 2ms/step - loss: 1.1597
16/16 [==============================] - 0s 2ms/step - loss: 1.1601
16/16 [==============================] - 0s 1ms/step - loss: 1.1606
16/16 [==============================] - 0s 1ms/step - loss: 1.1612
16/16 [==============================] - 0s 2ms/step - loss: 1.1614
16/16 [==============================] - 0s 2ms/step - loss: 1.1614
Epoch 24 of 60

Testing for epoch 24 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5228
16/16 [==============================] - 0s 1ms/step - loss: 1.1392
16/16 [==============================] - 0s 1ms/step - loss: 1.1615
16/16 [==============================] - 0s 977us/step - loss: 1.1623
16/16 [==============================] - 0s 1ms/step - loss: 1.1628
16/16 [==============================] - 0s 1ms/step - loss: 1.1633
16/16 [==============================] - 0s 1ms/step - loss: 1.1639
16/16 [==============================] - 0s 2ms/step - loss: 1.1646
16/16 [==============================] - 0s 1ms/step - loss: 1.1649
16/16 [==============================] - 0s 1ms/step - loss: 1.1649

Testing for epoch 24 index 2:
32/32 [==============================] - 0s 848us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5259
16/16 [==============================] - 0s 1ms/step - loss: 1.1609
16/16 [==============================] - 0s 1ms/step - loss: 1.1832
16/16 [==============================] - 0s 1ms/step - loss: 1.1841
16/16 [==============================] - 0s 2ms/step - loss: 1.1845
16/16 [==============================] - 0s 2ms/step - loss: 1.1848
16/16 [==============================] - 0s 2ms/step - loss: 1.1853
16/16 [==============================] - 0s 2ms/step - loss: 1.1859
16/16 [==============================] - 0s 2ms/step - loss: 1.1861
16/16 [==============================] - 0s 2ms/step - loss: 1.1861
Epoch 25 of 60

Testing for epoch 25 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5249
16/16 [==============================] - 0s 2ms/step - loss: 1.1680
16/16 [==============================] - 0s 2ms/step - loss: 1.1921
16/16 [==============================] - 0s 1ms/step - loss: 1.1930
16/16 [==============================] - 0s 1ms/step - loss: 1.1933
16/16 [==============================] - 0s 1ms/step - loss: 1.1937
16/16 [==============================] - 0s 959us/step - loss: 1.1941
16/16 [==============================] - 0s 3ms/step - loss: 1.1947
16/16 [==============================] - 0s 1ms/step - loss: 1.1949
16/16 [==============================] - 0s 1ms/step - loss: 1.1949

Testing for epoch 25 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5256
16/16 [==============================] - 0s 4ms/step - loss: 1.1816
16/16 [==============================] - 0s 1ms/step - loss: 1.2066
16/16 [==============================] - 0s 1ms/step - loss: 1.2075
16/16 [==============================] - 0s 1ms/step - loss: 1.2079
16/16 [==============================] - 0s 2ms/step - loss: 1.2082
16/16 [==============================] - 0s 1ms/step - loss: 1.2087
16/16 [==============================] - 0s 1ms/step - loss: 1.2092
16/16 [==============================] - 0s 1ms/step - loss: 1.2095
16/16 [==============================] - 0s 2ms/step - loss: 1.2095
Epoch 26 of 60

Testing for epoch 26 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5199
16/16 [==============================] - 0s 1ms/step - loss: 1.1842
16/16 [==============================] - 0s 1ms/step - loss: 1.2109
16/16 [==============================] - 0s 2ms/step - loss: 1.2118
16/16 [==============================] - 0s 2ms/step - loss: 1.2122
16/16 [==============================] - 0s 1ms/step - loss: 1.2126
16/16 [==============================] - 0s 1ms/step - loss: 1.2131
16/16 [==============================] - 0s 4ms/step - loss: 1.2137
16/16 [==============================] - 0s 2ms/step - loss: 1.2140
16/16 [==============================] - 0s 878us/step - loss: 1.2140

Testing for epoch 26 index 2:
32/32 [==============================] - 0s 656us/step
16/16 [==============================] - 0s 831us/step - loss: 0.5174
16/16 [==============================] - 0s 864us/step - loss: 1.1946
16/16 [==============================] - 0s 732us/step - loss: 1.2231
16/16 [==============================] - 0s 767us/step - loss: 1.2241
16/16 [==============================] - 0s 810us/step - loss: 1.2245
16/16 [==============================] - 0s 822us/step - loss: 1.2248
16/16 [==============================] - 0s 808us/step - loss: 1.2252
16/16 [==============================] - 0s 788us/step - loss: 1.2257
16/16 [==============================] - 0s 821us/step - loss: 1.2259
16/16 [==============================] - 0s 810us/step - loss: 1.2260
Epoch 27 of 60

Testing for epoch 27 index 1:
32/32 [==============================] - 0s 615us/step
16/16 [==============================] - 0s 796us/step - loss: 0.5052
16/16 [==============================] - 0s 812us/step - loss: 1.2202
16/16 [==============================] - 0s 814us/step - loss: 1.2513
16/16 [==============================] - 0s 778us/step - loss: 1.2525
16/16 [==============================] - 0s 782us/step - loss: 1.2529
16/16 [==============================] - 0s 804us/step - loss: 1.2532
16/16 [==============================] - 0s 777us/step - loss: 1.2536
16/16 [==============================] - 0s 785us/step - loss: 1.2541
16/16 [==============================] - 0s 795us/step - loss: 1.2544
16/16 [==============================] - 0s 797us/step - loss: 1.2544

Testing for epoch 27 index 2:
32/32 [==============================] - 0s 631us/step
16/16 [==============================] - 0s 837us/step - loss: 0.5002
16/16 [==============================] - 0s 831us/step - loss: 1.2353
16/16 [==============================] - 0s 827us/step - loss: 1.2665
16/16 [==============================] - 0s 780us/step - loss: 1.2678
16/16 [==============================] - 0s 798us/step - loss: 1.2682
16/16 [==============================] - 0s 771us/step - loss: 1.2685
16/16 [==============================] - 0s 778us/step - loss: 1.2690
16/16 [==============================] - 0s 809us/step - loss: 1.2696
16/16 [==============================] - 0s 818us/step - loss: 1.2698
16/16 [==============================] - 0s 784us/step - loss: 1.2698
Epoch 28 of 60

Testing for epoch 28 index 1:
32/32 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 792us/step - loss: 0.4877
16/16 [==============================] - 0s 796us/step - loss: 1.2490
16/16 [==============================] - 0s 816us/step - loss: 1.2845
16/16 [==============================] - 0s 825us/step - loss: 1.2858
16/16 [==============================] - 0s 782us/step - loss: 1.2862
16/16 [==============================] - 0s 824us/step - loss: 1.2866
16/16 [==============================] - 0s 812us/step - loss: 1.2870
16/16 [==============================] - 0s 799us/step - loss: 1.2875
16/16 [==============================] - 0s 792us/step - loss: 1.2877
16/16 [==============================] - 0s 811us/step - loss: 1.2877

Testing for epoch 28 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 782us/step - loss: 0.4795
16/16 [==============================] - 0s 819us/step - loss: 1.2762
16/16 [==============================] - 0s 807us/step - loss: 1.3130
16/16 [==============================] - 0s 810us/step - loss: 1.3144
16/16 [==============================] - 0s 812us/step - loss: 1.3148
16/16 [==============================] - 0s 816us/step - loss: 1.3151
16/16 [==============================] - 0s 774us/step - loss: 1.3156
16/16 [==============================] - 0s 780us/step - loss: 1.3161
16/16 [==============================] - 0s 805us/step - loss: 1.3163
16/16 [==============================] - 0s 775us/step - loss: 1.3163
Epoch 29 of 60

Testing for epoch 29 index 1:
32/32 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 791us/step - loss: 0.4700
16/16 [==============================] - 0s 815us/step - loss: 1.2786
16/16 [==============================] - 0s 795us/step - loss: 1.3164
16/16 [==============================] - 0s 800us/step - loss: 1.3177
16/16 [==============================] - 0s 781us/step - loss: 1.3182
16/16 [==============================] - 0s 768us/step - loss: 1.3186
16/16 [==============================] - 0s 775us/step - loss: 1.3191
16/16 [==============================] - 0s 795us/step - loss: 1.3197
16/16 [==============================] - 0s 799us/step - loss: 1.3199
16/16 [==============================] - 0s 775us/step - loss: 1.3199

Testing for epoch 29 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 790us/step - loss: 0.4639
16/16 [==============================] - 0s 816us/step - loss: 1.2951
16/16 [==============================] - 0s 784us/step - loss: 1.3344
16/16 [==============================] - 0s 821us/step - loss: 1.3358
16/16 [==============================] - 0s 769us/step - loss: 1.3362
16/16 [==============================] - 0s 798us/step - loss: 1.3366
16/16 [==============================] - 0s 773us/step - loss: 1.3371
16/16 [==============================] - 0s 781us/step - loss: 1.3376
16/16 [==============================] - 0s 803us/step - loss: 1.3379
16/16 [==============================] - 0s 795us/step - loss: 1.3379
Epoch 30 of 60

Testing for epoch 30 index 1:
32/32 [==============================] - 0s 629us/step
16/16 [==============================] - 0s 792us/step - loss: 0.4496
16/16 [==============================] - 0s 777us/step - loss: 1.3229
16/16 [==============================] - 0s 782us/step - loss: 1.3686
16/16 [==============================] - 0s 793us/step - loss: 1.3703
16/16 [==============================] - 0s 798us/step - loss: 1.3707
16/16 [==============================] - 0s 792us/step - loss: 1.3710
16/16 [==============================] - 0s 784us/step - loss: 1.3714
16/16 [==============================] - 0s 780us/step - loss: 1.3719
16/16 [==============================] - 0s 803us/step - loss: 1.3720
16/16 [==============================] - 0s 773us/step - loss: 1.3721

Testing for epoch 30 index 2:
32/32 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 780us/step - loss: 0.4461
16/16 [==============================] - 0s 772us/step - loss: 1.3343
16/16 [==============================] - 0s 771us/step - loss: 1.3836
16/16 [==============================] - 0s 777us/step - loss: 1.3853
16/16 [==============================] - 0s 823us/step - loss: 1.3857
16/16 [==============================] - 0s 797us/step - loss: 1.3861
16/16 [==============================] - 0s 783us/step - loss: 1.3865
16/16 [==============================] - 0s 770us/step - loss: 1.3870
16/16 [==============================] - 0s 769us/step - loss: 1.3871
16/16 [==============================] - 0s 791us/step - loss: 1.3872
Epoch 31 of 60

Testing for epoch 31 index 1:
32/32 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 793us/step - loss: 0.4388
16/16 [==============================] - 0s 803us/step - loss: 1.3348
16/16 [==============================] - 0s 785us/step - loss: 1.3881
16/16 [==============================] - 0s 795us/step - loss: 1.3898
16/16 [==============================] - 0s 784us/step - loss: 1.3903
16/16 [==============================] - 0s 814us/step - loss: 1.3906
16/16 [==============================] - 0s 764us/step - loss: 1.3910
16/16 [==============================] - 0s 769us/step - loss: 1.3915
16/16 [==============================] - 0s 766us/step - loss: 1.3917
16/16 [==============================] - 0s 770us/step - loss: 1.3917

Testing for epoch 31 index 2:
32/32 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 785us/step - loss: 0.4335
16/16 [==============================] - 0s 778us/step - loss: 1.3689
16/16 [==============================] - 0s 776us/step - loss: 1.4249
16/16 [==============================] - 0s 794us/step - loss: 1.4268
16/16 [==============================] - 0s 773us/step - loss: 1.4272
16/16 [==============================] - 0s 770us/step - loss: 1.4275
16/16 [==============================] - 0s 770us/step - loss: 1.4279
16/16 [==============================] - 0s 788us/step - loss: 1.4283
16/16 [==============================] - 0s 792us/step - loss: 1.4285
16/16 [==============================] - 0s 802us/step - loss: 1.4285
Epoch 32 of 60

Testing for epoch 32 index 1:
32/32 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 797us/step - loss: 0.4265
16/16 [==============================] - 0s 805us/step - loss: 1.3817
16/16 [==============================] - 0s 815us/step - loss: 1.4402
16/16 [==============================] - 0s 784us/step - loss: 1.4422
16/16 [==============================] - 0s 785us/step - loss: 1.4426
16/16 [==============================] - 0s 791us/step - loss: 1.4429
16/16 [==============================] - 0s 811us/step - loss: 1.4432
16/16 [==============================] - 0s 791us/step - loss: 1.4435
16/16 [==============================] - 0s 809us/step - loss: 1.4437
16/16 [==============================] - 0s 777us/step - loss: 1.4437

Testing for epoch 32 index 2:
32/32 [==============================] - 0s 622us/step
16/16 [==============================] - 0s 819us/step - loss: 0.4303
16/16 [==============================] - 0s 794us/step - loss: 1.3806
16/16 [==============================] - 0s 809us/step - loss: 1.4368
16/16 [==============================] - 0s 791us/step - loss: 1.4388
16/16 [==============================] - 0s 781us/step - loss: 1.4392
16/16 [==============================] - 0s 797us/step - loss: 1.4396
16/16 [==============================] - 0s 784us/step - loss: 1.4399
16/16 [==============================] - 0s 786us/step - loss: 1.4404
16/16 [==============================] - 0s 808us/step - loss: 1.4406
16/16 [==============================] - 0s 809us/step - loss: 1.4406
Epoch 33 of 60

Testing for epoch 33 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.4255
16/16 [==============================] - 0s 2ms/step - loss: 1.3957
16/16 [==============================] - 0s 2ms/step - loss: 1.4540
16/16 [==============================] - 0s 2ms/step - loss: 1.4562
16/16 [==============================] - 0s 1ms/step - loss: 1.4566
16/16 [==============================] - 0s 2ms/step - loss: 1.4569
16/16 [==============================] - 0s 1ms/step - loss: 1.4573
16/16 [==============================] - 0s 2ms/step - loss: 1.4577
16/16 [==============================] - 0s 2ms/step - loss: 1.4579
16/16 [==============================] - 0s 4ms/step - loss: 1.4579

Testing for epoch 33 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4288
16/16 [==============================] - 0s 1ms/step - loss: 1.4084
16/16 [==============================] - 0s 1ms/step - loss: 1.4660
16/16 [==============================] - 0s 1ms/step - loss: 1.4681
16/16 [==============================] - 0s 2ms/step - loss: 1.4686
16/16 [==============================] - 0s 2ms/step - loss: 1.4689
16/16 [==============================] - 0s 1ms/step - loss: 1.4692
16/16 [==============================] - 0s 1ms/step - loss: 1.4696
16/16 [==============================] - 0s 1ms/step - loss: 1.4698
16/16 [==============================] - 0s 1ms/step - loss: 1.4698
Epoch 34 of 60

Testing for epoch 34 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4279
16/16 [==============================] - 0s 1ms/step - loss: 1.4181
16/16 [==============================] - 0s 1ms/step - loss: 1.4764
16/16 [==============================] - 0s 5ms/step - loss: 1.4786
16/16 [==============================] - 0s 4ms/step - loss: 1.4790
16/16 [==============================] - 0s 2ms/step - loss: 1.4793
16/16 [==============================] - 0s 2ms/step - loss: 1.4796
16/16 [==============================] - 0s 1ms/step - loss: 1.4800
16/16 [==============================] - 0s 1ms/step - loss: 1.4802
16/16 [==============================] - 0s 1ms/step - loss: 1.4802

Testing for epoch 34 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 4ms/step - loss: 0.4335
16/16 [==============================] - 0s 1ms/step - loss: 1.4360
16/16 [==============================] - 0s 2ms/step - loss: 1.4928
16/16 [==============================] - 0s 3ms/step - loss: 1.4949
16/16 [==============================] - 0s 1ms/step - loss: 1.4954
16/16 [==============================] - 0s 1ms/step - loss: 1.4957
16/16 [==============================] - 0s 938us/step - loss: 1.4960
16/16 [==============================] - 0s 3ms/step - loss: 1.4964
16/16 [==============================] - 0s 4ms/step - loss: 1.4966
16/16 [==============================] - 0s 2ms/step - loss: 1.4966
Epoch 35 of 60

Testing for epoch 35 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4357
16/16 [==============================] - 0s 1ms/step - loss: 1.4423
16/16 [==============================] - 0s 1ms/step - loss: 1.4991
16/16 [==============================] - 0s 1ms/step - loss: 1.5013
16/16 [==============================] - 0s 987us/step - loss: 1.5017
16/16 [==============================] - 0s 2ms/step - loss: 1.5019
16/16 [==============================] - 0s 2ms/step - loss: 1.5022
16/16 [==============================] - 0s 1ms/step - loss: 1.5026
16/16 [==============================] - 0s 1ms/step - loss: 1.5028
16/16 [==============================] - 0s 2ms/step - loss: 1.5028

Testing for epoch 35 index 2:
32/32 [==============================] - 0s 4ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4458
16/16 [==============================] - 0s 3ms/step - loss: 1.4532
16/16 [==============================] - 0s 1ms/step - loss: 1.5074
16/16 [==============================] - 0s 1ms/step - loss: 1.5094
16/16 [==============================] - 0s 1ms/step - loss: 1.5098
16/16 [==============================] - 0s 1ms/step - loss: 1.5100
16/16 [==============================] - 0s 1ms/step - loss: 1.5103
16/16 [==============================] - 0s 1ms/step - loss: 1.5106
16/16 [==============================] - 0s 1ms/step - loss: 1.5107
16/16 [==============================] - 0s 2ms/step - loss: 1.5107
Epoch 36 of 60

Testing for epoch 36 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4508
16/16 [==============================] - 0s 2ms/step - loss: 1.4504
16/16 [==============================] - 0s 2ms/step - loss: 1.5026
16/16 [==============================] - 0s 1ms/step - loss: 1.5046
16/16 [==============================] - 0s 1ms/step - loss: 1.5050
16/16 [==============================] - 0s 1ms/step - loss: 1.5053
16/16 [==============================] - 0s 1ms/step - loss: 1.5056
16/16 [==============================] - 0s 1ms/step - loss: 1.5060
16/16 [==============================] - 0s 1ms/step - loss: 1.5062
16/16 [==============================] - 0s 1ms/step - loss: 1.5062

Testing for epoch 36 index 2:
32/32 [==============================] - 0s 988us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4614
16/16 [==============================] - 0s 1ms/step - loss: 1.4690
16/16 [==============================] - 0s 1ms/step - loss: 1.5199
16/16 [==============================] - 0s 1ms/step - loss: 1.5217
16/16 [==============================] - 0s 1ms/step - loss: 1.5222
16/16 [==============================] - 0s 1ms/step - loss: 1.5225
16/16 [==============================] - 0s 2ms/step - loss: 1.5228
16/16 [==============================] - 0s 891us/step - loss: 1.5233
16/16 [==============================] - 0s 1ms/step - loss: 1.5235
16/16 [==============================] - 0s 1ms/step - loss: 1.5235
Epoch 37 of 60

Testing for epoch 37 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.4674
16/16 [==============================] - 0s 1ms/step - loss: 1.4703
16/16 [==============================] - 0s 3ms/step - loss: 1.5202
16/16 [==============================] - 0s 1ms/step - loss: 1.5220
16/16 [==============================] - 0s 1ms/step - loss: 1.5224
16/16 [==============================] - 0s 1ms/step - loss: 1.5226
16/16 [==============================] - 0s 1ms/step - loss: 1.5229
16/16 [==============================] - 0s 1ms/step - loss: 1.5232
16/16 [==============================] - 0s 1ms/step - loss: 1.5233
16/16 [==============================] - 0s 1ms/step - loss: 1.5233

Testing for epoch 37 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4817
16/16 [==============================] - 0s 2ms/step - loss: 1.4794
16/16 [==============================] - 0s 2ms/step - loss: 1.5276
16/16 [==============================] - 0s 2ms/step - loss: 1.5293
16/16 [==============================] - 0s 1ms/step - loss: 1.5296
16/16 [==============================] - 0s 1ms/step - loss: 1.5299
16/16 [==============================] - 0s 2ms/step - loss: 1.5301
16/16 [==============================] - 0s 2ms/step - loss: 1.5304
16/16 [==============================] - 0s 2ms/step - loss: 1.5305
16/16 [==============================] - 0s 2ms/step - loss: 1.5305
Epoch 38 of 60

Testing for epoch 38 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.4878
16/16 [==============================] - 0s 1ms/step - loss: 1.4939
16/16 [==============================] - 0s 1ms/step - loss: 1.5415
16/16 [==============================] - 0s 2ms/step - loss: 1.5431
16/16 [==============================] - 0s 2ms/step - loss: 1.5435
16/16 [==============================] - 0s 1ms/step - loss: 1.5437
16/16 [==============================] - 0s 2ms/step - loss: 1.5439
16/16 [==============================] - 0s 2ms/step - loss: 1.5442
16/16 [==============================] - 0s 2ms/step - loss: 1.5443
16/16 [==============================] - 0s 2ms/step - loss: 1.5443

Testing for epoch 38 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5035
16/16 [==============================] - 0s 1ms/step - loss: 1.4905
16/16 [==============================] - 0s 1ms/step - loss: 1.5351
16/16 [==============================] - 0s 1ms/step - loss: 1.5365
16/16 [==============================] - 0s 1ms/step - loss: 1.5370
16/16 [==============================] - 0s 1ms/step - loss: 1.5373
16/16 [==============================] - 0s 988us/step - loss: 1.5376
16/16 [==============================] - 0s 2ms/step - loss: 1.5381
16/16 [==============================] - 0s 2ms/step - loss: 1.5382
16/16 [==============================] - 0s 2ms/step - loss: 1.5383
Epoch 39 of 60

Testing for epoch 39 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5103
16/16 [==============================] - 0s 1ms/step - loss: 1.5127
16/16 [==============================] - 0s 1ms/step - loss: 1.5577
16/16 [==============================] - 0s 1ms/step - loss: 1.5592
16/16 [==============================] - 0s 4ms/step - loss: 1.5596
16/16 [==============================] - 0s 4ms/step - loss: 1.5598
16/16 [==============================] - 0s 1ms/step - loss: 1.5601
16/16 [==============================] - 0s 3ms/step - loss: 1.5604
16/16 [==============================] - 0s 1ms/step - loss: 1.5605
16/16 [==============================] - 0s 1ms/step - loss: 1.5605

Testing for epoch 39 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5264
16/16 [==============================] - 0s 1ms/step - loss: 1.5167
16/16 [==============================] - 0s 3ms/step - loss: 1.5597
16/16 [==============================] - 0s 2ms/step - loss: 1.5612
16/16 [==============================] - 0s 1ms/step - loss: 1.5615
16/16 [==============================] - 0s 1ms/step - loss: 1.5617
16/16 [==============================] - 0s 1ms/step - loss: 1.5620
16/16 [==============================] - 0s 1ms/step - loss: 1.5622
16/16 [==============================] - 0s 1ms/step - loss: 1.5623
16/16 [==============================] - 0s 1ms/step - loss: 1.5623
Epoch 40 of 60

Testing for epoch 40 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5342
16/16 [==============================] - 0s 2ms/step - loss: 1.5283
16/16 [==============================] - 0s 2ms/step - loss: 1.5709
16/16 [==============================] - 0s 1ms/step - loss: 1.5724
16/16 [==============================] - 0s 1ms/step - loss: 1.5727
16/16 [==============================] - 0s 1ms/step - loss: 1.5729
16/16 [==============================] - 0s 2ms/step - loss: 1.5732
16/16 [==============================] - 0s 1ms/step - loss: 1.5734
16/16 [==============================] - 0s 1ms/step - loss: 1.5735
16/16 [==============================] - 0s 1ms/step - loss: 1.5735

Testing for epoch 40 index 2:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5499
16/16 [==============================] - 0s 2ms/step - loss: 1.5318
16/16 [==============================] - 0s 2ms/step - loss: 1.5719
16/16 [==============================] - 0s 1ms/step - loss: 1.5733
16/16 [==============================] - 0s 1ms/step - loss: 1.5736
16/16 [==============================] - 0s 2ms/step - loss: 1.5738
16/16 [==============================] - 0s 2ms/step - loss: 1.5740
16/16 [==============================] - 0s 2ms/step - loss: 1.5743
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
16/16 [==============================] - 0s 1ms/step - loss: 1.5744
Epoch 41 of 60

Testing for epoch 41 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5570
16/16 [==============================] - 0s 1ms/step - loss: 1.5475
16/16 [==============================] - 0s 1ms/step - loss: 1.5874
16/16 [==============================] - 0s 1ms/step - loss: 1.5888
16/16 [==============================] - 0s 2ms/step - loss: 1.5891
16/16 [==============================] - 0s 2ms/step - loss: 1.5892
16/16 [==============================] - 0s 2ms/step - loss: 1.5893
16/16 [==============================] - 0s 1ms/step - loss: 1.5895
16/16 [==============================] - 0s 1ms/step - loss: 1.5896
16/16 [==============================] - 0s 2ms/step - loss: 1.5896

Testing for epoch 41 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5733
16/16 [==============================] - 0s 1ms/step - loss: 1.5531
16/16 [==============================] - 0s 1ms/step - loss: 1.5914
16/16 [==============================] - 0s 1ms/step - loss: 1.5927
16/16 [==============================] - 0s 2ms/step - loss: 1.5931
16/16 [==============================] - 0s 2ms/step - loss: 1.5932
16/16 [==============================] - 0s 2ms/step - loss: 1.5934
16/16 [==============================] - 0s 1ms/step - loss: 1.5937
16/16 [==============================] - 0s 1ms/step - loss: 1.5938
16/16 [==============================] - 0s 1ms/step - loss: 1.5938
Epoch 42 of 60

Testing for epoch 42 index 1:
32/32 [==============================] - 0s 830us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.5804
16/16 [==============================] - 0s 2ms/step - loss: 1.5605
16/16 [==============================] - 0s 1ms/step - loss: 1.5989
16/16 [==============================] - 0s 2ms/step - loss: 1.6002
16/16 [==============================] - 0s 1ms/step - loss: 1.6005
16/16 [==============================] - 0s 1ms/step - loss: 1.6007
16/16 [==============================] - 0s 2ms/step - loss: 1.6010
16/16 [==============================] - 0s 2ms/step - loss: 1.6013
16/16 [==============================] - 0s 1ms/step - loss: 1.6014
16/16 [==============================] - 0s 2ms/step - loss: 1.6014

Testing for epoch 42 index 2:
32/32 [==============================] - 0s 770us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.5964
16/16 [==============================] - 0s 3ms/step - loss: 1.5755
16/16 [==============================] - 0s 2ms/step - loss: 1.6137
16/16 [==============================] - 0s 2ms/step - loss: 1.6149
16/16 [==============================] - 0s 1ms/step - loss: 1.6153
16/16 [==============================] - 0s 1ms/step - loss: 1.6155
16/16 [==============================] - 0s 1ms/step - loss: 1.6157
16/16 [==============================] - 0s 2ms/step - loss: 1.6160
16/16 [==============================] - 0s 2ms/step - loss: 1.6161
16/16 [==============================] - 0s 3ms/step - loss: 1.6161
Epoch 43 of 60

Testing for epoch 43 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6020
16/16 [==============================] - 0s 2ms/step - loss: 1.5861
16/16 [==============================] - 0s 4ms/step - loss: 1.6247
16/16 [==============================] - 0s 2ms/step - loss: 1.6259
16/16 [==============================] - 0s 2ms/step - loss: 1.6263
16/16 [==============================] - 0s 2ms/step - loss: 1.6264
16/16 [==============================] - 0s 1ms/step - loss: 1.6266
16/16 [==============================] - 0s 2ms/step - loss: 1.6268
16/16 [==============================] - 0s 2ms/step - loss: 1.6269
16/16 [==============================] - 0s 2ms/step - loss: 1.6269

Testing for epoch 43 index 2:
32/32 [==============================] - 0s 896us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6162
16/16 [==============================] - 0s 1ms/step - loss: 1.5924
16/16 [==============================] - 0s 988us/step - loss: 1.6302
16/16 [==============================] - 0s 2ms/step - loss: 1.6314
16/16 [==============================] - 0s 2ms/step - loss: 1.6318
16/16 [==============================] - 0s 1ms/step - loss: 1.6319
16/16 [==============================] - 0s 1ms/step - loss: 1.6321
16/16 [==============================] - 0s 1ms/step - loss: 1.6323
16/16 [==============================] - 0s 2ms/step - loss: 1.6324
16/16 [==============================] - 0s 2ms/step - loss: 1.6324
Epoch 44 of 60

Testing for epoch 44 index 1:
32/32 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.6208
16/16 [==============================] - 0s 3ms/step - loss: 1.6042
16/16 [==============================] - 0s 2ms/step - loss: 1.6422
16/16 [==============================] - 0s 1ms/step - loss: 1.6435
16/16 [==============================] - 0s 2ms/step - loss: 1.6438
16/16 [==============================] - 0s 2ms/step - loss: 1.6440
16/16 [==============================] - 0s 2ms/step - loss: 1.6442
16/16 [==============================] - 0s 1ms/step - loss: 1.6444
16/16 [==============================] - 0s 1ms/step - loss: 1.6445
16/16 [==============================] - 0s 1ms/step - loss: 1.6445

Testing for epoch 44 index 2:
32/32 [==============================] - 0s 855us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6333
16/16 [==============================] - 0s 1ms/step - loss: 1.6115
16/16 [==============================] - 0s 2ms/step - loss: 1.6493
16/16 [==============================] - 0s 2ms/step - loss: 1.6505
16/16 [==============================] - 0s 1ms/step - loss: 1.6508
16/16 [==============================] - 0s 1ms/step - loss: 1.6510
16/16 [==============================] - 0s 2ms/step - loss: 1.6512
16/16 [==============================] - 0s 2ms/step - loss: 1.6515
16/16 [==============================] - 0s 1ms/step - loss: 1.6516
16/16 [==============================] - 0s 2ms/step - loss: 1.6516
Epoch 45 of 60

Testing for epoch 45 index 1:
32/32 [==============================] - 0s 836us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6363
16/16 [==============================] - 0s 2ms/step - loss: 1.6203
16/16 [==============================] - 0s 1ms/step - loss: 1.6589
16/16 [==============================] - 0s 1ms/step - loss: 1.6601
16/16 [==============================] - 0s 1ms/step - loss: 1.6604
16/16 [==============================] - 0s 1ms/step - loss: 1.6606
16/16 [==============================] - 0s 771us/step - loss: 1.6608
16/16 [==============================] - 0s 1ms/step - loss: 1.6610
16/16 [==============================] - 0s 954us/step - loss: 1.6611
16/16 [==============================] - 0s 943us/step - loss: 1.6611

Testing for epoch 45 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.6489
16/16 [==============================] - 0s 1ms/step - loss: 1.6337
16/16 [==============================] - 0s 1ms/step - loss: 1.6729
16/16 [==============================] - 0s 1ms/step - loss: 1.6741
16/16 [==============================] - 0s 1ms/step - loss: 1.6744
16/16 [==============================] - 0s 1ms/step - loss: 1.6746
16/16 [==============================] - 0s 2ms/step - loss: 1.6747
16/16 [==============================] - 0s 2ms/step - loss: 1.6749
16/16 [==============================] - 0s 1ms/step - loss: 1.6749
16/16 [==============================] - 0s 2ms/step - loss: 1.6750
Epoch 46 of 60

Testing for epoch 46 index 1:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6501
16/16 [==============================] - 0s 1ms/step - loss: 1.6367
16/16 [==============================] - 0s 1ms/step - loss: 1.6765
16/16 [==============================] - 0s 3ms/step - loss: 1.6777
16/16 [==============================] - 0s 2ms/step - loss: 1.6780
16/16 [==============================] - 0s 2ms/step - loss: 1.6781
16/16 [==============================] - 0s 2ms/step - loss: 1.6783
16/16 [==============================] - 0s 1ms/step - loss: 1.6784
16/16 [==============================] - 0s 2ms/step - loss: 1.6785
16/16 [==============================] - 0s 1ms/step - loss: 1.6785

Testing for epoch 46 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 819us/step - loss: 0.6612
16/16 [==============================] - 0s 804us/step - loss: 1.6441
16/16 [==============================] - 0s 1ms/step - loss: 1.6840
16/16 [==============================] - 0s 785us/step - loss: 1.6852
16/16 [==============================] - 0s 1ms/step - loss: 1.6855
16/16 [==============================] - 0s 1ms/step - loss: 1.6856
16/16 [==============================] - 0s 1ms/step - loss: 1.6857
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
16/16 [==============================] - 0s 1ms/step - loss: 1.6858
Epoch 47 of 60

Testing for epoch 47 index 1:
32/32 [==============================] - 0s 835us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6626
16/16 [==============================] - 0s 1ms/step - loss: 1.6545
16/16 [==============================] - 0s 805us/step - loss: 1.6944
16/16 [==============================] - 0s 804us/step - loss: 1.6957
16/16 [==============================] - 0s 1ms/step - loss: 1.6960
16/16 [==============================] - 0s 1ms/step - loss: 1.6961
16/16 [==============================] - 0s 1ms/step - loss: 1.6961
16/16 [==============================] - 0s 1ms/step - loss: 1.6962
16/16 [==============================] - 0s 778us/step - loss: 1.6962
16/16 [==============================] - 0s 792us/step - loss: 1.6962

Testing for epoch 47 index 2:
32/32 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 791us/step - loss: 0.6744
16/16 [==============================] - 0s 976us/step - loss: 1.6678
16/16 [==============================] - 0s 1ms/step - loss: 1.7065
16/16 [==============================] - 0s 804us/step - loss: 1.7078
16/16 [==============================] - 0s 1ms/step - loss: 1.7081
16/16 [==============================] - 0s 1ms/step - loss: 1.7083
16/16 [==============================] - 0s 1ms/step - loss: 1.7085
16/16 [==============================] - 0s 777us/step - loss: 1.7087
16/16 [==============================] - 0s 800us/step - loss: 1.7088
16/16 [==============================] - 0s 789us/step - loss: 1.7088
Epoch 48 of 60

Testing for epoch 48 index 1:
32/32 [==============================] - 0s 618us/step
16/16 [==============================] - 0s 829us/step - loss: 0.6775
16/16 [==============================] - 0s 800us/step - loss: 1.6875
16/16 [==============================] - 0s 1ms/step - loss: 1.7276
16/16 [==============================] - 0s 1ms/step - loss: 1.7289
16/16 [==============================] - 0s 808us/step - loss: 1.7292
16/16 [==============================] - 0s 776us/step - loss: 1.7293
16/16 [==============================] - 0s 792us/step - loss: 1.7294
16/16 [==============================] - 0s 1ms/step - loss: 1.7295
16/16 [==============================] - 0s 1ms/step - loss: 1.7296
16/16 [==============================] - 0s 1ms/step - loss: 1.7296

Testing for epoch 48 index 2:
32/32 [==============================] - 0s 831us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.6904
16/16 [==============================] - 0s 1ms/step - loss: 1.7060
16/16 [==============================] - 0s 1ms/step - loss: 1.7464
16/16 [==============================] - 0s 1ms/step - loss: 1.7477
16/16 [==============================] - 0s 1ms/step - loss: 1.7480
16/16 [==============================] - 0s 1ms/step - loss: 1.7481
16/16 [==============================] - 0s 1ms/step - loss: 1.7482
16/16 [==============================] - 0s 1ms/step - loss: 1.7484
16/16 [==============================] - 0s 813us/step - loss: 1.7485
16/16 [==============================] - 0s 1ms/step - loss: 1.7485
Epoch 49 of 60

Testing for epoch 49 index 1:
32/32 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 779us/step - loss: 0.6923
16/16 [==============================] - 0s 771us/step - loss: 1.7161
16/16 [==============================] - 0s 799us/step - loss: 1.7569
16/16 [==============================] - 0s 819us/step - loss: 1.7583
16/16 [==============================] - 0s 1ms/step - loss: 1.7586
16/16 [==============================] - 0s 1ms/step - loss: 1.7587
16/16 [==============================] - 0s 1ms/step - loss: 1.7589
16/16 [==============================] - 0s 1ms/step - loss: 1.7591
16/16 [==============================] - 0s 1ms/step - loss: 1.7592
16/16 [==============================] - 0s 1ms/step - loss: 1.7592

Testing for epoch 49 index 2:
32/32 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 779us/step - loss: 0.7016
16/16 [==============================] - 0s 782us/step - loss: 1.7163
16/16 [==============================] - 0s 798us/step - loss: 1.7574
16/16 [==============================] - 0s 790us/step - loss: 1.7587
16/16 [==============================] - 0s 796us/step - loss: 1.7589
16/16 [==============================] - 0s 778us/step - loss: 1.7590
16/16 [==============================] - 0s 770us/step - loss: 1.7591
16/16 [==============================] - 0s 799us/step - loss: 1.7591
16/16 [==============================] - 0s 810us/step - loss: 1.7591
16/16 [==============================] - 0s 779us/step - loss: 1.7591
Epoch 50 of 60

Testing for epoch 50 index 1:
32/32 [==============================] - 0s 605us/step
16/16 [==============================] - 0s 792us/step - loss: 0.7041
16/16 [==============================] - 0s 787us/step - loss: 1.7274
16/16 [==============================] - 0s 833us/step - loss: 1.7685
16/16 [==============================] - 0s 826us/step - loss: 1.7698
16/16 [==============================] - 0s 792us/step - loss: 1.7702
16/16 [==============================] - 0s 818us/step - loss: 1.7703
16/16 [==============================] - 0s 778us/step - loss: 1.7705
16/16 [==============================] - 0s 841us/step - loss: 1.7707
16/16 [==============================] - 0s 805us/step - loss: 1.7708
16/16 [==============================] - 0s 838us/step - loss: 1.7708

Testing for epoch 50 index 2:
32/32 [==============================] - 0s 624us/step
16/16 [==============================] - 0s 824us/step - loss: 0.7152
16/16 [==============================] - 0s 796us/step - loss: 1.7311
16/16 [==============================] - 0s 817us/step - loss: 1.7720
16/16 [==============================] - 0s 781us/step - loss: 1.7732
16/16 [==============================] - 0s 1ms/step - loss: 1.7736
16/16 [==============================] - 0s 1ms/step - loss: 1.7737
16/16 [==============================] - 0s 1ms/step - loss: 1.7739
16/16 [==============================] - 0s 895us/step - loss: 1.7741
16/16 [==============================] - 0s 776us/step - loss: 1.7742
16/16 [==============================] - 0s 804us/step - loss: 1.7742
Epoch 51 of 60

Testing for epoch 51 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 813us/step - loss: 0.7194
16/16 [==============================] - 0s 799us/step - loss: 1.7544
16/16 [==============================] - 0s 796us/step - loss: 1.7966
16/16 [==============================] - 0s 790us/step - loss: 1.7980
16/16 [==============================] - 0s 810us/step - loss: 1.7983
16/16 [==============================] - 0s 804us/step - loss: 1.7984
16/16 [==============================] - 0s 821us/step - loss: 1.7985
16/16 [==============================] - 0s 791us/step - loss: 1.7987
16/16 [==============================] - 0s 781us/step - loss: 1.7987
16/16 [==============================] - 0s 789us/step - loss: 1.7987

Testing for epoch 51 index 2:
32/32 [==============================] - 0s 617us/step
16/16 [==============================] - 0s 789us/step - loss: 0.7322
16/16 [==============================] - 0s 802us/step - loss: 1.7637
16/16 [==============================] - 0s 793us/step - loss: 1.8060
16/16 [==============================] - 0s 795us/step - loss: 1.8073
16/16 [==============================] - 0s 783us/step - loss: 1.8076
16/16 [==============================] - 0s 776us/step - loss: 1.8077
16/16 [==============================] - 0s 770us/step - loss: 1.8079
16/16 [==============================] - 0s 779us/step - loss: 1.8080
16/16 [==============================] - 0s 787us/step - loss: 1.8081
16/16 [==============================] - 0s 805us/step - loss: 1.8081
Epoch 52 of 60

Testing for epoch 52 index 1:
32/32 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 809us/step - loss: 0.7334
16/16 [==============================] - 0s 807us/step - loss: 1.7648
16/16 [==============================] - 0s 785us/step - loss: 1.8070
16/16 [==============================] - 0s 789us/step - loss: 1.8083
16/16 [==============================] - 0s 788us/step - loss: 1.8086
16/16 [==============================] - 0s 825us/step - loss: 1.8088
16/16 [==============================] - 0s 794us/step - loss: 1.8089
16/16 [==============================] - 0s 839us/step - loss: 1.8091
16/16 [==============================] - 0s 827us/step - loss: 1.8092
16/16 [==============================] - 0s 832us/step - loss: 1.8092

Testing for epoch 52 index 2:
32/32 [==============================] - 0s 640us/step
16/16 [==============================] - 0s 953us/step - loss: 0.7473
16/16 [==============================] - 0s 1ms/step - loss: 1.7771
16/16 [==============================] - 0s 1ms/step - loss: 1.8202
16/16 [==============================] - 0s 782us/step - loss: 1.8215
16/16 [==============================] - 0s 806us/step - loss: 1.8217
16/16 [==============================] - 0s 789us/step - loss: 1.8217
16/16 [==============================] - 0s 821us/step - loss: 1.8217
16/16 [==============================] - 0s 810us/step - loss: 1.8217
16/16 [==============================] - 0s 706us/step - loss: 1.8217
16/16 [==============================] - 0s 675us/step - loss: 1.8217
Epoch 53 of 60

Testing for epoch 53 index 1:
32/32 [==============================] - 0s 543us/step
16/16 [==============================] - 0s 815us/step - loss: 0.7534
16/16 [==============================] - 0s 798us/step - loss: 1.7954
16/16 [==============================] - 0s 682us/step - loss: 1.8386
16/16 [==============================] - 0s 821us/step - loss: 1.8399
16/16 [==============================] - 0s 786us/step - loss: 1.8402
16/16 [==============================] - 0s 788us/step - loss: 1.8403
16/16 [==============================] - 0s 801us/step - loss: 1.8404
16/16 [==============================] - 0s 864us/step - loss: 1.8405
16/16 [==============================] - 0s 866us/step - loss: 1.8405
16/16 [==============================] - 0s 861us/step - loss: 1.8405

Testing for epoch 53 index 2:
32/32 [==============================] - 0s 821us/step
16/16 [==============================] - 0s 901us/step - loss: 0.7658
16/16 [==============================] - 0s 876us/step - loss: 1.7944
16/16 [==============================] - 0s 904us/step - loss: 1.8367
16/16 [==============================] - 0s 923us/step - loss: 1.8380
16/16 [==============================] - 0s 863us/step - loss: 1.8382
16/16 [==============================] - 0s 888us/step - loss: 1.8383
16/16 [==============================] - 0s 892us/step - loss: 1.8384
16/16 [==============================] - 0s 872us/step - loss: 1.8385
16/16 [==============================] - 0s 874us/step - loss: 1.8385
16/16 [==============================] - 0s 1ms/step - loss: 1.8385
Epoch 54 of 60

Testing for epoch 54 index 1:
32/32 [==============================] - 0s 675us/step
16/16 [==============================] - 0s 837us/step - loss: 0.7743
16/16 [==============================] - 0s 878us/step - loss: 1.8193
16/16 [==============================] - 0s 800us/step - loss: 1.8622
16/16 [==============================] - 0s 791us/step - loss: 1.8635
16/16 [==============================] - 0s 786us/step - loss: 1.8638
16/16 [==============================] - 0s 794us/step - loss: 1.8639
16/16 [==============================] - 0s 798us/step - loss: 1.8640
16/16 [==============================] - 0s 828us/step - loss: 1.8641
16/16 [==============================] - 0s 797us/step - loss: 1.8642
16/16 [==============================] - 0s 812us/step - loss: 1.8642

Testing for epoch 54 index 2:
32/32 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 818us/step - loss: 0.7864
16/16 [==============================] - 0s 822us/step - loss: 1.8117
16/16 [==============================] - 0s 809us/step - loss: 1.8535
16/16 [==============================] - 0s 794us/step - loss: 1.8547
16/16 [==============================] - 0s 811us/step - loss: 1.8550
16/16 [==============================] - 0s 806us/step - loss: 1.8551
16/16 [==============================] - 0s 844us/step - loss: 1.8552
16/16 [==============================] - 0s 794us/step - loss: 1.8553
16/16 [==============================] - 0s 784us/step - loss: 1.8554
16/16 [==============================] - 0s 802us/step - loss: 1.8554
Epoch 55 of 60

Testing for epoch 55 index 1:
32/32 [==============================] - 0s 621us/step
16/16 [==============================] - 0s 873us/step - loss: 0.7953
16/16 [==============================] - 0s 873us/step - loss: 1.8319
16/16 [==============================] - 0s 808us/step - loss: 1.8741
16/16 [==============================] - 0s 859us/step - loss: 1.8754
16/16 [==============================] - 0s 809us/step - loss: 1.8757
16/16 [==============================] - 0s 847us/step - loss: 1.8758
16/16 [==============================] - 0s 827us/step - loss: 1.8758
16/16 [==============================] - 0s 860us/step - loss: 1.8759
16/16 [==============================] - 0s 804us/step - loss: 1.8760
16/16 [==============================] - 0s 876us/step - loss: 1.8760

Testing for epoch 55 index 2:
32/32 [==============================] - 0s 643us/step
16/16 [==============================] - 0s 808us/step - loss: 0.8131
16/16 [==============================] - 0s 893us/step - loss: 1.8454
16/16 [==============================] - 0s 809us/step - loss: 1.8876
16/16 [==============================] - 0s 907us/step - loss: 1.8889
16/16 [==============================] - 0s 873us/step - loss: 1.8891
16/16 [==============================] - 0s 886us/step - loss: 1.8892
16/16 [==============================] - 0s 869us/step - loss: 1.8892
16/16 [==============================] - 0s 876us/step - loss: 1.8892
16/16 [==============================] - 0s 808us/step - loss: 1.8892
16/16 [==============================] - 0s 796us/step - loss: 1.8892
Epoch 56 of 60

Testing for epoch 56 index 1:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 694us/step - loss: 0.8154
16/16 [==============================] - 0s 812us/step - loss: 1.8371
16/16 [==============================] - 0s 815us/step - loss: 1.8781
16/16 [==============================] - 0s 796us/step - loss: 1.8793
16/16 [==============================] - 0s 867us/step - loss: 1.8796
16/16 [==============================] - 0s 798us/step - loss: 1.8797
16/16 [==============================] - 0s 791us/step - loss: 1.8798
16/16 [==============================] - 0s 878us/step - loss: 1.8799
16/16 [==============================] - 0s 872us/step - loss: 1.8800
16/16 [==============================] - 0s 799us/step - loss: 1.8800

Testing for epoch 56 index 2:
32/32 [==============================] - 0s 611us/step
16/16 [==============================] - 0s 830us/step - loss: 0.8363
16/16 [==============================] - 0s 883us/step - loss: 1.8623
16/16 [==============================] - 0s 873us/step - loss: 1.9037
16/16 [==============================] - 0s 817us/step - loss: 1.9049
16/16 [==============================] - 0s 837us/step - loss: 1.9052
16/16 [==============================] - 0s 811us/step - loss: 1.9052
16/16 [==============================] - 0s 862us/step - loss: 1.9053
16/16 [==============================] - 0s 859us/step - loss: 1.9054
16/16 [==============================] - 0s 839us/step - loss: 1.9054
16/16 [==============================] - 0s 809us/step - loss: 1.9054
Epoch 57 of 60

Testing for epoch 57 index 1:
32/32 [==============================] - 0s 860us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.8392
16/16 [==============================] - 0s 866us/step - loss: 1.8604
16/16 [==============================] - 0s 854us/step - loss: 1.9012
16/16 [==============================] - 0s 1ms/step - loss: 1.9024
16/16 [==============================] - 0s 1ms/step - loss: 1.9027
16/16 [==============================] - 0s 853us/step - loss: 1.9028
16/16 [==============================] - 0s 892us/step - loss: 1.9029
16/16 [==============================] - 0s 901us/step - loss: 1.9030
16/16 [==============================] - 0s 666us/step - loss: 1.9031
16/16 [==============================] - 0s 2ms/step - loss: 1.9031

Testing for epoch 57 index 2:
32/32 [==============================] - 0s 570us/step
16/16 [==============================] - 0s 875us/step - loss: 0.8581
16/16 [==============================] - 0s 839us/step - loss: 1.8764
16/16 [==============================] - 0s 1ms/step - loss: 1.9169
16/16 [==============================] - 0s 793us/step - loss: 1.9180
16/16 [==============================] - 0s 829us/step - loss: 1.9183
16/16 [==============================] - 0s 852us/step - loss: 1.9184
16/16 [==============================] - 0s 2ms/step - loss: 1.9185
16/16 [==============================] - 0s 786us/step - loss: 1.9186
16/16 [==============================] - 0s 890us/step - loss: 1.9187
16/16 [==============================] - 0s 2ms/step - loss: 1.9187
Epoch 58 of 60

Testing for epoch 58 index 1:
32/32 [==============================] - 0s 549us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.8680
16/16 [==============================] - 0s 922us/step - loss: 1.8985
16/16 [==============================] - 0s 765us/step - loss: 1.9394
16/16 [==============================] - 0s 781us/step - loss: 1.9405
16/16 [==============================] - 0s 820us/step - loss: 1.9408
16/16 [==============================] - 0s 1ms/step - loss: 1.9409
16/16 [==============================] - 0s 781us/step - loss: 1.9410
16/16 [==============================] - 0s 755us/step - loss: 1.9411
16/16 [==============================] - 0s 811us/step - loss: 1.9412
16/16 [==============================] - 0s 2ms/step - loss: 1.9412

Testing for epoch 58 index 2:
32/32 [==============================] - 0s 613us/step
16/16 [==============================] - 0s 863us/step - loss: 0.8825
16/16 [==============================] - 0s 2ms/step - loss: 1.9008
16/16 [==============================] - 0s 799us/step - loss: 1.9412
16/16 [==============================] - 0s 2ms/step - loss: 1.9423
16/16 [==============================] - 0s 2ms/step - loss: 1.9425
16/16 [==============================] - 0s 2ms/step - loss: 1.9426
16/16 [==============================] - 0s 791us/step - loss: 1.9427
16/16 [==============================] - 0s 851us/step - loss: 1.9427
16/16 [==============================] - 0s 2ms/step - loss: 1.9427
16/16 [==============================] - 0s 2ms/step - loss: 1.9427
Epoch 59 of 60

Testing for epoch 59 index 1:
32/32 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 818us/step - loss: 0.8879
16/16 [==============================] - 0s 803us/step - loss: 1.9056
16/16 [==============================] - 0s 2ms/step - loss: 1.9456
16/16 [==============================] - 0s 1ms/step - loss: 1.9468
16/16 [==============================] - 0s 962us/step - loss: 1.9470
16/16 [==============================] - 0s 794us/step - loss: 1.9470
16/16 [==============================] - 0s 800us/step - loss: 1.9471
16/16 [==============================] - 0s 2ms/step - loss: 1.9471
16/16 [==============================] - 0s 2ms/step - loss: 1.9471
16/16 [==============================] - 0s 1ms/step - loss: 1.9471

Testing for epoch 59 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 830us/step - loss: 0.9059
16/16 [==============================] - 0s 1ms/step - loss: 1.9160
16/16 [==============================] - 0s 838us/step - loss: 1.9552
16/16 [==============================] - 0s 788us/step - loss: 1.9563
16/16 [==============================] - 0s 2ms/step - loss: 1.9566
16/16 [==============================] - 0s 761us/step - loss: 1.9567
16/16 [==============================] - 0s 808us/step - loss: 1.9569
16/16 [==============================] - 0s 2ms/step - loss: 1.9571
16/16 [==============================] - 0s 2ms/step - loss: 1.9571
16/16 [==============================] - 0s 1ms/step - loss: 1.9571
Epoch 60 of 60

Testing for epoch 60 index 1:
32/32 [==============================] - 0s 561us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.9083
16/16 [==============================] - 0s 2ms/step - loss: 1.9140
16/16 [==============================] - 0s 800us/step - loss: 1.9538
16/16 [==============================] - 0s 793us/step - loss: 1.9549
16/16 [==============================] - 0s 877us/step - loss: 1.9551
16/16 [==============================] - 0s 783us/step - loss: 1.9551
16/16 [==============================] - 0s 1ms/step - loss: 1.9551
16/16 [==============================] - 0s 1ms/step - loss: 1.9552
16/16 [==============================] - 0s 884us/step - loss: 1.9552
16/16 [==============================] - 0s 2ms/step - loss: 1.9552

Testing for epoch 60 index 2:
32/32 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.9274
16/16 [==============================] - 0s 2ms/step - loss: 1.9310
16/16 [==============================] - 0s 2ms/step - loss: 1.9710
16/16 [==============================] - 0s 775us/step - loss: 1.9721
16/16 [==============================] - 0s 960us/step - loss: 1.9723
16/16 [==============================] - 0s 2ms/step - loss: 1.9723
16/16 [==============================] - 0s 794us/step - loss: 1.9722
16/16 [==============================] - 0s 1ms/step - loss: 1.9721
16/16 [==============================] - 0s 2ms/step - loss: 1.9721
16/16 [==============================] - 0s 2ms/step - loss: 1.9721
32/32 [==============================] - 0s 1ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1726">
<div class="sourceCode cell-code" id="cb304"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1727">
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1728">
<div class="sourceCode cell-code" id="cb306"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb306-1"><a href="#cb306-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_MO_GAAL_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1729">
<div class="sourceCode cell-code" id="cb307"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-213-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.950
Precision: 0.950
Recall: 1.000
F1 Score: 0.974</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1731">
<div class="sourceCode cell-code" id="cb310"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>thirteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  thirteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscpstar-1" class="level3">
<h3 class="anchored" data-anchor-id="lscpstar-1">LSCP<span class="math inline">\(\star\)</span></h3>
<div class="cell" data-execution_count="1732">
<div class="sourceCode cell-code" id="cb312"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb312-2"><a href="#cb312-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb312-3"><a href="#cb312-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'f'</span>]])</span>
<span id="cb312-4"><a href="#cb312-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1733">
<div class="sourceCode cell-code" id="cb314"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1734">
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1735">
<div class="sourceCode cell-code" id="cb316"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one,outlier_LSCP_one,tab_orbit)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1736">
<div class="sourceCode cell-code" id="cb317"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-219-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.994
Recall: 0.994
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1737">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> thirteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = thirteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="orbit-result" class="level2">
<h2 class="anchored" data-anchor-id="orbit-result">Orbit Result</h2>
<div class="cell" data-execution_count="1738">
<div class="sourceCode cell-code" id="cb322"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(fourteen,<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1738">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.998</td>
      <td>0.999</td>
      <td>0.999</td>
      <td>0.999</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.954</td>
      <td>0.976</td>
      <td>0.976</td>
      <td>0.976</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.948</td>
      <td>0.999</td>
      <td>0.946</td>
      <td>0.972</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.908</td>
      <td>0.977</td>
      <td>0.925</td>
      <td>0.950</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.916</td>
      <td>0.956</td>
      <td>0.956</td>
      <td>0.956</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.942</td>
      <td>0.969</td>
      <td>0.969</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.443</td>
      <td>0.992</td>
      <td>0.417</td>
      <td>0.587</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.935</td>
      <td>0.960</td>
      <td>0.973</td>
      <td>0.966</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.950</td>
      <td>0.974</td>
      <td>0.974</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.950</td>
      <td>0.950</td>
      <td>1.000</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.950</td>
      <td>0.950</td>
      <td>1.000</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.988</td>
      <td>0.994</td>
      <td>0.994</td>
      <td>0.994</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Orbit</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.916</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.956</td>
</tr>
<tr class="even">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">0.969</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.587</td>
</tr>
<tr class="odd">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.960</td>
<td style="text-align: center;">0.973</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="even">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">0.950</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.994</td>
</tr>
</tbody>
</table>
</section>
<section id="bunny" class="level2">
<h2 class="anchored" data-anchor-id="bunny">Bunny</h2>
<hr>
<section id="bunny-저장용" class="level3">
<h3 class="anchored" data-anchor-id="bunny-저장용">bunny 저장용</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb323"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygsp <span class="im">import</span> graphs, filters, plotting, utils</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_data(data_dict,fname):</span>
<span id="cb324-2"><a href="#cb324-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname,<span class="st">'wb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb324-3"><a href="#cb324-3" aria-hidden="true" tabindex="-1"></a>        pickle.dump(data_dict,outfile)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb325"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> graphs.Bunny()</span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> G.N</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb327"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> filters.Heat(G, tau<span class="op">=</span><span class="dv">75</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb328"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">2503</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb329"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb329-1"><a href="#cb329-1" aria-hidden="true" tabindex="-1"></a>normal <span class="op">=</span> np.random.randn(n)</span>
<span id="cb329-2"><a href="#cb329-2" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> np.concatenate([np.random.uniform(low<span class="op">=</span><span class="dv">3</span>,high<span class="op">=</span><span class="dv">7</span>,size<span class="op">=</span><span class="dv">60</span>), np.random.uniform(low<span class="op">=-</span><span class="dv">7</span>,high<span class="op">=-</span><span class="dv">3</span>,size<span class="op">=</span><span class="dv">60</span>),np.zeros(n<span class="op">-</span><span class="dv">120</span>)])<span class="op">;</span> np.random.shuffle(unif)</span>
<span id="cb329-3"><a href="#cb329-3" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> normal <span class="op">+</span> unif</span>
<span id="cb329-4"><a href="#cb329-4" aria-hidden="true" tabindex="-1"></a>index_of_trueoutlier2 <span class="op">=</span> np.where(unif<span class="op">!=</span><span class="dv">0</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb330"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.zeros(n)</span>
<span id="cb330-2"><a href="#cb330-2" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">1000</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3234</span></span>
<span id="cb330-3"><a href="#cb330-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> g.<span class="bu">filter</span>(f, method<span class="op">=</span><span class="st">'chebyshev'</span>) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-07-04 17:37:32,017:[WARNING](pygsp.graphs.graph.lmax): The largest eigenvalue G.lmax is not available, we need to estimate it. Explicitly call G.estimate_lmax() or G.compute_fourier_basis() once beforehand to suppress the warning.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb332"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a>G.coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(2503, 3)</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb334"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb334-1"><a href="#cb334-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> G.W.toarray()</span>
<span id="cb334-2"><a href="#cb334-2" aria-hidden="true" tabindex="-1"></a>_x <span class="op">=</span> G.coords[:,<span class="dv">0</span>]</span>
<span id="cb334-3"><a href="#cb334-3" aria-hidden="true" tabindex="-1"></a>_y <span class="op">=</span> G.coords[:,<span class="dv">1</span>]</span>
<span id="cb334-4"><a href="#cb334-4" aria-hidden="true" tabindex="-1"></a>_z <span class="op">=</span> <span class="op">-</span>G.coords[:,<span class="dv">2</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb335"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb335-1"><a href="#cb335-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb336"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb337"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb338"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> {<span class="st">'W'</span>:_W,<span class="st">'x'</span>:_x,<span class="st">'y'</span>:_y,<span class="st">'z'</span>:_z, <span class="st">'fnoise'</span>:f<span class="op">+</span>noise,<span class="st">'f'</span> : f, <span class="st">'noise'</span>: noise,<span class="st">'unif'</span>:unif,<span class="st">'index_of_trueoutlier2'</span>:index_of_trueoutlier2}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>save_data(_df,<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb340"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a>_df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'W': array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]),
 'x': array([ 0.26815193, -0.58456893, -0.02730755, ...,  0.15397547,
        -0.45056488, -0.29405249]),
 'y': array([ 0.39314334,  0.63468595,  0.33280949, ...,  0.80205526,
         0.6207154 , -0.40187451]),
 'z': array([-0.13834514, -0.22438843,  0.08658215, ...,  0.33698514,
         0.58353051, -0.08647485]),
 'fnoise': array([-1.63569131,  0.49423926, -1.04026277, ..., -1.0694093 ,
        -0.24395499,  0.41729667]),
 'f': array([-1.54422488, -0.03596483, -0.93972715, ..., -0.01924028,
        -0.02470869, -0.26266752]),
 'noise': array([-0.09146643,  0.53020409, -0.10053563, ..., -1.05016902,
        -0.2192463 ,  0.67996419]),
 'unif': array([0., 0., 0., ..., 0., 0., 0.]),
 'index_of_trueoutlier2': (array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
          240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
          397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
          569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
          858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
         1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
         1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
         1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
         1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
         2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
         2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)}</code></pre>
</div>
</div>
<hr>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb342"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname):</span>
<span id="cb342-2"><a href="#cb342-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fname, <span class="st">'rb'</span>) <span class="im">as</span> outfile:</span>
<span id="cb342-3"><a href="#cb342-3" aria-hidden="true" tabindex="-1"></a>        data_dict <span class="op">=</span> pickle.load(outfile)</span>
<span id="cb342-4"><a href="#cb342-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_dict</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1911">
<div class="sourceCode cell-code" id="cb343"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a>_df1 <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1912">
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: _df1[<span class="st">'x'</span>],<span class="st">'y'</span>:_df1[<span class="st">'y'</span>],<span class="st">'z'</span>:_df1[<span class="st">'z'</span>],<span class="st">'fnoise'</span>:_df1[<span class="st">'fnoise'</span>],<span class="st">'f'</span>:_df1[<span class="st">'f'</span>],<span class="st">'noise'</span>:_df1[<span class="st">'noise'</span>]})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1913">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a>unif <span class="op">=</span> _df1[<span class="st">'unif'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1914">
<div class="sourceCode cell-code" id="cb346"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a>_df1[<span class="st">'index_of_trueoutlier2'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1914">
<pre><code>(array([  15,   33,   34,   36,   45,   52,   61,  153,  227,  228,  235,
         240,  249,  267,  270,  273,  291,  313,  333,  353,  375,  389,
         397,  402,  439,  440,  447,  449,  456,  457,  472,  509,  564,
         569,  589,  638,  700,  713,  714,  732,  749,  814,  836,  851,
         858,  888,  910,  927,  934,  948,  953,  972,  986, 1002, 1041,
        1073, 1087, 1090, 1139, 1182, 1227, 1270, 1276, 1344, 1347, 1459,
        1461, 1467, 1499, 1500, 1512, 1515, 1544, 1562, 1610, 1637, 1640,
        1649, 1665, 1695, 1699, 1737, 1740, 1783, 1788, 1808, 1857, 1868,
        1882, 1928, 1941, 1954, 1973, 2014, 2017, 2020, 2065, 2108, 2115,
        2135, 2153, 2191, 2198, 2210, 2219, 2241, 2274, 2278, 2283, 2292,
        2314, 2328, 2340, 2341, 2357, 2387, 2399, 2477, 2485, 2487]),)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1915">
<div class="sourceCode cell-code" id="cb348"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="co"># _df = pd.DataFrame({'x' : _x, 'y' : _y, 'z' : _z, 'fnoise':f+noise,'f' : f, 'noise': noise})</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1916">
<div class="sourceCode cell-code" id="cb349"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> unif.copy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1917">
<div class="sourceCode cell-code" id="cb350"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">!=</span><span class="dv">0</span>  <span class="cf">else</span> <span class="dv">1</span>,outlier_true_one_2))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1920">
<div class="sourceCode cell-code" id="cb351"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(outlier_true_one_2).to_csv('bunny_outlier.csv')</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1748">
<div class="sourceCode cell-code" id="cb352"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(_df)[:,:<span class="dv">4</span>]</span></code></pre></div>
</div>
</section>
<section id="gode-2" class="level3">
<h3 class="anchored" data-anchor-id="gode-2">GODE</h3>
<div class="cell" data-execution_count="1749">
<div class="sourceCode cell-code" id="cb353"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb353-1"><a href="#cb353-1" aria-hidden="true" tabindex="-1"></a>_W <span class="op">=</span> _df1[<span class="st">'W'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1750">
<div class="sourceCode cell-code" id="cb354"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a>_BUNNY <span class="op">=</span> BUNNY(_df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1751">
<div class="sourceCode cell-code" id="cb355"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a>_BUNNY.fit(sd<span class="op">=</span><span class="dv">20</span>,ref<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1752">
<div class="sourceCode cell-code" id="cb356"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb356-1"><a href="#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(_BUNNY.f)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1752">
<pre><code>2503</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1753">
<div class="sourceCode cell-code" id="cb358"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb358-1"><a href="#cb358-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2503</span><span class="op">*</span><span class="fl">0.05</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1753">
<pre><code>125.15</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1754">
<div class="sourceCode cell-code" id="cb360"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> (_BUNNY.df[<span class="st">'Residual'</span>]<span class="op">**</span><span class="dv">2</span>).tolist()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1755">
<div class="sourceCode cell-code" id="cb361"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb361-1"><a href="#cb361-1" aria-hidden="true" tabindex="-1"></a><span class="co"># outlier_simul_one = list(map(lambda x: -1 if x &gt; 8.7 else 1,outlier_simul_one))</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1756">
<div class="sourceCode cell-code" id="cb362"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="fl">8.05</span> <span class="cf">else</span> <span class="dv">1</span>,outlier_simul_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1757">
<div class="sourceCode cell-code" id="cb363"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1757">
<pre><code>2378</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1758">
<div class="sourceCode cell-code" id="cb365"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb365-1"><a href="#cb365-1" aria-hidden="true" tabindex="-1"></a>outlier_simul_one.count(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1758">
<pre><code>125</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1759">
<div class="sourceCode cell-code" id="cb367"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb367-1"><a href="#cb367-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_simul_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1760">
<div class="sourceCode cell-code" id="cb368"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"GODE"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-259-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.988
Precision: 0.995
Recall: 0.993
F1 Score: 0.994</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1761">
<div class="sourceCode cell-code" id="cb371"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb371-1"><a href="#cb371-1" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> _conf.tab</span></code></pre></div>
</div>
</section>
<section id="lof" class="level3">
<h3 class="anchored" data-anchor-id="lof">LOF</h3>
<div class="cell" data-execution_count="1762">
<div class="sourceCode cell-code" id="cb372"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">2</span>,contamination<span class="op">=</span><span class="fl">0.05</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1763">
<div class="sourceCode cell-code" id="cb373"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb373-1"><a href="#cb373-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,clf.fit_predict(X),tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1764">
<div class="sourceCode cell-code" id="cb374"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LOF (Breunig et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-263-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.913
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1766">
<div class="sourceCode cell-code" id="cb377"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>two <span class="op">=</span> one.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  two = one.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="knn-2" class="level3">
<h3 class="anchored" data-anchor-id="knn-2">KNN</h3>
<div class="cell" data-tags="[]" data-execution_count="1767">
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNN()</span>
<span id="cb379-2"><a href="#cb379-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb379-3"><a href="#cb379-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'knn_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1768">
<div class="sourceCode cell-code" id="cb380"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb380-1"><a href="#cb380-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1769">
<div class="sourceCode cell-code" id="cb381"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a>outlier_KNN_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_KNN_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1770">
<div class="sourceCode cell-code" id="cb382"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_KNN_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1771">
<div class="sourceCode cell-code" id="cb383"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"kNN (Ramaswamy et al., 2000)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-269-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.942
Precision: 0.997
Recall: 0.942
F1 Score: 0.969</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1772">
<div class="sourceCode cell-code" id="cb386"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb386-1"><a href="#cb386-1" aria-hidden="true" tabindex="-1"></a>three <span class="op">=</span> two.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  three = two.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="cblof-1" class="level3">
<h3 class="anchored" data-anchor-id="cblof-1">CBLOF</h3>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb388"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>_df1 <span class="op">=</span> load_data(<span class="st">'Bunny.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb389"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a>outlier_true_one_2 <span class="op">=</span> pd.read_csv(<span class="st">'bunny_outlier.csv'</span>).iloc[:,<span class="dv">1</span>].to_list()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb390"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a>_df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: _df1[<span class="st">'x'</span>],<span class="st">'y'</span>:_df1[<span class="st">'y'</span>],<span class="st">'z'</span>:_df1[<span class="st">'z'</span>],<span class="st">'fnoise'</span>:_df1[<span class="st">'fnoise'</span>],<span class="st">'f'</span>:_df1[<span class="st">'f'</span>],<span class="st">'noise'</span>:_df1[<span class="st">'noise'</span>]})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb391"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> CBLOF(contamination<span class="op">=</span><span class="fl">0.05</span>,check_estimator<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb391-2"><a href="#cb391-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb391-3"><a href="#cb391-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'CBLOF_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/pygsp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb393"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>outlier_CBLOF_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_CBLOF_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb395"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_CBLOF_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb396"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb396-1"><a href="#cb396-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"CBLOF (He et al., 2003)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-278-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.974
Precision: 0.988
Recall: 0.985
F1 Score: 0.987</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DataFrame' object has no attribute 'append'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb399"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb399-1"><a href="#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="co"># four = three.append(_conf.tab)</span></span></code></pre></div>
</div>
<ul>
<li>Accuracy: 0.974</li>
<li>Precision: 0.988</li>
<li>Recall: 0.985</li>
<li>F1 Score: 0.987</li>
</ul>
</section>
<section id="ocsvm-2" class="level3">
<h3 class="anchored" data-anchor-id="ocsvm-2">OCSVM</h3>
<div class="cell" data-execution_count="1774">
<div class="sourceCode cell-code" id="cb400"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.OneClassSVM(nu<span class="op">=</span><span class="fl">0.1</span>, kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1775">
<div class="sourceCode cell-code" id="cb401"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb401-1"><a href="#cb401-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1775">
<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-9" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneClassSVM(gamma=0.1, nu=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" checked=""><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">OneClassSVM</label><div class="sk-toggleable__content"><pre>OneClassSVM(gamma=0.1, nu=0.1)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="1776">
<div class="sourceCode cell-code" id="cb402"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb402-1"><a href="#cb402-1" aria-hidden="true" tabindex="-1"></a>outlier_OSVM_one <span class="op">=</span> <span class="bu">list</span>(clf.predict(X))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1777">
<div class="sourceCode cell-code" id="cb403"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb403-1"><a href="#cb403-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_OSVM_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1778">
<div class="sourceCode cell-code" id="cb404"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb404-1"><a href="#cb404-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"OCSVM (Sch ̈olkopf et al., 2001)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-284-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.935
Precision: 0.992
Recall: 0.939
F1 Score: 0.965</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1779">
<div class="sourceCode cell-code" id="cb407"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb407-1"><a href="#cb407-1" aria-hidden="true" tabindex="-1"></a>five <span class="op">=</span> three.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  five = three.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mcd" class="level3">
<h3 class="anchored" data-anchor-id="mcd">MCD</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1791">
<div class="sourceCode cell-code" id="cb409"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb409-1"><a href="#cb409-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MCD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb409-2"><a href="#cb409-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb409-3"><a href="#cb409-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MCD_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1792">
<div class="sourceCode cell-code" id="cb410"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb410-1"><a href="#cb410-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1793">
<div class="sourceCode cell-code" id="cb411"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a>outlier_MCD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MCD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1794">
<div class="sourceCode cell-code" id="cb412"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb412-1"><a href="#cb412-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MCD_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1795">
<div class="sourceCode cell-code" id="cb413"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb413-1"><a href="#cb413-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MCD (Hardin and Rocke, 2004)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-290-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.982
Precision: 0.992
Recall: 0.989
F1 Score: 0.990</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1796">
<div class="sourceCode cell-code" id="cb416"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb416-1"><a href="#cb416-1" aria-hidden="true" tabindex="-1"></a>six <span class="op">=</span> five.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  six = five.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="feature-bagging" class="level3">
<h3 class="anchored" data-anchor-id="feature-bagging">Feature Bagging</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1797">
<div class="sourceCode cell-code" id="cb418"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> FeatureBagging(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb418-2"><a href="#cb418-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb418-3"><a href="#cb418-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'FeatureBagging_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1798">
<div class="sourceCode cell-code" id="cb419"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb419-1"><a href="#cb419-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1799">
<div class="sourceCode cell-code" id="cb420"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb420-1"><a href="#cb420-1" aria-hidden="true" tabindex="-1"></a>outlier_FeatureBagging_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_FeatureBagging_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1800">
<div class="sourceCode cell-code" id="cb421"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb421-1"><a href="#cb421-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_FeatureBagging_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1801">
<div class="sourceCode cell-code" id="cb422"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb422-1"><a href="#cb422-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Feature Bagging (Lazarevic and Kumar, 2005)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-296-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.954
Precision: 0.977
Recall: 0.974
F1 Score: 0.976</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1802">
<div class="sourceCode cell-code" id="cb425"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb425-1"><a href="#cb425-1" aria-hidden="true" tabindex="-1"></a>seven <span class="op">=</span> six.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  seven = six.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="abod" class="level3">
<h3 class="anchored" data-anchor-id="abod">ABOD</h3>
<div class="cell" data-execution_count="1803">
<div class="sourceCode cell-code" id="cb427"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb427-1"><a href="#cb427-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> ABOD(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb427-2"><a href="#cb427-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb427-3"><a href="#cb427-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'ABOD_Clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1804">
<div class="sourceCode cell-code" id="cb428"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb428-1"><a href="#cb428-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1805">
<div class="sourceCode cell-code" id="cb429"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb429-1"><a href="#cb429-1" aria-hidden="true" tabindex="-1"></a>outlier_ABOD_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_ABOD_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1806">
<div class="sourceCode cell-code" id="cb430"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb430-1"><a href="#cb430-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_ABOD_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1807">
<div class="sourceCode cell-code" id="cb431"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb431-1"><a href="#cb431-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"ABOD (Kriegel et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-302-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.979
Precision: 0.990
Recall: 0.988
F1 Score: 0.989</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1809">
<div class="sourceCode cell-code" id="cb434"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb434-1"><a href="#cb434-1" aria-hidden="true" tabindex="-1"></a>eight <span class="op">=</span> seven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eight = seven.append(_conf.tab)</code></pre>
</div>
</div>
<p>normal fix 안 해줘서 좀 다른듯</p>
</section>
<section id="iforest" class="level3">
<h3 class="anchored" data-anchor-id="iforest">IForest</h3>
<div class="cell" data-execution_count="1810">
<div class="sourceCode cell-code" id="cb436"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb436-1"><a href="#cb436-1" aria-hidden="true" tabindex="-1"></a>od <span class="op">=</span> IForest(</span>
<span id="cb436-2"><a href="#cb436-2" aria-hidden="true" tabindex="-1"></a>    threshold<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb436-3"><a href="#cb436-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">125</span></span>
<span id="cb436-4"><a href="#cb436-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1811">
<div class="sourceCode cell-code" id="cb437"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb437-1"><a href="#cb437-1" aria-hidden="true" tabindex="-1"></a>od.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1812">
<div class="sourceCode cell-code" id="cb438"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb438-1"><a href="#cb438-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> od.predict(</span>
<span id="cb438-2"><a href="#cb438-2" aria-hidden="true" tabindex="-1"></a>    _df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]],</span>
<span id="cb438-3"><a href="#cb438-3" aria-hidden="true" tabindex="-1"></a>    return_instance_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb438-4"><a href="#cb438-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1813">
<div class="sourceCode cell-code" id="cb439"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb439-1"><a href="#cb439-1" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'IF_alibi'</span>] <span class="op">=</span> preds[<span class="st">'data'</span>][<span class="st">'is_outlier'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1814">
<div class="sourceCode cell-code" id="cb440"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb440-1"><a href="#cb440-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> _df[<span class="st">'IF_alibi'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1815">
<div class="sourceCode cell-code" id="cb441"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb441-1"><a href="#cb441-1" aria-hidden="true" tabindex="-1"></a>outlier_alibi_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_alibi_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1816">
<div class="sourceCode cell-code" id="cb442"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb442-1"><a href="#cb442-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_alibi_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1817">
<div class="sourceCode cell-code" id="cb443"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb443-1"><a href="#cb443-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"Isolation Forest (Liu et al., 2008)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-311-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.827
Precision: 0.995
Recall: 0.822
F1 Score: 0.900</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1818">
<div class="sourceCode cell-code" id="cb446"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb446-1"><a href="#cb446-1" aria-hidden="true" tabindex="-1"></a>nine <span class="op">=</span> eight.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  nine = eight.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="hbos" class="level3">
<h3 class="anchored" data-anchor-id="hbos">HBOS</h3>
<div class="cell" data-execution_count="1819">
<div class="sourceCode cell-code" id="cb448"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb448-1"><a href="#cb448-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> HBOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb448-2"><a href="#cb448-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb448-3"><a href="#cb448-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'HBOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1820">
<div class="sourceCode cell-code" id="cb449"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb449-1"><a href="#cb449-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1821">
<div class="sourceCode cell-code" id="cb450"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb450-1"><a href="#cb450-1" aria-hidden="true" tabindex="-1"></a>outlier_HBOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_HBOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1822">
<div class="sourceCode cell-code" id="cb451"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb451-1"><a href="#cb451-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_HBOS_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1823">
<div class="sourceCode cell-code" id="cb452"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb452-1"><a href="#cb452-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"HBOS (Goldstein and Dengel, 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-317-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.919
Precision: 0.958
Recall: 0.956
F1 Score: 0.957</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1825">
<div class="sourceCode cell-code" id="cb455"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb455-1"><a href="#cb455-1" aria-hidden="true" tabindex="-1"></a>ten <span class="op">=</span> nine.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  ten = nine.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="sos" class="level3">
<h3 class="anchored" data-anchor-id="sos">SOS</h3>
<div class="cell" data-execution_count="1826">
<div class="sourceCode cell-code" id="cb457"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb457-1"><a href="#cb457-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SOS(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb457-2"><a href="#cb457-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb457-3"><a href="#cb457-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SOS_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1827">
<div class="sourceCode cell-code" id="cb458"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb458-1"><a href="#cb458-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1828">
<div class="sourceCode cell-code" id="cb459"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb459-1"><a href="#cb459-1" aria-hidden="true" tabindex="-1"></a>outlier_SOS_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SOS_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1829">
<div class="sourceCode cell-code" id="cb460"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb460-1"><a href="#cb460-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SOS_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1830">
<div class="sourceCode cell-code" id="cb461"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb461-1"><a href="#cb461-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SOS (Janssens et al., 2012)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-323-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.912
Precision: 0.955
Recall: 0.953
F1 Score: 0.954</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1832">
<div class="sourceCode cell-code" id="cb464"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb464-1"><a href="#cb464-1" aria-hidden="true" tabindex="-1"></a>eleven <span class="op">=</span> ten.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  eleven = ten.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="so_gaal-1" class="level3">
<h3 class="anchored" data-anchor-id="so_gaal-1">SO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1833">
<div class="sourceCode cell-code" id="cb466"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb466-1"><a href="#cb466-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb466-2"><a href="#cb466-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb466-3"><a href="#cb466-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'SO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:

Testing for epoch 1 index 2:

Testing for epoch 1 index 3:

Testing for epoch 1 index 4:

Testing for epoch 1 index 5:
Epoch 2 of 60

Testing for epoch 2 index 1:

Testing for epoch 2 index 2:

Testing for epoch 2 index 3:

Testing for epoch 2 index 4:

Testing for epoch 2 index 5:
Epoch 3 of 60

Testing for epoch 3 index 1:

Testing for epoch 3 index 2:

Testing for epoch 3 index 3:

Testing for epoch 3 index 4:

Testing for epoch 3 index 5:
Epoch 4 of 60

Testing for epoch 4 index 1:

Testing for epoch 4 index 2:

Testing for epoch 4 index 3:

Testing for epoch 4 index 4:

Testing for epoch 4 index 5:
Epoch 5 of 60

Testing for epoch 5 index 1:

Testing for epoch 5 index 2:

Testing for epoch 5 index 3:

Testing for epoch 5 index 4:

Testing for epoch 5 index 5:
Epoch 6 of 60

Testing for epoch 6 index 1:

Testing for epoch 6 index 2:

Testing for epoch 6 index 3:

Testing for epoch 6 index 4:

Testing for epoch 6 index 5:
Epoch 7 of 60

Testing for epoch 7 index 1:

Testing for epoch 7 index 2:

Testing for epoch 7 index 3:

Testing for epoch 7 index 4:

Testing for epoch 7 index 5:
Epoch 8 of 60

Testing for epoch 8 index 1:

Testing for epoch 8 index 2:

Testing for epoch 8 index 3:

Testing for epoch 8 index 4:

Testing for epoch 8 index 5:
Epoch 9 of 60

Testing for epoch 9 index 1:

Testing for epoch 9 index 2:

Testing for epoch 9 index 3:

Testing for epoch 9 index 4:

Testing for epoch 9 index 5:
Epoch 10 of 60

Testing for epoch 10 index 1:

Testing for epoch 10 index 2:

Testing for epoch 10 index 3:

Testing for epoch 10 index 4:

Testing for epoch 10 index 5:
Epoch 11 of 60

Testing for epoch 11 index 1:

Testing for epoch 11 index 2:

Testing for epoch 11 index 3:

Testing for epoch 11 index 4:

Testing for epoch 11 index 5:
Epoch 12 of 60

Testing for epoch 12 index 1:

Testing for epoch 12 index 2:

Testing for epoch 12 index 3:

Testing for epoch 12 index 4:

Testing for epoch 12 index 5:
Epoch 13 of 60

Testing for epoch 13 index 1:

Testing for epoch 13 index 2:

Testing for epoch 13 index 3:

Testing for epoch 13 index 4:

Testing for epoch 13 index 5:
Epoch 14 of 60

Testing for epoch 14 index 1:

Testing for epoch 14 index 2:

Testing for epoch 14 index 3:

Testing for epoch 14 index 4:

Testing for epoch 14 index 5:
Epoch 15 of 60

Testing for epoch 15 index 1:

Testing for epoch 15 index 2:

Testing for epoch 15 index 3:

Testing for epoch 15 index 4:

Testing for epoch 15 index 5:
Epoch 16 of 60

Testing for epoch 16 index 1:

Testing for epoch 16 index 2:

Testing for epoch 16 index 3:

Testing for epoch 16 index 4:

Testing for epoch 16 index 5:
Epoch 17 of 60

Testing for epoch 17 index 1:

Testing for epoch 17 index 2:

Testing for epoch 17 index 3:

Testing for epoch 17 index 4:

Testing for epoch 17 index 5:
Epoch 18 of 60

Testing for epoch 18 index 1:

Testing for epoch 18 index 2:

Testing for epoch 18 index 3:

Testing for epoch 18 index 4:

Testing for epoch 18 index 5:
Epoch 19 of 60

Testing for epoch 19 index 1:

Testing for epoch 19 index 2:

Testing for epoch 19 index 3:

Testing for epoch 19 index 4:

Testing for epoch 19 index 5:
Epoch 20 of 60

Testing for epoch 20 index 1:

Testing for epoch 20 index 2:

Testing for epoch 20 index 3:

Testing for epoch 20 index 4:

Testing for epoch 20 index 5:
Epoch 21 of 60

Testing for epoch 21 index 1:

Testing for epoch 21 index 2:

Testing for epoch 21 index 3:

Testing for epoch 21 index 4:

Testing for epoch 21 index 5:
Epoch 22 of 60

Testing for epoch 22 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 1.7853

Testing for epoch 22 index 2:
16/16 [==============================] - 0s 5ms/step - loss: 1.8346

Testing for epoch 22 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 1.8320

Testing for epoch 22 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.8046

Testing for epoch 22 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 1.8184
Epoch 23 of 60

Testing for epoch 23 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8771

Testing for epoch 23 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.8672

Testing for epoch 23 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 1.8837

Testing for epoch 23 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.8886

Testing for epoch 23 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 1.9140
Epoch 24 of 60

Testing for epoch 24 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.8837

Testing for epoch 24 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9102

Testing for epoch 24 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9125

Testing for epoch 24 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0084

Testing for epoch 24 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 1.9376
Epoch 25 of 60

Testing for epoch 25 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9044

Testing for epoch 25 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9835

Testing for epoch 25 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9699

Testing for epoch 25 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 1.9834

Testing for epoch 25 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.0290
Epoch 26 of 60

Testing for epoch 26 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 1.9765

Testing for epoch 26 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 1.9838

Testing for epoch 26 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 1.9822

Testing for epoch 26 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0609

Testing for epoch 26 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.0396
Epoch 27 of 60

Testing for epoch 27 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.0832

Testing for epoch 27 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0676

Testing for epoch 27 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.0518

Testing for epoch 27 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.0792

Testing for epoch 27 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1063
Epoch 28 of 60

Testing for epoch 28 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.1162

Testing for epoch 28 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.0633

Testing for epoch 28 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.0415

Testing for epoch 28 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.1830

Testing for epoch 28 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.1030
Epoch 29 of 60

Testing for epoch 29 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.0691

Testing for epoch 29 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.1029

Testing for epoch 29 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.0695

Testing for epoch 29 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.1422

Testing for epoch 29 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.1041
Epoch 30 of 60

Testing for epoch 30 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1561

Testing for epoch 30 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1334

Testing for epoch 30 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1333

Testing for epoch 30 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.0868

Testing for epoch 30 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.0846
Epoch 31 of 60

Testing for epoch 31 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.1405

Testing for epoch 31 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1730

Testing for epoch 31 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1575

Testing for epoch 31 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.1294

Testing for epoch 31 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1989
Epoch 32 of 60

Testing for epoch 32 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.1998

Testing for epoch 32 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.1295

Testing for epoch 32 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2162

Testing for epoch 32 index 4:
16/16 [==============================] - 0s 3ms/step - loss: 2.2034

Testing for epoch 32 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.1361
Epoch 33 of 60

Testing for epoch 33 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2382

Testing for epoch 33 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2261

Testing for epoch 33 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.1818

Testing for epoch 33 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2120

Testing for epoch 33 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2132
Epoch 34 of 60

Testing for epoch 34 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2494

Testing for epoch 34 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2255

Testing for epoch 34 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2671

Testing for epoch 34 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2116

Testing for epoch 34 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.2581
Epoch 35 of 60

Testing for epoch 35 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.2491

Testing for epoch 35 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2208

Testing for epoch 35 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.2014

Testing for epoch 35 index 4:
16/16 [==============================] - 0s 3ms/step - loss: 2.2550

Testing for epoch 35 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2830
Epoch 36 of 60

Testing for epoch 36 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2405

Testing for epoch 36 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.3333

Testing for epoch 36 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.2521

Testing for epoch 36 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.2896

Testing for epoch 36 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3155
Epoch 37 of 60

Testing for epoch 37 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3146

Testing for epoch 37 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2681

Testing for epoch 37 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.2337

Testing for epoch 37 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.2561

Testing for epoch 37 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.2611
Epoch 38 of 60

Testing for epoch 38 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.3340

Testing for epoch 38 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.2951

Testing for epoch 38 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2973

Testing for epoch 38 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3241

Testing for epoch 38 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.3202
Epoch 39 of 60

Testing for epoch 39 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.2970

Testing for epoch 39 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2818

Testing for epoch 39 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.2771

Testing for epoch 39 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.3100

Testing for epoch 39 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.2902
Epoch 40 of 60

Testing for epoch 40 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3639

Testing for epoch 40 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.2836

Testing for epoch 40 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4120

Testing for epoch 40 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.3052

Testing for epoch 40 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.2881
Epoch 41 of 60

Testing for epoch 41 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3652

Testing for epoch 41 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.3530

Testing for epoch 41 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3983

Testing for epoch 41 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3804

Testing for epoch 41 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.3145
Epoch 42 of 60

Testing for epoch 42 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3505

Testing for epoch 42 index 2:
16/16 [==============================] - 0s 3ms/step - loss: 2.3759

Testing for epoch 42 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3779

Testing for epoch 42 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4360

Testing for epoch 42 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3967
Epoch 43 of 60

Testing for epoch 43 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.4442

Testing for epoch 43 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.3817

Testing for epoch 43 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4227

Testing for epoch 43 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.3354

Testing for epoch 43 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3362
Epoch 44 of 60

Testing for epoch 44 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3727

Testing for epoch 44 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4077

Testing for epoch 44 index 3:
16/16 [==============================] - 0s 3ms/step - loss: 2.4266

Testing for epoch 44 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4087

Testing for epoch 44 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.3740
Epoch 45 of 60

Testing for epoch 45 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4019

Testing for epoch 45 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4554

Testing for epoch 45 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4162

Testing for epoch 45 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4631

Testing for epoch 45 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.4390
Epoch 46 of 60

Testing for epoch 46 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.3997

Testing for epoch 46 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4826

Testing for epoch 46 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.3973

Testing for epoch 46 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4596

Testing for epoch 46 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.4296
Epoch 47 of 60

Testing for epoch 47 index 1:
16/16 [==============================] - 0s 3ms/step - loss: 2.4578

Testing for epoch 47 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5058

Testing for epoch 47 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4464

Testing for epoch 47 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4684

Testing for epoch 47 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.4405
Epoch 48 of 60

Testing for epoch 48 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4991

Testing for epoch 48 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4709

Testing for epoch 48 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4676

Testing for epoch 48 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4131

Testing for epoch 48 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.4753
Epoch 49 of 60

Testing for epoch 49 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5160

Testing for epoch 49 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4963

Testing for epoch 49 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.4678

Testing for epoch 49 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4248

Testing for epoch 49 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.5513
Epoch 50 of 60

Testing for epoch 50 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.4780

Testing for epoch 50 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.4913

Testing for epoch 50 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4956

Testing for epoch 50 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.4918

Testing for epoch 50 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.4777
Epoch 51 of 60

Testing for epoch 51 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5556

Testing for epoch 51 index 2:
16/16 [==============================] - 0s 1ms/step - loss: 2.4938

Testing for epoch 51 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.4807

Testing for epoch 51 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5070

Testing for epoch 51 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.5431
Epoch 52 of 60

Testing for epoch 52 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.4874

Testing for epoch 52 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5284

Testing for epoch 52 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5150

Testing for epoch 52 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5187

Testing for epoch 52 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.5245
Epoch 53 of 60

Testing for epoch 53 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5878

Testing for epoch 53 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5331

Testing for epoch 53 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5031

Testing for epoch 53 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5649

Testing for epoch 53 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.5189
Epoch 54 of 60

Testing for epoch 54 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5311

Testing for epoch 54 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5879

Testing for epoch 54 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5670

Testing for epoch 54 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5522

Testing for epoch 54 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.5572
Epoch 55 of 60

Testing for epoch 55 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5563

Testing for epoch 55 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5327

Testing for epoch 55 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5742

Testing for epoch 55 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.4747

Testing for epoch 55 index 5:
16/16 [==============================] - 0s 3ms/step - loss: 2.5711
Epoch 56 of 60

Testing for epoch 56 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5344

Testing for epoch 56 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5182

Testing for epoch 56 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.4722

Testing for epoch 56 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5704

Testing for epoch 56 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6122
Epoch 57 of 60

Testing for epoch 57 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.5826

Testing for epoch 57 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5456

Testing for epoch 57 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.5821

Testing for epoch 57 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5895

Testing for epoch 57 index 5:
16/16 [==============================] - 0s 2ms/step - loss: 2.6114
Epoch 58 of 60

Testing for epoch 58 index 1:
16/16 [==============================] - 0s 2ms/step - loss: 2.5628

Testing for epoch 58 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5592

Testing for epoch 58 index 3:
16/16 [==============================] - 0s 2ms/step - loss: 2.6494

Testing for epoch 58 index 4:
16/16 [==============================] - 0s 2ms/step - loss: 2.5955

Testing for epoch 58 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6131
Epoch 59 of 60

Testing for epoch 59 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.6084

Testing for epoch 59 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5200

Testing for epoch 59 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.5612

Testing for epoch 59 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5473

Testing for epoch 59 index 5:
16/16 [==============================] - 0s 5ms/step - loss: 2.6558
Epoch 60 of 60

Testing for epoch 60 index 1:
16/16 [==============================] - 0s 1ms/step - loss: 2.6821

Testing for epoch 60 index 2:
16/16 [==============================] - 0s 2ms/step - loss: 2.5944

Testing for epoch 60 index 3:
16/16 [==============================] - 0s 1ms/step - loss: 2.6211

Testing for epoch 60 index 4:
16/16 [==============================] - 0s 1ms/step - loss: 2.5937

Testing for epoch 60 index 5:
16/16 [==============================] - 0s 1ms/step - loss: 2.6623
79/79 [==============================] - 0s 1ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1834">
<div class="sourceCode cell-code" id="cb469"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb469-1"><a href="#cb469-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1835">
<div class="sourceCode cell-code" id="cb470"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb470-1"><a href="#cb470-1" aria-hidden="true" tabindex="-1"></a>outlier_SO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_SO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1836">
<div class="sourceCode cell-code" id="cb471"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb471-1"><a href="#cb471-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_SO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1837">
<div class="sourceCode cell-code" id="cb472"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb472-1"><a href="#cb472-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"SO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-329-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1838">
<div class="sourceCode cell-code" id="cb475"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb475-1"><a href="#cb475-1" aria-hidden="true" tabindex="-1"></a>twelve <span class="op">=</span> eleven.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  twelve = eleven.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="mo_gaal" class="level3">
<h3 class="anchored" data-anchor-id="mo_gaal">MO_GAAL</h3>
<div class="cell" data-scrolled="true" data-tags="[]" data-execution_count="1839">
<div class="sourceCode cell-code" id="cb477"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb477-1"><a href="#cb477-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MO_GAAL(contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb477-2"><a href="#cb477-2" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb477-3"><a href="#cb477-3" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'MO_GAAL_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 of 60

Testing for epoch 1 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 1 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 2 of 60

Testing for epoch 2 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 2 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 2 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 3 of 60

Testing for epoch 3 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 3 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 3 index 3:
79/79 [==============================] - 0s 664us/step

Testing for epoch 3 index 4:
79/79 [==============================] - 0s 875us/step

Testing for epoch 3 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 4 of 60

Testing for epoch 4 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 4 index 2:
79/79 [==============================] - 0s 820us/step

Testing for epoch 4 index 3:
79/79 [==============================] - 0s 609us/step

Testing for epoch 4 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 4 index 5:
79/79 [==============================] - 0s 512us/step
Epoch 5 of 60

Testing for epoch 5 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 5 index 2:
79/79 [==============================] - 0s 684us/step

Testing for epoch 5 index 3:
79/79 [==============================] - 0s 589us/step

Testing for epoch 5 index 4:
79/79 [==============================] - 0s 742us/step

Testing for epoch 5 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 6 of 60

Testing for epoch 6 index 1:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 6 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 6 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 6 index 4:
79/79 [==============================] - 0s 3ms/step

Testing for epoch 6 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 7 of 60

Testing for epoch 7 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 7 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 7 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 7 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 7 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 8 of 60

Testing for epoch 8 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 8 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 8 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 8 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 8 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 9 of 60

Testing for epoch 9 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 9 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 9 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 9 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 9 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 10 of 60

Testing for epoch 10 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 10 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 10 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 11 of 60

Testing for epoch 11 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 11 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 11 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 12 of 60

Testing for epoch 12 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 12 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 12 index 5:
79/79 [==============================] - 0s 2ms/step
Epoch 13 of 60

Testing for epoch 13 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 13 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 14 of 60

Testing for epoch 14 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 14 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 15 of 60

Testing for epoch 15 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 15 index 5:
79/79 [==============================] - 0s 976us/step
Epoch 16 of 60

Testing for epoch 16 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 2:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 16 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 16 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 17 of 60

Testing for epoch 17 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 17 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 17 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 18 of 60

Testing for epoch 18 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 18 index 2:
79/79 [==============================] - 0s 891us/step

Testing for epoch 18 index 3:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 4:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 18 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 19 of 60

Testing for epoch 19 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 19 index 2:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 4:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 19 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 20 of 60

Testing for epoch 20 index 1:
79/79 [==============================] - 0s 2ms/step

Testing for epoch 20 index 2:
79/79 [==============================] - 0s 978us/step

Testing for epoch 20 index 3:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 20 index 4:
79/79 [==============================] - 0s 969us/step

Testing for epoch 20 index 5:
79/79 [==============================] - 0s 1ms/step
Epoch 21 of 60

Testing for epoch 21 index 1:
79/79 [==============================] - 0s 1ms/step

Testing for epoch 21 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2249
16/16 [==============================] - 0s 1ms/step - loss: 1.3848
16/16 [==============================] - 0s 2ms/step - loss: 1.5898
16/16 [==============================] - 1s 2ms/step - loss: 1.6900
16/16 [==============================] - 0s 1ms/step - loss: 1.7373
16/16 [==============================] - 0s 2ms/step - loss: 1.7695
16/16 [==============================] - 0s 1ms/step - loss: 1.7774
16/16 [==============================] - 0s 1ms/step - loss: 1.7766
16/16 [==============================] - 0s 1ms/step - loss: 1.7754
16/16 [==============================] - 0s 1ms/step - loss: 1.7754

Testing for epoch 21 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2249
16/16 [==============================] - 0s 2ms/step - loss: 1.4195
16/16 [==============================] - 0s 3ms/step - loss: 1.6365
16/16 [==============================] - 0s 2ms/step - loss: 1.7426
16/16 [==============================] - 0s 2ms/step - loss: 1.7927
16/16 [==============================] - 0s 2ms/step - loss: 1.8275
16/16 [==============================] - 0s 1ms/step - loss: 1.8359
16/16 [==============================] - 0s 1ms/step - loss: 1.8351
16/16 [==============================] - 0s 2ms/step - loss: 1.8338
16/16 [==============================] - 0s 2ms/step - loss: 1.8338

Testing for epoch 21 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.2255
16/16 [==============================] - 0s 2ms/step - loss: 1.4083
16/16 [==============================] - 0s 2ms/step - loss: 1.6229
16/16 [==============================] - 0s 1ms/step - loss: 1.7262
16/16 [==============================] - 0s 1ms/step - loss: 1.7739
16/16 [==============================] - 0s 2ms/step - loss: 1.8067
16/16 [==============================] - 0s 2ms/step - loss: 1.8141
16/16 [==============================] - 0s 1ms/step - loss: 1.8131
16/16 [==============================] - 0s 2ms/step - loss: 1.8118
16/16 [==============================] - 0s 2ms/step - loss: 1.8117

Testing for epoch 21 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2193
16/16 [==============================] - 0s 2ms/step - loss: 1.4150
16/16 [==============================] - 0s 2ms/step - loss: 1.6347
16/16 [==============================] - 0s 2ms/step - loss: 1.7387
16/16 [==============================] - 0s 1ms/step - loss: 1.7855
16/16 [==============================] - 0s 2ms/step - loss: 1.8169
16/16 [==============================] - 0s 2ms/step - loss: 1.8234
16/16 [==============================] - 0s 2ms/step - loss: 1.8219
16/16 [==============================] - 0s 2ms/step - loss: 1.8205
16/16 [==============================] - 0s 2ms/step - loss: 1.8205
Epoch 22 of 60

Testing for epoch 22 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.2173
16/16 [==============================] - 0s 2ms/step - loss: 1.4357
16/16 [==============================] - 0s 2ms/step - loss: 1.6634
16/16 [==============================] - 0s 5ms/step - loss: 1.7700
16/16 [==============================] - 0s 2ms/step - loss: 1.8171
16/16 [==============================] - 0s 3ms/step - loss: 1.8488
16/16 [==============================] - 0s 5ms/step - loss: 1.8558
16/16 [==============================] - 0s 2ms/step - loss: 1.8544
16/16 [==============================] - 0s 2ms/step - loss: 1.8529
16/16 [==============================] - 0s 3ms/step - loss: 1.8529

Testing for epoch 22 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2139
16/16 [==============================] - 0s 2ms/step - loss: 1.4286
16/16 [==============================] - 0s 2ms/step - loss: 1.6561
16/16 [==============================] - 0s 1ms/step - loss: 1.7609
16/16 [==============================] - 0s 4ms/step - loss: 1.8068
16/16 [==============================] - 0s 2ms/step - loss: 1.8372
16/16 [==============================] - 0s 6ms/step - loss: 1.8438
16/16 [==============================] - 0s 2ms/step - loss: 1.8422
16/16 [==============================] - 0s 2ms/step - loss: 1.8407
16/16 [==============================] - 0s 2ms/step - loss: 1.8407

Testing for epoch 22 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.2148
16/16 [==============================] - 0s 1ms/step - loss: 1.4293
16/16 [==============================] - 0s 2ms/step - loss: 1.6578
16/16 [==============================] - 0s 4ms/step - loss: 1.7632
16/16 [==============================] - 0s 2ms/step - loss: 1.8090
16/16 [==============================] - 0s 2ms/step - loss: 1.8394
16/16 [==============================] - 0s 2ms/step - loss: 1.8454
16/16 [==============================] - 0s 5ms/step - loss: 1.8437
16/16 [==============================] - 0s 2ms/step - loss: 1.8423
16/16 [==============================] - 0s 2ms/step - loss: 1.8423

Testing for epoch 22 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2181
16/16 [==============================] - 0s 3ms/step - loss: 1.3837
16/16 [==============================] - 0s 2ms/step - loss: 1.6049
16/16 [==============================] - 0s 2ms/step - loss: 1.7082
16/16 [==============================] - 0s 2ms/step - loss: 1.7544
16/16 [==============================] - 0s 4ms/step - loss: 1.7860
16/16 [==============================] - 0s 3ms/step - loss: 1.7928
16/16 [==============================] - 0s 2ms/step - loss: 1.7913
16/16 [==============================] - 0s 3ms/step - loss: 1.7897
16/16 [==============================] - 0s 2ms/step - loss: 1.7897

Testing for epoch 22 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.2083
16/16 [==============================] - 0s 991us/step - loss: 1.4684
16/16 [==============================] - 0s 873us/step - loss: 1.7111
16/16 [==============================] - 0s 2ms/step - loss: 1.8243
16/16 [==============================] - 0s 820us/step - loss: 1.8730
16/16 [==============================] - 0s 947us/step - loss: 1.9051
16/16 [==============================] - 0s 771us/step - loss: 1.9109
16/16 [==============================] - 0s 1ms/step - loss: 1.9087
16/16 [==============================] - 0s 1ms/step - loss: 1.9069
16/16 [==============================] - 0s 839us/step - loss: 1.9069
Epoch 23 of 60

Testing for epoch 23 index 1:
79/79 [==============================] - 0s 564us/step
16/16 [==============================] - 0s 872us/step - loss: 0.2068
16/16 [==============================] - 0s 929us/step - loss: 1.4438
16/16 [==============================] - 0s 859us/step - loss: 1.6817
16/16 [==============================] - 0s 829us/step - loss: 1.7917
16/16 [==============================] - 0s 1ms/step - loss: 1.8384
16/16 [==============================] - 0s 672us/step - loss: 1.8677
16/16 [==============================] - 0s 2ms/step - loss: 1.8721
16/16 [==============================] - 0s 3ms/step - loss: 1.8696
16/16 [==============================] - 0s 1ms/step - loss: 1.8677
16/16 [==============================] - 0s 942us/step - loss: 1.8676

Testing for epoch 23 index 2:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 827us/step - loss: 0.2075
16/16 [==============================] - 0s 724us/step - loss: 1.4278
16/16 [==============================] - 0s 781us/step - loss: 1.6611
16/16 [==============================] - 0s 855us/step - loss: 1.7673
16/16 [==============================] - 0s 1ms/step - loss: 1.8137
16/16 [==============================] - 0s 689us/step - loss: 1.8419
16/16 [==============================] - 0s 846us/step - loss: 1.8465
16/16 [==============================] - 0s 826us/step - loss: 1.8442
16/16 [==============================] - 0s 818us/step - loss: 1.8425
16/16 [==============================] - 0s 818us/step - loss: 1.8425

Testing for epoch 23 index 3:
79/79 [==============================] - 0s 843us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2072
16/16 [==============================] - 0s 1ms/step - loss: 1.4404
16/16 [==============================] - 0s 2ms/step - loss: 1.6810
16/16 [==============================] - 0s 5ms/step - loss: 1.7908
16/16 [==============================] - 0s 1ms/step - loss: 1.8406
16/16 [==============================] - 0s 1ms/step - loss: 1.8710
16/16 [==============================] - 0s 1ms/step - loss: 1.8762
16/16 [==============================] - 0s 2ms/step - loss: 1.8739
16/16 [==============================] - 0s 2ms/step - loss: 1.8721
16/16 [==============================] - 0s 1ms/step - loss: 1.8720

Testing for epoch 23 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.2005
16/16 [==============================] - 0s 4ms/step - loss: 1.4690
16/16 [==============================] - 0s 2ms/step - loss: 1.7149
16/16 [==============================] - 0s 1ms/step - loss: 1.8240
16/16 [==============================] - 0s 1ms/step - loss: 1.8711
16/16 [==============================] - 0s 2ms/step - loss: 1.8977
16/16 [==============================] - 0s 2ms/step - loss: 1.9010
16/16 [==============================] - 0s 2ms/step - loss: 1.8979
16/16 [==============================] - 0s 2ms/step - loss: 1.8961
16/16 [==============================] - 0s 2ms/step - loss: 1.8960

Testing for epoch 23 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1965
16/16 [==============================] - 0s 933us/step - loss: 1.4857
16/16 [==============================] - 0s 2ms/step - loss: 1.7374
16/16 [==============================] - 0s 1ms/step - loss: 1.8489
16/16 [==============================] - 0s 1ms/step - loss: 1.8958
16/16 [==============================] - 0s 1ms/step - loss: 1.9208
16/16 [==============================] - 0s 2ms/step - loss: 1.9232
16/16 [==============================] - 0s 1ms/step - loss: 1.9199
16/16 [==============================] - 0s 2ms/step - loss: 1.9179
16/16 [==============================] - 0s 2ms/step - loss: 1.9179
Epoch 24 of 60

Testing for epoch 24 index 1:
79/79 [==============================] - 0s 934us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1949
16/16 [==============================] - 0s 2ms/step - loss: 1.5125
16/16 [==============================] - 0s 1ms/step - loss: 1.7705
16/16 [==============================] - 0s 2ms/step - loss: 1.8843
16/16 [==============================] - 0s 1ms/step - loss: 1.9321
16/16 [==============================] - 0s 1ms/step - loss: 1.9573
16/16 [==============================] - 0s 934us/step - loss: 1.9592
16/16 [==============================] - 0s 2ms/step - loss: 1.9558
16/16 [==============================] - 0s 2ms/step - loss: 1.9537
16/16 [==============================] - 0s 1ms/step - loss: 1.9537

Testing for epoch 24 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1959
16/16 [==============================] - 0s 1ms/step - loss: 1.4640
16/16 [==============================] - 0s 2ms/step - loss: 1.7067
16/16 [==============================] - 0s 2ms/step - loss: 1.8128
16/16 [==============================] - 0s 2ms/step - loss: 1.8585
16/16 [==============================] - 0s 2ms/step - loss: 1.8822
16/16 [==============================] - 0s 970us/step - loss: 1.8835
16/16 [==============================] - 0s 1ms/step - loss: 1.8799
16/16 [==============================] - 0s 2ms/step - loss: 1.8778
16/16 [==============================] - 0s 1ms/step - loss: 1.8777

Testing for epoch 24 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1986
16/16 [==============================] - 0s 1ms/step - loss: 1.4867
16/16 [==============================] - 0s 4ms/step - loss: 1.7359
16/16 [==============================] - 0s 3ms/step - loss: 1.8473
16/16 [==============================] - 0s 2ms/step - loss: 1.8954
16/16 [==============================] - 0s 2ms/step - loss: 1.9193
16/16 [==============================] - 0s 2ms/step - loss: 1.9209
16/16 [==============================] - 0s 1ms/step - loss: 1.9173
16/16 [==============================] - 0s 2ms/step - loss: 1.9152
16/16 [==============================] - 0s 1ms/step - loss: 1.9151

Testing for epoch 24 index 4:
79/79 [==============================] - 0s 862us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1967
16/16 [==============================] - 0s 1ms/step - loss: 1.4806
16/16 [==============================] - 0s 2ms/step - loss: 1.7273
16/16 [==============================] - 0s 1ms/step - loss: 1.8367
16/16 [==============================] - 0s 2ms/step - loss: 1.8844
16/16 [==============================] - 0s 2ms/step - loss: 1.9072
16/16 [==============================] - 0s 1ms/step - loss: 1.9083
16/16 [==============================] - 0s 1ms/step - loss: 1.9047
16/16 [==============================] - 0s 2ms/step - loss: 1.9027
16/16 [==============================] - 0s 2ms/step - loss: 1.9027

Testing for epoch 24 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1922
16/16 [==============================] - 0s 1ms/step - loss: 1.5153
16/16 [==============================] - 0s 1ms/step - loss: 1.7681
16/16 [==============================] - 0s 1ms/step - loss: 1.8780
16/16 [==============================] - 0s 1ms/step - loss: 1.9241
16/16 [==============================] - 0s 1ms/step - loss: 1.9447
16/16 [==============================] - 0s 2ms/step - loss: 1.9445
16/16 [==============================] - 0s 1ms/step - loss: 1.9402
16/16 [==============================] - 0s 954us/step - loss: 1.9381
16/16 [==============================] - 0s 1ms/step - loss: 1.9380
Epoch 25 of 60

Testing for epoch 25 index 1:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 5ms/step - loss: 0.1929
16/16 [==============================] - 0s 1ms/step - loss: 1.4627
16/16 [==============================] - 0s 1ms/step - loss: 1.7036
16/16 [==============================] - 0s 953us/step - loss: 1.8077
16/16 [==============================] - 0s 1000us/step - loss: 1.8516
16/16 [==============================] - 0s 2ms/step - loss: 1.8687
16/16 [==============================] - 0s 1ms/step - loss: 1.8670
16/16 [==============================] - 0s 4ms/step - loss: 1.8625
16/16 [==============================] - 0s 3ms/step - loss: 1.8602
16/16 [==============================] - 0s 2ms/step - loss: 1.8602

Testing for epoch 25 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 3ms/step - loss: 0.1918
16/16 [==============================] - 0s 1ms/step - loss: 1.5117
16/16 [==============================] - 0s 2ms/step - loss: 1.7683
16/16 [==============================] - 0s 1ms/step - loss: 1.8769
16/16 [==============================] - 0s 2ms/step - loss: 1.9240
16/16 [==============================] - 0s 2ms/step - loss: 1.9418
16/16 [==============================] - 0s 1ms/step - loss: 1.9400
16/16 [==============================] - 0s 1ms/step - loss: 1.9352
16/16 [==============================] - 0s 2ms/step - loss: 1.9327
16/16 [==============================] - 0s 2ms/step - loss: 1.9326

Testing for epoch 25 index 3:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1905
16/16 [==============================] - 0s 1ms/step - loss: 1.5434
16/16 [==============================] - 0s 1ms/step - loss: 1.8096
16/16 [==============================] - 0s 1ms/step - loss: 1.9206
16/16 [==============================] - 0s 1ms/step - loss: 1.9683
16/16 [==============================] - 0s 5ms/step - loss: 1.9856
16/16 [==============================] - 0s 2ms/step - loss: 1.9832
16/16 [==============================] - 0s 2ms/step - loss: 1.9781
16/16 [==============================] - 0s 4ms/step - loss: 1.9756
16/16 [==============================] - 0s 2ms/step - loss: 1.9755

Testing for epoch 25 index 4:
79/79 [==============================] - 0s 623us/step
16/16 [==============================] - 0s 856us/step - loss: 0.1849
16/16 [==============================] - 0s 898us/step - loss: 1.5488
16/16 [==============================] - 0s 842us/step - loss: 1.8135
16/16 [==============================] - 0s 817us/step - loss: 1.9221
16/16 [==============================] - 0s 797us/step - loss: 1.9682
16/16 [==============================] - 0s 795us/step - loss: 1.9825
16/16 [==============================] - 0s 833us/step - loss: 1.9783
16/16 [==============================] - 0s 813us/step - loss: 1.9727
16/16 [==============================] - 0s 792us/step - loss: 1.9702
16/16 [==============================] - 0s 794us/step - loss: 1.9701

Testing for epoch 25 index 5:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 817us/step - loss: 0.1847
16/16 [==============================] - 0s 809us/step - loss: 1.5567
16/16 [==============================] - 0s 778us/step - loss: 1.8307
16/16 [==============================] - 0s 778us/step - loss: 1.9453
16/16 [==============================] - 0s 771us/step - loss: 1.9954
16/16 [==============================] - 0s 826us/step - loss: 2.0152
16/16 [==============================] - 0s 802us/step - loss: 2.0137
16/16 [==============================] - 0s 813us/step - loss: 2.0085
16/16 [==============================] - 0s 779us/step - loss: 2.0058
16/16 [==============================] - 0s 769us/step - loss: 2.0056
Epoch 26 of 60

Testing for epoch 26 index 1:
79/79 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1844
16/16 [==============================] - 0s 807us/step - loss: 1.5198
16/16 [==============================] - 0s 785us/step - loss: 1.7813
16/16 [==============================] - 0s 804us/step - loss: 1.8883
16/16 [==============================] - 0s 778us/step - loss: 1.9336
16/16 [==============================] - 0s 799us/step - loss: 1.9494
16/16 [==============================] - 0s 789us/step - loss: 1.9453
16/16 [==============================] - 0s 816us/step - loss: 1.9398
16/16 [==============================] - 0s 785us/step - loss: 1.9373
16/16 [==============================] - 0s 785us/step - loss: 1.9372

Testing for epoch 26 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 806us/step - loss: 0.1859
16/16 [==============================] - 0s 815us/step - loss: 1.5434
16/16 [==============================] - 0s 803us/step - loss: 1.8104
16/16 [==============================] - 0s 770us/step - loss: 1.9219
16/16 [==============================] - 0s 847us/step - loss: 1.9699
16/16 [==============================] - 0s 794us/step - loss: 1.9883
16/16 [==============================] - 0s 779us/step - loss: 1.9855
16/16 [==============================] - 0s 801us/step - loss: 1.9802
16/16 [==============================] - 0s 835us/step - loss: 1.9775
16/16 [==============================] - 0s 1ms/step - loss: 1.9773

Testing for epoch 26 index 3:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1817
16/16 [==============================] - 0s 1ms/step - loss: 1.5762
16/16 [==============================] - 0s 1ms/step - loss: 1.8483
16/16 [==============================] - 0s 1ms/step - loss: 1.9610
16/16 [==============================] - 0s 781us/step - loss: 2.0079
16/16 [==============================] - 0s 1ms/step - loss: 2.0228
16/16 [==============================] - 0s 1ms/step - loss: 2.0191
16/16 [==============================] - 0s 1ms/step - loss: 2.0135
16/16 [==============================] - 0s 771us/step - loss: 2.0108
16/16 [==============================] - 0s 785us/step - loss: 2.0106

Testing for epoch 26 index 4:
79/79 [==============================] - 0s 749us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1829
16/16 [==============================] - 0s 1ms/step - loss: 1.5509
16/16 [==============================] - 0s 808us/step - loss: 1.8163
16/16 [==============================] - 0s 782us/step - loss: 1.9243
16/16 [==============================] - 0s 783us/step - loss: 1.9681
16/16 [==============================] - 0s 782us/step - loss: 1.9796
16/16 [==============================] - 0s 785us/step - loss: 1.9733
16/16 [==============================] - 0s 789us/step - loss: 1.9671
16/16 [==============================] - 0s 795us/step - loss: 1.9644
16/16 [==============================] - 0s 797us/step - loss: 1.9643

Testing for epoch 26 index 5:
79/79 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 834us/step - loss: 0.1804
16/16 [==============================] - 0s 785us/step - loss: 1.5986
16/16 [==============================] - 0s 791us/step - loss: 1.8789
16/16 [==============================] - 0s 810us/step - loss: 1.9937
16/16 [==============================] - 0s 786us/step - loss: 2.0401
16/16 [==============================] - 0s 775us/step - loss: 2.0543
16/16 [==============================] - 0s 813us/step - loss: 2.0491
16/16 [==============================] - 0s 841us/step - loss: 2.0430
16/16 [==============================] - 0s 787us/step - loss: 2.0402
16/16 [==============================] - 0s 802us/step - loss: 2.0401
Epoch 27 of 60

Testing for epoch 27 index 1:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 980us/step - loss: 0.1780
16/16 [==============================] - 0s 1ms/step - loss: 1.5897
16/16 [==============================] - 0s 1ms/step - loss: 1.8713
16/16 [==============================] - 0s 1ms/step - loss: 1.9847
16/16 [==============================] - 0s 785us/step - loss: 2.0309
16/16 [==============================] - 0s 800us/step - loss: 2.0444
16/16 [==============================] - 0s 801us/step - loss: 2.0382
16/16 [==============================] - 0s 800us/step - loss: 2.0316
16/16 [==============================] - 0s 775us/step - loss: 2.0287
16/16 [==============================] - 0s 772us/step - loss: 2.0286

Testing for epoch 27 index 2:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1847
16/16 [==============================] - 0s 776us/step - loss: 1.5399
16/16 [==============================] - 0s 808us/step - loss: 1.8078
16/16 [==============================] - 0s 805us/step - loss: 1.9151
16/16 [==============================] - 0s 1ms/step - loss: 1.9593
16/16 [==============================] - 0s 774us/step - loss: 1.9706
16/16 [==============================] - 0s 922us/step - loss: 1.9641
16/16 [==============================] - 0s 1ms/step - loss: 1.9579
16/16 [==============================] - 0s 1ms/step - loss: 1.9552
16/16 [==============================] - 0s 1ms/step - loss: 1.9551

Testing for epoch 27 index 3:
79/79 [==============================] - 0s 609us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1802
16/16 [==============================] - 0s 1ms/step - loss: 1.5996
16/16 [==============================] - 0s 840us/step - loss: 1.8825
16/16 [==============================] - 0s 865us/step - loss: 1.9942
16/16 [==============================] - 0s 893us/step - loss: 2.0396
16/16 [==============================] - 0s 707us/step - loss: 2.0499
16/16 [==============================] - 0s 796us/step - loss: 2.0429
16/16 [==============================] - 0s 686us/step - loss: 2.0363
16/16 [==============================] - 0s 703us/step - loss: 2.0335
16/16 [==============================] - 0s 713us/step - loss: 2.0335

Testing for epoch 27 index 4:
79/79 [==============================] - 0s 763us/step
16/16 [==============================] - 0s 845us/step - loss: 0.1746
16/16 [==============================] - 0s 1ms/step - loss: 1.6245
16/16 [==============================] - 0s 1ms/step - loss: 1.9167
16/16 [==============================] - 0s 796us/step - loss: 2.0309
16/16 [==============================] - 0s 813us/step - loss: 2.0769
16/16 [==============================] - 0s 803us/step - loss: 2.0875
16/16 [==============================] - 0s 811us/step - loss: 2.0801
16/16 [==============================] - 0s 796us/step - loss: 2.0733
16/16 [==============================] - 0s 815us/step - loss: 2.0704
16/16 [==============================] - 0s 790us/step - loss: 2.0703

Testing for epoch 27 index 5:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 831us/step - loss: 0.1721
16/16 [==============================] - 0s 817us/step - loss: 1.6490
16/16 [==============================] - 0s 829us/step - loss: 1.9488
16/16 [==============================] - 0s 804us/step - loss: 2.0650
16/16 [==============================] - 0s 814us/step - loss: 2.1109
16/16 [==============================] - 0s 828us/step - loss: 2.1218
16/16 [==============================] - 0s 836us/step - loss: 2.1139
16/16 [==============================] - 0s 2ms/step - loss: 2.1069
16/16 [==============================] - 0s 2ms/step - loss: 2.1038
16/16 [==============================] - 0s 2ms/step - loss: 2.1037
Epoch 28 of 60

Testing for epoch 28 index 1:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 842us/step - loss: 0.1745
16/16 [==============================] - 0s 841us/step - loss: 1.6265
16/16 [==============================] - 0s 856us/step - loss: 1.9218
16/16 [==============================] - 0s 844us/step - loss: 2.0351
16/16 [==============================] - 0s 870us/step - loss: 2.0786
16/16 [==============================] - 0s 884us/step - loss: 2.0882
16/16 [==============================] - 0s 929us/step - loss: 2.0794
16/16 [==============================] - 0s 911us/step - loss: 2.0722
16/16 [==============================] - 0s 983us/step - loss: 2.0691
16/16 [==============================] - 0s 924us/step - loss: 2.0690

Testing for epoch 28 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1718
16/16 [==============================] - 0s 4ms/step - loss: 1.6199
16/16 [==============================] - 0s 2ms/step - loss: 1.9153
16/16 [==============================] - 0s 1ms/step - loss: 2.0279
16/16 [==============================] - 0s 2ms/step - loss: 2.0710
16/16 [==============================] - 0s 2ms/step - loss: 2.0805
16/16 [==============================] - 0s 1ms/step - loss: 2.0718
16/16 [==============================] - 0s 2ms/step - loss: 2.0644
16/16 [==============================] - 0s 2ms/step - loss: 2.0613
16/16 [==============================] - 0s 2ms/step - loss: 2.0612

Testing for epoch 28 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1764
16/16 [==============================] - 0s 2ms/step - loss: 1.5756
16/16 [==============================] - 0s 992us/step - loss: 1.8577
16/16 [==============================] - 0s 1ms/step - loss: 1.9628
16/16 [==============================] - 0s 4ms/step - loss: 2.0023
16/16 [==============================] - 0s 1ms/step - loss: 2.0074
16/16 [==============================] - 0s 2ms/step - loss: 1.9974
16/16 [==============================] - 0s 2ms/step - loss: 1.9900
16/16 [==============================] - 0s 2ms/step - loss: 1.9869
16/16 [==============================] - 0s 2ms/step - loss: 1.9867

Testing for epoch 28 index 4:
79/79 [==============================] - 0s 897us/step
16/16 [==============================] - 0s 991us/step - loss: 0.1714
16/16 [==============================] - 0s 2ms/step - loss: 1.5748
16/16 [==============================] - 0s 2ms/step - loss: 1.8565
16/16 [==============================] - 0s 1ms/step - loss: 1.9601
16/16 [==============================] - 0s 2ms/step - loss: 1.9993
16/16 [==============================] - 0s 2ms/step - loss: 2.0048
16/16 [==============================] - 0s 2ms/step - loss: 1.9951
16/16 [==============================] - 0s 1ms/step - loss: 1.9878
16/16 [==============================] - 0s 1ms/step - loss: 1.9850
16/16 [==============================] - 0s 2ms/step - loss: 1.9849

Testing for epoch 28 index 5:
79/79 [==============================] - 0s 947us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1700
16/16 [==============================] - 0s 1ms/step - loss: 1.6374
16/16 [==============================] - 0s 1ms/step - loss: 1.9381
16/16 [==============================] - 0s 1ms/step - loss: 2.0497
16/16 [==============================] - 0s 1ms/step - loss: 2.0926
16/16 [==============================] - 0s 1ms/step - loss: 2.0984
16/16 [==============================] - 0s 1ms/step - loss: 2.0886
16/16 [==============================] - 0s 1ms/step - loss: 2.0809
16/16 [==============================] - 0s 1ms/step - loss: 2.0778
16/16 [==============================] - 0s 2ms/step - loss: 2.0776
Epoch 29 of 60

Testing for epoch 29 index 1:
79/79 [==============================] - 0s 878us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1688
16/16 [==============================] - 0s 2ms/step - loss: 1.6160
16/16 [==============================] - 0s 2ms/step - loss: 1.9106
16/16 [==============================] - 0s 1ms/step - loss: 2.0177
16/16 [==============================] - 0s 1ms/step - loss: 2.0581
16/16 [==============================] - 0s 1ms/step - loss: 2.0626
16/16 [==============================] - 0s 2ms/step - loss: 2.0522
16/16 [==============================] - 0s 1ms/step - loss: 2.0446
16/16 [==============================] - 0s 1ms/step - loss: 2.0417
16/16 [==============================] - 0s 3ms/step - loss: 2.0417

Testing for epoch 29 index 2:
79/79 [==============================] - 0s 967us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1690
16/16 [==============================] - 0s 1ms/step - loss: 1.6719
16/16 [==============================] - 0s 1ms/step - loss: 1.9800
16/16 [==============================] - 0s 2ms/step - loss: 2.0915
16/16 [==============================] - 0s 1ms/step - loss: 2.1340
16/16 [==============================] - 0s 1ms/step - loss: 2.1376
16/16 [==============================] - 0s 1ms/step - loss: 2.1260
16/16 [==============================] - 0s 1ms/step - loss: 2.1178
16/16 [==============================] - 0s 964us/step - loss: 2.1145
16/16 [==============================] - 0s 1ms/step - loss: 2.1144

Testing for epoch 29 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1690
16/16 [==============================] - 0s 2ms/step - loss: 1.5813
16/16 [==============================] - 0s 1ms/step - loss: 1.8637
16/16 [==============================] - 0s 1ms/step - loss: 1.9638
16/16 [==============================] - 0s 2ms/step - loss: 2.0025
16/16 [==============================] - 0s 2ms/step - loss: 2.0058
16/16 [==============================] - 0s 2ms/step - loss: 1.9953
16/16 [==============================] - 0s 2ms/step - loss: 1.9879
16/16 [==============================] - 0s 2ms/step - loss: 1.9850
16/16 [==============================] - 0s 1ms/step - loss: 1.9849

Testing for epoch 29 index 4:
79/79 [==============================] - 0s 3ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1653
16/16 [==============================] - 0s 2ms/step - loss: 1.7200
16/16 [==============================] - 0s 2ms/step - loss: 2.0423
16/16 [==============================] - 0s 1ms/step - loss: 2.1567
16/16 [==============================] - 0s 1ms/step - loss: 2.2005
16/16 [==============================] - 0s 1ms/step - loss: 2.2035
16/16 [==============================] - 0s 1ms/step - loss: 2.1900
16/16 [==============================] - 0s 1ms/step - loss: 2.1809
16/16 [==============================] - 0s 2ms/step - loss: 2.1772
16/16 [==============================] - 0s 3ms/step - loss: 2.1770

Testing for epoch 29 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1656
16/16 [==============================] - 0s 2ms/step - loss: 1.6312
16/16 [==============================] - 0s 1ms/step - loss: 1.9296
16/16 [==============================] - 0s 1ms/step - loss: 2.0334
16/16 [==============================] - 0s 1ms/step - loss: 2.0736
16/16 [==============================] - 0s 1ms/step - loss: 2.0773
16/16 [==============================] - 0s 1ms/step - loss: 2.0655
16/16 [==============================] - 0s 2ms/step - loss: 2.0575
16/16 [==============================] - 0s 2ms/step - loss: 2.0543
16/16 [==============================] - 0s 2ms/step - loss: 2.0542
Epoch 30 of 60

Testing for epoch 30 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1641
16/16 [==============================] - 0s 1ms/step - loss: 1.6943
16/16 [==============================] - 0s 1ms/step - loss: 2.0115
16/16 [==============================] - 0s 1ms/step - loss: 2.1206
16/16 [==============================] - 0s 2ms/step - loss: 2.1614
16/16 [==============================] - 0s 1ms/step - loss: 2.1623
16/16 [==============================] - 0s 933us/step - loss: 2.1487
16/16 [==============================] - 0s 2ms/step - loss: 2.1400
16/16 [==============================] - 0s 2ms/step - loss: 2.1366
16/16 [==============================] - 0s 1ms/step - loss: 2.1364

Testing for epoch 30 index 2:
79/79 [==============================] - 0s 864us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1658
16/16 [==============================] - 0s 1ms/step - loss: 1.6611
16/16 [==============================] - 0s 1ms/step - loss: 1.9702
16/16 [==============================] - 0s 1ms/step - loss: 2.0763
16/16 [==============================] - 0s 1ms/step - loss: 2.1169
16/16 [==============================] - 0s 1ms/step - loss: 2.1173
16/16 [==============================] - 0s 1ms/step - loss: 2.1036
16/16 [==============================] - 0s 1ms/step - loss: 2.0951
16/16 [==============================] - 0s 1ms/step - loss: 2.0918
16/16 [==============================] - 0s 2ms/step - loss: 2.0917

Testing for epoch 30 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1678
16/16 [==============================] - 0s 2ms/step - loss: 1.6270
16/16 [==============================] - 0s 2ms/step - loss: 1.9300
16/16 [==============================] - 0s 2ms/step - loss: 2.0320
16/16 [==============================] - 0s 2ms/step - loss: 2.0718
16/16 [==============================] - 0s 2ms/step - loss: 2.0723
16/16 [==============================] - 0s 1ms/step - loss: 2.0596
16/16 [==============================] - 0s 2ms/step - loss: 2.0514
16/16 [==============================] - 0s 2ms/step - loss: 2.0481
16/16 [==============================] - 0s 2ms/step - loss: 2.0479

Testing for epoch 30 index 4:
79/79 [==============================] - 0s 932us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1629
16/16 [==============================] - 0s 2ms/step - loss: 1.6611
16/16 [==============================] - 0s 2ms/step - loss: 1.9644
16/16 [==============================] - 0s 2ms/step - loss: 2.0613
16/16 [==============================] - 0s 1ms/step - loss: 2.0966
16/16 [==============================] - 0s 3ms/step - loss: 2.0905
16/16 [==============================] - 0s 2ms/step - loss: 2.0735
16/16 [==============================] - 0s 1ms/step - loss: 2.0643
16/16 [==============================] - 0s 2ms/step - loss: 2.0611
16/16 [==============================] - 0s 1ms/step - loss: 2.0611

Testing for epoch 30 index 5:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1580
16/16 [==============================] - 0s 1ms/step - loss: 1.7343
16/16 [==============================] - 0s 926us/step - loss: 2.0589
16/16 [==============================] - 0s 3ms/step - loss: 2.1636
16/16 [==============================] - 0s 2ms/step - loss: 2.2026
16/16 [==============================] - 0s 960us/step - loss: 2.1988
16/16 [==============================] - 0s 2ms/step - loss: 2.1826
16/16 [==============================] - 0s 2ms/step - loss: 2.1732
16/16 [==============================] - 0s 2ms/step - loss: 2.1697
16/16 [==============================] - 0s 2ms/step - loss: 2.1695
Epoch 31 of 60

Testing for epoch 31 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1629
16/16 [==============================] - 0s 2ms/step - loss: 1.6340
16/16 [==============================] - 0s 2ms/step - loss: 1.9369
16/16 [==============================] - 0s 4ms/step - loss: 2.0366
16/16 [==============================] - 0s 1ms/step - loss: 2.0749
16/16 [==============================] - 0s 2ms/step - loss: 2.0736
16/16 [==============================] - 0s 1ms/step - loss: 2.0595
16/16 [==============================] - 0s 2ms/step - loss: 2.0507
16/16 [==============================] - 0s 1ms/step - loss: 2.0472
16/16 [==============================] - 0s 2ms/step - loss: 2.0470

Testing for epoch 31 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1602
16/16 [==============================] - 0s 2ms/step - loss: 1.6604
16/16 [==============================] - 0s 1ms/step - loss: 1.9645
16/16 [==============================] - 0s 2ms/step - loss: 2.0619
16/16 [==============================] - 0s 1ms/step - loss: 2.0977
16/16 [==============================] - 0s 2ms/step - loss: 2.0922
16/16 [==============================] - 0s 1ms/step - loss: 2.0766
16/16 [==============================] - 0s 2ms/step - loss: 2.0677
16/16 [==============================] - 0s 2ms/step - loss: 2.0645
16/16 [==============================] - 0s 2ms/step - loss: 2.0644

Testing for epoch 31 index 3:
79/79 [==============================] - 0s 814us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1592
16/16 [==============================] - 0s 3ms/step - loss: 1.7109
16/16 [==============================] - 0s 2ms/step - loss: 2.0223
16/16 [==============================] - 0s 1ms/step - loss: 2.1224
16/16 [==============================] - 0s 1ms/step - loss: 2.1597
16/16 [==============================] - 0s 977us/step - loss: 2.1517
16/16 [==============================] - 0s 961us/step - loss: 2.1344
16/16 [==============================] - 0s 2ms/step - loss: 2.1248
16/16 [==============================] - 0s 1ms/step - loss: 2.1212
16/16 [==============================] - 0s 1ms/step - loss: 2.1210

Testing for epoch 31 index 4:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 975us/step - loss: 0.1591
16/16 [==============================] - 0s 1ms/step - loss: 1.7203
16/16 [==============================] - 0s 1ms/step - loss: 2.0343
16/16 [==============================] - 0s 4ms/step - loss: 2.1337
16/16 [==============================] - 0s 1ms/step - loss: 2.1707
16/16 [==============================] - 0s 2ms/step - loss: 2.1621
16/16 [==============================] - 0s 2ms/step - loss: 2.1441
16/16 [==============================] - 0s 2ms/step - loss: 2.1342
16/16 [==============================] - 0s 1ms/step - loss: 2.1305
16/16 [==============================] - 0s 1ms/step - loss: 2.1303

Testing for epoch 31 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1568
16/16 [==============================] - 0s 2ms/step - loss: 1.7400
16/16 [==============================] - 0s 2ms/step - loss: 2.0591
16/16 [==============================] - 0s 2ms/step - loss: 2.1605
16/16 [==============================] - 0s 2ms/step - loss: 2.1977
16/16 [==============================] - 0s 2ms/step - loss: 2.1903
16/16 [==============================] - 0s 1ms/step - loss: 2.1724
16/16 [==============================] - 0s 2ms/step - loss: 2.1626
16/16 [==============================] - 0s 2ms/step - loss: 2.1590
16/16 [==============================] - 0s 1ms/step - loss: 2.1589
Epoch 32 of 60

Testing for epoch 32 index 1:
79/79 [==============================] - 0s 870us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1585
16/16 [==============================] - 0s 2ms/step - loss: 1.7001
16/16 [==============================] - 0s 1ms/step - loss: 2.0088
16/16 [==============================] - 0s 2ms/step - loss: 2.1060
16/16 [==============================] - 0s 2ms/step - loss: 2.1420
16/16 [==============================] - 0s 2ms/step - loss: 2.1348
16/16 [==============================] - 0s 2ms/step - loss: 2.1169
16/16 [==============================] - 0s 2ms/step - loss: 2.1072
16/16 [==============================] - 0s 4ms/step - loss: 2.1037
16/16 [==============================] - 0s 2ms/step - loss: 2.1035

Testing for epoch 32 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 899us/step - loss: 0.1574
16/16 [==============================] - 0s 1ms/step - loss: 1.7923
16/16 [==============================] - 0s 1ms/step - loss: 2.1196
16/16 [==============================] - 0s 2ms/step - loss: 2.2226
16/16 [==============================] - 0s 990us/step - loss: 2.2597
16/16 [==============================] - 0s 1ms/step - loss: 2.2503
16/16 [==============================] - 0s 1ms/step - loss: 2.2299
16/16 [==============================] - 0s 962us/step - loss: 2.2193
16/16 [==============================] - 0s 1ms/step - loss: 2.2156
16/16 [==============================] - 0s 996us/step - loss: 2.2155

Testing for epoch 32 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 7ms/step - loss: 0.1557
16/16 [==============================] - 0s 2ms/step - loss: 1.7954
16/16 [==============================] - 0s 2ms/step - loss: 2.1247
16/16 [==============================] - 0s 2ms/step - loss: 2.2272
16/16 [==============================] - 0s 2ms/step - loss: 2.2635
16/16 [==============================] - 0s 2ms/step - loss: 2.2531
16/16 [==============================] - 0s 2ms/step - loss: 2.2322
16/16 [==============================] - 0s 2ms/step - loss: 2.2215
16/16 [==============================] - 0s 2ms/step - loss: 2.2178
16/16 [==============================] - 0s 2ms/step - loss: 2.2177

Testing for epoch 32 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1537
16/16 [==============================] - 0s 1ms/step - loss: 1.7869
16/16 [==============================] - 0s 1ms/step - loss: 2.1168
16/16 [==============================] - 0s 1ms/step - loss: 2.2210
16/16 [==============================] - 0s 1ms/step - loss: 2.2596
16/16 [==============================] - 0s 1ms/step - loss: 2.2526
16/16 [==============================] - 0s 992us/step - loss: 2.2329
16/16 [==============================] - 0s 969us/step - loss: 2.2226
16/16 [==============================] - 0s 1ms/step - loss: 2.2187
16/16 [==============================] - 0s 1ms/step - loss: 2.2184

Testing for epoch 32 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1510
16/16 [==============================] - 0s 2ms/step - loss: 1.7654
16/16 [==============================] - 0s 1ms/step - loss: 2.0879
16/16 [==============================] - 0s 2ms/step - loss: 2.1879
16/16 [==============================] - 0s 1ms/step - loss: 2.2230
16/16 [==============================] - 0s 1ms/step - loss: 2.2123
16/16 [==============================] - 0s 1ms/step - loss: 2.1914
16/16 [==============================] - 0s 1ms/step - loss: 2.1809
16/16 [==============================] - 0s 1ms/step - loss: 2.1770
16/16 [==============================] - 0s 1ms/step - loss: 2.1768
Epoch 33 of 60

Testing for epoch 33 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1555
16/16 [==============================] - 0s 1ms/step - loss: 1.7559
16/16 [==============================] - 0s 2ms/step - loss: 2.0784
16/16 [==============================] - 0s 2ms/step - loss: 2.1784
16/16 [==============================] - 0s 4ms/step - loss: 2.2136
16/16 [==============================] - 0s 2ms/step - loss: 2.2035
16/16 [==============================] - 0s 2ms/step - loss: 2.1825
16/16 [==============================] - 0s 1ms/step - loss: 2.1721
16/16 [==============================] - 0s 3ms/step - loss: 2.1683
16/16 [==============================] - 0s 2ms/step - loss: 2.1681

Testing for epoch 33 index 2:
79/79 [==============================] - 0s 2ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1507
16/16 [==============================] - 0s 932us/step - loss: 1.7736
16/16 [==============================] - 0s 877us/step - loss: 2.0996
16/16 [==============================] - 0s 821us/step - loss: 2.2003
16/16 [==============================] - 0s 801us/step - loss: 2.2338
16/16 [==============================] - 0s 821us/step - loss: 2.2216
16/16 [==============================] - 0s 842us/step - loss: 2.2004
16/16 [==============================] - 0s 791us/step - loss: 2.1900
16/16 [==============================] - 0s 787us/step - loss: 2.1864
16/16 [==============================] - 0s 816us/step - loss: 2.1863

Testing for epoch 33 index 3:
79/79 [==============================] - 0s 589us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1522
16/16 [==============================] - 0s 829us/step - loss: 1.7884
16/16 [==============================] - 0s 806us/step - loss: 2.1161
16/16 [==============================] - 0s 793us/step - loss: 2.2152
16/16 [==============================] - 0s 777us/step - loss: 2.2465
16/16 [==============================] - 0s 780us/step - loss: 2.2315
16/16 [==============================] - 0s 794us/step - loss: 2.2087
16/16 [==============================] - 0s 783us/step - loss: 2.1979
16/16 [==============================] - 0s 824us/step - loss: 2.1942
16/16 [==============================] - 0s 1ms/step - loss: 2.1941

Testing for epoch 33 index 4:
79/79 [==============================] - 0s 600us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1512
16/16 [==============================] - 0s 838us/step - loss: 1.7421
16/16 [==============================] - 0s 848us/step - loss: 2.0614
16/16 [==============================] - 0s 818us/step - loss: 2.1598
16/16 [==============================] - 0s 791us/step - loss: 2.1919
16/16 [==============================] - 0s 785us/step - loss: 2.1795
16/16 [==============================] - 0s 815us/step - loss: 2.1576
16/16 [==============================] - 0s 800us/step - loss: 2.1471
16/16 [==============================] - 0s 835us/step - loss: 2.1433
16/16 [==============================] - 0s 804us/step - loss: 2.1431

Testing for epoch 33 index 5:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 850us/step - loss: 0.1533
16/16 [==============================] - 0s 823us/step - loss: 1.7343
16/16 [==============================] - 0s 841us/step - loss: 2.0496
16/16 [==============================] - 0s 819us/step - loss: 2.1449
16/16 [==============================] - 0s 840us/step - loss: 2.1741
16/16 [==============================] - 0s 829us/step - loss: 2.1592
16/16 [==============================] - 0s 810us/step - loss: 2.1358
16/16 [==============================] - 0s 784us/step - loss: 2.1250
16/16 [==============================] - 0s 834us/step - loss: 2.1212
16/16 [==============================] - 0s 850us/step - loss: 2.1210
Epoch 34 of 60

Testing for epoch 34 index 1:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1524
16/16 [==============================] - 0s 1ms/step - loss: 1.7155
16/16 [==============================] - 0s 1ms/step - loss: 2.0298
16/16 [==============================] - 0s 1ms/step - loss: 2.1247
16/16 [==============================] - 0s 816us/step - loss: 2.1539
16/16 [==============================] - 0s 845us/step - loss: 2.1409
16/16 [==============================] - 0s 784us/step - loss: 2.1187
16/16 [==============================] - 0s 1ms/step - loss: 2.1082
16/16 [==============================] - 0s 1ms/step - loss: 2.1044
16/16 [==============================] - 0s 970us/step - loss: 2.1041

Testing for epoch 34 index 2:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1485
16/16 [==============================] - 0s 826us/step - loss: 1.7384
16/16 [==============================] - 0s 794us/step - loss: 2.0580
16/16 [==============================] - 0s 786us/step - loss: 2.1532
16/16 [==============================] - 0s 782us/step - loss: 2.1809
16/16 [==============================] - 0s 782us/step - loss: 2.1669
16/16 [==============================] - 0s 792us/step - loss: 2.1444
16/16 [==============================] - 0s 779us/step - loss: 2.1341
16/16 [==============================] - 0s 782us/step - loss: 2.1306
16/16 [==============================] - 0s 828us/step - loss: 2.1305

Testing for epoch 34 index 3:
79/79 [==============================] - 0s 603us/step
16/16 [==============================] - 0s 809us/step - loss: 0.1477
16/16 [==============================] - 0s 1ms/step - loss: 1.7757
16/16 [==============================] - 0s 1ms/step - loss: 2.1041
16/16 [==============================] - 0s 820us/step - loss: 2.1998
16/16 [==============================] - 0s 783us/step - loss: 2.2271
16/16 [==============================] - 0s 774us/step - loss: 2.2111
16/16 [==============================] - 0s 783us/step - loss: 2.1877
16/16 [==============================] - 0s 1ms/step - loss: 2.1770
16/16 [==============================] - 0s 772us/step - loss: 2.1732
16/16 [==============================] - 0s 817us/step - loss: 2.1731

Testing for epoch 34 index 4:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 807us/step - loss: 0.1443
16/16 [==============================] - 0s 797us/step - loss: 1.8313
16/16 [==============================] - 0s 766us/step - loss: 2.1753
16/16 [==============================] - 0s 775us/step - loss: 2.2750
16/16 [==============================] - 0s 775us/step - loss: 2.3028
16/16 [==============================] - 0s 782us/step - loss: 2.2844
16/16 [==============================] - 0s 778us/step - loss: 2.2581
16/16 [==============================] - 0s 780us/step - loss: 2.2464
16/16 [==============================] - 0s 793us/step - loss: 2.2425
16/16 [==============================] - 0s 798us/step - loss: 2.2424

Testing for epoch 34 index 5:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 779us/step - loss: 0.1507
16/16 [==============================] - 0s 1ms/step - loss: 1.7991
16/16 [==============================] - 0s 1ms/step - loss: 2.1385
16/16 [==============================] - 0s 805us/step - loss: 2.2388
16/16 [==============================] - 0s 777us/step - loss: 2.2689
16/16 [==============================] - 0s 769us/step - loss: 2.2553
16/16 [==============================] - 0s 770us/step - loss: 2.2330
16/16 [==============================] - 0s 766us/step - loss: 2.2225
16/16 [==============================] - 0s 796us/step - loss: 2.2189
16/16 [==============================] - 0s 802us/step - loss: 2.2187
Epoch 35 of 60

Testing for epoch 35 index 1:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 810us/step - loss: 0.1468
16/16 [==============================] - 0s 1000us/step - loss: 1.8167
16/16 [==============================] - 0s 1ms/step - loss: 2.1570
16/16 [==============================] - 0s 783us/step - loss: 2.2540
16/16 [==============================] - 0s 816us/step - loss: 2.2807
16/16 [==============================] - 0s 980us/step - loss: 2.2621
16/16 [==============================] - 0s 787us/step - loss: 2.2360
16/16 [==============================] - 0s 814us/step - loss: 2.2244
16/16 [==============================] - 0s 805us/step - loss: 2.2204
16/16 [==============================] - 0s 832us/step - loss: 2.2203

Testing for epoch 35 index 2:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1469
16/16 [==============================] - 0s 791us/step - loss: 1.8178
16/16 [==============================] - 0s 775us/step - loss: 2.1558
16/16 [==============================] - 0s 784us/step - loss: 2.2515
16/16 [==============================] - 0s 796us/step - loss: 2.2769
16/16 [==============================] - 0s 783us/step - loss: 2.2571
16/16 [==============================] - 0s 802us/step - loss: 2.2299
16/16 [==============================] - 0s 779us/step - loss: 2.2181
16/16 [==============================] - 0s 811us/step - loss: 2.2141
16/16 [==============================] - 0s 798us/step - loss: 2.2140

Testing for epoch 35 index 3:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1499
16/16 [==============================] - 0s 823us/step - loss: 1.7804
16/16 [==============================] - 0s 814us/step - loss: 2.1084
16/16 [==============================] - 0s 789us/step - loss: 2.1988
16/16 [==============================] - 0s 779us/step - loss: 2.2227
16/16 [==============================] - 0s 772us/step - loss: 2.2030
16/16 [==============================] - 0s 794us/step - loss: 2.1772
16/16 [==============================] - 0s 787us/step - loss: 2.1661
16/16 [==============================] - 0s 822us/step - loss: 2.1624
16/16 [==============================] - 0s 797us/step - loss: 2.1623

Testing for epoch 35 index 4:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1474
16/16 [==============================] - 0s 804us/step - loss: 1.7882
16/16 [==============================] - 0s 816us/step - loss: 2.1206
16/16 [==============================] - 0s 826us/step - loss: 2.2126
16/16 [==============================] - 0s 844us/step - loss: 2.2362
16/16 [==============================] - 0s 804us/step - loss: 2.2145
16/16 [==============================] - 0s 1ms/step - loss: 2.1867
16/16 [==============================] - 0s 881us/step - loss: 2.1749
16/16 [==============================] - 0s 852us/step - loss: 2.1709
16/16 [==============================] - 0s 785us/step - loss: 2.1708

Testing for epoch 35 index 5:
79/79 [==============================] - 0s 585us/step
16/16 [==============================] - 0s 861us/step - loss: 0.1426
16/16 [==============================] - 0s 1ms/step - loss: 1.8107
16/16 [==============================] - 0s 762us/step - loss: 2.1481
16/16 [==============================] - 0s 757us/step - loss: 2.2402
16/16 [==============================] - 0s 771us/step - loss: 2.2636
16/16 [==============================] - 0s 772us/step - loss: 2.2406
16/16 [==============================] - 0s 768us/step - loss: 2.2119
16/16 [==============================] - 0s 766us/step - loss: 2.1997
16/16 [==============================] - 0s 765us/step - loss: 2.1956
16/16 [==============================] - 0s 771us/step - loss: 2.1955
Epoch 36 of 60

Testing for epoch 36 index 1:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 782us/step - loss: 0.1440
16/16 [==============================] - 0s 780us/step - loss: 1.8571
16/16 [==============================] - 0s 775us/step - loss: 2.2097
16/16 [==============================] - 0s 779us/step - loss: 2.3070
16/16 [==============================] - 0s 776us/step - loss: 2.3319
16/16 [==============================] - 0s 788us/step - loss: 2.3098
16/16 [==============================] - 0s 1ms/step - loss: 2.2808
16/16 [==============================] - 0s 1ms/step - loss: 2.2685
16/16 [==============================] - 0s 800us/step - loss: 2.2645
16/16 [==============================] - 0s 891us/step - loss: 2.2644

Testing for epoch 36 index 2:
79/79 [==============================] - 0s 693us/step
16/16 [==============================] - 0s 833us/step - loss: 0.1417
16/16 [==============================] - 0s 814us/step - loss: 1.8655
16/16 [==============================] - 0s 906us/step - loss: 2.2205
16/16 [==============================] - 0s 829us/step - loss: 2.3178
16/16 [==============================] - 0s 872us/step - loss: 2.3425
16/16 [==============================] - 0s 864us/step - loss: 2.3198
16/16 [==============================] - 0s 792us/step - loss: 2.2908
16/16 [==============================] - 0s 803us/step - loss: 2.2784
16/16 [==============================] - 0s 796us/step - loss: 2.2743
16/16 [==============================] - 0s 821us/step - loss: 2.2743

Testing for epoch 36 index 3:
79/79 [==============================] - 0s 620us/step
16/16 [==============================] - 0s 820us/step - loss: 0.1445
16/16 [==============================] - 0s 830us/step - loss: 1.8152
16/16 [==============================] - 0s 800us/step - loss: 2.1608
16/16 [==============================] - 0s 826us/step - loss: 2.2564
16/16 [==============================] - 0s 814us/step - loss: 2.2806
16/16 [==============================] - 0s 806us/step - loss: 2.2592
16/16 [==============================] - 0s 792us/step - loss: 2.2315
16/16 [==============================] - 0s 823us/step - loss: 2.2197
16/16 [==============================] - 0s 819us/step - loss: 2.2156
16/16 [==============================] - 0s 807us/step - loss: 2.2155

Testing for epoch 36 index 4:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1423
16/16 [==============================] - 0s 803us/step - loss: 1.8472
16/16 [==============================] - 0s 782us/step - loss: 2.1950
16/16 [==============================] - 0s 816us/step - loss: 2.2881
16/16 [==============================] - 0s 794us/step - loss: 2.3102
16/16 [==============================] - 0s 786us/step - loss: 2.2857
16/16 [==============================] - 0s 786us/step - loss: 2.2565
16/16 [==============================] - 0s 794us/step - loss: 2.2442
16/16 [==============================] - 0s 788us/step - loss: 2.2402
16/16 [==============================] - 0s 792us/step - loss: 2.2401

Testing for epoch 36 index 5:
79/79 [==============================] - 0s 659us/step
16/16 [==============================] - 0s 872us/step - loss: 0.1383
16/16 [==============================] - 0s 805us/step - loss: 1.8481
16/16 [==============================] - 0s 806us/step - loss: 2.2002
16/16 [==============================] - 0s 807us/step - loss: 2.2955
16/16 [==============================] - 0s 810us/step - loss: 2.3191
16/16 [==============================] - 0s 818us/step - loss: 2.2953
16/16 [==============================] - 0s 846us/step - loss: 2.2663
16/16 [==============================] - 0s 817us/step - loss: 2.2540
16/16 [==============================] - 0s 842us/step - loss: 2.2498
16/16 [==============================] - 0s 808us/step - loss: 2.2496
Epoch 37 of 60

Testing for epoch 37 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1396
16/16 [==============================] - 0s 800us/step - loss: 1.8411
16/16 [==============================] - 0s 794us/step - loss: 2.1902
16/16 [==============================] - 0s 789us/step - loss: 2.2840
16/16 [==============================] - 0s 805us/step - loss: 2.3066
16/16 [==============================] - 0s 794us/step - loss: 2.2821
16/16 [==============================] - 0s 787us/step - loss: 2.2532
16/16 [==============================] - 0s 790us/step - loss: 2.2411
16/16 [==============================] - 0s 814us/step - loss: 2.2372
16/16 [==============================] - 0s 796us/step - loss: 2.2371

Testing for epoch 37 index 2:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1395
16/16 [==============================] - 0s 832us/step - loss: 1.8573
16/16 [==============================] - 0s 835us/step - loss: 2.2095
16/16 [==============================] - 0s 826us/step - loss: 2.3029
16/16 [==============================] - 0s 804us/step - loss: 2.3241
16/16 [==============================] - 0s 805us/step - loss: 2.2983
16/16 [==============================] - 0s 796us/step - loss: 2.2682
16/16 [==============================] - 0s 807us/step - loss: 2.2556
16/16 [==============================] - 0s 1ms/step - loss: 2.2513
16/16 [==============================] - 0s 1ms/step - loss: 2.2511

Testing for epoch 37 index 3:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1401
16/16 [==============================] - 0s 796us/step - loss: 1.8239
16/16 [==============================] - 0s 798us/step - loss: 2.1752
16/16 [==============================] - 0s 804us/step - loss: 2.2721
16/16 [==============================] - 0s 838us/step - loss: 2.2980
16/16 [==============================] - 0s 841us/step - loss: 2.2774
16/16 [==============================] - 0s 820us/step - loss: 2.2510
16/16 [==============================] - 0s 694us/step - loss: 2.2395
16/16 [==============================] - 0s 737us/step - loss: 2.2355
16/16 [==============================] - 0s 689us/step - loss: 2.2353

Testing for epoch 37 index 4:
79/79 [==============================] - 0s 668us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1385
16/16 [==============================] - 0s 2ms/step - loss: 1.8566
16/16 [==============================] - 0s 2ms/step - loss: 2.2037
16/16 [==============================] - 0s 2ms/step - loss: 2.2918
16/16 [==============================] - 0s 2ms/step - loss: 2.3097
16/16 [==============================] - 0s 844us/step - loss: 2.2792
16/16 [==============================] - 0s 855us/step - loss: 2.2463
16/16 [==============================] - 0s 2ms/step - loss: 2.2331
16/16 [==============================] - 0s 2ms/step - loss: 2.2290
16/16 [==============================] - 0s 769us/step - loss: 2.2290

Testing for epoch 37 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 876us/step - loss: 0.1371
16/16 [==============================] - 0s 2ms/step - loss: 1.8841
16/16 [==============================] - 0s 781us/step - loss: 2.2415
16/16 [==============================] - 0s 754us/step - loss: 2.3349
16/16 [==============================] - 0s 831us/step - loss: 2.3552
16/16 [==============================] - 0s 788us/step - loss: 2.3269
16/16 [==============================] - 0s 832us/step - loss: 2.2956
16/16 [==============================] - 0s 797us/step - loss: 2.2825
16/16 [==============================] - 0s 2ms/step - loss: 2.2780
16/16 [==============================] - 0s 2ms/step - loss: 2.2778
Epoch 38 of 60

Testing for epoch 38 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1392
16/16 [==============================] - 0s 846us/step - loss: 1.9016
16/16 [==============================] - 0s 2ms/step - loss: 2.2615
16/16 [==============================] - 0s 2ms/step - loss: 2.3548
16/16 [==============================] - 0s 2ms/step - loss: 2.3744
16/16 [==============================] - 0s 783us/step - loss: 2.3445
16/16 [==============================] - 0s 1ms/step - loss: 2.3121
16/16 [==============================] - 0s 2ms/step - loss: 2.2989
16/16 [==============================] - 0s 2ms/step - loss: 2.2947
16/16 [==============================] - 0s 1ms/step - loss: 2.2946

Testing for epoch 38 index 2:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 804us/step - loss: 0.1370
16/16 [==============================] - 0s 2ms/step - loss: 1.8808
16/16 [==============================] - 0s 2ms/step - loss: 2.2309
16/16 [==============================] - 0s 803us/step - loss: 2.3252
16/16 [==============================] - 0s 2ms/step - loss: 2.3458
16/16 [==============================] - 0s 2ms/step - loss: 2.3187
16/16 [==============================] - 0s 2ms/step - loss: 2.2874
16/16 [==============================] - 0s 840us/step - loss: 2.2746
16/16 [==============================] - 0s 2ms/step - loss: 2.2703
16/16 [==============================] - 0s 805us/step - loss: 2.2702

Testing for epoch 38 index 3:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1335
16/16 [==============================] - 0s 2ms/step - loss: 1.9326
16/16 [==============================] - 0s 2ms/step - loss: 2.2893
16/16 [==============================] - 0s 804us/step - loss: 2.3820
16/16 [==============================] - 0s 2ms/step - loss: 2.3984
16/16 [==============================] - 0s 817us/step - loss: 2.3647
16/16 [==============================] - 0s 2ms/step - loss: 2.3292
16/16 [==============================] - 0s 2ms/step - loss: 2.3153
16/16 [==============================] - 0s 883us/step - loss: 2.3110
16/16 [==============================] - 0s 2ms/step - loss: 2.3111

Testing for epoch 38 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 849us/step - loss: 0.1333
16/16 [==============================] - 0s 805us/step - loss: 1.9265
16/16 [==============================] - 0s 793us/step - loss: 2.2845
16/16 [==============================] - 0s 815us/step - loss: 2.3802
16/16 [==============================] - 0s 808us/step - loss: 2.3993
16/16 [==============================] - 0s 818us/step - loss: 2.3696
16/16 [==============================] - 0s 2ms/step - loss: 2.3358
16/16 [==============================] - 0s 800us/step - loss: 2.3221
16/16 [==============================] - 0s 792us/step - loss: 2.3175
16/16 [==============================] - 0s 2ms/step - loss: 2.3173

Testing for epoch 38 index 5:
79/79 [==============================] - 0s 759us/step
16/16 [==============================] - 0s 844us/step - loss: 0.1361
16/16 [==============================] - 0s 833us/step - loss: 1.9262
16/16 [==============================] - 0s 799us/step - loss: 2.2858
16/16 [==============================] - 0s 2ms/step - loss: 2.3821
16/16 [==============================] - 0s 814us/step - loss: 2.4018
16/16 [==============================] - 0s 2ms/step - loss: 2.3724
16/16 [==============================] - 0s 2ms/step - loss: 2.3391
16/16 [==============================] - 0s 833us/step - loss: 2.3258
16/16 [==============================] - 0s 814us/step - loss: 2.3215
16/16 [==============================] - 0s 823us/step - loss: 2.3214
Epoch 39 of 60

Testing for epoch 39 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 833us/step - loss: 0.1330
16/16 [==============================] - 0s 1ms/step - loss: 1.8945
16/16 [==============================] - 0s 2ms/step - loss: 2.2436
16/16 [==============================] - 0s 1ms/step - loss: 2.3363
16/16 [==============================] - 0s 911us/step - loss: 2.3546
16/16 [==============================] - 0s 808us/step - loss: 2.3242
16/16 [==============================] - 0s 2ms/step - loss: 2.2909
16/16 [==============================] - 0s 2ms/step - loss: 2.2776
16/16 [==============================] - 0s 2ms/step - loss: 2.2733
16/16 [==============================] - 0s 791us/step - loss: 2.2731

Testing for epoch 39 index 2:
79/79 [==============================] - 0s 929us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1358
16/16 [==============================] - 0s 2ms/step - loss: 1.8447
16/16 [==============================] - 0s 832us/step - loss: 2.1816
16/16 [==============================] - 0s 795us/step - loss: 2.2687
16/16 [==============================] - 0s 807us/step - loss: 2.2848
16/16 [==============================] - 0s 2ms/step - loss: 2.2549
16/16 [==============================] - 0s 1ms/step - loss: 2.2232
16/16 [==============================] - 0s 919us/step - loss: 2.2103
16/16 [==============================] - 0s 2ms/step - loss: 2.2061
16/16 [==============================] - 0s 787us/step - loss: 2.2059

Testing for epoch 39 index 3:
79/79 [==============================] - 0s 533us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1353
16/16 [==============================] - 0s 1ms/step - loss: 1.9032
16/16 [==============================] - 0s 2ms/step - loss: 2.2511
16/16 [==============================] - 0s 2ms/step - loss: 2.3409
16/16 [==============================] - 0s 780us/step - loss: 2.3580
16/16 [==============================] - 0s 891us/step - loss: 2.3288
16/16 [==============================] - 0s 863us/step - loss: 2.2962
16/16 [==============================] - 0s 876us/step - loss: 2.2830
16/16 [==============================] - 0s 1ms/step - loss: 2.2787
16/16 [==============================] - 0s 937us/step - loss: 2.2786

Testing for epoch 39 index 4:
79/79 [==============================] - 0s 781us/step
16/16 [==============================] - 0s 835us/step - loss: 0.1367
16/16 [==============================] - 0s 2ms/step - loss: 1.9084
16/16 [==============================] - 0s 990us/step - loss: 2.2575
16/16 [==============================] - 0s 814us/step - loss: 2.3489
16/16 [==============================] - 0s 777us/step - loss: 2.3668
16/16 [==============================] - 0s 782us/step - loss: 2.3375
16/16 [==============================] - 0s 714us/step - loss: 2.3043
16/16 [==============================] - 0s 1ms/step - loss: 2.2911
16/16 [==============================] - 0s 649us/step - loss: 2.2868
16/16 [==============================] - 0s 790us/step - loss: 2.2867

Testing for epoch 39 index 5:
79/79 [==============================] - 0s 661us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1330
16/16 [==============================] - 0s 780us/step - loss: 1.9413
16/16 [==============================] - 0s 778us/step - loss: 2.3006
16/16 [==============================] - 0s 786us/step - loss: 2.3940
16/16 [==============================] - 0s 804us/step - loss: 2.4106
16/16 [==============================] - 0s 791us/step - loss: 2.3794
16/16 [==============================] - 0s 780us/step - loss: 2.3453
16/16 [==============================] - 0s 779us/step - loss: 2.3317
16/16 [==============================] - 0s 815us/step - loss: 2.3272
16/16 [==============================] - 0s 790us/step - loss: 2.3271
Epoch 40 of 60

Testing for epoch 40 index 1:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1342
16/16 [==============================] - 0s 1ms/step - loss: 1.9180
16/16 [==============================] - 0s 1ms/step - loss: 2.2724
16/16 [==============================] - 0s 1ms/step - loss: 2.3660
16/16 [==============================] - 0s 1ms/step - loss: 2.3839
16/16 [==============================] - 0s 781us/step - loss: 2.3552
16/16 [==============================] - 0s 1ms/step - loss: 2.3228
16/16 [==============================] - 0s 788us/step - loss: 2.3097
16/16 [==============================] - 0s 800us/step - loss: 2.3054
16/16 [==============================] - 0s 800us/step - loss: 2.3052

Testing for epoch 40 index 2:
79/79 [==============================] - 0s 583us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1336
16/16 [==============================] - 0s 806us/step - loss: 1.8845
16/16 [==============================] - 0s 785us/step - loss: 2.2270
16/16 [==============================] - 0s 789us/step - loss: 2.3128
16/16 [==============================] - 0s 803us/step - loss: 2.3252
16/16 [==============================] - 0s 807us/step - loss: 2.2901
16/16 [==============================] - 0s 789us/step - loss: 2.2552
16/16 [==============================] - 0s 803us/step - loss: 2.2418
16/16 [==============================] - 0s 903us/step - loss: 2.2374
16/16 [==============================] - 0s 860us/step - loss: 2.2373

Testing for epoch 40 index 3:
79/79 [==============================] - 0s 587us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1321
16/16 [==============================] - 0s 817us/step - loss: 1.9400
16/16 [==============================] - 0s 819us/step - loss: 2.2933
16/16 [==============================] - 0s 825us/step - loss: 2.3799
16/16 [==============================] - 0s 819us/step - loss: 2.3924
16/16 [==============================] - 0s 885us/step - loss: 2.3564
16/16 [==============================] - 0s 882us/step - loss: 2.3207
16/16 [==============================] - 0s 823us/step - loss: 2.3070
16/16 [==============================] - 0s 865us/step - loss: 2.3027
16/16 [==============================] - 0s 803us/step - loss: 2.3027

Testing for epoch 40 index 4:
79/79 [==============================] - 0s 669us/step
16/16 [==============================] - 0s 815us/step - loss: 0.1334
16/16 [==============================] - 0s 833us/step - loss: 1.9022
16/16 [==============================] - 0s 806us/step - loss: 2.2463
16/16 [==============================] - 0s 796us/step - loss: 2.3297
16/16 [==============================] - 0s 790us/step - loss: 2.3413
16/16 [==============================] - 0s 790us/step - loss: 2.3067
16/16 [==============================] - 0s 791us/step - loss: 2.2727
16/16 [==============================] - 0s 828us/step - loss: 2.2595
16/16 [==============================] - 0s 819us/step - loss: 2.2552
16/16 [==============================] - 0s 798us/step - loss: 2.2550

Testing for epoch 40 index 5:
79/79 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 790us/step - loss: 0.1269
16/16 [==============================] - 0s 804us/step - loss: 1.9772
16/16 [==============================] - 0s 796us/step - loss: 2.3427
16/16 [==============================] - 0s 779us/step - loss: 2.4319
16/16 [==============================] - 0s 792us/step - loss: 2.4454
16/16 [==============================] - 0s 806us/step - loss: 2.4078
16/16 [==============================] - 0s 804us/step - loss: 2.3714
16/16 [==============================] - 0s 817us/step - loss: 2.3572
16/16 [==============================] - 0s 854us/step - loss: 2.3526
16/16 [==============================] - 0s 889us/step - loss: 2.3524
Epoch 41 of 60

Testing for epoch 41 index 1:
79/79 [==============================] - 0s 862us/step
16/16 [==============================] - 0s 846us/step - loss: 0.1301
16/16 [==============================] - 0s 833us/step - loss: 1.9242
16/16 [==============================] - 0s 1ms/step - loss: 2.2728
16/16 [==============================] - 0s 814us/step - loss: 2.3565
16/16 [==============================] - 0s 834us/step - loss: 2.3696
16/16 [==============================] - 0s 832us/step - loss: 2.3336
16/16 [==============================] - 0s 849us/step - loss: 2.2979
16/16 [==============================] - 0s 895us/step - loss: 2.2839
16/16 [==============================] - 0s 835us/step - loss: 2.2793
16/16 [==============================] - 0s 842us/step - loss: 2.2791

Testing for epoch 41 index 2:
79/79 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 832us/step - loss: 0.1314
16/16 [==============================] - 0s 845us/step - loss: 1.9663
16/16 [==============================] - 0s 874us/step - loss: 2.3249
16/16 [==============================] - 0s 816us/step - loss: 2.4099
16/16 [==============================] - 0s 824us/step - loss: 2.4224
16/16 [==============================] - 0s 826us/step - loss: 2.3848
16/16 [==============================] - 0s 849us/step - loss: 2.3482
16/16 [==============================] - 0s 800us/step - loss: 2.3341
16/16 [==============================] - 0s 856us/step - loss: 2.3296
16/16 [==============================] - 0s 797us/step - loss: 2.3295

Testing for epoch 41 index 3:
79/79 [==============================] - 0s 719us/step
16/16 [==============================] - 0s 843us/step - loss: 0.1290
16/16 [==============================] - 0s 858us/step - loss: 2.0148
16/16 [==============================] - 0s 784us/step - loss: 2.3873
16/16 [==============================] - 0s 856us/step - loss: 2.4746
16/16 [==============================] - 0s 835us/step - loss: 2.4879
16/16 [==============================] - 0s 810us/step - loss: 2.4474
16/16 [==============================] - 0s 865us/step - loss: 2.4088
16/16 [==============================] - 0s 884us/step - loss: 2.3940
16/16 [==============================] - 0s 869us/step - loss: 2.3894
16/16 [==============================] - 0s 785us/step - loss: 2.3893

Testing for epoch 41 index 4:
79/79 [==============================] - 0s 618us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1312
16/16 [==============================] - 0s 807us/step - loss: 1.9137
16/16 [==============================] - 0s 1ms/step - loss: 2.2591
16/16 [==============================] - 0s 798us/step - loss: 2.3380
16/16 [==============================] - 0s 1ms/step - loss: 2.3479
16/16 [==============================] - 0s 1ms/step - loss: 2.3084
16/16 [==============================] - 0s 830us/step - loss: 2.2720
16/16 [==============================] - 0s 788us/step - loss: 2.2582
16/16 [==============================] - 0s 795us/step - loss: 2.2539
16/16 [==============================] - 0s 855us/step - loss: 2.2538

Testing for epoch 41 index 5:
79/79 [==============================] - 0s 616us/step
16/16 [==============================] - 0s 857us/step - loss: 0.1289
16/16 [==============================] - 0s 817us/step - loss: 1.9509
16/16 [==============================] - 0s 905us/step - loss: 2.3031
16/16 [==============================] - 0s 799us/step - loss: 2.3834
16/16 [==============================] - 0s 915us/step - loss: 2.3938
16/16 [==============================] - 0s 1ms/step - loss: 2.3538
16/16 [==============================] - 0s 911us/step - loss: 2.3167
16/16 [==============================] - 0s 934us/step - loss: 2.3026
16/16 [==============================] - 0s 891us/step - loss: 2.2981
16/16 [==============================] - 0s 866us/step - loss: 2.2980
Epoch 42 of 60

Testing for epoch 42 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1312
16/16 [==============================] - 0s 3ms/step - loss: 1.9436
16/16 [==============================] - 0s 1ms/step - loss: 2.2942
16/16 [==============================] - 0s 1ms/step - loss: 2.3728
16/16 [==============================] - 0s 801us/step - loss: 2.3809
16/16 [==============================] - 0s 1ms/step - loss: 2.3390
16/16 [==============================] - 0s 881us/step - loss: 2.3013
16/16 [==============================] - 0s 818us/step - loss: 2.2872
16/16 [==============================] - 0s 807us/step - loss: 2.2829
16/16 [==============================] - 0s 794us/step - loss: 2.2830

Testing for epoch 42 index 2:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 830us/step - loss: 0.1277
16/16 [==============================] - 0s 825us/step - loss: 1.9867
16/16 [==============================] - 0s 818us/step - loss: 2.3500
16/16 [==============================] - 0s 797us/step - loss: 2.4348
16/16 [==============================] - 0s 795us/step - loss: 2.4465
16/16 [==============================] - 0s 798us/step - loss: 2.4073
16/16 [==============================] - 0s 790us/step - loss: 2.3709
16/16 [==============================] - 0s 803us/step - loss: 2.3569
16/16 [==============================] - 0s 799us/step - loss: 2.3525
16/16 [==============================] - 0s 796us/step - loss: 2.3524

Testing for epoch 42 index 3:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1334
16/16 [==============================] - 0s 821us/step - loss: 1.9570
16/16 [==============================] - 0s 806us/step - loss: 2.3121
16/16 [==============================] - 0s 808us/step - loss: 2.3937
16/16 [==============================] - 0s 805us/step - loss: 2.4031
16/16 [==============================] - 0s 824us/step - loss: 2.3619
16/16 [==============================] - 0s 808us/step - loss: 2.3245
16/16 [==============================] - 0s 827us/step - loss: 2.3104
16/16 [==============================] - 0s 827us/step - loss: 2.3060
16/16 [==============================] - 0s 813us/step - loss: 2.3059

Testing for epoch 42 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1268
16/16 [==============================] - 0s 794us/step - loss: 1.9501
16/16 [==============================] - 0s 868us/step - loss: 2.3015
16/16 [==============================] - 0s 822us/step - loss: 2.3798
16/16 [==============================] - 0s 828us/step - loss: 2.3880
16/16 [==============================] - 0s 789us/step - loss: 2.3466
16/16 [==============================] - 0s 802us/step - loss: 2.3094
16/16 [==============================] - 0s 821us/step - loss: 2.2953
16/16 [==============================] - 0s 815us/step - loss: 2.2908
16/16 [==============================] - 0s 839us/step - loss: 2.2906

Testing for epoch 42 index 5:
79/79 [==============================] - 0s 730us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1280
16/16 [==============================] - 0s 1ms/step - loss: 1.9975
16/16 [==============================] - 0s 805us/step - loss: 2.3589
16/16 [==============================] - 0s 798us/step - loss: 2.4382
16/16 [==============================] - 0s 829us/step - loss: 2.4454
16/16 [==============================] - 0s 821us/step - loss: 2.4015
16/16 [==============================] - 0s 797us/step - loss: 2.3619
16/16 [==============================] - 0s 1ms/step - loss: 2.3472
16/16 [==============================] - 0s 815us/step - loss: 2.3427
16/16 [==============================] - 0s 813us/step - loss: 2.3427
Epoch 43 of 60

Testing for epoch 43 index 1:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1275
16/16 [==============================] - 0s 1ms/step - loss: 2.0014
16/16 [==============================] - 0s 773us/step - loss: 2.3669
16/16 [==============================] - 0s 771us/step - loss: 2.4493
16/16 [==============================] - 0s 1ms/step - loss: 2.4593
16/16 [==============================] - 0s 1ms/step - loss: 2.4179
16/16 [==============================] - 0s 1ms/step - loss: 2.3796
16/16 [==============================] - 0s 1ms/step - loss: 2.3652
16/16 [==============================] - 0s 1ms/step - loss: 2.3606
16/16 [==============================] - 0s 787us/step - loss: 2.3604

Testing for epoch 43 index 2:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1274
16/16 [==============================] - 0s 800us/step - loss: 1.9885
16/16 [==============================] - 0s 800us/step - loss: 2.3486
16/16 [==============================] - 0s 793us/step - loss: 2.4281
16/16 [==============================] - 0s 810us/step - loss: 2.4365
16/16 [==============================] - 0s 805us/step - loss: 2.3939
16/16 [==============================] - 0s 806us/step - loss: 2.3558
16/16 [==============================] - 0s 830us/step - loss: 2.3415
16/16 [==============================] - 0s 830us/step - loss: 2.3370
16/16 [==============================] - 0s 812us/step - loss: 2.3370

Testing for epoch 43 index 3:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 810us/step - loss: 0.1306
16/16 [==============================] - 0s 811us/step - loss: 1.9621
16/16 [==============================] - 0s 817us/step - loss: 2.3132
16/16 [==============================] - 0s 805us/step - loss: 2.3880
16/16 [==============================] - 0s 784us/step - loss: 2.3952
16/16 [==============================] - 0s 820us/step - loss: 2.3532
16/16 [==============================] - 0s 793us/step - loss: 2.3157
16/16 [==============================] - 0s 778us/step - loss: 2.3018
16/16 [==============================] - 0s 786us/step - loss: 2.2976
16/16 [==============================] - 0s 785us/step - loss: 2.2976

Testing for epoch 43 index 4:
79/79 [==============================] - 0s 636us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1253
16/16 [==============================] - 0s 825us/step - loss: 2.0501
16/16 [==============================] - 0s 816us/step - loss: 2.4197
16/16 [==============================] - 0s 851us/step - loss: 2.4972
16/16 [==============================] - 0s 822us/step - loss: 2.5028
16/16 [==============================] - 0s 876us/step - loss: 2.4551
16/16 [==============================] - 0s 910us/step - loss: 2.4127
16/16 [==============================] - 0s 879us/step - loss: 2.3973
16/16 [==============================] - 0s 871us/step - loss: 2.3927
16/16 [==============================] - 0s 818us/step - loss: 2.3928

Testing for epoch 43 index 5:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 828us/step - loss: 0.1265
16/16 [==============================] - 0s 801us/step - loss: 2.0007
16/16 [==============================] - 0s 796us/step - loss: 2.3614
16/16 [==============================] - 0s 798us/step - loss: 2.4380
16/16 [==============================] - 0s 812us/step - loss: 2.4449
16/16 [==============================] - 0s 809us/step - loss: 2.4011
16/16 [==============================] - 0s 821us/step - loss: 2.3625
16/16 [==============================] - 0s 811us/step - loss: 2.3483
16/16 [==============================] - 0s 815us/step - loss: 2.3439
16/16 [==============================] - 0s 808us/step - loss: 2.3438
Epoch 44 of 60

Testing for epoch 44 index 1:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1299
16/16 [==============================] - 0s 803us/step - loss: 1.9974
16/16 [==============================] - 0s 782us/step - loss: 2.3529
16/16 [==============================] - 0s 792us/step - loss: 2.4269
16/16 [==============================] - 0s 795us/step - loss: 2.4322
16/16 [==============================] - 0s 797us/step - loss: 2.3865
16/16 [==============================] - 0s 805us/step - loss: 2.3467
16/16 [==============================] - 0s 805us/step - loss: 2.3323
16/16 [==============================] - 0s 795us/step - loss: 2.3279
16/16 [==============================] - 0s 793us/step - loss: 2.3279

Testing for epoch 44 index 2:
79/79 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1263
16/16 [==============================] - 0s 809us/step - loss: 2.0233
16/16 [==============================] - 0s 809us/step - loss: 2.3927
16/16 [==============================] - 0s 835us/step - loss: 2.4734
16/16 [==============================] - 0s 809us/step - loss: 2.4828
16/16 [==============================] - 0s 835us/step - loss: 2.4407
16/16 [==============================] - 0s 810us/step - loss: 2.4019
16/16 [==============================] - 0s 906us/step - loss: 2.3872
16/16 [==============================] - 0s 824us/step - loss: 2.3824
16/16 [==============================] - 0s 789us/step - loss: 2.3822

Testing for epoch 44 index 3:
79/79 [==============================] - 0s 595us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1234
16/16 [==============================] - 0s 929us/step - loss: 2.0523
16/16 [==============================] - 0s 784us/step - loss: 2.4219
16/16 [==============================] - 0s 829us/step - loss: 2.4981
16/16 [==============================] - 0s 831us/step - loss: 2.5027
16/16 [==============================] - 0s 805us/step - loss: 2.4546
16/16 [==============================] - 0s 1ms/step - loss: 2.4132
16/16 [==============================] - 0s 1ms/step - loss: 2.3981
16/16 [==============================] - 0s 1ms/step - loss: 2.3935
16/16 [==============================] - 0s 1ms/step - loss: 2.3934

Testing for epoch 44 index 4:
79/79 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1256
16/16 [==============================] - 0s 787us/step - loss: 1.9662
16/16 [==============================] - 0s 788us/step - loss: 2.3195
16/16 [==============================] - 0s 787us/step - loss: 2.3944
16/16 [==============================] - 0s 790us/step - loss: 2.4012
16/16 [==============================] - 0s 790us/step - loss: 2.3588
16/16 [==============================] - 0s 795us/step - loss: 2.3210
16/16 [==============================] - 0s 790us/step - loss: 2.3069
16/16 [==============================] - 0s 788us/step - loss: 2.3024
16/16 [==============================] - 0s 801us/step - loss: 2.3022

Testing for epoch 44 index 5:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1243
16/16 [==============================] - 0s 807us/step - loss: 2.0090
16/16 [==============================] - 0s 838us/step - loss: 2.3705
16/16 [==============================] - 0s 823us/step - loss: 2.4464
16/16 [==============================] - 0s 817us/step - loss: 2.4520
16/16 [==============================] - 0s 803us/step - loss: 2.4062
16/16 [==============================] - 0s 809us/step - loss: 2.3657
16/16 [==============================] - 0s 829us/step - loss: 2.3510
16/16 [==============================] - 0s 824us/step - loss: 2.3466
16/16 [==============================] - 0s 796us/step - loss: 2.3466
Epoch 45 of 60

Testing for epoch 45 index 1:
79/79 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1223
16/16 [==============================] - 0s 1ms/step - loss: 2.0306
16/16 [==============================] - 0s 1ms/step - loss: 2.3982
16/16 [==============================] - 0s 1ms/step - loss: 2.4740
16/16 [==============================] - 0s 806us/step - loss: 2.4773
16/16 [==============================] - 0s 825us/step - loss: 2.4287
16/16 [==============================] - 0s 821us/step - loss: 2.3869
16/16 [==============================] - 0s 791us/step - loss: 2.3718
16/16 [==============================] - 0s 1ms/step - loss: 2.3672
16/16 [==============================] - 0s 791us/step - loss: 2.3671

Testing for epoch 45 index 2:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1210
16/16 [==============================] - 0s 791us/step - loss: 2.0704
16/16 [==============================] - 0s 1ms/step - loss: 2.4462
16/16 [==============================] - 0s 1ms/step - loss: 2.5242
16/16 [==============================] - 0s 1ms/step - loss: 2.5296
16/16 [==============================] - 0s 1ms/step - loss: 2.4812
16/16 [==============================] - 0s 1ms/step - loss: 2.4387
16/16 [==============================] - 0s 1ms/step - loss: 2.4232
16/16 [==============================] - 0s 1ms/step - loss: 2.4184
16/16 [==============================] - 0s 786us/step - loss: 2.4183

Testing for epoch 45 index 3:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1213
16/16 [==============================] - 0s 1ms/step - loss: 2.0630
16/16 [==============================] - 0s 1ms/step - loss: 2.4339
16/16 [==============================] - 0s 791us/step - loss: 2.5090
16/16 [==============================] - 0s 1ms/step - loss: 2.5119
16/16 [==============================] - 0s 1ms/step - loss: 2.4617
16/16 [==============================] - 0s 796us/step - loss: 2.4184
16/16 [==============================] - 0s 790us/step - loss: 2.4027
16/16 [==============================] - 0s 787us/step - loss: 2.3979
16/16 [==============================] - 0s 1ms/step - loss: 2.3979

Testing for epoch 45 index 4:
79/79 [==============================] - 0s 840us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1207
16/16 [==============================] - 0s 1ms/step - loss: 2.0925
16/16 [==============================] - 0s 916us/step - loss: 2.4711
16/16 [==============================] - 0s 783us/step - loss: 2.5501
16/16 [==============================] - 0s 783us/step - loss: 2.5549
16/16 [==============================] - 0s 826us/step - loss: 2.5060
16/16 [==============================] - 0s 813us/step - loss: 2.4629
16/16 [==============================] - 0s 857us/step - loss: 2.4472
16/16 [==============================] - 0s 1ms/step - loss: 2.4425
16/16 [==============================] - 0s 1ms/step - loss: 2.4424

Testing for epoch 45 index 5:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 797us/step - loss: 0.1209
16/16 [==============================] - 0s 794us/step - loss: 2.0450
16/16 [==============================] - 0s 781us/step - loss: 2.4120
16/16 [==============================] - 0s 811us/step - loss: 2.4853
16/16 [==============================] - 0s 1ms/step - loss: 2.4875
16/16 [==============================] - 0s 1ms/step - loss: 2.4384
16/16 [==============================] - 0s 1ms/step - loss: 2.3963
16/16 [==============================] - 0s 1ms/step - loss: 2.3811
16/16 [==============================] - 0s 807us/step - loss: 2.3765
16/16 [==============================] - 0s 797us/step - loss: 2.3764
Epoch 46 of 60

Testing for epoch 46 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1157
16/16 [==============================] - 0s 803us/step - loss: 2.0892
16/16 [==============================] - 0s 783us/step - loss: 2.4688
16/16 [==============================] - 0s 779us/step - loss: 2.5448
16/16 [==============================] - 0s 790us/step - loss: 2.5463
16/16 [==============================] - 0s 791us/step - loss: 2.4953
16/16 [==============================] - 0s 788us/step - loss: 2.4526
16/16 [==============================] - 0s 786us/step - loss: 2.4370
16/16 [==============================] - 0s 788us/step - loss: 2.4322
16/16 [==============================] - 0s 792us/step - loss: 2.4321

Testing for epoch 46 index 2:
79/79 [==============================] - 0s 599us/step
16/16 [==============================] - 0s 784us/step - loss: 0.1203
16/16 [==============================] - 0s 786us/step - loss: 2.0153
16/16 [==============================] - 0s 774us/step - loss: 2.3790
16/16 [==============================] - 0s 782us/step - loss: 2.4528
16/16 [==============================] - 0s 786us/step - loss: 2.4549
16/16 [==============================] - 0s 791us/step - loss: 2.4069
16/16 [==============================] - 0s 776us/step - loss: 2.3664
16/16 [==============================] - 0s 778us/step - loss: 2.3517
16/16 [==============================] - 0s 772us/step - loss: 2.3471
16/16 [==============================] - 0s 782us/step - loss: 2.3469

Testing for epoch 46 index 3:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1176
16/16 [==============================] - 0s 784us/step - loss: 2.0705
16/16 [==============================] - 0s 780us/step - loss: 2.4423
16/16 [==============================] - 0s 778us/step - loss: 2.5156
16/16 [==============================] - 0s 787us/step - loss: 2.5160
16/16 [==============================] - 0s 775us/step - loss: 2.4639
16/16 [==============================] - 0s 780us/step - loss: 2.4200
16/16 [==============================] - 0s 783us/step - loss: 2.4040
16/16 [==============================] - 0s 779us/step - loss: 2.3992
16/16 [==============================] - 0s 780us/step - loss: 2.3991

Testing for epoch 46 index 4:
79/79 [==============================] - 0s 610us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1199
16/16 [==============================] - 0s 796us/step - loss: 2.0859
16/16 [==============================] - 0s 808us/step - loss: 2.4654
16/16 [==============================] - 0s 790us/step - loss: 2.5423
16/16 [==============================] - 0s 787us/step - loss: 2.5441
16/16 [==============================] - 0s 1ms/step - loss: 2.4922
16/16 [==============================] - 0s 781us/step - loss: 2.4480
16/16 [==============================] - 0s 794us/step - loss: 2.4320
16/16 [==============================] - 0s 800us/step - loss: 2.4271
16/16 [==============================] - 0s 783us/step - loss: 2.4269

Testing for epoch 46 index 5:
79/79 [==============================] - 0s 594us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1187
16/16 [==============================] - 0s 794us/step - loss: 2.0720
16/16 [==============================] - 0s 787us/step - loss: 2.4514
16/16 [==============================] - 0s 784us/step - loss: 2.5300
16/16 [==============================] - 0s 806us/step - loss: 2.5335
16/16 [==============================] - 0s 798us/step - loss: 2.4858
16/16 [==============================] - 0s 802us/step - loss: 2.4440
16/16 [==============================] - 0s 798us/step - loss: 2.4288
16/16 [==============================] - 0s 794us/step - loss: 2.4241
16/16 [==============================] - 0s 794us/step - loss: 2.4240
Epoch 47 of 60

Testing for epoch 47 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1168
16/16 [==============================] - 0s 779us/step - loss: 2.0878
16/16 [==============================] - 0s 786us/step - loss: 2.4644
16/16 [==============================] - 0s 803us/step - loss: 2.5367
16/16 [==============================] - 0s 800us/step - loss: 2.5353
16/16 [==============================] - 0s 821us/step - loss: 2.4811
16/16 [==============================] - 0s 796us/step - loss: 2.4357
16/16 [==============================] - 0s 793us/step - loss: 2.4197
16/16 [==============================] - 0s 784us/step - loss: 2.4149
16/16 [==============================] - 0s 793us/step - loss: 2.4149

Testing for epoch 47 index 2:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 799us/step - loss: 0.1129
16/16 [==============================] - 0s 863us/step - loss: 2.1291
16/16 [==============================] - 0s 866us/step - loss: 2.5159
16/16 [==============================] - 0s 877us/step - loss: 2.5921
16/16 [==============================] - 0s 791us/step - loss: 2.5924
16/16 [==============================] - 0s 785us/step - loss: 2.5399
16/16 [==============================] - 0s 793us/step - loss: 2.4954
16/16 [==============================] - 0s 794us/step - loss: 2.4795
16/16 [==============================] - 0s 808us/step - loss: 2.4746
16/16 [==============================] - 0s 813us/step - loss: 2.4745

Testing for epoch 47 index 3:
79/79 [==============================] - 0s 591us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1157
16/16 [==============================] - 0s 801us/step - loss: 2.0875
16/16 [==============================] - 0s 797us/step - loss: 2.4622
16/16 [==============================] - 0s 793us/step - loss: 2.5350
16/16 [==============================] - 0s 793us/step - loss: 2.5349
16/16 [==============================] - 0s 802us/step - loss: 2.4821
16/16 [==============================] - 0s 803us/step - loss: 2.4374
16/16 [==============================] - 0s 803us/step - loss: 2.4214
16/16 [==============================] - 0s 790us/step - loss: 2.4166
16/16 [==============================] - 0s 784us/step - loss: 2.4165

Testing for epoch 47 index 4:
79/79 [==============================] - 0s 619us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1148
16/16 [==============================] - 0s 780us/step - loss: 2.1379
16/16 [==============================] - 0s 809us/step - loss: 2.5248
16/16 [==============================] - 0s 780us/step - loss: 2.5999
16/16 [==============================] - 0s 872us/step - loss: 2.5989
16/16 [==============================] - 0s 866us/step - loss: 2.5435
16/16 [==============================] - 0s 863us/step - loss: 2.4969
16/16 [==============================] - 0s 863us/step - loss: 2.4802
16/16 [==============================] - 0s 787us/step - loss: 2.4751
16/16 [==============================] - 0s 859us/step - loss: 2.4750

Testing for epoch 47 index 5:
79/79 [==============================] - 0s 580us/step
16/16 [==============================] - 0s 790us/step - loss: 0.1154
16/16 [==============================] - 0s 786us/step - loss: 2.0392
16/16 [==============================] - 0s 788us/step - loss: 2.4002
16/16 [==============================] - 0s 784us/step - loss: 2.4684
16/16 [==============================] - 0s 795us/step - loss: 2.4659
16/16 [==============================] - 0s 801us/step - loss: 2.4131
16/16 [==============================] - 0s 824us/step - loss: 2.3696
16/16 [==============================] - 0s 790us/step - loss: 2.3543
16/16 [==============================] - 0s 812us/step - loss: 2.3497
16/16 [==============================] - 0s 795us/step - loss: 2.3497
Epoch 48 of 60

Testing for epoch 48 index 1:
79/79 [==============================] - 0s 653us/step
16/16 [==============================] - 0s 876us/step - loss: 0.1150
16/16 [==============================] - 0s 864us/step - loss: 2.1081
16/16 [==============================] - 0s 861us/step - loss: 2.4903
16/16 [==============================] - 0s 856us/step - loss: 2.5626
16/16 [==============================] - 0s 862us/step - loss: 2.5596
16/16 [==============================] - 0s 865us/step - loss: 2.5044
16/16 [==============================] - 0s 865us/step - loss: 2.4593
16/16 [==============================] - 0s 870us/step - loss: 2.4434
16/16 [==============================] - 0s 875us/step - loss: 2.4386
16/16 [==============================] - 0s 808us/step - loss: 2.4386

Testing for epoch 48 index 2:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1147
16/16 [==============================] - 0s 781us/step - loss: 2.1044
16/16 [==============================] - 0s 779us/step - loss: 2.4888
16/16 [==============================] - 0s 782us/step - loss: 2.5643
16/16 [==============================] - 0s 825us/step - loss: 2.5644
16/16 [==============================] - 0s 801us/step - loss: 2.5118
16/16 [==============================] - 0s 819us/step - loss: 2.4675
16/16 [==============================] - 0s 796us/step - loss: 2.4516
16/16 [==============================] - 0s 786us/step - loss: 2.4465
16/16 [==============================] - 0s 779us/step - loss: 2.4463

Testing for epoch 48 index 3:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1152
16/16 [==============================] - 0s 774us/step - loss: 2.0719
16/16 [==============================] - 0s 786us/step - loss: 2.4408
16/16 [==============================] - 0s 809us/step - loss: 2.5109
16/16 [==============================] - 0s 793us/step - loss: 2.5086
16/16 [==============================] - 0s 795us/step - loss: 2.4552
16/16 [==============================] - 0s 811us/step - loss: 2.4115
16/16 [==============================] - 0s 797us/step - loss: 2.3960
16/16 [==============================] - 0s 824us/step - loss: 2.3913
16/16 [==============================] - 0s 818us/step - loss: 2.3912

Testing for epoch 48 index 4:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 802us/step - loss: 0.1107
16/16 [==============================] - 0s 795us/step - loss: 2.1577
16/16 [==============================] - 0s 857us/step - loss: 2.5481
16/16 [==============================] - 0s 813us/step - loss: 2.6204
16/16 [==============================] - 0s 797us/step - loss: 2.6165
16/16 [==============================] - 0s 790us/step - loss: 2.5579
16/16 [==============================] - 0s 782us/step - loss: 2.5097
16/16 [==============================] - 0s 804us/step - loss: 2.4927
16/16 [==============================] - 0s 779us/step - loss: 2.4877
16/16 [==============================] - 0s 782us/step - loss: 2.4876

Testing for epoch 48 index 5:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 829us/step - loss: 0.1159
16/16 [==============================] - 0s 803us/step - loss: 2.0767
16/16 [==============================] - 0s 810us/step - loss: 2.4525
16/16 [==============================] - 0s 781us/step - loss: 2.5232
16/16 [==============================] - 0s 796us/step - loss: 2.5203
16/16 [==============================] - 0s 810us/step - loss: 2.4657
16/16 [==============================] - 0s 782us/step - loss: 2.4213
16/16 [==============================] - 0s 814us/step - loss: 2.4055
16/16 [==============================] - 0s 805us/step - loss: 2.4008
16/16 [==============================] - 0s 781us/step - loss: 2.4008
Epoch 49 of 60

Testing for epoch 49 index 1:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1130
16/16 [==============================] - 0s 806us/step - loss: 2.1188
16/16 [==============================] - 0s 784us/step - loss: 2.5027
16/16 [==============================] - 0s 783us/step - loss: 2.5749
16/16 [==============================] - 0s 777us/step - loss: 2.5720
16/16 [==============================] - 0s 790us/step - loss: 2.5164
16/16 [==============================] - 0s 787us/step - loss: 2.4706
16/16 [==============================] - 0s 823us/step - loss: 2.4543
16/16 [==============================] - 0s 811us/step - loss: 2.4493
16/16 [==============================] - 0s 819us/step - loss: 2.4491

Testing for epoch 49 index 2:
79/79 [==============================] - 0s 589us/step
16/16 [==============================] - 0s 806us/step - loss: 0.1130
16/16 [==============================] - 0s 798us/step - loss: 2.1207
16/16 [==============================] - 0s 791us/step - loss: 2.5027
16/16 [==============================] - 0s 807us/step - loss: 2.5732
16/16 [==============================] - 0s 794us/step - loss: 2.5696
16/16 [==============================] - 0s 795us/step - loss: 2.5133
16/16 [==============================] - 0s 790us/step - loss: 2.4675
16/16 [==============================] - 0s 787us/step - loss: 2.4516
16/16 [==============================] - 0s 790us/step - loss: 2.4468
16/16 [==============================] - 0s 789us/step - loss: 2.4468

Testing for epoch 49 index 3:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1157
16/16 [==============================] - 0s 771us/step - loss: 2.1044
16/16 [==============================] - 0s 773us/step - loss: 2.4790
16/16 [==============================] - 0s 775us/step - loss: 2.5455
16/16 [==============================] - 0s 783us/step - loss: 2.5407
16/16 [==============================] - 0s 848us/step - loss: 2.4851
16/16 [==============================] - 0s 846us/step - loss: 2.4397
16/16 [==============================] - 0s 861us/step - loss: 2.4239
16/16 [==============================] - 0s 847us/step - loss: 2.4191
16/16 [==============================] - 0s 868us/step - loss: 2.4191

Testing for epoch 49 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1159
16/16 [==============================] - 0s 797us/step - loss: 2.1415
16/16 [==============================] - 0s 792us/step - loss: 2.5249
16/16 [==============================] - 0s 821us/step - loss: 2.5930
16/16 [==============================] - 0s 888us/step - loss: 2.5871
16/16 [==============================] - 0s 879us/step - loss: 2.5281
16/16 [==============================] - 0s 867us/step - loss: 2.4804
16/16 [==============================] - 0s 893us/step - loss: 2.4640
16/16 [==============================] - 0s 804us/step - loss: 2.4592
16/16 [==============================] - 0s 808us/step - loss: 2.4592

Testing for epoch 49 index 5:
79/79 [==============================] - 0s 590us/step
16/16 [==============================] - 0s 821us/step - loss: 0.1108
16/16 [==============================] - 0s 839us/step - loss: 2.1666
16/16 [==============================] - 0s 802us/step - loss: 2.5501
16/16 [==============================] - 0s 670us/step - loss: 2.6150
16/16 [==============================] - 0s 783us/step - loss: 2.6061
16/16 [==============================] - 0s 2ms/step - loss: 2.5432
16/16 [==============================] - 0s 748us/step - loss: 2.4931
16/16 [==============================] - 0s 2ms/step - loss: 2.4759
16/16 [==============================] - 0s 746us/step - loss: 2.4708
16/16 [==============================] - 0s 2ms/step - loss: 2.4707
Epoch 50 of 60

Testing for epoch 50 index 1:
79/79 [==============================] - 0s 834us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1092
16/16 [==============================] - 0s 2ms/step - loss: 2.1786
16/16 [==============================] - 0s 2ms/step - loss: 2.5691
16/16 [==============================] - 0s 783us/step - loss: 2.6374
16/16 [==============================] - 0s 1ms/step - loss: 2.6307
16/16 [==============================] - 0s 983us/step - loss: 2.5707
16/16 [==============================] - 0s 1ms/step - loss: 2.5218
16/16 [==============================] - 0s 2ms/step - loss: 2.5047
16/16 [==============================] - 0s 827us/step - loss: 2.4996
16/16 [==============================] - 0s 820us/step - loss: 2.4996

Testing for epoch 50 index 2:
79/79 [==============================] - 0s 577us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1106
16/16 [==============================] - 0s 812us/step - loss: 2.1213
16/16 [==============================] - 0s 2ms/step - loss: 2.4972
16/16 [==============================] - 0s 805us/step - loss: 2.5617
16/16 [==============================] - 0s 2ms/step - loss: 2.5540
16/16 [==============================] - 0s 779us/step - loss: 2.4949
16/16 [==============================] - 0s 798us/step - loss: 2.4473
16/16 [==============================] - 0s 802us/step - loss: 2.4311
16/16 [==============================] - 0s 827us/step - loss: 2.4263
16/16 [==============================] - 0s 827us/step - loss: 2.4263

Testing for epoch 50 index 3:
79/79 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 825us/step - loss: 0.1134
16/16 [==============================] - 0s 833us/step - loss: 2.1640
16/16 [==============================] - 0s 831us/step - loss: 2.5466
16/16 [==============================] - 0s 806us/step - loss: 2.6094
16/16 [==============================] - 0s 2ms/step - loss: 2.5990
16/16 [==============================] - 0s 2ms/step - loss: 2.5356
16/16 [==============================] - 0s 2ms/step - loss: 2.4853
16/16 [==============================] - 0s 2ms/step - loss: 2.4681
16/16 [==============================] - 0s 830us/step - loss: 2.4631
16/16 [==============================] - 0s 2ms/step - loss: 2.4631

Testing for epoch 50 index 4:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1106
16/16 [==============================] - 0s 2ms/step - loss: 2.1669
16/16 [==============================] - 0s 2ms/step - loss: 2.5499
16/16 [==============================] - 0s 2ms/step - loss: 2.6154
16/16 [==============================] - 0s 919us/step - loss: 2.6077
16/16 [==============================] - 0s 1ms/step - loss: 2.5490
16/16 [==============================] - 0s 2ms/step - loss: 2.5020
16/16 [==============================] - 0s 2ms/step - loss: 2.4856
16/16 [==============================] - 0s 2ms/step - loss: 2.4805
16/16 [==============================] - 0s 1ms/step - loss: 2.4803

Testing for epoch 50 index 5:
79/79 [==============================] - 0s 853us/step
16/16 [==============================] - 0s 803us/step - loss: 0.1134
16/16 [==============================] - 0s 1ms/step - loss: 2.1299
16/16 [==============================] - 0s 1ms/step - loss: 2.5127
16/16 [==============================] - 0s 1ms/step - loss: 2.5788
16/16 [==============================] - 0s 818us/step - loss: 2.5713
16/16 [==============================] - 0s 828us/step - loss: 2.5120
16/16 [==============================] - 0s 806us/step - loss: 2.4655
16/16 [==============================] - 0s 1ms/step - loss: 2.4496
16/16 [==============================] - 0s 825us/step - loss: 2.4450
16/16 [==============================] - 0s 851us/step - loss: 2.4451
Epoch 51 of 60

Testing for epoch 51 index 1:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 799us/step - loss: 0.1102
16/16 [==============================] - 0s 2ms/step - loss: 2.1080
16/16 [==============================] - 0s 1ms/step - loss: 2.4813
16/16 [==============================] - 0s 801us/step - loss: 2.5444
16/16 [==============================] - 0s 1ms/step - loss: 2.5367
16/16 [==============================] - 0s 1ms/step - loss: 2.4800
16/16 [==============================] - 0s 779us/step - loss: 2.4343
16/16 [==============================] - 0s 780us/step - loss: 2.4184
16/16 [==============================] - 0s 809us/step - loss: 2.4137
16/16 [==============================] - 0s 816us/step - loss: 2.4137

Testing for epoch 51 index 2:
79/79 [==============================] - 0s 544us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1094
16/16 [==============================] - 0s 2ms/step - loss: 2.1884
16/16 [==============================] - 0s 825us/step - loss: 2.5791
16/16 [==============================] - 0s 1ms/step - loss: 2.6449
16/16 [==============================] - 0s 837us/step - loss: 2.6358
16/16 [==============================] - 0s 1ms/step - loss: 2.5744
16/16 [==============================] - 0s 792us/step - loss: 2.5257
16/16 [==============================] - 0s 2ms/step - loss: 2.5088
16/16 [==============================] - 0s 807us/step - loss: 2.5036
16/16 [==============================] - 0s 2ms/step - loss: 2.5035

Testing for epoch 51 index 3:
79/79 [==============================] - 0s 575us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1135
16/16 [==============================] - 0s 918us/step - loss: 2.1417
16/16 [==============================] - 0s 778us/step - loss: 2.5163
16/16 [==============================] - 0s 839us/step - loss: 2.5775
16/16 [==============================] - 0s 1ms/step - loss: 2.5668
16/16 [==============================] - 0s 817us/step - loss: 2.5060
16/16 [==============================] - 0s 820us/step - loss: 2.4582
16/16 [==============================] - 0s 2ms/step - loss: 2.4420
16/16 [==============================] - 0s 2ms/step - loss: 2.4372
16/16 [==============================] - 0s 2ms/step - loss: 2.4371

Testing for epoch 51 index 4:
79/79 [==============================] - 0s 660us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1133
16/16 [==============================] - 0s 2ms/step - loss: 2.1446
16/16 [==============================] - 0s 780us/step - loss: 2.5259
16/16 [==============================] - 0s 2ms/step - loss: 2.5907
16/16 [==============================] - 0s 2ms/step - loss: 2.5826
16/16 [==============================] - 0s 2ms/step - loss: 2.5259
16/16 [==============================] - 0s 778us/step - loss: 2.4802
16/16 [==============================] - 0s 945us/step - loss: 2.4642
16/16 [==============================] - 0s 2ms/step - loss: 2.4593
16/16 [==============================] - 0s 937us/step - loss: 2.4592

Testing for epoch 51 index 5:
79/79 [==============================] - 0s 1ms/step
16/16 [==============================] - 0s 867us/step - loss: 0.1097
16/16 [==============================] - 0s 2ms/step - loss: 2.1334
16/16 [==============================] - 0s 2ms/step - loss: 2.5077
16/16 [==============================] - 0s 1ms/step - loss: 2.5687
16/16 [==============================] - 0s 814us/step - loss: 2.5580
16/16 [==============================] - 0s 1ms/step - loss: 2.4978
16/16 [==============================] - 0s 1ms/step - loss: 2.4505
16/16 [==============================] - 0s 2ms/step - loss: 2.4342
16/16 [==============================] - 0s 804us/step - loss: 2.4293
16/16 [==============================] - 0s 831us/step - loss: 2.4292
Epoch 52 of 60

Testing for epoch 52 index 1:
79/79 [==============================] - 0s 964us/step
16/16 [==============================] - 0s 2ms/step - loss: 0.1128
16/16 [==============================] - 0s 2ms/step - loss: 2.1843
16/16 [==============================] - 0s 1ms/step - loss: 2.5731
16/16 [==============================] - 0s 992us/step - loss: 2.6381
16/16 [==============================] - 0s 2ms/step - loss: 2.6285
16/16 [==============================] - 0s 2ms/step - loss: 2.5692
16/16 [==============================] - 0s 815us/step - loss: 2.5219
16/16 [==============================] - 0s 944us/step - loss: 2.5053
16/16 [==============================] - 0s 740us/step - loss: 2.5000
16/16 [==============================] - 0s 799us/step - loss: 2.4998

Testing for epoch 52 index 2:
79/79 [==============================] - 0s 498us/step
16/16 [==============================] - 0s 814us/step - loss: 0.1151
16/16 [==============================] - 0s 662us/step - loss: 2.1366
16/16 [==============================] - 0s 786us/step - loss: 2.5143
16/16 [==============================] - 0s 832us/step - loss: 2.5790
16/16 [==============================] - 0s 828us/step - loss: 2.5708
16/16 [==============================] - 0s 772us/step - loss: 2.5126
16/16 [==============================] - 0s 763us/step - loss: 2.4669
16/16 [==============================] - 0s 761us/step - loss: 2.4509
16/16 [==============================] - 0s 762us/step - loss: 2.4460
16/16 [==============================] - 0s 765us/step - loss: 2.4459

Testing for epoch 52 index 3:
79/79 [==============================] - 0s 651us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1137
16/16 [==============================] - 0s 776us/step - loss: 2.1214
16/16 [==============================] - 0s 777us/step - loss: 2.4961
16/16 [==============================] - 0s 810us/step - loss: 2.5559
16/16 [==============================] - 0s 1ms/step - loss: 2.5443
16/16 [==============================] - 0s 1ms/step - loss: 2.4830
16/16 [==============================] - 0s 1ms/step - loss: 2.4348
16/16 [==============================] - 0s 1ms/step - loss: 2.4184
16/16 [==============================] - 0s 823us/step - loss: 2.4137
16/16 [==============================] - 0s 786us/step - loss: 2.4137

Testing for epoch 52 index 4:
79/79 [==============================] - 0s 809us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1077
16/16 [==============================] - 0s 1ms/step - loss: 2.2251
16/16 [==============================] - 0s 765us/step - loss: 2.6189
16/16 [==============================] - 0s 1ms/step - loss: 2.6792
16/16 [==============================] - 0s 1ms/step - loss: 2.6652
16/16 [==============================] - 0s 1ms/step - loss: 2.5992
16/16 [==============================] - 0s 1ms/step - loss: 2.5479
16/16 [==============================] - 0s 787us/step - loss: 2.5304
16/16 [==============================] - 0s 1ms/step - loss: 2.5253
16/16 [==============================] - 0s 1ms/step - loss: 2.5253

Testing for epoch 52 index 5:
79/79 [==============================] - 0s 575us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1081
16/16 [==============================] - 0s 787us/step - loss: 2.1911
16/16 [==============================] - 0s 801us/step - loss: 2.5848
16/16 [==============================] - 0s 776us/step - loss: 2.6481
16/16 [==============================] - 0s 819us/step - loss: 2.6369
16/16 [==============================] - 0s 784us/step - loss: 2.5737
16/16 [==============================] - 0s 778us/step - loss: 2.5244
16/16 [==============================] - 0s 774us/step - loss: 2.5073
16/16 [==============================] - 0s 830us/step - loss: 2.5021
16/16 [==============================] - 0s 783us/step - loss: 2.5019
Epoch 53 of 60

Testing for epoch 53 index 1:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 783us/step - loss: 0.1105
16/16 [==============================] - 0s 798us/step - loss: 2.2424
16/16 [==============================] - 0s 801us/step - loss: 2.6434
16/16 [==============================] - 0s 782us/step - loss: 2.7071
16/16 [==============================] - 0s 809us/step - loss: 2.6960
16/16 [==============================] - 0s 781us/step - loss: 2.6329
16/16 [==============================] - 0s 796us/step - loss: 2.5825
16/16 [==============================] - 0s 785us/step - loss: 2.5653
16/16 [==============================] - 0s 779us/step - loss: 2.5603
16/16 [==============================] - 0s 780us/step - loss: 2.5603

Testing for epoch 53 index 2:
79/79 [==============================] - 0s 666us/step
16/16 [==============================] - 0s 800us/step - loss: 0.1065
16/16 [==============================] - 0s 773us/step - loss: 2.2126
16/16 [==============================] - 0s 780us/step - loss: 2.5990
16/16 [==============================] - 0s 799us/step - loss: 2.6537
16/16 [==============================] - 0s 775us/step - loss: 2.6362
16/16 [==============================] - 0s 778us/step - loss: 2.5665
16/16 [==============================] - 0s 777us/step - loss: 2.5130
16/16 [==============================] - 0s 782us/step - loss: 2.4951
16/16 [==============================] - 0s 793us/step - loss: 2.4897
16/16 [==============================] - 0s 783us/step - loss: 2.4896

Testing for epoch 53 index 3:
79/79 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1109
16/16 [==============================] - 0s 783us/step - loss: 2.2409
16/16 [==============================] - 0s 826us/step - loss: 2.6359
16/16 [==============================] - 0s 802us/step - loss: 2.6951
16/16 [==============================] - 0s 784us/step - loss: 2.6803
16/16 [==============================] - 0s 818us/step - loss: 2.6154
16/16 [==============================] - 0s 854us/step - loss: 2.5654
16/16 [==============================] - 0s 824us/step - loss: 2.5480
16/16 [==============================] - 0s 878us/step - loss: 2.5427
16/16 [==============================] - 0s 823us/step - loss: 2.5425

Testing for epoch 53 index 4:
79/79 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 822us/step - loss: 0.1077
16/16 [==============================] - 0s 774us/step - loss: 2.1988
16/16 [==============================] - 0s 791us/step - loss: 2.5828
16/16 [==============================] - 0s 824us/step - loss: 2.6395
16/16 [==============================] - 0s 777us/step - loss: 2.6247
16/16 [==============================] - 0s 786us/step - loss: 2.5585
16/16 [==============================] - 0s 791us/step - loss: 2.5071
16/16 [==============================] - 0s 796us/step - loss: 2.4895
16/16 [==============================] - 0s 784us/step - loss: 2.4842
16/16 [==============================] - 0s 781us/step - loss: 2.4840

Testing for epoch 53 index 5:
79/79 [==============================] - 0s 607us/step
16/16 [==============================] - 0s 793us/step - loss: 0.1101
16/16 [==============================] - 0s 823us/step - loss: 2.1742
16/16 [==============================] - 0s 806us/step - loss: 2.5541
16/16 [==============================] - 0s 815us/step - loss: 2.6106
16/16 [==============================] - 0s 786us/step - loss: 2.5974
16/16 [==============================] - 0s 779us/step - loss: 2.5359
16/16 [==============================] - 0s 777us/step - loss: 2.4884
16/16 [==============================] - 0s 821us/step - loss: 2.4719
16/16 [==============================] - 0s 831us/step - loss: 2.4668
16/16 [==============================] - 0s 794us/step - loss: 2.4666
Epoch 54 of 60

Testing for epoch 54 index 1:
79/79 [==============================] - 0s 584us/step
16/16 [==============================] - 0s 824us/step - loss: 0.1084
16/16 [==============================] - 0s 791us/step - loss: 2.1517
16/16 [==============================] - 0s 804us/step - loss: 2.5217
16/16 [==============================] - 0s 781us/step - loss: 2.5735
16/16 [==============================] - 0s 773us/step - loss: 2.5572
16/16 [==============================] - 0s 860us/step - loss: 2.4921
16/16 [==============================] - 0s 798us/step - loss: 2.4427
16/16 [==============================] - 0s 783us/step - loss: 2.4259
16/16 [==============================] - 0s 788us/step - loss: 2.4209
16/16 [==============================] - 0s 779us/step - loss: 2.4208

Testing for epoch 54 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 841us/step - loss: 0.1095
16/16 [==============================] - 0s 791us/step - loss: 2.1899
16/16 [==============================] - 0s 857us/step - loss: 2.5646
16/16 [==============================] - 0s 832us/step - loss: 2.6178
16/16 [==============================] - 0s 805us/step - loss: 2.5997
16/16 [==============================] - 0s 811us/step - loss: 2.5326
16/16 [==============================] - 0s 1ms/step - loss: 2.4819
16/16 [==============================] - 0s 799us/step - loss: 2.4647
16/16 [==============================] - 0s 810us/step - loss: 2.4596
16/16 [==============================] - 0s 818us/step - loss: 2.4596

Testing for epoch 54 index 3:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1083
16/16 [==============================] - 0s 802us/step - loss: 2.1131
16/16 [==============================] - 0s 796us/step - loss: 2.4631
16/16 [==============================] - 0s 776us/step - loss: 2.5087
16/16 [==============================] - 0s 791us/step - loss: 2.4890
16/16 [==============================] - 0s 833us/step - loss: 2.4226
16/16 [==============================] - 0s 784us/step - loss: 2.3731
16/16 [==============================] - 0s 772us/step - loss: 2.3567
16/16 [==============================] - 0s 772us/step - loss: 2.3520
16/16 [==============================] - 0s 798us/step - loss: 2.3520

Testing for epoch 54 index 4:
79/79 [==============================] - 0s 592us/step
16/16 [==============================] - 0s 813us/step - loss: 0.1097
16/16 [==============================] - 0s 820us/step - loss: 2.2147
16/16 [==============================] - 0s 790us/step - loss: 2.5931
16/16 [==============================] - 0s 786us/step - loss: 2.6463
16/16 [==============================] - 0s 793us/step - loss: 2.6278
16/16 [==============================] - 0s 815us/step - loss: 2.5607
16/16 [==============================] - 0s 786us/step - loss: 2.5099
16/16 [==============================] - 0s 800us/step - loss: 2.4930
16/16 [==============================] - 0s 804us/step - loss: 2.4882
16/16 [==============================] - 0s 803us/step - loss: 2.4882

Testing for epoch 54 index 5:
79/79 [==============================] - 0s 598us/step
16/16 [==============================] - 0s 865us/step - loss: 0.1090
16/16 [==============================] - 0s 821us/step - loss: 2.2205
16/16 [==============================] - 0s 781us/step - loss: 2.5931
16/16 [==============================] - 0s 1ms/step - loss: 2.6411
16/16 [==============================] - 0s 1ms/step - loss: 2.6206
16/16 [==============================] - 0s 783us/step - loss: 2.5518
16/16 [==============================] - 0s 789us/step - loss: 2.5000
16/16 [==============================] - 0s 791us/step - loss: 2.4825
16/16 [==============================] - 0s 786us/step - loss: 2.4773
16/16 [==============================] - 0s 784us/step - loss: 2.4773
Epoch 55 of 60

Testing for epoch 55 index 1:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 788us/step - loss: 0.1066
16/16 [==============================] - 0s 821us/step - loss: 2.2507
16/16 [==============================] - 0s 780us/step - loss: 2.6376
16/16 [==============================] - 0s 776us/step - loss: 2.6928
16/16 [==============================] - 0s 775us/step - loss: 2.6741
16/16 [==============================] - 0s 780us/step - loss: 2.6065
16/16 [==============================] - 0s 778us/step - loss: 2.5550
16/16 [==============================] - 0s 908us/step - loss: 2.5376
16/16 [==============================] - 0s 1ms/step - loss: 2.5325
16/16 [==============================] - 0s 1ms/step - loss: 2.5324

Testing for epoch 55 index 2:
79/79 [==============================] - 0s 827us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1066
16/16 [==============================] - 0s 830us/step - loss: 2.2226
16/16 [==============================] - 0s 782us/step - loss: 2.5906
16/16 [==============================] - 0s 780us/step - loss: 2.6408
16/16 [==============================] - 0s 1ms/step - loss: 2.6207
16/16 [==============================] - 0s 1ms/step - loss: 2.5530
16/16 [==============================] - 0s 1ms/step - loss: 2.5026
16/16 [==============================] - 0s 1ms/step - loss: 2.4856
16/16 [==============================] - 0s 1ms/step - loss: 2.4805
16/16 [==============================] - 0s 1ms/step - loss: 2.4805

Testing for epoch 55 index 3:
79/79 [==============================] - 0s 733us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1096
16/16 [==============================] - 0s 1ms/step - loss: 2.2626
16/16 [==============================] - 0s 1ms/step - loss: 2.6387
16/16 [==============================] - 0s 1ms/step - loss: 2.6881
16/16 [==============================] - 0s 1ms/step - loss: 2.6669
16/16 [==============================] - 0s 1ms/step - loss: 2.5970
16/16 [==============================] - 0s 1ms/step - loss: 2.5450
16/16 [==============================] - 0s 1ms/step - loss: 2.5276
16/16 [==============================] - 0s 1ms/step - loss: 2.5226
16/16 [==============================] - 0s 799us/step - loss: 2.5226

Testing for epoch 55 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1016
16/16 [==============================] - 0s 783us/step - loss: 2.2888
16/16 [==============================] - 0s 782us/step - loss: 2.6711
16/16 [==============================] - 0s 815us/step - loss: 2.7212
16/16 [==============================] - 0s 1ms/step - loss: 2.6985
16/16 [==============================] - 0s 848us/step - loss: 2.6265
16/16 [==============================] - 0s 837us/step - loss: 2.5724
16/16 [==============================] - 0s 788us/step - loss: 2.5543
16/16 [==============================] - 0s 828us/step - loss: 2.5490
16/16 [==============================] - 0s 827us/step - loss: 2.5490

Testing for epoch 55 index 5:
79/79 [==============================] - 0s 833us/step
16/16 [==============================] - 0s 924us/step - loss: 0.1076
16/16 [==============================] - 0s 874us/step - loss: 2.3363
16/16 [==============================] - 0s 793us/step - loss: 2.7287
16/16 [==============================] - 0s 798us/step - loss: 2.7820
16/16 [==============================] - 0s 796us/step - loss: 2.7605
16/16 [==============================] - 0s 836us/step - loss: 2.6894
16/16 [==============================] - 0s 801us/step - loss: 2.6356
16/16 [==============================] - 0s 797us/step - loss: 2.6175
16/16 [==============================] - 0s 791us/step - loss: 2.6122
16/16 [==============================] - 0s 794us/step - loss: 2.6122
Epoch 56 of 60

Testing for epoch 56 index 1:
79/79 [==============================] - 0s 588us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1053
16/16 [==============================] - 0s 823us/step - loss: 2.2654
16/16 [==============================] - 0s 784us/step - loss: 2.6376
16/16 [==============================] - 0s 796us/step - loss: 2.6831
16/16 [==============================] - 0s 798us/step - loss: 2.6585
16/16 [==============================] - 0s 784us/step - loss: 2.5853
16/16 [==============================] - 0s 784us/step - loss: 2.5317
16/16 [==============================] - 0s 776us/step - loss: 2.5138
16/16 [==============================] - 0s 788us/step - loss: 2.5086
16/16 [==============================] - 0s 780us/step - loss: 2.5085

Testing for epoch 56 index 2:
79/79 [==============================] - 0s 601us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1091
16/16 [==============================] - 0s 846us/step - loss: 2.2312
16/16 [==============================] - 0s 782us/step - loss: 2.6027
16/16 [==============================] - 0s 806us/step - loss: 2.6531
16/16 [==============================] - 0s 791us/step - loss: 2.6318
16/16 [==============================] - 0s 771us/step - loss: 2.5612
16/16 [==============================] - 0s 795us/step - loss: 2.5079
16/16 [==============================] - 0s 779us/step - loss: 2.4899
16/16 [==============================] - 0s 788us/step - loss: 2.4844
16/16 [==============================] - 0s 784us/step - loss: 2.4842

Testing for epoch 56 index 3:
79/79 [==============================] - 0s 596us/step
16/16 [==============================] - 0s 818us/step - loss: 0.1080
16/16 [==============================] - 0s 804us/step - loss: 2.2179
16/16 [==============================] - 0s 792us/step - loss: 2.5805
16/16 [==============================] - 0s 778us/step - loss: 2.6276
16/16 [==============================] - 0s 777us/step - loss: 2.6063
16/16 [==============================] - 0s 784us/step - loss: 2.5380
16/16 [==============================] - 0s 779us/step - loss: 2.4867
16/16 [==============================] - 0s 795us/step - loss: 2.4695
16/16 [==============================] - 0s 798us/step - loss: 2.4644
16/16 [==============================] - 0s 791us/step - loss: 2.4644

Testing for epoch 56 index 4:
79/79 [==============================] - 0s 709us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1050
16/16 [==============================] - 0s 1ms/step - loss: 2.2906
16/16 [==============================] - 0s 1ms/step - loss: 2.6671
16/16 [==============================] - 0s 1ms/step - loss: 2.7144
16/16 [==============================] - 0s 1ms/step - loss: 2.6909
16/16 [==============================] - 0s 1ms/step - loss: 2.6183
16/16 [==============================] - 0s 787us/step - loss: 2.5653
16/16 [==============================] - 0s 783us/step - loss: 2.5474
16/16 [==============================] - 0s 800us/step - loss: 2.5423
16/16 [==============================] - 0s 1ms/step - loss: 2.5422

Testing for epoch 56 index 5:
79/79 [==============================] - 0s 823us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1082
16/16 [==============================] - 0s 831us/step - loss: 2.2431
16/16 [==============================] - 0s 843us/step - loss: 2.6105
16/16 [==============================] - 0s 781us/step - loss: 2.6582
16/16 [==============================] - 0s 786us/step - loss: 2.6367
16/16 [==============================] - 0s 790us/step - loss: 2.5673
16/16 [==============================] - 0s 809us/step - loss: 2.5156
16/16 [==============================] - 0s 805us/step - loss: 2.4986
16/16 [==============================] - 0s 807us/step - loss: 2.4937
16/16 [==============================] - 0s 804us/step - loss: 2.4937
Epoch 57 of 60

Testing for epoch 57 index 1:
79/79 [==============================] - 0s 582us/step
16/16 [==============================] - 0s 792us/step - loss: 0.1051
16/16 [==============================] - 0s 794us/step - loss: 2.3166
16/16 [==============================] - 0s 852us/step - loss: 2.6952
16/16 [==============================] - 0s 812us/step - loss: 2.7417
16/16 [==============================] - 0s 788us/step - loss: 2.7163
16/16 [==============================] - 0s 781us/step - loss: 2.6402
16/16 [==============================] - 0s 775us/step - loss: 2.5838
16/16 [==============================] - 0s 787us/step - loss: 2.5650
16/16 [==============================] - 0s 783us/step - loss: 2.5596
16/16 [==============================] - 0s 808us/step - loss: 2.5596

Testing for epoch 57 index 2:
79/79 [==============================] - 0s 614us/step
16/16 [==============================] - 0s 798us/step - loss: 0.1056
16/16 [==============================] - 0s 1ms/step - loss: 2.1999
16/16 [==============================] - 0s 1ms/step - loss: 2.5532
16/16 [==============================] - 0s 1ms/step - loss: 2.5957
16/16 [==============================] - 0s 1ms/step - loss: 2.5734
16/16 [==============================] - 0s 930us/step - loss: 2.5046
16/16 [==============================] - 0s 902us/step - loss: 2.4545
16/16 [==============================] - 0s 1ms/step - loss: 2.4380
16/16 [==============================] - 0s 1ms/step - loss: 2.4332
16/16 [==============================] - 0s 1ms/step - loss: 2.4332

Testing for epoch 57 index 3:
79/79 [==============================] - 0s 665us/step
16/16 [==============================] - 0s 791us/step - loss: 0.1134
16/16 [==============================] - 0s 842us/step - loss: 2.1538
16/16 [==============================] - 0s 780us/step - loss: 2.5023
16/16 [==============================] - 0s 775us/step - loss: 2.5460
16/16 [==============================] - 0s 788us/step - loss: 2.5254
16/16 [==============================] - 0s 775us/step - loss: 2.4601
16/16 [==============================] - 0s 775us/step - loss: 2.4117
16/16 [==============================] - 0s 789us/step - loss: 2.3954
16/16 [==============================] - 0s 788us/step - loss: 2.3907
16/16 [==============================] - 0s 787us/step - loss: 2.3906

Testing for epoch 57 index 4:
79/79 [==============================] - 0s 909us/step
16/16 [==============================] - 0s 804us/step - loss: 0.1055
16/16 [==============================] - 0s 809us/step - loss: 2.3141
16/16 [==============================] - 0s 817us/step - loss: 2.6890
16/16 [==============================] - 0s 861us/step - loss: 2.7333
16/16 [==============================] - 0s 789us/step - loss: 2.7077
16/16 [==============================] - 0s 777us/step - loss: 2.6323
16/16 [==============================] - 0s 780us/step - loss: 2.5774
16/16 [==============================] - 0s 780us/step - loss: 2.5593
16/16 [==============================] - 0s 802us/step - loss: 2.5541
16/16 [==============================] - 0s 790us/step - loss: 2.5541

Testing for epoch 57 index 5:
79/79 [==============================] - 0s 604us/step
16/16 [==============================] - 0s 801us/step - loss: 0.1056
16/16 [==============================] - 0s 789us/step - loss: 2.2966
16/16 [==============================] - 0s 796us/step - loss: 2.6697
16/16 [==============================] - 0s 781us/step - loss: 2.7157
16/16 [==============================] - 0s 781us/step - loss: 2.6915
16/16 [==============================] - 0s 1ms/step - loss: 2.6184
16/16 [==============================] - 0s 1ms/step - loss: 2.5641
16/16 [==============================] - 0s 803us/step - loss: 2.5462
16/16 [==============================] - 0s 776us/step - loss: 2.5410
16/16 [==============================] - 0s 805us/step - loss: 2.5409
Epoch 58 of 60

Testing for epoch 58 index 1:
79/79 [==============================] - 0s 585us/step
16/16 [==============================] - 0s 781us/step - loss: 0.1061
16/16 [==============================] - 0s 785us/step - loss: 2.3267
16/16 [==============================] - 0s 777us/step - loss: 2.7069
16/16 [==============================] - 0s 784us/step - loss: 2.7544
16/16 [==============================] - 0s 782us/step - loss: 2.7306
16/16 [==============================] - 0s 1ms/step - loss: 2.6573
16/16 [==============================] - 0s 816us/step - loss: 2.6031
16/16 [==============================] - 0s 1ms/step - loss: 2.5850
16/16 [==============================] - 0s 1ms/step - loss: 2.5797
16/16 [==============================] - 0s 1ms/step - loss: 2.5796

Testing for epoch 58 index 2:
79/79 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.1053
16/16 [==============================] - 0s 1ms/step - loss: 2.2433
16/16 [==============================] - 0s 778us/step - loss: 2.6007
16/16 [==============================] - 0s 778us/step - loss: 2.6389
16/16 [==============================] - 0s 782us/step - loss: 2.6116
16/16 [==============================] - 0s 784us/step - loss: 2.5366
16/16 [==============================] - 0s 777us/step - loss: 2.4824
16/16 [==============================] - 0s 773us/step - loss: 2.4647
16/16 [==============================] - 0s 780us/step - loss: 2.4596
16/16 [==============================] - 0s 792us/step - loss: 2.4596

Testing for epoch 58 index 3:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 796us/step - loss: 0.1060
16/16 [==============================] - 0s 813us/step - loss: 2.2387
16/16 [==============================] - 0s 788us/step - loss: 2.5997
16/16 [==============================] - 0s 780us/step - loss: 2.6431
16/16 [==============================] - 0s 827us/step - loss: 2.6195
16/16 [==============================] - 0s 818us/step - loss: 2.5483
16/16 [==============================] - 0s 820us/step - loss: 2.4955
16/16 [==============================] - 0s 774us/step - loss: 2.4780
16/16 [==============================] - 0s 791us/step - loss: 2.4729
16/16 [==============================] - 0s 801us/step - loss: 2.4729

Testing for epoch 58 index 4:
79/79 [==============================] - 0s 586us/step
16/16 [==============================] - 0s 812us/step - loss: 0.1044
16/16 [==============================] - 0s 792us/step - loss: 2.3186
16/16 [==============================] - 0s 778us/step - loss: 2.6976
16/16 [==============================] - 0s 779us/step - loss: 2.7451
16/16 [==============================] - 0s 783us/step - loss: 2.7220
16/16 [==============================] - 0s 795us/step - loss: 2.6492
16/16 [==============================] - 0s 787us/step - loss: 2.5949
16/16 [==============================] - 0s 792us/step - loss: 2.5768
16/16 [==============================] - 0s 1ms/step - loss: 2.5714
16/16 [==============================] - 0s 807us/step - loss: 2.5713

Testing for epoch 58 index 5:
79/79 [==============================] - 0s 593us/step
16/16 [==============================] - 0s 783us/step - loss: 0.1039
16/16 [==============================] - 0s 794us/step - loss: 2.2733
16/16 [==============================] - 0s 768us/step - loss: 2.6396
16/16 [==============================] - 0s 790us/step - loss: 2.6824
16/16 [==============================] - 0s 774us/step - loss: 2.6577
16/16 [==============================] - 0s 780us/step - loss: 2.5860
16/16 [==============================] - 0s 1ms/step - loss: 2.5336
16/16 [==============================] - 0s 1ms/step - loss: 2.5162
16/16 [==============================] - 0s 1ms/step - loss: 2.5110
16/16 [==============================] - 0s 1ms/step - loss: 2.5109
Epoch 59 of 60

Testing for epoch 59 index 1:
79/79 [==============================] - 0s 574us/step
16/16 [==============================] - 0s 785us/step - loss: 0.1015
16/16 [==============================] - 0s 799us/step - loss: 2.2663
16/16 [==============================] - 0s 786us/step - loss: 2.6320
16/16 [==============================] - 0s 785us/step - loss: 2.6746
16/16 [==============================] - 0s 782us/step - loss: 2.6500
16/16 [==============================] - 0s 779us/step - loss: 2.5779
16/16 [==============================] - 0s 776us/step - loss: 2.5255
16/16 [==============================] - 0s 781us/step - loss: 2.5079
16/16 [==============================] - 0s 780us/step - loss: 2.5025
16/16 [==============================] - 0s 807us/step - loss: 2.5023

Testing for epoch 59 index 2:
79/79 [==============================] - 0s 578us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1025
16/16 [==============================] - 0s 807us/step - loss: 2.3515
16/16 [==============================] - 0s 777us/step - loss: 2.7275
16/16 [==============================] - 0s 774us/step - loss: 2.7688
16/16 [==============================] - 0s 1ms/step - loss: 2.7405
16/16 [==============================] - 0s 1ms/step - loss: 2.6618
16/16 [==============================] - 0s 776us/step - loss: 2.6044
16/16 [==============================] - 0s 1ms/step - loss: 2.5857
16/16 [==============================] - 0s 780us/step - loss: 2.5804
16/16 [==============================] - 0s 786us/step - loss: 2.5804

Testing for epoch 59 index 3:
79/79 [==============================] - 0s 602us/step
16/16 [==============================] - 0s 787us/step - loss: 0.1027
16/16 [==============================] - 0s 791us/step - loss: 2.2619
16/16 [==============================] - 0s 780us/step - loss: 2.6166
16/16 [==============================] - 0s 783us/step - loss: 2.6521
16/16 [==============================] - 0s 819us/step - loss: 2.6231
16/16 [==============================] - 0s 796us/step - loss: 2.5477
16/16 [==============================] - 0s 827us/step - loss: 2.4932
16/16 [==============================] - 0s 795us/step - loss: 2.4756
16/16 [==============================] - 0s 786us/step - loss: 2.4707
16/16 [==============================] - 0s 778us/step - loss: 2.4708

Testing for epoch 59 index 4:
79/79 [==============================] - 0s 608us/step
16/16 [==============================] - 0s 808us/step - loss: 0.1013
16/16 [==============================] - 0s 800us/step - loss: 2.2814
16/16 [==============================] - 0s 797us/step - loss: 2.6450
16/16 [==============================] - 0s 797us/step - loss: 2.6843
16/16 [==============================] - 0s 797us/step - loss: 2.6560
16/16 [==============================] - 0s 801us/step - loss: 2.5800
16/16 [==============================] - 0s 792us/step - loss: 2.5259
16/16 [==============================] - 0s 796us/step - loss: 2.5080
16/16 [==============================] - 0s 814us/step - loss: 2.5027
16/16 [==============================] - 0s 820us/step - loss: 2.5026

Testing for epoch 59 index 5:
79/79 [==============================] - 0s 657us/step
16/16 [==============================] - 0s 795us/step - loss: 0.1035
16/16 [==============================] - 0s 785us/step - loss: 2.3241
16/16 [==============================] - 0s 810us/step - loss: 2.7005
16/16 [==============================] - 0s 802us/step - loss: 2.7443
16/16 [==============================] - 0s 788us/step - loss: 2.7189
16/16 [==============================] - 0s 785us/step - loss: 2.6445
16/16 [==============================] - 0s 783us/step - loss: 2.5895
16/16 [==============================] - 0s 787us/step - loss: 2.5711
16/16 [==============================] - 0s 794us/step - loss: 2.5655
16/16 [==============================] - 0s 1ms/step - loss: 2.5654
Epoch 60 of 60

Testing for epoch 60 index 1:
79/79 [==============================] - 0s 828us/step
16/16 [==============================] - 0s 1ms/step - loss: 0.0991
16/16 [==============================] - 0s 797us/step - loss: 2.3587
16/16 [==============================] - 0s 1ms/step - loss: 2.7350
16/16 [==============================] - 0s 1ms/step - loss: 2.7747
16/16 [==============================] - 0s 1ms/step - loss: 2.7463
16/16 [==============================] - 0s 1ms/step - loss: 2.6678
16/16 [==============================] - 0s 1ms/step - loss: 2.6113
16/16 [==============================] - 0s 1ms/step - loss: 2.5929
16/16 [==============================] - 0s 1ms/step - loss: 2.5877
16/16 [==============================] - 0s 809us/step - loss: 2.5878

Testing for epoch 60 index 2:
79/79 [==============================] - 0s 576us/step
16/16 [==============================] - 0s 828us/step - loss: 0.1038
16/16 [==============================] - 0s 830us/step - loss: 2.2804
16/16 [==============================] - 0s 783us/step - loss: 2.6366
16/16 [==============================] - 0s 788us/step - loss: 2.6709
16/16 [==============================] - 0s 1ms/step - loss: 2.6408
16/16 [==============================] - 0s 1ms/step - loss: 2.5626
16/16 [==============================] - 0s 1ms/step - loss: 2.5067
16/16 [==============================] - 0s 1ms/step - loss: 2.4886
16/16 [==============================] - 0s 1ms/step - loss: 2.4834
16/16 [==============================] - 0s 803us/step - loss: 2.4834

Testing for epoch 60 index 3:
79/79 [==============================] - 0s 812us/step
16/16 [==============================] - 0s 788us/step - loss: 0.0991
16/16 [==============================] - 0s 1ms/step - loss: 2.3934
16/16 [==============================] - 0s 1ms/step - loss: 2.7744
16/16 [==============================] - 0s 1ms/step - loss: 2.8152
16/16 [==============================] - 0s 1ms/step - loss: 2.7874
16/16 [==============================] - 0s 1ms/step - loss: 2.7085
16/16 [==============================] - 0s 777us/step - loss: 2.6519
16/16 [==============================] - 0s 1ms/step - loss: 2.6333
16/16 [==============================] - 0s 778us/step - loss: 2.6279
16/16 [==============================] - 0s 1ms/step - loss: 2.6278

Testing for epoch 60 index 4:
79/79 [==============================] - 0s 579us/step
16/16 [==============================] - 0s 793us/step - loss: 0.0991
16/16 [==============================] - 0s 784us/step - loss: 2.3763
16/16 [==============================] - 0s 782us/step - loss: 2.7524
16/16 [==============================] - 0s 782us/step - loss: 2.7925
16/16 [==============================] - 0s 1ms/step - loss: 2.7641
16/16 [==============================] - 0s 1ms/step - loss: 2.6876
16/16 [==============================] - 0s 1ms/step - loss: 2.6322
16/16 [==============================] - 0s 1ms/step - loss: 2.6139
16/16 [==============================] - 0s 1ms/step - loss: 2.6085
16/16 [==============================] - 0s 1ms/step - loss: 2.6085

Testing for epoch 60 index 5:
79/79 [==============================] - 0s 581us/step
16/16 [==============================] - 0s 786us/step - loss: 0.1005
16/16 [==============================] - 0s 785us/step - loss: 2.3451
16/16 [==============================] - 0s 785us/step - loss: 2.7153
16/16 [==============================] - 0s 771us/step - loss: 2.7525
16/16 [==============================] - 0s 774us/step - loss: 2.7234
16/16 [==============================] - 0s 789us/step - loss: 2.6445
16/16 [==============================] - 0s 784us/step - loss: 2.5884
16/16 [==============================] - 0s 789us/step - loss: 2.5702
16/16 [==============================] - 0s 789us/step - loss: 2.5652
16/16 [==============================] - 0s 802us/step - loss: 2.5653
79/79 [==============================] - 0s 580us/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1840">
<div class="sourceCode cell-code" id="cb480"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb480-1"><a href="#cb480-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1841">
<div class="sourceCode cell-code" id="cb481"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb481-1"><a href="#cb481-1" aria-hidden="true" tabindex="-1"></a>outlier_MO_GAAL_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_MO_GAAL_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1842">
<div class="sourceCode cell-code" id="cb482"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb482-1"><a href="#cb482-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_MO_GAAL_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1843">
<div class="sourceCode cell-code" id="cb483"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb483-1"><a href="#cb483-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"MO-GAAL (Liu et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-335-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.952
Precision: 0.952
Recall: 1.000
F1 Score: 0.975</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1844">
<div class="sourceCode cell-code" id="cb486"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb486-1"><a href="#cb486-1" aria-hidden="true" tabindex="-1"></a>thirteen <span class="op">=</span> twelve.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  thirteen = twelve.append(_conf.tab)</code></pre>
</div>
</div>
</section>
<section id="lscp" class="level3">
<h3 class="anchored" data-anchor-id="lscp">LSCP</h3>
<div class="cell" data-execution_count="1845">
<div class="sourceCode cell-code" id="cb488"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb488-1"><a href="#cb488-1" aria-hidden="true" tabindex="-1"></a>detectors <span class="op">=</span> [KNN(), LOF(), OCSVM()]</span>
<span id="cb488-2"><a href="#cb488-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LSCP(detectors,contamination<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb488-3"><a href="#cb488-3" aria-hidden="true" tabindex="-1"></a>clf.fit(_df[[<span class="st">'x'</span>, <span class="st">'y'</span>,<span class="st">'fnoise'</span>]])</span>
<span id="cb488-4"><a href="#cb488-4" aria-hidden="true" tabindex="-1"></a>_df[<span class="st">'LSCP_clf'</span>] <span class="op">=</span> clf.labels_</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/pyod/models/lscp.py:382: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1846">
<div class="sourceCode cell-code" id="cb490"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb490-1"><a href="#cb490-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(clf.labels_)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1847">
<div class="sourceCode cell-code" id="cb491"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb491-1"><a href="#cb491-1" aria-hidden="true" tabindex="-1"></a>outlier_LSCP_one <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="dv">0</span>  <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,outlier_LSCP_one))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1848">
<div class="sourceCode cell-code" id="cb492"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb492-1"><a href="#cb492-1" aria-hidden="true" tabindex="-1"></a>_conf <span class="op">=</span> Conf_matrx(outlier_true_one_2,outlier_LSCP_one,tab_bunny)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="1849">
<div class="sourceCode cell-code" id="cb493"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb493-1"><a href="#cb493-1" aria-hidden="true" tabindex="-1"></a>_conf.conf(<span class="st">"LSCP (Zhao et al., 2019)"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-07-03-other_outlier_detection_files/figure-html/cell-341-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.978
Precision: 0.990
Recall: 0.987
F1 Score: 0.989</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.tab = self.tab.append(pd.DataFrame({"Accuracy":[self.acc],"Precision":[self.pre],"Recall":[self.rec],"F1":[self.f1]},index = [name]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1850">
<div class="sourceCode cell-code" id="cb496"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb496-1"><a href="#cb496-1" aria-hidden="true" tabindex="-1"></a>fourteen <span class="op">=</span> thirteen.append(_conf.tab)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  fourteen = thirteen.append(_conf.tab)</code></pre>
</div>
</div>
</section>
</section>
<section id="bunny-result" class="level2">
<h2 class="anchored" data-anchor-id="bunny-result">Bunny Result</h2>
<div class="cell" data-execution_count="1851">
<div class="sourceCode cell-code" id="cb498"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb498-1"><a href="#cb498-1" aria-hidden="true" tabindex="-1"></a>fourteen.<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1851">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GODE</th>
      <td>0.988</td>
      <td>0.995</td>
      <td>0.993</td>
      <td>0.994</td>
    </tr>
    <tr>
      <th>LOF (Breunig et al., 2000)</th>
      <td>0.913</td>
      <td>0.955</td>
      <td>0.953</td>
      <td>0.954</td>
    </tr>
    <tr>
      <th>kNN (Ramaswamy et al., 2000)</th>
      <td>0.942</td>
      <td>0.997</td>
      <td>0.942</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>OCSVM (Sch ̈olkopf et al., 2001)</th>
      <td>0.935</td>
      <td>0.992</td>
      <td>0.939</td>
      <td>0.965</td>
    </tr>
    <tr>
      <th>MCD (Hardin and Rocke, 2004)</th>
      <td>0.982</td>
      <td>0.992</td>
      <td>0.989</td>
      <td>0.990</td>
    </tr>
    <tr>
      <th>Feature Bagging (Lazarevic and Kumar, 2005)</th>
      <td>0.954</td>
      <td>0.977</td>
      <td>0.974</td>
      <td>0.976</td>
    </tr>
    <tr>
      <th>ABOD (Kriegel et al., 2008)</th>
      <td>0.979</td>
      <td>0.990</td>
      <td>0.988</td>
      <td>0.989</td>
    </tr>
    <tr>
      <th>Isolation Forest (Liu et al., 2008)</th>
      <td>0.827</td>
      <td>0.995</td>
      <td>0.822</td>
      <td>0.900</td>
    </tr>
    <tr>
      <th>HBOS (Goldstein and Dengel, 2012)</th>
      <td>0.919</td>
      <td>0.958</td>
      <td>0.956</td>
      <td>0.957</td>
    </tr>
    <tr>
      <th>SOS (Janssens et al., 2012)</th>
      <td>0.912</td>
      <td>0.955</td>
      <td>0.953</td>
      <td>0.954</td>
    </tr>
    <tr>
      <th>SO-GAAL (Liu et al., 2019)</th>
      <td>0.952</td>
      <td>0.952</td>
      <td>1.000</td>
      <td>0.975</td>
    </tr>
    <tr>
      <th>MO-GAAL (Liu et al., 2019)</th>
      <td>0.952</td>
      <td>0.952</td>
      <td>1.000</td>
      <td>0.975</td>
    </tr>
    <tr>
      <th>LSCP (Zhao et al., 2019)</th>
      <td>0.978</td>
      <td>0.990</td>
      <td>0.987</td>
      <td>0.989</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Bunny 5%</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GODE</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr class="even">
<td style="text-align: center;">LOF (Breunig et al., 2000)</td>
<td style="text-align: center;">0.913</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">KNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">CBLOF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OCSVM (Sch ̈olkopf et al., 2001)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">MCD (Hardin and Rocke, 2004)</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.990</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Feature Bagging (Lazarevic and Kumar, 2005)</td>
<td style="text-align: center;">0.954</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">0.976</td>
</tr>
<tr class="even">
<td style="text-align: center;">ABOD (Kriegel et al., 2008)</td>
<td style="text-align: center;">0.977</td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.987</td>
<td style="text-align: center;">0.988</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Isolation Forest (Liu et al., 2008)</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.996</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.884</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBOS (Goldstein and Dengel, 2012)</td>
<td style="text-align: center;">0.919</td>
<td style="text-align: center;">0.958</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">0.957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SOS (Janssens et al., 2012)</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.953</td>
<td style="text-align: center;">0.954</td>
</tr>
<tr class="even">
<td style="text-align: center;">SO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MO-GAAL (Liu et al., 2019)</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">0.952</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="even">
<td style="text-align: center;">LSCP (Zhao et al., 2019)</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.989</td>
</tr>
</tbody>
</table>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="seoyeonc/blog" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>
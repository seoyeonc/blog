{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8e90f49b-a002-4301-9656-147f3e4b8c46",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"PedalMeDatasetLoader lag 4 Randomly Missing comparison Table\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-02-16\"\n",
    "categories:\n",
    "  - ST-GCN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf50ae2-58ec-4c6e-9cc8-393c473767eb",
   "metadata": {},
   "source": [
    "> ST-GCN Dataset PedalMeDatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463f6e7-0b6c-490d-b7ee-4022ce4345a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f90af573-4bc0-4c9e-ad94-e9739160055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "# scipy \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import copy\n",
    "\n",
    "import rpy2.robjects.numpy2ri as rpyn\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dbbe91df-66c9-46da-abf9-379f37061d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f9f9-20fb-489c-9a8d-0f47cf681b1e",
   "metadata": {},
   "source": [
    "# my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "227faf0a-4609-4fb1-bb57-f72308e2b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'rb') as outfile:\n",
    "        data_dict = pickle.load(outfile)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a159f970-32cf-4719-b3b7-d16eeb939f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict,fname):\n",
    "    with open(fname,'wb') as outfile:\n",
    "        pickle.dump(data_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "46b2f8de-d7db-4a8a-8b56-68987ea54c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f,*args,t=None,h=2.5,**kwargs):\n",
    "    T,N = f.shape\n",
    "    if t == None: t = range(T)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots(N,1)\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "        ax[n].set_title('node='+str(n))\n",
    "    fig.set_figheight(N*h)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dfd30cd2-1daf-474d-b132-7b41af02e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_add(fig,f,*args,t=None,**kwargs):\n",
    "    T = f.shape[0]\n",
    "    N = f.shape[1] \n",
    "    if t == None: t = range(T)   \n",
    "    ax = fig.get_axes()\n",
    "    for n in range(N):\n",
    "        ax[n].plot(t,f[:,n],*args,**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5422d968-a917-483b-8e82-4ab2bf569bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Psi(T):\n",
    "    W = np.zeros((T,T))\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            if i==j :\n",
    "                W[i,j] = 0\n",
    "            elif np.abs(i-j) <= 1 : \n",
    "                W[i,j] = 1\n",
    "    d = np.array(W.sum(axis=1))\n",
    "    D = np.diag(d)\n",
    "    L = np.array(np.diag(1/np.sqrt(d)) @ (D-W) @ np.diag(1/np.sqrt(d)))\n",
    "    lamb, Psi = np.linalg.eigh(L)\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6fdbd67c-4d90-4d7f-9a4f-2f73dac5485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7da0eb4f-5518-4e35-b392-9762da230d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(f):\n",
    "    f = np.array(f)\n",
    "    if len(f.shape)==1: f = f.reshape(-1,1)\n",
    "    T,N = f.shape\n",
    "    Psi = make_Psi(T)\n",
    "    fbar = Psi.T @ f # apply dft \n",
    "    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n",
    "    fhat = Psi @ fbar_threshed # inverse dft \n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3036d47a-8211-4f46-9cd3-c316e01e5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_freq_domain(signal, missing_index):\n",
    "    signal = np.array(signal)\n",
    "    T,N = signal.shape \n",
    "    signal_trimed = trim(signal)\n",
    "    for i in range(N):\n",
    "        signal[missing_index[i],i] = signal_trimed[missing_index[i],i]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7494a4-48fb-4615-8278-92c167349a86",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5df260d-2d15-4aad-aa43-6a007338235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import  PedalMeDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "39c0532a-4145-444b-b21c-cd2527ac9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PedalMeDatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a769d9e-6673-45a9-af2d-d2f468eb4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.get_dataset(lags=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0fa5d05-33c4-4a1e-a35e-165a199bb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7bfb4-afc6-4dbe-8214-74c3ab5b54e8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91f23ab1-64bb-464b-b9bf-1a5f969a98c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StaticGraphTemporalSignal' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3593792/1414111177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'StaticGraphTemporalSignal' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "train_dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6636dc51-0b08-46c3-a085-e393a97aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    data_train.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f5966c5-a39b-4b70-9028-a61dfd1de3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 4]),\n",
       " torch.Size([15]),\n",
       " torch.Size([2, 225]),\n",
       " torch.Size([225]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a07c500-5603-47c3-bdbf-2263bce42ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6f10135-8c29-4ebf-81d0-be0757442889",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = time\n",
    "N = len(data_train[0][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "daa85896-7946-4953-8ee3-b26fd94acd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data_train[0][1].edge_index\n",
    "edge_attr = data_train[0][1].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b676bbb5-3b7f-4124-bc07-b76bbb3ef55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(time):\n",
    "    x_train.append(data_train[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "133c53ec-f888-4692-8ec2-1190210ea234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 15, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_train = data_tensor.reshape(time,15,-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e0e2332-9332-457c-838f-913c746c357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(time):\n",
    "    y_train.append(data_train[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d77b6591-a226-48e1-ad80-c80c450a0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 15])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_train:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_train = data_tensor.reshape(time,15)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a982424-a5d6-4f00-b9f9-99148e4e71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 15, 4]), torch.Size([23, 15]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d821f1b-bddd-4df4-91f1-f80f0d34492d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85c19483-c755-45dd-9a3f-1998c4088d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    data_test.append([time,snapshot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "620a37fb-0ac2-4550-8c66-5e788cdfa0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 4]),\n",
       " torch.Size([15]),\n",
       " torch.Size([2, 225]),\n",
       " torch.Size([225]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23c43585-3bf3-43ad-a84b-26edcc809058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80140e76-d286-4fc9-b94a-d93de15e70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_test = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cedea55-bc18-45ac-b61a-676002cf8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(time):\n",
    "    x_test.append(data_test[i][1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b775a13-ed2c-44ef-9d53-b53a475be2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 15, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in x_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "x_test = data_tensor.reshape(time,15,-1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a6a387a-f862-423c-b29f-e636c8ef507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for i in range(time):\n",
    "    y_test.append(data_test[i][1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d2c5d2c-1b76-4022-b699-39cd13649f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 15])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.Tensor()\n",
    "# Iterate over the data points of the dataset\n",
    "for i in y_test:\n",
    "    # Concatenate the data point to the tensor\n",
    "    data_tensor = torch.cat((data_tensor, i), dim=0)\n",
    "y_test = data_tensor.reshape(time,15)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf275097-975f-4812-a385-290f49d83136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 15, 4]), torch.Size([6, 15]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c101-5cff-4aec-9f7b-fe41c9c16b47",
   "metadata": {},
   "source": [
    "# data 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4e297-0e68-4b57-adc2-2abafc28cc03",
   "metadata": {},
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a16a8e01-944a-4b32-aba4-519372d25976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 23, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_test,T_train,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c27e81db-e176-44d4-aef7-b978e6e8fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "          4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
       "          8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "          9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13,\n",
       "         13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n",
       "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,\n",
       "          6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,\n",
       "          9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
       "         12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "          0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n",
       "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,\n",
       "          6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,\n",
       "          9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
       "         12, 13, 14,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "          0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n",
       "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,  5,\n",
       "          6,  7,  8,  9, 10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = edge_index;E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8bbe9e3-5bb9-4fce-b8d0-4501388c620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "307602a2-61d2-40cd-b331-f498a8539e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.4255, 0.1574, 0.2065, 0.5641, 0.5186, 0.4004, 0.0267, 0.2247,\n",
       "        0.5012, 0.6450, 0.3018, 0.2209, 0.2913, 0.2953, 0.4255, 1.0000, 0.0675,\n",
       "        0.2620, 0.3781, 0.3043, 0.4957, 0.0126, 0.4736, 0.2147, 0.6440, 0.1405,\n",
       "        0.1200, 0.2369, 0.5157, 0.1574, 0.0675, 1.0000, 0.0580, 0.1245, 0.1816,\n",
       "        0.0840, 0.1300, 0.0394, 0.3139, 0.1045, 0.2730, 0.2654, 0.0848, 0.0490,\n",
       "        0.2065, 0.2620, 0.0580, 1.0000, 0.1279, 0.2995, 0.4941, 0.0193, 0.3641,\n",
       "        0.1441, 0.2718, 0.0660, 0.1816, 0.0693, 0.1373, 0.5641, 0.3781, 0.1245,\n",
       "        0.1279, 1.0000, 0.2931, 0.2577, 0.0182, 0.1796, 0.3608, 0.4670, 0.3473,\n",
       "        0.1312, 0.5161, 0.3760, 0.5186, 0.3043, 0.1816, 0.2995, 0.2931, 1.0000,\n",
       "        0.4593, 0.0411, 0.2104, 0.4788, 0.4550, 0.2095, 0.3927, 0.1517, 0.1748,\n",
       "        0.4004, 0.4957, 0.0840, 0.4941, 0.2577, 0.4593, 1.0000, 0.0201, 0.4531,\n",
       "        0.2433, 0.5497, 0.1222, 0.2012, 0.1401, 0.2557, 0.0267, 0.0126, 0.1300,\n",
       "        0.0193, 0.0182, 0.0411, 0.0201, 1.0000, 0.0092, 0.0502, 0.0194, 0.0355,\n",
       "        0.0997, 0.0114, 0.0079, 0.2247, 0.4736, 0.0394, 0.3641, 0.1796, 0.2104,\n",
       "        0.4531, 0.0092, 1.0000, 0.1203, 0.3470, 0.0693, 0.0918, 0.1144, 0.3018,\n",
       "        0.5012, 0.2147, 0.3139, 0.1441, 0.3608, 0.4788, 0.2433, 0.0502, 0.1203,\n",
       "        1.0000, 0.3310, 0.4210, 0.3253, 0.2087, 0.1523, 0.6450, 0.6440, 0.1045,\n",
       "        0.2718, 0.4670, 0.4550, 0.5497, 0.0194, 0.3470, 0.3310, 1.0000, 0.1990,\n",
       "        0.1788, 0.2543, 0.3829, 0.3018, 0.1405, 0.2730, 0.0660, 0.3473, 0.2095,\n",
       "        0.1222, 0.0355, 0.0693, 0.4210, 0.1990, 1.0000, 0.1468, 0.2950, 0.1316,\n",
       "        0.2209, 0.1200, 0.2654, 0.1816, 0.1312, 0.3927, 0.2012, 0.0997, 0.0918,\n",
       "        0.3253, 0.1788, 0.1468, 1.0000, 0.0707, 0.0690, 0.2913, 0.2369, 0.0848,\n",
       "        0.0693, 0.5161, 0.1517, 0.1401, 0.0114, 0.1144, 0.2087, 0.2543, 0.2950,\n",
       "        0.0707, 1.0000, 0.3298, 0.2953, 0.5157, 0.0490, 0.1373, 0.3760, 0.1748,\n",
       "        0.2557, 0.0079, 0.3018, 0.1523, 0.3829, 0.1316, 0.0690, 0.3298, 1.0000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed58fa-3cd6-428b-a6d0-52e3460d9e1f",
   "metadata": {},
   "source": [
    "`-` train / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829a2c68-3ed8-4c46-909e-fae75875f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f = torch.concat([x_train[:-1,:,0], x_train[-1,:,:].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4efba7cf-02a4-4f5c-b0ec-8b25d8339b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 15, 4]),\n",
       " torch.Size([26, 15]),\n",
       " torch.Size([6, 15, 4]),\n",
       " torch.Size([23, 15]),\n",
       " torch.Size([6, 15]),\n",
       " 23,\n",
       " 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_train_f.shape, x_test.shape,y_train.shape,y_test.shape,T_train,T_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ecff-ebeb-4d3f-97de-297aa69aa487",
   "metadata": {},
   "source": [
    "# Random Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9c2d697-7649-4ed0-a0c7-e4b66c4fd45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Missing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.N = N\n",
    "        self.number = []\n",
    "    def miss(self,percent=0.5):\n",
    "        self.missing = copy.deepcopy(self.df)\n",
    "        self.percent = percent\n",
    "        for i in range(self.N):\n",
    "            #self.seed = np.random.choice(1000,1,replace=False)\n",
    "            #np.random.seed(self.seed)\n",
    "            self.number.append(np.random.choice(int(len(self.df))-1,int(len(self.df)*self.percent),replace=False))\n",
    "            self.missing[self.number[i],i] = float('nan')\n",
    "    def first_mean(self):\n",
    "        self.train_mean = np.array(copy.deepcopy(self.missing))\n",
    "        for i in range(self.N):\n",
    "            self.train_mean[self.number[i],i] = np.nanmean(self.missing[:,i])\n",
    "    def second_linear(self):\n",
    "        self.train_linear = pd.DataFrame(self.missing.tolist())\n",
    "        self.train_linear.interpolate(method='linear', inplace=True)\n",
    "        self.train_linear = self.train_linear.fillna(0)\n",
    "        self.train_linear = np.array(self.train_linear).reshape(int(len(self.df)),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dece228d-91f6-4691-acc1-f3a780821e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test']\n",
    "\n",
    "rate = [i/10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9d407-a7b9-4d9c-90cf-390558a2a54d",
   "metadata": {},
   "source": [
    "# Class code by Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151cae6-7517-4a1e-a359-a06ad54c7d54",
   "metadata": {},
   "source": [
    "## STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbc2ee07-4339-452f-9e43-bdd3941978cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[j:(T_train+j),:] for j in range(self.lag)],axis = -1)).float()\n",
    "            y = torch.tensor(interpolated_signal[self.lag:,:]).float()\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            for epoch in range(50):\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):\n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_stgcn = (((self.real_y-yhat.squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_stgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "    \n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_stgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_stgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67e699-fa29-4673-bf2c-bb814f8d7367",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhencement of STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3b20225-0621-4e11-8798-199c1bcf7e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESTGCN_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.XX = x_test\n",
    "        self.yy = y_test\n",
    "\n",
    "        self.real_y = y_train\n",
    "        for i in range(self.iterable):\n",
    "    \n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            net = RecurrentGCN(node_features=self.lag, filters=self.Number_of_filters)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            net.train()\n",
    "            signal = interpolated_signal.copy()\n",
    "            for epoch in range(50):\n",
    "                signal = update_from_freq_domain(signal,missing_index)\n",
    "                X = torch.tensor(np.stack([signal[i:(T_train+epoch+i),:] for i in range(self.lag)],axis = -1)).reshape(-1,N,self.lag).float()\n",
    "                y = torch.tensor(signal).reshape(-1,N,1).float()[self.lag:,:,:]\n",
    "                for time, (xt,yt) in enumerate(zip(X,y)):        \n",
    "                    yt_hat = net(xt, edge_index, edge_attr)\n",
    "                    cost = torch.mean((yt_hat-yt)**2)\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                signal = torch.concat([X[:-1,:,0], X[-1,:,:].T, yt_hat.detach().reshape(1,-1)]).squeeze()\n",
    "\n",
    "            yhat = torch.stack([net(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n",
    "            yyhat = torch.stack([net(xt, edge_index, edge_attr) for xt in self.XX]).detach().numpy()\n",
    "\n",
    "            train_mse_total_estgcn = (((self.real_y-yhat[:T_train,:].squeeze()).squeeze())**2).mean()\n",
    "            test_mse_total_estgcn = (((self.yy-yyhat.squeeze()).squeeze())**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_estgcn.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_estgcn.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d193fc-447d-4565-9b34-437a886bd802",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78e55b5c-e4d4-44c8-bf27-f523035636ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69a2fb6-e833-4211-954b-95227d29337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: igraph\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: wordcloud\n",
      "\n",
      "R[write to console]: Loading required package: RColorBrewer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(GNAR)\n",
    "library(igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "283a240b-abfe-4a3e-9840-b44c55f67ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNAR = importr('GNAR') # import GNAR \n",
    "igraph = importr('igraph') # import igraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4135e6e-aac4-4dc1-83b9-6e6067590ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.zeros((N,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "704f5ec0-fc72-495b-a1db-0ea20cf2d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(edge_index[0])):\n",
    "    w[edge_index[0][k],edge_index[1][k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c5f74e5-e93e-4680-93a3-6d5d65c5e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = robjects.r.matrix(FloatVector(w), nrow = N, ncol = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23d64792-9f0e-435e-805b-c26813996ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNAR_Missing:\n",
    "    def __init__(self,Dataset, df, iterable, Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation):\n",
    "        self.Dataset = Dataset\n",
    "        self.df = df\n",
    "        self.iterable = iterable\n",
    "        self.Method = Method\n",
    "        self.Missingrate = Missingrate\n",
    "        self.Missingtype = Missingtype\n",
    "        self.lag = lag\n",
    "        self.Number_of_filters = Number_of_filters\n",
    "        self.Interpolation = Interpolation\n",
    "        self.iterable = iterable\n",
    "    def iter(self):\n",
    "        self.yy = torch.tensor(y_test).float()\n",
    "        for i in range(self.iterable):\n",
    "\n",
    "            _zero = Missing(x_train_f)\n",
    "            _zero.miss(percent = self.Missingrate)\n",
    "            _zero.second_linear()\n",
    "\n",
    "            missing_index = _zero.number\n",
    "            interpolated_signal = _zero.train_linear\n",
    "\n",
    "            X = torch.tensor(np.stack([interpolated_signal[i:(T_train+i),:] for i in range(self.lag)],axis = -1)).float()\n",
    "\n",
    "            answer = GNAR.GNARfit(vts=robjects.r.matrix(rpyn.numpy2rpy(np.array(X).squeeze()), nrow = T_train, ncol = N),net = GNAR.matrixtoGNAR(m), alphaOrder = 4, betaOrder = FloatVector([1, 1, 1, 1]))             \n",
    "            predict = GNAR.predict_GNARfit(answer,n_ahead=T_test)\n",
    "\n",
    "\n",
    "            train_mse_total_gnar = ((pd.DataFrame(GNAR.residuals_GNARfit(answer)).values.reshape(-1,N))**2).mean()\n",
    "            test_mse_total_gnar = ((self.yy - pd.DataFrame(predict).values.reshape(-1,N))**2).mean()\n",
    "\n",
    "            df_row = pd.DataFrame(columns=col)\n",
    "            df_row['Dataset'] = self.Dataset,\n",
    "            df_row['iteration'] = i+1, # 1,2,3,...,10 \n",
    "            df_row['method'] = self.Method, # 'stgcn','estgcn','gnar' \n",
    "            df_row['missingrate'] = self.Missingrate, # 0.0, 0.2, 0.4, 0.6, 0.8 \n",
    "            df_row['missingtype'] = self.Missingtype,  # None, 'randomly' and 'block' \n",
    "            df_row['lag'] = self.lag, # 1,2,3,4 ... \n",
    "            df_row['number_of_filters'] = self.Number_of_filters, # 16,24,32, ... \n",
    "            df_row['interpolation'] = self.Interpolation, # None, 'mean', 'linear'\n",
    "            df_row['MSE_train'] = train_mse_total_gnar.tolist()\n",
    "            df_row['MSE_test'] = test_mse_total_gnar.tolist()\n",
    "\n",
    "            self.df = pd.concat([self.df,df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423800d-629b-4e4a-8452-3285f5caecd8",
   "metadata": {},
   "source": [
    "## STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8e2d68b-4e7d-4b53-9250-94b3188a13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'PedalMeDatasetLoader'\n",
    "Method = 'stgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f69f148a-8d9c-41ac-b7bd-6772644abc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stgcn= pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43943dc-9a5e-443e-a0e8-94c746507c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    stgcn = STGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    stgcn.iter()\n",
    "    df_add = stgcn.df.copy()\n",
    "    df_stgcn = pd.concat([df_stgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a4cd8-8420-4e85-a3ba-2ea115046627",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_stgcn, './data/Pedal_stgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b0839-0ce0-4e9c-9117-55edbfb8b56e",
   "metadata": {},
   "source": [
    "## Enhencement of STGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cde8e-4610-475d-bbb6-657161d373b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'PedalMeDatasetLoader'\n",
    "Method = 'estgcn' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = 4 # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a632d7f-230f-4b93-b4f4-0856a30f48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estgcn = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8957bc-61ec-41bb-b8c2-e1cd64ebefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    estgcn = ESTGCN_Missing(Dataset,df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    estgcn.iter()\n",
    "    df_add = estgcn.df.copy()\n",
    "    df_estgcn = pd.concat([df_estgcn,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4d2de-d979-4470-8830-42e4e1dc5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_estgcn, './data/Pedal_estgcn_randomly_by_rate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f435b52-7a28-4f9c-8876-92532e600406",
   "metadata": {},
   "source": [
    "## GNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc596277-a478-452d-8562-a63da5917aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = 'PedalMeDatasetLoader'\n",
    "Method = 'gnar' # 'stgcn','estgcn','gnar' \n",
    "Missingtype = 'randomly'  # None, 'randomly' and 'block' \n",
    "lag = 4 # 1,2,3,4 ... \n",
    "Number_of_filters = None # 16,24,32, ... \n",
    "Interpolation = 'Linear' # None, 'mean', 'linear'\n",
    "iterable = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41814ad1-6894-4685-949f-482422168504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnar = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43354b7e-971e-4106-93e3-955b987e7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Missingrate in rate:\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    gnar = GNAR_Missing(Dataset, df, iterable,Method, Missingrate, Missingtype, lag, Number_of_filters, Interpolation)\n",
    "    gnar.iter()\n",
    "    df_add = gnar.df.copy()\n",
    "    df_gnar = pd.concat([df_gnar,df_add],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d81f39-8c51-473f-b9c1-431372106038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(df_gnar, './data/Pedal_gnar_randomly_by_rate.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

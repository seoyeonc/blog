{
 "cells": [
  {
   "cell_type": "raw",
   "id": "19a1409b-8eb6-49f1-8c2d-aa227c14b8b5",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"**[LLM]**Transformer_META\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-08-01\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d3976-300d-4665-9e63-64506d6f9d55",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05ea4af3-1006-4a87-89d6-9cb8630d4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers accelerate sentencepiece\n",
    "# !huggingface-cli login\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400f77c-8e7d-402c-8fc3-b2d614dcef63",
   "metadata": {},
   "source": [
    "# 텍스트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07d631-7530-4b7e-ae29-53db514cbe0d",
   "metadata": {},
   "source": [
    "## Load a model & tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e93d75-0be8-4eaa-bf97-a49f4354b30a",
   "metadata": {},
   "source": [
    "### chat version은 txt 주고 받는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "054c1247-d20c-4fb4-a31a-9198167645f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af522a75-5d53-421f-9e83-dbfd91d32e5c",
   "metadata": {},
   "source": [
    "`AutoTokenizer.from_pretrained`\n",
    "\n",
    "- 사전 훈련된 model 가져와\n",
    "- 인증한 tokenizer를 자동으로 선택하고 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865fdd3-040b-46f6-ae27-653f0ca1ea1d",
   "metadata": {},
   "source": [
    "*꼭 모델을 지정해주고 입력, 바로 모델을 pretrainded에 넣으면 에러 뜸*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50183d44-5a52-4e0e-bfb6-3584b20a4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model,\n",
    "    use_auth_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a73e9e-b171-4ddf-b220-7dd681a940db",
   "metadata": {},
   "source": [
    "사용가능한 pretrained된 model들 종류 아직 llama2는 업데이트되지 않은듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48cc943-ba46-4bbf-b877-04bf5e67414c",
   "metadata": {},
   "source": [
    "    - **albert** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (ALBERT model)\n",
    "    - **align** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ALIGN model)\n",
    "    - **bart** -- [`BartTokenizer`] or [`BartTokenizerFast`] (BART model)\n",
    "    - **barthez** -- [`BarthezTokenizer`] or [`BarthezTokenizerFast`] (BARThez model)\n",
    "    - **bartpho** -- [`BartphoTokenizer`] (BARTpho model)\n",
    "    - **bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (BERT model)\n",
    "    - **bert-generation** -- [`BertGenerationTokenizer`] (Bert Generation model)\n",
    "    - **bert-japanese** -- [`BertJapaneseTokenizer`] (BertJapanese model)\n",
    "    - **bertweet** -- [`BertweetTokenizer`] (BERTweet model)\n",
    "    - **big_bird** -- [`BigBirdTokenizer`] or [`BigBirdTokenizerFast`] (BigBird model)\n",
    "    - **bigbird_pegasus** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (BigBird-Pegasus model)\n",
    "    - **biogpt** -- [`BioGptTokenizer`] (BioGpt model)\n",
    "    - **blenderbot** -- [`BlenderbotTokenizer`] or [`BlenderbotTokenizerFast`] (Blenderbot model)\n",
    "    - **blenderbot-small** -- [`BlenderbotSmallTokenizer`] (BlenderbotSmall model)\n",
    "    - **blip** -- [`BertTokenizer`] or [`BertTokenizerFast`] (BLIP model)\n",
    "    - **blip-2** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (BLIP-2 model)\n",
    "    - **bloom** -- [`BloomTokenizerFast`] (BLOOM model)\n",
    "    - **bridgetower** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (BridgeTower model)\n",
    "    - **byt5** -- [`ByT5Tokenizer`] (ByT5 model)\n",
    "    - **camembert** -- [`CamembertTokenizer`] or [`CamembertTokenizerFast`] (CamemBERT model)\n",
    "    - **canine** -- [`CanineTokenizer`] (CANINE model)\n",
    "    - **chinese_clip** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Chinese-CLIP model)\n",
    "    - **clap** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (CLAP model)\n",
    "    - **clip** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (CLIP model)\n",
    "    - **clipseg** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (CLIPSeg model)\n",
    "    - **codegen** -- [`CodeGenTokenizer`] or [`CodeGenTokenizerFast`] (CodeGen model)\n",
    "    - **convbert** -- [`ConvBertTokenizer`] or [`ConvBertTokenizerFast`] (ConvBERT model)\n",
    "    - **cpm** -- [`CpmTokenizer`] or [`CpmTokenizerFast`] (CPM model)\n",
    "    - **cpmant** -- [`CpmAntTokenizer`] (CPM-Ant model)\n",
    "    - **ctrl** -- [`CTRLTokenizer`] (CTRL model)\n",
    "    - **data2vec-text** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (Data2VecText model)\n",
    "    - **deberta** -- [`DebertaTokenizer`] or [`DebertaTokenizerFast`] (DeBERTa model)\n",
    "    - **deberta-v2** -- [`DebertaV2Tokenizer`] or [`DebertaV2TokenizerFast`] (DeBERTa-v2 model)\n",
    "    - **distilbert** -- [`DistilBertTokenizer`] or [`DistilBertTokenizerFast`] (DistilBERT model)\n",
    "    - **dpr** -- [`DPRQuestionEncoderTokenizer`] or [`DPRQuestionEncoderTokenizerFast`] (DPR model)\n",
    "    - **electra** -- [`ElectraTokenizer`] or [`ElectraTokenizerFast`] (ELECTRA model)\n",
    "    - **ernie** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ERNIE model)\n",
    "    - **ernie_m** -- [`ErnieMTokenizer`] (ErnieM model)\n",
    "    - **esm** -- [`EsmTokenizer`] (ESM model)\n",
    "    - **flaubert** -- [`FlaubertTokenizer`] (FlauBERT model)\n",
    "    - **fnet** -- [`FNetTokenizer`] or [`FNetTokenizerFast`] (FNet model)\n",
    "    - **fsmt** -- [`FSMTTokenizer`] (FairSeq Machine-Translation model)\n",
    "    - **funnel** -- [`FunnelTokenizer`] or [`FunnelTokenizerFast`] (Funnel Transformer model)\n",
    "    - **git** -- [`BertTokenizer`] or [`BertTokenizerFast`] (GIT model)\n",
    "    - **gpt-sw3** -- [`GPTSw3Tokenizer`] (GPT-Sw3 model)\n",
    "    - **gpt2** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (OpenAI GPT-2 model)\n",
    "    - **gpt_bigcode** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPTBigCode model)\n",
    "    - **gpt_neo** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPT Neo model)\n",
    "    - **gpt_neox** -- [`GPTNeoXTokenizerFast`] (GPT NeoX model)\n",
    "    - **gpt_neox_japanese** -- [`GPTNeoXJapaneseTokenizer`] (GPT NeoX Japanese model)\n",
    "    - **gptj** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPT-J model)\n",
    "    - **gptsan-japanese** -- [`GPTSanJapaneseTokenizer`] (GPTSAN-japanese model)\n",
    "    - **groupvit** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (GroupViT model)\n",
    "    - **herbert** -- [`HerbertTokenizer`] or [`HerbertTokenizerFast`] (HerBERT model)\n",
    "    - **hubert** -- [`Wav2Vec2CTCTokenizer`] (Hubert model)\n",
    "    - **ibert** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (I-BERT model)\n",
    "    - **jukebox** -- [`JukeboxTokenizer`] (Jukebox model)\n",
    "    - **layoutlm** -- [`LayoutLMTokenizer`] or [`LayoutLMTokenizerFast`] (LayoutLM model)\n",
    "    - **layoutlmv2** -- [`LayoutLMv2Tokenizer`] or [`LayoutLMv2TokenizerFast`] (LayoutLMv2 model)\n",
    "    - **layoutlmv3** -- [`LayoutLMv3Tokenizer`] or [`LayoutLMv3TokenizerFast`] (LayoutLMv3 model)\n",
    "    - **layoutxlm** -- [`LayoutXLMTokenizer`] or [`LayoutXLMTokenizerFast`] (LayoutXLM model)\n",
    "    - **led** -- [`LEDTokenizer`] or [`LEDTokenizerFast`] (LED model)\n",
    "    - **lilt** -- [`LayoutLMv3Tokenizer`] or [`LayoutLMv3TokenizerFast`] (LiLT model)\n",
    "    - **llama** -- [`LlamaTokenizer`] or [`LlamaTokenizerFast`] (LLaMA model)\n",
    "    - **longformer** -- [`LongformerTokenizer`] or [`LongformerTokenizerFast`] (Longformer model)\n",
    "    - **longt5** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (LongT5 model)\n",
    "    - **luke** -- [`LukeTokenizer`] (LUKE model)\n",
    "    - **lxmert** -- [`LxmertTokenizer`] or [`LxmertTokenizerFast`] (LXMERT model)\n",
    "    - **m2m_100** -- [`M2M100Tokenizer`] (M2M100 model)\n",
    "    - **marian** -- [`MarianTokenizer`] (Marian model)\n",
    "    - **mbart** -- [`MBartTokenizer`] or [`MBartTokenizerFast`] (mBART model)\n",
    "    - **mbart50** -- [`MBart50Tokenizer`] or [`MBart50TokenizerFast`] (mBART-50 model)\n",
    "    - **mega** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (MEGA model)\n",
    "    - **megatron-bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Megatron-BERT model)\n",
    "    - **mgp-str** -- [`MgpstrTokenizer`] (MGP-STR model)\n",
    "    - **mluke** -- [`MLukeTokenizer`] (mLUKE model)\n",
    "    - **mobilebert** -- [`MobileBertTokenizer`] or [`MobileBertTokenizerFast`] (MobileBERT model)\n",
    "    - **mpnet** -- [`MPNetTokenizer`] or [`MPNetTokenizerFast`] (MPNet model)\n",
    "    - **mt5** -- [`MT5Tokenizer`] or [`MT5TokenizerFast`] (MT5 model)\n",
    "    - **mvp** -- [`MvpTokenizer`] or [`MvpTokenizerFast`] (MVP model)\n",
    "    - **nezha** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Nezha model)\n",
    "    - **nllb** -- [`NllbTokenizer`] or [`NllbTokenizerFast`] (NLLB model)\n",
    "    - **nllb-moe** -- [`NllbTokenizer`] or [`NllbTokenizerFast`] (NLLB-MOE model)\n",
    "    - **nystromformer** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (Nyströmformer model)\n",
    "    - **oneformer** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (OneFormer model)\n",
    "    - **openai-gpt** -- [`OpenAIGPTTokenizer`] or [`OpenAIGPTTokenizerFast`] (OpenAI GPT model)\n",
    "    - **opt** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (OPT model)\n",
    "    - **owlvit** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (OWL-ViT model)\n",
    "    - **pegasus** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (Pegasus model)\n",
    "    - **pegasus_x** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (PEGASUS-X model)\n",
    "    - **perceiver** -- [`PerceiverTokenizer`] (Perceiver model)\n",
    "    - **phobert** -- [`PhobertTokenizer`] (PhoBERT model)\n",
    "    - **pix2struct** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (Pix2Struct model)\n",
    "    - **plbart** -- [`PLBartTokenizer`] (PLBart model)\n",
    "    - **prophetnet** -- [`ProphetNetTokenizer`] (ProphetNet model)\n",
    "    - **qdqbert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (QDQBert model)\n",
    "    - **rag** -- [`RagTokenizer`] (RAG model)\n",
    "    - **realm** -- [`RealmTokenizer`] or [`RealmTokenizerFast`] (REALM model)\n",
    "    - **reformer** -- [`ReformerTokenizer`] or [`ReformerTokenizerFast`] (Reformer model)\n",
    "    - **rembert** -- [`RemBertTokenizer`] or [`RemBertTokenizerFast`] (RemBERT model)\n",
    "    - **retribert** -- [`RetriBertTokenizer`] or [`RetriBertTokenizerFast`] (RetriBERT model)\n",
    "    - **roberta** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (RoBERTa model)\n",
    "    - **roberta-prelayernorm** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (RoBERTa-PreLayerNorm model)\n",
    "    - **roc_bert** -- [`RoCBertTokenizer`] (RoCBert model)\n",
    "    - **roformer** -- [`RoFormerTokenizer`] or [`RoFormerTokenizerFast`] (RoFormer model)\n",
    "    - **rwkv** -- [`GPTNeoXTokenizerFast`] (RWKV model)\n",
    "    - **speech_to_text** -- [`Speech2TextTokenizer`] (Speech2Text model)\n",
    "    - **speech_to_text_2** -- [`Speech2Text2Tokenizer`] (Speech2Text2 model)\n",
    "    - **speecht5** -- [`SpeechT5Tokenizer`] (SpeechT5 model)\n",
    "    - **splinter** -- [`SplinterTokenizer`] or [`SplinterTokenizerFast`] (Splinter model)\n",
    "    - **squeezebert** -- [`SqueezeBertTokenizer`] or [`SqueezeBertTokenizerFast`] (SqueezeBERT model)\n",
    "    - **switch_transformers** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (SwitchTransformers model)\n",
    "    - **t5** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (T5 model)\n",
    "    - **tapas** -- [`TapasTokenizer`] (TAPAS model)\n",
    "    - **tapex** -- [`TapexTokenizer`] (TAPEX model)\n",
    "    - **transfo-xl** -- [`TransfoXLTokenizer`] (Transformer-XL model)\n",
    "    - **vilt** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ViLT model)\n",
    "    - **visual_bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (VisualBERT model)\n",
    "    - **wav2vec2** -- [`Wav2Vec2CTCTokenizer`] (Wav2Vec2 model)\n",
    "    - **wav2vec2-conformer** -- [`Wav2Vec2CTCTokenizer`] (Wav2Vec2-Conformer model)\n",
    "    - **wav2vec2_phoneme** -- [`Wav2Vec2PhonemeCTCTokenizer`] (Wav2Vec2Phoneme model)\n",
    "    - **whisper** -- [`WhisperTokenizer`] or [`WhisperTokenizerFast`] (Whisper model)\n",
    "    - **xclip** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (X-CLIP model)\n",
    "    - **xglm** -- [`XGLMTokenizer`] or [`XGLMTokenizerFast`] (XGLM model)\n",
    "    - **xlm** -- [`XLMTokenizer`] (XLM model)\n",
    "    - **xlm-prophetnet** -- [`XLMProphetNetTokenizer`] (XLM-ProphetNet model)\n",
    "    - **xlm-roberta** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (XLM-RoBERTa model)\n",
    "    - **xlm-roberta-xl** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (XLM-RoBERTa-XL model)\n",
    "    - **xlnet** -- [`XLNetTokenizer`] or [`XLNetTokenizerFast`] (XLNet model)\n",
    "    - **xmod** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (X-MOD model)\n",
    "    - **yoso** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (YOSO model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d877f8-83a8-4ad2-835a-25de6df926e2",
   "metadata": {},
   "source": [
    "transformers.pipeline\n",
    "\n",
    "- 사전 훈련된 모델과 tokenizer를 자동으로 선택\n",
    "- `torch_dtype`=torch.float16 데이터 타입 지정\n",
    "- `\"text-generation\"` 쓰면 입력 문장 이어서 텍스트 생성하도록 함.\n",
    "- `device_map=\"auto\"` 쓰면 gpu 혹은 cpu 자동 할당 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbcefe88-9c5a-4236-8613-67784f47f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 614/614 [00:00<00:00, 680kB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00,  5.04it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c59db1-4427-4c32-a540-c235d7f67f01",
   "metadata": {},
   "source": [
    "`\"text-generation\"`이외에 쓸 수 있는 task option 들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef53af1-cbd8-482b-a5bc-d0e74e3a43fa",
   "metadata": {},
   "source": [
    " task (`str`):\n",
    "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
    "\n",
    "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
    "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
    "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
    "            - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
    "            - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
    "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
    "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
    "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
    "            - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
    "            - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
    "            - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n",
    "            - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
    "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
    "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
    "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
    "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
    "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
    "              [`TextClassificationPipeline`].\n",
    "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
    "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
    "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
    "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
    "            - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
    "            - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
    "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
    "            - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
    "            - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n",
    "            - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a1db02-9d06-458e-80b0-ccc6ad3d7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x, max_length=200):\n",
    "    sequences = pipeline(\n",
    "        x,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return sequences[0][\"generated_text\"].replace(x, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769ccd2-ce47-4cb6-a8e4-6c1bd771e7a3",
   "metadata": {},
   "source": [
    "이 pc에서 실행은 되지 않는다..colab에서!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cf2bd-475e-44ce-93c0-ad12efb62cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen('I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d265a1-0cbe-484e-b5cd-f6c145b8d8f9",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2decd15-2b45-4827-ae4a-f2a6833cb21e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55228d89-8e25-4afc-b8aa-64ca1de75aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen(\"대한민국에서 유명한 인공지능 유튜버 3명만 나열해봐.\", 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532f7bd-d09f-44a1-bacd-cb4b3f12a543",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9a078-aae3-4eef-a897-acb6bfdf26e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b02e7-24a4-4e48-b09d-28c7008d0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen(\"유튜브 빵형의 개발도상국 채널 알아?\", 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ada65-0e56-4725-bbe1-e14be1fd490d",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4a4f4-12e9-48d4-aa70-f0d1d8f5ab6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8ba6e1-3e6a-4cf8-a878-b9c2b27d3b15",
   "metadata": {},
   "source": [
    "### 단순 txt 생성하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e930d8-4c30-4f09-9ed4-0bc543622f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\n",
    "    model2,\n",
    "    use_auth_token=True,\n",
    ")\n",
    "\n",
    "pipeline2 = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model2,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dc998-dd32-4053-8789-9d0e3ac89ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen2(x, max_length=200):\n",
    "    sequences = pipeline2(\n",
    "        x,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return sequences[0][\"generated_text\"].replace(x, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad258ca8-8e8e-437a-8e93-f07ed18874a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen2('I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837bedb-b885-4fb0-bcfa-d1a20b0f53ed",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2415a85-772d-47f4-8a82-9978d10652eb",
   "metadata": {},
   "source": [
    "I love \"Breaking Bad\" too, though I'm not sure I would like \"Band\", I am a little afraid it's too \"gory\" for me. What about \"House\" or \"Lost\" and some of the others mentioned in my other answer (e.g. \"Fringe\" has been a bit of a guilty pleasure of mine, and I am currently watching \"Downton Abbey\" which I really love)?\n",
    "I don't think I could watch \"Game of Thrones\" but I am interested in \"Lost\" and I'll give it a shot. I'm a bit of a chick-flick fanatic though and I think I'd love \"The Good Wife\" and maybe \"Homeland\".\n",
    "Oh and \"House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabd886-405d-49b3-bf40-aa51ffbc6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen(\"대한민국에서 유명한 인공지능 유튜버 3명만 나열해봐.\", 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67184975-c265-4539-b11c-62732038e391",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2317b-d532-4eaa-9e5b-ac1ec0a0b30a",
   "metadata": {},
   "source": [
    "2015년 11월 3일, 대한민국의 유튜버 출신이자 개발자였던 이준수가 자연어 이해의 능력을 인공지능을 통해 갖기 위한 프로젝트를 시작하였다. 얼마 지나지 않고 KAIST에서 이루어진 연구에 영감을 얻은 이준수는 이를 인공지능 데이터를 획득했다. 초창기 인공지능 획득 과정은 심지어 아시아 내의 인공지능 컬렉터들이 인공지능 데이터를 모아온 것과, 그 자체로 인공지능 컬렉터라는 일자리가 늘어난 것은 사실이다. 인공지능 데이터는 특별히 액세스가 필요한 괜찮았으나, 말하자면 분명한 경우, 인공지능 컬렉터들은 돈으로 인공지능 데이터를 구워오며 돈은 그들의 수명과 길이가 연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3872c-0097-4480-a361-07b5cc6ef1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen(\"유튜브 빵형의 개발도상국 채널 알아?\", 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddded081-5968-44b2-9424-314eb921abd2",
   "metadata": {},
   "source": [
    "- result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f71ca5-6dcf-42bc-8237-1e472e087f04",
   "metadata": {},
   "source": [
    "할아버지 폭투리 변신 (2013.01.19)\"\n",
    "1. 압태, 2020. 6. 8. \"아이유가 입었던 클럽웨어 판권 소송에 대한 배신 행위 야기한 사실 근거 없다\". 아툴립트. 2020년 6월 28일에 원본 문서에서 보존된 문서. 2020년 6월 11일에 확인함. CS1 관리 - 추가 문서 (루마니아)(죄인에서 죄 후에 거듭된 행위를 받을 수 있음)\n",
    "2. 루마니아 최고재판소는 2017. 10. 24 이격 피고인에게 적법한 재판결정을 채택했다.\n",
    "3. 루마니아 최고 재판소는 이격 피고인에 대해 \"배심원 투표에서 엄청난 비중으로 피고인의 재판에 관대도덕적 반격\" 또는 \"피고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2228c1-2179-4d24-aed6-5eaa6f198dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
